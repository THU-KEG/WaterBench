{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入tabulate模块，它可以将数据转换为markdown表格格式\n",
    "# import tabulate\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## p1 = r\"(?P<misson_name>.+)_(?P<gamma>\\d+(\\.\\d+)?)_(?P<delta>.+)_(?P<threshold>.+)_z\"\n",
    "## \n",
    "## file = \"alpacafarm_0.75_5.0_6.0_z.jsonl\"\n",
    "## matcher1 = re.match(p1, file)\n",
    "## misson_name = matcher1.group(\"misson_name\")\n",
    "## threshold = matcher1.group(\"threshold\")\n",
    "## \n",
    "## print(misson_name, threshold)\n",
    "\n",
    "# g0.5 d5.0\n",
    "# g0.25 d5.0\n",
    "# g0.75 d5.0\n",
    "# g0.5 d2.0\n",
    "# g0.25 d2.0\n",
    "# g0.9 d5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subfolder is: llama2-7b-chat-4k_old_g0.75_d5.0_hard\n",
      "subfolder is: llama2-7b-chat-4k_v2_g0.25_d2.0\n",
      "subfolder is: llama2-7b-chat-4k_old_g0.5_d2.0_hard\n",
      "subfolder is: llama2-7b-chat-4k_old_g0.25_d5.0_hard\n",
      "subfolder is: llama2-7b-chat-4k_gpt_g0.5_d5.0\n",
      "subfolder is: llama2-7b-chat-4k_v2_g0.9_d5.0\n",
      "subfolder is: llama2-7b-chat-4k_old_g0.5_d2.0\n",
      "subfolder is: llama2-7b-chat-4k_gpt_g0.5_d2.0\n",
      "subfolder is: llama2-7b-chat-4k_gpt_g0.9_d5.0\n",
      "subfolder is: llama2-7b-chat-4k_old_g0.25_d2.0\n",
      "subfolder is: llama2-7b-chat-4k_old_g0.9_d5.0_hard\n",
      "subfolder is: llama2-7b-chat-4k_v2_g0.5_d5.0\n",
      "subfolder is: llama2-7b-chat-4k_gpt_g0.25_d5.0\n",
      "subfolder is: llama2-7b-chat-4k_v2_g0.75_d5.0\n",
      "subfolder is: llama2-7b-chat-4k_v2_g0.5_d2.0\n",
      "subfolder is: llama2-7b-chat-4k_old_g0.9_d5.0\n",
      "subfolder is: llama2-7b-chat-4k_old_g0.5_d5.0_hard\n",
      "subfolder is: llama2-7b-chat-4k_new_g0.5_d5.0\n",
      "subfolder is: llama2-7b-chat-4k_no_g0.5_d5.0\n",
      "subfolder is: llama2-7b-chat-4k_gpt_g0.75_d5.0\n",
      "subfolder is: llama2-7b-chat-4k_old_g0.25_d2.0_hard\n",
      "subfolder is: llama2-7b-chat-4k_v2_g0.25_d5.0\n",
      "subfolder is: llama2-7b-chat-4k_old_g0.75_d5.0\n",
      "subfolder is: llama2-7b-chat-4k_old_g0.5_d5.0\n",
      "subfolder is: llama2-7b-chat-4k_old_g0.25_d5.0\n",
      "            model_name             mission_name mode gamma delta  threshold  \\\n",
      "0    llama2-7b-chat-4k               alpacafarm  old  0.75   5.0        6.0   \n",
      "1    llama2-7b-chat-4k   konwledge_memorization  old  0.75   5.0        6.0   \n",
      "2    llama2-7b-chat-4k                    qmsum  old  0.75   5.0        6.0   \n",
      "3    llama2-7b-chat-4k               finance_qa  old  0.75   5.0        6.0   \n",
      "4    llama2-7b-chat-4k  konwledge_understanding  old  0.75   5.0        6.0   \n",
      "..                 ...                      ...  ...   ...   ...        ...   \n",
      "211  llama2-7b-chat-4k                    qmsum  old  0.25   5.0        6.0   \n",
      "212  llama2-7b-chat-4k  konwledge_understanding  old  0.25   5.0        6.0   \n",
      "213  llama2-7b-chat-4k                      lcc  old  0.25   5.0        6.0   \n",
      "214  llama2-7b-chat-4k               finance_qa  old  0.25   5.0        6.0   \n",
      "215  llama2-7b-chat-4k               alpacafarm  old  0.25   5.0        6.0   \n",
      "\n",
      "    bl_type    z_score  sum  \n",
      "0      hard   8.646414  805  \n",
      "1      hard   2.641556  200  \n",
      "2      hard   4.840824  200  \n",
      "3      hard   9.696045  200  \n",
      "4      hard   0.592229  200  \n",
      "..      ...        ...  ...  \n",
      "211    soft   7.724550  200  \n",
      "212    soft   2.025398  200  \n",
      "213    soft   6.130328  200  \n",
      "214    soft  10.500217  200  \n",
      "215    soft   9.231044  805  \n",
      "\n",
      "[216 rows x 9 columns]\n",
      "216\n"
     ]
    }
   ],
   "source": [
    "# load data from pred\n",
    "\n",
    "\n",
    "df = pd.DataFrame(columns=[\"model_name\", \"mission_name\", \"mode\", \"gamma\", \"delta\", \"threshold\", \"bl_type\", \"z_score\", \"sum\"])\n",
    "\n",
    "input_dir = \"./pred\"\n",
    "p = r\"(?P<model_name>.+)_(?P<mode>old|v2|gpt|new|no)_g(?P<gamma>.+)_d(?P<delta>\\d+(\\.\\d+)?)\"\n",
    "p1 = r\"(?P<misson_name>[a-zA-Z_]+)_(?P<gamma>\\d+(\\.\\d+)?)_(?P<delta>.+)_z\"\n",
    "\n",
    "num = 0\n",
    "# get all files from input_dir\n",
    "for subfolder in os.listdir(input_dir):\n",
    "    # print(\"subfolder is:\", subfolder)\n",
    "    matcher = re.match(p, subfolder)\n",
    "    model_name = matcher.group(\"model_name\")\n",
    "    mode = matcher.group(\"mode\")\n",
    "    gamma = matcher.group(\"gamma\")\n",
    "    delta = matcher.group(\"delta\")\n",
    "    \n",
    "    bl_type = \"None\"\n",
    "    bl_type = (subfolder.split(\"_\")[-1]).split(\".\")[0]\n",
    "    \n",
    "    if bl_type != \"hard\":\n",
    "        if \"old\" in subfolder:\n",
    "            bl_type = \"soft\"\n",
    "        else:\n",
    "            bl_type = \"None\"\n",
    "        \n",
    "        \n",
    "    # print(model_name, mode, gamma, delta, bl_type)\n",
    "    \n",
    "    z_score_path = os.path.join(input_dir, subfolder, \"z_score\")\n",
    "    if os.path.exists(z_score_path):\n",
    "        print(\"subfolder is:\", subfolder)\n",
    "        files = os.listdir(z_score_path)\n",
    "        \n",
    "        for file in files:\n",
    "            # print(file)\n",
    "            # read jsons\n",
    "            matcher1 = re.match(p1, file)\n",
    "            if matcher1:\n",
    "                misson_name = matcher1.group(\"misson_name\")\n",
    "                threshold = 6.0\n",
    "            else:\n",
    "                threshold = file.split(\"_\")[-2]\n",
    "            \n",
    "            with open(os.path.join(z_score_path, file), \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # get data\n",
    "            avarage_z = data[\"avarage_z\"]\n",
    "            sum = len(data[\"z_score_list\"])\n",
    "            # wm_pred_avarage = data[\"wm_pred_avarage\"]\n",
    "            \n",
    "            temp = pd.DataFrame({\n",
    "                \"model_name\": [model_name],\n",
    "                \"mode\": [mode],\n",
    "                \"mission_name\": [misson_name],\n",
    "                \"gamma\": [gamma],\n",
    "                \"delta\":[delta],\n",
    "                \"threshold\": [threshold],\n",
    "                \"bl_type\": [bl_type],\n",
    "                \"z_score\": [avarage_z],\n",
    "                \"sum\": [sum]})\n",
    "            \n",
    "            df = pd.concat([df, temp], ignore_index=True)\n",
    "            num += 1\n",
    "\n",
    "df.to_csv(\"z_score.csv\")           \n",
    "print(df)\n",
    "print(num)\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            model_name             mission_name mode gamma delta  threshold  \\\n",
      "154  llama2-7b-chat-4k                      lcc   no   0.5   5.0        6.0   \n",
      "137  llama2-7b-chat-4k                 hotpotqa  old   0.9   5.0        6.0   \n",
      "141  llama2-7b-chat-4k  konwledge_understanding  old   0.9   5.0        6.0   \n",
      "126  llama2-7b-chat-4k  konwledge_understanding   v2   0.5   2.0        6.0   \n",
      "97   llama2-7b-chat-4k  konwledge_understanding  old   0.9   5.0        6.0   \n",
      "..                 ...                      ...  ...   ...   ...        ...   \n",
      "180  llama2-7b-chat-4k              longform_qa  old  0.25   2.0        6.0   \n",
      "31   llama2-7b-chat-4k                    qmsum  old  0.25   5.0        6.0   \n",
      "177  llama2-7b-chat-4k                    qmsum  old  0.25   2.0        6.0   \n",
      "30   llama2-7b-chat-4k               multi_news  old  0.25   5.0        6.0   \n",
      "176  llama2-7b-chat-4k               multi_news  old  0.25   2.0        6.0   \n",
      "\n",
      "    bl_type    z_score  sum  \n",
      "154    None  -0.915615  200  \n",
      "137    soft  -0.717057  200  \n",
      "141    soft  -0.534699  200  \n",
      "126    None  -0.507295  200  \n",
      "97     hard  -0.487937  200  \n",
      "..      ...        ...  ...  \n",
      "180    hard  29.735363  200  \n",
      "31     hard  30.585075  200  \n",
      "177    hard  30.816006  200  \n",
      "30     hard  37.959408  200  \n",
      "176    hard  38.530666  200  \n",
      "\n",
      "[216 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "df_sorted = df.sort_values(by=\"z_score\", ascending=True)\n",
    "df_sorted.to_csv(\"z_score_sorted.csv\")           \n",
    "print(df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 ('wmklmm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "acdb7ce7ce850a195ea1a66ef30c55071e5db04eb4f79a2da398a13b17183832"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
