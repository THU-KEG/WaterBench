{"input": "", "context": "import numpy as np\nfrom numpy.linalg import inv\nimport os\n#see detail comments in hexahedra_4\nx0_v,y0_v,z0_v=np.array([1.,0.,0.]),np.array([0.,1.,0.]),np.array([0.,0.,1.])\n#anonymous function f1 calculating transforming matrix with the basis vector expressions,x1y1z1 is the original basis vector\n#x2y2z2 are basis of new coor defined in the original frame,new=T.orig\nf1=lambda x1,y1,z1,x2,y2,z2:np.array([[np.dot(x2,x1),np.dot(x2,y1),np.dot(x2,z1)],\\\n                                      [np.dot(y2,x1),np.dot(y2,y1),np.dot(y2,z1)],\\\n                                      [np.dot(z2,x1),np.dot(z2,y1),np.dot(z2,z1)]])\n#f2 calculate the distance b/ p1 and p2\nf2=lambda p1,p2:np.sqrt(np.sum((p1-p2)**2))\n#anonymous function f3 is to calculate the coordinates of basis with magnitude of 1.,p1 and p2 are coordinates for two known points, the \n#direction of the basis is pointing from p1 to p2\nf3=lambda p1,p2:(1./f2(p1,p2))*(p2-p1)+p1\nbasis=np.array([5.038,5.434,7.3707])\n#atoms to be checked for distance\natms_cell_half=[[0.653,1.1121,1.903],[0.847,0.6121,1.903],[0.306,0.744,1.75],[0.194,0.243,1.75],\\\n      [0.5,1.019,1.645],[0,0.518,1.645],[0.847,0.876,1.597],[0.653,0.375,1.597]]\natms_cell_full=[[0.153,0.9452,2.097],[0.347,0.4452,2.097],[0.653,1.1121,1.903],[0.847,0.6121,1.903],[0.,0.9691,1.855],[0.5,0.4691,1.855],[0.306,0.744,1.75],[0.194,0.243,1.75],\\\n      [0.5,1.019,1.645],[0,0.518,1.645],[0.847,0.876,1.597],[0.653,0.375,1.597]]\natms_cell=atms_cell_half\natms=np.append(np.array(atms_cell),np.array(atms_cell)+[-1,0,0],axis=0)\natms=np.append(atms,np.array(atms_cell)+[1,0,0],axis=0)\natms=np.append(atms,np.array(atms_cell)+[0,-1,0],axis=0)\natms=np.append(atms,np.array(atms_cell)+[0,1,0],axis=0)\natms=np.append(atms,np.array(atms_cell)+[1,1,0],axis=0)\natms=np.append(atms,np.array(atms_cell)+[-1,-1,0],axis=0)\natms=np.append(atms,np.array(atms_cell)+[1,-1,0],axis=0)\natms=np.append(atms,np.array(atms_cell)+[-1,1,0],axis=0)\natms=atms*basis\nO1,O2=[0.653,1.1121,1.903]*basis,[0.847,0.6121,1.903]*basis\nO3,O4=[0.306,0.744,1.75]*basis,[0.194,0.243,1.75]*basis\nO11_top,O12_top=[0.153,0.9452,2.097]*basis,[0.347,0.4452,2.097]*basis\nanchor1,anchor2=O1,O2\nclass share_face():\n    def __init__(self,face=np.array([[0.,0.,2.5],[2.5,0,0.],[0,2.5,0]]),mirror=False):\n        #pass in the vector of three known vertices\n        #mirror setting will make the sorbate projecting in an opposite direction referenced to the p0p1p2 plane\n        self.face=face\n        self.mirror=mirror\n    def share_face_init(self,flag='right_triangle',dr=[0,0,0]):\n        #octahedra has a high symmetrical configuration,there are only two types of share face.\n        #flag 'right_triangle' means the shared face is defined by a right triangle with two equal lateral and the other one\n        #passing through body center;'regular_triangle' means the shared face is defined by a regular triangle\n        #dr is used for fitting purpose, set this to be 0 to get a regular octahedral\n        p0,p1,p2=self.face[0,:],self.face[1,:],self.face[2,:]\n        #consider the possible unregular shape for the known triangle\n        dist_list=[np.sqrt(np.sum((p0-p1)**2)),np.sqrt(np.sum((p1-p2)**2)),np.sqrt(np.sum((p0-p2)**2))]\n        index=dist_list.index(max(dist_list)) \n        \n        if flag=='right_triangle':\n        #'2_1'tag means 2 atoms at upside and downside, the other one at middle layer\n            if index==0:self.center_point=(p0+p1)/2\n            elif index==1:self.center_point=(p1+p2)/2\n            elif index==2:self.center_point=(p0+p2)/2\n            else:self.center_point=(p0+p2)/2\n        elif flag=='regular_triangle':\n            #the basic idea is building a sperical coordinate system centering at the middle point of each two of the three corner\n            #and then calculate the center point through theta angle, which can be easily calculated under that geometrical seting\n            def _cal_center(p1,p2,p0):\n                origin=(p1+p2)/2\n                y_v=f3(np.zeros(3),p1-origin)\n                x_v=f3(np.zeros(3),p0-origin)\n                z_v=np.cross(x_v,y_v)\n                T=f1(x0_v,y0_v,z0_v,x_v,y_v,z_v)\n                r=f2(p1,p2)/2.\n                phi=0.\n                theta=np.pi/2+np.arctan(np.sqrt(2))\n                if self.mirror:\n                    theta=np.pi/2-np.arctan(np.sqrt(2))\n                center_point_new=np.array([r*np.cos(phi)*np.sin(theta),r*np.sin(phi)*np.sin(theta),r*np.cos(theta)])\n                center_point_org=np.dot(inv(T),center_point_new)+origin\n                #the two possible points are related to each other via invertion over the origin\n                if abs(f2(center_point_org,p0)-f2(center_point_org,p1))>0.00001:\n                    center_point_org=2*origin-center_point_org\n                return center_point_org\n            self.center_point=_cal_center(p0,p1,p2)\n        self._find_the_other_three(self.center_point,p0,p1,p2,flag,dr)\n        \n    def _find_the_other_three(self,center_point,p0,p1,p2,flag,dr):\n        dist_list=[np.sqrt(np.sum((p0-p1)**2)),np.sqrt(np.sum((p1-p2)**2)),np.sqrt(np.sum((p0-p2)**2))]\n        index=dist_list.index(max(dist_list))\n        \n        if flag=='right_triangle':\n            def _cal_points(center_point,p0,p1,p2):\n                #here p0-->p1 is the long lateral\n                z_v=f3(np.zeros(3),p2-center_point)\n                x_v=f3(np.zeros(3),p0-center_point)\n                y_v=np.cross(z_v,x_v)\n                T=f1(x0_v,y0_v,z0_v,x_v,y_v,z_v)\n                r=f2(center_point,p0)\n                #print [r*np.cos(np.pi/2)*np.sin(np.pi/2),r*np.sin(np.pi/2)*np.sin(np.pi/2),0]\n                p3_new=np.array([r*np.cos(np.pi/2)*np.sin(np.pi/2),r*np.sin(np.pi/2)*np.sin(np.pi/2),0])\n                p4_new=np.array([r*np.cos(3*np.pi/2)*np.sin(np.pi/2),r*np.sin(3*np.pi/2)*np.sin(np.pi/2),0])\n                p3_old=np.dot(inv(T),p3_new)+center_point\n                p4_old=np.dot(inv(T),p4_new)+center_point\n                p5_old=2*center_point-p2\n                return T,r,p3_old,p4_old,p5_old\n            if index==0:#p0-->p1 long lateral\n                self.T,self.r,self.p3,self.p4,self.p5=_cal_points(center_point,p0,p1,p2)\n            elif index==1:#p1-->p2 long lateral\n                self.T,self.r,self.p3,self.p4,self.p5=_cal_points(center_point,p1,p2,p0)\n            elif index==2:#p0-->p2 long lateral\n                self.T,self.r,self.p3,self.p4,self.p5=_cal_points(center_point,p0,p2,p1)\n        elif flag=='regular_triangle':\n            x_v=f3(np.zeros(3),p2-center_point)\n            y_v=f3(np.zeros(3),p0-center_point)\n            z_v=np.cross(x_v,x_v)\n            self.T=f1(x0_v,y0_v,z0_v,x_v,y_v,z_v)\n            self.r=f2(center_point,p0)\n            self.p3=(center_point-p0)*((self.r+dr[0])/self.r)+center_point\n            self.p4=(center_point-p1)*((self.r+dr[1])/self.r)+center_point\n            self.p5=(center_point-p2)*((self.r+dr[2])/self.r)+center_point\n            #print f2(self.center_point,self.p3),f2(self.center_point,self.p4)\n             \n    def cal_point_in_fit(self,r,theta,phi):\n        #during fitting,use the same coordinate system, but a different origin\n        #note the origin_coor is the new position for the sorbate0, ie new center point\n        x=r*np.cos(phi)*np.sin(theta)\n        y=r*np.sin(phi)*np.sin(theta)\n        z=r*np.cos(theta)\n        point_in_original_coor=np.dot(inv(self.T),np.array([x,y,z]))+self.center_point\n        return point_in_original_coor\n    \n    def print_xyz(self,file=\"D:\\\\test.xyz\"):\n        f=open(file,\"w\")\n        f.write('7\\n#\\n')\n        s = '%-5s   %7.5e   %7.5e   %7.5e\\n' % ('Sb', self.center_point[0],self.center_point[1],self.center_point[2])\n        f.write(s)\n        s = '%-5s   %7.5e   %7.5e   %7.5e\\n' % ('O', self.face[0,:][0],self.face[0,:][1],self.face[0,:][2])\n        f.write(s)\n        s = '%-5s   %7.5e   %7.5e   %7.5e\\n' % ('O', self.face[1,:][0],self.face[1,:][1],self.face[1,:][2])\n        f.write(s)\n        s = '%-5s   %7.5e   %7.5e   %7.5e\\n' % ('O', self.face[2,:][0],self.face[2,:][1],self.face[2,:][2])\n        f.write(s)\n        s = '%-5s   %7.5e   %7.5e   %7.5e\\n' % ('O', self.p3[0],self.p3[1],self.p3[2])\n        f.write(s)\n        s = '%-5s   %7.5e   %7.5e   %7.5e\\n' % ('O', self.p4[0],self.p4[1],self.p4[2])\n        f.write(s)\n        s = '%-5s   %7.5e   %7.5e   %7.5e' % ('O', self.p5[0],self.p5[1],self.p5[2])\n        f.write(s)\n        f.close()  \n        \nclass share_edge(share_face):\n    def __init__(self,edge=np.array([[0.,0.,0.],[5,5,5]])):\n        self.edge=edge\n        \n    def cal_p2(self,ref_p=None,phi=np.pi/2,flag='off_center',**args):\n        p0=self.edge[0,:]\n        p1=self.edge[1,:]\n        origin=(p0+p1)/2\n        dist=f2(p0,p1)\n        diff=p1-p0\n        c=np.sum(p1**2-p0**2)\n        ref_point=0\n        if ref_p!=None:\n            ref_point=np.cross(p0-origin,np.cross(p0-origin,ref_p-origin))+origin\n            #print ref_point\n        elif diff[2]==0:\n            ref_point=origin+[0,0,1]\n        else:\n            x,y,z=0.,0.,0.\n            #set the reference point as simply as possible,using the same distance assumption, we end up with a plane equation\n            #then we try to find one cross point between one of the three basis and the plane we just got\n            #here combine two line equations (ref-->p0,and ref-->p1,the distance should be the same)\n            if diff[0]!=0:\n                x=c/(2*diff[0])\n            elif diff[1]!=0.:\n                y=c/(2*diff[1])\n            elif diff[2]!=0.:\n                z=c/(2*diff[2])\n            ref_point=np.array([x,y,z])\n            if sum(ref_point)==0:\n                #if the vector (p0-->p1) pass through origin [0,0,0],we need to specify another point satisfying the same-distance condition\n                #here, we a known point (x0,y0,z0)([0,0,0] in this case) and the normal vector to calculate the plane equation, \n                #which is a(x-x0)+b(y-y0)+c(z-z0)=0, we specify x y to 1 and 0, calculate z value.\n                #a b c coresponds to vector origin-->p0\n                ref_point=np.array([1.,0.,-p0[0]/p0[2]])\n        if flag=='cross_center':\n            x1_v=f3(np.zeros(3),ref_point-origin)\n            z1_v=f3(np.zeros(3),p1-origin)\n            y1_v=np.cross(z1_v,x1_v)\n            T=f1(x0_v,y0_v,z0_v,x1_v,y1_v,z1_v)\n            r=dist/2\n            #here phi=[0,2pi]\n            x_p2=r*np.cos(phi)*np.sin(np.pi/2)\n            y_p2=r*np.sin(phi)*np.sin(np.pi/2)\n            z_p2=0\n            p2_new=np.array([x_p2,y_p2,z_p2])\n            p2_old=np.dot(inv(T),p2_new)+origin\n            self.p2=p2_old\n            self.face=np.append(self.edge,[p2_old],axis=0)\n            self.flag='right_triangle'\n        elif flag=='off_center':\n            x1_v=f3(np.zeros(3),ref_point-origin)\n            z1_v=f3(np.zeros(3),p1-origin)\n            y1_v=np.cross(z1_v,x1_v)\n            T=f1(x0_v,y0_v,z0_v,x1_v,y1_v,z1_v)\n            r=dist/2.\n            #note in this case, phi can be in the range of [0,2pi]\n            x_center=r*np.cos(phi)*np.sin(np.pi/2)\n            y_center=r*np.sin(phi)*np.sin(np.pi/2)\n            z_center=r*np.cos(np.pi/2)\n            center_org=np.dot(inv(T),np.array([x_center,y_center,z_center]))+origin\n            p2_old=2*center_org-p0\n            self.p2=p2_old\n            self.face=np.append(self.edge,[p2_old],axis=0)\n            self.flag='right_triangle'\n    \n    def all_in_all(self,phi=np.pi/2,ref_p=None,flag='off_center'):\n        self.cal_p2(ref_p=ref_p,phi=phi,flag=flag)\n        self.share_face_init(self.flag)\n        \n#steric_check will check the steric feasibility by changing the theta angle (0-pi) and or phi [0,2pi]\n#the dist bw sorbate(both metal and oxygen) and atms (defined on top) will be cal and compared to the cutting_limit\n#higher cutting limit will result in fewer items in return file (so be wise to choose cutting limit)\n#the container has 12 items, ie phi (rotation angle), theta, low_dis, apex coors (x,y,z), os1 coors(x,y,z),os2 coors(x,y,z)\n#in which the low_dis is the lowest dist between sorbate and atm \nclass steric_check(share_edge):\n    def __init__(self,p0=anchor1,p1=anchor2,cutting_limit=2.5):\n        self.edge=np.array([p0,p1])\n        self.cutting_limit=cutting_limit\n        self.container=np.zeros((1,18))[0:0]\n        print \"distance between anchor points is \",f2(p0,p1),'anstrom'\n    def steric_check(self,theta_res=0.1,phi=np.pi/2,flag='off_center',print_path=None):\n        #consider the steric constrain, flag 'off_center' (the center point is off the connection line of anchors)\n        #is more favorable\n", "outputs": ["        for theta in np.arange(0,np.pi,theta_res):"], "input_length": 2757, "output_length": 12, "length": 2769, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "b7d5576af7311b75becef64ac68e5e1b3d7fe9eb1785d34679f19854388d99c4"}
{"input": "", "context": "//\n// DO NOT REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n//\n// @Authors:\n//       peters\n//\n// Copyright 2004-2012 by OM International\n//\n// This file is part of OpenPetra.org.\n//\n// OpenPetra.org is free software: you can redistribute it and/or modify\n// it under the terms of the GNU General Public License as published by\n// the Free Software Foundation, either version 3 of the License, or\n// (at your option) any later version.\n//\n// OpenPetra.org is distributed in the hope that it will be useful,\n// but WITHOUT ANY WARRANTY; without even the implied warranty of\n// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n// GNU General Public License for more details.\n//\n// You should have received a copy of the GNU General Public License\n// along with OpenPetra.org.  If not, see <http://www.gnu.org/licenses/>.\n//\nusing System;\nusing System.Collections.Generic;\nusing System.Data;\nusing System.Windows.Forms;\nusing GNU.Gettext;\nusing Ict.Common;\nusing Ict.Common.Exceptions;\nusing Ict.Common.Verification;\nusing Ict.Petra.Client.App.Core;\nusing Ict.Petra.Client.App.Core.RemoteObjects;\nusing Ict.Petra.Client.MPartner.Gui;\nusing Ict.Petra.Shared;\nusing Ict.Petra.Shared.MConference;\nusing Ict.Petra.Shared.MConference.Data;\nusing Ict.Petra.Shared.MConference.Validation;\nusing Ict.Petra.Shared.MPartner;\nusing Ict.Petra.Shared.MPartner.Partner.Data;\nnamespace Ict.Petra.Client.MConference.Gui.Setup\n{\n    public partial class TFrmConferenceMasterSettings\n    {\n        /// PartnerKey for selected conference to be set from outside\n        public static Int64 FPartnerKey {\n            private get; set;\n        }\n        private void InitializeManualCode()\n        {\n            string ConferenceName;\n            // load data into dataset\n            FMainDS.Clear();\n            FMainDS.Merge(TRemote.MConference.Conference.WebConnectors.LoadConferenceSettings(FPartnerKey, out ConferenceName));\n            // display conference name\n            this.Text = this.Text + \" [\" + ConferenceName + \"]\";\n            txtConferenceName.Text = ConferenceName;\n            // display campaign code prefix\n            txtCampaignPrefixCode.Text = ((PcConferenceRow)FMainDS.PcConference.Rows[0]).OutreachPrefix;\n            // display start/end dates\n            dtpStartDate.Date = ((PPartnerLocationRow)FMainDS.PPartnerLocation.Rows[0]).DateEffective;\n            dtpEndDate.Date = ((PPartnerLocationRow)FMainDS.PPartnerLocation.Rows[0]).DateGoodUntil;\n            // enable dtps only if date is null\n            if ((dtpStartDate.Date == null) || (dtpStartDate.Date == DateTime.MinValue))\n            {\n                dtpStartDate.Enabled = true;\n            }\n            if ((dtpEndDate.Date == null) || (dtpEndDate.Date == DateTime.MinValue))\n            {\n                dtpEndDate.Enabled = true;\n            }\n            // display currency (if currency code in PUnit has changed then use that over the currency code in PcConference)\n            if ((FMainDS.PUnit.Rows.Count == 0)\n                || (((PUnitRow)FMainDS.PUnit.Rows[0]).OutreachCostCurrencyCode == ((PcConferenceRow)FMainDS.PcConference.Rows[0]).CurrencyCode))\n            {\n                cmbCurrency.SetSelectedString(((PcConferenceRow)FMainDS.PcConference.Rows[0]).CurrencyCode, -1);\n            }\n            else\n            {\n                cmbCurrency.SetSelectedString(((PUnitRow)FMainDS.PUnit.Rows[0]).OutreachCostCurrencyCode, -1);\n            }\n            // set radio buttons and checkbox\n            Boolean ChargeCampaign = true;\n            Boolean AddAccommodationCosts = false;\n            foreach (PcConferenceOptionRow CurrentRow in FMainDS.PcConferenceOption.Rows)\n            {\n                if ((CurrentRow.OptionTypeCode == \"COST_PER_NIGHT\") && (CurrentRow.OptionSet == true))\n                {\n                    ChargeCampaign = false;\n                    rbtNight.Checked = true;\n                }\n                else if ((CurrentRow.OptionTypeCode == \"COST_PER_DAY\") && (CurrentRow.OptionSet == true))\n                {\n                    ChargeCampaign = false;\n                    rbtDay.Checked = true;\n                }\n                else if ((CurrentRow.OptionTypeCode == \"ADD_ACCOMM_COST_FOR_TOTAL\") && (CurrentRow.OptionSet == true))\n                {\n                    AddAccommodationCosts = true;\n                }\n            }\n            if (ChargeCampaign == true)\n            {\n                rbtCampaign.Checked = true;\n                chkAddAccommodationCosts.Enabled = false;\n            }\n            else if (AddAccommodationCosts == true)\n            {\n                chkAddAccommodationCosts.Checked = true;\n                txtSpecialRolePreAccommodation.ReadOnly = false;\n                txtVolunteerPreAccommodation.ReadOnly = false;\n                txtParticipantPreAccommodation.ReadOnly = false;\n                txtSpecialRoleAccommodation.ReadOnly = false;\n                txtVolunteerAccommodation.ReadOnly = false;\n                txtSpecialRoleCampaignAccommodation.ReadOnly = false;\n                txtSpecialRolePreAccommodation.TabStop = true;\n                txtVolunteerPreAccommodation.TabStop = true;\n                txtParticipantPreAccommodation.TabStop = true;\n                txtSpecialRoleAccommodation.TabStop = true;\n                txtVolunteerAccommodation.TabStop = true;\n                txtSpecialRoleCampaignAccommodation.TabStop = true;\n            }\n            // display conference discounts\n            foreach (PcDiscountRow CurrentRow in FMainDS.PcDiscount.Rows)\n            {\n                if (CurrentRow.CostTypeCode == \"CONFERENCE\")\n                {\n                    if (CurrentRow.Validity == \"PRE\")\n                    {\n                        if (CurrentRow.DiscountCriteriaCode == \"ROLE\")\n                        {\n                            txtSpecialRolePreAttendance.NumberValueInt = (int)CurrentRow.Discount;\n                        }\n                        else if (CurrentRow.DiscountCriteriaCode == \"VOL\")\n                        {\n                            txtVolunteerPreAttendance.NumberValueInt = (int)CurrentRow.Discount;\n                        }\n                        else if (CurrentRow.DiscountCriteriaCode == \"OTHER\")\n                        {\n                            txtParticipantPreAttendance.NumberValueInt = (int)CurrentRow.Discount;\n                        }\n                    }\n                    else if (CurrentRow.Validity == \"CONF\")\n                    {\n                        if (CurrentRow.DiscountCriteriaCode == \"ROLE\")\n                        {\n                            txtSpecialRoleAttendance.NumberValueInt = (int)CurrentRow.Discount;\n                        }\n                        else if (CurrentRow.DiscountCriteriaCode == \"VOL\")\n                        {\n                            txtVolunteerAttendance.NumberValueInt = (int)CurrentRow.Discount;\n                        }\n                    }\n                    else if ((CurrentRow.Validity == \"POST\") && (CurrentRow.DiscountCriteriaCode == \"ROLE\"))\n                    {\n                        txtSpecialRoleCampaignAttendance.NumberValueInt = (int)CurrentRow.Discount;\n                    }\n                }\n                else if (CurrentRow.CostTypeCode == \"ACCOMMODATION\")\n                {\n                    if (CurrentRow.Validity == \"PRE\")\n                    {\n                        if (CurrentRow.DiscountCriteriaCode == \"ROLE\")\n                        {\n                            txtSpecialRolePreAccommodation.NumberValueInt = (int)CurrentRow.Discount;\n                        }\n                        else if (CurrentRow.DiscountCriteriaCode == \"VOL\")\n                        {\n                            txtVolunteerPreAccommodation.NumberValueInt = (int)CurrentRow.Discount;\n                        }\n                        else if (CurrentRow.DiscountCriteriaCode == \"OTHER\")\n                        {\n                            txtParticipantPreAccommodation.NumberValueInt = (int)CurrentRow.Discount;\n                        }\n                    }\n                    else if (CurrentRow.Validity == \"CONF\")\n                    {\n                        if (CurrentRow.DiscountCriteriaCode == \"ROLE\")\n                        {\n                            txtSpecialRoleAccommodation.NumberValueInt = (int)CurrentRow.Discount;\n                        }\n                        else if (CurrentRow.DiscountCriteriaCode == \"VOL\")\n                        {\n                            txtVolunteerAccommodation.NumberValueInt = (int)CurrentRow.Discount;\n                        }\n                    }\n                    else if ((CurrentRow.Validity == \"POST\") && (CurrentRow.DiscountCriteriaCode == \"ROLE\"))\n                    {\n                        txtSpecialRoleCampaignAccommodation.NumberValueInt = (int)CurrentRow.Discount;\n                    }\n                }\n            }\n            // display grid containing venue details\n            grdVenues.Columns.Clear();\n            grdVenues.AddPartnerKeyColumn(Catalog.GetString(\"Venue Key\"), FMainDS.PcConferenceVenue.ColumnVenueKey);\n            grdVenues.AddTextColumn(Catalog.GetString(\"Venue Name\"), FMainDS.PcConferenceVenue.ColumnVenueName);\n            DataView MyDataView = FMainDS.PcConferenceVenue.DefaultView;\n            MyDataView.Sort = \"p_venue_name_c ASC\";\n            MyDataView.AllowNew = false;\n            grdVenues.DataSource = new DevAge.ComponentModel.BoundDataView(MyDataView);\n        }\n        // disables or enables the checkbox when a different radio button is selected\n        private void AttendanceChargeChanged(object sender, EventArgs e)\n        {\n            if (rbtDay.Checked || rbtNight.Checked)\n            {\n                chkAddAccommodationCosts.Enabled = true;\n            }\n            else\n            {\n                chkAddAccommodationCosts.Checked = false;\n                chkAddAccommodationCosts.Enabled = false;\n            }\n        }\n        // Called when the checkbox is changed. Toggles textboxes' ReadOnly property.\n        private void UpdateDiscounts(object sender, EventArgs e)\n        {\n            Boolean AccommodationDiscountsReadOnly = true;\n            if (chkAddAccommodationCosts.Checked)\n            {\n                AccommodationDiscountsReadOnly = false;\n            }\n            txtSpecialRolePreAccommodation.ReadOnly = AccommodationDiscountsReadOnly;\n            txtVolunteerPreAccommodation.ReadOnly = AccommodationDiscountsReadOnly;\n            txtParticipantPreAccommodation.ReadOnly = AccommodationDiscountsReadOnly;\n            txtSpecialRoleAccommodation.ReadOnly = AccommodationDiscountsReadOnly;\n            txtVolunteerAccommodation.ReadOnly = AccommodationDiscountsReadOnly;\n            txtSpecialRoleCampaignAccommodation.ReadOnly = AccommodationDiscountsReadOnly;\n            txtSpecialRolePreAccommodation.TabStop = !AccommodationDiscountsReadOnly;\n            txtVolunteerPreAccommodation.TabStop = !AccommodationDiscountsReadOnly;\n            txtParticipantPreAccommodation.TabStop = !AccommodationDiscountsReadOnly;\n            txtSpecialRoleAccommodation.TabStop = !AccommodationDiscountsReadOnly;\n            txtVolunteerAccommodation.TabStop = !AccommodationDiscountsReadOnly;\n            txtSpecialRoleCampaignAccommodation.TabStop = !AccommodationDiscountsReadOnly;\n        }\n        // Called with Add button. Adds new venue to conference.\n        private void AddVenue(object sender, EventArgs e)\n        {\n            long ResultVenueKey;\n            String ResultVenueName;\n            TPartnerClass? PartnerClass;\n            TLocationPK ResultLocationPK;\n            DataRow[] ExistingVenueDataRows;\n            // the user has to select an existing venue to make that venue a conference venue\n            try\n            {\n                // launches partner find screen and returns true if a venue is selected\n                if (TPartnerFindScreenManager.OpenModalForm(\"VENUE\", out ResultVenueKey, out ResultVenueName, out PartnerClass, out ResultLocationPK,\n                        this))\n                {\n                    // search for selected venue in dataset\n                    ExistingVenueDataRows = FMainDS.PcConferenceVenue.Select(ConferenceSetupTDSPcConferenceVenueTable.GetVenueKeyDBName() +\n                        \" = \" + ResultVenueKey.ToString());\n                    // if venue does not already exist for venue\n                    if (ExistingVenueDataRows.Length == 0)\n                    {\n                        ConferenceSetupTDSPcConferenceVenueRow AddedVenue = FMainDS.PcConferenceVenue.NewRowTyped(true);\n                        AddedVenue.ConferenceKey = FPartnerKey;\n                        AddedVenue.VenueKey = ResultVenueKey;\n                        AddedVenue.VenueName = ResultVenueName;\n                        FMainDS.PcConferenceVenue.Rows.Add(AddedVenue);\n                        FPetraUtilsObject.SetChangedFlag();\n                    }\n                    // if venue does already exist for venue\n                    else\n                    {\n                        MessageBox.Show(Catalog.GetString(\"This venue is already included for this conference\"),\n                            Catalog.GetString(\"Add Venue to Conference\"),\n                            MessageBoxButtons.OK,\n                            MessageBoxIcon.Information);\n                    }\n                }\n            }\n            catch (Exception exp)\n            {\n                throw new EOPAppException(\"Exception occured while calling VenueFindScreen!\", exp);\n            }\n        }\n        // Called with Remove button. Removes a venue from conference.\n        private void RemoveVenue(object sender, EventArgs e)\n        {\n            if (grdVenues.SelectedDataRows.Length == 1)\n            {\n                long SelectedVenueKey;\n                SelectedVenueKey = (Int64)((DataRowView)grdVenues.SelectedDataRows[0]).Row[PcConferenceVenueTable.GetVenueKeyDBName()];\n                DataRow RowToRemove = FMainDS.PcConferenceVenue.Rows.Find(new object[] { FPartnerKey, SelectedVenueKey });\n                RowToRemove.Delete();\n                FPetraUtilsObject.SetChangedFlag();\n            }\n        }\n        // get data from screen and ammend/add to dataset\n        private void GetDataFromControlsManual(PcConferenceRow ARow)\n        {\n            PcConferenceRow ConferenceData = (PcConferenceRow)FMainDS.PcConference.Rows[0];\n            PPartnerLocationRow PartnerLocationData = (PPartnerLocationRow)FMainDS.PPartnerLocation.Rows[0];\n            PUnitRow UnitData = (PUnitRow)FMainDS.PUnit.Rows[0];\n            // do not save currency if it is blank but instead change the combo box to display original value\n            if (cmbCurrency.GetSelectedString() != \"\")\n            {\n                ConferenceData.CurrencyCode = cmbCurrency.GetSelectedString();\n                UnitData.OutreachCostCurrencyCode = cmbCurrency.GetSelectedString();\n            }\n            else\n            {\n                cmbCurrency.SetSelectedString(ConferenceData.CurrencyCode);\n            }\n            ConferenceData.Start = dtpStartDate.Date;\n            ConferenceData.End = dtpEndDate.Date;\n            PartnerLocationData.DateEffective = dtpStartDate.Date;\n            PartnerLocationData.DateGoodUntil = dtpEndDate.Date;\n            // get data from radio buttons and check button for PcConferenceOption\n            string[] OptionTypeCodes =\n            {\n                \"COST_PER_NIGHT\", \"COST_PER_DAY\", \"ADD_ACCOMM_COST_FOR_TOTAL\"\n            };\n            Boolean[] OptionSet =\n            {\n                rbtNight.Checked, rbtDay.Checked, chkAddAccommodationCosts.Checked\n            };\n            for (int i = 0; i < 3; i++)\n            {\n                DataRow RowExists = FMainDS.PcConferenceOption.Rows.Find(new object[] { FPartnerKey, OptionTypeCodes[i] });\n                // create new row if needed\n                if ((RowExists == null) && OptionSet[i])\n                {\n                    PcConferenceOptionRow RowToAdd = FMainDS.PcConferenceOption.NewRowTyped(true);\n                    RowToAdd.ConferenceKey = FPartnerKey;\n                    RowToAdd.OptionTypeCode = OptionTypeCodes[i];\n                    RowToAdd.OptionSet = true;\n                    FMainDS.PcConferenceOption.Rows.Add(RowToAdd);\n                }\n                // update existing record\n                else if ((RowExists != null) && OptionSet[i])\n                {\n                    ((PcConferenceOptionRow)RowExists).OptionSet = true;\n                }\n                // delete existing record if discount is 0\n                else if ((RowExists != null) && !OptionSet[i])\n                {\n                    RowExists.Delete();\n                }\n            }\n            // reset the Accommodation text boxs to 0 if no longer needed\n            if (!chkAddAccommodationCosts.Checked)\n            {\n                txtSpecialRolePreAccommodation.NumberValueInt = 0;\n                txtVolunteerPreAccommodation.NumberValueInt = 0;\n                txtParticipantPreAccommodation.NumberValueInt = 0;\n                txtSpecialRoleAccommodation.NumberValueInt = 0;\n                txtVolunteerAccommodation.NumberValueInt = 0;\n                txtSpecialRoleCampaignAccommodation.NumberValueInt = 0;\n            }\n            // get data from discount text boxes for PcDiscount\n            string[, ] Discounts =\n            {\n                { \"ROLE\", \"CONFERENCE\", \"PRE\", txtSpecialRolePreAttendance.Text.TrimEnd(new char[] { ' ', '%' }) },\n                { \"VOL\", \"CONFERENCE\", \"PRE\", txtVolunteerPreAttendance.Text.TrimEnd(new char[] { ' ', '%' }) },\n                { \"OTHER\", \"CONFERENCE\", \"PRE\", txtParticipantPreAttendance.Text.TrimEnd(new char[] { ' ', '%' }) },\n                { \"ROLE\", \"CONFERENCE\", \"CONF\", txtSpecialRoleAttendance.Text.TrimEnd(new char[] { ' ', '%' }) },\n                { \"VOL\", \"CONFERENCE\", \"CONF\", txtVolunteerAttendance.Text.TrimEnd(new char[] { ' ', '%' }) },\n                { \"ROLE\", \"CONFERENCE\", \"POST\", txtSpecialRoleCampaignAttendance.Text.TrimEnd(new char[] { ' ', '%' }) },\n                { \"ROLE\", \"ACCOMMODATION\", \"PRE\", txtSpecialRolePreAccommodation.Text.TrimEnd(new char[] { ' ', '%' }) },\n                { \"VOL\", \"ACCOMMODATION\", \"PRE\", txtVolunteerPreAccommodation.Text.TrimEnd(new char[] { ' ', '%' }) },\n                { \"OTHER\", \"ACCOMMODATION\", \"PRE\", txtParticipantPreAccommodation.Text.TrimEnd(new char[] { ' ', '%' }) },\n                { \"ROLE\", \"ACCOMMODATION\", \"CONF\", txtSpecialRoleAccommodation.Text.TrimEnd(new char[] { ' ', '%' }) },\n                { \"VOL\", \"ACCOMMODATION\", \"CONF\", txtVolunteerAccommodation.Text.TrimEnd(new char[] { ' ', '%' }) },\n                { \"ROLE\", \"ACCOMMODATION\", \"POST\", txtSpecialRoleCampaignAccommodation.Text.TrimEnd(new char[] { ' ', '%' }) }\n            };\n            for (int i = 0; i < 12; i++)\n            {\n                DataRow RowExists = FMainDS.PcDiscount.Rows.Find(new object[] { FPartnerKey, Discounts[i, 0], Discounts[i, 1], Discounts[i, 2], -1 });\n                if (Discounts[i, 3] == \"\")\n                {\n                    Discounts[i, 3] = \"0\";\n                }\n                // create new row if needed\n                if ((RowExists == null) && (Convert.ToInt32(Discounts[i, 3]) != 0))\n                {\n                    PcDiscountRow RowToAdd = FMainDS.PcDiscount.NewRowTyped(true);\n                    RowToAdd.ConferenceKey = FPartnerKey;\n                    RowToAdd.DiscountCriteriaCode = Discounts[i, 0];\n                    RowToAdd.CostTypeCode = Discounts[i, 1];\n                    RowToAdd.Validity = Discounts[i, 2];\n                    RowToAdd.UpToAge = -1;\n                    RowToAdd.Percentage = true;\n                    RowToAdd.Discount = Convert.ToInt32(Discounts[i, 3]);\n                    FMainDS.PcDiscount.Rows.Add(RowToAdd);\n                }\n                // update existing record\n                else if ((RowExists != null) && (Convert.ToInt32(Discounts[i, 3]) != 0))\n                {\n                    ((PcDiscountRow)RowExists).Discount = Convert.ToInt32(Discounts[i, 3]);\n                }\n                // delete existing record if discount is 0\n                else if ((RowExists != null) && (Convert.ToInt32(Discounts[i, 3]) == 0))\n                {\n                    RowExists.Delete();\n                }\n            }\n        }\n        // save data\n        private TSubmitChangesResult StoreManualCode(ref ConferenceSetupTDS ASubmitChanges, out TVerificationResultCollection AVerificationResult)\n        {\n            AVerificationResult = null;\n            return TRemote.MConference.Conference.WebConnectors.SaveConferenceSetupTDS(ref ASubmitChanges);\n        }\n        private void ValidateDataManual(PcConferenceRow ARow)\n        {\n            PcDiscountTable DiscountTable = FMainDS.PcDiscount;\n            TVerificationResultCollection VerificationResultCollection = FPetraUtilsObject.VerificationResultCollection;\n            TValidationControlsData ValidationControlsData;\n            TScreenVerificationResult VerificationResult = null;\n            DataColumn ValidationColumn;\n            List <string>CriteriaCodesUsed = new List <string>();\n            foreach (PcDiscountRow Row in DiscountTable.Rows)\n            {\n                if ((Row.RowState != DataRowState.Deleted) && (Row.DiscountCriteriaCode != \"CHILD\"))\n                {\n                    if (Row.Discount > 100)\n                    {\n                        ValidationColumn = Row.Table.Columns[PcDiscountTable.ColumnDiscountId];\n                        // displays a warning message\n                        VerificationResult = new TScreenVerificationResult(new TVerificationResult(this, ErrorCodes.GetErrorInfo(\n                                    PetraErrorCodes.ERR_DISCOUNT_PERCENTAGE_GREATER_THAN_100)),\n                            ValidationColumn, ValidationControlsData.ValidationControl);\n                        // Handle addition to/removal from TVerificationResultCollection\n                        VerificationResultCollection.Auto_Add_Or_AddOrRemove(this, VerificationResult, ValidationColumn);\n                    }\n                    if (!CriteriaCodesUsed.Exists(element => element == Row.DiscountCriteriaCode))\n                    {\n                        CriteriaCodesUsed.Add(Row.DiscountCriteriaCode);\n                    }\n                }\n            }\n", "outputs": ["            string[] CriteriaCodesUsedArray = CriteriaCodesUsed.ToArray();"], "input_length": 2655, "output_length": 9, "length": 2664, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "392c6aa20be7e95946d387875a893cc891852ae147d06a3f6ec7a054194fd3a5"}
{"input": "", "context": "// $Id: FigSingleLineText.java 132 2010-09-26 23:32:33Z marcusvnac $\n// Copyright (c) 1996-2008 The Regents of the University of California. All\n// Rights Reserved. Permission to use, copy, modify, and distribute this\n// software and its documentation without fee, and without a written\n// agreement is hereby granted, provided that the above copyright notice\n// and this paragraph appear in all copies.  This software program and\n// documentation are copyrighted by The Regents of the University of\n// California. The software program and documentation are supplied \"AS\n// IS\", without any accompanying services from The Regents. The Regents\n// does not warrant that the operation of the program will be\n// uninterrupted or error-free. The end-user understands that the program\n// was developed for research purposes and is advised not to rely\n// exclusively on the program for any reason.  IN NO EVENT SHALL THE\n// UNIVERSITY OF CALIFORNIA BE LIABLE TO ANY PARTY FOR DIRECT, INDIRECT,\n// SPECIAL, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, INCLUDING LOST PROFITS,\n// ARISING OUT OF THE USE OF THIS SOFTWARE AND ITS DOCUMENTATION, EVEN IF\n// THE UNIVERSITY OF CALIFORNIA HAS BEEN ADVISED OF THE POSSIBILITY OF\n// SUCH DAMAGE. THE UNIVERSITY OF CALIFORNIA SPECIFICALLY DISCLAIMS ANY\n// WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF\n// MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE. THE SOFTWARE\n// PROVIDED HEREUNDER IS ON AN \"AS IS\" BASIS, AND THE UNIVERSITY OF\n// CALIFORNIA HAS NO OBLIGATIONS TO PROVIDE MAINTENANCE, SUPPORT,\n// UPDATES, ENHANCEMENTS, OR MODIFICATIONS.\npackage org.argouml.uml.diagram.ui;\nimport java.awt.Dimension;\nimport java.awt.Font;\nimport java.awt.Rectangle;\nimport java.awt.event.KeyEvent;\nimport java.beans.PropertyChangeEvent;\nimport java.util.Arrays;\nimport javax.swing.SwingUtilities;\nimport org.argouml.model.AttributeChangeEvent;\nimport org.argouml.model.InvalidElementException;\nimport org.argouml.model.Model;\nimport org.argouml.model.UmlChangeEvent;\nimport org.argouml.uml.diagram.DiagramSettings;\nimport org.tigris.gef.presentation.FigText;\n/**\n * A SingleLine FigText to provide consistency across Figs displaying single\n * lines of text.<ul>\n * <li>The display area is transparent\n * <li>Text is center justified\n * <li>There is no line border\n * <li>There is space below the line for a \"Clarifier\",\n * i.e. a red squiggly line.\n * </ul><p>\n * \n * Some of these have an UML object as owner, others do not.\n *\n * @author Bob Tarling\n */\npublic class FigSingleLineText extends ArgoFigText  {\n    \n    /**\n     * The properties of 'owner' that this is interested in\n     */\n    private String[] properties;\n    /**\n     * The constructor.\n     *\n     * @param x the initial x position\n     * @param y the initial y position\n     * @param w the initial width\n     * @param h the initial height\n     * @param expandOnly true if the Fig should never shrink\n     * @deprecated for 0.27.3 by tfmorris.  Use \n     * {@link #FigSingleLineText(Object, Rectangle, DiagramSettings, boolean)}.\n     */\n    @SuppressWarnings(\"deprecation\")\n    @Deprecated\n    public FigSingleLineText(int x, int y, int w, int h, boolean expandOnly) {\n        super(x, y, w, h, expandOnly);\n        initialize();\n//        initNotationArguments(); /* There is no NotationProvider yet! */\n    }\n    private void initialize() {\n        setFillColor(FILL_COLOR); // in case someone turns it on\n        setFilled(false);\n        setTabAction(FigText.END_EDITING);\n        setReturnAction(FigText.END_EDITING);\n        setLineWidth(0);\n        setTextColor(TEXT_COLOR);\n    }\n    /**\n     * The constructor.\n     *\n     * @param x the initial x position\n     * @param y the initial y position\n     * @param w the initial width\n     * @param h the initial height\n     * @param expandOnly true if this fig shall not shrink\n     * @param property the property to listen to\n     * @deprecated for 0.27.3 by tfmorris.  Use \n     * {@link #FigSingleLineText(Object, Rectangle, DiagramSettings, boolean)}.\n     */\n    @Deprecated\n    public FigSingleLineText(int x, int y, int w, int h, boolean expandOnly, \n            String property) {\n        this(x, y, w, h, expandOnly, new String[] {property});\n    }\n    /**\n     * The constructor.\n     *\n     * @param x the initial x position\n     * @param y the initial y position\n     * @param w the initial width\n     * @param h the initial height\n     * @param expandOnly true if this fig shall not shrink\n     * @param allProperties the properties to listen to\n     * @see org.tigris.gef.presentation.FigText#FigText(\n     *         int, int, int, int, boolean)\n     * @deprecated for 0.27.3 by tfmorris.  Use \n     * {@link #FigSingleLineText(Object, Rectangle, DiagramSettings, boolean)}.\n     */\n    @Deprecated\n    public FigSingleLineText(int x, int y, int w, int h, boolean expandOnly, \n            String[] allProperties) {\n        this(x, y, w, h, expandOnly);\n        this.properties = allProperties;\n    }\n    /**\n     * Construct text fig\n     * \n     * @param owner owning UML element\n     * @param bounds position and size\n     * @param settings rendering settings\n     * @param expandOnly true if the Fig should only expand and never contract\n     */\n    public FigSingleLineText(Object owner, Rectangle bounds,\n            DiagramSettings settings, boolean expandOnly) {\n        this(owner, bounds, settings, expandOnly, (String[]) null);\n    }\n    /**\n     * Construct text fig\n     * \n     * @param owner owning UML element\n     * @param bounds position and size\n     * @param settings rendering settings\n     * @param expandOnly true if the Fig should only expand and never contract\n     * @param property name of property to listen to\n     */\n    public FigSingleLineText(Object owner, Rectangle bounds,\n            DiagramSettings settings, boolean expandOnly, String property) {\n        this(owner, bounds, settings, expandOnly, new String[] {property});\n    }\n    /**\n     * Constructor for text fig without owner. \n     * Using this constructor shall mean \n     * that this fig will never have an owner.\n     * \n     * @param bounds position and size\n     * @param settings rendering settings\n     * @param expandOnly true if the Fig should only expand and never contract\n     */\n    public FigSingleLineText(Rectangle bounds,\n            DiagramSettings settings, boolean expandOnly) {\n        this(null, bounds, settings, expandOnly);\n    }\n    \n    /**\n     * Construct text fig\n     * \n     * @param owner owning UML element\n     * @param bounds position and size\n     * @param settings rendering settings\n     * @param expandOnly true if the Fig should only expand and never contract\n     * @param allProperties names of properties to listen to\n     */\n    public FigSingleLineText(Object owner, Rectangle bounds,\n            DiagramSettings settings, boolean expandOnly, \n            String[] allProperties) {\n        super(owner, bounds, settings, expandOnly);\n        initialize();\n        this.properties = allProperties;\n        addModelListener();\n    }\n    \n    @Override\n    public Dimension getMinimumSize() {\n        Dimension d = new Dimension();\n        Font font = getFont();\n", "outputs": ["        if (font == null) {"], "input_length": 1298, "output_length": 7, "length": 1305, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "2157d2ec00be59ef5905fd675c603cb2855969d387355a7053403abb36995f50"}
{"input": "", "context": "###############################################################################\n#cyn.in is an open source Collaborative Knowledge Management Appliance that \n#enables teams to seamlessly work together on files, documents and content in \n#a secure central environment.\n#\n#cyn.in v2 an open source appliance is distributed under the GPL v3 license \n#along with commercial support options.\n#\n#cyn.in is a Cynapse Invention.\n#\n#Copyright (C) 2008 Cynapse India Pvt. Ltd.\n#\n#This program is free software: you can redistribute it and/or modify it under\n#the terms of the GNU General Public License as published by the Free Software \n#Foundation, either version 3 of the License, or any later version and observe \n#the Additional Terms applicable to this program and must display appropriate \n#legal notices. In accordance with Section 7(b) of the GNU General Public \n#License version 3, these Appropriate Legal Notices must retain the display of \n#the \"Powered by cyn.in\" AND \"A Cynapse Invention\" logos. You should have \n#received a copy of the detailed Additional Terms License with this program.\n#\n#This program is distributed in the hope that it will be useful,\n#but WITHOUT ANY WARRANTY; without even the implied warranty of \n#MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General \n#Public License for more details.\n#\n#You should have received a copy of the GNU General Public License along with \n#this program.  If not, see <http://www.gnu.org/licenses/>.\n#\n#You can contact Cynapse at support@cynapse.com with any problems with cyn.in. \n#For any queries regarding the licensing, please send your mails to \n# legal@cynapse.com\n#\n#You can also contact Cynapse at:\n#802, Building No. 1,\n#Dheeraj Sagar, Malad(W)\n#Mumbai-400064, India\n###############################################################################\nimport jsonlib\nfrom Products.CMFCore.utils import getToolByName\nfrom zope.component import getMultiAdapter\nfrom ubify.cyninv2theme import setCurrentStatusMessageForUser\nfrom ubify.cyninv2theme import getLocationListForAddContent\nfrom Products.Five.browser.pagetemplatefile import ViewPageTemplateFile\nfrom ubify.policy import CyninMessageFactory as _\nfrom AccessControl import getSecurityManager\nfrom Acquisition import aq_inner, aq_parent\nfrom DateTime import DateTime\nfrom plone.intelligenttext.transforms import convertWebIntelligentPlainTextToHtml\nfrom ubify.policy import CyninMessageFactory as _\nfrom kss.core import force_unicode\nEmptymessageError = 'Empty message'\nEmptydiscussionError = 'Empty Discussion'\nRatingError = 'Rating Error'\nEmptycommentError = 'Empty comment text'\ndef get_displaycountforlist():\n    return 5\ndef canreply(obj):\n    return getSecurityManager().checkPermission('Reply to item', aq_inner(obj)) > 0\n    \ndef getjsondata(context,reply_dict,portal_url,item_url,extra_data={}):\n        site_encoding = context.plone_utils.getSiteEncoding()        \n        mi = getToolByName(context, 'portal_membership')\n        util = getToolByName(context,'translation_service')\n        output = {}\n        items = []\n        for eachobj in reply_dict:\n            temp = {}\n            temp['depth'] = 0\n            if eachobj.has_key('prev_id'):\n                temp['prev_id'] = eachobj['prev_id']\n            else:\n                temp['prev_id'] = ''\n            reply = eachobj['object']\n            if reply <> None:\n                temp['id'] = reply.id\n                temp['replyurl'] = reply.absolute_url()\n                temp['replytoid'] = '-1'\n                if reply.inReplyTo() and reply.inReplyTo().portal_type == 'Discussion Item':\n                    temp['replytoid'] = reply.inReplyTo().getId()\n                temp['depth'] = eachobj['depth']\n                temp['mdate'] = util.ulocalized_time(reply.ModificationDate(), 1, context, domain='plonelocales')                \n                creator = reply.Creator()\n                temp['userid'] = creator\n                temp['userinfourl'] = portal_url + '/userinfo?userid=' + creator\n                temp['useravatarurl'] = mi.getPersonalPortrait(creator).absolute_url()\n                temp['replycooked'] = reply.cooked_text.decode(site_encoding)                \n                temp['permalink'] = item_url + '#' + reply.id\n                \n            items.append(temp)\n        \n        output['items'] = items        \n        for key,val in extra_data.items():\n            output[key] = val\n        \n        return jsonlib.write(output)\n    \nclass CustomMethods(object):\n    \n    def findpreviouscommentid(self,allreplies,current_reply):\n        prev_id = ''        \n        indexlist =  [j for j in [allreplies.index(k) for k in allreplies if k['id'] == current_reply.id]]\n        if len(indexlist) > 0:\n            idx_reply = indexlist[0]\n            prev_idx = idx_reply - 1\n            #find id of an object with previndex\n            prev_list = [k['id'] for k in allreplies if allreplies.index(k) == prev_idx]\n            if len(prev_list) > 0:\n                prev_id = prev_list[0]\n                \n        return prev_id\n    \n    def get_replies(self,pd,object):\n        replies = []\n        def getRs(obj, replies, counter):\n            rs = pd.getDiscussionFor(obj).getReplies()\n            if len(rs) > 0:\n                rs.sort(lambda x, y: cmp(x.modified(), y.modified()))\n                for r in rs:\n                    replies.append({'depth':counter,'id':r.id, 'object':r})\n                    getRs(r, replies, counter=counter + 1)\n        try:\n            getRs(object, replies, 0)\n        except DiscussionNotAllowed:\n            # We tried to get discussions for an object that has not only\n            # discussions turned off but also no discussion container.\n            return []\n        return replies\n    \n    def setstatusmessage(self):        \n        portal_state = getMultiAdapter((self.context, self.request), name=u\"plone_portal_state\")\n        if portal_state.anonymous():\n            return\n        user_token = portal_state.member().getId()\n        if user_token is None:\n            return\n        \n        message = ''        \n        if self.request.form.has_key('com.cynapse.cynin.statusmessageinput'):\n            message = self.request.form['com.cynapse.cynin.statusmessageinput']\n        htmltitle = ''\n        if self.request.form.has_key('comcynapsesmessagetitle'):\n            htmltitle = self.request.form['comcynapsesmessagetitle']\n        message = message.strip(' ')\n        \n        if message == '' or message.lower() == htmltitle.lower():\n            raise EmptymessageError, 'Unable to set message.'\n        \n        obj = setCurrentStatusMessageForUser(portal_state.portal(),user_token,message,self.context)\n        \n        return message\n    \n    def creatediscussion(self):\n        strDiscussion = ''\n        strTags = ''\n        discussiontitle = ''\n        tagstitle = ''\n        obj = None\n        location = self.context\n        is_discussiontitle_reqd = False\n        strDiscussionTitle = ''\n        \n        portal_state = getMultiAdapter((self.context, self.request), name=u\"plone_portal_state\")\n        cat = getToolByName(self.context, 'uid_catalog')\n        portal = portal_state.portal()\n        if self.request.has_key('com.cynapse.cynin.discussionmessageinput'):\n            strDiscussion = self.request['com.cynapse.cynin.discussionmessageinput']\n        if self.request.has_key('comcynapsediscussiontag'):\n            strTags = self.request['comcynapsediscussiontag']\n        if self.request.has_key('comcynapsediscussiontitle'):\n            discussiontitle = self.request['comcynapsediscussiontitle']\n        if self.request.has_key('comcynapsetagstitle'):\n            tagstitle = self.request['comcynapsetagstitle']\n        if self.request.has_key('comcynapseadddiscussioncontextuid'):\n            locationuid = self.request['comcynapseadddiscussioncontextuid']\n        else:\n            locationuid = ''\n            \n        if self.request.has_key('com.cynapse.cynin.discussiontitle'):\n            is_discussiontitle_reqd = True\n            strDiscussionTitle = self.request['com.cynapse.cynin.discussiontitle']        \n        \n        query = {'UID':locationuid}\n        resbrains = cat.searchResults(query)\n        if len(resbrains) == 1:\n            location = resbrains[0].getObject()\n        \n        if strDiscussion == '' or strDiscussion.lower() == discussiontitle.lower():            \n            raise EmptydiscussionError, 'Unable to add discussion with blank text.'\n        elif is_discussiontitle_reqd and (strDiscussionTitle == ''):\n            raise EmptydiscussionError, 'Unable to add discussion with blank title.'\n        else:\n            from ubify.cyninv2theme import addDiscussion\n            strActualTags = ''\n            if strTags.lower() != tagstitle.lower():\n                strActualTags = strTags\n            obj = addDiscussion(portal,strDiscussion,strActualTags,location,strDiscussionTitle)\n            if obj <> None:\n                here_text = _(u'lbl_here',u'here')\n                strlink = \"<a href='%s'>%s</a>\" % (obj.absolute_url(),self.context.translate(here_text),)\n                return strlink\n            \n    def fetchlocationstoaddcontent(self):\n        portal_state = getMultiAdapter((self.context, self.request), name=u\"plone_portal_state\")\n        portal = portal_state.portal()\n        \n        results = getLocationListForAddContent(portal)\n        \n        output = {}\n        items = []\n        for eachobj in results:\n            temp = {}\n            temp['title'] = force_unicode(eachobj['object'].Title,'utf8')\n            temp['UID'] = eachobj['object'].UID\n            temp['occ'] = ''\n            if eachobj['canAdd'] == False or 'Discussion' in eachobj['disallowedtypes']:\n                temp['occ'] = 'disabledspaceselection'\n            temp['depth'] = eachobj['depth']\n            items.append(temp)\n        \n        output['items'] = items\n        output = jsonlib.write(output)\n        \n    \n        return output\n    \n    def ratecontent(self):        \n        ratevalue = None\n        uid = None\n        if self.request.form.has_key('ratevalue'):\n            ratevalue = self.request.form['ratevalue']\n        if self.request.form.has_key('itemUID'):\n            uid = self.request.form['itemUID']\n            \n        if ratevalue is None:\n            raise RatingError,'No rating value.'\n        elif uid is None:\n            raise RatingError,'No rating item.'\n        else:\n            pr = getToolByName(self.context, 'portal_ratings', None)\n            cat = getToolByName(self.context, 'uid_catalog')\n            pr.addRating(int(ratevalue), uid)\n            \n            query = {'UID':uid}\n            resbrains = cat.searchResults(query)\n            if len(resbrains) == 1:\n                obj = resbrains[0].getObject()\n                obj.reindexObject()\n            \n            myval = int(pr.getUserRating(uid))\n            newval = int(pr.getRatingMean(uid))\n            ratecount = pr.getRatingCount(uid)\n            value_totalscore = pr.getCyninRating(uid)\n            value_scorecountlist = pr.getCyninRatingCount(uid)\n            value_pscore = value_scorecountlist['positivescore']\n            value_pcount = value_scorecountlist['positive']\n            value_nscore = value_scorecountlist['negativescore']\n            value_ncount = value_scorecountlist['negative']\n            \n            if myval == 1:\n                newtitle=_(u'hated_it',u\"Hate it (-2)\")\n            elif myval == 2:\n                newtitle=_(u'didnt_like_it',u\"Dislike it (-1)\")\n            elif myval == 3:\n                newtitle=''\n            elif myval == 4:\n                newtitle=_(u'liked_it',u\"Like it (+1)\")\n            elif myval == 5:\n                newtitle=_(u'loved_it',u\"Love it (+2)\")\n            \n            trans_title = self.context.translate(newtitle)\n            \n            if value_totalscore > 0:\n                plus_sign = \"+\"\n            else:\n                plus_sign = \"\"\n            totalscore = plus_sign + str(value_totalscore)\n            \n            output = trans_title + ',' + totalscore + ',' + str(value_pcount) + ',' + str(value_ncount)\n            return output\n    \n    def fetchcomments(self,uid,itemindex,lasttimestamp,commentcount,lastcommentid,viewtype):\n        \n        query = {'UID':uid}\n        pdt = getToolByName(self.context, 'portal_discussion', None)\n        cat = getToolByName(self.context, 'uid_catalog')\n        resbrains = cat.searchResults(query)\n        replydict = []\n        jsondata = getjsondata(self.context,replydict,self.context.portal_url(),'')        \n        if len(resbrains) == 1:\n            contobj = resbrains[0].getObject()\n            isDiscussable = contobj.isDiscussable()\n            canReply = canreply(contobj)\n            if isDiscussable and canReply:                \n                passedcommentcount = 0\n                passedcommentcount = int(commentcount)\n                flasttimestamp = float(lasttimestamp)\n                datefromlasttimestamp = DateTime(flasttimestamp)\n                newlastdate = datefromlasttimestamp.timeTime()\n                marker_delete_objectid = ''\n                removeallcomments = False\n                \n                disc_container = pdt.getDiscussionFor(contobj)\n                newreplycount = disc_container.replyCount(contobj)\n                allreplies = self.get_replies(pdt,contobj)\n                \n                if passedcommentcount <> newreplycount:                    \n                    jsondata = getjsondata(self.context,replydict,self.context.portal_url(),contobj.absolute_url())\n                    alldiscussions = disc_container.objectValues()\n                    newlastcommentid = lastcommentid\n                    \n                    newlyaddedcomments = [k for k in alldiscussions if k.modified().greaterThan(datefromlasttimestamp) and k.id not in (lastcommentid)]\n                    newlyaddedcomments.sort(lambda x,y:cmp(x.modified(),y.modified()))\n                    \n                    lenofnewcomments = len(newlyaddedcomments)\n                    display_count = get_displaycountforlist()\n                    \n                    lastxdiscussions = []\n                    if lenofnewcomments >= display_count:\n                        newlyaddedcomments.sort(lambda x,y:cmp(x.modified(),y.modified()),reverse=True)\n                        lastxdiscussions = newlyaddedcomments[:display_count]\n                        lastxdiscussions.sort(lambda x,y:cmp(x.modified(),y.modified()))\n                        if viewtype.lower() == 'listview':\n                            removeallcomments = True\n                    else:\n                        lastxdiscussions = newlyaddedcomments                        \n                        if lenofnewcomments > 0 and len(alldiscussions) > display_count and viewtype.lower() == 'listview':\n                            alldiscussions.sort(lambda x,y:cmp(x.modified(),y.modified()),reverse=True)\n                            marker_discussion = alldiscussions[display_count-1: display_count]\n                            if len(marker_discussion) > 0:\n                                #delete nodes before this item                                \n                                marker_delete_objectid = 'commenttable' + marker_discussion[0].id                                \n                    \n                    complete_output = ''\n                    list_reply_ids = []\n                    for eachcomment in lastxdiscussions:                    \n                        reply = disc_container.getReply(eachcomment.id)\n                        if reply <> None:     \n                            parentsInThread = reply.parentsInThread()\n                            depthvalue = 0\n                            if viewtype.lower() == 'threadedview':\n                                lenofparents = len(parentsInThread)\n                                depthvalue = lenofparents - 1\n                            \n                            prev_reply_id = self.findpreviouscommentid(allreplies,reply)\n                            \n                            newlastdate = reply.modified().timeTime()\n                            newlastcommentid = reply.id\n                            \n                            replydict.append({'depth': depthvalue, 'object': reply,'prev_id':prev_reply_id,'view_type':viewtype})\n                            list_reply_ids.append(reply.id)                            \n                            \n                    other_data = {}\n                    other_data['timeoutuid'] = uid\n                    other_data['timeoutindex'] = itemindex\n                    other_data['timeouttimestamp'] = str(newlastdate)\n                    other_data['timeoutlastcommentid'] = newlastcommentid\n                    other_data['timeoutcommentcount'] = str(newreplycount)\n                    \n                    other_data['marker_delete'] = marker_delete_objectid\n                    other_data['removeallcomments'] = str(removeallcomments)\n                    \n                    other_data['shownocomments'] = str(False)\n                    other_data['showmorecomments'] = str(False)\n                    other_data['view_type'] = viewtype\n                    other_data['canreply'] = str(canReply)\n                    \n                    if newreplycount > display_count:\n                        xmorecomments = newreplycount - display_count\n                        other_data['xmorecomments'] = str(xmorecomments)\n                        other_data['showmorecomments'] = str(True)\n                    elif newreplycount > 0 and newreplycount <= display_count:\n                        other_data['xmorecomments'] = ''\n                    else:\n                        other_data['shownocomments'] = str(True)\n                    \n                    jsondata = getjsondata(self.context,replydict,self.context.portal_url(),contobj.absolute_url(),other_data)\n        \n        return jsondata\n        \n    def fetchcommentsforlist(self):        \n        uid = self.request['comcynapsecyninfetchUID']\n        itemindex = self.request['comcynapsecyninfetchindex']\n        lasttimestamp = self.request['comcynapselasttimestamp']\n        lastcommentid = self.request['comcynapselastcommentid']\n        lastcommentcount = self.request['comcynapsecommentcount']\n        viewtype = self.request['comcynapseviewtype']\n        \n        return self.fetchcomments(uid,itemindex,lasttimestamp,lastcommentcount,lastcommentid,viewtype)\n        \n    def fetchnewcomments(self):        \n        uid = self.request['comcynapsecynincontextUID']\n        itemindex = ''\n        if self.request.has_key('comcynapsecyninfetchindex'):\n            itemindex = self.request['comcynapsecyninfetchindex']\n        lasttimestamp = self.request['comcynapselasttimestamp']\n        lastcommentid = self.request['comcynapselastcommentid']\n        lastcommentcount = self.request['comcynapsecommentcount']\n        viewtype = self.request['comcynapseviewtype']\n        \n        return self.fetchcomments(uid,itemindex,lasttimestamp,lastcommentcount,lastcommentid,viewtype)\n        \n    def addnewcomment(self):        \n        uid = ''\n        itemindex = ''\n        viewtype = ''\n        lasttimestamp = ''\n        lastcommentid = ''\n        commentscount = ''\n        inreplyto = ''\n        if self.request.has_key('comcynapsecynincontextUID'):\n            uid = self.request['comcynapsecynincontextUID']\n        if self.request.has_key('comcynapsecyninitemindex'):\n            itemindex = self.request['comcynapsecyninitemindex']\n        if self.request.has_key('comcynapseviewtype'):\n            viewtype = self.request['comcynapseviewtype']\n        if self.request.has_key('comcynapselasttimestamp'):\n            lasttimestamp = self.request['comcynapselasttimestamp']\n        if self.request.has_key('comcynapselastcommentid'):\n            lastcommentid = self.request['comcynapselastcommentid']\n        if self.request.has_key('comcynapsecommentcount'):\n            commentscount = self.request['comcynapsecommentcount']\n        if self.request.has_key('inreplyto'):\n            inreplyto = self.request['inreplyto']\n        \n        query = {'UID':uid}\n        pdt = getToolByName(self.context, 'portal_discussion', None)\n        cat = getToolByName(self.context, 'uid_catalog')\n        resbrains = cat.searchResults(query)\n        if len(resbrains) == 1:\n            contobj = resbrains[0].getObject()\t    \n            \n            if contobj.isDiscussable() and canreply(contobj):\n                mtool = getToolByName(self.context, 'portal_membership')\n                username = mtool.getAuthenticatedMember().getId()\n                dobj = pdt.getDiscussionFor(contobj)\n                if len(self.request['comcynapsecyninNewCommentBody'].strip(' ')) == 0 or self.request['comcynapsecyninNewCommentBody'].lower() == self.request['comcynapsenewcommenttitle'].lower():                    \n                    raise EmptycommentError, 'No comment text provided.'\n                else:\n                    id = dobj.createReply(title=\"\",text=self.request['comcynapsecyninNewCommentBody'], Creator=username)\n                    reply = dobj.getReply(id)\n                    reply.cooked_text = convertWebIntelligentPlainTextToHtml(reply.text)\n                    if inreplyto != '':\n                        replyto = dobj.getReply(inreplyto)\n                        reply.setReplyTo(replyto)\n                    if reply <> None:\n                        from ubify.cyninv2theme import triggerAddOnDiscussionItem                        \n                        triggerAddOnDiscussionItem(reply)\n                        return self.fetchcomments(uid,itemindex,lasttimestamp,commentscount,lastcommentid,viewtype)\n                        \n    \n    def togglecommentsview(self):        \n        uid = ''\n        itemindex = ''\n        viewtype = ''\n        if self.request.has_key('uid'):\n            uid = self.request['uid']\n        if self.request.has_key('viewtype'):\n            viewtype = self.request['viewtype']\n        \n        objcommentslist = []\n        replydict = []\n        jsondata = getjsondata(self.context,replydict,self.context.portal_url(),'')\n        \n        pdt = getToolByName(self.context, 'portal_discussion', None)\n        query = {'UID':uid}\n", "outputs": ["        cat = getToolByName(self.context, 'uid_catalog')"], "input_length": 3226, "output_length": 9, "length": 3235, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "fbb691fcb051ebb3b7541334a0f9b312869a4f3dbf2bb4e84306fd84685da8dc"}
{"input": "", "context": "/**\n *  Copyright (C) 2002-2015   The FreeCol Team\n *\n *  This file is part of FreeCol.\n *\n *  FreeCol is free software: you can redistribute it and/or modify\n *  it under the terms of the GNU General Public License as published by\n *  the Free Software Foundation, either version 2 of the License, or\n *  (at your option) any later version.\n *\n *  FreeCol is distributed in the hope that it will be useful,\n *  but WITHOUT ANY WARRANTY; without even the implied warranty of\n *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n *  GNU General Public License for more details.\n *\n *  You should have received a copy of the GNU General Public License\n *  along with FreeCol.  If not, see <http://www.gnu.org/licenses/>.\n */\npackage net.sf.freecol.common.model;\nimport java.util.ArrayList;\nimport java.util.Collections;\nimport java.util.List;\nimport javax.xml.stream.XMLStreamException;\nimport net.sf.freecol.common.io.FreeColXMLReader;\nimport net.sf.freecol.common.io.FreeColXMLWriter;\nimport static net.sf.freecol.common.util.CollectionUtils.*;\n/**\n * The effect of a natural disaster or other event. How the\n * probability of the effect is interpreted depends on the number of\n * effects value of the disaster or event. If the number of effects is\n * ALL, the probability is ignored. If it is ONE, then the probability\n * may be an arbitrary integer, and is used only for comparison with\n * other effects. If the number of effects is SEVERAL, however, the\n * probability must be a percentage.\n *\n * @see Disaster\n */\npublic class Effect extends FreeColGameObjectType {\n    public static final String DAMAGED_UNIT\n        = \"model.disaster.effect.damagedUnit\";\n    public static final String LOSS_OF_UNIT\n        = \"model.disaster.effect.lossOfUnit\";\n    public static final String LOSS_OF_MONEY\n        = \"model.disaster.effect.lossOfMoney\";\n    public static final String LOSS_OF_GOODS\n        = \"model.disaster.effect.lossOfGoods\";\n    public static final String LOSS_OF_TILE_PRODUCTION\n        = \"model.disaster.effect.lossOfTileProduction\";\n    public static final String LOSS_OF_BUILDING\n        = \"model.disaster.effect.lossOfBuilding\";\n    public static final String LOSS_OF_BUILDING_PRODUCTION\n        = \"model.disaster.effect.lossOfBuildingProduction\";\n    /** The probability of this effect. */\n    private int probability;\n    /** Scopes that might limit this Effect to certain types of objects. */\n    private List<Scope> scopes = null;\n    /**\n     * Deliberately empty constructor.\n     */\n    protected Effect() {}\n    /**\n     * Creates a new <code>Effect</code> instance.\n     *\n     * @param xr The <code>FreeColXMLReader</code> to read from.\n     * @param specification The <code>Specification</code> to refer to.\n     * @exception XMLStreamException if an error occurs\n     */\n    public Effect(FreeColXMLReader xr, Specification specification) throws XMLStreamException {\n        setSpecification(specification);\n        readFromXML(xr);\n    }\n    /**\n     * Create a new effect from an existing one.\n     *\n     * @param template The <code>Effect</code> to copy from.\n     */\n    public Effect(Effect template) {\n        setId(template.getId());\n        setSpecification(template.getSpecification());\n        this.probability = template.probability;\n        this.scopes = template.scopes;\n        addFeatures(template);\n    }\n    /**\n     * Get the probability of this effect.\n     *\n     * @return The probability.\n     */\n    public final int getProbability() {\n        return probability;\n    }\n    /**\n     * Get the scopes applicable to this effect.\n     *\n     * @return A list of <code>Scope</code>s.\n     */\n    public final List<Scope> getScopes() {\n        return (scopes == null) ? Collections.<Scope>emptyList()\n            : scopes;\n    }\n    /**\n     * Add a scope.\n     *\n     * @param scope The <code>Scope</code> to add.\n     */\n    private void addScope(Scope scope) {\n        if (scopes == null) scopes = new ArrayList<>();\n        scopes.add(scope);\n    }\n    /**\n     * Does at least one of this effect's scopes apply to an object.\n     *\n     * @param objectType The <code>FreeColGameObjectType</code> to check.\n     * @return True if this effect applies.\n     */\n    public boolean appliesTo(final FreeColGameObjectType objectType) {\n        return (scopes == null || scopes.isEmpty()) ? true\n            : any(scopes, s -> s.appliesTo(objectType));\n    }\n    // Serialization\n    private static final String PROBABILITY_TAG = \"probability\";\n    /**\n     * {@inheritDoc}\n     */\n    @Override\n    protected void writeAttributes(FreeColXMLWriter xw) throws XMLStreamException {\n        super.writeAttributes(xw);\n        xw.writeAttribute(PROBABILITY_TAG, probability);\n    }\n    /**\n     * {@inheritDoc}\n     */\n    @Override\n    protected void writeChildren(FreeColXMLWriter xw) throws XMLStreamException {\n        super.writeChildren(xw);\n        for (Scope scope : getScopes()) scope.toXML(xw);\n    }\n    /**\n     * {@inheritDoc}\n     */\n    @Override\n    protected void readAttributes(FreeColXMLReader xr) throws XMLStreamException {\n        super.readAttributes(xr);\n        probability = xr.getAttribute(PROBABILITY_TAG, 0);\n    }\n    /**\n     * {@inheritDoc}\n     */\n    @Override\n    protected void readChildren(FreeColXMLReader xr) throws XMLStreamException {\n        // Clear containers.\n        if (xr.shouldClearContainers()) {\n            scopes = null;\n        }\n        super.readChildren(xr);\n    }\n    /**\n     * {@inheritDoc}\n     */\n    @Override\n    protected void readChild(FreeColXMLReader xr) throws XMLStreamException {\n        final String tag = xr.getLocalName();\n        if (Scope.getXMLElementTagName().equals(tag)) {\n            addScope(new Scope(xr));\n        } else {\n            super.readChild(xr);\n        }\n    }\n    /**\n     * {@inheritDoc}\n     */\n    @Override\n    public String toString() {\n", "outputs": ["        StringBuilder sb = new StringBuilder(32);"], "input_length": 1033, "output_length": 9, "length": 1042, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "025bd72f09cb3e04a7bf81668bc2d2e5f7612b043c3b04f18af116537ed4bb65"}
{"input": "", "context": "// This code is derived from jcifs smb client library <jcifs at samba dot org>\n// Ported by J. Arturo <webmaster at komodosoft dot net>\n//  \n// This library is free software; you can redistribute it and/or\n// modify it under the terms of the GNU Lesser General Public\n// License as published by the Free Software Foundation; either\n// version 2.1 of the License, or (at your option) any later version.\n// \n// This library is distributed in the hope that it will be useful,\n// but WITHOUT ANY WARRANTY; without even the implied warranty of\n// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n// Lesser General Public License for more details.\n// \n// You should have received a copy of the GNU Lesser General Public\n// License along with this library; if not, write to the Free Software\n// Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA\nusing System;\nusing System.IO;\nusing WinrtCifs.Util;\nusing WinrtCifs.Util.Sharpen;\nnamespace WinrtCifs.Smb\n{\n\t/// <summary>\n\t/// There are hundreds of error codes that may be returned by a CIFS\n\t/// server.\n\t/// </summary>\n\t/// <remarks>\n\t/// There are hundreds of error codes that may be returned by a CIFS\n\t/// server. Rather than represent each with it's own <code>Exception</code>\n\t/// class, this class represents all of them. For many of the popular\n\t/// error codes, constants and text messages like \"The device is not ready\"\n\t/// are provided.\n\t/// <p>\n\t/// The jCIFS client maps DOS error codes to NTSTATUS codes. This means that\n\t/// the user may recieve a different error from a legacy server than that of\n\t/// a newer varient such as Windows NT and above. If you should encounter\n\t/// such a case, please report it to jcifs at samba dot org and we will\n\t/// change the mapping.\n\t/// </remarks>\n\t\n\tpublic class SmbException : IOException\n\t{\n       \n        internal static string GetMessageByCode(int errcode)\n\t\t{\n\t\t\tif (errcode == 0)\n\t\t\t{\n\t\t\t\treturn \"NT_STATUS_SUCCESS\";\n\t\t\t}\n\t\t\tif ((errcode & unchecked((int)(0xC0000000))) == unchecked((int)(0xC0000000)))\n\t\t\t{\n\t\t\t\tint min = 1;\n\t\t\t\tint max = NtStatus.NtStatusCodes.Length - 1;\n\t\t\t\twhile (max >= min)\n\t\t\t\t{\n\t\t\t\t\tint mid = (min + max) / 2;\n                    if (errcode > NtStatus.NtStatusCodes[mid])\n\t\t\t\t\t{\n\t\t\t\t\t\tmin = mid + 1;\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n                        if (errcode < NtStatus.NtStatusCodes[mid])\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tmax = mid - 1;\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse\n\t\t\t\t\t\t{\n                            return NtStatus.NtStatusMessages[mid];\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tint min = 0;\n\t\t\t\tint max = DosError.DosErrorCodes.Length - 1;\n\t\t\t\twhile (max >= min)\n\t\t\t\t{\n\t\t\t\t\tint mid = (min + max) / 2;\n                    if (errcode > DosError.DosErrorCodes[mid][0])\n\t\t\t\t\t{\n\t\t\t\t\t\tmin = mid + 1;\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n                        if (errcode < DosError.DosErrorCodes[mid][0])\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tmax = mid - 1;\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse\n\t\t\t\t\t\t{\n                            return DosError.DosErrorMessages[mid];\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn \"0x\" + Hexdump.ToHexString(errcode, 8);\n\t\t}\n\t\tinternal static int GetStatusByCode(int errcode)\n\t\t{\n\t\t\tif ((errcode & unchecked((int)(0xC0000000))) != 0)\n\t\t\t{\n\t\t\t\treturn errcode;\n\t\t\t}\n\t\t    int min = 0;\n\t\t    int max = DosError.DosErrorCodes.Length - 1;\n\t\t    while (max >= min)\n\t\t    {\n\t\t        int mid = (min + max) / 2;\n\t\t        if (errcode > DosError.DosErrorCodes[mid][0])\n\t\t        {\n\t\t            min = mid + 1;\n\t\t        }\n\t\t        else\n\t\t        {\n\t\t            if (errcode < DosError.DosErrorCodes[mid][0])\n\t\t            {\n\t\t                max = mid - 1;\n\t\t            }\n\t\t            else\n\t\t            {\n\t\t                return DosError.DosErrorCodes[mid][1];\n\t\t            }\n\t\t        }\n\t\t    }\n\t\t    return NtStatus.NtStatusUnsuccessful;\n\t\t}\n\t\tinternal static string GetMessageByWinerrCode(int errcode)\n\t\t{\n\t\t\tint min = 0;\n\t\t\tint max = WinError.WinerrCodes.Length - 1;\n\t\t\twhile (max >= min)\n\t\t\t{\n\t\t\t\tint mid = (min + max) / 2;\n                if (errcode > WinError.WinerrCodes[mid])\n\t\t\t\t{\n\t\t\t\t\tmin = mid + 1;\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n                    if (errcode < WinError.WinerrCodes[mid])\n\t\t\t\t\t{\n\t\t\t\t\t\tmax = mid - 1;\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n                        return WinError.WinerrMessages[mid];\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn errcode + string.Empty;\n\t\t}\n\t\tprivate int _status;\n\t\tprivate Exception _rootCause;\n\t\tpublic SmbException()\n\t\t{\n\t\t}\n\t\tinternal SmbException(int errcode, Exception rootCause) : base(GetMessageByCode(errcode\n\t\t\t))\n\t\t{\n\t\t\t_status = GetStatusByCode(errcode);\n\t\t\tthis._rootCause = rootCause;\n\t\t}\n\t\tpublic SmbException(string msg) : base(msg)\n\t\t{\n            _status = NtStatus.NtStatusUnsuccessful;\n\t\t}\n\t\tpublic SmbException(string msg, Exception rootCause) : base(msg)\n\t\t{\n\t\t\tthis._rootCause = rootCause;\n            _status = NtStatus.NtStatusUnsuccessful;\n\t\t}\n\t\tpublic SmbException(int errcode, bool winerr) : base(winerr ? GetMessageByWinerrCode\n\t\t\t(errcode) : GetMessageByCode(errcode))\n\t\t{\n\t\t\t_status = winerr ? errcode : GetStatusByCode(errcode);\n\t\t}\n\t\tpublic virtual int GetNtStatus()\n\t\t{\n\t\t\treturn _status;\n\t\t}\n\t\tpublic virtual Exception GetRootCause()\n\t\t{\n\t\t\treturn _rootCause;\n\t\t}\n\t\tpublic override string ToString()\n\t\t{\n\t\t    if (_rootCause != null)\n\t\t\t{\n\t\t\t\tRuntime.PrintStackTrace(_rootCause, LogStream.GetInstance());\n", "outputs": ["\t\t\t\treturn base.ToString() + \"\\n\" + _rootCause;"], "input_length": 981, "output_length": 11, "length": 992, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "8491b9924b994aa87aea310ff98d2b3a35555f454896db6bcbd4ebcbef4efb87"}
{"input": "", "context": "package com.electronwill.nightconfig.core.utils;\nimport java.util.AbstractMap;\nimport java.util.Collection;\nimport java.util.Map;\nimport java.util.Set;\nimport java.util.function.BiConsumer;\nimport java.util.function.BiFunction;\nimport java.util.function.Function;\n/**\n *\n * A TransformingMap contains an internal {@code Map<K, InternalV>} values, and exposes the\n * features of a {@code Map<K, ExternalV>} applying transformations to the values.\n * <p>\n * The transformations are applied \"just in time\", that is, the values are converted only when\n * they are used, not during the construction of the TransformingMap.\n * <p>\n * For instance, if you have a {@code Map<String, String>} and you want to convert its values\n * \"just in time\" to integers, you use a {@code TransformingMap<String, String, Integer>}.\n * To get one, you create these three functions:\n * <ul>\n * <li>one that converts a String to an Integer: that's the parse transformation. It converts an\n * Integer read from the internal map to a String.\n * <li>one that converts an Integer to a String: that's the write transformation. It converts a\n * String given to the TransformingMap to an Integer.\n * <li>one that converts an Object to another Object: that's the search transformation. It is used\n * (mainly) by the {@link #containsKey(Object)} method of the TransformingMap. If its argument is\n * an Integer then it should convert it to an String in the same way as the write transformation.\n * Otherwise, it is free to try to convert it to a String if possible, or not to.\n * </ul>\n *\n * @author TheElectronWill\n */\n@SuppressWarnings(\"unchecked\")\npublic final class TransformingMap<K, I, E> extends AbstractMap<K, E> {\n\tprivate final BiFunction<K, ? super I, ? extends E> readTransform;\n\tprivate final BiFunction<K, ? super E, ? extends I> writeTransform;\n\tprivate final Function<Object, ? extends I> searchTransform;\n\tprivate final Map<K, I> internalMap;\n\t/**\n\t * Create a new TransformingMap.\n\t *\n\t * @param map                  the internal map to use\n\t * @param readTransform   the parse transformation (see javadoc of the class)\n\t * @param writeTransform  the write transformation (see javadoc of the class)\n\t * @param searchTransform the search transformation (see javadoc of the class)\n\t */\n\tpublic TransformingMap(Map<K, I> map,\n\t\t\t\t\t\t   Function<? super I, ? extends E> readTransform,\n\t\t\t\t\t\t   Function<? super E, ? extends I> writeTransform,\n\t\t\t\t\t\t   Function<Object, ? extends I> searchTransform) {\n\t\tthis.internalMap = map;\n\t\tthis.readTransform = (k, v) -> readTransform.apply(v);\n\t\tthis.writeTransform = (k, v) -> writeTransform.apply(v);\n\t\tthis.searchTransform = searchTransform;\n\t}\n\t/**\n\t * Create a new TransformingMap.\n\t *\n\t * @param map                  the internal map to use\n\t * @param readTransform   the parse transformation (see javadoc of the class)\n\t * @param writeTransform  the write transformation (see javadoc of the class)\n\t * @param searchTransform the search transformation (see javadoc of the class)\n\t */\n\tpublic TransformingMap(Map<K, I> map,\n\t\t\t\t\t\t   BiFunction<K, ? super I, ? extends E> readTransform,\n\t\t\t\t\t\t   BiFunction<K, ? super E, ? extends I> writeTransform,\n\t\t\t\t\t\t   Function<Object, ? extends I> searchTransform) {\n\t\tthis.internalMap = map;\n\t\tthis.readTransform = readTransform;\n\t\tthis.writeTransform = writeTransform;\n\t\tthis.searchTransform = searchTransform;\n\t}\n\tprivate E read(Object key, I value) {\n\t\treturn readTransform.apply((K)key, value);\n\t}\n\tprivate I write(Object key, E value) {\n\t\treturn writeTransform.apply((K)key, value);\n\t}\n\tprivate I search(Object arg) {\n\t\treturn searchTransform.apply(arg);\n\t}\n\t@Override\n\tpublic int size() {\n\t\treturn internalMap.size();\n\t}\n\t@Override\n\tpublic boolean isEmpty() {\n\t\treturn internalMap.isEmpty();\n\t}\n\t@Override\n\tpublic boolean containsKey(Object key) {\n\t\treturn internalMap.containsKey(key);\n\t}\n\t@Override\n\tpublic boolean containsValue(Object value) {\n\t\treturn internalMap.containsValue(searchTransform.apply(value));\n\t}\n\t@Override\n\tpublic E get(Object key) {\n\t\treturn read(key, internalMap.get(key));\n\t}\n\t@Override\n\tpublic E put(K key, E value) {\n\t\treturn read(key, internalMap.put(key, write(key, value)));\n\t}\n\t@Override\n\tpublic E remove(Object key) {\n\t\treturn read(key, internalMap.remove(key));\n\t}\n\t@Override\n\tpublic void putAll(Map<? extends K, ? extends E> m) {\n\t\tinternalMap.putAll(new TransformingMap(m, writeTransform, (k, o) -> o, o -> o));\n\t}\n\t@Override\n\tpublic void clear() {\n\t\tinternalMap.clear();\n\t}\n\t@Override\n\tpublic Set<K> keySet() {\n\t\treturn internalMap.keySet();\n\t}\n\t@Override\n\tpublic Collection<E> values() {\n\t\treturn new TransformingCollection<>(internalMap.values(), o->read(null,o),\n\t\t\t\t\t\t\t\t\t\t\to->write(null,o), searchTransform);\n\t}\n\t@Override\n\tpublic Set<Map.Entry<K, E>> entrySet() {\n\t\tFunction<Entry<K, I>, Entry<K, E>> read =\n\t\t\ti -> TransformingMapEntry.from(i, readTransform, writeTransform);\n\t\tFunction<Entry<K, E>, Entry<K, I>> write =\n\t\t\te -> TransformingMapEntry.from(e, writeTransform, readTransform);\n\t\tFunction<Object, Map.Entry<K, I>> search = o -> {\n\t\t\tif (o instanceof Map.Entry) {\n\t\t\t\tMap.Entry<K, E> entry = (Map.Entry)o;\n\t\t\t\treturn TransformingMapEntry.from(entry, writeTransform, readTransform);\n\t\t\t}\n\t\t\treturn null;\n\t\t};\n\t\treturn new TransformingSet<>(internalMap.entrySet(), read, write, search);\n\t}\n\t@Override\n\tpublic E getOrDefault(Object key, E defaultValue) {\n\t\tI result = internalMap.get(key);\n\t\treturn (result == null || result == defaultValue) ? defaultValue : read(key, result);\n\t}\n\t@Override\n\tpublic void forEach(BiConsumer<? super K, ? super E> action) {\n\t\tinternalMap.forEach((k, o) -> action.accept(k, read(k, o)));\n\t}\n\t@Override\n\tpublic void replaceAll(BiFunction<? super K, ? super E, ? extends E> function) {\n\t\tinternalMap.replaceAll(transform(function));\n\t}\n\t@Override\n\tpublic E putIfAbsent(K key, E value) {\n\t\treturn read(key, internalMap.putIfAbsent(key, write(key, value)));\n\t}\n\t@Override\n\tpublic boolean remove(Object key, Object value) {\n\t\treturn internalMap.remove(key, search(value));\n\t}\n\t@Override\n\tpublic boolean replace(K key, E oldValue, E newValue) {\n\t\treturn internalMap.replace(key, search(oldValue), write(key, newValue));\n\t}\n\t@Override\n\tpublic E replace(K key, E value) {\n\t\treturn read(key, internalMap.replace(key, write(key, value)));\n\t}\n\t@Override\n\tpublic E computeIfAbsent(K key, Function<? super K, ? extends E> mappingFunction) {\n\t\tFunction<K, I> function = k -> write(k, mappingFunction.apply(k));\n\t\treturn read(key, internalMap.computeIfAbsent(key, function));\n\t}\n\t@Override\n\tpublic E computeIfPresent(K key,\n\t\t\t\t\t\t\t  BiFunction<? super K, ? super E, ? extends E> remappingFunction) {\n\t\tI computed = internalMap.computeIfPresent(key, transform(remappingFunction));\n", "outputs": ["\t\treturn read(key, computed);"], "input_length": 1497, "output_length": 8, "length": 1505, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "530388406d217d3c302895901b1faee7a379dd0850c81f74d4aa576231452818"}
{"input": "", "context": "package de.fhg.fokus.mdc.odrClientProxy.registry;\nimport java.io.IOException;\nimport java.util.ArrayList;\nimport java.util.List;\nimport org.codehaus.jackson.JsonGenerationException;\nimport org.codehaus.jackson.map.JsonMappingException;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport de.fhg.fokus.mdc.odrClientProxy.model.GemoApplicationResource;\nimport de.fhg.fokus.mdc.odrClientProxy.model.GemoMetadata;\nimport de.fhg.fokus.odp.registry.ODRClient;\nimport de.fhg.fokus.odp.registry.ckan.impl.LicenceImpl;\nimport de.fhg.fokus.odp.registry.ckan.impl.ScopeImpl;\nimport de.fhg.fokus.odp.registry.ckan.json.LicenceBean;\nimport de.fhg.fokus.odp.registry.ckan.json.ScopeBean;\nimport de.fhg.fokus.odp.registry.model.Category;\nimport de.fhg.fokus.odp.registry.model.Contact;\nimport de.fhg.fokus.odp.registry.model.Licence;\nimport de.fhg.fokus.odp.registry.model.Metadata;\nimport de.fhg.fokus.odp.registry.model.MetadataEnumType;\nimport de.fhg.fokus.odp.registry.model.Resource;\nimport de.fhg.fokus.odp.registry.model.RoleEnumType;\nimport de.fhg.fokus.odp.registry.model.Scope;\n/*The MetadataWrapper adds a level of abstraction to the Metadata interface of odrc since in gemo not all the methods are needed to be exposed*/\npublic class MetadataWrapper {\n\tprivate Metadata odrMetadata;\n\tpublic Metadata getOdrMetadata() {\n\t\treturn odrMetadata;\n\t}\n\tpublic void setOdrMetadata(Metadata odrMetadata) {\n\t\tthis.odrMetadata = odrMetadata;\n\t}\n\t/** The logger. */\n\tprivate final Logger LOG = LoggerFactory.getLogger(getClass());\n\t/** The licences. */\n\tprivate List<Licence> relevantLicences;\n\t/** The categories. */\n\tprivate List<Category> categories;\n\t/** The sectors. */\n\t// private List<SectorEnumType> sectors;\n\t/** The geo granularities. */\n\t// private List<GeoGranularityEnumType> geoGranularities;\n\t/** The temporal granularity enum types. */\n\t// private List<TemporalGranularityEnumType> temporalGranularityEnumTypes;\n\t/** The selected categories. */\n\t// private List<String> selectedCategories;\n\t/** The selected tags. */\n\t// private List<String> selectedTags;\n\t/** The author. */\n\tprivate Contact author;\n\t/** The maintainer. */\n\t// private Contact maintainer;\n\t/** The distributor. */\n\t// private Contact distributor;\n\t/** The date pattern. */\n\tpublic final static String DATE_PATTERN = \"dd.MM.yyyy\";\n\t// adjust the Map<String, Object> appMetadata method\n\t// public Metadata init(ODRClient odrc, Map<String, Object> appMetadata) {\n\t// odrMetadata = odrc.createMetadata(MetadataEnumType.APPLICATION);\n\t// odrMetadata.setTitle(appMetadata.get(\"name\").toString());\n\t// return odrMetadata;\n\t// }\n\tpublic String getTitle() {\n\t\treturn this.odrMetadata.getTitle();\n\t}\n\tpublic void setTitle(String title) {\n\t\tthis.odrMetadata.setTitle(title);\n\t}\n\tpublic String getName() {\n\t\treturn this.odrMetadata.getTitle();\n\t}\n\tpublic String getAuthor() {\n\t\treturn this.odrMetadata.getAuthor();\n\t}\n\tpublic String getLicenceId() {\n\t\treturn this.odrMetadata.getLicence().getName();\n\t}\n\t/* if odrMetadata is null, registering new */\n\t// TODO do not catch the exception here\n\tprotected Metadata translateGemoMetadataToODR(ODRClient odrc,\n\t\t\tGemoMetadata gemoMetadata) {\n\t\tif (odrMetadata == null) {\n\t\t\todrMetadata = odrc.createMetadata(MetadataEnumType.DOCUMENT);\n\t\t\tLOG.debug(\"created new Metadata object\");\n\t\t}\n\t\tgetLicencesforType(odrc);\n\t\ttry {\n\t\t\twriteIntoODRMetadata(odrc, gemoMetadata);\n\t\t} catch (JsonGenerationException e) {\n\t\t\t// TODO Auto-generated catch block\n\t\t\te.printStackTrace();\n\t\t} catch (JsonMappingException e) {\n\t\t\t// TODO Auto-generated catch block\n\t\t\te.printStackTrace();\n\t\t} catch (IOException e) {\n\t\t\t// TODO Auto-generated catch block\n\t\t\te.printStackTrace();\n\t\t}\n\t\treturn odrMetadata;\n\t}\n\t/* if odrMetadata is not null, if it is set with odrc.getM and odrc.queryM */\n\tprivate void writeIntoODRMetadata(ODRClient odrc, GemoMetadata gemoMetadata)\n\t\t\tthrows JsonGenerationException, JsonMappingException, IOException {\n\t\t// TODO other metadata fields to be mapped\n\t\t// when creating metadata persistMetadata sets the odrMetadata.name\n\t\t// based on title,\n\t\t// when updating metadata, odrMetadata has already a unique name as\n\t\t// identifier, so cannot be changed\n\t\todrMetadata.setTitle(gemoMetadata.getName());\n\t\t// set values for the author which is referenced by\n\t\t// metadataimpl.contacts list\n\t\tauthor = odrMetadata.newContact(RoleEnumType.AUTHOR);\n\t\tauthor.setName(gemoMetadata.getAuthor());\n\t\tsetLicence(gemoMetadata.getLicenceId());\n\t\t// why list licences if set already?\n\t\todrc.listLicenses();\n\t\todrMetadata.setNotes(gemoMetadata.getDescription());\n\t\tcategories = odrc.listCategories();\n\t\t// TODO change this with search for the name that gemometadata specified\n\t\tCategory e = null;\n\t\tfor (Category c : categories) {\n\t\t\tif (c.getName().equals(gemoMetadata.getCategory()))\n\t\t\t\te = c;\n\t\t}\n\t\todrMetadata.getCategories().add(e);\n\t\t// odrMetadata.set\n\t\tList<GemoApplicationResource> gemoResources = gemoMetadata\n\t\t\t\t.getResources();\n\t\tif (gemoResources.size() > 0) {\n\t\t\tfor (GemoApplicationResource gemoR : gemoResources) {\n\t\t\t\tResource r = odrc.createResource();\n\t\t\t\tr.setDescription(gemoR.getDescription());\n\t\t\t\tr.setFormat(gemoR.getFormat());\n\t\t\t\tr.setUrl(gemoR.getUrl());\n\t\t\t\todrMetadata.getResources().add(r);\n\t\t\t}\n\t\t}\n\t\tList<ScopeBean> gemoScopes = new ArrayList<ScopeBean>();\n\t\tgemoScopes = gemoMetadata.getScopes();\n\t\tif (gemoScopes.size() > 0) {\n\t\t\tfor (ScopeBean scopeBean : gemoScopes) {\n\t\t\t\tScope odrScope = new ScopeImpl(scopeBean);\n\t\t\t\todrMetadata.getScopes().add(odrScope);\n\t\t\t}\n\t\t}\n\t}\n\tprotected GemoMetadata readIntoGemo(Metadata metadata) {\n\t\tGemoMetadata gemoMetadata = new GemoMetadata();\n\t\tgemoMetadata.setAuthor(metadata.getContacts().get(0).getName());\n\t\tgemoMetadata.setName(metadata.getName());\n\t\tgemoMetadata.setLicenceId(metadata.getLicence().getName());\n\t\tgemoMetadata.setDescription(metadata.getNotes());\n\t\tList<GemoApplicationResource> gemoResources = new ArrayList<GemoApplicationResource>();\n\t\tList<Resource> odrResources = metadata.getResources();\n\t\t// go through the resources list of metadata, add to gemoresources list\n\t\tfor (Resource odrResource : odrResources) {\n\t\t\tGemoApplicationResource gemoResource = new GemoApplicationResource();\n\t\t\tgemoResource.setUrl(odrResource.getUrl());\n\t\t\tgemoResource.setFormat(odrResource.getFormat());\n\t\t\tgemoResource.setDescription(odrResource.getDescription());\n\t\t\tgemoResources.add(gemoResource);\n\t\t}\n\t\tgemoMetadata.setResources(gemoResources);\n\t\tList<ScopeBean> gemoScopes = new ArrayList<ScopeBean>();\n\t\tList<Scope> odrScopes = metadata.getScopes();\n\t\tfor (Scope s : odrScopes) {\n\t\t\tScopeBean gemoScope = new ScopeBean();\n\t\t\tgemoScope.setName(s.getName());\n\t\t\tgemoScope.setDescription(s.getDescription());\n\t\t\tgemoScopes.add(gemoScope);\n\t\t}\n\t\tgemoMetadata.setScopes(gemoScopes);\n\t\t// TODO other metadata fields to be mapped\n\t\treturn gemoMetadata;\n\t}\n\tprivate void getLicencesforType(ODRClient odrClient) {\n\t\trelevantLicences = new ArrayList<Licence>();\n\t\tList<Licence> availableLicences = odrClient.listLicenses();\n\t\t/*\n\t\t * Fill licences according to the metadata type: dataset, app, document\n\t\t */\n\t\tif (availableLicences.size() > 0) {\n\t\t\tLOG.debug(\"Number of available licences: \"\n\t\t\t\t\t+ availableLicences.size());\n\t\t\ttry {\n\t\t\t\tif (odrMetadata.getType().equals(MetadataEnumType.DATASET)\n\t\t\t\t\t\t|| odrMetadata.getType().equals(\n\t\t\t\t\t\t\t\tMetadataEnumType.UNKNOWN)) {\n\t\t\t\t\tfor (Licence licence : availableLicences) {\n\t\t\t\t\t\tif (licence.isDomainData()) {\n\t\t\t\t\t\t\trelevantLicences.add(licence);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if (odrMetadata.getType().equals(\n\t\t\t\t\t\tMetadataEnumType.APPLICATION)) {\n\t\t\t\t\tfor (Licence licence : availableLicences) {\n", "outputs": ["\t\t\t\t\t\tif (licence.isDomainSoftware()) {"], "input_length": 1232, "output_length": 7, "length": 1239, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "2138a9c53c21d19d869c2c2c376761696774fdeb39096121ef4f1a3e4aa37477"}
{"input": "", "context": "using System;\nusing System.Collections;\nusing System.Collections.Generic;\nusing System.Diagnostics;\nusing System.IO;\nusing System.Net.Mail;\nusing Server;\nusing Server.Accounting;\nusing Server.Network;\nnamespace Server.Misc\n{\n\tpublic class CrashGuard\n\t{\n\t\tprivate static bool Enabled = true;\n\t\tprivate static bool SaveBackup = true;\n\t\tprivate static bool RestartServer = true;\n\t\tprivate static bool GenerateReport = true;\n\t\tpublic static void Initialize()\n\t\t{\n\t\t\tif ( Enabled ) // If enabled, register our crash event handler\n\t\t\t\tEventSink.Crashed += new CrashedEventHandler( CrashGuard_OnCrash );\n\t\t}\n\t\tpublic static void CrashGuard_OnCrash( CrashedEventArgs e )\n\t\t{\n\t\t\tif ( GenerateReport )\n\t\t\t\tGenerateCrashReport( e );\n\t\t\tWorld.WaitForWriteCompletion();\n\t\t\tif ( SaveBackup )\n\t\t\t\tBackup();\n\t\t\t/*if ( Core.Service )\n\t\t\t\te.Close = true;\n\t\t\telse */ if ( RestartServer )\n\t\t\t\tRestart( e );\n\t\t}\n\t\tprivate static void SendEmail( string filePath )\n\t\t{\n\t\t\tConsole.Write( \"Crash: Sending email...\" );\n\t\t\tMailMessage message = new MailMessage( Email.FromAddress, Email.CrashAddresses );\n\t\t\tmessage.Subject = \"Automated RunUO Crash Report\";\n\t\t\tmessage.Body = \"Automated RunUO Crash Report. See attachment for details.\";\n\t\t\tmessage.Attachments.Add( new Attachment( filePath ) );\n\t\t\tif ( Email.Send( message ) )\n\t\t\t\tConsole.WriteLine( \"done\" );\n\t\t\telse\n\t\t\t\tConsole.WriteLine( \"failed\" );\n\t\t}\n\t\tprivate static string GetRoot()\n\t\t{\n\t\t\ttry\n\t\t\t{\n\t\t\t\treturn Path.GetDirectoryName( Environment.GetCommandLineArgs()[0] );\n\t\t\t}\n\t\t\tcatch\n\t\t\t{\n\t\t\t\treturn \"\";\n\t\t\t}\n\t\t}\n\t\tprivate static string Combine( string path1, string path2 )\n\t\t{\n\t\t\tif ( path1.Length == 0 )\n\t\t\t\treturn path2;\n\t\t\treturn Path.Combine( path1, path2 );\n\t\t}\n\t\tprivate static void Restart( CrashedEventArgs e )\n\t\t{\n\t\t\tstring root = GetRoot();\n\t\t\tConsole.Write( \"Crash: Restarting...\" );\n\t\t\ttry\n\t\t\t{\n\t\t\t\tProcess.Start( Core.ExePath, Core.Arguments );\n\t\t\t\tConsole.WriteLine( \"done\" );\n\t\t\t\te.Close = true;\n\t\t\t}\n\t\t\tcatch\n\t\t\t{\n\t\t\t\tConsole.WriteLine( \"failed\" );\n\t\t\t}\n\t\t}\n\t\tprivate static void CreateDirectory( string path )\n\t\t{\n\t\t\tif ( !Directory.Exists( path ) )\n\t\t\t\tDirectory.CreateDirectory( path );\n\t\t}\n\t\tprivate static void CreateDirectory( string path1, string path2 )\n\t\t{\n\t\t\tCreateDirectory( Combine( path1, path2 ) );\n\t\t}\n\t\tprivate static void CopyFile( string rootOrigin, string rootBackup, string path )\n\t\t{\n\t\t\tstring originPath = Combine( rootOrigin, path );\n\t\t\tstring backupPath = Combine( rootBackup, path );\n\t\t\ttry\n\t\t\t{\n\t\t\t\tif ( File.Exists( originPath ) )\n\t\t\t\t\tFile.Copy( originPath, backupPath );\n\t\t\t}\n\t\t\tcatch\n\t\t\t{\n\t\t\t}\n\t\t}\n\t\tprivate static void Backup()\n\t\t{\n\t\t\tConsole.Write( \"Crash: Backing up...\" );\n\t\t\ttry\n\t\t\t{\n\t\t\t\tstring timeStamp = GetTimeStamp();\n\t\t\t\tstring root = GetRoot();\n\t\t\t\tstring rootBackup = Combine( root, String.Format( \"Backups/Crashed/{0}/\", timeStamp ) );\n\t\t\t\tstring rootOrigin = Combine( root, String.Format( \"Saves/\" ) );\n\t\t\t\t// Create new directories\n\t\t\t\tCreateDirectory( rootBackup );\n\t\t\t\tCreateDirectory( rootBackup, \"Accounts/\" );\n\t\t\t\tCreateDirectory( rootBackup, \"Items/\" );\n\t\t\t\tCreateDirectory( rootBackup, \"Mobiles/\" );\n\t\t\t\tCreateDirectory( rootBackup, \"Guilds/\" );\n\t\t\t\tCreateDirectory( rootBackup, \"Regions/\" );\n\t\t\t\t// Copy files\n\t\t\t\tCopyFile( rootOrigin, rootBackup, \"Accounts/Accounts.xml\" );\n\t\t\t\tCopyFile( rootOrigin, rootBackup, \"Items/Items.bin\" );\n\t\t\t\tCopyFile( rootOrigin, rootBackup, \"Items/Items.idx\" );\n\t\t\t\tCopyFile( rootOrigin, rootBackup, \"Items/Items.tdb\" );\n\t\t\t\tCopyFile( rootOrigin, rootBackup, \"Mobiles/Mobiles.bin\" );\n\t\t\t\tCopyFile( rootOrigin, rootBackup, \"Mobiles/Mobiles.idx\" );\n\t\t\t\tCopyFile( rootOrigin, rootBackup, \"Mobiles/Mobiles.tdb\" );\n\t\t\t\tCopyFile( rootOrigin, rootBackup, \"Guilds/Guilds.bin\" );\n\t\t\t\tCopyFile( rootOrigin, rootBackup, \"Guilds/Guilds.idx\" );\n\t\t\t\tCopyFile( rootOrigin, rootBackup, \"Regions/Regions.bin\" );\n\t\t\t\tCopyFile( rootOrigin, rootBackup, \"Regions/Regions.idx\" );\n\t\t\t\tConsole.WriteLine( \"done\" );\n\t\t\t}\n\t\t\tcatch\n\t\t\t{\n\t\t\t\tConsole.WriteLine( \"failed\" );\n\t\t\t}\n\t\t}\n\t\tprivate static void GenerateCrashReport( CrashedEventArgs e )\n\t\t{\n\t\t\tConsole.Write( \"Crash: Generating report...\" );\n\t\t\ttry\n\t\t\t{\n\t\t\t\tstring timeStamp = GetTimeStamp();\n\t\t\t\tstring fileName = String.Format( \"Crash {0}.log\", timeStamp );\n\t\t\t\tstring root = GetRoot();\n\t\t\t\tstring filePath = Combine( root, fileName );\n\t\t\t\tusing ( StreamWriter op = new StreamWriter( filePath ) )\n\t\t\t\t{\n\t\t\t\t\tVersion ver = Core.Assembly.GetName().Version;\n\t\t\t\t\top.WriteLine( \"Server Crash Report\" );\n\t\t\t\t\top.WriteLine( \"===================\" );\n\t\t\t\t\top.WriteLine();\n\t\t\t\t\top.WriteLine( \"RunUO Version {0}.{1}, Build {2}.{3}\", ver.Major, ver.Minor, ver.Build, ver.Revision );\n\t\t\t\t\top.WriteLine( \"Operating System: {0}\", Environment.OSVersion );\n\t\t\t\t\top.WriteLine( \".NET Framework: {0}\", Environment.Version );\n\t\t\t\t\top.WriteLine( \"Time: {0}\", DateTime.Now );\n\t\t\t\t\ttry { op.WriteLine( \"Mobiles: {0}\", World.Mobiles.Count ); }\n\t\t\t\t\tcatch {}\n\t\t\t\t\ttry { op.WriteLine( \"Items: {0}\", World.Items.Count ); }\n\t\t\t\t\tcatch {}\n\t\t\t\t\top.WriteLine( \"Exception:\" );\n\t\t\t\t\top.WriteLine( e.Exception );\n\t\t\t\t\top.WriteLine();\n\t\t\t\t\top.WriteLine( \"Clients:\" );\n\t\t\t\t\ttry\n\t\t\t\t\t{\n\t\t\t\t\t\tList<NetState> states = NetState.Instances;\n\t\t\t\t\t\top.WriteLine( \"- Count: {0}\", states.Count );\n\t\t\t\t\t\tfor ( int i = 0; i < states.Count; ++i )\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tNetState state = states[i];\n\t\t\t\t\t\t\top.Write( \"+ {0}:\", state );\n\t\t\t\t\t\t\tAccount a = state.Account as Account;\n\t\t\t\t\t\t\tif ( a != null )\n\t\t\t\t\t\t\t\top.Write( \" (account = {0})\", a.Username );\n\t\t\t\t\t\t\tMobile m = state.Mobile;\n\t\t\t\t\t\t\tif ( m != null )\n\t\t\t\t\t\t\t\top.Write( \" (mobile = 0x{0:X} '{1}')\", m.Serial.Value, m.Name );\n\t\t\t\t\t\t\top.WriteLine();\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tcatch\n\t\t\t\t\t{\n\t\t\t\t\t\top.WriteLine( \"- Failed\" );\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tConsole.WriteLine( \"done\" );\n\t\t\t\tif ( Email.FromAddress != null && Email.CrashAddresses != null )\n", "outputs": ["\t\t\t\t\tSendEmail( filePath );"], "input_length": 1118, "output_length": 5, "length": 1123, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "0fcca02040e205fa2ff243e033d9fcc36856484e8cb9d378439fca8b11a8f4d5"}
{"input": "", "context": "/* This code is part of Freenet. It is distributed under the GNU General\n * Public License, version 2 (or at your option any later version). See\n * http://www.gnu.org/ for further details of the GPL. */\npackage freenet.client.filter;\nimport freenet.client.filter.HTMLFilter.ParsedTag;\nimport freenet.clients.http.ExternalLinkToadlet;\nimport freenet.clients.http.HTTPRequestImpl;\nimport freenet.clients.http.StaticToadlet;\nimport freenet.keys.FreenetURI;\nimport freenet.l10n.NodeL10n;\nimport freenet.support.*;\nimport freenet.support.Logger.LogLevel;\nimport freenet.support.api.HTTPRequest;\nimport java.io.UnsupportedEncodingException;\nimport java.net.MalformedURLException;\nimport java.net.URI;\nimport java.net.URISyntaxException;\nimport java.net.URLEncoder;\nimport java.nio.charset.Charset;\nimport java.util.HashSet;\nimport java.util.regex.Pattern;\npublic class GenericReadFilterCallback implements FilterCallback, URIProcessor {\n\tpublic static final HashSet<String> allowedProtocols;\n\t\n\tstatic {\n\t\tallowedProtocols = new HashSet<String>();\n\t\tallowedProtocols.add(\"http\");\n\t\tallowedProtocols.add(\"https\");\n\t\tallowedProtocols.add(\"ftp\");\n\t\tallowedProtocols.add(\"mailto\");\n\t\tallowedProtocols.add(\"nntp\");\n\t\tallowedProtocols.add(\"news\");\n\t\tallowedProtocols.add(\"snews\");\n\t\tallowedProtocols.add(\"about\");\n\t\tallowedProtocols.add(\"irc\");\n\t\t// file:// ?\n\t}\n\tprivate URI baseURI;\n\tprivate URI strippedBaseURI;\n\tprivate final FoundURICallback cb;\n\tprivate final TagReplacerCallback trc;\n\t/** Provider for link filter exceptions. */\n\tprivate final LinkFilterExceptionProvider linkFilterExceptionProvider;\n        private static volatile boolean logMINOR;\n\tstatic {\n\t\tLogger.registerLogThresholdCallback(new LogThresholdCallback(){\n\t\t\t@Override\n\t\t\tpublic void shouldUpdate(){\n\t\t\t\tlogMINOR = Logger.shouldLog(LogLevel.MINOR, this);\n\t\t\t}\n\t\t});\n\t}\n\tpublic GenericReadFilterCallback(URI uri, FoundURICallback cb,TagReplacerCallback trc, LinkFilterExceptionProvider linkFilterExceptionProvider) {\n\t\tthis.baseURI = uri;\n\t\tthis.cb = cb;\n\t\tthis.trc=trc;\n\t\tthis.linkFilterExceptionProvider = linkFilterExceptionProvider;\n\t\tsetStrippedURI(uri.toString());\n\t}\n\t\n\tpublic GenericReadFilterCallback(FreenetURI uri, FoundURICallback cb,TagReplacerCallback trc, LinkFilterExceptionProvider linkFilterExceptionProvider) {\n\t\ttry {\n\t\t\tthis.baseURI = uri.toRelativeURI();\n\t\t\tsetStrippedURI(baseURI.toString());\n\t\t\tthis.cb = cb;\n\t\t\tthis.trc=trc;\n\t\t\tthis.linkFilterExceptionProvider = linkFilterExceptionProvider;\n\t\t} catch (URISyntaxException e) {\n\t\t\tthrow new Error(e);\n\t\t}\n\t}\n\tprivate void setStrippedURI(String u) {\n\t\tint idx = u.lastIndexOf('/');\n\t\tif(idx > 0) {\n\t\t\tu = u.substring(0, idx+1);\n\t\t\ttry {\n\t\t\t\tstrippedBaseURI = new URI(u);\n\t\t\t} catch (URISyntaxException e) {\n\t\t\t\tLogger.error(this, \"Can't strip base URI: \"+e+\" parsing \"+u);\n\t\t\t\tstrippedBaseURI = baseURI;\n\t\t\t}\n\t\t} else\n\t\t\tstrippedBaseURI = baseURI;\n\t}\n\t@Override\n\tpublic String processURI(String u, String overrideType) throws CommentException {\n\t\treturn processURI(u, overrideType, false, false);\n\t}\n\t\n\t// RFC3986\n\t//  unreserved    = ALPHA / DIGIT / \"-\" / \".\" / \"_\" / \"~\"\n\tprotected static final String UNRESERVED = \"[a-zA-Z0-9\\\\-\\\\._~]\";\n\t//  pct-encoded   = \"%\" HEXDIG HEXDIG\n\tprotected static final String PCT_ENCODED = \"(?:%[0-9A-Fa-f][0-9A-Fa-f])\";\n\t//  sub-delims    = \"!\" / \"$\" / \"&\" / \"'\" / \"(\" / \")\"\n\t//                / \"*\" / \"+\" / \",\" / \";\" / \"=\"\n\tprotected static final String SUB_DELIMS  = \"[\\\\!\\\\$&'\\\\(\\\\)\\\\*\\\\+,;=]\";\n\t//  pchar         = unreserved / pct-encoded / sub-delims / \":\" / \"@\"\n\tprotected static final String PCHAR      = \"(?>\" + UNRESERVED + \"|\" + PCT_ENCODED + \"|\" + SUB_DELIMS + \"|[:@])\";\n\t//  fragment      = *( pchar / \"/\" / \"?\" )\n\tprotected static final String FRAGMENT   = \"(?>\" + PCHAR + \"|\\\\/|\\\\?)*\";\n\tprivate static final Pattern anchorRegex;\n\tstatic {\n\t    anchorRegex = Pattern.compile(\"^#\" + FRAGMENT + \"$\");\n\t}\n\t@Override\n\tpublic String processURI(String u, String overrideType, boolean forBaseHref, boolean inline) throws CommentException {\n\t\tif(anchorRegex.matcher(u).matches()) {\n\t\t\t// Hack for anchors, see #710\n\t\t\treturn u;\n\t\t}\n\t\t\n\t\tboolean noRelative = forBaseHref;\n\t\t// evil hack, see #2451 and r24565,r24566\n\t\tu = u.replaceAll(\" #\", \" %23\");\n\t\t\n\t\tURI uri;\n\t\tURI resolved;\n\t\ttry {\n\t\t\tif(logMINOR) Logger.minor(this, \"Processing \"+u);\n\t\t\turi = URIPreEncoder.encodeURI(u).normalize();\n\t\t\tif(logMINOR) Logger.minor(this, \"Processing \"+uri);\n\t\t\tif(u.startsWith(\"/\") || u.startsWith(\"%2f\"))\n\t\t\t\t// Don't bother with relative URIs if it's obviously absolute.\n\t\t\t\t// Don't allow encoded /'s, they're just too confusing (here they would get decoded and then coalesced with other slashes).\n\t\t\t\tnoRelative = true;\n\t\t\tif(!noRelative)\n\t\t\t\tresolved = baseURI.resolve(uri);\n\t\t\telse\n\t\t\t\tresolved = uri;\n\t\t\tif(logMINOR) Logger.minor(this, \"Resolved: \"+resolved);\n\t\t} catch (URISyntaxException e1) {\n\t\t\tif(logMINOR) Logger.minor(this, \"Failed to parse URI: \"+e1);\n\t\t\tthrow new CommentException(l10n(\"couldNotParseURIWithError\", \"error\", e1.getMessage()));\n\t\t}\n\t\tString path = uri.getPath();\n\t\t\n\t\tHTTPRequest req = new HTTPRequestImpl(uri, \"GET\");\n\t\tif (path != null) {\n\t\t\tif (path.equals(\"/\") && req.isParameterSet(\"newbookmark\") && !forBaseHref) {\n\t\t\t\t// allow links to the root to add bookmarks\n\t\t\t\tString bookmark_key = req.getParam(\"newbookmark\");\n\t\t\t\tString bookmark_desc = req.getParam(\"desc\");\n\t\t\t\tString bookmark_activelink = req.getParam(\"hasAnActivelink\", \"\");\n\t\t\t\ttry {\n\t\t\t\t\tFreenetURI furi = new FreenetURI(bookmark_key);\n\t\t\t\t\tbookmark_key = furi.toString();\n\t\t\t\t\tbookmark_desc = URLEncoder.encode(bookmark_desc, \"UTF-8\");\n\t\t\t\t} catch (UnsupportedEncodingException e) {\n\t\t\t\t\t// impossible, UTF-8 is always supported\n\t\t\t\t} catch (MalformedURLException e) {\n\t\t\t\t\tthrow new CommentException(\"Invalid Freenet URI: \" + e);\n\t\t\t\t}\n\t\t\t\tString url = \"/?newbookmark=\"+bookmark_key+\"&desc=\"+bookmark_desc;\n\t\t\t\tif (bookmark_activelink.equals(\"true\")) {\n\t\t\t\t\turl = url + \"&hasAnActivelink=true\";\n\t\t\t\t}\n\t\t\t\treturn url;\n\t\t\t} else if(path.startsWith(StaticToadlet.ROOT_URL)) {\n\t\t\t\t// @see bug #2297\n\t\t\t\treturn path;\n\t\t\t} else if (linkFilterExceptionProvider != null) {\n\t\t\t\tif (linkFilterExceptionProvider.isLinkExcepted(uri)) {\n\t\t\t\t\treturn path + ((uri.getQuery() != null) ? (\"?\" + uri.getQuery()) : \"\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\n\t\tString reason = l10n(\"deletedURI\");\n\t\t\n\t\t// Try as an absolute URI\n\t\t\n\t\tURI origURI = uri;\n\t\t\n\t\t// Convert localhost uri's to relative internal ones.\n\t\t\n\t\tString host = uri.getHost();\n\t\tif(host != null && (host.equals(\"localhost\") || host.equals(\"127.0.0.1\")) && uri.getPort() == 8888) {\n\t\t\ttry {\n\t\t\t\turi = new URI(null, null, null, -1, uri.getPath(), uri.getQuery(), uri.getFragment());\n\t\t\t} catch (URISyntaxException e) {\n\t\t\t\tLogger.error(this, \"URI \"+uri+\" looked like localhost but could not parse\", e);\n\t\t\t\tthrow new CommentException(\"URI looked like localhost but could not parse: \"+e);\n\t\t\t}\n\t\t\thost = null;\n\t\t}\n\t\t\n\t\tString rpath = uri.getPath();\n\t\tif(logMINOR) Logger.minor(this, \"Path: \\\"\"+path+\"\\\" rpath: \\\"\"+rpath+\"\\\"\");\n\t\t\n\t\tif(host == null) {\n\t\t\n\t\t\tboolean isAbsolute = false;\n\t\t\t\n\t\t\tif(rpath != null) {\n\t\t\t\tif(logMINOR) Logger.minor(this, \"Resolved URI (rpath absolute): \\\"\"+rpath+\"\\\"\");\n\t\t\t\t\n\t\t\t\t// Valid FreenetURI?\n\t\t\t\ttry {\n\t\t\t\t\tString p = rpath;\n\t\t\t\t\twhile(p.startsWith(\"/\")) {\n\t\t\t\t\t\tp = p.substring(1);\n\t\t\t\t\t}\n\t\t\t\t\tFreenetURI furi = new FreenetURI(p, true);\n\t\t\t\t\tisAbsolute = true;\n\t\t\t\t\tif(logMINOR) Logger.minor(this, \"Parsed: \"+furi);\n\t\t\t\t\treturn processURI(furi, uri, overrideType, true, inline);\n\t\t\t\t} catch (MalformedURLException e) {\n\t\t\t\t\t// Not a FreenetURI\n\t\t\t\t\tif(logMINOR) Logger.minor(this, \"Malformed URL (a): \"+e, e);\n\t\t\t\t\tif(e.getMessage() != null) {\n\t\t\t\t\t\treason = l10n(\"malformedAbsoluteURL\", \"error\", e.getMessage());\n\t\t\t\t\t} else {\n\t\t\t\t\t\treason = l10n(\"couldNotParseAbsoluteFreenetURI\");\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\tif((!isAbsolute) && (!forBaseHref)) {\n\t\t\t\t\n\t\t\t\t// Relative URI\n\t\t\t\t\n\t\t\t\trpath = resolved.getPath();\n\t\t\t\tif(rpath == null) throw new CommentException(\"No URI\");\n\t\t\t\tif(logMINOR) Logger.minor(this, \"Resolved URI (rpath relative): \"+rpath);\n\t\t\t\t\n\t\t\t\t// Valid FreenetURI?\n\t\t\t\ttry {\n\t\t\t\t\tString p = rpath;\n\t\t\t\t\twhile(p.startsWith(\"/\")) p = p.substring(1);\n\t\t\t\t\tFreenetURI furi = new FreenetURI(p, true);\n\t\t\t\t\tif(logMINOR) Logger.minor(this, \"Parsed: \"+furi);\n\t\t\t\t\treturn processURI(furi, uri, overrideType, forBaseHref, inline);\n\t\t\t\t} catch (MalformedURLException e) {\n\t\t\t\t\tif(logMINOR) Logger.minor(this, \"Malformed URL (b): \"+e, e);\n\t\t\t\t\tif(e.getMessage() != null) {\n\t\t\t\t\t\treason = l10n(\"malformedRelativeURL\", \"error\", e.getMessage());\n\t\t\t\t\t} else {\n\t\t\t\t\t\treason = l10n(\"couldNotParseRelativeFreenetURI\");\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t\n\t\t\t}\n\t\t\n\t\t}\n\t\t\n\t\turi = origURI;\n\t\t\n\t\tif(forBaseHref)\n\t\t\tthrow new CommentException(l10n(\"bogusBaseHref\"));\n\t\tif(GenericReadFilterCallback.allowedProtocols.contains(uri.getScheme()))\n\t\t\treturn ExternalLinkToadlet.escape(uri.toString());\n\t\telse {\n\t\t\tif(uri.getScheme() == null) {\n\t\t\t\tthrow new CommentException(reason);\n\t\t\t}\n\t\t\tthrow new CommentException(l10n(\"protocolNotEscaped\", \"protocol\", uri.getScheme()));\n\t\t}\n\t}\n\t\n\t@Override\n\tpublic String makeURIAbsolute(String uri) throws URISyntaxException{\n\t\treturn baseURI.resolve(URIPreEncoder.encodeURI(uri).normalize()).toASCIIString();\n\t}\n\tprivate static String l10n(String key, String pattern, String value) {\n\t\treturn NodeL10n.getBase().getString(\"GenericReadFilterCallback.\"+key, pattern, value);\n\t}\n\tprivate static String l10n(String key) {\n\t\treturn NodeL10n.getBase().getString(\"GenericReadFilterCallback.\"+key);\n\t}\n\tprivate String finishProcess(HTTPRequest req, String overrideType, String path, URI u, boolean noRelative) {\n\t\tString typeOverride = req.getParam(\"type\", null);\n\t\tif(overrideType != null)\n\t\t\ttypeOverride = overrideType;\n\t\tif(typeOverride != null) {\n\t\t\tString[] split = HTMLFilter.splitType(typeOverride);\n\t\t\tif(split[1] != null) {\n\t\t\t\tString charset = split[1];\n\t\t\t\tif(charset != null) {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tcharset = URLDecoder.decode(charset, false);\n\t\t\t\t\t} catch (URLEncodedFormatException e) {\n\t\t\t\t\t\tcharset = null;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif(charset != null && charset.indexOf('&') != -1)\n\t\t\t\t\tcharset = null;\n\t\t\t\tif(charset != null && !Charset.isSupported(charset))\n\t\t\t\t\tcharset = null;\n\t\t\t\tif(charset != null)\n\t\t\t\t\ttypeOverride = split[0]+\"; charset=\"+charset;\n\t\t\t\telse\n\t\t\t\t\ttypeOverride = split[0];\n\t\t\t}\n\t\t}\n\t\t\n\t\t// REDFLAG any other options we should support? \n\t\t// Obviously we don't want to support ?force= !!\n\t\t// At the moment, ?type= and ?force= are the only options supported by FProxy anyway.\n\t\t\n\t\ttry {\n\t\t\t// URI encoding issues: FreenetURI.toString() does URLEncode'ing of critical components.\n\t\t\t// So if we just pass it in to the component-wise constructor, we end up encoding twice, \n\t\t\t// so get %2520 for a space.\n\t\t\t\n\t\t\t// However, we want to support encoded slashes or @'s in the path, so we don't want to\n\t\t\t// just decode before feeding it to the constructor. It looks like the best option is\n\t\t\t// to construct it ourselves and then re-parse it. This is doing unnecessary work, it\n\t\t\t// would be much easier if we had a component-wise constructor for URI that didn't \n\t\t\t// re-encode, but at least it works...\n\t\t\t\n\t\t\tStringBuilder sb = new StringBuilder();\n\t\t\tif(strippedBaseURI.getScheme() != null && !noRelative) {\n\t\t\t\tsb.append(strippedBaseURI.getScheme());\n\t\t\t\tsb.append(\"://\");\n\t\t\t\tsb.append(strippedBaseURI.getAuthority());\n\t\t\t\tassert(path.startsWith(\"/\"));\n\t\t\t}\n\t\t\tsb.append(path);\n\t\t\tif(typeOverride != null) {\n\t\t\t\tsb.append(\"?type=\");\n\t\t\t\tsb.append(freenet.support.URLEncoder.encode(typeOverride, \"\", false, \"=\"));\n\t\t\t}\n\t\t\tif(u.getFragment() != null) {\n\t\t\t\tsb.append('#');\n\t\t\t\tsb.append(u.getRawFragment());\n\t\t\t}\n\t\t\t\n\t\t\tURI uri = new URI(sb.toString());\n\t\t\t\n\t\t\tif(!noRelative)\n\t\t\t\turi = strippedBaseURI.relativize(uri);\n\t\t\tif(logMINOR)\n\t\t\t\tLogger.minor(this, \"Returning \"+uri.toASCIIString()+\" from \"+path+\" from baseURI=\"+baseURI+\" stripped base uri=\"+strippedBaseURI.toString());\n\t\t\treturn uri.toASCIIString();\n\t\t} catch (URISyntaxException e) {\n\t\t\tLogger.error(this, \"Could not parse own URI: path=\"+path+\", typeOverride=\"+typeOverride+\", frag=\"+u.getFragment()+\" : \"+e, e);\n\t\t\tString p = path;\n\t\t\tif(typeOverride != null)\n\t\t\t\tp += \"?type=\"+typeOverride;\n\t\t\tif(u.getFragment() != null){\n\t\t\t\ttry{\n\t\t\t\t// FIXME encode it properly\n\t\t\t\t\tp += URLEncoder.encode(u.getFragment(),\"UTF-8\");\n\t\t\t\t}catch (UnsupportedEncodingException e1){\n\t\t\t\t\tthrow new Error(\"Impossible: JVM doesn't support UTF-8: \" + e, e);\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn p;\n\t\t}\n\t}\n\tprivate String processURI(FreenetURI furi, URI uri, String overrideType, boolean noRelative, boolean inline) {\n\t\t// Valid Freenet URI, allow it\n\t\t// Now what about the queries?\n\t\tHTTPRequest req = new HTTPRequestImpl(uri, \"GET\");\n\t\tif(cb != null) cb.foundURI(furi);\n\t\tif(cb != null) cb.foundURI(furi, inline);\n\t\treturn finishProcess(req, overrideType, '/' + furi.toString(false, false), uri, noRelative);\n\t}\n\t@Override\n\tpublic String onBaseHref(String baseHref) {\n\t\tString ret;\n\t\ttry {\n\t\t\tret = processURI(baseHref, null, true, false);\n\t\t} catch (CommentException e1) {\n\t\t\tLogger.error(this, \"Failed to parse base href: \"+baseHref+\" -> \"+e1.getMessage());\n\t\t\tret = null;\n\t\t}\n\t\tif(ret == null) {\n\t\t\tLogger.error(this, \"onBaseHref() failed: cannot sanitize \"+baseHref);\n\t\t\treturn null;\n\t\t} else {\n\t\t\ttry {\n\t\t\t\tbaseURI = new URI(ret);\n\t\t\t\tsetStrippedURI(ret);\n\t\t\t} catch (URISyntaxException e) {\n\t\t\t\tthrow new Error(e); // Impossible\n\t\t\t}\n\t\t\treturn baseURI.toASCIIString();\n\t\t}\n\t}\n\t@Override\n\tpublic void onText(String s, String type) {\n\t\tif(cb != null)\n\t\t\tcb.onText(s, type, baseURI);\n\t}\n\tstatic final String PLUGINS_PREFIX = \"/plugins/\";\n\t\n\t/**\n\t * Process a form.\n\t * Current strategy:\n\t * - Both POST and GET forms are allowed to /\n\t * Anything that is hazardous should be protected through formPassword.\n\t * @throws CommentException If the form element could not be parsed and the user should be told.\n\t */\n\t@Override\n\tpublic String processForm(String method, String action) throws CommentException {\n\t\tif(action == null) return null;\n\t\tif(method == null) method = \"GET\";\n\t\tmethod = method.toUpperCase();\n\t\tif(!(method.equals(\"POST\") || method.equals(\"GET\"))) \n\t\t\treturn null; // no irregular form sending methods\n\t\t// FIXME what about /downloads/ /friends/ etc?\n\t\t// Allow access to Library for searching, form passwords are used for actions such as adding bookmarks\n\t\tif(action.equals(\"/library/\"))\n\t\t\treturn action;\n\t\ttry {\n\t\t\tURI uri = URIPreEncoder.encodeURI(action);\n\t\t\tif(uri.getScheme() != null || uri.getHost() != null || uri.getPort() != -1 || uri.getUserInfo() != null)\n\t\t\t\tthrow new CommentException(l10n(\"invalidFormURI\"));\n", "outputs": ["\t\t\tString path = uri.getPath();"], "input_length": 3118, "output_length": 7, "length": 3125, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "3b446fd0f84b455d517bde09a35278219f61344a520fe140ea161d801c05e98b"}
{"input": "", "context": "from PyQt4 import QtCore,QtGui,Qt\nimport sys, os\nfrom ui import design\nfrom genericpath import isdir, isfile\nfrom collections import OrderedDict\nfrom src import Utils, showTags\nfrom functools import partial\ntry:\n    _fromUtf8 = QtCore.QString.fromUtf8\nexcept AttributeError:\n    _fromUtf8 = lambda s: s\nclass WindowSource(QtGui.QMainWindow,design.Ui_Dialog):\n    currentDir = \".\"\n    clickedFile = \"\"\n    clickedFileOrDir = \"\"\n    activeTreeview = 0\n    filter = \"\"\n    ftpParams=[]\n    \n    def __init__(self,parent=None):\n        super(WindowSource,self).__init__(parent)\n        self.setupUi(self)\n        self.connectActions()\n        print self.__class__.__name__ + \" is initialized\"\n        \n        self.treeViews = [ self.treeView, self.treeView_2 ]\n        self.fileSystemModels = [ self.fileSystemModel, self.fileSystemModel2 ]\n        self.roots = [ self.root, self.root2 ]\n        \n        \n        self.treeviewClicked(self.root)\n        self.currentDirTxtLine2.setText(self.currentDir)\n        self.changeActiveTreeview(0)\n        \n        self.showTagsOnMainWindow()\n        \n    def main(self):\n        #self.showMaximized()\n        self.show()\n        print \"window is showed\"\n        \n    def connectActions(self):\n        \n        #self.showDir.clicked.connect(self.doShowDir)\n        self.currentDirTxtLine.returnPressed.connect(lambda: self.doShowDir(0))\n        self.currentDirTxtLine2.returnPressed.connect(lambda: self.doShowDir(1))\n        self.newDirButton.triggered.connect(self.callNewDir)\n        \n        self.homeTreeView.clicked.connect(self.homeTreeviewClicked)\n        \n        self.treeView.clicked.connect(lambda: self.changeActiveTreeview(0))\n        self.treeView_2.clicked.connect(lambda: self.changeActiveTreeview(1))\n        self.treeView.clicked.connect(self.changeclickedFileOrDir)\n        self.treeView_2.clicked.connect(self.changeclickedFileOrDir)\n        \n        \n        self.treeView.doubleClicked.connect(self.treeviewClicked)\n        self.treeView_2.doubleClicked.connect(self.treeviewClicked)\n        \n        self.newFileButton.triggered.connect(self.callNewFile)\n        self.parentDir.triggered.connect(self.showParentDir)\n        self.openFileButton.triggered.connect(self.callOpenFile)\n        self.renameButton.triggered.connect(self.callRename)\n        self.deleteButton.triggered.connect(self.callDelete)\n        self.fileTypeButton.triggered.connect(self.callFileTypeInfo)\n        self.bookmarkButton.triggered.connect(self.callAddToBookmarks)\n        self.bookmarkListButton.triggered.connect(self.callListBookmarks)\n        self.ftpConnectionButton.triggered.connect(self.callFtp)\n        self.createTagButton.triggered.connect(self.callCreateTag)\n        self.searchButton.triggered.connect(self.search)\n        self.aboutButton.triggered.connect(self.about)\n        \n        self.treeView.setContextMenuPolicy(QtCore.Qt.CustomContextMenu)\n        self.treeView.customContextMenuRequested.connect(self.rightClickMenu)\n        \n        self.treeView_2.setContextMenuPolicy(QtCore.Qt.CustomContextMenu)\n        self.treeView_2.customContextMenuRequested.connect(self.rightClickMenu)\n        \n        self.filterTxtLine.textChanged.connect(self.setFilter)\n    \n    def showTagsOnMainWindow(self):\n        tagObj = showTags.showTags()\n        self.tags = tagObj.getTags()\n        buts = {}\n        colorList = []\n        \n        for i in reversed(self.tags):\n            buts.update({i['name'] : i['color']})\n            colorList.append(i['color'])\n        self.buttons = []\n        i=0\n        for name, color in buts.items():\n            self.buttons.append(QtGui.QPushButton(\"#\"+name, self))\n            width = self.buttons[-1].fontMetrics().boundingRect(name).width() + 20\n            self.buttons[-1].setMaximumWidth(width)\n            self.buttons[-1].clicked.connect(partial(self.callClickedTag, data=name))\n            self.buttons[-1].setStyleSheet(\"QPushButton { background-color : transparent; color : \"+color+\"; }\")\n            self.buttons[-1].setCursor(QtGui.QCursor(QtCore.Qt.PointingHandCursor))\n            self.tagButtons.addWidget(self.buttons[-1])\n            i += 1\n        \n    def clearTagsOnMainWindow(self):\n        for i in self.buttons:\n            i.setParent(None)\n    \n    def callClickedTag(self, x, data):\n        import showTagsPaths\n        self.newTagPath = \"\"\n        tag = showTagsPaths.showTagsPaths(data)\n        \n        if tag.changePath:\n            if self.activeTreeview == 0:\n                self.currentDirTxtLine.setText(tag.newTagPath)\n            elif self.activeTreeview == 1:\n                self.currentDirTxtLine2.setText(tag.newTagPath)\n                   \n            self.doShowDir(self.activeTreeview)\n        self.clearTagsOnMainWindow()\n        self.showTagsOnMainWindow()\n        \n    def search(self):\n        import searchFile\n        self.newSearchPath = \"\"\n        sf = searchFile.searchFile(self.currentDir)\n        if sf.changePath:\n            if self.activeTreeview==0:\n                self.currentDirTxtLine.setText(sf.newSearchPath)\n            elif self.activeTreeview==1:\n                self.currentDirTxtLine2.setText(sf.newSearchPath)\n                \n            self.doShowDir(self.activeTreeview)\n        \n    def about(self):\n        import about\n        about.aboutDialog()\n    \n    def setFilter(self):\n        self.filter = unicode( self.filterTxtLine.text() )\n        self.doShowDir(self.activeTreeview)\n        \n    def changeActiveTreeview(self, i):\n        self.activeTreeview = i\n        print \"active treeview is now \" + str(i)\n        if i==0:\n            self.currentDir = self.currentDirTxtLine.text()\n            self.currentDirTxtLine2.setStyleSheet(\"QLineEdit { background-color : #ccc; color : #999; }\")\n            self.currentDirTxtLine.setStyleSheet(\"\")\n        elif i==1:\n            self.currentDir = self.currentDirTxtLine2.text()\n            self.currentDirTxtLine.setStyleSheet(\"QLineEdit { background-color : #ccc; color : #999; }\")\n            self.currentDirTxtLine2.setStyleSheet(\"\")\n        \n        self.showCurrentDirInfo()\n            \n    def rightClickMenu(self, pos):\n        print \"right clicked\"\n        \n        menu = QtGui.QMenu()\n        actionsList = OrderedDict((('Open', 'callOpenFile'),  ('Copy', 'copyFile'), ('Cut' , 'cutFile'), ('Paste', 'pasteFile'), ('Rename', 'callRename'), ('Delete', 'callDelete'),  ('Add to Bookmarks', 'callAddToBookmarks'), ('Add Tag', 'callAddToTags'), ('File Type Info', 'callFileTypeInfo'), ('Properties', 'callProperties')))\n        seperatorAfterThis = ['callOpenFile', 'pasteFile', 'callDelete', 'callAddToTags']\n        actions = []\n        actionFunctions = []\n        \n        for k,v in actionsList.iteritems():\n            actions.append(menu.addAction(k))\n            actionFunctions.append(v)\n            \n            if v in seperatorAfterThis:\n                menu.addSeparator()\n        \n        action = menu.exec_(self.treeViews[self.activeTreeview].mapToGlobal(pos))\n        \n        for i in range(0, len(actions)):\n            if action == actions[i]:\n                getattr(self, actionFunctions[i])()\n                \n                \n    def copyFile(self):\n        self.copyCutFile = ['copy', self.currentDir + \"/\" + self.clickedFileOrDir]\n        print self.clickedFileOrDir + \" file set to be copied\"\n    \n    def cutFile(self):\n        self.copyCutFile = ['cut', self.currentDir + \"/\" + self.clickedFileOrDir]\n        print self.clickedFileOrDir + \" file set to be cut\"\n        \n    def pasteFile(self):\n        import copyCutPaste\n        if self.activeTreeview == 0:\n            p = unicode(self.currentDirTxtLine.text())\n        elif self.activeTreeview == 1:\n            p = unicode(self.currentDirTxtLine2.text())\n        copyCutPaste.copyCutPaste(self.copyCutFile[0], self.copyCutFile[1], p)\n    \n    def callFileTypeInfo(self):\n        import fileTypeInfo\n        fileTypeInfo.fileTypeInfo(self.clickedFileOrDir)\n        \n    def callAddToBookmarks(self):\n        import addToBookmarks\n        addToBookmarks.addToBookmarks(self.currentDir + \"/\" + self.clickedFileOrDir)\n        \n    def callListBookmarks(self):\n        self.newBookmarkPath = \"\"\n        import showBookmarksList\n        bm = showBookmarksList.showBookmarksList(self.currentDir + \"/\" + self.clickedFileOrDir)\n        if bm.changePath:\n            if self.activeTreeview==0:\n                self.currentDirTxtLine.setText(bm.newBookmarkPath)\n            elif self.activeTreeview==1:\n                self.currentDirTxtLine2.setText(bm.newBookmarkPath)\n                \n            self.doShowDir(self.activeTreeview)\n    \n    def callDelete(self):\n        import deleteFileDir\n        deleteFileDir.deleteFileDir(self.currentDir + \"/\" + self.clickedFileOrDir)\n        \n    def callRename(self):\n        import renameFileDir\n        renameFileDir.renameFileDir(self.currentDir + \"/\" + self.clickedFileOrDir)\n    def callOpenFile(self):\n        print \"to open\"\n        import openFile\n        from os.path import isfile\n        toOpenFile = self.clickedFile\n        if(isfile(toOpenFile)):\n            openFile.openFile(toOpenFile)\n    \n    def callAddToTags(self):\n        import addToTags\n        addToTags.addToTags(self.currentDir + \"/\" + self.clickedFileOrDir)\n    \n    def callCreateTag(self):\n        import createTag\n        newTag = createTag.createTag(self.currentDir + \"/\" + self.clickedFileOrDir)\n        newTag.showNewTagDialog()\n        self.clearTagsOnMainWindow()\n        self.showTagsOnMainWindow()\n    \n    def callProperties(self):\n        import properties\n        properties.properties(self.currentDir + \"/\" + self.clickedFileOrDir)\n        \n    def callNewFile(self):\n        import newFile\n        newFile.newFile(self.currentDir)\n    \n    def callNewDir(self):\n        import newDir\n        newDir.newDir(self.currentDir)\n        \n    def callFtp(self):\n        import ftpConn\n        f = ftpConn.ftpConn()\n        \n        if self.activeTreeview==0:\n            self.currentDirTxtLine.setText(f.getPath())\n        elif self.activeTreeview==1:\n            self.currentDirTxtLine2.setText(f.getPath())\n            \n        self.doShowDir(self.activeTreeview)\n        \n    def callShowDir(self):\n        import showDir\n        if self.activeTreeview==0:\n            self.currentDir = showDir.showDir(self.currentDirTxtLine.text())\n        elif self.activeTreeview==1:\n            self.currentDir = showDir.showDir(self.currentDirTxtLine2.text())\n    \n    def showParentDir(self):\n        self.clickedFileOrDir = \"\"\n        parentDir = str(self.currentDir).rsplit('/',1)[0]\n        if(isdir(parentDir)):\n            self.roots[self.activeTreeview] = self.fileSystemModels[self.activeTreeview].setRootPath(parentDir)\n            self.treeViews[self.activeTreeview].setModel(self.fileSystemModels[self.activeTreeview])\n            self.treeViews[self.activeTreeview].setRootIndex(self.roots[self.activeTreeview])\n            self.currentDir = parentDir\n            if self.activeTreeview==0:\n                self.currentDirTxtLine.setText(self.currentDir)\n            elif self.activeTreeview==1:\n                self.currentDirTxtLine2.setText(self.currentDir)\n            self.showCurrentDirInfo()\n        else:\n            print parentDir + \" is not a directory\"\n        \n    def doShowDir(self, tv):\n        self.activeTreeview = tv\n        if self.activeTreeview==0:\n            newDir = unicode(self.currentDirTxtLine.text())\n        elif self.activeTreeview==1:\n            newDir = unicode(self.currentDirTxtLine2.text())\n            \n        self.clickedFileOrDir = \"\"\n        \n        if(isdir(newDir)):\n            \n            self.fileSystemModels[self.activeTreeview].setNameFilters([self.filter+\"*\"])  \n            self.fileSystemModels[self.activeTreeview].setNameFilterDisables(False)\n            self.roots[self.activeTreeview] = self.fileSystemModels[self.activeTreeview].setRootPath(newDir)\n            self.treeViews[self.activeTreeview].setModel(self.fileSystemModels[self.activeTreeview])\n            self.treeViews[self.activeTreeview].setRootIndex(self.roots[self.activeTreeview])\n            self.currentDir = newDir\n            \n            self.changeActiveTreeview(tv)\n            \n        else:\n            print unicode(newDir) + \" is not a directory\"\n    \n    def treeviewClicked(self, index):\n        print \"> \" + unicode(self.fileSystemModels[self.activeTreeview].filePath(index))\n        newPath = self.fileSystemModels[self.activeTreeview].filePath(index)\n        print \"new path is \" + unicode(newPath)\n        if isdir(newPath):\n            self.currentDir = newPath\n            if self.activeTreeview==0:\n                self.currentDirTxtLine.setText(self.currentDir)\n            elif self.activeTreeview==1:\n                self.currentDirTxtLine2.setText(self.currentDir)\n            self.doShowDir(self.activeTreeview)\n        elif isfile(newPath):\n            self.clickedFile = newPath\n            self.callOpenFile()\n            \n    def homeTreeviewClicked(self, index):\n        \n        newPath = unicode(self.fileSystemModel3.filePath(index))\n        print \"new path is set to\" + newPath + \" by home treeview\"\n        self.currentDir = newPath\n        if self.activeTreeview==0:\n            self.currentDirTxtLine.setText(self.currentDir)\n        elif self.activeTreeview==1:\n            self.currentDirTxtLine2.setText(self.currentDir)\n        self.doShowDir(self.activeTreeview)\n    \n    def changeclickedFileOrDir(self, index):\n        self.clickedFileOrDir = unicode(self.fileSystemModels[self.activeTreeview].filePath(index)).rsplit('/')[-1]\n        from genericpath import isfile\n        if isfile(self.currentDir + \"/\" + self.clickedFileOrDir):\n            self.clickedFile = self.currentDir + \"/\" + self.clickedFileOrDir\n        ##elif isdir(self.clickedFileOrDir):\n        #    self.currentDir = self.clickedFileOrDir\n        print self.clickedFileOrDir + \" is clicked\"\n        \n        from preview import preview\n        preImg = preview()\n        if preImg.showPreview(self.currentDir + \"/\" + self.clickedFileOrDir):\n            self.imageLabel.setPixmap(QtGui.QPixmap.fromImage(QtGui.QImage(self.currentDir + \"/\" + self.clickedFileOrDir)))\n            self.imageLabel.setVisible(True)\n            self.scrollArea.setVisible(True)\n            self.previewLabel.setVisible(True)\n        else:\n            self.imageLabel.setVisible(False)\n            self.scrollArea.setVisible(False)\n            self.previewLabel.setVisible(False)\n            \n    def showCurrentDirInfo(self):\n        numberOfFiles = len([item for item in os.listdir(unicode(self.currentDir)) if not item[0] == '.' and os.path.isfile(os.path.join(unicode(self.currentDir), item))])\n        numberOfDirs = len([item for item in os.listdir(unicode(self.currentDir)) if not item[0] == '.' and os.path.isdir(os.path.join(unicode(self.currentDir), item))]) \n        \n        numberOfHiddenFiles = len([item for item in os.listdir(unicode(self.currentDir)) if item[0] == '.'  and os.path.isfile(os.path.join(unicode(self.currentDir), item))]) \n        numberOfHiddenDirs = len([item for item in os.listdir(unicode(self.currentDir)) if item[0] == '.' and os.path.isdir(os.path.join(unicode(self.currentDir), item))]) \n        \n        infoText = \"<u>\" + Utils.getFileNameFromFullPath(unicode(self.currentDir)) + \"</u><br><br>\"\n        infoText +=  str(numberOfDirs)\n        infoText += \" directory\" if numberOfDirs==1 else \" directories\"\n        infoText += \"<br>\"\n        \n        if numberOfHiddenDirs>0:\n            infoText += \"(+\" + str(numberOfHiddenDirs) + \" hidden \" \n            infoText += \"directory\" if numberOfHiddenDirs==1 else \"directories\" \n            infoText += \")<br>\"\n            \n        infoText +=  str(numberOfFiles) \n", "outputs": ["        infoText += \" file\" if numberOfFiles==1 else \" files\" "], "input_length": 2062, "output_length": 11, "length": 2073, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "e73af9a190b582161e65cd131a7614deecdee48a7690d8082b19f656c0cf7c4b"}
{"input": "", "context": "/*\nBullet Continuous Collision Detection and Physics Library\nCopyright (c) 2003-2008 Erwin Coumans  http://bulletphysics.com\nThis software is provided 'as-is', without any express or implied warranty.\nIn no event will the authors be held liable for any damages arising from the use of this software.\nPermission is granted to anyone to use this software for any purpose, \nincluding commercial applications, and to alter it and redistribute it freely, \nsubject to the following restrictions:\n1. The origin of this software must not be misrepresented; you must not claim that you wrote the original software. If you use this software in a product, an acknowledgment in the product documentation would be appreciated but is not required.\n2. Altered source versions must be plainly marked as such, and must not be misrepresented as being the original software.\n3. This notice may not be removed or altered from any source distribution.\n*/\n#include <stdio.h>\n#include \"LinearMath/btIDebugDraw.h\"\n#include \"BulletCollision/CollisionDispatch/btGhostObject.h\"\n#include \"BulletCollision/CollisionShapes/btMultiSphereShape.h\"\n#include \"BulletCollision/BroadphaseCollision/btOverlappingPairCache.h\"\n#include \"BulletCollision/BroadphaseCollision/btCollisionAlgorithm.h\"\n#include \"BulletCollision/CollisionDispatch/btCollisionWorld.h\"\n#include \"LinearMath/btDefaultMotionState.h\"\n#include \"btKinematicCharacterController.h\"\n// static helper method\nstatic btVector3\ngetNormalizedVector(ref btVector3 v)\n{\n\tbtVector3 n(0, 0, 0);\n\tif (v.length() > SIMD_EPSILON) {\n\t\tn = v.normalized();\n\t}\n\treturn n;\n}\n///@todo Interact with dynamic objects,\n///Ride kinematicly animated platforms properly\n///More realistic (or maybe just a config option) falling\n/// . Should integrate falling velocity manually and use that in stepDown()\n///Support jumping\n///Support ducking\nclass btKinematicClosestNotMeRayResultCallback : btCollisionWorld::ClosestRayResultCallback\n{\npublic:\n\tbtKinematicClosestNotMeRayResultCallback (btCollisionObject me) : btCollisionWorld::ClosestRayResultCallback(btVector3(0.0, 0.0, 0.0), btVector3(0.0, 0.0, 0.0))\n\t{\n\t\tm_me = me;\n\t}\n\tvirtual double addSingleResult(btCollisionWorld::LocalRayResult& rayResult,bool normalInWorldSpace)\n\t{\n\t\tif (rayResult.m_collisionObject == m_me)\n\t\t\treturn 1.0;\n\t\treturn ClosestRayResultCallback::addSingleResult (rayResult, normalInWorldSpace);\n\t}\nprotected:\n\tbtCollisionObject m_me;\n};\nclass btKinematicClosestNotMeConvexResultCallback : btCollisionWorld::ClosestConvexResultCallback\n{\npublic:\n\tbtKinematicClosestNotMeConvexResultCallback (btCollisionObject me, ref btVector3 up, double minSlopeDot)\n\t: btCollisionWorld::ClosestConvexResultCallback(btVector3(0.0, 0.0, 0.0), btVector3(0.0, 0.0, 0.0))\n\t, m_me(me)\n\t, m_up(up)\n\t, m_minSlopeDot(minSlopeDot)\n\t{\n\t}\n\tvirtual double addSingleResult(btCollisionWorld::LocalConvexResult& convexResult,bool normalInWorldSpace)\n\t{\n\t\tif (convexResult.m_hitCollisionObject == m_me)\n\t\t\treturn (double)(1.0);\n\t\tif (!convexResult.m_hitCollisionObject.hasContactResponse())\n\t\t\treturn (double)(1.0);\n\t\tbtVector3 hitNormalWorld;\n\t\tif (normalInWorldSpace)\n\t\t{\n\t\t\thitNormalWorld = convexResult.m_hitNormalLocal;\n\t\t} else\n\t\t{\n\t\t\t///need to transform normal into worldspace\n\t\t\thitNormalWorld = convexResult.m_hitCollisionObject.getWorldTransform().getBasis()*convexResult.m_hitNormalLocal;\n\t\t}\n\t\tdouble dotUp = m_up.dot(hitNormalWorld);\n\t\tif (dotUp < m_minSlopeDot) {\n\t\t\treturn (double)(1.0);\n\t\t}\n\t\treturn ClosestConvexResultCallback::addSingleResult (convexResult, normalInWorldSpace);\n\t}\nprotected:\n\tbtCollisionObject m_me;\n\tbtVector3 m_up;\n\tdouble m_minSlopeDot;\n};\n/*\n * Returns the reflection direction of a ray going 'direction' hitting a surface with normal 'normal'\n *\n * from: http://www-cs-students.stanford.edu/~adityagp/final/node3.html\n */\nbtVector3 btKinematicCharacterController::computeReflectionDirection (ref btVector3 direction, ref btVector3 normal)\n{\n\treturn direction - ((double)(2.0) * direction.dot(normal)) * normal;\n}\n/*\n * Returns the portion of 'direction' that is parallel to 'normal'\n */\nbtVector3 btKinematicCharacterController::parallelComponent (ref btVector3 direction, ref btVector3 normal)\n{\n\tdouble magnitude = direction.dot(normal);\n\treturn normal * magnitude;\n}\n/*\n * Returns the portion of 'direction' that is perpindicular to 'normal'\n */\nbtVector3 btKinematicCharacterController::perpindicularComponent (ref btVector3 direction, ref btVector3 normal)\n{\n\treturn direction - parallelComponent(direction, normal);\n}\nbtKinematicCharacterController::btKinematicCharacterController (btPairCachingGhostObject* ghostObject,btConvexShape* convexShape,double stepHeight, int upAxis)\n{\n\tm_upAxis = upAxis;\n\tm_addedMargin = 0.02;\n\tm_walkDirection.setValue(0,0,0);\n\tm_useGhostObjectSweepTest = true;\n\tm_ghostObject = ghostObject;\n\tm_stepHeight = stepHeight;\n\tm_turnAngle = (double)(0.0);\n\tm_convexShape=convexShape;\t\n\tm_useWalkDirection = true;\t// use walk direction by default, legacy behavior\n\tm_velocityTimeInterval = 0.0;\n\tm_verticalVelocity = 0.0;\n\tm_verticalOffset = 0.0;\n\tm_gravity = 9.8 * 3 ; // 3G acceleration.\n\tm_fallSpeed = 55.0; // Terminal velocity of a sky diver in m/s.\n\tm_jumpSpeed = 10.0; // ?\n\tm_wasOnGround = false;\n\tm_wasJumping = false;\n\tm_interpolateUp = true;\n\tsetMaxSlope(btRadians(45.0));\n\tm_currentStepOffset = 0;\n\tfull_drop = false;\n\tbounce_fix = false;\n}\nbtKinematicCharacterController::~btKinematicCharacterController ()\n{\n}\nbtPairCachingGhostObject* btKinematicCharacterController::getGhostObject()\n{\n\treturn m_ghostObject;\n}\nbool btKinematicCharacterController::recoverFromPenetration ( btCollisionWorld* collisionWorld)\n{\n\t// Here we must refresh the overlapping paircache as the penetrating movement itself or the\n\t// previous recovery iteration might have used setWorldTransform and pushed us into an object\n\t// that is not in the previous cache contents from the last timestep, as will happen if we\n\t// are pushed into a new AABB overlap. Unhandled this means the next convex sweep gets stuck.\n\t//\n\t// Do this by calling the broadphase's setAabb with the moved AABB, this will update the broadphase\n\t// paircache and the ghostobject's internal paircache at the same time.    /BW\n\tbtVector3 minAabb, maxAabb;\n\tm_convexShape.getAabb(m_ghostObject.getWorldTransform(), minAabb,maxAabb);\n\tcollisionWorld.getBroadphase().setAabb(m_ghostObject.getBroadphaseHandle(), \n\t\t\t\t\t\t minAabb, \n\t\t\t\t\t\t maxAabb, \n\t\t\t\t\t\t collisionWorld.getDispatcher());\n\t\t\t\t\t\t \n\tbool penetration = false;\n\tcollisionWorld.getDispatcher().dispatchAllCollisionPairs(m_ghostObject.getOverlappingPairCache(), collisionWorld.getDispatchInfo(), collisionWorld.getDispatcher());\n\tm_currentPosition = m_ghostObject.getWorldTransform().getOrigin();\n\t\n\tdouble maxPen = (double)(0.0);\n\tfor (int i = 0; i < m_ghostObject.getOverlappingPairCache().getNumOverlappingPairs(); i++)\n\t{\n\t\tm_manifoldArray.resize(0);\n\t\tbtBroadphasePair* collisionPair = &m_ghostObject.getOverlappingPairCache().getOverlappingPairArray()[i];\n\t\tbtCollisionObject obj0 = static_cast<btCollisionObject>(collisionPair.m_pProxy0.m_clientObject);\n                btCollisionObject obj1 = static_cast<btCollisionObject>(collisionPair.m_pProxy1.m_clientObject);\n\t\tif ((obj0 && !obj0.hasContactResponse()) || (obj1 && !obj1.hasContactResponse()))\n\t\t\tcontinue;\n\t\t\n\t\tif (collisionPair.m_algorithm)\n\t\t\tcollisionPair.m_algorithm.getAllContactManifolds(m_manifoldArray);\n\t\t\n\t\tfor (int j=0;j<m_manifoldArray.Count;j++)\n\t\t{\n\t\t\tbtPersistentManifold* manifold = m_manifoldArray[j];\n\t\t\tdouble directionSign = manifold.getBody0() == m_ghostObject ? (double)(-1.0) : (double)(1.0);\n\t\t\tfor (int p=0;p<manifold.getNumContacts();p++)\n\t\t\t{\n\t\t\t\tbtManifoldPointpt = manifold.getContactPoint(p);\n\t\t\t\tdouble dist = pt.getDistance();\n\t\t\t\tif (dist < 0.0)\n\t\t\t\t{\n\t\t\t\t\tif (dist < maxPen)\n\t\t\t\t\t{\n\t\t\t\t\t\tmaxPen = dist;\n\t\t\t\t\t\tm_touchingNormal = pt.m_normalWorldOnB * directionSign;//??\n\t\t\t\t\t}\n\t\t\t\t\tm_currentPosition += pt.m_normalWorldOnB * directionSign * dist * (double)(0.2);\n\t\t\t\t\tpenetration = true;\n\t\t\t\t} else {\n\t\t\t\t\t//Console.WriteLine(\"touching %f\\n\", dist);\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\t//manifold.clearManifold();\n\t\t}\n\t}\n\tbtTransform newTrans = m_ghostObject.getWorldTransform();\n\tnewTrans.setOrigin(m_currentPosition);\n\tm_ghostObject.setWorldTransform(newTrans);\n//\tConsole.WriteLine(\"m_touchingNormal = %f,%f,%f\\n\",m_touchingNormal,m_touchingNormal[1],m_touchingNormal[2]);\n\treturn penetration;\n}\nvoid btKinematicCharacterController::stepUp ( btCollisionWorld* world)\n{\n\t// phase 1: up\n\tbtTransform start, end;\n\tm_targetPosition = m_currentPosition + getUpAxisDirections()[m_upAxis] * (m_stepHeight + (m_verticalOffset > 0?m_verticalOffset:0));\n\tstart.setIdentity ();\n\tend.setIdentity ();\n\t/* FIXME: Handle penetration properly */\n\tstart.setOrigin (m_currentPosition + getUpAxisDirections()[m_upAxis] * (m_convexShape.getMargin() + m_addedMargin));\n\tend.setOrigin (m_targetPosition);\n\tbtKinematicClosestNotMeConvexResultCallback callback (m_ghostObject, -getUpAxisDirections()[m_upAxis], (double)(0.7071));\n\tcallback.m_collisionFilterGroup = getGhostObject().getBroadphaseHandle().m_collisionFilterGroup;\n\tcallback.m_collisionFilterMask = getGhostObject().getBroadphaseHandle().m_collisionFilterMask;\n\t\n\tif (m_useGhostObjectSweepTest)\n\t{\n\t\tm_ghostObject.convexSweepTest (m_convexShape, start, end, callback, world.getDispatchInfo().m_allowedCcdPenetration);\n\t}\n\telse\n\t{\n\t\tworld.convexSweepTest (m_convexShape, start, end, callback);\n\t}\n\t\n\tif (callback.hasHit())\n\t{\n\t\t// Only modify the position if the hit was a slope and not a wall or ceiling.\n\t\tif(callback.m_hitNormalWorld.dot(getUpAxisDirections()[m_upAxis]) > 0.0)\n\t\t{\n\t\t\t// we moved up only a fraction of the step height\n\t\t\tm_currentStepOffset = m_stepHeight * callback.m_closestHitFraction;\n\t\t\tif (m_interpolateUp == true)\n\t\t\t\tm_currentPosition.setInterpolate3 (m_currentPosition, m_targetPosition, callback.m_closestHitFraction);\n\t\t\telse\n\t\t\t\tm_currentPosition = m_targetPosition;\n\t\t}\n\t\tm_verticalVelocity = 0.0;\n\t\tm_verticalOffset = 0.0;\n\t} else {\n\t\tm_currentStepOffset = m_stepHeight;\n\t\tm_currentPosition = m_targetPosition;\n\t}\n}\nvoid btKinematicCharacterController::updateTargetPositionBasedOnCollision (ref btVector3 hitNormal, double tangentMag, double normalMag)\n{\n\tbtVector3 movementDirection = m_targetPosition - m_currentPosition;\n\tdouble movementLength = movementDirection.length();\n\tif (movementLength>SIMD_EPSILON)\n\t{\n\t\tmovementDirection.normalize();\n\t\tbtVector3 reflectDir = computeReflectionDirection (movementDirection, hitNormal);\n\t\treflectDir.normalize();\n\t\tbtVector3 parallelDir, perpindicularDir;\n\t\tparallelDir = parallelComponent (reflectDir, hitNormal);\n\t\tperpindicularDir = perpindicularComponent (reflectDir, hitNormal);\n\t\tm_targetPosition = m_currentPosition;\n\t\tif (0)//tangentMag != 0.0)\n\t\t{\n\t\t\tbtVector3 parComponent = parallelDir * double (tangentMag*movementLength);\n//\t\t\tConsole.WriteLine(\"parComponent=%f,%f,%f\\n\",parComponent[0],parComponent[1],parComponent[2]);\n\t\t\tm_targetPosition +=  parComponent;\n\t\t}\n\t\tif (normalMag != 0.0)\n\t\t{\n\t\t\tbtVector3 perpComponent = perpindicularDir * double (normalMag*movementLength);\n//\t\t\tConsole.WriteLine(\"perpComponent=%f,%f,%f\\n\",perpComponent[0],perpComponent[1],perpComponent[2]);\n\t\t\tm_targetPosition += perpComponent;\n\t\t}\n\t} else\n\t{\n//\t\tConsole.WriteLine(\"movementLength don't normalize a zero vector\\n\");\n\t}\n}\nvoid btKinematicCharacterController::stepForwardAndStrafe ( btCollisionWorld* collisionWorld, ref btVector3 walkMove)\n{\n\t// Console.WriteLine(\"m_normalizedDirection=%f,%f,%f\\n\",\n\t// \tm_normalizedDirection[0],m_normalizedDirection[1],m_normalizedDirection[2]);\n\t// phase 2: forward and strafe\n\tbtTransform start, end;\n\tm_targetPosition = m_currentPosition + walkMove;\n\tstart.setIdentity ();\n\tend.setIdentity ();\n\t\n\tdouble fraction = 1.0;\n\tdouble distance2 = (m_currentPosition-m_targetPosition).length2();\n//\tConsole.WriteLine(\"distance2=%f\\n\",distance2);\n\tif (m_touchingContact)\n\t{\n\t\tif (m_normalizedDirection.dot(m_touchingNormal) > (double)(0.0))\n\t\t{\n\t\t\t//interferes with step movement\n\t\t\t//updateTargetPositionBasedOnCollision (m_touchingNormal);\n\t\t}\n\t}\n\tint maxIter = 10;\n\twhile (fraction > (double)(0.01) && maxIter-- > 0)\n\t{\n\t\tstart.setOrigin (m_currentPosition);\n\t\tend.setOrigin (m_targetPosition);\n\t\tbtVector3 sweepDirNegative(m_currentPosition - m_targetPosition);\n\t\tbtKinematicClosestNotMeConvexResultCallback callback (m_ghostObject, sweepDirNegative, (double)(0.0));\n\t\tcallback.m_collisionFilterGroup = getGhostObject().getBroadphaseHandle().m_collisionFilterGroup;\n\t\tcallback.m_collisionFilterMask = getGhostObject().getBroadphaseHandle().m_collisionFilterMask;\n\t\tdouble margin = m_convexShape.getMargin();\n\t\tm_convexShape.setMargin(margin + m_addedMargin);\n\t\tif (m_useGhostObjectSweepTest)\n\t\t{\n\t\t\tm_ghostObject.convexSweepTest (m_convexShape, start, end, callback, collisionWorld.getDispatchInfo().m_allowedCcdPenetration);\n\t\t} else\n\t\t{\n\t\t\tcollisionWorld.convexSweepTest (m_convexShape, start, end, callback, collisionWorld.getDispatchInfo().m_allowedCcdPenetration);\n\t\t}\n\t\t\n\t\tm_convexShape.setMargin(margin);\n\t\t\n\t\tfraction -= callback.m_closestHitFraction;\n\t\tif (callback.hasHit())\n\t\t{\t\n\t\t\t// we moved only a fraction\n\t\t\t//double hitDistance;\n\t\t\t//hitDistance = (callback.m_hitPointWorld - m_currentPosition).length();\n//\t\t\tm_currentPosition.setInterpolate3 (m_currentPosition, m_targetPosition, callback.m_closestHitFraction);\n\t\t\tupdateTargetPositionBasedOnCollision (callback.m_hitNormalWorld);\n\t\t\tbtVector3 currentDir = m_targetPosition - m_currentPosition;\n\t\t\tdistance2 = currentDir.length2();\n\t\t\tif (distance2 > SIMD_EPSILON)\n\t\t\t{\n\t\t\t\tcurrentDir.normalize();\n\t\t\t\t/* See Quake2: \"If velocity is against original velocity, stop ead to avoid tiny oscilations in sloping corners.\" */\n\t\t\t\tif (currentDir.dot(m_normalizedDirection) <= (double)(0.0))\n\t\t\t\t{\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t{\n//\t\t\t\tConsole.WriteLine(\"currentDir: don't normalize a zero vector\\n\");\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else {\n\t\t\t// we moved whole way\n\t\t\tm_currentPosition = m_targetPosition;\n\t\t}\n\t//\tif (callback.m_closestHitFraction == 0)\n\t//\t\tbreak;\n\t}\n}\nvoid btKinematicCharacterController::stepDown ( btCollisionWorld* collisionWorld, double dt)\n{\n\tbtTransform start, end, end_double;\n\tbool runonce = false;\n\t// phase 3: down\n\t/*double additionalDownStep = (m_wasOnGround && !onGround()) ? m_stepHeight : 0.0;\n\tbtVector3 step_drop = getUpAxisDirections()[m_upAxis] * (m_currentStepOffset + additionalDownStep);\n\tdouble downVelocity = (additionalDownStep == 0.0 && m_verticalVelocity<0.0?-m_verticalVelocity:0.0) * dt;\n\tbtVector3 gravity_drop = getUpAxisDirections()[m_upAxis] * downVelocity; \n\tm_targetPosition -= (step_drop + gravity_drop);*/\n\tbtVector3 orig_position = m_targetPosition;\n\t\n\tdouble downVelocity = (m_verticalVelocity<0?-m_verticalVelocity:0) * dt;\n\tif(downVelocity > 0.0 && downVelocity > m_fallSpeed\n\t\t&& (m_wasOnGround || !m_wasJumping))\n\t\tdownVelocity = m_fallSpeed;\n\tbtVector3 step_drop = getUpAxisDirections()[m_upAxis] * (m_currentStepOffset + downVelocity);\n\tm_targetPosition -= step_drop;\n\tbtKinematicClosestNotMeConvexResultCallback callback (m_ghostObject, getUpAxisDirections()[m_upAxis], m_maxSlopeCosine);\n        callback.m_collisionFilterGroup = getGhostObject().getBroadphaseHandle().m_collisionFilterGroup;\n        callback.m_collisionFilterMask = getGhostObject().getBroadphaseHandle().m_collisionFilterMask;\n        btKinematicClosestNotMeConvexResultCallback callback2 (m_ghostObject, getUpAxisDirections()[m_upAxis], m_maxSlopeCosine);\n        callback2.m_collisionFilterGroup = getGhostObject().getBroadphaseHandle().m_collisionFilterGroup;\n        callback2.m_collisionFilterMask = getGhostObject().getBroadphaseHandle().m_collisionFilterMask;\n\twhile (1)\n\t{\n\t\tstart.setIdentity ();\n\t\tend.setIdentity ();\n\t\tend_double.setIdentity ();\n\t\tstart.setOrigin (m_currentPosition);\n\t\tend.setOrigin (m_targetPosition);\n\t\t//set double test for 2x the step drop, to check for a large drop vs small drop\n\t\tend_double.setOrigin (m_targetPosition - step_drop);\n\t\tif (m_useGhostObjectSweepTest)\n\t\t{\n\t\t\tm_ghostObject.convexSweepTest (m_convexShape, start, end, callback, collisionWorld.getDispatchInfo().m_allowedCcdPenetration);\n\t\t\tif (!callback.hasHit())\n\t\t\t{\n\t\t\t\t//test a double fall height, to see if the character should interpolate it's fall (full) or not (partial)\n\t\t\t\tm_ghostObject.convexSweepTest (m_convexShape, start, end_double, callback2, collisionWorld.getDispatchInfo().m_allowedCcdPenetration);\n\t\t\t}\n\t\t} else\n\t\t{\n\t\t\tcollisionWorld.convexSweepTest (m_convexShape, start, end, callback, collisionWorld.getDispatchInfo().m_allowedCcdPenetration);\n\t\t\tif (!callback.hasHit())\n\t\t\t\t\t{\n\t\t\t\t\t\t\t//test a double fall height, to see if the character should interpolate it's fall (large) or not (small)\n\t\t\t\t\t\t\tcollisionWorld.convexSweepTest (m_convexShape, start, end_double, callback2, collisionWorld.getDispatchInfo().m_allowedCcdPenetration);\n\t\t\t\t\t}\n\t\t}\n\t\n\t\tdouble downVelocity2 = (m_verticalVelocity<0?-m_verticalVelocity:0) * dt;\n\t\tbool has_hit = false;\n\t\tif (bounce_fix == true)\n\t\t\thas_hit = callback.hasHit() || callback2.hasHit();\n\t\telse\n\t\t\thas_hit = callback2.hasHit();\n\t\tif(downVelocity2 > 0.0 && downVelocity2 < m_stepHeight && has_hit == true && runonce == false\n\t\t\t\t\t&& (m_wasOnGround || !m_wasJumping))\n\t\t{\n\t\t\t//redo the velocity calculation when falling a small amount, for fast stairs motion\n\t\t\t//for larger falls, use the smoother/slower interpolated movement by not touching the target position\n\t\t\tm_targetPosition = orig_position;\n\t\t\t\t\tdownVelocity = m_stepHeight;\n\t\t\t\tbtVector3 step_drop = getUpAxisDirections()[m_upAxis] * (m_currentStepOffset + downVelocity);\n\t\t\tm_targetPosition -= step_drop;\n\t\t\trunonce = true;\n\t\t\tcontinue; //re-run previous tests\n\t\t}\n\t\tbreak;\n\t}\n\tif (callback.hasHit() || runonce == true)\n\t{\n\t\t// we dropped a fraction of the height . hit floor\n\t\tdouble fraction = (m_currentPosition.y - callback.m_hitPointWorld.y) / 2;\n\t\t//Console.WriteLine(\"hitpoint: %g - pos %g\\n\", callback.m_hitPointWorld.y, m_currentPosition.y);\n\t\tif (bounce_fix == true)\n\t\t{\n\t\t\tif (full_drop == true)\n                                m_currentPosition.setInterpolate3 (m_currentPosition, m_targetPosition, callback.m_closestHitFraction);\n                        else\n                                //due to errors in the closestHitFraction variable when used with large polygons, calculate the hit fraction manually\n                                m_currentPosition.setInterpolate3 (m_currentPosition, m_targetPosition, fraction);\n\t\t}\n\t\telse\n\t\t\tm_currentPosition.setInterpolate3 (m_currentPosition, m_targetPosition, callback.m_closestHitFraction);\n\t\tfull_drop = false;\n\t\tm_verticalVelocity = 0.0;\n\t\tm_verticalOffset = 0.0;\n\t\tm_wasJumping = false;\n\t} else {\n\t\t// we dropped the full height\n\t\t\n\t\tfull_drop = true;\n\t\tif (bounce_fix == true)\n\t\t{\n\t\t\tdownVelocity = (m_verticalVelocity<0?-m_verticalVelocity:0) * dt;\n\t\t\tif (downVelocity > m_fallSpeed && (m_wasOnGround || !m_wasJumping))\n\t\t\t{\n\t\t\t\tm_targetPosition += step_drop; //undo previous target change\n\t\t\t\tdownVelocity = m_fallSpeed;\n\t\t\t\tstep_drop = getUpAxisDirections()[m_upAxis] * (m_currentStepOffset + downVelocity);\n\t\t\t\tm_targetPosition -= step_drop;\n\t\t\t}\n\t\t}\n\t\t//Console.WriteLine(\"full drop - %g, %g\\n\", m_currentPosition.y, m_targetPosition.y);\n\t\tm_currentPosition = m_targetPosition;\n\t}\n}\nvoid btKinematicCharacterController::setWalkDirection\n(\nref btVector3 walkDirection\n)\n{\n\tm_useWalkDirection = true;\n\tm_walkDirection = walkDirection;\n\tm_normalizedDirection = getNormalizedVector(m_walkDirection);\n}\nvoid btKinematicCharacterController::setVelocityForTimeInterval\n(\nref btVector3 velocity,\ndouble timeInterval\n)\n{\n//\tConsole.WriteLine(\"setVelocity!\\n\");\n//\tConsole.WriteLine(\"  interval: %f\\n\", timeInterval);\n//\tConsole.WriteLine(\"  velocity: (%f, %f, %f)\\n\",\n//\t\t velocity.x, velocity.y, velocity.z);\n\tm_useWalkDirection = false;\n\tm_walkDirection = velocity;\n\tm_normalizedDirection = getNormalizedVector(m_walkDirection);\n\tm_velocityTimeInterval += timeInterval;\n}\nvoid btKinematicCharacterController::reset ( btCollisionWorld* collisionWorld )\n{\n        m_verticalVelocity = 0.0;\n        m_verticalOffset = 0.0;\n        m_wasOnGround = false;\n        m_wasJumping = false;\n        m_walkDirection.setValue(0,0,0);\n        m_velocityTimeInterval = 0.0;\n        //clear pair cache\n        btHashedOverlappingPairCache *cache = m_ghostObject.getOverlappingPairCache();\n        while (cache.getOverlappingPairArray().Count > 0)\n        {\n                cache.removeOverlappingPair(cache.getOverlappingPairArray()[0].m_pProxy0, cache.getOverlappingPairArray()[0].m_pProxy1, collisionWorld.getDispatcher());\n        }\n}\nvoid btKinematicCharacterController::warp (ref btVector3 origin)\n{\n\tbtTransform xform;\n\txform.setIdentity();\n\txform.setOrigin (origin);\n\tm_ghostObject.setWorldTransform (xform);\n}\nvoid btKinematicCharacterController::preStep (  btCollisionWorld* collisionWorld)\n{\n\t\n\tint numPenetrationLoops = 0;\n\tm_touchingContact = false;\n\twhile (recoverFromPenetration (collisionWorld))\n\t{\n\t\tnumPenetrationLoops++;\n\t\tm_touchingContact = true;\n\t\tif (numPenetrationLoops > 4)\n\t\t{\n\t\t\t//Console.WriteLine(\"character could not recover from penetration = %d\\n\", numPenetrationLoops);\n\t\t\tbreak;\n\t\t}\n\t}\n\tm_currentPosition = m_ghostObject.getWorldTransform().getOrigin();\n\tm_targetPosition = m_currentPosition;\n//\tConsole.WriteLine(\"m_targetPosition=%f,%f,%f\\n\",m_targetPosition[0],m_targetPosition[1],m_targetPosition[2]);\n\t\n}\n#include <stdio.h>\nvoid btKinematicCharacterController::playerStep (  btCollisionWorld* collisionWorld, double dt)\n{\n//\tConsole.WriteLine(\"playerStep(): \");\n//\tConsole.WriteLine(\"  dt = %f\", dt);\n\t// quick check...\n\tif (!m_useWalkDirection & (m_velocityTimeInterval <= 0.0 || m_walkDirection.fuzzyZero())) {\n//\t\tConsole.WriteLine(\"\\n\");\n\t\treturn;\t\t// no motion\n\t}\n\tm_wasOnGround = onGround();\n\t// Update fall velocity.\n\tm_verticalVelocity -= m_gravity * dt;\n\tif(m_verticalVelocity > 0.0 && m_verticalVelocity > m_jumpSpeed)\n\t{\n\t\tm_verticalVelocity = m_jumpSpeed;\n\t}\n\tif(m_verticalVelocity < 0.0 && btFabs(m_verticalVelocity) > btFabs(m_fallSpeed))\n\t{\n\t\tm_verticalVelocity = -btFabs(m_fallSpeed);\n\t}\n\tm_verticalOffset = m_verticalVelocity * dt;\n\tbtTransform xform;\n\txform = m_ghostObject.getWorldTransform ();\n//\tConsole.WriteLine(\"walkDirection(%f,%f,%f)\\n\",walkDirection,walkDirection[1],walkDirection[2]);\n//\tConsole.WriteLine(\"walkSpeed=%f\\n\",walkSpeed);\n\tstepUp (collisionWorld);\n\tif (m_useWalkDirection) {\n\t\tstepForwardAndStrafe (collisionWorld, m_walkDirection);\n\t} else {\n\t\t//Console.WriteLine(\"  time: %f\", m_velocityTimeInterval);\n\t\t// still have some time left for moving!\n\t\tdouble dtMoving =\n\t\t\t(dt < m_velocityTimeInterval) ? dt : m_velocityTimeInterval;\n\t\tm_velocityTimeInterval -= dt;\n\t\t// how far will we move while we are moving?\n\t\tbtVector3 move = m_walkDirection * dtMoving;\n\t\t//Console.WriteLine(\"  dtMoving: %f\", dtMoving);\n\t\t// okay, step\n\t\tstepForwardAndStrafe(collisionWorld, move);\n\t}\n\tstepDown (collisionWorld, dt);\n\t// Console.WriteLine(\"\\n\");\n\txform.setOrigin (m_currentPosition);\n\tm_ghostObject.setWorldTransform (xform);\n}\nvoid btKinematicCharacterController::setFallSpeed (double fallSpeed)\n{\n\tm_fallSpeed = fallSpeed;\n}\nvoid btKinematicCharacterController::setJumpSpeed (double jumpSpeed)\n{\n\tm_jumpSpeed = jumpSpeed;\n}\nvoid btKinematicCharacterController::setMaxJumpHeight (double maxJumpHeight)\n{\n\tm_maxJumpHeight = maxJumpHeight;\n}\nbool btKinematicCharacterController::canJump ()\n{\n\treturn onGround();\n}\nvoid btKinematicCharacterController::jump ()\n{\n\tif (!canJump())\n\t\treturn;\n\tm_verticalVelocity = m_jumpSpeed;\n\tm_wasJumping = true;\n#if 0\n\tcurrently no jumping.\n\tbtTransform xform;\n\tm_rigidBody.getMotionState().getWorldTransform (xform);\n\tbtVector3 up = xform.getBasis()[1];\n\tup.normalize ();\n\tdouble magnitude = ((double)(1.0)/m_rigidBody.getInvMass()) * (double)(8.0);\n\tm_rigidBody.applyCentralImpulse (up * magnitude);\n#endif\n}\nvoid btKinematicCharacterController::setGravity(double gravity)\n{\n\tm_gravity = gravity;\n}\ndouble btKinematicCharacterController::getGravity()\n{\n\treturn m_gravity;\n}\nvoid btKinematicCharacterController::setMaxSlope(double slopeRadians)\n{\n\tm_maxSlopeRadians = slopeRadians;\n", "outputs": ["\tm_maxSlopeCosine = btCos(slopeRadians);"], "input_length": 3879, "output_length": 7, "length": 3886, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "625d4de85cdf63525407a36d588b19067e67d049446cf2042c5022364bea6e69"}
{"input": "", "context": "using System;\nusing System.Collections.Generic;\nusing System.Diagnostics;\nusing System.Linq;\nusing System.Text;\nusing Loyc;\nusing Loyc.Collections;\nusing S = Loyc.Syntax.CodeSymbols;\nnamespace Loyc.Syntax\n{\n\t/// <summary>Standard extension methods for <see cref=\"LNode\"/>.</summary>\n\tpublic static class LNodeExt\n\t{\n\t\t#region Trivia management\n\t\tpublic static VList<LNode> GetTrivia(this LNode node) { return GetTrivia(node.Attrs); }\n\t\tpublic static VList<LNode> GetTrivia(this VList<LNode> attrs)\n\t\t{\n\t\t\tvar trivia = VList<LNode>.Empty;\n\t\t\tforeach (var a in attrs)\n\t\t\t\tif (a.IsTrivia)\n\t\t\t\t\ttrivia.Add(a);\n\t\t\treturn trivia;\n\t\t}\n\t\t/// <summary>Gets all trailing trivia attached to the specified node.</summary>\n\t\tpublic static VList<LNode> GetTrailingTrivia(this LNode node) { return GetTrailingTrivia(node.Attrs); }\n\t\t/// <summary>Gets all trailing trivia attached to the specified node.</summary>\n\t\t/// <remarks>Trailing trivia is represented by a call to #trivia_trailing in\n\t\t/// a node's attribute list; each argument to #trivia_trailing represents one\n\t\t/// piece of trivia. If the attribute list has multiple calls to \n\t\t/// #trivia_trailing, this method combines those lists into a single list.</remarks>\n\t\tpublic static VList<LNode> GetTrailingTrivia(this VList<LNode> attrs)\n\t\t{\n\t\t\tvar trivia = VList<LNode>.Empty;\n\t\t\tforeach (var a in attrs)\n\t\t\t\tif (a.Calls(S.TriviaTrailing))\n\t\t\t\t\ttrivia.AddRange(a.Args);\n\t\t\treturn trivia;\n\t\t}\n\t\t/// <summary>Removes a node's trailing trivia and adds a new list of trailing trivia.</summary>\n\t\tpublic static LNode WithTrailingTrivia(this LNode node, VList<LNode> trivia)\n\t\t{\n\t\t\treturn node.WithAttrs(WithTrailingTrivia(node.Attrs, trivia));\n\t\t}\n\t\t/// <summary>Removes all existing trailing trivia from an attribute list and adds a new list of trailing trivia.</summary>\n\t\t/// <remarks>This method has a side-effect of recreating the #trivia_trailing\n\t\t/// node, if there is one, at the end of the attribute list. If <c>trivia</c>\n\t\t/// is empty then all calls to #trivia_trailing are removed.</remarks>\n\t\tpublic static VList<LNode> WithTrailingTrivia(this VList<LNode> attrs, VList<LNode> trivia)\n\t\t{\n\t\t\tvar attrs2 = WithoutTrailingTrivia(attrs);\n\t\t\tif (trivia.IsEmpty)\n\t\t\t\treturn attrs2;\n\t\t\treturn attrs2.Add(LNode.Call(S.TriviaTrailing, trivia));\n\t\t}\n\t\t/// <summary>Gets a new list with any #trivia_trailing attributes removed.</summary>\n\t\tpublic static VList<LNode> WithoutTrailingTrivia(this VList<LNode> attrs)\n\t\t{\n\t\t\treturn attrs.Transform((int i, ref LNode attr) => attr.Calls(S.TriviaTrailing) ? XfAction.Drop : XfAction.Keep);\n\t\t}\n\t\t/// <summary>Gets a new list with any #trivia_trailing attributes removed. Those trivia are returned in an `out` parameter.</summary>\n\t\tpublic static VList<LNode> WithoutTrailingTrivia(this VList<LNode> attrs, out VList<LNode> trailingTrivia)\n\t\t{\n\t\t\tvar trailingTrivia2 = VList<LNode>.Empty;\n\t\t\tattrs = attrs.Transform((int i, ref LNode attr) => {\n\t\t\t\tif (attr.Calls(S.TriviaTrailing)) {\n\t\t\t\t\ttrailingTrivia2.AddRange(attr.Args);\n\t\t\t\t\treturn XfAction.Drop;\n\t\t\t\t}\n\t\t\t\treturn XfAction.Keep;\n\t\t\t});\n\t\t\ttrailingTrivia = trailingTrivia2; // cannot use `out` parameter within lambda method\n\t\t\treturn attrs;\n\t\t}\n\t\t/// <summary>Adds additional trailing trivia to a node.</summary>\n\t\tpublic static LNode PlusTrailingTrivia(this LNode node, VList<LNode> trivia)\n\t\t{\n\t\t\treturn node.WithAttrs(PlusTrailingTrivia(node.Attrs, trivia));\n\t\t}\n\t\t/// <summary>Adds additional trailing trivia to a node.</summary>\n\t\tpublic static LNode PlusTrailingTrivia(this LNode node, LNode trivia)\n\t\t{\n\t\t\treturn node.WithAttrs(PlusTrailingTrivia(node.Attrs, trivia));\n\t\t}\n\t\t/// <summary>Adds additional trailing trivia to an attribute list. Has no effect if <c>trivia</c> is empty.</summary>\n\t\t/// <remarks>\n\t\t/// Trailing trivia is represented by a call to #trivia_trailing in a node's \n\t\t/// attribute list; each argument to #trivia_trailing represents one piece of \n\t\t/// trivia.\n\t\t/// <para/>\n\t\t/// In the current design, this method has a side-effect of recreating the #trivia_trailing\n\t\t/// node at the end of the attribute list, and if there are multiple #trivia_trailing\n\t\t/// lists, consolidating them into a single list, but only if the specified <c>trivia</c> \n\t\t/// list is not empty.</remarks>\n\t\tpublic static VList<LNode> PlusTrailingTrivia(this VList<LNode> attrs, VList<LNode> trivia)\n\t\t{\n\t\t\tif (trivia.IsEmpty)\n\t\t\t\treturn attrs;\n\t\t\tVList<LNode> oldTrivia;\n\t\t\tattrs = WithoutTrailingTrivia(attrs, out oldTrivia);\n\t\t\treturn attrs.Add(LNode.Call(S.TriviaTrailing, oldTrivia.AddRange(trivia)));\n\t\t}\n\t\t/// <summary>Adds additional trailing trivia to an attribute list.</summary>\n\t\tpublic static VList<LNode> PlusTrailingTrivia(this VList<LNode> attrs, LNode trivia)\n\t\t{\n\t\t\tVList<LNode> oldTrivia;\n\t\t\tattrs = WithoutTrailingTrivia(attrs, out oldTrivia);\n\t\t\treturn attrs.Add(LNode.Call(S.TriviaTrailing, oldTrivia.Add(trivia)));\n\t\t}\n\t\t#endregion\n\t\t/// <summary>Interprets a node as a list by returning <c>block.Args</c> if \n\t\t/// <c>block.Calls(listIdentifier)</c>, otherwise returning a one-item list \n\t\t/// of nodes with <c>block</c> as the only item.</summary>\n\t\tpublic static VList<LNode> AsList(this LNode block, Symbol listIdentifier)\n\t\t{\n\t\t\treturn block.Calls(listIdentifier) ? block.Args : new VList<LNode>(block);\n\t\t}\n\t\t/// <summary>Converts a list of LNodes to a single LNode by using the list \n\t\t/// as the argument list in a call to the specified identifier, or, if the \n\t\t/// list contains a single item, by returning that single item.</summary>\n\t\t/// <param name=\"listIdentifier\">Target of the node that is created if <c>list</c>\n\t\t/// does not contain exactly one item. Typical values include \"'{}\" and \"#splice\".</param>\n\t\t/// <remarks>This is the reverse of the operation performed by <see cref=\"AsList(LNode,Symbol)\"/>.</remarks>\n\t\tpublic static LNode AsLNode(this VList<LNode> list, Symbol listIdentifier)\n\t\t{\n\t\t\tif (list.Count == 1)\n\t\t\t\treturn list[0];\n\t\t\telse {\n\t\t\t\tvar r = SourceRange.Nowhere;\n\t\t\t\tif (list.Count != 0) {\n\t\t\t\t\tr = list[0].Range;\n\t\t\t\t\tr = new SourceRange(r.Source, r.StartIndex, list.Last.Range.EndIndex - r.StartIndex);\n\t\t\t\t}\n \t\t\t\treturn LNode.Call(listIdentifier, list, r);\n\t\t\t}\n\t\t}\n\t\tpublic static VList<LNode> WithSpliced(this VList<LNode> list, int index, LNode node, Symbol listName = null)\n\t\t{\n\t\t\tif (node.Calls(listName ?? CodeSymbols.Splice))\n\t\t\t\treturn list.InsertRange(index, node.Args);\n\t\t\telse\n\t\t\t\treturn list.Insert(index, node);\n\t\t}\n\t\tpublic static VList<LNode> WithSpliced(this VList<LNode> list, LNode node, Symbol listName = null)\n\t\t{\n\t\t\tif (node.Calls(listName ?? CodeSymbols.Splice))\n\t\t\t\treturn list.AddRange(node.Args);\n\t\t\telse\n\t\t\t\treturn list.Add(node);\n\t\t}\n\t\tpublic static void SpliceInsert(this WList<LNode> list, int index, LNode node, Symbol listName = null)\n\t\t{\n\t\t\tif (node.Calls(listName ?? CodeSymbols.Splice))\n\t\t\t\tlist.InsertRange(index, node.Args);\n\t\t\telse\n\t\t\t\tlist.Insert(index, node);\n\t\t}\n\t\tpublic static void SpliceAdd(this WList<LNode> list, LNode node, Symbol listName = null)\n\t\t{\n\t\t\tif (node.Calls(listName ?? CodeSymbols.Splice))\n\t\t\t\tlist.AddRange(node.Args);\n\t\t\telse\n\t\t\t\tlist.Add(node);\n\t\t}\n\t\tpublic static LNode AttrNamed(this LNode self, Symbol name)\n\t\t{\n\t\t\treturn self.Attrs.NodeNamed(name);\n\t\t}\n\t\tpublic static LNode WithoutAttrNamed(this LNode self, Symbol name)\n\t\t{\n\t\t\tLNode _;\n\t\t\treturn WithoutAttrNamed(self, name, out _);\n\t\t}\n\t\tpublic static VList<LNode> Without(this VList<LNode> list, LNode node)\n\t\t{\n\t\t\tint i = list.Count;\n\t\t\tforeach (var item in list.ToFVList()) {\n\t\t\t\ti--;\n\t\t\t\tif (item == node) {\n\t\t\t\t\tDebug.Assert(list[i] == node);\n\t\t\t\t\treturn list.RemoveAt(i);\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn list;\n\t\t}\n\t\tpublic static LNode WithoutAttr(this LNode self, LNode node)\n\t\t{\n\t\t\treturn self.WithAttrs(self.Attrs.Without(node));\n\t\t}\n\t\tpublic static LNode WithoutAttrNamed(this LNode self, Symbol name, out LNode removedAttr)\n\t\t{\n\t\t\tvar a = self.Attrs.WithoutNodeNamed(name, out removedAttr);\n\t\t\tif (removedAttr != null)\n\t\t\t\treturn self.WithAttrs(a);\n\t\t\telse\n\t\t\t\treturn self;\n\t\t}\n\t\tpublic static VList<LNode> WithoutNodeNamed(this VList<LNode> a, Symbol name)\n\t\t{\n\t\t\tLNode _;\n\t\t\treturn WithoutNodeNamed(a, name, out _);\n\t\t}\n\t\tpublic static VList<LNode> WithoutNodeNamed(this VList<LNode> list, Symbol name, out LNode removedNode)\n\t\t{\n\t\t\tremovedNode = null;\n\t\t\tfor (int i = 0, c = list.Count; i < c; i++)\n\t\t\t\tif (list[i].Name == name) {\n\t\t\t\t\tremovedNode = list[i];\n\t\t\t\t\treturn list.RemoveAt(i);\n\t\t\t\t}\n\t\t\treturn list;\n\t\t}\n\t\tpublic static LNode ArgNamed(this LNode self, Symbol name)\n\t\t{\n\t\t\treturn self.Args.NodeNamed(name);\n\t\t}\n\t\tpublic static int IndexWithName(this VList<LNode> self, Symbol name, int resultIfNotFound = -1)\n\t\t{\n\t\t\tint i = 0;\n\t\t\tforeach (LNode node in self)\n\t\t\t\tif (node.Name == name)\n\t\t\t\t\treturn i;\n\t\t\t\telse\n\t\t\t\t\ti++;\n\t\t\treturn resultIfNotFound;\n\t\t}\n\t\tpublic static LNode NodeNamed(this VList<LNode> self, Symbol name)\n\t\t{\n\t\t\tforeach (LNode node in self)\n\t\t\t\tif (node.Name == name)\n\t\t\t\t\treturn node;\n\t\t\treturn null;\n\t\t}\n\t\t#region Parentheses management\n\t\tpublic static bool IsParenthesizedExpr(this LNode node)\n\t\t{\n\t\t\treturn node.AttrNamed(CodeSymbols.TriviaInParens) != null;\n\t\t}\n\t\t/// <summary>Returns the same node with a parentheses attribute added.</summary>\n\t\tpublic static LNode InParens(this LNode node)\n\t\t{\n\t\t\treturn node.PlusAttrBefore(LNode.Id(CodeSymbols.TriviaInParens));\n\t\t}\n\t\t/// <summary>Returns the same node with a parentheses attribute added.</summary>\n\t\t/// <remarks>The node's range is changed to the provided <see cref=\"SourceRange\"/>.</remarks>\n\t\tpublic static LNode InParens(this LNode node, SourceRange range)\n\t\t{\n\t\t\treturn node.WithRange(range).PlusAttrBefore(LNode.Id(CodeSymbols.TriviaInParens));\n\t\t}\n\t\t/// <summary>Returns the same node with a parentheses attribute added.</summary>\n\t\tpublic static LNode InParens(this LNode node, ISourceFile file, int startIndex, int endIndex)\n\t\t{\n            return InParens(node, new SourceRange(file, startIndex, endIndex - startIndex));\n\t\t}\n\t\t/// <summary>Removes a single pair of parentheses, if the node has a \n\t\t/// #trivia_inParens attribute. Returns the same node when no parens are \n\t\t/// present.</summary>\n\t\tpublic static LNode WithoutOuterParens(this LNode self)\n\t\t{\n\t\t\tLNode parens;\n\t\t\tself = WithoutAttrNamed(self, S.TriviaInParens, out parens);\n\t\t\t// Restore original node range\n\t\t\tif (parens != null && self.Range.Contains(parens.Range))\n\t\t\t\treturn self.WithRange(parens.Range);\n\t\t\treturn self;\n\t\t}\n\t\t#endregion\n\t\t#region MatchesPattern() and helper methods // Used by replace() macro\n\t\tstatic LNodeFactory F = new LNodeFactory(new EmptySourceFile(\"LNodeExt.cs\"));\n\t\t/// <summary>Determines whether one Loyc tree \"matches\" another. This is \n\t\t/// different from a simple equality test in that (1) trivia atributes do \n\t\t/// not have to match, and (2) the pattern can contain placeholders represented\n\t\t/// by calls to $ (the substitution operator) with an identifier as a parameter.\n\t\t/// Placeholders match any subtree, and are saved to the <c>captures</c> map.\n\t\t/// </summary>\n\t\t/// <param name=\"candidate\">A node that you want to compare with a 'pattern'.</param>\n\t\t/// <param name=\"pattern\">A syntax tree that may contain placeholders. A \n\t\t/// placeholder is a call to the $ operator with one parameter, which must \n\t\t/// be either (A) a simple identifier, or (B) the \"..\" operator with a simple\n\t\t/// identifier as its single parameter. Otherwise, the $ operator is treated \n\t\t/// literally as something that must exist in <c>candidate</c>). The subtree \n\t\t/// in <c>candidate</c> corresponding to the placeholder is saved in \n\t\t/// <c>captures</c>.</param>\n\t\t/// <param name=\"captures\">A table that maps placeholder names from \n\t\t/// <c>pattern</c> to subtrees in <c>candidate</c>. You can set your map to \n\t\t/// null and a map will be created for you if necessary. If you already have\n\t\t/// a map, you should clear it before calling this method.</param>\n\t\t/// <param name=\"unmatchedAttrs\">On return, a list of trivia attributes in \n\t\t/// <c>candidate</c> that were not present in <c>pattern</c>.</param>\n\t\t/// <returns>true if <c>pattern</c> matches <c>candidate</c>, false otherwise.</returns>\n\t\t/// <remarks>\n\t\t/// Attributes in patterns are not yet supported.\n\t\t/// <para/>\n\t\t/// This method supports multi-part captures, which are matched to \n\t\t/// placeholders whose identifier either (A) has a #params attribute or\n\t\t/// (B) has the unary \"..\" operator applied to it (for example, if \n\t\t/// the placeholder is called p, this is written as <c>$(params p)</c> in \n\t\t/// EC#.) A placeholder that looks like this can match multiple arguments or\n\t\t/// multiple statements in the <c>candidate</c> (or <i>no</i> arguments, or\n\t\t/// no statements), and will become a #splice(...) node in <c>captures</c>\n\t\t/// if it matches multiple items. Multi-part captures are often useful for\n\t\t/// getting lists of statements before and after some required element,\n\t\t/// e.g. <c>{ $(params before); MatchThis($something); $(params after); }</c>\n\t\t/// <para/>\n\t\t/// If the same placeholder appears twice then the two matching items are \n\t\t/// combined into a single output node (calling #splice).\n\t\t/// <para/>\n\t\t/// If matching is unsuccessful, <c>captures</c> and <c>unmatchedAttrs</c>\n\t\t/// may contain irrelevant information gathered during the attempt to match.\n\t\t/// <para/>\n\t\t/// In EC#, the quote(...) macro can be used to create the LNode object for \n\t\t/// a pattern.\n\t\t/// </remarks>\n\t\tpublic static bool MatchesPattern(this LNode candidate, LNode pattern, ref MMap<Symbol, LNode> captures, out VList<LNode> unmatchedAttrs)\n\t\t{\n\t\t\t// [$capture] (...)\n\t\t\tif (!AttributesMatch(candidate, pattern, ref captures, out unmatchedAttrs))\n\t\t\t\treturn false;\n\t\t\t// $capture or $(..capture)\n\t\t\tLNode sub = GetCaptureIdentifier(pattern);\n\t\t\tif (sub != null)\n\t\t\t{\n\t\t\t\tcaptures = captures ?? new MMap<Symbol, LNode>();\n\t\t\t\tAddCapture(captures, sub.Name, candidate);\n\t\t\t\tunmatchedAttrs = VList<LNode>.Empty; // The attrs (if any) were captured\n\t\t\t\treturn true;\n\t\t\t}\n\t\t\tvar kind = candidate.Kind;\n\t\t\tif (kind != pattern.Kind)\n\t\t\t\treturn false;\n", "outputs": ["\t\t\tif (kind == LNodeKind.Id && candidate.Name != pattern.Name)"], "input_length": 2960, "output_length": 12, "length": 2972, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "1283f4628f415264bdef2bc9ff1c65e6e1627c7645584130bf6584a171814c10"}
{"input": "", "context": "# coding=utf-8\n# Author: Nic Wolfe <nic@wolfeden.ca>\n# URL: http://code.google.com/p/sickbeard/\n#\n# This file is part of SickRage.\n#\n# SickRage is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# SickRage is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with SickRage.  If not, see <http://www.gnu.org/licenses/>.\nfrom __future__ import with_statement\nimport datetime\nimport os\nimport re\nimport itertools\nimport urllib\nimport sickbeard\nimport requests\nfrom sickbeard import helpers, classes, logger, db\nfrom sickbeard.common import MULTI_EP_RESULT, SEASON_RESULT, USER_AGENT\nfrom sickbeard import tvcache\nfrom sickbeard import encodingKludge as ek\nfrom sickbeard.exceptions import ex\nfrom sickbeard.name_parser.parser import NameParser, InvalidNameException, InvalidShowException\nfrom sickbeard.common import Quality\nfrom hachoir_parser import createParser\nfrom base64 import b16encode, b32decode\nclass GenericProvider:\n    NZB = \"nzb\"\n    TORRENT = \"torrent\"\n    def __init__(self, name):\n        # these need to be set in the subclass\n        self.providerType = None\n        self.name = name\n        self.proxy = ProviderProxy()\n        self.urls = {}\n        self.url = ''\n        self.show = None\n        self.supportsBacklog = False\n        self.supportsAbsoluteNumbering = False\n        self.anime_only = False\n        self.search_mode = None\n        self.search_fallback = False\n        self.enable_daily = False\n        self.enable_backlog = False\n        self.cache = tvcache.TVCache(self)\n        self.session = requests.session()\n        self.headers = {'User-Agent': USER_AGENT}\n    def getID(self):\n        return GenericProvider.makeID(self.name)\n    @staticmethod\n    def makeID(name):\n        return re.sub(\"[^\\w\\d_]\", \"_\", name.strip().lower())\n    def imageName(self):\n        return self.getID() + '.png'\n    def _checkAuth(self):\n        return True\n    def _doLogin(self):\n        return True\n    def isActive(self):\n        if self.providerType == GenericProvider.NZB and sickbeard.USE_NZBS:\n            return self.isEnabled()\n        elif self.providerType == GenericProvider.TORRENT and sickbeard.USE_TORRENTS:\n            return self.isEnabled()\n        else:\n            return False\n    def isEnabled(self):\n        \"\"\"\n        This should be overridden and should return the config setting eg. sickbeard.MYPROVIDER\n        \"\"\"\n        return False\n    def getResult(self, episodes):\n        \"\"\"\n        Returns a result of the correct type for this provider\n        \"\"\"\n        if self.providerType == GenericProvider.NZB:\n            result = classes.NZBSearchResult(episodes)\n        elif self.providerType == GenericProvider.TORRENT:\n            result = classes.TorrentSearchResult(episodes)\n        else:\n            result = classes.SearchResult(episodes)\n        result.provider = self\n        return result\n    def getURL(self, url, post_data=None, params=None, timeout=30, json=False):\n        \"\"\"\n        By default this is just a simple urlopen call but this method should be overridden\n        for providers with special URL requirements (like cookies)\n        \"\"\"\n        # check for auth\n        if not self._doLogin():\n            return\n        if self.proxy.isEnabled():\n            self.headers.update({'Referer': self.proxy.getProxyURL()})\n        return helpers.getURL(self.proxy._buildURL(url), post_data=post_data, params=params, headers=self.headers, timeout=timeout,\n                              session=self.session, json=json)\n    def downloadResult(self, result):\n        \"\"\"\n        Save the result to disk.\n        \"\"\"\n        # check for auth\n        if not self._doLogin():\n            return False\n        if self.providerType == GenericProvider.TORRENT:\n            try:\n                torrent_hash = re.findall('urn:btih:([\\w]{32,40})', result.url)[0].upper()\n                if len(torrent_hash) == 32:\n                    torrent_hash = b16encode(b32decode(torrent_hash)).lower()\n                if not torrent_hash:\n                    logger.log(\"Unable to extract torrent hash from link: \" + ex(result.url), logger.ERROR)\n                    return False\n                urls = [\n                    'http://torcache.net/torrent/' + torrent_hash + '.torrent',\n                    'http://torrage.com/torrent/' + torrent_hash + '.torrent',\n                    'http://zoink.it/torrent/' + torrent_hash + '.torrent',\n                ]\n            except:\n                urls = [result.url]\n            filename = ek.ek(os.path.join, sickbeard.TORRENT_DIR,\n                             helpers.sanitizeFileName(result.name) + '.' + self.providerType)\n        elif self.providerType == GenericProvider.NZB:\n            urls = [result.url]\n            filename = ek.ek(os.path.join, sickbeard.NZB_DIR,\n                             helpers.sanitizeFileName(result.name) + '.' + self.providerType)\n        else:\n            return\n        for url in urls:\n            if helpers.download_file(url, filename, session=self.session):\n                logger.log(u\"Downloading a result from \" + self.name + \" at \" + url)\n                if self.providerType == GenericProvider.TORRENT:\n                    logger.log(u\"Saved magnet link to \" + filename, logger.INFO)\n                else:\n                    logger.log(u\"Saved result to \" + filename, logger.INFO)\n                if self._verify_download(filename):\n                    return True\n        logger.log(u\"Failed to download result\", logger.WARNING)\n        return False\n    def _verify_download(self, file_name=None):\n        \"\"\"\n        Checks the saved file to see if it was actually valid, if not then consider the download a failure.\n        \"\"\"\n        # primitive verification of torrents, just make sure we didn't get a text file or something\n        if self.providerType == GenericProvider.TORRENT:\n            try:\n                parser = createParser(file_name)\n                if parser:\n                    mime_type = parser._getMimeType()\n                    try:\n                        parser.stream._input.close()\n                    except:\n                        pass\n                    if mime_type == 'application/x-bittorrent':\n                        return True\n            except Exception as e:\n                logger.log(u\"Failed to validate torrent file: \" + ex(e), logger.DEBUG)\n            logger.log(u\"Result is not a valid torrent file\", logger.WARNING)\n            return False\n        return True\n    def searchRSS(self, episodes):\n        return self.cache.findNeededEpisodes(episodes)\n    def getQuality(self, item, anime=False):\n        \"\"\"\n        Figures out the quality of the given RSS item node\n        \n        item: An elementtree.ElementTree element representing the <item> tag of the RSS feed\n        \n        Returns a Quality value obtained from the node's data \n        \"\"\"\n        (title, url) = self._get_title_and_url(item)\n        quality = Quality.sceneQuality(title, anime)\n        return quality\n    def _doSearch(self, search_params, search_mode='eponly', epcount=0, age=0):\n        return []\n    def _get_season_search_strings(self, episode):\n        return []\n    def _get_episode_search_strings(self, eb_obj, add_string=''):\n        return []\n    def _get_title_and_url(self, item):\n        \"\"\"\n        Retrieves the title and URL data from the item XML node\n        item: An elementtree.ElementTree element representing the <item> tag of the RSS feed\n        Returns: A tuple containing two strings representing title and URL respectively\n        \"\"\"\n        title = item.get('title')\n        if title:\n            title = u'' + title.replace(' ', '.')\n        url = item.get('link')\n        if url:\n            url = url.replace('&amp;', '&')\n        return title, url\n    def findSearchResults(self, show, episodes, search_mode, manualSearch=False):\n        self._checkAuth()\n        self.show = show\n        results = {}\n        itemList = []\n        searched_scene_season = None\n        for epObj in episodes:\n            # search cache for episode result\n            cacheResult = self.cache.searchCache(epObj, manualSearch)\n            if cacheResult:\n                if epObj.episode not in results:\n                    results[epObj.episode] = cacheResult\n                else:\n                    results[epObj.episode].extend(cacheResult)\n                # found result, search next episode\n                continue\n            # skip if season already searched\n            if len(episodes) > 1 and searched_scene_season == epObj.scene_season:\n                continue\n            # mark season searched for season pack searches so we can skip later on\n            searched_scene_season = epObj.scene_season\n            if len(episodes) > 1:\n                # get season search results\n                for curString in self._get_season_search_strings(epObj):\n                    itemList += self._doSearch(curString, search_mode, len(episodes))\n            else:\n                # get single episode search results\n                for curString in self._get_episode_search_strings(epObj):\n                    itemList += self._doSearch(curString, 'eponly', len(episodes))\n        # if we found what we needed already from cache then return results and exit\n        if len(results) == len(episodes):\n            return results\n        # sort list by quality\n        if len(itemList):\n            items = {}\n            itemsUnknown = []\n            for item in itemList:\n                quality = self.getQuality(item, anime=show.is_anime)\n                if quality == Quality.UNKNOWN:\n                    itemsUnknown += [item]\n                else:\n                    if quality not in items:\n                        items[quality] = [item]\n                    else:\n                        items[quality].append(item)\n            itemList = list(itertools.chain(*[v for (k, v) in sorted(items.items(), reverse=True)]))\n            itemList += itemsUnknown if itemsUnknown else []\n        # filter results\n        cl = []\n        for item in itemList:\n            (title, url) = self._get_title_and_url(item)\n            # parse the file name\n            try:\n                myParser = NameParser(False, convert=True)\n                parse_result = myParser.parse(title)\n            except InvalidNameException:\n                logger.log(u\"Unable to parse the filename \" + title + \" into a valid episode\", logger.DEBUG)\n                continue\n            except InvalidShowException:\n                logger.log(u\"Unable to parse the filename \" + title + \" into a valid show\", logger.DEBUG)\n                continue\n            showObj = parse_result.show\n            quality = parse_result.quality\n            release_group = parse_result.release_group\n            version = parse_result.version\n            addCacheEntry = False\n            if not (showObj.air_by_date or showObj.sports):\n                if search_mode == 'sponly': \n                    if len(parse_result.episode_numbers):\n                        logger.log(\n                            u\"This is supposed to be a season pack search but the result \" + title + \" is not a valid season pack, skipping it\",\n                            logger.DEBUG)\n                        addCacheEntry = True\n                    if len(parse_result.episode_numbers) and (\n                                    parse_result.season_number not in set([ep.season for ep in episodes]) or not [ep for ep in episodes if\n                                                                                 ep.scene_episode in parse_result.episode_numbers]):\n                        logger.log(\n                            u\"The result \" + title + \" doesn't seem to be a valid episode that we are trying to snatch, ignoring\",\n                            logger.DEBUG)\n                        addCacheEntry = True\n                else:\n                    if not len(parse_result.episode_numbers) and parse_result.season_number and not [ep for ep in\n                                                                                                     episodes if\n                                                                                                     ep.season == parse_result.season_number and ep.episode in parse_result.episode_numbers]:\n                        logger.log(\n                            u\"The result \" + title + \" doesn't seem to be a valid season that we are trying to snatch, ignoring\",\n                            logger.DEBUG)\n                        addCacheEntry = True\n                    elif len(parse_result.episode_numbers) and not [ep for ep in episodes if\n                                                                    ep.season == parse_result.season_number and ep.episode in parse_result.episode_numbers]:\n                        logger.log(\n                            u\"The result \" + title + \" doesn't seem to be a valid episode that we are trying to snatch, ignoring\",\n                            logger.DEBUG)\n                        addCacheEntry = True\n                if not addCacheEntry:\n                    # we just use the existing info for normal searches\n                    actual_season = parse_result.season_number\n                    actual_episodes = parse_result.episode_numbers\n            else:\n                if not (parse_result.is_air_by_date):\n                    logger.log(\n                        u\"This is supposed to be a date search but the result \" + title + \" didn't parse as one, skipping it\",\n                        logger.DEBUG)\n                    addCacheEntry = True\n                else:\n                    airdate = parse_result.air_date.toordinal()\n                    myDB = db.DBConnection()\n                    sql_results = myDB.select(\n                        \"SELECT season, episode FROM tv_episodes WHERE showid = ? AND airdate = ?\",\n                        [showObj.indexerid, airdate])\n                    if len(sql_results) != 1:\n                        logger.log(\n                            u\"Tried to look up the date for the episode \" + title + \" but the database didn't give proper results, skipping it\",\n                            logger.WARNING)\n                        addCacheEntry = True\n                if not addCacheEntry:\n                    actual_season = int(sql_results[0][\"season\"])\n                    actual_episodes = [int(sql_results[0][\"episode\"])]\n            # add parsed result to cache for usage later on\n            if addCacheEntry:\n                logger.log(u\"Adding item from search to cache: \" + title, logger.DEBUG)\n                ci = self.cache._addCacheEntry(title, url, parse_result=parse_result)\n                if ci is not None:\n                    cl.append(ci)\n                continue\n            # make sure we want the episode\n            wantEp = True\n            for epNo in actual_episodes:\n                if not showObj.wantEpisode(actual_season, epNo, quality, manualSearch):\n                    wantEp = False\n                    break\n            if not wantEp:\n                logger.log(\n                    u\"Ignoring result \" + title + \" because we don't want an episode that is \" +\n                    Quality.qualityStrings[\n                        quality], logger.DEBUG)\n                continue\n            logger.log(u\"Found result \" + title + \" at \" + url, logger.DEBUG)\n            # make a result object\n            epObj = []\n            for curEp in actual_episodes:\n                epObj.append(showObj.getEpisode(actual_season, curEp))\n            result = self.getResult(epObj)\n            result.show = showObj\n            result.url = url\n            result.name = title\n            result.quality = quality\n            result.release_group = release_group\n            result.content = None\n            result.version = version\n            if len(epObj) == 1:\n                epNum = epObj[0].episode\n                logger.log(u\"Single episode result.\", logger.DEBUG)\n            elif len(epObj) > 1:\n                epNum = MULTI_EP_RESULT\n                logger.log(u\"Separating multi-episode result to check for later - result contains episodes: \" + str(\n                    parse_result.episode_numbers), logger.DEBUG)\n            elif len(epObj) == 0:\n                epNum = SEASON_RESULT\n                logger.log(u\"Separating full season result to check for later\", logger.DEBUG)\n            if epNum not in results:\n                results[epNum] = [result]\n            else:\n                results[epNum].append(result)\n        # check if we have items to add to cache\n        if len(cl) > 0:\n            myDB = self.cache._getDB()\n            myDB.mass_action(cl)\n        return results\n    def findPropers(self, search_date=None):\n        results = self.cache.listPropers(search_date)\n        return [classes.Proper(x['name'], x['url'], datetime.datetime.fromtimestamp(x['time']), self.show) for x in\n                results]\n    def seedRatio(self):\n        '''\n        Provider should override this value if custom seed ratio enabled\n        It should return the value of the provider seed ratio\n        '''\n        return ''\nclass NZBProvider(GenericProvider):\n    def __init__(self, name):\n        GenericProvider.__init__(self, name)\n        self.providerType = GenericProvider.NZB\nclass TorrentProvider(GenericProvider):\n    def __init__(self, name):\n        GenericProvider.__init__(self, name)\n        self.providerType = GenericProvider.TORRENT\nclass ProviderProxy:\n    def __init__(self):\n        self.Type = 'GlypeProxy'\n        self.param = 'browse.php?u='\n        self.option = '&b=32&f=norefer'\n        self.enabled = False\n        self.url = None\n        self.urls = {\n            'getprivate.eu (NL)': 'http://getprivate.eu/',\n            'hideme.nl (NL)': 'http://hideme.nl/',\n            'proxite.eu (DE)': 'http://proxite.eu/',\n            'interproxy.net (EU)': 'http://interproxy.net/',\n        }\n    def isEnabled(self):\n        \"\"\" Return True if we Choose to call TPB via Proxy \"\"\"\n        return self.enabled\n    def getProxyURL(self):\n        \"\"\" Return the Proxy URL Choosen via Provider Setting \"\"\"\n        return str(self.url)\n    def _buildURL(self, url):\n        \"\"\" Return the Proxyfied URL of the page \"\"\"\n        if self.isEnabled():\n            url = self.getProxyURL() + self.param + urllib.quote_plus(url) + self.option\n            logger.log(u\"Proxified URL: \" + url, logger.DEBUG)\n        return url\n    def _buildRE(self, regx):\n        \"\"\" Return the Proxyfied RE string \"\"\"\n        if self.isEnabled():\n            regx = re.sub('//1', self.option, regx).replace('&', '&amp;')\n", "outputs": ["            logger.log(u\"Proxified REGEX: \" + regx, logger.DEBUG)"], "input_length": 2780, "output_length": 13, "length": 2793, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "963af646c6b0130fb4189e1c3ab731b0d8c04b94b7dc038b17aa8887771302cf"}
{"input": "", "context": "// created on 10/12/2002 at 20:37\nusing System;\nusing System.Collections.Generic;\nusing System.Runtime.InteropServices;\nusing xServer.Core.NAudio.Wave.MmeInterop;\nnamespace xServer.Core.NAudio.Mixer \n{\n    /// <summary>\n    /// Represents a mixer line (source or destination)\n    /// </summary>\n    public class MixerLine \n    {\n        private MixerInterop.MIXERLINE mixerLine;\n        private IntPtr mixerHandle;\n        private MixerFlags mixerHandleType;\n        /// <summary>\n        /// Creates a new mixer destination\n        /// </summary>\n        /// <param name=\"mixerHandle\">Mixer Handle</param>\n        /// <param name=\"destinationIndex\">Destination Index</param>\n        /// <param name=\"mixerHandleType\">Mixer Handle Type</param>\n        public MixerLine(IntPtr mixerHandle, int destinationIndex, MixerFlags mixerHandleType) \n        {\n            this.mixerHandle = mixerHandle;\n            this.mixerHandleType = mixerHandleType;\n            mixerLine = new MixerInterop.MIXERLINE();\n            mixerLine.cbStruct = Marshal.SizeOf(mixerLine);\n            mixerLine.dwDestination = destinationIndex;\n            MmException.Try(MixerInterop.mixerGetLineInfo(mixerHandle, ref mixerLine, mixerHandleType | MixerFlags.GetLineInfoOfDestination), \"mixerGetLineInfo\");\n        }\n        /// <summary>\n        /// Creates a new Mixer Source For a Specified Source\n        /// </summary>\n        /// <param name=\"mixerHandle\">Mixer Handle</param>\n        /// <param name=\"destinationIndex\">Destination Index</param>\n        /// <param name=\"sourceIndex\">Source Index</param>\n        /// <param name=\"mixerHandleType\">Flag indicating the meaning of mixerHandle</param>\n        public MixerLine(IntPtr mixerHandle, int destinationIndex, int sourceIndex, MixerFlags mixerHandleType) \n        {\n            this.mixerHandle = mixerHandle;\n            this.mixerHandleType = mixerHandleType;\n            mixerLine = new MixerInterop.MIXERLINE();\n            mixerLine.cbStruct = Marshal.SizeOf(mixerLine);\n            mixerLine.dwDestination = destinationIndex;\n            mixerLine.dwSource = sourceIndex;\n            MmException.Try(MixerInterop.mixerGetLineInfo(mixerHandle, ref mixerLine, mixerHandleType | MixerFlags.GetLineInfoOfSource), \"mixerGetLineInfo\");\n        }\n        /// <summary>\n        /// Creates a new Mixer Source\n        /// </summary>\n        /// <param name=\"waveInDevice\">Wave In Device</param>\n        public static int GetMixerIdForWaveIn(int waveInDevice)\n        {\n            int mixerId = -1;\n            MmException.Try(MixerInterop.mixerGetID((IntPtr)waveInDevice, out mixerId, MixerFlags.WaveIn), \"mixerGetID\");\n            return mixerId;\n        }\n        /// <summary>\n        /// Mixer Line Name\n        /// </summary>\n        public String Name \n        {\n            get \n            {\n                return mixerLine.szName;\n            }\n        }\n        \n        /// <summary>\n        /// Mixer Line short name\n        /// </summary>\n        public String ShortName \n        {\n            get \n            {\n                return mixerLine.szShortName;\n            }\n        }\n        /// <summary>\n        /// The line ID\n        /// </summary>\n        public int LineId\n        {\n            get\n            {\n                return mixerLine.dwLineID;\n            }\n        }\n        /// <summary>\n        /// Component Type\n        /// </summary>\n        public MixerLineComponentType ComponentType\n        {\n            get\n            {\n                return mixerLine.dwComponentType;\n            }\n        }\n        /// <summary>\n        /// Mixer destination type description\n        /// </summary>\n        public String TypeDescription \n        {\n            get \n            {\n                switch (mixerLine.dwComponentType)\n                {\n                    // destinations\n                    case MixerLineComponentType.DestinationUndefined:\n                        return \"Undefined Destination\";\n                    case MixerLineComponentType.DestinationDigital:\n                        return \"Digital Destination\";\n                    case MixerLineComponentType.DestinationLine:\n                        return \"Line Level Destination\";\n                    case MixerLineComponentType.DestinationMonitor:\n                        return \"Monitor Destination\";\n                    case MixerLineComponentType.DestinationSpeakers:\n                        return \"Speakers Destination\";\n                    case MixerLineComponentType.DestinationHeadphones:\n                        return \"Headphones Destination\";\n                    case MixerLineComponentType.DestinationTelephone:\n                        return \"Telephone Destination\";\n                    case MixerLineComponentType.DestinationWaveIn:\n                        return \"Wave Input Destination\";\n                    case MixerLineComponentType.DestinationVoiceIn:\n                        return \"Voice Recognition Destination\";\n                    // sources\n                    case MixerLineComponentType.SourceUndefined:\n                        return \"Undefined Source\";\n                    case MixerLineComponentType.SourceDigital:\n                        return \"Digital Source\";\n                    case MixerLineComponentType.SourceLine:\n                        return \"Line Level Source\";\n                    case MixerLineComponentType.SourceMicrophone:\n                        return \"Microphone Source\";\n                    case MixerLineComponentType.SourceSynthesizer:\n                        return \"Synthesizer Source\";\n                    case MixerLineComponentType.SourceCompactDisc:\n                        return \"Compact Disk Source\";\n                    case MixerLineComponentType.SourceTelephone:\n                        return \"Telephone Source\";\n                    case MixerLineComponentType.SourcePcSpeaker:\n                        return \"PC Speaker Source\";\n                    case MixerLineComponentType.SourceWaveOut:\n                        return \"Wave Out Source\";\n                    case MixerLineComponentType.SourceAuxiliary:\n                        return \"Auxiliary Source\";\n                    case MixerLineComponentType.SourceAnalog:\n                        return \"Analog Source\";\n                    default:\n                        return \"Invalid Component Type\";\n                }\n            }\t\t\t\t\n        }\n        \n        /// <summary>\n        /// Number of channels\n        /// </summary>\n        public int Channels \n        {\n            get \n            {\n                return mixerLine.cChannels;\n            }\n        }\n        \n        /// <summary>\n        /// Number of sources\n        /// </summary>\n        public int SourceCount \n        {\n            get \n            {\n                return mixerLine.cConnections;\n            }\n        }\n        \n        /// <summary>\n        /// Number of controls\n        /// </summary>\n        public int ControlsCount \n        {\n            get \n            {\n                return mixerLine.cControls;\n            }\n        }\n        /// <summary>\n        /// Is this destination active\n        /// </summary>\n        public bool IsActive\n        {\n            get\n            {\n                return (mixerLine.fdwLine & MixerInterop.MIXERLINE_LINEF.MIXERLINE_LINEF_ACTIVE) != 0;\n            }\n        }\n        /// <summary>\n        /// Is this destination disconnected\n        /// </summary>\n        public bool IsDisconnected\n        {\n            get\n            {\n                return (mixerLine.fdwLine & MixerInterop.MIXERLINE_LINEF.MIXERLINE_LINEF_DISCONNECTED) != 0;\n            }\n        }\n        /// <summary>\n        /// Is this destination a source\n        /// </summary>\n        public bool IsSource\n        {\n            get\n            {\n                return (mixerLine.fdwLine & MixerInterop.MIXERLINE_LINEF.MIXERLINE_LINEF_SOURCE) != 0;\n            }\n        }\n        /// <summary>\n        /// Gets the specified source\n        /// </summary>\n        public MixerLine GetSource(int sourceIndex) \n        {\n            if(sourceIndex < 0 || sourceIndex >= SourceCount) \n            {\n                throw new ArgumentOutOfRangeException(\"sourceIndex\");\n            }\n            return new MixerLine(mixerHandle, mixerLine.dwDestination, sourceIndex, this.mixerHandleType);\t\t\t\n        }\n        /// <summary>\n        /// Enumerator for the controls on this Mixer Limne\n        /// </summary>\n        public IEnumerable<MixerControl> Controls\n        {\n            get\n            {\n                return MixerControl.GetMixerControls(this.mixerHandle, this, this.mixerHandleType);\n            }\n        }\n        /// <summary>\n        /// Enumerator for the sources on this Mixer Line\n        /// </summary>\n        public IEnumerable<MixerLine> Sources\n        {\n            get\n            {\n                for (int source = 0; source < SourceCount; source++)\n                {\n                    yield return GetSource(source);\n                }\n            }\n        }\n        /// <summary>\n        /// The name of the target output device\n        /// </summary>\n        public string TargetName\n        {\n            get\n            {\n                return mixerLine.szPname;\n            }\n        }\n        /// <summary>\n        /// Describes this Mixer Line (for diagnostic purposes)\n        /// </summary>\n        public override string ToString()\n        {\n", "outputs": ["            return String.Format(\"{0} {1} ({2} controls, ID={3})\", "], "input_length": 1053, "output_length": 23, "length": 1076, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "fe5be62cc3a384a8ebe262cda7cfa0528da00ec7e15b06564856ce9ecfb45199"}
{"input": "", "context": "package fr.inria.arles.yarta.desktop.library.util;\nimport java.io.BufferedReader;\nimport java.io.File;\nimport java.io.FileInputStream;\nimport java.io.FileOutputStream;\nimport java.io.FileReader;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.OutputStream;\nimport java.io.PrintWriter;\nimport java.io.StringWriter;\nimport java.net.URL;\nimport java.net.URLConnection;\nimport javax.swing.JOptionPane;\nimport fr.inria.arles.yarta.desktop.library.DownloaderDialog;\nimport fr.inria.arles.yarta.desktop.library.RMIUtil;\nimport fr.inria.arles.yarta.desktop.library.Service;\n/**\n * Helper class which permits (un)installing & updating the application.\n */\npublic class Installer {\n\tpublic static final String InstallPath = System.getProperty(\"user.home\")\n\t\t\t+ \"/.yarta/\";\n\tpublic static final String FilesPath = InstallPath + \"res/\";\n\tprivate static final String[] files = { \"mse-1.2.rdf\", \"policies\" };\n\tprivate String currentJarPath;\n\tprivate String installedJarPath;\n\tprivate Exception error;\n\tpublic Installer() {\n\t\tString jarFile = System.getProperty(\"java.class.path\");\n\t\tif (!jarFile.endsWith(\"jar\")) {\n\t\t\tjarFile = \"yarta.jar\";\n\t\t}\n\t\tcurrentJarPath = new File(jarFile).getAbsolutePath();\n\t\tinstalledJarPath = InstallPath + \"yarta.jar\";\n\t}\n\t/**\n\t * Checks whether Yarta is installed on the current machine.\n\t * \n\t * @return\n\t */\n\tpublic boolean isInstalled() {\n\t\treturn checkFilesConsistency();\n\t}\n\t/**\n\t * Checks if Yarta Service is running.\n\t * \n\t * @return\n\t */\n\tpublic boolean isRunning() {\n\t\tService service = RMIUtil.getObject(Service.Name);\n\t\tboolean running = service != null;\n\t\tservice = null;\n\t\treturn running;\n\t}\n\t/**\n\t * Runs a jar file with the specified arguments;\n\t * \n\t * @param jarPath\n\t * @param args\n\t * @return\n\t */\n\tprivate Process runJar(String jarPath, String... args) {\n\t\tString command = \"java -jar \" + jarPath;\n\t\tif (isWindows()) {\n\t\t\tcommand = \"javaw -jar \" + jarPath;\n\t\t}\n\t\tfor (String arg : args) {\n\t\t\tcommand += \" \" + arg;\n\t\t}\n\t\ttry {\n\t\t\treturn Runtime.getRuntime().exec(command);\n\t\t} catch (Exception ex) {\n\t\t}\n\t\treturn null;\n\t}\n\t/**\n\t * Launches the application.\n\t * \n\t * @return\n\t */\n\tpublic boolean launchApp() {\n\t\treturn runJar(installedJarPath) != null;\n\t}\n\t/**\n\t * Returns the timestamp of yarta.jar from Internet.\n\t * \n\t * @return\n\t */\n\tprivate long getLastModifiedRemote() {\n\t\tlong lastModified = 0;\n\t\ttry {\n\t\t\tURL url = new URL(Strings.DownloaderYartaLink);\n\t\t\tURLConnection conn = url.openConnection();\n\t\t\tlastModified = conn.getLastModified();\n\t\t} catch (Exception ex) {\n\t\t}\n\t\treturn lastModified;\n\t}\n\t/**\n\t * Checks for updates, and if there are any, asks users and update. Returns\n\t * false otherwise.\n\t * \n\t * @return true/false\n\t */\n\tpublic boolean checkAndUpdate() {\n\t\tlong lastModifiedLocal = new File(installedJarPath).lastModified();\n\t\tlong lastModifiedRemote = getLastModifiedRemote();\n\t\tif (lastModifiedRemote > lastModifiedLocal) {\n\t\t\tint option = 0;\n\t\t\ttry {\n\t\t\t\toption = JOptionPane.showConfirmDialog(null,\n\t\t\t\t\t\tStrings.InstallerUpdatePrompt,\n\t\t\t\t\t\tStrings.InstallerUpdateTitle,\n\t\t\t\t\t\tJOptionPane.OK_CANCEL_OPTION,\n\t\t\t\t\t\tJOptionPane.INFORMATION_MESSAGE);\n\t\t\t} catch (Exception ex) {\n\t\t\t\t// system does not have UI\n\t\t\t\toption = JOptionPane.OK_OPTION;\n\t\t\t}\n\t\t\tif (option == JOptionPane.OK_OPTION) {\n\t\t\t\tString downloadedJarFile = performDownload();\n\t\t\t\tif (downloadedJarFile != null) {\n\t\t\t\t\treturn performInstallerLaunch(downloadedJarFile);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}\n\tpublic boolean launchService() {\n\t\treturn runJar(installedJarPath, \"/start\") != null;\n\t}\n\tpublic boolean stopService() {\n\t\tif (!new File(installedJarPath).exists()) {\n\t\t\treturn true;\n\t\t}\n\t\ttry {\n\t\t\tProcess process = runJar(installedJarPath, \"/stop\");\n\t\t\tprocess.waitFor();\n\t\t\treturn true;\n\t\t} catch (Exception ex) {\n\t\t\treturn false;\n\t\t}\n\t}\n\tpublic boolean install() {\n\t\tboolean hasUI = true;\n\t\ttry {\n\t\t\tint selection = JOptionPane.showConfirmDialog(null,\n\t\t\t\t\tStrings.InstallerPrompt, Strings.InstallerPromptTitle,\n\t\t\t\t\tJOptionPane.OK_CANCEL_OPTION,\n\t\t\t\t\tJOptionPane.INFORMATION_MESSAGE);\n\t\t\tif (selection == JOptionPane.OK_OPTION) {\n\t\t\t\treturn performInstallation();\n\t\t\t}\n\t\t} catch (Exception ex) {\n\t\t\thasUI = false;\n\t\t}\n\t\tif (!hasUI) {\n\t\t\treturn performInstallation();\n\t\t}\n\t\treturn false;\n\t}\n\t/**\n\t * This should download and install Yarta.\n\t * \n\t * When the function returns true Yarta will be installed.\n\t * \n\t * @return true/false\n\t */\n\tpublic boolean downloadAndInstall() {\n\t\tint selection = JOptionPane.showConfirmDialog(null,\n\t\t\t\tStrings.InstallerDownloadPrompt,\n\t\t\t\tStrings.InstallerDownloadTitle, JOptionPane.OK_CANCEL_OPTION,\n\t\t\t\tJOptionPane.INFORMATION_MESSAGE);\n\t\tif (selection == JOptionPane.OK_OPTION) {\n", "outputs": ["\t\t\tString downloadedJarFile = performDownload();"], "input_length": 808, "output_length": 7, "length": 815, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "23f49d75f5e2241a26905bca0f672151b22e4d0dd187df3ee4fbcf4772bd1277"}
{"input": "", "context": "import sys\nimport os\nfrom gm_base.json_data import *\nimport gm_base.geometry_files.layers_io as lfc\nclass LayerType(IntEnum):\n    \"\"\"Layer type\"\"\"\n    stratum = 0\n    fracture = 1\n    shadow = 2\n    \nclass TopologyType(IntEnum):\n    given = 0\n    interpolated = 1\nclass RegionDim(IntEnum):\n    invalid = -2\n    none = -1\n    point = 0\n    well = 1\n    fracture = 2\n    bulk = 3\n    \nclass TopologyDim(IntEnum):\n    invalid = -1\n    node = 0\n    segment = 1\n    polygon = 2\nclass Curve(JsonData):\n    def __init__(self, config={}):\n        super().__init__(config)\nclass SurfaceApproximation(JsonData):\n    \"\"\"\n    Serialization class for Z_Surface.\n    \"\"\"\n    def __init__(self, config={}):\n        self.u_knots = [float]\n        self.v_knots = [float]\n        self.u_degree = 2\n        self.v_degree = 2\n        self.rational = False\n        self.poles = [ [ [float] ] ]\n        self.orig_quad = 4*(2*(float,),)\n        self.xy_map = [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0]]\n        self.z_map = [1.0, 0.0]\n        super().__init__(config)\nclass Surface(JsonData):\n    \n    def __init__(self, config={}):\n        self.grid_file = \"\"\n        \"\"\"File with approximated points (grid of 3D points). None for plane\"\"\"\n        self.file_skip_lines = 0\n        \"\"\"Number of header lines to skip. \"\"\"\n        self.file_delimiter = ' '\n        \"\"\" Delimiter of data fields on a single line.\"\"\"\n        self.name = \"\"\n        \"\"\"Surface name\"\"\"\n        self.approximation = ClassFactory(SurfaceApproximation)\n        \"\"\"Serialization of the  Z_Surface.\"\"\"\n        self.regularization = 1.0\n        \"\"\"Regularization weight.\"\"\"\n        self.approx_error = 0.0\n        \"\"\"L-inf error of aproximation\"\"\"\n        super().__init__(config)\n        \n    # @staticmethod\n    # def make_surface():\n    #     surf = Surface()\n    #     surf.approximation = None\n    #     return surf\n    @property\n    def quad(self):\n        return self.approximation.quad\n    @classmethod\n    def convert(cls, other):\n        new_surf = lfc.convert_json_data(sys.modules[__name__], other, cls)\n        new_surf.approx_error = 0.0\n        new_surf.regularization = 1.0\n        new_surf.file_skip_lines = 0\n        new_surf.file_delimiter = ' '\n        return new_surf\nclass Interface(JsonData):\n    \n    def __init__(self, config={}):\n        self.surface_id = int\n        \"\"\"Surface index\"\"\"\n        self.transform_z = 2*(float,)\n        \"\"\"Transformation in Z direction (scale and shift).\"\"\"\n        self.elevation = float\n        \"\"\" Representative Z coord of the surface.\"\"\"\n        # Grid polygon should be in SurfaceApproximation, however\n        # what for the case of planar interfaces without surface reference.\n        #self.grid_polygon = 4*(2*(float,))\n        \"\"\"Vertices of the boundary polygon of the grid.\"\"\"\n        super().__init__(config)\n    def __eq__(self, other):\n        \"\"\"operators for comparation\"\"\"\n        return self.elevation == other.elevation \\\n            and self.transform_z == other.transform_z \\\n            and self.surface_id != other.surface_id\nclass Segment(JsonData):\n    \"\"\"Line object\"\"\"\n    def __init__(self, config={}):\n        self.node_ids  = ( int, int )\n        \"\"\"First point index\"\"\"\n        \"\"\"Second point index\"\"\"\n        self.interface_id = None\n        \"\"\"Interface index\"\"\"\n        super().__init__(config)\n    def __eq__(self, other):\n        return self.node_ids == other.node.ids \\\n            and self.surface_id == other.surface_id\nclass Polygon(JsonData):\n    \"\"\"Polygon object\"\"\"\n    def __init__(self, config={}):\n        self.segment_ids = [ int ]\n        \"\"\"List of segments index of the outer wire.\"\"\"\n        self.holes = []\n        \"\"\"List of lists of segments of hole's wires\"\"\"\n        self.free_points = [ int ]\n        \"\"\"List of free points in polygon.\"\"\"\n        self.interface_id = None\n        \"\"\"Interface index\"\"\"\n        super().__init__(config)\n    def __eq__(self, other):\n        return self.segment_ids == other.segment_ids \\\n            and self.holes == other.holes \\\n            and self.free_points == other.free_points \\\n            and self.surface_id == other.surface_id\nclass Topology(JsonData):\n    \"\"\"Topological presentation of geometry objects\"\"\"\n    def __init__(self, config={}):\n        self.segments = [ ClassFactory(Segment) ]\n        \"\"\"List of topology segments (line)\"\"\"\n        self.polygons = [ ClassFactory(Polygon) ]\n        \"\"\"List of topology polygons\"\"\"\n        super().__init__(config)\n    def __eq__(self, other):\n        return self.segments == other.segments \\\n            and self.polygons == other.polygons \\\nclass NodeSet(JsonData):\n    \"\"\"Set of point (nodes) with topology\"\"\"\n    def __init__(self, config={}):\n        self.topology_id = int\n        \"\"\"Topology index\"\"\"\n        self.nodes = [ (float, float) ]\n        \"\"\"list of Nodes\"\"\"\n        self.linked_node_set_id = None\n        \"\"\"node_set_idx of pair interface node set or None\"\"\"\n        self.linked_node_ids = [ ]\n        \"\"\"List of node IDs that match node ids in other nodesets on the same interface. I.e. arbitrary number of nodesets can be linkedIf linked_node_set is not None there is list od pair indexes of nodes or none\n        if node has not pair\"\"\"\n        super().__init__(config)\n    def reset(self):\n        \"\"\"Reset node set\"\"\"\n        self.nodes = []\nclass InterfaceNodeSet(JsonData):\n    \"\"\"Node set in space for transformation(x,y) ->(u,v). \n    Only for GL\"\"\"\n    _not_serialized_attrs_ = ['interface_type']\n    def __init__(self, config={}):\n        self.nodeset_id = int\n        \"\"\"Node set index\"\"\"\n        self.interface_id = int\n        \"\"\"Interface index\"\"\"\n        super().__init__(config)\n        self.interface_type = TopologyType.given\nclass InterpolatedNodeSet(JsonData):\n    \"\"\"Two node set with same Topology in space for transformation(x,y) ->(u,v).\n    If both node sets is same, topology is vertical    \n    Only for GL\"\"\"\n    _not_serialized_attrs_ = ['interface_type']\n    def __init__(self, config={}):\n        self.surf_nodesets = ( ClassFactory([InterfaceNodeSet]), ClassFactory([InterfaceNodeSet]) )\n        \"\"\"Top and bottom node set index\"\"\"\n        self.interface_id = int\n        \"\"\"Interface index\"\"\"\n        super().__init__(config)\n        self.interface_type = TopologyType.interpolated\nclass Region(JsonData):\n    \"\"\"Description of disjunct geometri area sorte by dimension (dim=1 well, dim=2 fracture, dim=3 bulk). \"\"\"\n    \n    def __init__(self, config={}):\n        self.color = \"\"\n        \"\"\"8-bite region color\"\"\"\n        self.name = \"\"\n        \"\"\"region name\"\"\"\n        self.dim = RegionDim.invalid\n        \"\"\" Real dimension of the region. (0,1,2,3)\"\"\"\n        self.topo_dim = TopologyDim.invalid\n        \"\"\"For backward compatibility. Dimension (0,1,2) in Stratum layer: node, segment, polygon\"\"\"\n        self.boundary = False\n        \"\"\"Is boundary region\"\"\"\n        self.not_used = False\n        \"\"\"is used \"\"\"\n        self.mesh_step = 0.0\n        \"\"\"mesh step - 0.0 is automatic choice\"\"\"\n        self.brep_shape_ids = [ ]\n        \"\"\"List of shape indexes - in BREP geometry \"\"\"\n        super().__init__(config)\n    def fix_dim(self, extruded):\n        if self.topo_dim != TopologyDim.invalid:\n            # old format\n            if self.dim == RegionDim.invalid:\n                self.dim = RegionDim(self.topo_dim + extruded)\n            if self.not_used:\n                return\n            assert self.dim.value == self.topo_dim + extruded, \"Region {} , dimension mismatch.\"\n        assert self.dim != RegionDim.invalid\nclass GeoLayer(JsonData):\n    \"\"\"Geological layers\"\"\"\n    _not_serialized_attrs_ = ['layer_type']\n    def __init__(self, config={}):\n        self.name =  \"\"\n        \"\"\"Layer Name\"\"\"\n        self.top =  ClassFactory( [InterfaceNodeSet, InterpolatedNodeSet] )\n        \"\"\"Accoding topology type interface node set or interpolated node set\"\"\"\n        \n        # assign regions to every topology object\n        self.polygon_region_ids = [ int ]\n        self.segment_region_ids = [ int ]\n        self.node_region_ids = [ int ]\n        super().__init__(config)\n        self.layer_type = LayerType.shadow\n    def fix_region_dim(self, regions):\n        extruded = (self.layer_type == LayerType.stratum)\n        for reg_list in  [self.polygon_region_ids, self.segment_region_ids, self.node_region_ids]:\n            for reg_idx in reg_list:\n                if reg_idx>0:\n                    reg = regions[reg_idx]\n                    reg.fix_dim(extruded)\n                \n    def fix_region_id(self):\n        for reg_list in  [self.polygon_region_ids, self.segment_region_ids, self.node_region_ids]:\n            for i in range(0, len(reg_list)):\n                if reg_list[i]>2:\n                    reg_list[i] -= 2\n                else:\n                    reg_list[i] = 0\nclass FractureLayer(GeoLayer):\n", "outputs": ["    _not_serialized_attrs_ = ['layer_type', 'top_type']"], "input_length": 1659, "output_length": 9, "length": 1668, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "cc5121bb9c4c27ebbaf936f8c91972beaf086ab13ba0b1d478cf2463528a6742"}
{"input": "", "context": "#!/usr/bin/python\n# -*- coding: utf-8 -*-\n# Copyright: (c) 2012, Dane Summers <dsummers@pinedesk.biz>\n# Copyright: (c) 2013, Mike Grozak  <mike.grozak@gmail.com>\n# Copyright: (c) 2013, Patrick Callahan <pmc@patrickcallahan.com>\n# Copyright: (c) 2015, Evan Kaufman <evan@digitalflophouse.com>\n# Copyright: (c) 2015, Luca Berruti <nadirio@gmail.com>\n# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)\nfrom __future__ import absolute_import, division, print_function\n__metaclass__ = type\nANSIBLE_METADATA = {'metadata_version': '1.1',\n                    'status': ['preview'],\n                    'supported_by': 'community'}\nDOCUMENTATION = r'''\n---\nmodule: cron\nshort_description: Manage cron.d and crontab entries\ndescription:\n  - Use this module to manage crontab and environment variables entries. This module allows\n    you to create environment variables and named crontab entries, update, or delete them.\n  - 'When crontab jobs are managed: the module includes one line with the description of the\n    crontab entry C(\"#Ansible: <name>\") corresponding to the \"name\" passed to the module,\n    which is used by future ansible/module calls to find/check the state. The \"name\"\n    parameter should be unique, and changing the \"name\" value will result in a new cron\n    task being created (or a different one being removed).'\n  - When environment variables are managed, no comment line is added, but, when the module\n    needs to find/check the state, it uses the \"name\" parameter to find the environment\n    variable definition line.\n  - When using symbols such as %, they must be properly escaped.\nversion_added: \"0.9\"\noptions:\n  name:\n    description:\n      - Description of a crontab entry or, if env is set, the name of environment variable.\n      - Required if C(state=absent).\n      - Note that if name is not set and C(state=present), then a\n        new crontab entry will always be created, regardless of existing ones.\n      - This parameter will always be required in future releases.\n    type: str\n  user:\n    description:\n      - The specific user whose crontab should be modified.\n      - When unset, this parameter defaults to using C(root).\n    type: str\n  job:\n    description:\n      - The command to execute or, if env is set, the value of environment variable.\n      - The command should not contain line breaks.\n      - Required if C(state=present).\n    type: str\n    aliases: [ value ]\n  state:\n    description:\n      - Whether to ensure the job or environment variable is present or absent.\n    type: str\n    choices: [ absent, present ]\n    default: present\n  cron_file:\n    description:\n      - If specified, uses this file instead of an individual user's crontab.\n      - If this is a relative path, it is interpreted with respect to I(/etc/cron.d).\n      - If it is absolute, it will typically be I(/etc/crontab).\n      - Many linux distros expect (and some require) the filename portion to consist solely\n        of upper- and lower-case letters, digits, underscores, and hyphens.\n      - To use the C(cron_file) parameter you must specify the C(user) as well.\n    type: str\n  backup:\n    description:\n      - If set, create a backup of the crontab before it is modified.\n        The location of the backup is returned in the C(backup_file) variable by this module.\n    type: bool\n    default: no\n  minute:\n    description:\n      - Minute when the job should run ( 0-59, *, */2, etc )\n    type: str\n    default: \"*\"\n  hour:\n    description:\n      - Hour when the job should run ( 0-23, *, */2, etc )\n    type: str\n    default: \"*\"\n  day:\n    description:\n      - Day of the month the job should run ( 1-31, *, */2, etc )\n    type: str\n    default: \"*\"\n    aliases: [ dom ]\n  month:\n    description:\n      - Month of the year the job should run ( 1-12, *, */2, etc )\n    type: str\n    default: \"*\"\n  weekday:\n    description:\n      - Day of the week that the job should run ( 0-6 for Sunday-Saturday, *, etc )\n    type: str\n    default: \"*\"\n    aliases: [ dow ]\n  reboot:\n    description:\n      - If the job should be run at reboot. This option is deprecated. Users should use special_time.\n    version_added: \"1.0\"\n    type: bool\n    default: no\n  special_time:\n    description:\n      - Special time specification nickname.\n    type: str\n    choices: [ annually, daily, hourly, monthly, reboot, weekly, yearly ]\n    version_added: \"1.3\"\n  disabled:\n    description:\n      - If the job should be disabled (commented out) in the crontab.\n      - Only has effect if C(state=present).\n    type: bool\n    default: no\n    version_added: \"2.0\"\n  env:\n    description:\n      - If set, manages a crontab's environment variable.\n      - New variables are added on top of crontab.\n      - C(name) and C(value) parameters are the name and the value of environment variable.\n    type: bool\n    default: no\n    version_added: \"2.1\"\n  insertafter:\n    description:\n      - Used with C(state=present) and C(env).\n      - If specified, the environment variable will be inserted after the declaration of specified environment variable.\n    type: str\n    version_added: \"2.1\"\n  insertbefore:\n    description:\n      - Used with C(state=present) and C(env).\n      - If specified, the environment variable will be inserted before the declaration of specified environment variable.\n    type: str\n    version_added: \"2.1\"\nrequirements:\n  - cron (or cronie on CentOS)\nauthor:\n    - Dane Summers (@dsummersl)\n    - Mike Grozak (@rhaido)\n    - Patrick Callahan (@dirtyharrycallahan)\n    - Evan Kaufman (@EvanK)\n    - Luca Berruti (@lberruti)\n'''\nEXAMPLES = r'''\n- name: Ensure a job that runs at 2 and 5 exists. Creates an entry like \"0 5,2 * * ls -alh > /dev/null\"\n  cron:\n    name: \"check dirs\"\n    minute: \"0\"\n    hour: \"5,2\"\n    job: \"ls -alh > /dev/null\"\n- name: 'Ensure an old job is no longer present. Removes any job that is prefixed by \"#Ansible: an old job\" from the crontab'\n  cron:\n    name: \"an old job\"\n    state: absent\n- name: Creates an entry like \"@reboot /some/job.sh\"\n  cron:\n    name: \"a job for reboot\"\n    special_time: reboot\n    job: \"/some/job.sh\"\n- name: Creates an entry like \"PATH=/opt/bin\" on top of crontab\n  cron:\n    name: PATH\n    env: yes\n    job: /opt/bin\n- name: Creates an entry like \"APP_HOME=/srv/app\" and insert it after PATH declaration\n  cron:\n    name: APP_HOME\n    env: yes\n    job: /srv/app\n    insertafter: PATH\n- name: Creates a cron file under /etc/cron.d\n  cron:\n    name: yum autoupdate\n    weekday: \"2\"\n    minute: \"0\"\n    hour: \"12\"\n    user: root\n    job: \"YUMINTERACTIVE=0 /usr/sbin/yum-autoupdate\"\n    cron_file: ansible_yum-autoupdate\n- name: Removes a cron file from under /etc/cron.d\n  cron:\n    name: \"yum autoupdate\"\n    cron_file: ansible_yum-autoupdate\n    state: absent\n- name: Removes \"APP_HOME\" environment variable from crontab\n  cron:\n    name: APP_HOME\n    env: yes\n    state: absent\n'''\nimport os\nimport platform\nimport pwd\nimport re\nimport sys\nimport tempfile\nfrom ansible.module_utils.basic import AnsibleModule\nfrom ansible.module_utils.six.moves import shlex_quote\nclass CronTabError(Exception):\n    pass\nclass CronTab(object):\n    \"\"\"\n        CronTab object to write time based crontab file\n        user      - the user of the crontab (defaults to root)\n        cron_file - a cron file under /etc/cron.d, or an absolute path\n    \"\"\"\n    def __init__(self, module, user=None, cron_file=None):\n        self.module = module\n        self.user = user\n        self.root = (os.getuid() == 0)\n        self.lines = None\n        self.ansible = \"#Ansible: \"\n        self.existing = ''\n        self.cron_cmd = self.module.get_bin_path('crontab', required=True)\n        if cron_file:\n            if os.path.isabs(cron_file):\n                self.cron_file = cron_file\n            else:\n                self.cron_file = os.path.join('/etc/cron.d', cron_file)\n        else:\n            self.cron_file = None\n        self.read()\n    def read(self):\n        # Read in the crontab from the system\n        self.lines = []\n        if self.cron_file:\n            # read the cronfile\n            try:\n                f = open(self.cron_file, 'r')\n                self.existing = f.read()\n                self.lines = self.existing.splitlines()\n                f.close()\n            except IOError:\n                # cron file does not exist\n                return\n            except Exception:\n                raise CronTabError(\"Unexpected error:\", sys.exc_info()[0])\n        else:\n            # using safely quoted shell for now, but this really should be two non-shell calls instead.  FIXME\n            (rc, out, err) = self.module.run_command(self._read_user_execute(), use_unsafe_shell=True)\n            if rc != 0 and rc != 1:  # 1 can mean that there are no jobs.\n                raise CronTabError(\"Unable to read crontab\")\n            self.existing = out\n            lines = out.splitlines()\n            count = 0\n            for l in lines:\n                if count > 2 or (not re.match(r'# DO NOT EDIT THIS FILE - edit the master and reinstall.', l) and\n                                 not re.match(r'# \\(/tmp/.*installed on.*\\)', l) and\n                                 not re.match(r'# \\(.*version.*\\)', l)):\n                    self.lines.append(l)\n                else:\n                    pattern = re.escape(l) + '[\\r\\n]?'\n                    self.existing = re.sub(pattern, '', self.existing, 1)\n                count += 1\n    def is_empty(self):\n        if len(self.lines) == 0:\n            return True\n        else:\n            return False\n    def write(self, backup_file=None):\n        \"\"\"\n        Write the crontab to the system. Saves all information.\n        \"\"\"\n        if backup_file:\n            fileh = open(backup_file, 'w')\n        elif self.cron_file:\n            fileh = open(self.cron_file, 'w')\n        else:\n            filed, path = tempfile.mkstemp(prefix='crontab')\n            os.chmod(path, int('0644', 8))\n            fileh = os.fdopen(filed, 'w')\n        fileh.write(self.render())\n        fileh.close()\n        # return if making a backup\n        if backup_file:\n            return\n        # Add the entire crontab back to the user crontab\n        if not self.cron_file:\n            # quoting shell args for now but really this should be two non-shell calls.  FIXME\n            (rc, out, err) = self.module.run_command(self._write_execute(path), use_unsafe_shell=True)\n            os.unlink(path)\n            if rc != 0:\n                self.module.fail_json(msg=err)\n        # set SELinux permissions\n        if self.module.selinux_enabled() and self.cron_file:\n            self.module.set_default_selinux_context(self.cron_file, False)\n    def do_comment(self, name):\n        return \"%s%s\" % (self.ansible, name)\n    def add_job(self, name, job):\n        # Add the comment\n        self.lines.append(self.do_comment(name))\n        # Add the job\n        self.lines.append(\"%s\" % (job))\n    def update_job(self, name, job):\n        return self._update_job(name, job, self.do_add_job)\n    def do_add_job(self, lines, comment, job):\n        lines.append(comment)\n        lines.append(\"%s\" % (job))\n    def remove_job(self, name):\n        return self._update_job(name, \"\", self.do_remove_job)\n    def do_remove_job(self, lines, comment, job):\n        return None\n    def add_env(self, decl, insertafter=None, insertbefore=None):\n        if not (insertafter or insertbefore):\n            self.lines.insert(0, decl)\n            return\n        if insertafter:\n            other_name = insertafter\n        elif insertbefore:\n            other_name = insertbefore\n        other_decl = self.find_env(other_name)\n        if len(other_decl) > 0:\n            if insertafter:\n                index = other_decl[0] + 1\n            elif insertbefore:\n                index = other_decl[0]\n            self.lines.insert(index, decl)\n            return\n        self.module.fail_json(msg=\"Variable named '%s' not found.\" % other_name)\n    def update_env(self, name, decl):\n        return self._update_env(name, decl, self.do_add_env)\n    def do_add_env(self, lines, decl):\n        lines.append(decl)\n    def remove_env(self, name):\n        return self._update_env(name, '', self.do_remove_env)\n    def do_remove_env(self, lines, decl):\n        return None\n    def remove_job_file(self):\n        try:\n            os.unlink(self.cron_file)\n            return True\n        except OSError:\n            # cron file does not exist\n            return False\n        except Exception:\n            raise CronTabError(\"Unexpected error:\", sys.exc_info()[0])\n    def find_job(self, name, job=None):\n        # attempt to find job by 'Ansible:' header comment\n        comment = None\n        for l in self.lines:\n            if comment is not None:\n                if comment == name:\n                    return [comment, l]\n                else:\n                    comment = None\n            elif re.match(r'%s' % self.ansible, l):\n", "outputs": ["                comment = re.sub(r'%s' % self.ansible, '', l)"], "input_length": 2428, "output_length": 16, "length": 2444, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "8139ef31587ce476f84303ae3c47b065d7f1e13d0defbc5047e6e29da2511886"}
{"input": "", "context": "package org.yamcs.events;\nimport java.util.Timer;\nimport java.util.TimerTask;\nimport java.util.concurrent.atomic.AtomicInteger;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.yamcs.yarch.protobuf.Db.Event;\nimport org.yamcs.protobuf.Yamcs.Event.EventSeverity;\n/**\n * Default implementation of an EventProducer that provides shortcut methods for sending message of different severity\n * types.\n */\npublic abstract class AbstractEventProducer implements EventProducer {\n    private static final Logger log = LoggerFactory.getLogger(EventProducer.class);\n    protected boolean logAllMessages = true;\n    String source;\n    AtomicInteger seqNo = new AtomicInteger();\n    private boolean repeatedEventReduction; // Whether to check for message repetitions\n    private Event originalEvent; // Original evt of a series of repeated events\n    private Event lastRepeat; // Last evt of a series of repeated events\n    private int repeatCounter = 0;\n    private long repeatedEventTimeout = 60000; // how long in milliseconds to buffer repeated events\n    // Flushes the Event Buffer about every minute\n    private Timer flusher;\n    @Override\n    public void setSource(String source) {\n        this.source = source;\n    }\n    @Override\n    public void setSeqNo(int sn) {\n        this.seqNo.set(sn);\n    }\n    @Override\n    public synchronized void sendError(String type, String msg) {\n        sendMessage(EventSeverity.ERROR, type, msg);\n    }\n    @Override\n    public synchronized void sendWarning(String type, String msg) {\n        sendMessage(EventSeverity.WARNING, type, msg);\n    }\n    @Override\n    public synchronized void sendInfo(String type, String msg) {\n        sendMessage(EventSeverity.INFO, type, msg);\n    }\n    @Override\n    public synchronized void sendWatch(String type, String msg) {\n        sendMessage(EventSeverity.WATCH, type, msg);\n    }\n    @Override\n    public synchronized void sendDistress(String type, String msg) {\n        sendMessage(EventSeverity.DISTRESS, type, msg);\n    }\n    @Override\n    public synchronized void sendCritical(String type, String msg) {\n        sendMessage(EventSeverity.CRITICAL, type, msg);\n    }\n    @Override\n    public synchronized void sendSevere(String type, String msg) {\n        sendMessage(EventSeverity.SEVERE, type, msg);\n    }\n    @Override\n    public void sendInfo(String msg) {\n        sendInfo(getInvokingClass(), msg);\n    }\n    @Override\n    public void sendWatch(String msg) {\n        sendWatch(getInvokingClass(), msg);\n    }\n    @Override\n    public void sendWarning(String msg) {\n        sendWarning(getInvokingClass(), msg);\n    }\n    @Override\n    public void sendCritical(String msg) {\n        sendCritical(getInvokingClass(), msg);\n    }\n    @Override\n    public void sendDistress(String msg) {\n        sendDistress(getInvokingClass(), msg);\n    }\n    @Override\n    public void sendSevere(String msg) {\n        sendSevere(getInvokingClass(), msg);\n    }\n    private String getInvokingClass() {\n        Throwable throwable = new Throwable();\n        String classname = throwable.getStackTrace()[2].getClassName();\n        int idx = classname.lastIndexOf('.');\n        return classname.substring(idx + 1);\n    }\n    private void sendMessage(EventSeverity severity, String type, String msg) {\n        if (logAllMessages) {\n            log.debug(\"event: {}; {}; {}\", severity, type, msg);\n        }\n        Event.Builder eventb = newEvent().setSeverity(severity).setMessage(msg);\n        if (type != null) {\n            eventb.setType(type);\n        }\n        Event e = eventb.build();\n        if (!repeatedEventReduction) {\n            sendEvent(e);\n        } else {\n            if (originalEvent == null) {\n                sendEvent(e);\n                originalEvent = e;\n            } else if (isRepeat(e)) {\n                if (flusher == null) { // Prevent buffering repeated events forever\n                    flusher = new Timer(true);\n                    flusher.scheduleAtFixedRate(new TimerTask() {\n                        @Override\n                        public void run() {\n                            flushEventBuffer(false);\n                        }\n                    }, repeatedEventTimeout, repeatedEventTimeout);\n                }\n                lastRepeat = e;\n                repeatCounter++;\n            } else { // No more repeats\n                if (flusher != null) {\n                    flusher.cancel();\n                    flusher = null;\n                }\n                flushEventBuffer(true);\n                sendEvent(e);\n                originalEvent = e;\n                lastRepeat = null;\n            }\n        }\n    }\n    /**\n     * By default event repetitions are checked for possible reduction. Disable if 'realtime' events are required.\n     */\n    @Override\n    public synchronized void setRepeatedEventReduction(boolean repeatedEventReduction,\n            long repeatedEventTimeoutMillisec) {\n        this.repeatedEventReduction = repeatedEventReduction;\n        this.repeatedEventTimeout = repeatedEventTimeoutMillisec;\n        if (!repeatedEventReduction) {\n            if (flusher != null) {\n                flusher.cancel();\n                flusher = null;\n            }\n            flushEventBuffer(true);\n        }\n    }\n    protected synchronized void flushEventBuffer(boolean startNewSequence) {\n        if (repeatCounter > 1) {\n            sendEvent(Event.newBuilder(lastRepeat)\n                    .setMessage(\"Repeated \" + repeatCounter + \" times: \" + lastRepeat.getMessage())\n                    .build());\n        } else if (repeatCounter == 1) {\n            sendEvent(lastRepeat);\n            lastRepeat = null;\n        }\n        if (startNewSequence) {\n            originalEvent = null;\n        }\n        repeatCounter = 0;\n    }\n    /**\n     * Checks whether the specified Event is a repeat of the previous Event.\n     */\n    private boolean isRepeat(Event e) {\n        if (originalEvent == e) {\n            return true;\n        }\n        return originalEvent.getMessage().equals(e.getMessage())\n                && originalEvent.getSeverity().equals(e.getSeverity())\n                && originalEvent.getSource().equals(e.getSource())\n                && originalEvent.hasType() == e.hasType()\n                && (!originalEvent.hasType() || originalEvent.getType().equals(e.getType()));\n    }\n    @Override\n    public Event.Builder newEvent() {\n", "outputs": ["        long t = getMissionTime();"], "input_length": 998, "output_length": 7, "length": 1005, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "39b6e70946421fd234ac7a8a81bcb4991cd11cd1e582b015fb5897bf3b849f92"}
{"input": "", "context": "using System.Data.Common;\nusing System.Collections;\nusing NHibernate.Cache;\nusing NHibernate.Cfg;\nusing NHibernate.Engine;\nusing NUnit.Framework;\nnamespace NHibernate.Test.SecondLevelCacheTests\n{\n\tusing Criterion;\n\t[TestFixture]\n\tpublic class SecondLevelCacheTest : TestCase\n\t{\n\t\tprotected override string MappingsAssembly\n\t\t{\n\t\t\tget { return \"NHibernate.Test\"; }\n\t\t}\n\t\tprotected override IList Mappings\n\t\t{\n\t\t\tget { return new string[] { \"SecondLevelCacheTest.Item.hbm.xml\" }; }\n\t\t}\n\t\tprotected override void Configure(Configuration configuration)\n\t\t{\n\t\t\tbase.Configure(configuration);\n\t\t\tconfiguration.Properties[Environment.CacheProvider] = typeof(HashtableCacheProvider).AssemblyQualifiedName;\n\t\t\tconfiguration.Properties[Environment.UseQueryCache] = \"true\";\n\t\t}\n\t\tprotected override void OnSetUp()\n\t\t{\n\t\t\t// Clear cache at each test.\n\t\t\tRebuildSessionFactory();\n\t\t\tusing (ISession session = OpenSession())\n\t\t\tusing (ITransaction tx = session.BeginTransaction())\n\t\t\t{\n\t\t\t\tItem item = new Item();\n\t\t\t\titem.Id = 1;\n\t\t\t\tsession.Save(item);\n\t\t\t\tfor (int i = 0; i < 4; i++)\n\t\t\t\t{\n\t\t\t\t\tItem child = new Item();\n\t\t\t\t\tchild.Id = i + 2;\n\t\t\t\t\tchild.Parent = item;\n\t\t\t\t\tsession.Save(child);\n\t\t\t\t\titem.Children.Add(child);\n\t\t\t\t}\n\t\t\t\tfor (int i = 0; i < 5; i++)\n\t\t\t\t{\n\t\t\t\t\tAnotherItem obj = new AnotherItem(\"Item #\" + i);\n\t\t\t\t\tobj.Id = i + 1;\n\t\t\t\t\tsession.Save(obj);\n\t\t\t\t}\n\t\t\t\ttx.Commit();\n\t\t\t}\n\t\t\tSfi.Evict(typeof(Item));\n\t\t\tSfi.EvictCollection(typeof(Item).FullName + \".Children\");\n\t\t}\n\t\tprotected override void OnTearDown()\n\t\t{\n\t\t\tusing (ISession session = OpenSession())\n\t\t\t{\n\t\t\t\tsession.Delete(\"from Item\"); //cleaning up\n\t\t\t\tsession.Delete(\"from AnotherItem\"); //cleaning up\n\t\t\t\tsession.Flush();\n\t\t\t}\n\t\t}\n\t\t[Test]\n\t\tpublic void CachedQueriesHandlesEntitiesParametersCorrectly()\n\t\t{\n\t\t\tusing (ISession session = OpenSession())\n\t\t\t{\n\t\t\t\tItem one = (Item)session.Load(typeof(Item), 1);\n\t\t\t\tIList results = session.CreateQuery(\"from Item item where item.Parent = :parent\")\n\t\t\t\t\t.SetEntity(\"parent\", one)\n\t\t\t\t\t.SetCacheable(true).List();\n\t\t\t\tAssert.AreEqual(4, results.Count);\n\t\t\t\tforeach (Item item in results)\n\t\t\t\t{\n\t\t\t\t\tAssert.AreEqual(1, item.Parent.Id);\n\t\t\t\t}\n\t\t\t}\n\t\t\tusing (ISession session = OpenSession())\n\t\t\t{\n\t\t\t\tItem two = (Item)session.Load(typeof(Item), 2);\n\t\t\t\tIList results = session.CreateQuery(\"from Item item where item.Parent = :parent\")\n\t\t\t\t\t.SetEntity(\"parent\", two)\n\t\t\t\t\t.SetCacheable(true).List();\n\t\t\t\tAssert.AreEqual(0, results.Count);\n\t\t\t}\n\t\t}\n\t\t[Test]\n\t\tpublic void DeleteItemFromCollectionThatIsInTheSecondLevelCache()\n\t\t{\n\t\t\tusing (ISession session = OpenSession())\n\t\t\t{\n\t\t\t\tItem item = (Item)session.Load(typeof(Item), 1);\n\t\t\t\tAssert.IsTrue(item.Children.Count == 4); // just force it into the second level cache here\n\t\t\t}\n\t\t\tint childId = -1;\n\t\t\tusing (ISession session = OpenSession())\n\t\t\t{\n\t\t\t\tItem item = (Item)session.Load(typeof(Item), 1);\n\t\t\t\tItem child = (Item)item.Children[0];\n\t\t\t\tchildId = child.Id;\n\t\t\t\tsession.Delete(child);\n\t\t\t\titem.Children.Remove(child);\n\t\t\t\tsession.Flush();\n\t\t\t}\n\t\t\tusing (ISession session = OpenSession())\n\t\t\t{\n\t\t\t\tItem item = (Item)session.Load(typeof(Item), 1);\n\t\t\t\tAssert.AreEqual(3, item.Children.Count);\n\t\t\t\tforeach (Item child in item.Children)\n\t\t\t\t{\n\t\t\t\t\tNHibernateUtil.Initialize(child);\n\t\t\t\t\tAssert.IsFalse(child.Id == childId);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t[Test]\n\t\tpublic void InsertItemToCollectionOnTheSecondLevelCache()\n\t\t{\n\t\t\tusing (ISession session = OpenSession())\n\t\t\t{\n\t\t\t\tItem item = (Item)session.Load(typeof(Item), 1);\n\t\t\t\tItem child = new Item();\n\t\t\t\tchild.Id = 6;\n\t\t\t\titem.Children.Add(child);\n\t\t\t\tsession.Save(child);\n\t\t\t\tsession.Flush();\n\t\t\t}\n\t\t\tusing (ISession session = OpenSession())\n\t\t\t{\n\t\t\t\tItem item = (Item)session.Load(typeof(Item), 1);\n\t\t\t\tint count = item.Children.Count;\n\t\t\t\tAssert.AreEqual(5, count);\n\t\t\t}\n\t\t}\n\t\t[Test]\n\t\tpublic void SecondLevelCacheWithCriteriaQueries()\n\t\t{\n\t\t\tusing (ISession session = OpenSession())\n\t\t\t{\n\t\t\t\tIList list = session.CreateCriteria(typeof(AnotherItem))\n\t\t\t\t\t.Add(Expression.Gt(\"Id\", 2))\n\t\t\t\t\t.SetCacheable(true)\n\t\t\t\t\t.List();\n\t\t\t\tAssert.AreEqual(3, list.Count);\n\t\t\t\tusing (var cmd = session.Connection.CreateCommand())\n\t\t\t\t{\n\t\t\t\t\tcmd.CommandText = \"DELETE FROM AnotherItem\";\n\t\t\t\t\tcmd.ExecuteNonQuery();\n\t\t\t\t}\n\t\t\t}\n\t\t\tusing (ISession session = OpenSession())\n\t\t\t{\n\t\t\t\t//should bring from cache\n\t\t\t\tIList list = session.CreateCriteria(typeof(AnotherItem))\n\t\t\t\t\t.Add(Expression.Gt(\"Id\", 2))\n\t\t\t\t\t.SetCacheable(true)\n\t\t\t\t\t.List();\n\t\t\t\tAssert.AreEqual(3, list.Count);\n\t\t\t}\n\t\t}\n\t\t[Test]\n\t\tpublic void SecondLevelCacheWithCriteriaQueriesForItemWithCollections()\n\t\t{\n\t\t\tusing (ISession session = OpenSession())\n\t\t\t{\n\t\t\t\tIList list = session.CreateCriteria(typeof(Item))\n\t\t\t\t\t.Add(Expression.Gt(\"Id\", 2))\n\t\t\t\t\t.SetCacheable(true)\n\t\t\t\t\t.List();\n\t\t\t\tAssert.AreEqual(3, list.Count);\n\t\t\t\tusing (var cmd = session.Connection.CreateCommand())\n\t\t\t\t{\n\t\t\t\t\tcmd.CommandText = \"DELETE FROM Item\";\n\t\t\t\t\tcmd.ExecuteNonQuery();\n\t\t\t\t}\n\t\t\t}\n\t\t\tusing (ISession session = OpenSession())\n\t\t\t{\n\t\t\t\t//should bring from cache\n", "outputs": ["\t\t\t\tIList list = session.CreateCriteria(typeof(Item))"], "input_length": 963, "output_length": 10, "length": 973, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "ac5a3b0aaa20e56aaacf0f46035dc4a2bdd20935b1c704dddf19de03303c39d3"}
{"input": "", "context": "// ---------------------------------\n// <copyright file=\"AbstractTrados2007LanguageDirection.cs\" company=\"SDL International\">\n// Copyright  2011 All Right Reserved\n// </copyright>\n// <author>Kostiantyn Lukianets</author>\n// <email>klukianets@sdl.com</email>\n// <date>2011-11-08</date>\n// ---------------------------------\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Runtime.InteropServices;\nnamespace Sdl.Community.Trados2007\n{\n    using System;\n    using System.Diagnostics.CodeAnalysis;\n    using System.Globalization;\n    using Sdl.LanguagePlatform.Core;\n    using Sdl.LanguagePlatform.TranslationMemory;\n    using Sdl.LanguagePlatform.TranslationMemoryApi;\n    using Trados.Interop.TMAccess;\n    using Action = Sdl.LanguagePlatform.TranslationMemory.Action;\n    using SearchResult = Sdl.LanguagePlatform.TranslationMemory.SearchResult;\n    \n    using Sdl.LanguagePlatform.Lingua.TermRecognition;\n    /// <summary>\n    /// Abstract base class for file- and server-based Trados 2007 language directions.\n    /// </summary>\n    [SuppressMessage(\"StyleCop.CSharp.DocumentationRules\", \"SA1623:PropertySummaryDocumentationMustMatchAccessors\",\n        Justification = \"By original SDL API design.\")]\n    public abstract class AbstractTrados2007LanguageDirection : ITranslationProviderLanguageDirection\n    {\n        #region Fields\n        protected readonly object locker = new object();\n        /// <summary>\n        /// Stores Trados 2007 Translation Provider that owns this particular Language Direction.\n        /// </summary>\n        private readonly AbstractTrados2007TranslationProvider translationProvider;\n        /// <summary>\n        /// Stores languages direction.\n        /// </summary>\n        private readonly LanguagePair languageDirection;\n        #endregion // Fields\n        /// <summary>\n        /// Initializes a new instance of the <see cref=\"AbstractTrados2007LanguageDirection\"/> class.\n        /// </summary>\n        /// <param name=\"translationProvider\">The Trados 2007 translation provider.</param>\n        protected AbstractTrados2007LanguageDirection(AbstractTrados2007TranslationProvider translationProvider)\n        {\n            if (translationProvider == null)\n            {\n                throw new ArgumentNullException(\"translationProvider\");\n            }\n            // Trados 2007 TP supports only one language direction, regardless file- or -server based\n            this.translationProvider = translationProvider;\n            this.languageDirection = translationProvider.LanguageDirection;\n        }\n        #region Properties\n        /// <summary>\n        /// The translation provider to which this language direction belongs.\n        /// </summary>\n        ITranslationProvider ITranslationProviderLanguageDirection.TranslationProvider\n        {\n            get\n            {\n                return this.translationProvider;\n            }\n        }\n        /// <summary>\n        /// Gets the source language.\n        /// </summary>\n        public CultureInfo SourceLanguage\n        {\n            get\n            {\n                return this.languageDirection.SourceCulture;\n            }\n        }\n        /// <summary>\n        /// Gets the target language.\n        /// </summary>\n        public CultureInfo TargetLanguage\n        {\n            get\n            {\n                return this.languageDirection.TargetCulture;\n            }\n        }\n        /// <summary>\n        /// Gets a flag which indicates whether the translation provider supports\n        /// searches in the reversed language direction.\n        /// </summary>\n        public bool CanReverseLanguageDirection\n        {\n            get\n            {\n                return false;\n            }\n        }\n        /// <summary>\n        /// The translation provider to which this language direction belongs.\n        /// </summary>\n        protected AbstractTrados2007TranslationProvider TranslationProvider\n        {\n            get\n            {\n                return this.translationProvider;\n            }\n        }\n        #endregion // Properties\n        #region Methods\n        /// <summary>\n        /// Adds a translation unit to the database. If the provider doesn't support adding/updating, the \n        ///             implementation should return a reasonable <see cref=\"T:Sdl.LanguagePlatform.TranslationMemory.ImportResult\"/> but should not throw an exception.\n        /// </summary>\n        /// <param name=\"translationUnit\">The translation unit.</param><param name=\"settings\">The settings used for this operation.</param>\n        /// <returns>\n        /// An <see cref=\"T:Sdl.LanguagePlatform.TranslationMemory.ImportResult\"/> which represents the status of the operation (succeeded, ignored, etc).\n        /// </returns>\n        [Obsolete(@\"Trados 2007 Translation Provider does not support adding\\editing.\")]\n        public virtual ImportResult AddTranslationUnit(TranslationUnit translationUnit, ImportSettings settings)\n        {\n            return new ImportResult { Action = Action.Add, ErrorCode = ErrorCode.InvalidOperation };\n        }\n        /// <summary>\n        /// Adds an array of translation units to the database. If the provider doesn't support adding/updating, the \n        ///             implementation should return a reasonable <see cref=\"T:Sdl.LanguagePlatform.TranslationMemory.ImportResult\"/> but should not throw an exception.\n        /// </summary>\n        /// <param name=\"translationUnits\">An arrays of translation units to be added.</param><param name=\"settings\">The settings used for this operation.</param>\n        /// <returns>\n        /// An array of <see cref=\"T:Sdl.LanguagePlatform.TranslationMemory.ImportResult\"/> objects, which mirrors the translation unit array. It has the exact same size and contains the\n        ///             status of each add operation for each particular translation unit with the same index within the array.\n        /// </returns>\n        [Obsolete(@\"Trados 2007 Translation Provider does not support adding\\editing.\")]\n        public virtual ImportResult[] AddTranslationUnits(TranslationUnit[] translationUnits, ImportSettings settings)\n        {\n            return new[] { new ImportResult() { Action = Action.Add, ErrorCode = ErrorCode.InvalidOperation } };\n        }\n        /// <summary>\n        /// Adds an array of translation units to the database. If hash codes of the previous translations are provided, \n        ///             a found translation will be overwritten. If none is found, or the hash is 0 or the collection is <c>null</c>, \n        ///             the operation behaves identical to <see cref=\"M:Sdl.LanguagePlatform.TranslationMemoryApi.ITranslationProviderLanguageDirection.AddTranslationUnits(Sdl.LanguagePlatform.TranslationMemory.TranslationUnit[],Sdl.LanguagePlatform.TranslationMemory.ImportSettings)\"/>.\n        /// <para>\n        /// If the provider doesn't support adding/updating, the \n        ///             implementation should return a reasonable <see cref=\"T:Sdl.LanguagePlatform.TranslationMemory.ImportResult\"/> but should not throw an exception.\n        /// </para>\n        /// </summary>\n        /// <param name=\"translationUnits\">An arrays of translation units to be added.</param><param name=\"previousTranslationHashes\">If provided, a corresponding array of a the hash code of a previous translation.</param><param name=\"settings\">The settings used for this operation.</param>\n        /// <returns>\n        /// An array of <see cref=\"T:Sdl.LanguagePlatform.TranslationMemory.ImportResult\"/> objects, which mirrors the translation unit array. It has the exact same size and contains the\n        ///             status of each add operation for each particular translation unit with the same index within the array.\n        /// </returns>\n        [Obsolete(@\"Trados 2007 Translation Provider does not support adding\\editing.\")]\n        public virtual ImportResult[] AddOrUpdateTranslationUnits(TranslationUnit[] translationUnits, int[] previousTranslationHashes, ImportSettings settings)\n        {\n            int count = translationUnits.Length;\n            var result = new ImportResult[count];\n            var err = new ImportResult() { Action = Action.Add, ErrorCode = ErrorCode.InvalidOperation };\n            for (int i = 0; i < count; i++)\n            {\n                result[i] = err;\n            }\n            return result;\n        }\n        /// <summary>\n        /// Adds an array of translation units to the database, but will only add those\n        ///             for which the corresponding mask field is <c>true</c>. If the provider doesn't support adding/updating, the \n        ///             implementation should return a reasonable ImportResult but should not throw an exception.\n        /// </summary>\n        /// <param name=\"translationUnits\">An arrays of translation units to be added.</param><param name=\"settings\">The settings used for this operation.</param><param name=\"mask\">A boolean array with the same cardinality as the TU array, specifying which TUs to add.</param>\n        /// <returns>\n        /// An array of ImportResult objects, which mirrors the translation unit array. It has the exact same size and contains the\n        ///             status of each add operation for each particular translation unit with the same index within the array.\n        /// </returns>\n        [Obsolete(@\"Trados 2007 Translation Provider does not support adding\\editing.\")]\n        public virtual ImportResult[] AddTranslationUnitsMasked(TranslationUnit[] translationUnits, ImportSettings settings, bool[] mask)\n        {\n            return new[] { new ImportResult() { Action = Action.Add, ErrorCode = ErrorCode.InvalidOperation } };\n        }\n        /// <summary>\n        /// Adds an array of translation units to the database, but will only add those\n        ///             for which the corresponding mask field is true. If the previous translation hashes are provided,\n        ///             existing translations will be updated if the target segment hash changed.\n        /// <para>\n        /// If the provider doesn't support adding/updating, the \n        ///             implementation should return a reasonable ImportResult but should not throw an exception.\n        /// </para>\n        /// </summary>\n        /// <param name=\"translationUnits\">An arrays of translation units to be added.</param><param name=\"previousTranslationHashes\">Corresponding hash codes of a previous translation (0 if unknown). The parameter may be null.</param><param name=\"settings\">The settings used for this operation.</param><param name=\"mask\">A boolean array with the same cardinality as the TU array, specifying which TUs to add.</param>\n        /// <returns>\n        /// An array of ImportResult objects, which mirrors the translation unit array. It has the exact same size and contains the\n        ///             status of each add operation for each particular translation unit with the same index within the array.\n        /// </returns>\n        [Obsolete(@\"Trados 2007 Translation Provider does not support adding\\editing.\")]\n        public virtual ImportResult[] AddOrUpdateTranslationUnitsMasked(TranslationUnit[] translationUnits, int[] previousTranslationHashes, ImportSettings settings, bool[] mask)\n        {\n            return new[] { new ImportResult() { Action = Action.Add, ErrorCode = ErrorCode.InvalidOperation } };\n        }\n        /// <summary>\n        /// Performs a search for an array of segments.\n        /// </summary>\n        /// <param name=\"settings\">The settings that define the search parameters.</param><param name=\"segments\">The array containing the segments to search for.</param>\n        /// <returns>\n        /// An array of <see cref=\"T:Sdl.LanguagePlatform.TranslationMemory.SearchResults\"/> objects, which mirrors the segments array. It has the exact same size and contains the\n        ///             search results for each segment with the same index within the segments array.\n        /// </returns>\n        public virtual SearchResults[] SearchSegments(SearchSettings settings, Segment[] segments)\n        {\n", "outputs": ["            var searchResultsArray = new SearchResults[segments.Length];"], "input_length": 1835, "output_length": 9, "length": 1844, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "c284eb32096def02da4ded5297bbacdeeb35b2d99c53327e0918be49a1c25767"}
{"input": "", "context": "package org.exist.security;\nimport org.exist.storage.io.VariableByteInputStream;\nimport java.io.ByteArrayInputStream;\nimport java.io.IOException;\nimport org.exist.storage.io.VariableByteOutputStream;\nimport org.exist.Database;\nimport org.exist.security.ACLPermission.ACE_TARGET;\nimport org.exist.security.ACLPermission.ACE_ACCESS_TYPE;\nimport org.exist.security.internal.SecurityManagerImpl;\nimport java.util.Random;\nimport org.easymock.EasyMock;\nimport org.exist.util.ByteArray;\nimport org.junit.Test;\nimport static org.junit.Assert.assertTrue;\nimport static org.junit.Assert.assertFalse;\nimport static org.junit.Assert.assertEquals;\nimport static org.easymock.EasyMock.replay;\nimport static org.easymock.EasyMock.verify;\nimport static org.easymock.EasyMock.expect;\n/**\n *\n * @author Adam Retter <adam@exist-db.org>\n */\npublic class SimpleACLPermissionTest {\n    private final static int ALL = Permission.READ | Permission.WRITE | Permission.EXECUTE;\n    @Test\n    public void add() throws PermissionDeniedException {\n        final SecurityManager mockSecurityManager = EasyMock.createMock(SecurityManager.class);\n        final Database mockDatabase = EasyMock.createMock(Database.class);\n        final Subject mockCurrentSubject = EasyMock.createMock(Subject.class);\n        \n        //expect(mockSecurityManager.getDatabase()).andReturn(mockDatabase);\n        //expect(mockDatabase.getCurrentSubject()).andReturn(mockCurrentSubject);\n        //expect(mockCurrentSubject.hasDbaRole()).andReturn(true);\n        replay(mockSecurityManager, mockDatabase, mockCurrentSubject);\n        \n        SimpleACLPermission permission = new SimpleACLPermission(mockSecurityManager);\n        assertEquals(0, permission.getACECount());\n        final int userId = 1;\n        final int mode = ALL;\n        permission.addUserACE(ACE_ACCESS_TYPE.ALLOWED, userId, mode);\n        \n        verify(mockSecurityManager, mockDatabase, mockCurrentSubject);\n        \n        assertEquals(1, permission.getACECount());\n        assertEquals(ACE_ACCESS_TYPE.ALLOWED, permission.getACEAccessType(0));\n        assertEquals(ACE_TARGET.USER, permission.getACETarget(0));\n        assertEquals(userId, permission.getACEId(0));\n        assertEquals(mode, permission.getACEMode(0));\n    }\n    @Test\n    public void addACE_ForUserWithModeString() throws PermissionDeniedException {\n        final SecurityManager mockSecurityManager = EasyMock.createMock(SecurityManager.class);\n        final Database mockDatabase = EasyMock.createMock(Database.class);\n        final Subject mockCurrentSubject = EasyMock.createMock(Subject.class);\n        final Account mockAccount = EasyMock.createMock(Account.class);\n        SimpleACLPermission permission = new SimpleACLPermission(mockSecurityManager);\n        assertEquals(0, permission.getACECount());\n        final int userId = 1112;\n        final String userName = \"aretter\";\n        final String mode = \"rwx\";\n        //expect(mockSecurityManager.getDatabase()).andReturn(mockDatabase);\n        //expect(mockDatabase.getCurrentSubject()).andReturn(mockCurrentSubject);\n        //expect(mockCurrentSubject.hasDbaRole()).andReturn(true);\n        expect(mockSecurityManager.getAccount(userName)).andReturn(mockAccount);\n        expect(mockAccount.getId()).andReturn(userId);\n        replay(mockSecurityManager, mockDatabase, mockCurrentSubject, mockAccount);\n        permission.addACE(ACE_ACCESS_TYPE.ALLOWED, ACE_TARGET.USER, userName, mode);\n        verify(mockSecurityManager, mockDatabase, mockCurrentSubject, mockAccount);\n        assertEquals(1, permission.getACECount());\n        assertEquals(userId, permission.getACEId(0));\n        assertEquals(ACE_ACCESS_TYPE.ALLOWED, permission.getACEAccessType(0));\n        assertEquals(ACE_TARGET.USER, permission.getACETarget(0));\n        assertEquals(ALL, permission.getACEMode(0));\n    }\n    @Test\n    public void addACE_ForGroupWithModeString() throws PermissionDeniedException {\n        final SecurityManager mockSecurityManager = EasyMock.createMock(SecurityManager.class);\n        final Database mockDatabase = EasyMock.createMock(Database.class);\n        final Subject mockCurrentSubject = EasyMock.createMock(Subject.class);\n        final Group mockGroup = EasyMock.createMock(Group.class);\n        SimpleACLPermission permission = new SimpleACLPermission(mockSecurityManager);\n        assertEquals(0, permission.getACECount());\n        final int groupId = 1112;\n        final String groupName = \"aretter\";\n        final String mode = \"rwx\";\n        //expect(mockSecurityManager.getDatabase()).andReturn(mockDatabase);\n        //expect(mockDatabase.getCurrentSubject()).andReturn(mockCurrentSubject);\n        //expect(mockCurrentSubject.hasDbaRole()).andReturn(true);\n        \n        expect(mockSecurityManager.getGroup(groupName)).andReturn(mockGroup);\n        expect(mockGroup.getId()).andReturn(groupId);\n        replay(mockSecurityManager, mockDatabase, mockCurrentSubject, mockGroup);\n        permission.addACE(ACE_ACCESS_TYPE.ALLOWED, ACE_TARGET.GROUP, groupName, mode);\n        verify(mockSecurityManager, mockDatabase, mockCurrentSubject, mockGroup);\n        assertEquals(1, permission.getACECount());\n        assertEquals(groupId, permission.getACEId(0));\n        assertEquals(ACE_ACCESS_TYPE.ALLOWED, permission.getACEAccessType(0));\n        assertEquals(ACE_TARGET.GROUP, permission.getACETarget(0));\n        assertEquals(ALL, permission.getACEMode(0));\n        assertEquals(mode, permission.getACEModeString(0));\n    }\n    @Test\n    public void insert_atFront_whenEmpty() throws PermissionDeniedException {\n        final SecurityManager mockSecurityManager = EasyMock.createMock(SecurityManager.class);\n        final Database mockDatabase = EasyMock.createMock(Database.class);\n        final Subject mockCurrentSubject = EasyMock.createMock(Subject.class);\n        //expect(mockSecurityManager.getDatabase()).andReturn(mockDatabase);\n        //expect(mockDatabase.getCurrentSubject()).andReturn(mockCurrentSubject);\n        //expect(mockCurrentSubject.hasDbaRole()).andReturn(true);\n        \n        replay(mockSecurityManager, mockDatabase, mockCurrentSubject);\n        \n        SimpleACLPermission permission = new SimpleACLPermission(mockSecurityManager);\n        assertEquals(0, permission.getACECount());\n        final int userId = 1112;\n        final int mode = ALL;\n        permission.insertUserACE(0, ACE_ACCESS_TYPE.ALLOWED, userId, mode);\n        \n        verify(mockSecurityManager, mockDatabase, mockCurrentSubject);\n        assertEquals(1, permission.getACECount());\n        assertEquals(userId, permission.getACEId(0));\n        assertEquals(ACE_ACCESS_TYPE.ALLOWED, permission.getACEAccessType(0));\n        assertEquals(ACE_TARGET.USER, permission.getACETarget(0));\n        assertEquals(ALL, permission.getACEMode(0));\n    }\n    @Test\n    public void insert_atFront() throws PermissionDeniedException {\n        final SecurityManager mockSecurityManager = EasyMock.createMock(SecurityManager.class);\n        final Database mockDatabase = EasyMock.createMock(Database.class);\n        final Subject mockCurrentSubject = EasyMock.createMock(Subject.class);\n        //expect(mockSecurityManager.getDatabase()).andReturn(mockDatabase).times(2);\n        //expect(mockDatabase.getCurrentSubject()).andReturn(mockCurrentSubject).times(2);\n        //expect(mockCurrentSubject.hasDbaRole()).andReturn(true).times(2);\n        \n        replay(mockSecurityManager, mockDatabase, mockCurrentSubject);\n        \n        SimpleACLPermission permission = new SimpleACLPermission(mockSecurityManager);\n        assertEquals(0, permission.getACECount());\n        final int userId = 1112;\n        final int mode = ALL;\n        permission.addUserACE(ACE_ACCESS_TYPE.ALLOWED, userId, mode);\n        \n        assertEquals(1, permission.getACECount());\n        assertEquals(userId, permission.getACEId(0));\n        assertEquals(ACE_ACCESS_TYPE.ALLOWED, permission.getACEAccessType(0));\n        assertEquals(ACE_TARGET.USER, permission.getACETarget(0));\n        assertEquals(ALL, permission.getACEMode(0));\n        final int secondUserId = 1113;\n        final int secondMode = 04;\n        permission.insertUserACE(0, ACE_ACCESS_TYPE.ALLOWED, secondUserId, secondMode);\n        \n        assertEquals(2, permission.getACECount());\n        assertEquals(secondUserId, permission.getACEId(0));\n        assertEquals(ACE_ACCESS_TYPE.ALLOWED, permission.getACEAccessType(0));\n        assertEquals(ACE_TARGET.USER, permission.getACETarget(0));\n        assertEquals(secondMode, permission.getACEMode(0));\n        \n        verify(mockSecurityManager, mockDatabase, mockCurrentSubject);\n    }\n    @Test\n    public void insert_inMiddle() throws PermissionDeniedException {\n        final SecurityManager mockSecurityManager = EasyMock.createMock(SecurityManager.class);\n        final Database mockDatabase = EasyMock.createMock(Database.class);\n        final Subject mockCurrentSubject = EasyMock.createMock(Subject.class);\n        //expect(mockSecurityManager.getDatabase()).andReturn(mockDatabase).times(3);\n        //expect(mockDatabase.getCurrentSubject()).andReturn(mockCurrentSubject).times(3);\n        //expect(mockCurrentSubject.hasDbaRole()).andReturn(true).times(3);\n        \n        replay(mockSecurityManager, mockDatabase, mockCurrentSubject);\n        SimpleACLPermission permission = new SimpleACLPermission(mockSecurityManager);\n        \n        assertEquals(0, permission.getACECount());\n        final int userId = 1112;\n        final int mode = ALL;\n        permission.addUserACE(ACE_ACCESS_TYPE.ALLOWED, userId, mode);\n        \n        assertEquals(1, permission.getACECount());\n        \n        assertEquals(userId, permission.getACEId(0));\n        assertEquals(ACE_ACCESS_TYPE.ALLOWED, permission.getACEAccessType(0));\n        assertEquals(ACE_TARGET.USER, permission.getACETarget(0));\n        assertEquals(ALL, permission.getACEMode(0));\n        final int secondUserId = 1113;\n        final int secondMode = 04;\n        permission.addUserACE(ACE_ACCESS_TYPE.ALLOWED, secondUserId, secondMode);\n        \n        assertEquals(2, permission.getACECount());\n        \n        assertEquals(secondUserId, permission.getACEId(1));\n        assertEquals(ACE_ACCESS_TYPE.ALLOWED, permission.getACEAccessType(1));\n        assertEquals(ACE_TARGET.USER, permission.getACETarget(1));\n        assertEquals(secondMode, permission.getACEMode(1));\n        final int thirdUserId = 1114;\n        final int thirdMode = 02;\n        permission.insertUserACE(1, ACE_ACCESS_TYPE.ALLOWED, thirdUserId, thirdMode);\n        \n        assertEquals(3, permission.getACECount());\n        \n        assertEquals(userId, permission.getACEId(0));\n        assertEquals(ACE_ACCESS_TYPE.ALLOWED, permission.getACEAccessType(0));\n        assertEquals(ACE_TARGET.USER, permission.getACETarget(0));\n        assertEquals(ALL, permission.getACEMode(0));\n        assertEquals(thirdUserId, permission.getACEId(1));\n        assertEquals(ACE_ACCESS_TYPE.ALLOWED, permission.getACEAccessType(1));\n        assertEquals(ACE_TARGET.USER, permission.getACETarget(1));\n        assertEquals(thirdMode, permission.getACEMode(1));\n        assertEquals(secondUserId, permission.getACEId(2));\n        assertEquals(ACE_ACCESS_TYPE.ALLOWED, permission.getACEAccessType(2));\n        assertEquals(ACE_TARGET.USER, permission.getACETarget(2));\n        assertEquals(secondMode, permission.getACEMode(2));\n        \n        verify(mockSecurityManager, mockDatabase, mockCurrentSubject);\n    }\n    @Test(expected=PermissionDeniedException.class)\n    public void insert_atEnd() throws PermissionDeniedException {\n        final SecurityManager mockSecurityManager = EasyMock.createMock(SecurityManager.class);\n        final Database mockDatabase = EasyMock.createMock(Database.class);\n        final Subject mockCurrentSubject = EasyMock.createMock(Subject.class);\n        //expect(mockSecurityManager.getDatabase()).andReturn(mockDatabase).times(2);\n        //expect(mockDatabase.getCurrentSubject()).andReturn(mockCurrentSubject).times(2);\n        //expect(mockCurrentSubject.hasDbaRole()).andReturn(true).times(2);\n        \n        replay(mockSecurityManager, mockDatabase, mockCurrentSubject);\n        SimpleACLPermission permission = new SimpleACLPermission(mockSecurityManager);\n        \n        assertEquals(0, permission.getACECount());\n        final int userId = 1112;\n        final int mode = ALL;\n        permission.addUserACE(ACE_ACCESS_TYPE.ALLOWED, userId, mode);\n        \n        assertEquals(1, permission.getACECount());\n        assertEquals(userId, permission.getACEId(0));\n        assertEquals(ACE_ACCESS_TYPE.ALLOWED, permission.getACEAccessType(0));\n        assertEquals(ACE_TARGET.USER, permission.getACETarget(0));\n        assertEquals(ALL, permission.getACEMode(0));\n        final int secondUserId = 1113;\n        final int secondMode = 04;\n        permission.insertUserACE(1, ACE_ACCESS_TYPE.ALLOWED, secondUserId, secondMode);\n        \n        verify(mockSecurityManager, mockDatabase, mockCurrentSubject);\n    }\n    @Test\n    public void remove_firstACE() throws PermissionDeniedException {\n        final SecurityManager mockSecurityManager = EasyMock.createMock(SecurityManager.class);\n        final Database mockDatabase = EasyMock.createMock(Database.class);\n        final Subject mockCurrentSubject = EasyMock.createMock(Subject.class);\n        //expect(mockSecurityManager.getDatabase()).andReturn(mockDatabase).times(3);\n        //expect(mockDatabase.getCurrentSubject()).andReturn(mockCurrentSubject).times(3);\n        //expect(mockCurrentSubject.hasDbaRole()).andReturn(true).times(3);\n        \n        replay(mockSecurityManager, mockDatabase, mockCurrentSubject);\n        SimpleACLPermission permission = new SimpleACLPermission(mockSecurityManager);\n        \n        assertEquals(0, permission.getACECount());\n        permission.addUserACE(ACE_ACCESS_TYPE.ALLOWED, 1, ALL);\n        final int secondUserId = 2;\n        permission.addUserACE(ACE_ACCESS_TYPE.ALLOWED, secondUserId, ALL);\n        assertEquals(2, permission.getACECount());\n        permission.removeACE(0);\n        assertEquals(1, permission.getACECount());\n        assertEquals(ACE_ACCESS_TYPE.ALLOWED, permission.getACEAccessType(0));\n        assertEquals(ACE_TARGET.USER, permission.getACETarget(0));\n        assertEquals(secondUserId, permission.getACEId(0));\n        \n        verify(mockSecurityManager, mockDatabase, mockCurrentSubject);\n    }\n    @Test\n    public void remove_middleACE() throws PermissionDeniedException {\n        final SecurityManager mockSecurityManager = EasyMock.createMock(SecurityManager.class);\n        final Database mockDatabase = EasyMock.createMock(Database.class);\n        final Subject mockCurrentSubject = EasyMock.createMock(Subject.class);\n        //expect(mockSecurityManager.getDatabase()).andReturn(mockDatabase).times(4);\n        //expect(mockDatabase.getCurrentSubject()).andReturn(mockCurrentSubject).times(4);\n        //expect(mockCurrentSubject.hasDbaRole()).andReturn(true).times(4);\n        replay(mockSecurityManager, mockDatabase, mockCurrentSubject);\n        \n        SimpleACLPermission permission = new SimpleACLPermission(mockSecurityManager);\n        \n        assertEquals(0, permission.getACECount());\n        final int firstUserId = 1;\n        permission.addUserACE(ACE_ACCESS_TYPE.ALLOWED, firstUserId, ALL);\n        permission.addUserACE(ACE_ACCESS_TYPE.ALLOWED, 2, ALL);\n        final int thirdUserId = 3;\n        permission.addUserACE(ACE_ACCESS_TYPE.ALLOWED, thirdUserId, ALL);\n        assertEquals(3, permission.getACECount());\n        permission.removeACE(1);\n        assertEquals(2, permission.getACECount());\n        assertEquals(firstUserId, permission.getACEId(0));\n        assertEquals(thirdUserId, permission.getACEId(1));\n        \n        verify(mockSecurityManager, mockDatabase, mockCurrentSubject);\n    }\n    @Test\n    public void remove_lastACE() throws PermissionDeniedException {\n        final SecurityManager mockSecurityManager = EasyMock.createMock(SecurityManager.class);\n        final Database mockDatabase = EasyMock.createMock(Database.class);\n        final Subject mockCurrentSubject = EasyMock.createMock(Subject.class);\n        //expect(mockSecurityManager.getDatabase()).andReturn(mockDatabase).times(3);\n        //expect(mockDatabase.getCurrentSubject()).andReturn(mockCurrentSubject).times(3);\n        //expect(mockCurrentSubject.hasDbaRole()).andReturn(true).times(3);\n        replay(mockSecurityManager, mockDatabase, mockCurrentSubject);\n        SimpleACLPermission permission = new SimpleACLPermission(mockSecurityManager);\n        \n        assertEquals(0, permission.getACECount());\n        final int firstUserId = 1;\n        permission.addUserACE(ACE_ACCESS_TYPE.ALLOWED, firstUserId, ALL);\n        permission.addUserACE(ACE_ACCESS_TYPE.ALLOWED, 2, ALL);\n        assertEquals(2, permission.getACECount());\n        permission.removeACE(1);\n        assertEquals(1, permission.getACECount());\n        assertEquals(firstUserId, permission.getACEId(0));\n        \n        verify(mockSecurityManager, mockDatabase, mockCurrentSubject);\n    }\n    @Test\n    public void modify() throws PermissionDeniedException {\n        final SecurityManager mockSecurityManager = EasyMock.createMock(SecurityManager.class);\n        final Database mockDatabase = EasyMock.createMock(Database.class);\n        final Subject mockCurrentSubject = EasyMock.createMock(Subject.class);\n        //expect(mockSecurityManager.getDatabase()).andReturn(mockDatabase).times(3);\n        //expect(mockDatabase.getCurrentSubject()).andReturn(mockCurrentSubject).times(3);\n        //expect(mockCurrentSubject.hasDbaRole()).andReturn(true).times(3);\n        replay(mockSecurityManager, mockDatabase, mockCurrentSubject);\n        SimpleACLPermission permission = new SimpleACLPermission(mockSecurityManager);\n        \n        assertEquals(0, permission.getACECount());\n        final int userId = 1;\n        final int mode = Permission.READ;\n        final ACE_ACCESS_TYPE access_type = ACE_ACCESS_TYPE.ALLOWED;\n        permission.addUserACE(access_type, userId, mode);\n        assertEquals(1, permission.getACECount());\n        assertEquals(userId, permission.getACEId(0));\n        assertEquals(access_type, permission.getACEAccessType(0));\n        assertEquals(ACE_TARGET.USER, permission.getACETarget(0));\n        assertEquals(mode, permission.getACEMode(0));\n        permission.modifyACE(0, access_type, Permission.WRITE);\n        assertEquals(1, permission.getACECount());\n        assertEquals(userId, permission.getACEId(0));\n        assertEquals(access_type, permission.getACEAccessType(0));\n        assertEquals(ACE_TARGET.USER, permission.getACETarget(0));\n        assertEquals(Permission.WRITE, permission.getACEMode(0));\n        permission.modifyACE(0, ACE_ACCESS_TYPE.DENIED, Permission.READ | Permission.WRITE);\n        assertEquals(1, permission.getACECount());\n        assertEquals(userId, permission.getACEId(0));\n        assertEquals(ACE_TARGET.USER, permission.getACETarget(0));\n        assertEquals(ACE_ACCESS_TYPE.DENIED, permission.getACEAccessType(0));\n        assertEquals(Permission.READ | Permission.WRITE, permission.getACEMode(0));\n        \n        verify(mockSecurityManager, mockDatabase, mockCurrentSubject);\n    }\n    @Test\n    public void clear() throws PermissionDeniedException {\n        final SecurityManager mockSecurityManager = EasyMock.createMock(SecurityManager.class);\n        final Database mockDatabase = EasyMock.createMock(Database.class);\n        final Subject mockCurrentSubject = EasyMock.createMock(Subject.class);\n        //expect(mockSecurityManager.getDatabase()).andReturn(mockDatabase).times(3);\n        //expect(mockDatabase.getCurrentSubject()).andReturn(mockCurrentSubject).times(3);\n        //expect(mockCurrentSubject.hasDbaRole()).andReturn(true).times(3);\n        replay(mockSecurityManager, mockDatabase, mockCurrentSubject);\n        SimpleACLPermission permission = new SimpleACLPermission(mockSecurityManager);\n        assertEquals(0, permission.getACECount());\n        permission.addUserACE(ACE_ACCESS_TYPE.ALLOWED, 1, ALL);\n        final int secondUserId = 2;\n        permission.addUserACE(ACE_ACCESS_TYPE.ALLOWED, secondUserId, ALL);\n        assertEquals(2, permission.getACECount());\n        permission.clear();\n        assertEquals(0, permission.getACECount());\n        \n        verify(mockSecurityManager, mockDatabase, mockCurrentSubject);\n    }\n    @Test\n    public void validate_cant_read_when_readNotInACL() throws PermissionDeniedException {\n        final SecurityManager mockSecurityManager = EasyMock.createMock(SecurityManager.class);\n        final int ownerId = new Random().nextInt(SecurityManagerImpl.MAX_USER_ID);\n        final int mode = 0700;\n        final int ownerGroupId = new Random().nextInt(SecurityManagerImpl.MAX_GROUP_ID);\n", "outputs": ["        final Subject mockUser = EasyMock.createMock(Subject.class);"], "input_length": 2902, "output_length": 9, "length": 2911, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "a3e1854844188b8151ef69e80d845c944fb83077e2d4068fffd84aeb9810b39a"}
{"input": "", "context": "/********\n * This file is part of Ext.NET.\n *     \n * Ext.NET is free software: you can redistribute it and/or modify\n * it under the terms of the GNU AFFERO GENERAL PUBLIC LICENSE as \n * published by the Free Software Foundation, either version 3 of the \n * License, or (at your option) any later version.\n * \n * Ext.NET is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU AFFERO GENERAL PUBLIC LICENSE for more details.\n * \n * You should have received a copy of the GNU AFFERO GENERAL PUBLIC LICENSE\n * along with Ext.NET.  If not, see <http://www.gnu.org/licenses/>.\n *\n *\n * @version   : 1.2.0 - Ext.NET Pro License\n * @author    : Ext.NET, Inc. http://www.ext.net/\n * @date      : 2011-09-12\n * @copyright : Copyright (c) 2006-2011, Ext.NET, Inc. (http://www.ext.net/). All rights reserved.\n * @license   : GNU AFFERO GENERAL PUBLIC LICENSE (AGPL) 3.0. \n *              See license.txt and http://www.ext.net/license/.\n *              See AGPL License at http://www.gnu.org/licenses/agpl-3.0.txt\n ********/\nusing System;\nusing System.ComponentModel;\nusing System.IO;\nusing System.Web.UI;\nusing Newtonsoft.Json;\nusing Ext.Net.Utilities;\nnamespace Ext.Net\n{\n    /// <summary>\n    /// \n    /// </summary>\n    /// <typeparam name=\"T\"></typeparam>\n    [Meta]\n    [Description(\"\")]\n    public abstract partial class MultiSelectBase<T> : Field, IStore where T : StateManagedItem \n    {\n        /// <summary>\n        /// The data store to use.\n        /// </summary>\n        [Meta]\n        [ConfigOption(\"store\", JsonMode.ToClientID)]\n        [Category(\"6. MultiSelect\")]\n        [DefaultValue(\"\")]\n        [IDReferenceProperty(typeof(Store))]\n        [Description(\"The data store to use.\")]\n        public virtual string StoreID\n        {\n            get\n            {\n                return (string)this.ViewState[\"StoreID\"] ?? \"\";\n            }\n            set\n            {\n                this.ViewState[\"StoreID\"] = value;\n            }\n        }\n        private StoreCollection store;\n        /// <summary>\n        ///  The data store to use.\n        /// </summary>\n        [Meta]\n        [ConfigOption(\"store>Primary\")]\n        [Category(\"7. MultiSelect\")]\n        [PersistenceMode(PersistenceMode.InnerProperty)]\n        [Description(\"The data store to use.\")]\n        public virtual StoreCollection Store\n        {\n            get\n            {\n                if (this.store == null)\n                {\n                    this.store = new StoreCollection();\n                    this.store.AfterItemAdd += this.AfterStoreAdd;\n                    this.store.AfterItemRemove += this.AfterStoreRemove;\n                }\n                return this.store;\n            }\n        }\n\t\t/// <summary>\n\t\t/// \n\t\t/// </summary>\n\t\t[Description(\"\")]\n        protected virtual void AfterStoreAdd(Store item)\n        {\n            this.Controls.AddAt(0, item);\n            this.LazyItems.Insert(0, item);\n        }\n\t\t/// <summary>\n\t\t/// \n\t\t/// </summary>\n\t\t[Description(\"\")]\n        protected virtual void AfterStoreRemove(Store item)\n        {\n            this.Controls.Remove(item);\n            this.LazyItems.Remove(item);\n        }\n        private ListItemCollection<T> items;\n        /// <summary>\n        /// \n        /// </summary>\n        [Meta]\n        [PersistenceMode(PersistenceMode.InnerProperty)]\n        [ViewStateMember]\n        [Description(\"\")]\n        public ListItemCollection<T> Items\n        {\n            get\n            {\n                if (this.items == null)\n                {\n                    this.items = new ListItemCollection<T>();\n                }\n                return this.items;\n            }\n        }\n\t\t/// <summary>\n\t\t/// \n\t\t/// </summary>\n        [ConfigOption(\"store\", JsonMode.Raw)]\n        [DefaultValue(\"\")]\n\t\t[Description(\"\")]\n        protected string ItemsProxy\n        {\n            get\n            {\n                if (this.StoreID.IsNotEmpty() || this.Store.Primary != null)\n                {\n                    return \"\";\n                }\n                return this.ItemsToStore;\n            }\n        }\n        private string ItemsToStore\n        {\n            get\n            {\n                StringWriter sw = new StringWriter();\n                JsonTextWriter jw = new JsonTextWriter(sw);\n                ListItemCollectionJsonConverter converter = new ListItemCollectionJsonConverter();\n                converter.WriteJson(jw, this.Items, null);\n                return sw.GetStringBuilder().ToString();\n            }\n        }\n        private SelectedListItemCollection selectedItems;\n        /// <summary>\n        /// \n        /// </summary>\n        [Meta]\n        [PersistenceMode(PersistenceMode.InnerProperty)]\n        [ViewStateMember]\n        [Description(\"\")]\n        public SelectedListItemCollection SelectedItems\n        {\n            get\n            {\n                if (this.selectedItems == null)\n                {\n                    this.selectedItems = new SelectedListItemCollection();\n                }\n                return this.selectedItems;\n            }\n        }\n        /// <summary>\n        /// The underlying data field name to bind to this MultiSelect.\n        /// </summary>\n        [Meta]\n        [ConfigOption]\n        [Category(\"6. MultiSelect\")]\n        [DefaultValue(\"\")]\n        [Description(\"The underlying data field name to bind to this MultiSelect.\")]\n        public virtual string DisplayField\n        {\n            get\n            {\n                return (string)this.ViewState[\"DisplayField\"] ?? \"text\";\n            }\n            set\n            {\n                this.ViewState[\"DisplayField\"] = value;\n            }\n        }\n        /// <summary>\n        /// The underlying data value name to bind to this MultiSelect.\n        /// </summary>\n        [Meta]\n        [ConfigOption]\n        [Category(\"6. MultiSelect\")]\n        [DefaultValue(\"\")]\n        [Description(\"The underlying data value name to bind to this MultiSelect.\")]\n        public virtual string ValueField\n        {\n            get\n            {\n                return (string)this.ViewState[\"ValueField\"] ?? \"value\";\n            }\n            set\n            {\n                this.ViewState[\"ValueField\"] = value;\n            }\n        }\n        /// <summary>\n        /// False to validate that the value length > 0 (defaults to true).\n        /// </summary>\n        [Meta]\n        [ConfigOption]\n        [Category(\"6. MultiSelect\")]\n        [DefaultValue(true)]\n        [Description(\"False to validate that the value length > 0 (defaults to true).\")]\n        public virtual bool AllowBlank\n        {\n            get\n            {\n                object obj = this.ViewState[\"AllowBlank\"];\n                return (obj == null) ? true : (bool)obj;\n            }\n            set\n            {\n                this.ViewState[\"AllowBlank\"] = value;\n            }\n        }\n        /// <summary>\n        /// Maximum input field length allowed (defaults to Number.MAX_VALUE).\n        /// </summary>\n        [Meta]\n        [ConfigOption]\n        [Category(\"6. MultiSelect\")]\n        [DefaultValue(-1)]\n        [Description(\"Maximum input field length allowed (defaults to Number.MAX_VALUE).\")]\n        public virtual int MaxLength\n        {\n            get\n            {\n                object obj = this.ViewState[\"MaxLength\"];\n                return (obj == null) ? -1 : (int)obj;\n            }\n            set\n            {\n                this.ViewState[\"MaxLength\"] = value;\n            }\n        }\n        /// <summary>\n        /// Minimum input field length required (defaults to 0).\n        /// </summary>\n        [Meta]\n        [ConfigOption]\n        [Category(\"6. MultiSelect\")]\n        [DefaultValue(0)]\n        [Description(\"Minimum input field length required (defaults to 0).\")]\n        public virtual int MinLength\n        {\n            get\n            {\n                object obj = this.ViewState[\"MinLength\"];\n                return (obj == null) ? 0 : (int)obj;\n            }\n            set\n            {\n                this.ViewState[\"MinLength\"] = value;\n            }\n        }\n        /// <summary>\n        /// Error text to display if the maximum length validation fails (defaults to 'The maximum length for this field is {maxLength}').\n        /// </summary>\n        [Meta]\n        [ConfigOption]\n        [Category(\"6. MultiSelect\")]\n        [DefaultValue(\"\")]\n        [Localizable(true)]\n        [Description(\"Error text to display if the maximum length validation fails (defaults to 'The maximum length for this field is {maxLength}').\")]\n        public virtual string MaxLengthText\n        {\n            get\n            {\n                return (string)this.ViewState[\"MaxLengthText\"] ?? \"\";\n            }\n            set\n            {\n                this.ViewState[\"MaxLengthText\"] = value;\n            }\n        }\n        /// <summary>\n        /// Error text to display if the minimum length validation fails (defaults to 'The minimum length for this field is {minLength}').\n        /// </summary>\n        [Meta]\n        [ConfigOption]\n        [Category(\"6. MultiSelect\")]\n        [DefaultValue(\"\")]\n        [Localizable(true)]\n        [Description(\"Error text to display if the minimum length validation fails (defaults to 'The minimum length for this field is {minLength}').\")]\n        public virtual string MinLengthText\n        {\n            get\n            {\n                return (string)this.ViewState[\"MinLengthText\"] ?? \"\";\n            }\n            set\n            {\n                this.ViewState[\"MinLengthText\"] = value;\n            }\n        }\n        /// <summary>\n        /// Error text to display if the allow blank validation fails (defaults to 'This field is required').\n        /// </summary>\n        [Meta]\n        [ConfigOption]\n        [Category(\"6. MultiSelect\")]\n        [DefaultValue(\"\")]\n        [Localizable(true)]\n        [Description(\"Error text to display if the allow blank validation fails (defaults to 'This field is required').\")]\n        public virtual string BlankText\n        {\n            get\n            {\n                return (string)this.ViewState[\"BlankText\"] ?? \"\";\n            }\n            set\n            {\n                this.ViewState[\"BlankText\"] = value;\n            }\n        }\n        /// <summary>\n        /// Causes drag operations to copy nodes rather than move (defaults to false).\n        /// </summary>\n        [Meta]\n        [ConfigOption]\n        [Category(\"6. MultiSelect\")]\n        [DefaultValue(false)]\n        [Description(\"Causes drag operations to copy nodes rather than move (defaults to false).\")]\n        public virtual bool Copy\n        {\n            get\n            {\n                object obj = this.ViewState[\"Copy\"];\n                return (obj == null) ? false : (bool)obj;\n            }\n            set\n            {\n                this.ViewState[\"Copy\"] = value;\n            }\n        }\n        /// <summary>\n        /// \n        /// </summary>\n        [Meta]\n        [ConfigOption(\"allowDup\")]\n        [Category(\"6. MultiSelect\")]\n        [DefaultValue(false)]\n        [Description(\"\")]\n        public virtual bool AllowDuplicates\n        {\n            get\n            {\n                object obj = this.ViewState[\"AllowDuplicates\"];\n                return (obj == null) ? false : (bool)obj;\n            }\n            set\n            {\n                this.ViewState[\"AllowDuplicates\"] = value;\n            }\n        }\n        /// <summary>\n        /// \n        /// </summary>\n        [Meta]\n        [ConfigOption]\n        [Category(\"6. MultiSelect\")]\n        [DefaultValue(false)]\n        [Description(\"\")]\n        public virtual bool AllowTrash\n        {\n            get\n            {\n                object obj = this.ViewState[\"AllowTrash\"];\n                return (obj == null) ? false : (bool)obj;\n            }\n            set\n            {\n                this.ViewState[\"AllowTrash\"] = value;\n            }\n        }\n        /// <summary>\n        /// The title text to display in the panel header (defaults to '')\n        /// </summary>\n        [Meta]\n        [ConfigOption]\n        [Category(\"6. MultiSelect\")]\n        [DefaultValue(\"\")]\n        [Description(\"The title text to display in the panel header (defaults to '')\")]\n        public virtual string Legend\n        {\n            get\n            {\n                return (string)this.ViewState[\"Legend\"] ?? \"\";\n            }\n            set\n            {\n                this.ViewState[\"Legend\"] = value;\n            }\n        }\n        /// <summary>\n        /// The string used to delimit between items when set or returned as a string of values\n        /// </summary>\n        [Meta]\n        [ConfigOption]\n        [Category(\"6. MultiSelect\")]\n        [DefaultValue(\",\")]\n        [Description(\"The string used to delimit between items when set or returned as a string of values\")]\n        public virtual string Delimiter\n        {\n            get\n            {\n                return (string)this.ViewState[\"Delimiter\"] ?? \",\";\n            }\n            set\n            {\n                this.ViewState[\"Delimiter\"] = value;\n            }\n        }\n        /// <summary>\n        /// The ddgroup name(s) for the View's DragZone (defaults to undefined).\n        /// </summary>\n        [Meta]\n        [ConfigOption]\n        [Category(\"6. MultiSelect\")]\n        [DefaultValue(\"\")]\n        [Description(\"The ddgroup name(s) for the View's DragZone (defaults to undefined).\")]\n        public virtual string DragGroup\n        {\n            get\n            {\n                return (string)this.ViewState[\"DragGroup\"] ?? \"\";\n            }\n            set\n            {\n                this.ViewState[\"DragGroup\"] = value;\n            }\n        }\n        /// <summary>\n        /// The ddgroup name(s) for the View's DropZone (defaults to undefined).\n        /// </summary>\n        [Meta]\n        [ConfigOption]\n        [Category(\"6. MultiSelect\")]\n        [DefaultValue(\"\")]\n        [Description(\"The ddgroup name(s) for the View's DropZone (defaults to undefined).\")]\n        public virtual string DropGroup\n        {\n            get\n            {\n                return (string)this.ViewState[\"DropGroup\"] ?? \"\";\n            }\n            set\n            {\n                this.ViewState[\"DropGroup\"] = value;\n            }\n        }\n        /// <summary>\n        /// \n        /// </summary>\n        [Meta]\n        [ConfigOption]\n        [Category(\"6. MultiSelect\")]\n        [DefaultValue(false)]\n        [Description(\"\")]\n        public virtual bool AppendOnly\n        {\n            get\n            {\n                object obj = this.ViewState[\"AppendOnly\"];\n                return (obj == null) ? false : (bool)obj;\n            }\n            set\n            {\n                this.ViewState[\"AppendOnly\"] = value;\n            }\n        }\n        /// <summary>\n        /// \n        /// </summary>\n        [Meta]\n        [ConfigOption]\n        [Category(\"6. MultiSelect\")]\n        [DefaultValue(\"\")]\n        [Description(\"\")]\n        public virtual string SortField\n        {\n            get\n            {\n                return (string)this.ViewState[\"SortField\"] ?? \"\";\n            }\n            set\n            {\n                this.ViewState[\"SortField\"] = value;\n            }\n        }\n        /// <summary>\n        /// \n        /// </summary>\n        [Meta]\n        [ConfigOption(JsonMode.ToLower)]\n        [DefaultValue(SortDirection.ASC)]\n        [NotifyParentProperty(true)]\n        [Description(\"\")]\n        public SortDirection Direction\n        {\n            get\n            {\n                object obj = this.ViewState[\"Direction\"];\n                return (obj == null) ? SortDirection.ASC : (SortDirection)obj;\n            }\n            set\n            {\n                this.ViewState[\"Direction\"] = value;\n            }\n        }\n        /// <summary>\n        /// True to submit text of selected items\n        /// </summary>\n        [Meta]\n        [ConfigOption]\n        [Category(\"6. MultiSelect\")]\n        [DefaultValue(true)]\n        [Description(\"True to submit text of selected items\")]\n        public virtual bool SubmitText\n        {\n            get\n            {\n", "outputs": ["                object obj = this.ViewState[\"SubmitText\"];"], "input_length": 2731, "output_length": 10, "length": 2741, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "bea665a4bcef9ba937a9ef03e1bbfdf89039168caa0f47522995e6ee47f7c5e9"}
{"input": "", "context": "# encoding: utf-8\nimport ckan.logic as logic\nimport ckan.authz as authz\nimport ckan.logic.auth as logic_auth\nfrom ckan.common import _\n@logic.auth_allow_anonymous_access\ndef package_create(context, data_dict=None):\n    user = context['user']\n    if authz.auth_is_anon_user(context):\n        check1 = all(authz.check_config_permission(p) for p in (\n            'anon_create_dataset',\n            'create_dataset_if_not_in_organization',\n            'create_unowned_dataset',\n            ))\n    else:\n        check1 = all(authz.check_config_permission(p) for p in (\n            'create_dataset_if_not_in_organization',\n            'create_unowned_dataset',\n            )) or authz.has_user_permission_for_some_org(\n            user, 'create_dataset')\n    if not check1:\n        return {'success': False, 'msg': _('User %s not authorized to create packages') % user}\n    check2 = _check_group_auth(context,data_dict)\n    if not check2:\n        return {'success': False, 'msg': _('User %s not authorized to edit these groups') % user}\n    # If an organization is given are we able to add a dataset to it?\n    data_dict = data_dict or {}\n    org_id = data_dict.get('owner_org')\n    if org_id and not authz.has_user_permission_for_group_or_org(\n            org_id, user, 'create_dataset'):\n        return {'success': False, 'msg': _('User %s not authorized to add dataset to this organization') % user}\n    return {'success': True}\ndef file_upload(context, data_dict=None):\n    user = context['user']\n    if authz.auth_is_anon_user(context):\n        return {'success': False, 'msg': _('User %s not authorized to create packages') % user}\n    return {'success': True}\ndef resource_create(context, data_dict):\n    model = context['model']\n    user = context.get('user')\n    package_id = data_dict.get('package_id')\n    if not package_id and data_dict.get('id'):\n        # This can happen when auth is deferred, eg from `resource_view_create`\n        resource = logic_auth.get_resource_object(context, data_dict)\n        package_id = resource.package_id\n    if not package_id:\n        raise logic.NotFound(\n            _('No dataset id provided, cannot check auth.')\n        )\n    # check authentication against package\n    pkg = model.Package.get(package_id)\n    if not pkg:\n        raise logic.NotFound(\n            _('No package found for this resource, cannot check auth.')\n        )\n    pkg_dict = {'id': pkg.id}\n    authorized = authz.is_authorized('package_update', context, pkg_dict).get('success')\n    if not authorized:\n        return {'success': False,\n                'msg': _('User %s not authorized to create resources on dataset %s') %\n                        (str(user), package_id)}\n    else:\n        return {'success': True}\ndef resource_view_create(context, data_dict):\n    return authz.is_authorized('resource_create', context, {'id': data_dict['resource_id']})\ndef resource_create_default_resource_views(context, data_dict):\n    return authz.is_authorized('resource_create', context, {'id': data_dict['resource']['id']})\ndef package_create_default_resource_views(context, data_dict):\n    return authz.is_authorized('package_update', context,\n                               data_dict['package'])\ndef package_relationship_create(context, data_dict):\n    user = context['user']\n    id = data_dict['subject']\n    id2 = data_dict['object']\n    # If we can update each package we can see the relationships\n    authorized1 = authz.is_authorized_boolean(\n        'package_update', context, {'id': id})\n    authorized2 = authz.is_authorized_boolean(\n        'package_update', context, {'id': id2})\n    if not authorized1 and authorized2:\n        return {'success': False, 'msg': _('User %s not authorized to edit these packages') % user}\n    else:\n        return {'success': True}\ndef group_create(context, data_dict=None):\n    user = context['user']\n    user = authz.get_user_id_for_username(user, allow_none=True)\n    if user and authz.check_config_permission('user_create_groups'):\n        return {'success': True}\n    return {'success': False,\n            'msg': _('User %s not authorized to create groups') % user}\ndef organization_create(context, data_dict=None):\n    user = context['user']\n    user = authz.get_user_id_for_username(user, allow_none=True)\n    if user and authz.check_config_permission('user_create_organizations'):\n        return {'success': True}\n    return {'success': False,\n            'msg': _('User %s not authorized to create organizations') % user}\ndef rating_create(context, data_dict):\n    # No authz check in the logic function\n    return {'success': True}\n@logic.auth_allow_anonymous_access\ndef user_create(context, data_dict=None):\n    using_api = 'api_version' in context\n    create_user_via_api = authz.check_config_permission(\n            'create_user_via_api')\n    create_user_via_web = authz.check_config_permission(\n            'create_user_via_web')\n    if using_api and not create_user_via_api:\n        return {'success': False, 'msg': _('User {user} not authorized to '\n            'create users via the API').format(user=context.get('user'))}\n    if not using_api and not create_user_via_web:\n        return {'success': False, 'msg': _('Not authorized to '\n            'create users')}\n    return {'success': True}\ndef user_invite(context, data_dict):\n    data_dict['id'] = data_dict['group_id']\n    return group_member_create(context, data_dict)\ndef _check_group_auth(context, data_dict):\n    '''Has this user got update permission for all of the given groups?\n    If there is a package in the context then ignore that package's groups.\n    (owner_org is checked elsewhere.)\n    :returns: False if not allowed to update one (or more) of the given groups.\n              True otherwise. i.e. True is the default. A blank data_dict\n              mentions no groups, so it returns True.\n    '''\n    # FIXME This code is shared amoung other logic.auth files and should be\n    # somewhere better\n    if not data_dict:\n        return True\n    model = context['model']\n    user = context['user']\n    pkg = context.get(\"package\")\n    api_version = context.get('api_version') or '1'\n    group_blobs = data_dict.get('groups', [])\n    groups = set()\n    for group_blob in group_blobs:\n        # group_blob might be a dict or a group_ref\n        if isinstance(group_blob, dict):\n            # use group id by default, but we can accept name as well\n            id = group_blob.get('id') or group_blob.get('name')\n            if not id:\n                continue\n        else:\n            id = group_blob\n        grp = model.Group.get(id)\n        if grp is None:\n            raise logic.NotFound(_('Group was not found.'))\n        groups.add(grp)\n    if pkg:\n        pkg_groups = pkg.get_groups()\n        groups = groups - set(pkg_groups)\n    for group in groups:\n        if not authz.has_user_permission_for_group_or_org(group.id, user, 'update'):\n            return False\n    return True\n## Modifications for rest api\ndef package_create_rest(context, data_dict):\n    model = context['model']\n    user = context['user']\n    if not user:\n        return {'success': False, 'msg': _('Valid API key needed to create a package')}\n    return authz.is_authorized('package_create', context, data_dict)\ndef group_create_rest(context, data_dict):\n    model = context['model']\n    user = context['user']\n    if not user:\n        return {'success': False, 'msg': _('Valid API key needed to create a group')}\n    return authz.is_authorized('group_create', context, data_dict)\ndef vocabulary_create(context, data_dict):\n    # sysadmins only\n    return {'success': False}\ndef activity_create(context, data_dict):\n    # sysadmins only\n    return {'success': False}\ndef tag_create(context, data_dict):\n    # sysadmins only\n    return {'success': False}\ndef _group_or_org_member_create(context, data_dict):\n    user = context['user']\n", "outputs": ["    group_id = data_dict['id']"], "input_length": 1438, "output_length": 7, "length": 1445, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "973b9bcc0069769ff9e455e52b350d980a692cb62348aa60fce2b9c99a4ce128"}
{"input": "", "context": "//#############################################################################\n//#                                                                           #\n//#  Copyright (C) <2014>  <IMS MAXIMS>                                       #\n//#                                                                           #\n//#  This program is free software: you can redistribute it and/or modify     #\n//#  it under the terms of the GNU Affero General Public License as           #\n//#  published by the Free Software Foundation, either version 3 of the       #\n//#  License, or (at your option) any later version.                          # \n//#                                                                           #\n//#  This program is distributed in the hope that it will be useful,          #\n//#  but WITHOUT ANY WARRANTY; without even the implied warranty of           #\n//#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the            #\n//#  GNU Affero General Public License for more details.                      #\n//#                                                                           #\n//#  You should have received a copy of the GNU Affero General Public License #\n//#  along with this program.  If not, see <http://www.gnu.org/licenses/>.    #\n//#                                                                           #\n//#############################################################################\n//#EOH\n// This code was generated by Daniel Laffan using IMS Development Environment (version 1.65 build 3163.31063)\n// Copyright (C) 1995-2008 IMS MAXIMS plc. All rights reserved.\npackage ims.ocrr.forms.investigationscomponent;\nimport ims.ocrr.forms.investigationscomponent.GenForm.grdResultsRow;\nimport ims.ocrr.forms.investigationscomponent.GenForm.grdResultsRowCollection;\nimport ims.configuration.gen.ConfigFlag;\nimport ims.domain.exceptions.DomainInterfaceException;\nimport ims.framework.exceptions.CodingRuntimeException;\nimport ims.framework.utils.Color;\nimport ims.framework.utils.Date;\nimport ims.framework.utils.DateTime;\nimport ims.framework.utils.Image;\nimport ims.ocrr.vo.OcsPathRadResultVo;\nimport ims.ocrr.vo.OcsPathRadResultVoCollection;\nimport ims.ocrr.vo.OrderInvestigationLiteVo;\nimport ims.ocrr.vo.OrderInvestigationLiteVoCollection;\nimport ims.ocrr.vo.OrderSpecimenLiteVo;\nimport ims.ocrr.vo.OrderSpecimenLiteVoCollection;\nimport ims.ocrr.vo.OrderedInvestigationStatusVo;\nimport ims.ocrr.vo.lookups.OrderInvStatus;\npublic class Logic extends BaseLogic\n{\n\tprivate static final long\tserialVersionUID\t= 1L;\n\t//-----------------------------------------------------------------------------------------------------------------------------------------\n\t//\tComponent interface methods below here\n\t//-----------------------------------------------------------------------------------------------------------------------------------------\n\t/**\n\t * WDEV-13944\n\t * Initialise component (decide to list investigation for selected referral or all referrals) \n\t */\n\tpublic void initialise(Boolean canViewConfidentialInvsResults, Boolean canViewConfidentialInvsOrdered)\n\t{\n\t\tif(canViewConfidentialInvsOrdered == null || canViewConfidentialInvsResults == null)\n\t\t\tthrow new CodingRuntimeException(\"mandatory params are null in method initialise\");\n\t\t\n\t\tform.getLocalContext().setcanViewConfidentialInvsResults(canViewConfidentialInvsResults);\n\t\tform.getLocalContext().setcanViewConfidentialInvsOrdered(canViewConfidentialInvsOrdered);\n\t\t\n\t\t\n\t\tpopulateScreenFromData();\n\t}\n\t\n\t//-----------------------------------------------------------------------------------------------------------------------------------------\n\t\n\tprotected void onFormOpen(Object[] args) throws ims.framework.exceptions.PresentationLogicException\n\t{\n\t\n\t}\n\t/**\n\t * WDEV-13944\n\t * Function used to populate screen with investigation\n\t * Component might be used in more than one form - that is why is populating based on parameter\n\t */\n\tprivate void populateScreenFromData()\n\t{\n\t\tform.grdResults().getRows().clear();\n\t\tform.grdResults().setReadOnly(false);\n\t\tOrderInvestigationLiteVoCollection results;\n\t\ttry\n\t\t{\n\t\t\tresults = domain.listResults(form.getGlobalContext().Core.getPatientShort());\t\t\t\t\t\t\n\t\t}\n\t\tcatch (DomainInterfaceException e)\n\t\t{\n\t\t\tupdateTotal();\n\t\t\tengine.showMessage(e.getMessage());\n\t\t\treturn;\n\t\t}\n\t\tif (results == null || results.size() == 0)\n\t\t{\n\t\t\tupdateTotal();\n\t\t\treturn;\n\t\t}\n\t\tInteger nNewResUnseenDays = new Integer(ConfigFlag.DOM.OCS_NEWRES_UNSEEN_CUTOFF.getValue());\n\t\tDate dateUnseen = new Date().addDay(-1 * nNewResUnseenDays.intValue());\n\t\tfor (int x = 0; x < results.size(); x++)\n\t\t{\n\t\t\taddResult(results.get(x), dateUnseen);\n\t\t}\n\t\tcleanUpResultGrid();\n\t\tupdateTotal();\n\t}\n\tprivate void updateTotal()\n\t{\n\t\tStringBuffer total = new StringBuffer();\n\t\ttotal.append(\"<b>\");\n\t\ttotal.append(\"Total: \");\n\t\ttotal.append(form.grdResults().getRows().size());\n\t\ttotal.append(\"</b>\");\n\t\tform.grdResults().setFooterValue(total.toString());\n\t}\n\t/**\n\t * if there are any parent rows with no children - remove them ie. there are\n\t * no viewable results for this specimen - WDEV-3953\n\t */\n\tprivate void cleanUpResultGrid()\n\t{\n\t\tgrdResultsRow pRow;\n\t\tfor (int i = form.grdResults().getRows().size(); i > 0; i--)\n\t\t{\n\t\t\tpRow = form.grdResults().getRows().get(i - 1);\n\t\t\tif (pRow.getRows().size() == 0 && pRow.getColTestName() == null)\n\t\t\t\tform.grdResults().getRows().remove(i - 1);\n\t\t}\n\t}\n\tprivate void addResult(OrderInvestigationLiteVo orderInvestigationLiteVo, Date dateUnseen)\n\t{\n\t\tif (orderInvestigationLiteVo == null)\n\t\t\treturn;\n\t\t// WDEV-3953\n\t\t/*boolean isConfidentialInv = orderInvestigationLiteVo.getInvestigationIsNotNull() && orderInvestigationLiteVo.getInvestigation().getInvestigationIndexIsNotNull() && orderInvestigationLiteVo.getInvestigation().getInvestigationIndex().getConfidentialTestIsNotNull() && orderInvestigationLiteVo.getInvestigation().getInvestigationIndex().getConfidentialTest().booleanValue();\n\t\tif (isConfidentialInv)\n\t\t{\n\t\t\tif (!form.getLocalContext().getcanViewConfidentialInvsOrdered())\n\t\t\t{\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tif (orderInvestigationLiteVo.getPathResultDetailsIsNotNull() || orderInvestigationLiteVo.getRadReportingDetailsIsNotNull())\n\t\t\t{\n\t\t\t\tif (!form.getLocalContext().getcanViewConfidentialInvsResults())\n\t\t\t\t{\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t}*/\n\t\tgrdResultsRow parentRow = createOrFindSpecimenGridRow(orderInvestigationLiteVo);\n\t\tif (parentRow == null)\n\t\t\treturn;\n\t\tgrdResultsRow row = null;\n\t\tif (parentRow.getColTestName() == null)\n\t\t\trow = parentRow;\n\t\telse\n\t\t{\n\t\t\trow = parentRow.getRows().newRow();\n\t\t\trow.setSelectable(false);\n\t\t}\n\t\tOcsPathRadResultVo res = new OcsPathRadResultVo();\n\t\tif(orderInvestigationLiteVo.getInvestigationIsNotNull() && orderInvestigationLiteVo.getInvestigation().getInvestigationIndexIsNotNull())\n\t\t\tres.setCategory(orderInvestigationLiteVo.getInvestigation().getInvestigationIndex().getCategory());\n\t\tres.setOrderInvestigation(orderInvestigationLiteVo);\n\t\trow.setValue(res);\n\t\t// Test Name\n\t\tif (orderInvestigationLiteVo.getInvestigationIsNotNull() && orderInvestigationLiteVo.getInvestigation().getInvestigationIndexIsNotNull() && orderInvestigationLiteVo.getInvestigation().getInvestigationIndex().getNameIsNotNull())\n\t\t{\n\t\t\trow.setColTestName(orderInvestigationLiteVo.getInvestigation().getInvestigationIndex().getName());\n\t\t}\n\t\t// ABN\n\t\t// WDEV-16224 - modifications following OCS DFT model changes\n\t\tif (orderInvestigationLiteVo.getResultDetailsIsNotNull() && orderInvestigationLiteVo.getResultDetails().getPathologyResultDetailsIsNotNull())\n\t\t{\n\t\t\tfor (int i=0; i<orderInvestigationLiteVo.getResultDetails().getPathologyResultDetails().size(); i++)\n\t\t\t{\n\t\t\t\tif (orderInvestigationLiteVo.getResultDetails().getPathologyResultDetails().get(i).getIsAbnormalIsNotNull() && orderInvestigationLiteVo.getResultDetails().getPathologyResultDetails().get(i).getIsAbnormal().booleanValue())\n\t\t\t\t{\n\t\t\t\t\trow.setColABN(form.getImages().Core.CriticalError);\n\t\t\t\t\trow.setTooltipForColABN(\"Abnormal Result\");\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t// Status\n\t\tif (orderInvestigationLiteVo.getOrdInvCurrentStatusIsNotNull() && orderInvestigationLiteVo.getOrdInvCurrentStatus().getOrdInvStatusIsNotNull())\n\t\t{\n\t\t\tOrderInvStatus currStat = orderInvestigationLiteVo.getOrdInvCurrentStatus().getOrdInvStatus();\n\t\t\tImage image = currStat.getImage();\n\t\t\tString szTooltip = generateStatusTooltip(orderInvestigationLiteVo.getOrdInvCurrentStatus());\n\t\t\tif (orderInvestigationLiteVo.getRepDateTimeIsNotNull() && dateUnseen != null)\n\t\t\t{\n\t\t\t\tif (currStat.equals(OrderInvStatus.NEW_RESULT) || currStat.equals(OrderInvStatus.UPDATED_RESULT))\n\t\t\t\t{\n\t\t\t\t\tif (orderInvestigationLiteVo.getRepDateTime().getDate().isLessThan(dateUnseen))\n\t\t\t\t\t{\n\t\t\t\t\t\trow.setBold(true);\n\t\t\t\t\t\tszTooltip = (szTooltip + \"<br>Unseen\");\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse if (currStat.equals(OrderInvStatus.REVIEW))\n\t\t\t\t{\n\t\t\t\t\tif (orderInvestigationLiteVo.getOrdInvCurrentStatus().getChangeDateTime().getDate().isLessThan(dateUnseen))\n\t\t\t\t\t{\n\t\t\t\t\t\trow.setBold(true);\n\t\t\t\t\t\tszTooltip = (szTooltip + \"<br>Requires Attention\");\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t\tszTooltip = (szTooltip + \"<br>\" + OrderInvStatus.REVIEW.toString());\n\t\t\t\t}\n\t\t\t}\n\t\t\trow.setColStatus(image);\n\t\t\trow.setTooltipForColStatus(szTooltip);\n\t\t\t\n\t\t\tif(orderInvestigationLiteVo.getOrdInvCurrentStatusIsNotNull() && orderInvestigationLiteVo.getOrdInvCurrentStatus().getOrdInvStatusIsNotNull()\n\t\t\t\t\t&& (orderInvestigationLiteVo.getOrdInvCurrentStatus().getOrdInvStatus().equals(OrderInvStatus.CANCEL_REQUEST)\n\t\t\t\t\t\t\t|| orderInvestigationLiteVo.getOrdInvCurrentStatus().getOrdInvStatus().equals(OrderInvStatus.CANCELLED)))\n\t\t\t\trow.setBackColor(ConfigFlag.UI.CANCELLED_INVESTIGATION_ROW_COLOUR.getValue());\n\t\t\telse\n\t\t\t\trow.setBackColor(parentRow.getBackColor());\n\t\t\t\n\t\t\trow.setReadOnly(false);\n\t\t}\n\t}\n\tprivate grdResultsRow createOrFindSpecimenGridRow(OrderInvestigationLiteVo orderInvestigationLiteVo)\n\t{\n", "outputs": ["\t\tif (orderInvestigationLiteVo == null)"], "input_length": 1698, "output_length": 6, "length": 1704, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "0b4e20ca1aaba76f72afc159417738904c89c429a19acc6f7e7b73855918b2dc"}
{"input": "", "context": "/*\n  KeePass Password Safe - The Open-Source Password Manager\n  Copyright (C) 2003-2019 Dominik Reichl <dominik.reichl@t-online.de>\n  This program is free software; you can redistribute it and/or modify\n  it under the terms of the GNU General Public License as published by\n  the Free Software Foundation; either version 2 of the License, or\n  (at your option) any later version.\n  This program is distributed in the hope that it will be useful,\n  but WITHOUT ANY WARRANTY; without even the implied warranty of\n  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n  GNU General Public License for more details.\n  You should have received a copy of the GNU General Public License\n  along with this program; if not, write to the Free Software\n  Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA\n*/\nusing System;\nusing System.Collections.Generic;\nusing System.ComponentModel;\nusing System.Diagnostics;\nusing System.IO;\nusing System.Text;\nusing System.Xml;\nusing System.Xml.Serialization;\n#if !KeePassUAP\nusing System.Drawing;\nusing System.Windows.Forms;\n#endif\n#if KeePassLibSD\nusing ICSharpCode.SharpZipLib.GZip;\n#else\nusing System.IO.Compression;\n#endif\nusing KeePassLib.Interfaces;\nusing KeePassLib.Utility;\nnamespace KeePassLib.Translation\n{\n\t[XmlRoot(\"Translation\")]\n\tpublic sealed class KPTranslation\n\t{\n\t\tpublic static readonly string FileExtension = \"lngx\";\n\t\tprivate KPTranslationProperties m_props = new KPTranslationProperties();\n\t\tpublic KPTranslationProperties Properties\n\t\t{\n\t\t\tget { return m_props; }\n\t\t\tset\n\t\t\t{\n\t\t\t\tif(value == null) throw new ArgumentNullException(\"value\");\n\t\t\t\tm_props = value;\n\t\t\t}\n\t\t}\n\t\tprivate List<KPStringTable> m_vStringTables = new List<KPStringTable>();\n\t\t[XmlArrayItem(\"StringTable\")]\n\t\tpublic List<KPStringTable> StringTables\n\t\t{\n\t\t\tget { return m_vStringTables; }\n\t\t\tset\n\t\t\t{\n\t\t\t\tif(value == null) throw new ArgumentNullException(\"value\");\n\t\t\t\tm_vStringTables = value;\n\t\t\t}\n\t\t}\n\t\tprivate List<KPFormCustomization> m_vForms = new List<KPFormCustomization>();\n\t\t[XmlArrayItem(\"Form\")]\n\t\tpublic List<KPFormCustomization> Forms\n\t\t{\n\t\t\tget { return m_vForms; }\n\t\t\tset\n\t\t\t{\n\t\t\t\tif(value == null) throw new ArgumentNullException(\"value\");\n\t\t\t\tm_vForms = value;\n\t\t\t}\n\t\t}\n\t\tprivate string m_strUnusedText = string.Empty;\n\t\t[DefaultValue(\"\")]\n\t\tpublic string UnusedText\n\t\t{\n\t\t\tget { return m_strUnusedText; }\n\t\t\tset\n\t\t\t{\n\t\t\t\tif(value == null) throw new ArgumentNullException(\"value\");\n\t\t\t\tm_strUnusedText = value;\n\t\t\t}\n\t\t}\n\t\tpublic static void Save(KPTranslation kpTrl, string strFileName,\n\t\t\tIXmlSerializerEx xs)\n\t\t{\n\t\t\tusing(FileStream fs = new FileStream(strFileName, FileMode.Create,\n\t\t\t\tFileAccess.Write, FileShare.None))\n\t\t\t{\n\t\t\t\tSave(kpTrl, fs, xs);\n\t\t\t}\n\t\t}\n\t\tpublic static void Save(KPTranslation kpTrl, Stream sOut,\n\t\t\tIXmlSerializerEx xs)\n\t\t{\n\t\t\tif(xs == null) throw new ArgumentNullException(\"xs\");\n#if !KeePassLibSD\n\t\t\tusing(GZipStream gz = new GZipStream(sOut, CompressionMode.Compress))\n#else\n\t\t\tusing(GZipOutputStream gz = new GZipOutputStream(sOut))\n#endif\n\t\t\t{\n\t\t\t\tusing(XmlWriter xw = XmlUtilEx.CreateXmlWriter(gz))\n\t\t\t\t{\n\t\t\t\t\txs.Serialize(xw, kpTrl);\n\t\t\t\t}\n\t\t\t}\n\t\t\tsOut.Close();\n\t\t}\n\t\tpublic static KPTranslation Load(string strFile, IXmlSerializerEx xs)\n\t\t{\n\t\t\tKPTranslation kpTrl = null;\n\t\t\tusing(FileStream fs = new FileStream(strFile, FileMode.Open,\n\t\t\t\tFileAccess.Read, FileShare.Read))\n\t\t\t{\n\t\t\t\tkpTrl = Load(fs, xs);\n\t\t\t}\n\t\t\treturn kpTrl;\n\t\t}\n\t\tpublic static KPTranslation Load(Stream s, IXmlSerializerEx xs)\n\t\t{\n\t\t\tif(xs == null) throw new ArgumentNullException(\"xs\");\n\t\t\tKPTranslation kpTrl = null;\n#if !KeePassLibSD\n\t\t\tusing(GZipStream gz = new GZipStream(s, CompressionMode.Decompress))\n#else\n\t\t\tusing(GZipInputStream gz = new GZipInputStream(s))\n#endif\n\t\t\t{\n\t\t\t\tkpTrl = (xs.Deserialize(gz) as KPTranslation);\n\t\t\t}\n\t\t\ts.Close();\n\t\t\treturn kpTrl;\n\t\t}\n\t\tpublic Dictionary<string, string> SafeGetStringTableDictionary(\n\t\t\tstring strTableName)\n\t\t{\n\t\t\tforeach(KPStringTable kpst in m_vStringTables)\n\t\t\t{\n\t\t\t\tif(kpst.Name == strTableName) return kpst.ToDictionary();\n\t\t\t}\n\t\t\treturn new Dictionary<string, string>();\n\t\t}\n#if (!KeePassLibSD && !KeePassUAP)\n\t\tpublic void ApplyTo(Form form)\n\t\t{\n\t\t\tif(form == null) throw new ArgumentNullException(\"form\");\n\t\t\tif(m_props.RightToLeft)\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\tform.RightToLeft = RightToLeft.Yes;\n\t\t\t\t\tform.RightToLeftLayout = true;\n\t\t\t\t}\n\t\t\t\tcatch(Exception) { Debug.Assert(false); }\n\t\t\t}\n\t\t\tstring strTypeName = form.GetType().FullName;\n\t\t\tforeach(KPFormCustomization kpfc in m_vForms)\n\t\t\t{\n\t\t\t\tif(kpfc.FullName == strTypeName)\n\t\t\t\t{\n\t\t\t\t\tkpfc.ApplyTo(form);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif(m_props.RightToLeft)\n\t\t\t{\n", "outputs": ["\t\t\t\ttry { RtlApplyToControls(form.Controls); }"], "input_length": 850, "output_length": 8, "length": 858, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "c47d2de603172d05647cc10cad3b8a64be1ee56c0b4c09bf59d59391ad07acfd"}
{"input": "", "context": "using UnityCMF.CCore;\nusing UnityCMF.ECore;\n// PROTECTED REGION ID(ETypedElement.Namespaces) ENABLED START\n// PROTECTED REGION END\nnamespace UnityCMF.ECore {\n\tpublic interface ETypedElement : EModelElement,ENamedElement {\n\t\tbool Ordered { get; set; }\n\t\tvoid SetOrdered(bool value, object data);\n\t\tbool Unique { get; set; }\n\t\tvoid SetUnique(bool value, object data);\n\t\tint LowerBound { get; set; }\n\t\tvoid SetLowerBound(int value, object data);\n\t\tint UpperBound { get; set; }\n\t\tvoid SetUpperBound(int value, object data);\n\t\tbool Many { get;  }\n\t\tbool Required { get;  }\n\t\tEClassifier EType { get; set; }\n\t\tvoid SetEType(EClassifier value, object data);\n\t\tEGenericType EGenericType { get; set; }\n\t\tvoid SetEGenericType(EGenericType value, object data);\n\t\t\n\t\t\n\t}\n\tpublic class ETypedElementImpl : ENamedElementImpl, ETypedElement {\n\t\n\t\tpublic ETypedElementImpl(UnityCMF.ECore.EClass eClass) : base(eClass) {\n\t\t\t// PROTECTED REGION ID(ETypedElement.Constructor) ENABLED START\n\t\n\t\t\t// PROTECTED REGION END\n\t\t}\n\t\t\n\t\t#region client code\n\t\t// PROTECTED REGION ID(ETypedElement.ClientCode) ENABLED START\n\t\n\t\t// PROTECTED REGION END\n\t\t#endregion\t\t\t\t\n\t\n\t\t#region derived features and operations\n\t\tpublic  bool Many {\n\t\t\tget {\n\t\t\t\t// PROTECTED REGION ID(ETypedElement.Many) ENABLED START\n\t\t\t\treturn UpperBound == -1 || UpperBound > 1;\n\t\t\t\t// PROTECTED REGION END\n\t\t\t}\n\t\t}\n\t\t\n\t\tpublic  bool Required {\n\t\t\tget {\n\t\t\t\t// PROTECTED REGION ID(ETypedElement.Required) ENABLED START\n\t\t\t\treturn default(bool);\n\t\t\t\t// PROTECTED REGION END\n\t\t\t}\n\t\t}\n\t\t\n\t\t\n\t\t#endregion\n\t\t\n\t\tprivate bool _ordered;\n\t\tpublic  bool Ordered {\n\t\t\tget {\n\t\t\t\treturn _ordered;\n\t\t\t}\n\t\t\tset {\n\t\t\t\tbool oldValue = _ordered;\n\t\t\t\t_ordered = value;\n\t\t\t\tif (CNotificationRequired(ECoreMeta.cINSTANCE.Package.ETypedElement_Ordered)) {\n\t\t\t\t\tCNotify(new CAction(this, CActionType.SET, ECoreMeta.cINSTANCE.Package.ETypedElement_Ordered, oldValue, value, -1, null));\n\t\t\t\t}\t\n\t\t\t}\n\t\t}\n\t\tpublic  void SetOrdered(bool value, object data) {\n\t\t\tbool oldValue = _ordered;\n\t\t\t_ordered = value;\n\t\t\tif (CNotificationRequired(ECoreMeta.cINSTANCE.Package.ETypedElement_Ordered)) {\n\t\t\t\tCNotify(new CAction(this, CActionType.SET, ECoreMeta.cINSTANCE.Package.ETypedElement_Ordered, oldValue, value, -1, data));\n\t\t\t}\n\t\t}\n\t\t\n\t\tprivate bool _unique;\n\t\tpublic  bool Unique {\n\t\t\tget {\n\t\t\t\treturn _unique;\n\t\t\t}\n\t\t\tset {\n\t\t\t\tbool oldValue = _unique;\n\t\t\t\t_unique = value;\n\t\t\t\tif (CNotificationRequired(ECoreMeta.cINSTANCE.Package.ETypedElement_Unique)) {\n\t\t\t\t\tCNotify(new CAction(this, CActionType.SET, ECoreMeta.cINSTANCE.Package.ETypedElement_Unique, oldValue, value, -1, null));\n\t\t\t\t}\t\n\t\t\t}\n\t\t}\n\t\tpublic  void SetUnique(bool value, object data) {\n\t\t\tbool oldValue = _unique;\n\t\t\t_unique = value;\n\t\t\tif (CNotificationRequired(ECoreMeta.cINSTANCE.Package.ETypedElement_Unique)) {\n\t\t\t\tCNotify(new CAction(this, CActionType.SET, ECoreMeta.cINSTANCE.Package.ETypedElement_Unique, oldValue, value, -1, data));\n\t\t\t}\n\t\t}\n\t\t\n\t\tprivate int _lowerBound;\n\t\tpublic  int LowerBound {\n\t\t\tget {\n\t\t\t\treturn _lowerBound;\n\t\t\t}\n\t\t\tset {\n\t\t\t\tint oldValue = _lowerBound;\n\t\t\t\t_lowerBound = value;\n\t\t\t\tif (CNotificationRequired(ECoreMeta.cINSTANCE.Package.ETypedElement_LowerBound)) {\n\t\t\t\t\tCNotify(new CAction(this, CActionType.SET, ECoreMeta.cINSTANCE.Package.ETypedElement_LowerBound, oldValue, value, -1, null));\n\t\t\t\t}\t\n\t\t\t}\n\t\t}\n\t\tpublic  void SetLowerBound(int value, object data) {\n\t\t\tint oldValue = _lowerBound;\n\t\t\t_lowerBound = value;\n\t\t\tif (CNotificationRequired(ECoreMeta.cINSTANCE.Package.ETypedElement_LowerBound)) {\n\t\t\t\tCNotify(new CAction(this, CActionType.SET, ECoreMeta.cINSTANCE.Package.ETypedElement_LowerBound, oldValue, value, -1, data));\n\t\t\t}\n\t\t}\n\t\t\n\t\tprivate int _upperBound;\n\t\tpublic  int UpperBound {\n\t\t\tget {\n\t\t\t\treturn _upperBound;\n\t\t\t}\n\t\t\tset {\n\t\t\t\tint oldValue = _upperBound;\n\t\t\t\t_upperBound = value;\n\t\t\t\tif (CNotificationRequired(ECoreMeta.cINSTANCE.Package.ETypedElement_UpperBound)) {\n\t\t\t\t\tCNotify(new CAction(this, CActionType.SET, ECoreMeta.cINSTANCE.Package.ETypedElement_UpperBound, oldValue, value, -1, null));\n\t\t\t\t}\t\n\t\t\t}\n\t\t}\n\t\tpublic  void SetUpperBound(int value, object data) {\n\t\t\tint oldValue = _upperBound;\n\t\t\t_upperBound = value;\n\t\t\tif (CNotificationRequired(ECoreMeta.cINSTANCE.Package.ETypedElement_UpperBound)) {\n\t\t\t\tCNotify(new CAction(this, CActionType.SET, ECoreMeta.cINSTANCE.Package.ETypedElement_UpperBound, oldValue, value, -1, data));\n\t\t\t}\n\t\t}\n\t\t\n\t\tprivate EClassifier _eType;\n\t\tpublic  EClassifier EType {\n\t\t\tget {\n\t\t\t\treturn _eType;\n\t\t\t}\n\t\t\tset {\n\t\t\t\tEClassifier oldValue = _eType;\n\t\t\t\t_eType = value;\n\t\t\t\tif (CNotificationRequired(ECoreMeta.cINSTANCE.Package.ETypedElement_EType)) {\n\t\t\t\t\tCNotify(new CAction(this, CActionType.SET, ECoreMeta.cINSTANCE.Package.ETypedElement_EType, oldValue, value, -1, null));\n\t\t\t\t}\t\n\t\t\t}\n\t\t}\n\t\tpublic  void SetEType(EClassifier value, object data) {\n\t\t\tEClassifier oldValue = _eType;\n\t\t\t_eType = value;\n\t\t\tif (CNotificationRequired(ECoreMeta.cINSTANCE.Package.ETypedElement_EType)) {\n\t\t\t\tCNotify(new CAction(this, CActionType.SET, ECoreMeta.cINSTANCE.Package.ETypedElement_EType, oldValue, value, -1, data));\n\t\t\t}\n\t\t}\n\t\t\n\t\tprivate EGenericType _eGenericType;\n\t\tpublic  EGenericType EGenericType {\n\t\t\tget {\n\t\t\t\treturn _eGenericType;\n\t\t\t}\n\t\t\tset {\n\t\t\t\tEGenericType oldValue = _eGenericType;\n\t\t\t\t_eGenericType = value;\n\t\t\t\tif (oldValue != null) (oldValue as CObjectImpl).CContainer = null;\n\t\t\t\tif (value != null) (value as CObjectImpl).CContainer = this;\n\t\t\t\tif (CNotificationRequired(ECoreMeta.cINSTANCE.Package.ETypedElement_EGenericType)) {\n\t\t\t\t\tCNotify(new CAction(this, CActionType.SET, ECoreMeta.cINSTANCE.Package.ETypedElement_EGenericType, oldValue, value, -1, null));\n\t\t\t\t}\t\n\t\t\t}\n\t\t}\n\t\tpublic  void SetEGenericType(EGenericType value, object data) {\n\t\t\tEGenericType oldValue = _eGenericType;\n\t\t\t_eGenericType = value;\n\t\t\tif (oldValue != null) (oldValue as CObjectImpl).CContainer = null;\n\t\t\tif (value != null) (value as CObjectImpl).CContainer = this;\n\t\t\tif (CNotificationRequired(ECoreMeta.cINSTANCE.Package.ETypedElement_EGenericType)) {\n\t\t\t\tCNotify(new CAction(this, CActionType.SET, ECoreMeta.cINSTANCE.Package.ETypedElement_EGenericType, oldValue, value, -1, data));\n\t\t\t}\n\t\t}\n\t\t\n\t\t\n\t\tpublic override void CSet(EStructuralFeature feature, object value) {\n\t\t\tswitch(feature.Name) {\n\t\t\t\tcase \"ordered\" : \n\t\t\t\t\tOrdered = (bool)value;\n\t\t\t\t\tbreak;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\tcase \"unique\" : \n\t\t\t\t\tUnique = (bool)value;\n\t\t\t\t\tbreak;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\tcase \"lowerBound\" : \n\t\t\t\t\tLowerBound = (int)value;\n\t\t\t\t\tbreak;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\tcase \"upperBound\" : \n\t\t\t\t\tUpperBound = (int)value;\n\t\t\t\t\tbreak;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\tcase \"eType\" : \n", "outputs": ["\t\t\t\t\tEType = (EClassifier)value;"], "input_length": 1059, "output_length": 7, "length": 1066, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "87a9c3c7a5e4f3e9ae05ddf7a422d1682e725eba25dba2b4ad2fda79e5ca027b"}
{"input": "", "context": "import json\nimport os\nimport re\nfrom collections import defaultdict\nfrom six import iteritems, itervalues, viewkeys\nfrom .item import ManualTest, WebdriverSpecTest, Stub, RefTestNode, RefTest, TestharnessTest, SupportFile, ConformanceCheckerTest, VisualTest\nfrom .log import get_logger\nfrom .utils import from_os_path, to_os_path, rel_path_to_url\nCURRENT_VERSION = 4\nclass ManifestError(Exception):\n    pass\nclass ManifestVersionMismatch(ManifestError):\n    pass\ndef sourcefile_items(args):\n    tests_root, url_base, rel_path, status = args\n    source_file = SourceFile(tests_root,\n                             rel_path,\n                             url_base)\n    return rel_path, source_file.manifest_items()\nclass Manifest(object):\n    def __init__(self, url_base=\"/\"):\n        assert url_base is not None\n        self._path_hash = {}\n        self._data = defaultdict(dict)\n        self._reftest_nodes_by_url = None\n        self.url_base = url_base\n    def __iter__(self):\n        return self.itertypes()\n    def itertypes(self, *types):\n        if not types:\n            types = sorted(self._data.keys())\n        for item_type in types:\n            for path, tests in sorted(iteritems(self._data[item_type])):\n                yield item_type, path, tests\n    def iterpath(self, path):\n        for type_tests in self._data.values():\n            for test in type_tests.get(path, set()):\n                yield test\n    def iterdir(self, dir_name):\n        if not dir_name.endswith(os.path.sep):\n            dir_name = dir_name + os.path.sep\n        for type_tests in self._data.values():\n            for path, tests in type_tests.iteritems():\n                if path.startswith(dir_name):\n                    for test in tests:\n                        yield test\n    @property\n    def reftest_nodes_by_url(self):\n        if self._reftest_nodes_by_url is None:\n            by_url = {}\n            for path, nodes in iteritems(self._data.get(\"reftests\", {})):\n                for node in nodes:\n                    by_url[node.url] = node\n            self._reftest_nodes_by_url = by_url\n        return self._reftest_nodes_by_url\n    def get_reference(self, url):\n        return self.reftest_nodes_by_url.get(url)\n    def update(self, tree):\n        new_data = defaultdict(dict)\n        new_hashes = {}\n        reftest_nodes = []\n        old_files = defaultdict(set, {k: set(viewkeys(v)) for k, v in iteritems(self._data)})\n        changed = False\n        reftest_changes = False\n        for source_file in tree:\n            rel_path = source_file.rel_path\n            file_hash = source_file.hash\n            is_new = rel_path not in self._path_hash\n            hash_changed = False\n            if not is_new:\n                old_hash, old_type = self._path_hash[rel_path]\n                old_files[old_type].remove(rel_path)\n                if old_hash != file_hash:\n                    new_type, manifest_items = source_file.manifest_items()\n                    hash_changed = True\n                else:\n                    new_type, manifest_items = old_type, self._data[old_type][rel_path]\n            else:\n                new_type, manifest_items = source_file.manifest_items()\n            if new_type in (\"reftest\", \"reftest_node\"):\n                reftest_nodes.extend(manifest_items)\n                if is_new or hash_changed:\n                    reftest_changes = True\n            elif new_type:\n                new_data[new_type][rel_path] = set(manifest_items)\n            new_hashes[rel_path] = (file_hash, new_type)\n            if is_new or hash_changed:\n                changed = True\n        if reftest_changes or old_files[\"reftest\"] or old_files[\"reftest_node\"]:\n            reftests, reftest_nodes, changed_hashes = self._compute_reftests(reftest_nodes)\n            new_data[\"reftest\"] = reftests\n            new_data[\"reftest_node\"] = reftest_nodes\n            new_hashes.update(changed_hashes)\n        else:\n            new_data[\"reftest\"] = self._data[\"reftest\"]\n            new_data[\"reftest_node\"] = self._data[\"reftest_node\"]\n        if any(itervalues(old_files)):\n            changed = True\n        self._data = new_data\n        self._path_hash = new_hashes\n        return changed\n    def _compute_reftests(self, reftest_nodes):\n        self._reftest_nodes_by_url = {}\n        has_inbound = set()\n        for item in reftest_nodes:\n            for ref_url, ref_type in item.references:\n                has_inbound.add(ref_url)\n        reftests = defaultdict(set)\n        references = defaultdict(set)\n        changed_hashes = {}\n        for item in reftest_nodes:\n            if item.url in has_inbound:\n                # This is a reference\n                if isinstance(item, RefTest):\n                    item = item.to_RefTestNode()\n                    changed_hashes[item.source_file.rel_path] = (item.source_file.hash,\n                                                                 item.item_type)\n                references[item.source_file.rel_path].add(item)\n                self._reftest_nodes_by_url[item.url] = item\n            else:\n                if isinstance(item, RefTestNode):\n                    item = item.to_RefTest()\n                    changed_hashes[item.source_file.rel_path] = (item.source_file.hash,\n                                                                 item.item_type)\n                reftests[item.source_file.rel_path].add(item)\n        return reftests, references, changed_hashes\n    def to_json(self):\n        out_items = {\n            test_type: {\n                from_os_path(path):\n                [t for t in sorted(test.to_json() for test in tests)]\n                for path, tests in iteritems(type_paths)\n            }\n            for test_type, type_paths in iteritems(self._data)\n        }\n        rv = {\"url_base\": self.url_base,\n              \"paths\": {from_os_path(k): v for k, v in iteritems(self._path_hash)},\n              \"items\": out_items,\n              \"version\": CURRENT_VERSION}\n        return rv\n    @classmethod\n    def from_json(cls, tests_root, obj):\n        version = obj.get(\"version\")\n        if version != CURRENT_VERSION:\n            raise ManifestVersionMismatch\n        self = cls(url_base=obj.get(\"url_base\", \"/\"))\n        if not hasattr(obj, \"items\") and hasattr(obj, \"paths\"):\n            raise ManifestError\n        self._path_hash = {to_os_path(k): v for k, v in iteritems(obj[\"paths\"])}\n        item_classes = {\"testharness\": TestharnessTest,\n                        \"reftest\": RefTest,\n                        \"reftest_node\": RefTestNode,\n                        \"manual\": ManualTest,\n                        \"stub\": Stub,\n                        \"wdspec\": WebdriverSpecTest,\n                        \"conformancechecker\": ConformanceCheckerTest,\n                        \"visual\": VisualTest,\n                        \"support\": SupportFile}\n        source_files = {}\n        for test_type, type_paths in iteritems(obj[\"items\"]):\n            if test_type not in item_classes:\n                raise ManifestError\n            test_cls = item_classes[test_type]\n            tests = defaultdict(set)\n", "outputs": ["            for path, manifest_tests in iteritems(type_paths):"], "input_length": 1047, "output_length": 10, "length": 1057, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "df7e443cb53e17fc718e18b2d9b93b919620a50b3de3f966413bdc8ebefe1e6c"}
{"input": "", "context": "\"\"\"\nUtilities\n\"\"\"\n# Consistency\nfrom __future__ import print_function\nimport copy\nimport getpass\nimport re\nimport readline\nimport sys\npy_version = sys.version_info.major\nif py_version == 2:\n    import urllib\nelse:\n    import urllib.parse as urllib\ntry:\n    import termcolor\n    if sys.platform == 'win32':\n        # Only enable termcolor on Windows if colorama is available\n        try:\n            import colorama\n            colorama.init()\n        except ImportError:\n            colorama = termcolor = None\nexcept ImportError:\n    termcolor = None\nif not sys.stdout.isatty() or '--no-color' in sys.argv:\n    # Prevent coloring of output with  --no-color or if stdout is not a tty\n    termcolor = None\nclass UnsupportedPythonVersion(Exception):\n    def __init__(self, *args, **kwargs):\n        super(UnsupportedPythonVersion, self).__init__(*args)\n        log('Unsupported Python version (%s)' %\n            (kwargs['version'] if 'version' in kwargs else py_version),\n            type='fatal')\nclass DynamicList(list):\n    def __setitem__(self, i, v):\n        # Fill with None\n        self[len(self):i+1] = [None for x in range(i+1-len(self))]\n        super(DynamicList, self).__setitem__(i, v)\n_log_color_split = re.compile('\\s*[,/]?\\s*')\n_log_opts = re.compile('<[^>]*>')\n_log_types = {\n    'error': 'red, bold',\n    'fatal': 'white, on_red, bold',\n    'warn': 'yellow, bold',\n    'ok': 'green',\n    'success': 'green, bold',\n    'info': 'blue',\n    'progress': 'cyan',\n    'bold': 'bold',\n    'underline': 'underline',\n}\ndef _log_parse(*args, **kwargs):\n    s = ' '.join([str(x) for x in args]) + '<>'\n    if 'type' in kwargs and kwargs['type'] in _log_types:\n        s = '<' + _log_types[kwargs['type']] + '>' + s\n    if 'color' not in kwargs:\n        kwargs['color'] = True\n    if termcolor is not None and kwargs['color']:\n        parts = s.replace('\\01', '').replace('<', '\\01<').split('\\01')\n        s = ''\n        for p in parts:\n            if '>' in p:\n                opts, text = p.split('>', 1)\n                if opts[1:2] == '+':\n                    opts = opts[2:]\n                else:\n                    opts = opts[1:]\n                    s += termcolor.RESET\n                opts = _log_color_split.split(opts)\n                args, attrs = [None, None], []\n                for opt in opts:\n                    opt = opt.lower()\n                    if opt in termcolor.COLORS:\n                        args[0] = opt\n                    elif opt in termcolor.HIGHLIGHTS:\n                        args[1] = opt\n                    elif opt in termcolor.ATTRIBUTES:\n                        attrs.append(opt)\n                s += termcolor.colored(text, *args, **{'attrs': attrs}).replace(termcolor.RESET, '')\n            else:\n                s += p\n    else:\n        # Remove <...> tags if termcolor isn't available\n        s = _log_opts.sub('', s)\n    return s\ndef log(*args, **kwargs):\n    print(_log_parse(*args, **kwargs))\ndef logf(*args, **kwargs):\n    sys.stdout.write(_log_parse(*args, **kwargs))\n    sys.stdout.flush()\n_debug = ('--debug' in sys.argv)\ndef debug(*args, **kwargs):\n    if _debug:\n        return log(*args, **kwargs)\n_input = input if py_version == 3 else raw_input\ndef input(prompt='', visible=True, input=''):\n    \"\"\"\n    Enhanced implementation of input (independent of Python version)\n    Similar to Python 2's \"raw_input\" and Python 3's \"input\"\n    prompt (string): The prompt to display (on the same line as the text)\n    visible (bool): Enables/disables echoing of input. Note that \"False\"\n        enforces a tty (i.e. it will read from the command line, not a file).\n    input (string): Formatting to apply to the input string (only when visible)\n        e.g. \"red, bold\" (angle brackets are not required)\n    \"\"\"\n    prompt = _log_parse(prompt)\n    if input and termcolor is not None:\n        input = input.replace('<', '').replace('>', '')\n        input = _log_parse('<%s>' % input).replace(termcolor.RESET, '')\n    try:\n        if not visible:\n            text = getpass.getpass(prompt)\n        else:\n            text = _input(prompt + input)\n    except:\n        logf('<>')  # Reset terminal\n        raise  # Allow exception to propagate\n    logf('<>')\n    return text\ndef get_file(prompt='File: ', exists=True, path=''):\n    \"\"\"\n    Prompt for a file\n    \n    prompt: Text to display (defaults to \"File: \")\n    exists: True if file should exist (defaults to True)\n    path: An initial path to use, returned if acceptable (optional)\n    \"\"\"\n    path = str(path)\n    while 1:\n        if not path:\n            path = input(prompt)\n        if exists:\n            try:\n                f = open(path)\n            except IOError:\n                pass\n            else:\n                break\n        else:\n            break\n        path = ''\n    return path\ndef die(*args, **kwargs):\n    log(*args, **kwargs)\n    sys.exit()\ndef dict_auto_filter(obj):\n    while True:\n        try:\n            if len(obj.keys()) > 1:\n                break\n            # list() is necessary for python 3, where keys() doesn't return\n            # a list that supports indexes\n            if isinstance(obj[list(obj.keys())[0]], dict):\n                obj = obj[list(obj.keys())[0]]\n            else:\n                break\n        except AttributeError:\n            # Single remaining object is not a dict\n            break\n    \n    return obj\ndef dict_extend(d1, d2):\n    \"\"\"\n    Merges dictionaries 'd1' and 'd2'\n    For keys that exist in both, the value from d2 is used\n    \"\"\"\n    return dict(d1, **d2)\ndef dict_recursive_fetch_list(d, key):\n    \"\"\"\n    Returns a list of _all_ values in dict 'd' with key 'key'\n    Also fetches items in lists\n    \"\"\"\n    l = []\n    \n    if isinstance(d, list):\n        for i in d:\n            l.extend(dict_recursive_fetch_list(i, key))\n        return l\n    for i in d:\n        if i == key:\n            l.append(d[i])\n        elif isinstance(d[i], (dict, list)):\n            l.extend(dict_recursive_fetch_list(d[i], key))\n            \n    return l\ndef recursive_merge(d1, d2):\n    \"\"\"\n    Merges two dictionaries and their sub-dictionaries and/or lists\n    \"\"\"\n    d1, d2 = copy.copy(d1), copy.copy(d2)\n    result = {} if isinstance(d1, dict) or isinstance(d2, dict) else []\n    keys = (list(d1.keys()) if isinstance(d1, dict) else range(len(d1))) + \\\n           (list(d2.keys()) if isinstance(d2, dict) else range(len(d2)))\n    # Remove duplicates\n    keys = list(set(keys))\n    if isinstance(result, dict):\n        # Current object is a dict\n        for k in keys:\n            if k in d1 and k in d2:\n                v1, v2 = d1[k], d2[k]\n                if v1 != v2:\n                    if isinstance(v1, (dict, list)) and isinstance(v2, (dict, list)):\n                        # Values can be merged\n                        result[k] = recursive_merge(v1, v2)\n                    else:\n                        # Values cannot be merged, so return the value from d1\n                        result[k] = v1\n                else:\n                    # Values are equal, so merging is unnecessary\n                    result[k] = v1\n            else:\n                # Key is either in d1 or d2\n                result[k] = d1[k] if k in d1 else d2[k]\n    else:\n        # Current object is a list\n        result = d1 + d2\n    return result\n    \ndef str_format(string, *args, **kwargs):\n    \"\"\"\n    A slightly modified version of the native str.format(), using {% and %}\n    instead of { and }\n    \n    >>> str_format('{a}', a=2)\n    {a}\n    >>> str_format('{%a%}', a=2)\n    2\n    >>> str_format('{% a %}', a=2)\n    2\n    \"\"\"\n    # Accept whitespace directly inside {% ... %} tags\n    string = re.compile(r'\\{%\\s+').sub('{%', string)\n    string = re.compile(r'\\s+%\\}').sub('%}', string)\n    string = string.replace('{','{{').replace('}','}}') \\\n        .replace('{{%', '{').replace('%}}','}')\n", "outputs": ["    return string.format(*args, **kwargs)"], "input_length": 1767, "output_length": 10, "length": 1777, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "fa0563bc14a0fc7d17f88cac1a51bde4a5fbc776a18057e72f64278392049a57"}
{"input": "", "context": "/*\n * AsoBrain 3D Toolkit\n * Copyright (C) 1999-2016 Peter S. Heijnen\n *\n * This library is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n *\n * This library is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with this library; if not, write to the Free Software\n * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA\n */\npackage ab.j3d.yafaray;\nimport java.io.*;\nimport java.util.*;\nimport ab.j3d.*;\nimport ab.j3d.appearance.*;\nimport ab.j3d.awt.view.*;\nimport ab.j3d.geom.*;\nimport ab.j3d.model.*;\nimport ab.xml.*;\nimport org.jetbrains.annotations.*;\n/**\n * Writes a YafaRay scene.\n *\n * <p>\n * Documentation about the YafaRay XML-format is limited, but some useful\n * references are:\n * <ul>\n *     <li><a href=\"http://www.yafaray.org/development/documentation/XMLspecs\">YafaRay XML scene specifications</a></li>\n *     <li><a href=\"http://www.yafaray.org/development/documentation/XMLparameters\">YafaRay XML scene parameters</a></li>\n * </ul>\n * </p>\n *\n * @author G. Meinders\n */\npublic class YafaRayWriter\n{\n\t/**\n\t * XML writer to be used.\n\t */\n\tprivate final XMLWriter _writer;\n\t/**\n\t * Maps appearances to YafaRay material identifiers.\n\t */\n\tprivate final Map<Appearance, String> _appearanceMap = new HashMap<Appearance, String>();\n\t/**\n\t * Texture library.\n\t */\n\tprivate TextureLibrary _textureLibrary;\n\t/**\n\t * Index used to generate unique material names.\n\t */\n\tprivate int _materialIndex = 0;\n\t/**\n\t * Index used to generate unique light names.\n\t */\n\tpublic int _lightIndex = 0;\n\t/**\n\t * Width of the image.\n\t */\n\tprivate int _width = 1024;\n\t/**\n\t * Height of the image.\n\t */\n\tprivate int _height = 768;\n\t/**\n\t * Camera location.\n\t */\n\tprivate Vector3D _cameraFrom;\n\t/**\n\t * Camera target.\n\t */\n\tprivate Vector3D _cameraTo;\n\t/**\n\t * Constructs a new instance.\n\t *\n\t * @param   out     Output stream to write to.\n\t *\n\t * @throws  XMLException if no {@link XMLWriter} can be created.\n\t */\n\tpublic YafaRayWriter( final OutputStream out, final TextureLibrary textureLibrary )\n\tthrows XMLException\n\t{\n\t\tfinal XMLWriterFactory writerFactory = XMLWriterFactory.newInstance();\n\t\twriterFactory.setIndenting( true );\n\t\t_writer = writerFactory.createXMLWriter( out, \"UTF-8\" );\n\t\t_textureLibrary = textureLibrary;\n\t}\n\t/**\n\t * Sets the size of the image to be rendered.\n\t *\n\t * @param   width   Width of the image.\n\t * @param   height  Height of the image.\n\t */\n\tpublic void setOutputSize( final int width, final int height )\n\t{\n\t\t_width = width;\n\t\t_height = height;\n\t}\n\t/**\n\t * Sets the location and target of the camera.\n\t *\n\t * @param   from    Location of the camera.\n\t * @param   to      Target that the camera is pointed at.\n\t */\n\tpublic void setCamera( final Vector3D from, final Vector3D to )\n\t{\n\t\t_cameraFrom = from;\n\t\t_cameraTo = to;\n\t}\n\t/**\n\t * Writes an YafaRay scene specification for the given scene.\n\t *\n\t * @param   scene   Scene to be written.\n\t *\n\t * @throws  XMLException if an XML-related exception occurs.\n\t */\n\tpublic void write( final Scene scene )\n\tthrows XMLException\n\t{\n\t\tfinal XMLWriter writer = _writer;\n\t\twriter.startDocument();\n\t\twriter.startTag( null, \"scene\" );\n\t\twriter.attribute( null, \"type\", \"triangle\" );\n\t\tscene.walk( new Node3DVisitor()\n\t\t{\n\t\t\tpublic boolean visitNode( @NotNull final Node3DPath path )\n\t\t\t{\n\t\t\t\tfinal Node3D node = path.getNode();\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\tif ( node instanceof Object3D )\n\t\t\t\t\t{\n\t\t\t\t\t\tfinal Object3D object = (Object3D)node;\n\t\t\t\t\t\tfor ( final FaceGroup faceGroup : object.getFaceGroups() )\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tfinal Appearance appearance = faceGroup.getAppearance();\n\t\t\t\t\t\t\tString identifier = _appearanceMap.get( appearance );\n\t\t\t\t\t\t\tif ( identifier== null )\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tidentifier = writeMaterial( appearance );\n\t\t\t\t\t\t\t\t_appearanceMap.put( appearance, identifier );\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\twriteMesh( object, path.getTransform() );\n\t\t\t\t\t}\n\t\t\t\t\telse if ( node instanceof Light3D )\n\t\t\t\t\t{\n\t\t\t\t\t\tfinal Light3D light = (Light3D)node;\n\t\t\t\t\t\tfinal Matrix3D transform = path.getTransform();\n\t\t\t\t\t\twriter.startTag( null, \"light\" );\n\t\t\t\t\t\twriter.attribute( null, \"name\", \"light\" + _lightIndex++ );\n\t\t\t\t\t\twriteValue( \"type\", \"spherelight\" );\n//\t\t\t\t\t\twriteValue( \"type\", \"pointlight\" );\n\t\t\t\t\t\twriteColor( \"color\", (double)light.getDiffuseRed(), (double)light.getDiffuseGreen(), (double)light.getDiffuseBlue() );\n\t\t\t\t\t\twritePoint( \"from\", transform.getTranslation() );\n\t\t\t\t\t\tfinal double radius = 0.1;\n\t\t\t\t\t\tfinal double power = 1.0;\n\t\t\t\t\t\twriteFloat( \"power\", power / ( radius * radius ) );\n\t\t\t\t\t\twriteFloat( \"radius\", radius );\n\t\t\t\t\t\twriteInteger( \"samples\", 16 );\n/*\n\t\t\t\t\t\t<light name=\"Lamp.001\">\n\t\t\t\t\t\t<color r=\"1\" g=\"1\" b=\"1\" a=\"1\"/>\n\t\t\t\t\t\t<corner x=\"-0.25\" y=\"-0.25\" z=\"1.99646\"/>\n\t\t\t\t\t\t<from x=\"0\" y=\"0\" z=\"1.99646\"/>\n\t\t\t\t\t\t<point1 x=\"-0.25\" y=\"0.25\" z=\"1.99646\"/>\n\t\t\t\t\t\t<point2 x=\"0.25\" y=\"-0.25\" z=\"1.99646\"/>\n\t\t\t\t\t\t<power fval=\"5\"/>\n\t\t\t\t\t\t<samples ival=\"16\"/>\n\t\t\t\t\t\t<type sval=\"arealight\"/>\n*/\n\t\t\t\t\t\twriter.endTag( null, \"light\" );\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tcatch ( XMLException e )\n\t\t\t\t{\n\t\t\t\t\tthrow new RuntimeException( e );\n\t\t\t\t}\n\t\t\t\treturn true;\n\t\t\t}\n\t\t} );\n\t\twriter.startTag( null, \"camera\" );\n\t\tfinal String cameraName = \"camera0\";\n\t\twriter.attribute( null, \"name\", cameraName );\n\t\twriteValue( \"type\", \"perspective\" );\n\t\twritePoint( \"from\", _cameraFrom );\n\t\twritePoint( \"to\", _cameraTo );\n\t\tfinal Vector3D cameraDirection = _cameraFrom.directionTo( _cameraTo );\n\t\tfinal Vector3D left = Vector3D.cross( cameraDirection, Vector3D.POSITIVE_Z_AXIS.multiply( 1.0 / 0.001 ) );\n\t\tfinal Vector3D up = Vector3D.cross( left, cameraDirection );\n\t\twritePoint( \"up\", _cameraFrom.plus( up ) );\n\t\twriteInteger( \"resx\", _width );\n\t\twriteInteger( \"resy\", _height );\n\t\twriter.endTag( null, \"camera\" );\n/*\n\t\t<camera name=\"cam\">\n\t\t\t...\n\t\t\t<aperture fval=\"0\"/>\n\t\t\t<bokeh_rotation fval=\"0\"/>\n\t\t\t<bokeh_type sval=\"disk1\"/>\n\t\t\t<dof_distance fval=\"0\"/>\n\t\t\t<focal fval=\"1.37374\"/>\n\t\t</camera>\n*/\n\t\tfinal Vector3D sunDirection = Vector3D.normalize( -1.0, -0.5, 3.5 );\n//\t\tVector3D sunDirection = Vector3D.normalize( 1.0, 0.0, 2.0 );\n//\t\tVector3D sunDirection = Vector3D.normalize( -0.5, 1.0, -2.0 );\n\t\twriter.startTag( null, \"light\" );\n\t\twriter.attribute( null, \"name\", \"light\" + _lightIndex++ );\n\t\twriteValue( \"type\", \"sunlight\" );\n\t\twriteFloat( \"angle\", 0.5 );\n\t\twriteColor( \"color\", 1.0, 1.0, 1.0 );\n\t\twriteVector( \"direction\", sunDirection );\n\t\twriteFloat( \"power\", 1.0 );\n//\t\twriteInteger( \"samples\", 16 );\n\t\twriter.endTag( null, \"light\" );\n/*\n\t\tfinal String backgroundName = \"background0\";\n\t\twriter.startTag( null, \"background\" );\n\t\twriter.attribute( null, \"name\", backgroundName );\n\t\twriteValue( \"type\", \"constant\" );\n\t\twriteColor( \"color\", 1.0, 1.0, 1.0 );\n\t\twriter.endTag( null, \"background\" );\n*/\n\t\tfinal String backgroundName = \"background0\";\n\t\twriter.startTag( null, \"background\" );\n\t\twriter.attribute( null, \"name\", backgroundName );\n\t\twriteValue( \"type\", \"sunsky\" );\n\t\twriteVector( \"from\", sunDirection );\n\t\twriter.endTag( null, \"background\" );\n/*\n\t\t<integrator name=\"default\">\n\t\t\t<bounces ival=\"3\"/>\n\t\t\t<caustic_mix ival=\"5\"/>\n\t\t\t<diffuseRadius fval=\"1\"/>\n\t\t\t<fg_bounces ival=\"3\"/>\n\t\t\t<fg_samples ival=\"32\"/>\n\t\t\t<raydepth ival=\"4\"/>\n\t\t\t<search ival=\"150\"/>\n\t\t\t<shadowDepth ival=\"2\"/>\n\t\t\t<show_map bval=\"false\"/>\n\t\t\t<transpShad bval=\"false\"/>\n\t\t\t<use_background bval=\"false\"/>\n\t\t</integrator>\n*/\n\t\tfinal String integratorName = \"integrator0\";\n\t\twriter.startTag( null, \"integrator\" );\n\t\twriter.attribute( null, \"name\", integratorName );\n\t\tswitch ( 2 )\n\t\t{\n\t\t\tcase 0:\n\t\t\t{\n\t\t\t\twriteValue( \"type\", \"directlighting\" );\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tcase 1:\n\t\t\t{\n\t\t\t\twriteValue( \"type\", \"pathtracing\" );\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tcase 2:\n\t\t\t{\n\t\t\t\twriteValue( \"type\", \"photonmapping\" );\n//\t\t\t\twriteInteger( \"search\", 160 );\n\t\t\t\twriteInteger( \"photons\", 200000 );\n\t\t\t\twriteBoolean( \"finalGather\", true );\n\t\t\t\twriteInteger( \"fg_samples\", 64 );\n\t\t\t\twriteBoolean( \"use_background\", false );\n//\t\t\t\twriteBoolean( \"show_map\", true );\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\twriter.endTag( null, \"integrator\" );\n\t\tfinal String volumeIntegratorName = \"integrator1\";\n\t\twriter.startTag( null, \"integrator\" );\n\t\twriter.attribute( null, \"name\", volumeIntegratorName );\n\t\twriteValue( \"type\", \"none\" );\n\t\twriter.endTag( null, \"integrator\" );\n\t\twriter.startTag( null, \"render\" );\n\t\twriteValue( \"camera_name\", cameraName );\n\t\twriteValue( \"background_name\", backgroundName );\n\t\twriteValue( \"integrator_name\", integratorName );\n\t\twriteValue( \"volintegrator_name\", volumeIntegratorName );\n\t\twriteInteger( \"threads\", Math.max( 1, Runtime.getRuntime().availableProcessors() - 1 ) );\n\t\twriteFloat( \"gamma\", 2.2 );\n\t\twriteInteger( \"width\", _width );\n\t\twriteInteger( \"height\", _height );\n\t\twriteInteger( \"xstart\", 0 );\n\t\twriteInteger( \"ystart\", 0 );\n//\t\t``writeValue( \"filter_type\", \"mitchell\" );\n\t\twriteInteger( \"AA_inc_samples\", 2 );\n\t\twriteInteger( \"AA_minsamples\", 2 );\n\t\twriteInteger( \"AA_passes\", 2 );\n\t\twriteFloat( \"AA_pixelwidth\", 1.5 );\n\t\twriteFloat( \"AA_threshold\", 0.05 );\n/*\n\t\t<background_name sval=\"world_background\"/>\n\t\t<clamp_rgb bval=\"true\"/>\n\t\t<filter_type sval=\"mitchell\"/>\n\t\t<integrator_name sval=\"default\"/>\n\t\t<volintegrator_name sval=\"volintegr\"/>\n\t\t<z_channel bval=\"true\"/>\n*/\n\t\twriter.endTag( null, \"render\" );\n\t\twriter.endTag( null, \"scene\" );\n\t\twriter.endDocument();\n\t\twriter.flush();\n\t}\n\t/**\n\t * Writes a YafaRay material reprseenting the given appearance.\n\t *\n\t * @param   appearance  Appearance to be written.\n\t *\n\t * @return  Name of the YafaRay material.\n\t * @throws  XMLException if an XML-related exception occurs.\n\t */\n\tprivate String writeMaterial( final Appearance appearance )\n\tthrows XMLException\n\t{\n\t\tfinal int materialIndex = _materialIndex++;\n\t\tfinal String name = \"material\" + materialIndex;\n\t\tString textureMapperName = null;\n\t\tString textureName = null;\n\t\tfinal XMLWriter writer = _writer;\n\t\tfinal TextureMap colorMap = appearance.getColorMap();\n\t\tif ( colorMap != null )\n\t\t{\n\t\t\tfinal File textureFile = _textureLibrary.getFile( colorMap );\n\t\t\tif ( textureFile != null )\n\t\t\t{\n\t\t\t\ttextureName = \"texture\" + materialIndex;\n\t/*\n\t<texture name=\"t1\">\n\t\t<calc_alpha bval=\"true\"/>\n\t\t<clipping sval=\"repeat\"/>\n\t\t<cropmax_x fval=\"1\"/>\n\t\t<cropmax_y fval=\"1\"/>\n\t\t<cropmin_x fval=\"0\"/>\n\t\t<cropmin_y fval=\"0\"/>\n\t\t<filename sval=\"C:\\WallPapers\\Lotus.jpg\"/>\n\t\t<gamma fval=\"2\"/>\n\t\t<type sval=\"image\"/>\n\t\t<use_alpha bval=\"true\"/>\n\t\t<xrepeat ival=\"1\"/>\n\t\t<yrepeat ival=\"1\"/>\n\t</texture>\n\t*/\n\t\t\t\twriter.startTag( null, \"texture\" );\n\t\t\t\twriter.attribute( null, \"name\", textureName );\n\t\t\t\twriteValue( \"type\", \"image\" );\n\t\t\t\twriteValue( \"filename\", textureFile.toString() );\n\t\t\t\twriter.endTag( null, \"texture\" );\n\t\t\t}\n\t\t}\n\t\twriter.startTag( null, \"material\" );\n\t\twriter.attribute( null, \"name\", name );\n\t\twriteValue( \"type\", \"shinydiffusemat\" );\n\t\twriteColor( \"color\", appearance.getDiffuseColor() );\n\t\twriteFloat( \"transparency\", 1.0 - (double)appearance.getDiffuseColor().getAlphaFloat() );\n\t\tif ( appearance.getDiffuseColor().getAlphaFloat() < 0.5f )\n\t\t{\n\t\t\twriteFloat( \"IOR\", 1520.0 );\n\t\t}\n\t\tif ( colorMap != null )\n\t\t{\n\t\t\ttextureMapperName = \"textureMapper\" + materialIndex;\n\t\t\twriter.startTag( null, \"list_element\" );\n\t\t\twriteValue( \"element\", \"shader_node\" );\n\t\t\twriteValue( \"type\", \"texture_mapper\" );\n\t\t\twriteValue( \"name\", textureMapperName );\n\t\t\twriteValue( \"texture\", textureName );\n\t\t\twriteValue( \"texco\", \"uv\" );\n\t\t\twriter.endTag( null, \"list_element\" );\n\t\t}\n\t\tif ( textureMapperName != null )\n\t\t{\n\t\t\twriteValue( \"diffuse_shader\", textureMapperName );\n\t\t}\n\t\tif ( appearance.getReflectionMap() != null )\n\t\t{\n\t\t\twriteColor( \"mirror_color\", appearance.getReflectionColor() );\n\t\t\twriteFloat( \"specular_reflect\", (double)( appearance.getReflectionMin() + appearance.getReflectionMax() ) / 2.0 );\n\t\t}\n\t\twriter.endTag( null, \"material\" );\n\t\treturn name;\n\t}\n\t/**\n\t * Writes a YafaRay mesh for the given object.\n\t *\n\t * @param   object          Object to be written.\n\t * @param   objectToScene   Transforms the object into scene coordinates.\n\t *\n\t * @throws  XMLException if an XML-related exception occurs.\n\t */\n\tprivate void writeMesh( final Object3D object, final Matrix3D objectToScene )\n\tthrows XMLException\n\t{\n\t\tint vertexCount = 0;\n\t\tint triangleCount = 0;\n\t\tfinal List<FaceGroup> faceGroups = object.getFaceGroups();\n\t\tfor ( final FaceGroup faceGroup : faceGroups )\n\t\t{\n\t\t\tfor ( final Face3D face : faceGroup.getFaces() )\n\t\t\t{\n\t\t\t\tvertexCount += face.getVertexCount();\n\t\t\t\tfinal Tessellation tessellation = face.getTessellation();\n\t\t\t\tfor ( final TessellationPrimitive primitive : tessellation.getPrimitives() )\n\t\t\t\t{\n\t\t\t\t\ttriangleCount += primitive.getTriangles().length / 3;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfinal XMLWriter writer = _writer;\n\t\twriter.startTag( null, \"mesh\" );\n\t\twriter.attribute( null, \"vertices\", String.valueOf( vertexCount ) );\n\t\twriter.attribute( null, \"faces\", String.valueOf( triangleCount ) );\n\t\twriter.attribute( null, \"has_orco\", String.valueOf( false ) );\n\t\twriter.attribute( null, \"has_uv\", String.valueOf( true ) );\n\t\twriter.attribute( null, \"type\", String.valueOf( 0 ) );\n\t\tint vertexIndex = 0;\n\t\tfor ( final FaceGroup faceGroup : faceGroups )\n\t\t{\n\t\t\tfinal String materialName = _appearanceMap.get( faceGroup.getAppearance() );\n\t\t\twriteValue( \"set_material\", materialName );\n\t\t\tfor ( final Face3D face : faceGroup.getFaces() )\n\t\t\t{\n\t\t\t\tfinal List<Vertex3D> vertices = face.getVertices();\n\t\t\t\tfor ( final Vertex3D vertex : vertices )\n\t\t\t\t{\n\t\t\t\t\twritePoint( \"p\", objectToScene.transform( vertex.point ) );\n\t\t\t\t\twriter.emptyTag( null, \"uv\" );\n\t\t\t\t\twriter.attribute( null, \"u\", String.valueOf( Float.isNaN( vertex.colorMapU ) ? 0.0f : vertex.colorMapU ) );\n\t\t\t\t\twriter.attribute( null, \"v\", String.valueOf( Float.isNaN( vertex.colorMapV ) ? 0.0f : vertex.colorMapV ) );\n\t\t\t\t\twriter.endTag( null, \"uv\" );\n\t\t\t\t}\n\t\t\t\tfinal Tessellation tessellation = face.getTessellation();\n\t\t\t\tfor ( final TessellationPrimitive primitive : tessellation.getPrimitives() )\n\t\t\t\t{\n\t\t\t\t\tfinal int[] triangles = primitive.getTriangles();\n\t\t\t\t\tfor ( int i = 0; i < triangles.length; i += 3 )\n\t\t\t\t\t{\n\t\t\t\t\t\tfinal int a = triangles[ i ];\n\t\t\t\t\t\tfinal int b = triangles[ i + 1 ];\n\t\t\t\t\t\tfinal int c = triangles[ i + 2 ];\n\t\t\t\t\t\twriter.emptyTag( null, \"f\" );\n\t\t\t\t\t\twriter.attribute( null, \"a\", String.valueOf( vertexIndex + a ) );\n\t\t\t\t\t\twriter.attribute( null, \"b\", String.valueOf( vertexIndex + b ) );\n\t\t\t\t\t\twriter.attribute( null, \"c\", String.valueOf( vertexIndex + c ) );\n\t\t\t\t\t\twriter.attribute( null, \"uv_a\", String.valueOf( vertexIndex + a ) );\n\t\t\t\t\t\twriter.attribute( null, \"uv_b\", String.valueOf( vertexIndex + b ) );\n\t\t\t\t\t\twriter.attribute( null, \"uv_c\", String.valueOf( vertexIndex + c ) );\n\t\t\t\t\t\twriter.endTag( null, \"f\" );\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tvertexIndex += vertices.size();\n\t\t\t}\n\t\t}\n\t\twriter.endTag( null, \"mesh\" );\n\t}\n\t/**\n\t * Writes a parameter with an integer value.\n\t *\n\t * @param   name    Name of the parameter.\n\t * @param   value   Value of the parameter.\n\t *\n\t * @throws  XMLException if an XML-related exception occurs.\n\t */\n\tprivate void writeInteger( final String name, final int value )\n\tthrows XMLException\n\t{\n\t\tfinal XMLWriter writer = _writer;\n\t\twriter.emptyTag( null, name );\n\t\twriter.attribute( null, \"ival\", String.valueOf( value ) );\n\t\twriter.endTag( null, name );\n\t}\n\t/**\n\t * Writes a parameter with a boolean value.\n\t *\n\t * @param   name    Name of the parameter.\n\t * @param   value   Value of the parameter.\n\t *\n\t * @throws  XMLException if an XML-related exception occurs.\n\t */\n\tprivate void writeBoolean( final String name, final boolean value )\n\tthrows XMLException\n\t{\n\t\tfinal XMLWriter writer = _writer;\n\t\twriter.emptyTag( null, name );\n\t\twriter.attribute( null, \"bval\", String.valueOf( value ) );\n\t\twriter.endTag( null, name );\n\t}\n\t/**\n\t * Writes a parameter with a string value.\n\t *\n\t * @param   name    Name of the parameter.\n\t * @param   value   Value of the parameter.\n\t *\n\t * @throws  XMLException if an XML-related exception occurs.\n\t */\n\tprivate void writeValue( final String name, final String value )\n\tthrows XMLException\n\t{\n\t\tfinal XMLWriter writer = _writer;\n\t\twriter.emptyTag( null, name );\n\t\twriter.attribute( null, \"sval\", value );\n\t\twriter.endTag( null, name );\n\t}\n\t/**\n\t * Writes a parameter with an float value.\n\t *\n\t * @param   name    Name of the parameter.\n\t * @param   value   Value of the parameter.\n\t *\n\t * @throws  XMLException if an XML-related exception occurs.\n\t */\n\tprivate void writeFloat( final String name, final double value )\n\tthrows XMLException\n\t{\n\t\tfinal XMLWriter writer = _writer;\n\t\twriter.emptyTag( null, name );\n\t\twriter.attribute( null, \"fval\", String.valueOf( value ) );\n\t\twriter.endTag( null, name );\n\t}\n\t/**\n\t * Writes a parameter with a point value. The value typically represents a\n\t * point in space, and may be transformed to account for scene scale.\n\t *\n\t * @param   name    Name of the parameter.\n\t * @param   x       X-coordinate of the point.\n\t * @param   y       Y-coordinate of the point.\n\t * @param   z       Z-coordinate of the point.\n\t *\n\t * @throws  XMLException if an XML-related exception occurs.\n\t */\n\tprivate void writePoint( final String name, final double x, final double y, final double z )\n\tthrows XMLException\n\t{\n\t\tfinal XMLWriter writer = _writer;\n\t\twriter.emptyTag( null, name );\n\t\twriter.attribute( null, \"x\", String.valueOf( 0.001 * x ) );\n\t\twriter.attribute( null, \"y\", String.valueOf( 0.001 * y ) );\n\t\twriter.attribute( null, \"z\", String.valueOf( 0.001 * z ) );\n\t\twriter.endTag( null, name );\n\t}\n\t/**\n\t * Writes a parameter with a point value. The value typically represents a\n\t * point in space, and may be transformed to account for scene scale.\n\t *\n\t * @param   name    Name of the parameter.\n\t * @param   value   Value of the parameter.\n\t *\n\t * @throws  XMLException if an XML-related exception occurs.\n\t */\n\tprivate void writePoint( final String name, final Vector3D value )\n\tthrows XMLException\n\t{\n\t\twritePoint( name, value.x, value.y, value.z );\n\t}\n\t/**\n\t * Writes a parameter with a vector value. This is typically a unit vector,\n\t * and as such no transformations are applied to account for scene scale.\n\t *\n\t * @param   name    Name of the parameter.\n\t * @param   value   Value of the parameter.\n\t *\n\t * @throws  XMLException if an XML-related exception occurs.\n\t */\n\tprivate void writeVector( final String name, final Vector3D value )\n\tthrows XMLException\n\t{\n\t\tfinal XMLWriter writer = _writer;\n\t\twriter.emptyTag( null, name );\n\t\twriter.attribute( null, \"x\", String.valueOf( value.x ) );\n\t\twriter.attribute( null, \"y\", String.valueOf( value.y ) );\n\t\twriter.attribute( null, \"z\", String.valueOf( value.z ) );\n\t\twriter.endTag( null, name );\n\t}\n\t/**\n\t * Writes a parameter with a color value.\n\t *\n\t * @param   name    Name of the parameter.\n\t * @param   r       Red-component of the color.\n\t * @param   g       Green-component of the color.\n\t * @param   b       Blue-component of the color.\n\t *\n\t * @throws  XMLException if an XML-related exception occurs.\n\t */\n\tprivate void writeColor( final String name, final double r, final double g, final double b )\n\tthrows XMLException\n\t{\n\t\tfinal XMLWriter writer = _writer;\n\t\twriter.emptyTag( null, name );\n\t\twriter.attribute( null, \"r\", String.valueOf( r ) );\n\t\twriter.attribute( null, \"g\", String.valueOf( g ) );\n", "outputs": ["\t\twriter.attribute( null, \"b\", String.valueOf( b ) );"], "input_length": 4173, "output_length": 14, "length": 4187, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "66b0dc126957eff62a8a0b70afe786b0c2d2b913c6a2cb45d03bf20a786aede0"}
{"input": "", "context": "# -*- coding: utf-8 -*-\n# This file is part of Shoop.\n#\n# Copyright (c) 2012-2015, Shoop Ltd. All rights reserved.\n#\n# This source code is licensed under the AGPLv3 license found in the\n# LICENSE file in the root directory of this source tree.\nfrom __future__ import unicode_literals\nimport random\nfrom django import forms\nfrom django.contrib import messages\nfrom django.contrib.auth import get_user_model\nfrom django.core.urlresolvers import reverse\nfrom django.db.transaction import atomic\nfrom django.forms.models import modelform_factory\nfrom django.http.response import HttpResponseRedirect\nfrom django.utils.encoding import force_text\nfrom django.utils.translation import ugettext_lazy as _\nfrom shoop.admin.toolbar import (\n    DropdownActionButton, DropdownDivider, DropdownItem, PostActionButton, Toolbar, get_default_edit_toolbar\n)\nfrom shoop.admin.utils.urls import get_model_url\nfrom shoop.admin.utils.views import CreateOrUpdateView\nfrom shoop.core.models import Contact, PersonContact\nfrom shoop.utils.excs import Problem\nfrom shoop.utils.text import flatten\nclass BaseUserForm(forms.ModelForm):\n    password = forms.CharField(label=_(\"Password\"), widget=forms.PasswordInput)\n    permission_info = forms.CharField(\n        label=_(\"Permissions\"),\n        widget=forms.TextInput(attrs={\"readonly\": True, \"disabled\": True}),\n        required=False,\n        help_text=_(\"See the permissions view to change these.\")\n    )\n    def __init__(self, *args, **kwargs):\n        super(BaseUserForm, self).__init__(*args, **kwargs)\n        if self.instance.pk:\n            # Changing the password for an existing user requires more confirmation\n            self.fields.pop(\"password\")\n            self.initial[\"permission_info\"] = \", \".join(force_text(perm) for perm in [\n                _(\"staff\") if self.instance.is_staff else \"\",\n                _(\"superuser\") if self.instance.is_superuser else \"\",\n            ] if perm) or _(\"No special permissions\")\n        else:\n            self.fields.pop(\"permission_info\")\n    def save(self, commit=True):\n        user = super(BaseUserForm, self).save(commit=False)\n        if \"password\" in self.fields:\n            user.set_password(self.cleaned_data[\"password\"])\n        if commit:\n            user.save()\n        return user\nclass UserDetailToolbar(Toolbar):\n    def __init__(self, view):\n        self.view = view\n        self.request = view.request\n        self.user = view.object\n        super(UserDetailToolbar, self).__init__()\n        self.extend(get_default_edit_toolbar(self.view, \"user_form\", with_split_save=False))\n        if self.user.pk:\n            self._build_existing_user()\n    def _build_existing_user(self):\n        user = self.user\n        change_password_button = DropdownItem(\n            url=reverse(\"shoop_admin:user.change-password\", kwargs={\"pk\": user.pk}),\n            text=_(u\"Change Password\"), icon=\"fa fa-exchange\"\n        )\n        reset_password_button = DropdownItem(\n            url=reverse(\"shoop_admin:user.reset-password\", kwargs={\"pk\": user.pk}),\n            disable_reason=(_(\"User has no email address\") if not user.email else None),\n            text=_(u\"Send Password Reset Email\"), icon=\"fa fa-envelope\"\n        )\n        permissions_button = DropdownItem(\n            url=reverse(\"shoop_admin:user.change-permissions\", kwargs={\"pk\": user.pk}),\n            text=_(u\"Edit Permissions\"), icon=\"fa fa-lock\"\n        )\n        menu_items = [\n            change_password_button,\n            reset_password_button,\n            permissions_button,\n            DropdownDivider()\n        ]\n        person_contact = PersonContact.objects.filter(user=user).first()\n        if person_contact:\n            contact_url = reverse(\"shoop_admin:contact.detail\", kwargs={\"pk\": person_contact.pk})\n            menu_items.append(DropdownItem(\n                url=contact_url,\n                icon=\"fa fa-search\",\n                text=_(u\"Contact Details\"),\n            ))\n        else:\n            contact_url = reverse(\"shoop_admin:contact.new\") + \"?user_id=%s\" % user.pk\n            menu_items.append(DropdownItem(\n                url=contact_url,\n                icon=\"fa fa-plus\",\n                text=_(u\"New Contact\"),\n                tooltip=_(\"Create a new contact and associate it with this user\")\n            ))\n        self.append(DropdownActionButton(\n            menu_items,\n            icon=\"fa fa-star\",\n            text=_(u\"Actions\"),\n            extra_css_class=\"btn-info\",\n        ))\n        if not user.is_active:\n            self.append(PostActionButton(\n                post_url=self.request.path,\n                name=\"set_is_active\",\n                value=\"1\",\n                icon=\"fa fa-check-circle\",\n                text=_(u\"Activate User\"),\n                extra_css_class=\"btn-gray\",\n            ))\n        else:\n            self.append(PostActionButton(\n                post_url=self.request.path,\n                name=\"set_is_active\",\n                value=\"0\",\n                icon=\"fa fa-times-circle\",\n                text=_(u\"Deactivate User\"),\n                extra_css_class=\"btn-gray\",\n            ))\n        # TODO: Add extensibility\nclass UserDetailView(CreateOrUpdateView):\n    # Model set during dispatch because it's swappable\n    template_name = \"shoop/admin/users/detail.jinja\"\n    context_object_name = \"user\"\n    fields = (\"username\", \"email\", \"first_name\", \"last_name\")\n    def get_form_class(self):\n        return modelform_factory(self.model, form=BaseUserForm, fields=self.fields)\n    def _get_bind_contact(self):\n        contact_id = self.request.REQUEST.get(\"contact_id\")\n        if contact_id:\n            return Contact.objects.get(pk=contact_id)\n        return None\n    def get_initial(self):\n        initial = super(UserDetailView, self).get_initial()\n        contact = self._get_bind_contact()\n        if contact:\n            # Guess some sort of usable username\n            username = flatten(contact, \".\")\n            if len(username) < 3:\n                username = getattr(contact, \"email\", \"\").split(\"@\")[0]\n            if len(username) < 3:\n                username = \"user%08d\" % random.randint(0, 99999999)\n            initial.update(\n                username=username,\n                email=getattr(contact, \"email\", \"\"),\n                first_name=getattr(contact, \"first_name\", \"\"),\n                last_name=getattr(contact, \"last_name\", \"\"),\n            )\n        return initial\n    def get_toolbar(self):\n        return UserDetailToolbar(view=self)\n    @atomic\n    def save_form(self, form):\n        self.object = form.save()\n        contact = self._get_bind_contact()\n        if contact and not contact.user:\n            contact.user = self.object\n            contact.save()\n            messages.info(self.request, _(u\"User bound to contact %(contact)s.\") % {\"contact\": contact})\n    def get_success_url(self):\n        return get_model_url(self.object)\n    def _handle_set_is_active(self):\n        state = bool(int(self.request.POST[\"set_is_active\"]))\n        if not state:\n            if (self.object.is_superuser and not self.request.user.is_superuser):\n                raise Problem(_(\"You can not deactivate a superuser.\"))\n            if self.object == self.request.user:\n                raise Problem(_(\"You can not deactivate yourself.\"))\n        self.object.is_active = state\n        self.object.save(update_fields=(\"is_active\",))\n        messages.success(self.request, _(\"%(user)s is now %(state)s.\") % {\n            \"user\": self.object,\n            \"state\": _(\"active\") if state else _(\"inactive\")\n        })\n        return HttpResponseRedirect(self.request.path)\n    def post(self, request, *args, **kwargs):\n", "outputs": ["        self.object = self.get_object()"], "input_length": 1246, "output_length": 5, "length": 1251, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "011dd90c6f61b7af2193ab300cb1fefe24ac16e020cf9dc2f2867c3bd3c7ab92"}
{"input": "", "context": "using System;\nusing System.Collections;\nusing System.Collections.Generic;\nusing Server.Commands;\nusing Server.Engines.PartySystem;\nusing Server.Factions;\nusing Server.Gumps;\nusing Server.Items;\nusing Server.Mobiles;\nusing Server.Network;\nusing Server.Spells;\nusing Server.Spells.Bushido;\nusing Server.Spells.Chivalry;\nusing Server.Spells.Necromancy;\nusing Server.Spells.Ninjitsu;\nusing Server.Spells.Seventh;\nusing Server.Spells.Spellweaving;\nnamespace Server.Engines.ConPVP\n{\n    public delegate void CountdownCallback( int count );\n\tpublic class DuelContext\n\t{\n\t\tprivate Mobile m_Initiator;\n\t\tprivate ArrayList m_Participants;\n\t\tprivate Ruleset m_Ruleset;\n\t\tprivate Arena m_Arena;\n\t\tprivate bool m_Registered = true;\n\t\tprivate bool m_Finished, m_Started;\n\t\tprivate bool m_ReadyWait;\n\t\tprivate int m_ReadyCount;\n\t\tprivate bool m_Rematch;\n\t\tpublic bool Rematch{ get{ return m_Rematch; } }\n\t\tpublic bool ReadyWait{ get{ return m_ReadyWait; } }\n\t\tpublic int ReadyCount{ get{ return m_ReadyCount; } }\n\t\tpublic bool Registered{ get{ return m_Registered; } }\n\t\tpublic bool Finished{ get{ return m_Finished; } }\n\t\tpublic bool Started{ get{ return m_Started; } }\n\t\tpublic Mobile Initiator{ get{ return m_Initiator; } }\n\t\tpublic ArrayList Participants{ get{ return m_Participants; } }\n\t\tpublic Ruleset Ruleset{ get{ return m_Ruleset; } }\n\t\tpublic Arena Arena{ get{ return m_Arena; } }\n\t\tprivate bool CantDoAnything( Mobile mob )\n\t\t{\n\t\t\tif ( m_EventGame != null )\n\t\t\t\treturn m_EventGame.CantDoAnything( mob );\n\t\t\telse\n\t\t\t\treturn false;\n\t\t}\n\t\tpublic static bool IsFreeConsume( Mobile mob )\n\t\t{\n\t\t\tPlayerMobile pm = mob as PlayerMobile;\n\t\t\tif ( pm == null || pm.DuelContext == null || pm.DuelContext.m_EventGame == null )\n\t\t\t\treturn false;\n\t\t\treturn pm.DuelContext.m_EventGame.FreeConsume;\n\t\t}\n\t\tpublic void DelayBounce( TimeSpan ts, Mobile mob, Container corpse )\n\t\t{\n\t\t\tTimer.DelayCall( ts, new TimerStateCallback( DelayBounce_Callback ), new object[]{ mob, corpse } );\n\t\t}\n\t\tpublic static bool AllowSpecialMove( Mobile from, string name, SpecialMove move )\n\t\t{\n\t\t\tPlayerMobile pm = from as PlayerMobile;\n\t\t\tif( pm == null )\n\t\t\t\treturn true;\n\t\t\tDuelContext dc = pm.DuelContext;\n\t\t\treturn (dc == null || dc.InstAllowSpecialMove( from, name, move ));\n\t\t}\n\t\tpublic bool InstAllowSpecialMove( Mobile from, string name, SpecialMove move )\n\t\t{\n\t\t\tif ( !m_StartedBeginCountdown )\n\t\t\t\treturn true;\n\t\t\tDuelPlayer pl = Find( from );\n\t\t\tif ( pl == null || pl.Eliminated )\n\t\t\t\treturn true;\n\t\t\tif ( CantDoAnything( from ) )\n\t\t\t\treturn false;\n\t\t\tstring title = null;\n\t\t\tif( move is NinjaMove )\n\t\t\t\ttitle = \"Bushido\";\n\t\t\telse if( move is SamuraiMove )\n\t\t\t\ttitle = \"Ninjitsu\";\n\t\t\tif ( title == null || name == null || m_Ruleset.GetOption( title, name ) )\n\t\t\t\treturn true;\n\t\t\tfrom.SendMessage( \"The dueling ruleset prevents you from using this move.\" );\n\t\t\treturn false;\n\t\t}\n\t\tpublic bool AllowSpellCast( Mobile from, Spell spell )\n\t\t{\n\t\t\tif ( !m_StartedBeginCountdown )\n\t\t\t\treturn true;\n\t\t\tDuelPlayer pl = Find( from );\n\t\t\tif ( pl == null || pl.Eliminated )\n\t\t\t\treturn true;\n\t\t\tif ( CantDoAnything( from ) )\n\t\t\t\treturn false;\n\t\t\tif ( spell is Server.Spells.Fourth.RecallSpell )\n\t\t\t\tfrom.SendMessage( \"You may not cast this spell.\" );\n\t\t\tstring title = null, option = null;\n\t\t\tif( spell is ArcanistSpell )\n\t\t\t{\n\t\t\t\ttitle = \"Spellweaving\";\n\t\t\t\toption = spell.Name;\n\t\t\t}\n\t\t\telse if ( spell is PaladinSpell )\n\t\t\t{\n\t\t\t\ttitle = \"Chivalry\";\n\t\t\t\toption = spell.Name;\n\t\t\t}\n\t\t\telse if ( spell is NecromancerSpell )\n\t\t\t{\n\t\t\t\ttitle = \"Necromancy\";\n\t\t\t\toption = spell.Name;\n\t\t\t}\n\t\t\telse if ( spell is NinjaSpell )\n\t\t\t{\n\t\t\t\ttitle = \"Ninjitsu\";\n\t\t\t\toption = spell.Name;\n\t\t\t}\n\t\t\telse if ( spell is SamuraiSpell )\n\t\t\t{\n\t\t\t\ttitle = \"Bushido\";\n\t\t\t\toption = spell.Name;\n\t\t\t}\n\t\t\telse if( spell is MagerySpell )\n\t\t\t{\n\t\t\t\tswitch( ((MagerySpell)spell).Circle )\n\t\t\t\t{\n\t\t\t\t\tcase SpellCircle.First: title = \"1st Circle\"; break;\n\t\t\t\t\tcase SpellCircle.Second: title = \"2nd Circle\"; break;\n\t\t\t\t\tcase SpellCircle.Third: title = \"3rd Circle\"; break;\n\t\t\t\t\tcase SpellCircle.Fourth: title = \"4th Circle\"; break;\n\t\t\t\t\tcase SpellCircle.Fifth: title = \"5th Circle\"; break;\n\t\t\t\t\tcase SpellCircle.Sixth: title = \"6th Circle\"; break;\n\t\t\t\t\tcase SpellCircle.Seventh: title = \"7th Circle\"; break;\n\t\t\t\t\tcase SpellCircle.Eighth: title = \"8th Circle\"; break;\n\t\t\t\t}\n\t\t\t\toption = spell.Name;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\ttitle = \"Other Spell\";\n\t\t\t\toption = spell.Name;\n\t\t\t}\n\t\t\tif ( title == null || option == null || m_Ruleset.GetOption( title, option ) )\n\t\t\t\treturn true;\n\t\t\tfrom.SendMessage( \"The dueling ruleset prevents you from casting this spell.\" );\n\t\t\treturn false;\n\t\t}\n\t\tpublic bool AllowItemEquip( Mobile from, Item item )\n\t\t{\n\t\t\tif ( !m_StartedBeginCountdown )\n\t\t\t\treturn true;\n\t\t\tDuelPlayer pl = Find( from );\n\t\t\tif ( pl == null || pl.Eliminated )\n\t\t\t\treturn true;\n\t\t\tif ( item is Dagger || CheckItemEquip( from, item ) )\n\t\t\t\treturn true;\n\t\t\tfrom.SendMessage( \"The dueling ruleset prevents you from equiping this item.\" );\n\t\t\treturn false;\n\t\t}\n\t\tpublic static bool AllowSpecialAbility( Mobile from, string name, bool message )\n\t\t{\n\t\t\tPlayerMobile pm = from as PlayerMobile;\n\t\t\tif ( pm == null )\n\t\t\t\treturn true;\n\t\t\tDuelContext dc = pm.DuelContext;\n\t\t\treturn ( dc == null || dc.InstAllowSpecialAbility( from, name, message ) );\n\t\t}\n\t\tpublic bool InstAllowSpecialAbility( Mobile from, string name, bool message )\n\t\t{\n\t\t\tif ( !m_StartedBeginCountdown )\n\t\t\t\treturn true;\n\t\t\tDuelPlayer pl = Find( from );\n\t\t\tif ( pl == null || pl.Eliminated )\n\t\t\t\treturn true;\n\t\t\tif ( CantDoAnything( from ) )\n\t\t\t\treturn false;\n\t\t\tif ( m_Ruleset.GetOption( \"Combat Abilities\", name ) )\n\t\t\t\treturn true;\n\t\t\tif ( message )\n\t\t\t\tfrom.SendMessage( \"The dueling ruleset prevents you from using this combat ability.\" );\n\t\t\treturn false;\n\t\t}\n\t\tpublic bool CheckItemEquip( Mobile from, Item item )\n\t\t{\n\t\t\tif ( item is Fists )\n\t\t\t{\n\t\t\t\tif ( !m_Ruleset.GetOption( \"Weapons\", \"Wrestling\" ) )\n\t\t\t\t\treturn false;\n\t\t\t}\n\t\t\telse if ( item is BaseArmor )\n\t\t\t{\n\t\t\t\tBaseArmor armor = (BaseArmor)item;\n\t\t\t\tif ( armor.ProtectionLevel > ArmorProtectionLevel.Regular && !m_Ruleset.GetOption( \"Armor\", \"Magical\" ) )\n\t\t\t\t\treturn false;\n\t\t\t\tif ( !Core.AOS && armor.Resource != armor.DefaultResource && !m_Ruleset.GetOption( \"Armor\", \"Colored\" ) )\n\t\t\t\t\treturn false;\n\t\t\t\tif ( armor is BaseShield && !m_Ruleset.GetOption( \"Armor\", \"Shields\" ) )\n\t\t\t\t\treturn false;\n\t\t\t}\n\t\t\telse if ( item is BaseWeapon )\n\t\t\t{\n\t\t\t\tBaseWeapon weapon = (BaseWeapon)item;\n\t\t\t\tif ( (weapon.DamageLevel > WeaponDamageLevel.Regular || weapon.AccuracyLevel > WeaponAccuracyLevel.Regular) && !m_Ruleset.GetOption( \"Weapons\", \"Magical\" ) )\n\t\t\t\t\treturn false;\n\t\t\t\tif ( !Core.AOS && weapon.Resource != CraftResource.Iron && weapon.Resource != CraftResource.None && !m_Ruleset.GetOption( \"Weapons\", \"Runics\" ) )\n\t\t\t\t\treturn false;\n\t\t\t\tif ( weapon is BaseRanged && !m_Ruleset.GetOption( \"Weapons\", \"Ranged\" ) )\n\t\t\t\t\treturn false;\n\t\t\t\tif ( !(weapon is BaseRanged) && !m_Ruleset.GetOption( \"Weapons\", \"Melee\" ) )\n\t\t\t\t\treturn false;\n\t\t\t\tif ( weapon.PoisonCharges > 0 && weapon.Poison != null && !m_Ruleset.GetOption( \"Weapons\", \"Poisoned\" ) )\n\t\t\t\t\treturn false;\n\t\t\t\tif ( weapon is BaseWand && !m_Ruleset.GetOption( \"Items\", \"Wands\" ) )\n\t\t\t\t\treturn false;\n\t\t\t}\n\t\t\treturn true;\n\t\t}\n\t\tpublic bool AllowSkillUse( Mobile from, SkillName skill )\n\t\t{\n\t\t\tif ( !m_StartedBeginCountdown )\n\t\t\t\treturn true;\n\t\t\tDuelPlayer pl = Find( from );\n\t\t\tif ( pl == null || pl.Eliminated )\n\t\t\t\treturn true;\n\t\t\tif ( CantDoAnything( from ) )\n\t\t\t\treturn false;\n\t\t\tint id = (int)skill;\n\t\t\tif ( id >= 0 && id < SkillInfo.Table.Length )\n\t\t\t{\n\t\t\t\tif ( m_Ruleset.GetOption( \"Skills\", SkillInfo.Table[id].Name ) )\n\t\t\t\t\treturn true;\n\t\t\t}\n\t\t\tfrom.SendMessage( \"The dueling ruleset prevents you from using this skill.\" );\n\t\t\treturn false;\n\t\t}\n\t\tpublic bool AllowItemUse( Mobile from, Item item )\n\t\t{\n\t\t\tif ( !m_StartedBeginCountdown )\n\t\t\t\treturn true;\n\t\t\tDuelPlayer pl = Find( from );\n\t\t\tif ( pl == null || pl.Eliminated )\n\t\t\t\treturn true;\n\t\t\tif ( !(item is BaseRefreshPotion) )\n\t\t\t{\n\t\t\t\tif ( CantDoAnything( from ) )\n\t\t\t\t\treturn false;\n\t\t\t}\n\t\t\tstring title = null, option = null;\n\t\t\tif ( item is BasePotion )\n\t\t\t{\n\t\t\t\ttitle = \"Potions\";\n\t\t\t\tif ( item is BaseAgilityPotion )\n\t\t\t\t\toption = \"Agility\";\n\t\t\t\telse if ( item is BaseCurePotion )\n\t\t\t\t\toption = \"Cure\";\n\t\t\t\telse if ( item is BaseHealPotion )\n\t\t\t\t\toption = \"Heal\";\n\t\t\t\telse if ( item is NightSightPotion )\n\t\t\t\t\toption = \"Nightsight\";\n\t\t\t\telse if ( item is BasePoisonPotion )\n\t\t\t\t\toption = \"Poison\";\n\t\t\t\telse if ( item is BaseStrengthPotion )\n\t\t\t\t\toption = \"Strength\";\n\t\t\t\telse if ( item is BaseExplosionPotion )\n\t\t\t\t\toption = \"Explosion\";\n\t\t\t\telse if ( item is BaseRefreshPotion )\n\t\t\t\t\toption = \"Refresh\";\n\t\t\t}\n\t\t\telse if ( item is Bandage )\n\t\t\t{\n\t\t\t\ttitle = \"Items\";\n\t\t\t\toption = \"Bandages\";\n\t\t\t}\n\t\t\telse if ( item is TrapableContainer )\n\t\t\t{\n\t\t\t\tif ( ((TrapableContainer)item).TrapType != TrapType.None )\n\t\t\t\t{\n\t\t\t\t\ttitle = \"Items\";\n\t\t\t\t\toption = \"Trapped Containers\";\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if ( item is Bola )\n\t\t\t{\n\t\t\t\ttitle = \"Items\";\n\t\t\t\toption = \"Bolas\";\n\t\t\t}\n\t\t\telse if ( item is OrangePetals )\n\t\t\t{\n\t\t\t\ttitle = \"Items\";\n\t\t\t\toption = \"Orange Petals\";\n\t\t\t}\n\t\t\telse if ( item is EtherealMount || item.Layer == Layer.Mount )\n\t\t\t{\n\t\t\t\ttitle = \"Items\";\n\t\t\t\toption = \"Mounts\";\n\t\t\t}\n\t\t\telse if ( item is LeatherNinjaBelt )\n\t\t\t{\n\t\t\t\ttitle = \"Items\";\n\t\t\t\toption = \"Shurikens\";\n\t\t\t}\n\t\t\telse if ( item is Fukiya )\n\t\t\t{\n\t\t\t\ttitle = \"Items\";\n\t\t\t\toption = \"Fukiya Darts\";\n\t\t\t}\n\t\t\telse if ( item is FireHorn )\n\t\t\t{\n\t\t\t\ttitle = \"Items\";\n\t\t\t\toption = \"Fire Horns\";\n\t\t\t}\n\t\t\telse if ( item is BaseWand )\n\t\t\t{\n\t\t\t\ttitle = \"Items\";\n\t\t\t\toption = \"Wands\";\n\t\t\t}\n\t\t\tif ( title != null && option != null && m_StartedBeginCountdown && !m_Started )\n\t\t\t{\n\t\t\t\tfrom.SendMessage( \"You may not use this item before the duel begins.\" );\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\telse if ( item is BasePotion && !(item is BaseExplosionPotion) && !(item is BaseRefreshPotion) && IsSuddenDeath )\n\t\t\t{\n\t\t\t\tfrom.SendMessage( 0x22, \"You may not drink potions in sudden death.\" );\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\telse if ( item is Bandage && IsSuddenDeath )\n\t\t\t{\n\t\t\t\tfrom.SendMessage( 0x22, \"You may not use bandages in sudden death.\" );\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\tif ( title == null || option == null || m_Ruleset.GetOption( title, option ) )\n\t\t\t\treturn true;\n\t\t\tfrom.SendMessage( \"The dueling ruleset prevents you from using this item.\" );\n\t\t\treturn false;\n\t\t}\n\t\tprivate void DelayBounce_Callback( object state )\n\t\t{\n\t\t\tobject[] states = (object[])state;\n\t\t\tMobile mob = (Mobile) states[0];\n\t\t\tContainer corpse = (Container) states[1];\n\t\t\tRemoveAggressions( mob );\n\t\t\tSendOutside( mob );\n\t\t\tRefresh( mob, corpse );\n\t\t\tDebuff( mob );\n\t\t\tCancelSpell( mob );\n\t\t\tmob.Frozen = false;\n\t\t}\n\t\tpublic void OnMapChanged( Mobile mob )\n\t\t{\n\t\t\tOnLocationChanged( mob );\n\t\t}\n\t\tpublic void OnLocationChanged( Mobile mob )\n\t\t{\n\t\t\tif ( !m_Registered || !m_StartedBeginCountdown || m_Finished )\n\t\t\t\treturn;\n\t\t\tArena arena = m_Arena;\n\t\t\tif ( arena == null )\n\t\t\t\treturn;\n\t\t\tif ( mob.Map == arena.Facet && arena.Bounds.Contains( mob.Location ) )\n\t\t\t\treturn;\n\t\t\tDuelPlayer pl = Find( mob );\n\t\t\tif ( pl == null || pl.Eliminated )\n\t\t\t\treturn;\n\t\t\tif ( mob.Map == Map.Internal ) {\n\t\t\t\t// they've logged out\n\t\t\t\tif ( mob.LogoutMap == arena.Facet && arena.Bounds.Contains( mob.LogoutLocation ) ) {\n\t\t\t\t\t// they logged out inside the arena.. set them to eject on login\n\t\t\t\t\tmob.LogoutLocation = arena.Outside;\n\t\t\t\t}\n\t\t\t}\n\t\t\tpl.Eliminated = true;\n\t\t\tmob.LocalOverheadMessage( MessageType.Regular, 0x22, false, \"You have forfeited your position in the duel.\" );\n\t\t\tmob.NonlocalOverheadMessage( MessageType.Regular, 0x22, false, String.Format( \"{0} has forfeited by leaving the dueling arena.\", mob.Name ) );\n\t\t\tParticipant winner = CheckCompletion();\n\t\t\tif ( winner != null )\n\t\t\t\tFinish( winner );\n\t\t}\n\t\tprivate bool m_Yielding;\n\t\tpublic void OnDeath( Mobile mob, Container corpse )\n\t\t{\n\t\t\tif ( !m_Registered || !m_Started )\n\t\t\t\treturn;\n\t\t\tDuelPlayer pl = Find( mob );\n\t\t\tif ( pl != null && !pl.Eliminated )\n\t\t\t{\n\t\t\t\tif ( m_EventGame != null && !m_EventGame.OnDeath( mob, corpse ) )\n\t\t\t\t\treturn;\n\t\t\t\tpl.Eliminated = true;\n\t\t\t\tif ( mob.Poison != null )\n\t\t\t\t\tmob.Poison = null;\n\t\t\t\tRequip( mob, corpse );\n\t\t\t\tDelayBounce( TimeSpan.FromSeconds( 4.0 ), mob, corpse );\n\t\t\t\tParticipant winner = CheckCompletion();\n\t\t\t\tif ( winner != null )\n\t\t\t\t{\n\t\t\t\t\tFinish( winner );\n\t\t\t\t}\n\t\t\t\telse if ( !m_Yielding )\n\t\t\t\t{\n\t\t\t\t\tmob.LocalOverheadMessage( MessageType.Regular, 0x22, false, \"You have been defeated.\" );\n\t\t\t\t\tmob.NonlocalOverheadMessage( MessageType.Regular, 0x22, false, String.Format( \"{0} has been defeated.\", mob.Name ) );\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tpublic bool CheckFull()\n\t\t{\n\t\t\tfor ( int i = 0; i < m_Participants.Count; ++i )\n\t\t\t{\n\t\t\t\tParticipant p = (Participant)m_Participants[i];\n\t\t\t\tif ( p.HasOpenSlot )\n\t\t\t\t\treturn false;\n\t\t\t}\n\t\t\treturn true;\n\t\t}\n\t\tpublic void Requip( Mobile from, Container cont )\n\t\t{\n\t\t\tCorpse corpse = cont as Corpse;\n\t\t\tif ( corpse == null )\n\t\t\t\treturn;\n\t\t\tList<Item> items = new List<Item>( corpse.Items );\n\t\t\tbool gathered = false;\n\t\t\tbool didntFit = false;\n\t\t\tContainer pack = from.Backpack;\n\t\t\tfor ( int i = 0; !didntFit && i < items.Count; ++i )\n\t\t\t{\n\t\t\t\tItem item = items[i];\n\t\t\t\tPoint3D loc = item.Location;\n\t\t\t\tif ( (item.Layer == Layer.Hair || item.Layer == Layer.FacialHair) || !item.Movable )\n\t\t\t\t\tcontinue;\n\t\t\t\tif ( pack != null )\n\t\t\t\t{\n\t\t\t\t\tpack.DropItem( item );\n\t\t\t\t\tgathered = true;\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tdidntFit = true;\n\t\t\t\t}\n\t\t\t}\n\t\t\tcorpse.Carved = true;\n\t\t\tif ( corpse.ItemID == 0x2006 )\n\t\t\t{\n\t\t\t\tcorpse.ProcessDelta();\n\t\t\t\tcorpse.SendRemovePacket();\n\t\t\t\tcorpse.ItemID = Utility.Random( 0xECA, 9 ); // bone graphic\n\t\t\t\tcorpse.Hue = 0;\n\t\t\t\tcorpse.ProcessDelta();\n\t\t\t\tMobile killer = from.FindMostRecentDamager( false );\n\t\t\t\tif ( killer != null && killer.Player )\n\t\t\t\t\tkiller.AddToBackpack( new Head( m_Tournament == null ? HeadType.Duel : HeadType.Tournament, from.Name ) );\n\t\t\t}\n\t\t\tfrom.PlaySound( 0x3E3 );\n\t\t\tif ( gathered && !didntFit )\n\t\t\t\tfrom.SendLocalizedMessage( 1062471 ); // You quickly gather all of your belongings.\n\t\t\telse if ( gathered && didntFit )\n\t\t\t\tfrom.SendLocalizedMessage( 1062472 ); // You gather some of your belongings. The rest remain on the corpse.\n\t\t}\n\t\tpublic void Refresh( Mobile mob, Container cont )\n\t\t{\n\t\t\tif ( !mob.Alive )\n\t\t\t{\n\t\t\t\tmob.Resurrect();\n\t\t\t\tDeathRobe robe = mob.FindItemOnLayer( Layer.OuterTorso ) as DeathRobe;\n\t\t\t\tif ( robe != null )\n\t\t\t\t\trobe.Delete();\n\t\t\t\tif ( cont is Corpse )\n\t\t\t\t{\n\t\t\t\t\tCorpse corpse = (Corpse) cont;\n\t\t\t\t\tfor ( int i = 0; i < corpse.EquipItems.Count; ++i )\n\t\t\t\t\t{\n\t\t\t\t\t\tItem item = corpse.EquipItems[i];\n\t\t\t\t\t\tif ( item.Movable && item.Layer != Layer.Hair && item.Layer != Layer.FacialHair && item.IsChildOf( mob.Backpack ) )\n\t\t\t\t\t\t\tmob.EquipItem( item );\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tmob.Hits = mob.HitsMax;\n\t\t\tmob.Stam = mob.StamMax;\n\t\t\tmob.Mana = mob.ManaMax;\n\t\t\tmob.Poison = null;\n\t\t}\n\t\tpublic void SendOutside( Mobile mob )\n\t\t{\n\t\t\tif ( m_Arena == null )\n\t\t\t\treturn;\n\t\t\tmob.Combatant = null;\n\t\t\tmob.MoveToWorld( m_Arena.Outside, m_Arena.Facet );\n\t\t}\n\t\tprivate Point3D m_GatePoint;\n\t\tprivate Map m_GateFacet;\n\t\tpublic void Finish( Participant winner )\n\t\t{\n\t\t\tif ( m_Finished )\n\t\t\t\treturn;\n\t\t\tEndAutoTie();\n\t\t\tStopSDTimers();\n\t\t\tm_Finished = true;\n\t\t\tfor ( int i = 0; i < winner.Players.Length; ++i )\n\t\t\t{\n\t\t\t\tDuelPlayer pl = winner.Players[i];\n\t\t\t\tif ( pl != null && !pl.Eliminated )\n\t\t\t\t\tDelayBounce( TimeSpan.FromSeconds( 8.0 ), pl.Mobile, null );\n\t\t\t}\n\t\t\twinner.Broadcast( 0x59, null, winner.Players.Length == 1 ? \"{0} has won the duel.\" : \"{0} and {1} team have won the duel.\", winner.Players.Length == 1 ? \"You have won the duel.\" : \"Your team has won the duel.\" );\n\t\t\tif ( m_Tournament != null && winner.TournyPart != null )\n\t\t\t{\n\t\t\t\tm_Match.Winner = winner.TournyPart;\n\t\t\t\twinner.TournyPart.WonMatch( m_Match );\n\t\t\t\tm_Tournament.HandleWon( m_Arena, m_Match, winner.TournyPart );\n\t\t\t}\n\t\t\tfor ( int i = 0; i < m_Participants.Count; ++i )\n\t\t\t{\n\t\t\t\tParticipant loser = (Participant)m_Participants[i];\n\t\t\t\tif ( loser != winner )\n\t\t\t\t{\n\t\t\t\t\tloser.Broadcast( 0x22, null, loser.Players.Length == 1 ? \"{0} has lost the duel.\" : \"{0} and {1} team have lost the duel.\", loser.Players.Length == 1 ? \"You have lost the duel.\" : \"Your team has lost the duel.\" );\n\t\t\t\t\tif ( m_Tournament != null && loser.TournyPart != null )\n\t\t\t\t\t\tloser.TournyPart.LostMatch( m_Match );\n\t\t\t\t}\n\t\t\t\tfor ( int j = 0; j < loser.Players.Length; ++j )\n\t\t\t\t{\n\t\t\t\t\tif ( loser.Players[j] != null )\n\t\t\t\t\t{\n\t\t\t\t\t\tRemoveAggressions( loser.Players[j].Mobile );\n\t\t\t\t\t\tloser.Players[j].Mobile.Delta( MobileDelta.Noto );\n\t\t\t\t\t\tloser.Players[j].Mobile.CloseGump( typeof( BeginGump ) );\n\t\t\t\t\t\tif ( m_Tournament != null )\n\t\t\t\t\t\t\tloser.Players[j].Mobile.SendEverything();\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif ( IsOneVsOne )\n\t\t\t{\n\t\t\t\tDuelPlayer dp1 = ((Participant)m_Participants[0]).Players[0];\n\t\t\t\tDuelPlayer dp2 = ((Participant)m_Participants[1]).Players[0];\n\t\t\t\tif ( dp1 != null && dp2 != null )\n\t\t\t\t{\n\t\t\t\t\tAward( dp1.Mobile, dp2.Mobile, dp1.Participant == winner );\n\t\t\t\t\tAward( dp2.Mobile, dp1.Mobile, dp2.Participant == winner );\n\t\t\t\t}\n\t\t\t}\n\t\t\tif ( m_EventGame != null )\n\t\t\t\tm_EventGame.OnStop();\n\t\t\tTimer.DelayCall( TimeSpan.FromSeconds( 9.0 ), new TimerCallback( UnregisterRematch ) );\n\t\t}\n\t\tpublic void Award( Mobile us, Mobile them, bool won )\n\t\t{\n\t\t\tLadder ladder = ( m_Arena == null ? Ladder.Instance : m_Arena.AcquireLadder() );\n\t\t\tif ( ladder == null )\n\t\t\t\treturn;\n\t\t\tLadderEntry ourEntry = ladder.Find( us );\n\t\t\tLadderEntry theirEntry = ladder.Find( them );\n\t\t\tif ( ourEntry == null || theirEntry == null )\n\t\t\t\treturn;\n\t\t\tint xpGain = Ladder.GetExperienceGain( ourEntry, theirEntry, won );\n\t\t\tif ( xpGain == 0 )\n\t\t\t\treturn;\n\t\t\tif ( m_Tournament != null )\n\t\t\t\txpGain *= ( xpGain > 0 ? 5 : 2 );\n\t\t\tif ( won )\n\t\t\t\t++ourEntry.Wins;\n\t\t\telse\n\t\t\t\t++ourEntry.Losses;\n\t\t\tint oldLevel = Ladder.GetLevel( ourEntry.Experience );\n\t\t\tourEntry.Experience += xpGain;\n\t\t\tif ( ourEntry.Experience < 0 )\n\t\t\t\tourEntry.Experience = 0;\n\t\t\tladder.UpdateEntry( ourEntry );\n\t\t\tint newLevel = Ladder.GetLevel( ourEntry.Experience );\n\t\t\tif ( newLevel > oldLevel )\n\t\t\t\tus.SendMessage( 0x59, \"You have achieved level {0}!\", newLevel );\n\t\t\telse if ( newLevel < oldLevel )\n\t\t\t\tus.SendMessage( 0x22, \"You have lost a level. You are now at {0}.\", newLevel );\n\t\t}\n\t\tpublic void UnregisterRematch()\n\t\t{\n\t\t\tUnregister(true);\n\t\t}\n\t\tpublic void Unregister()\n\t\t{\n\t\t\tUnregister(false);\n\t\t}\n\t\tpublic void Unregister( bool queryRematch )\n\t\t{\n\t\t\tDestroyWall();\n\t\t\tif ( !m_Registered )\n\t\t\t\treturn;\n\t\t\tm_Registered = false;\n\t\t\tif ( m_Arena != null )\n\t\t\t\tm_Arena.Evict();\n\t\t\tStopSDTimers();\n\t\t\tType[] types = new Type[]{ typeof( BeginGump ), typeof( DuelContextGump ), typeof( ParticipantGump ), typeof( PickRulesetGump ), typeof( ReadyGump ), typeof( ReadyUpGump ), typeof( RulesetGump ) };\n\t\t\tfor ( int i = 0; i < m_Participants.Count; ++i )\n\t\t\t{\n\t\t\t\tParticipant p = (Participant)m_Participants[i];\n\t\t\t\tfor ( int j = 0; j < p.Players.Length; ++j )\n\t\t\t\t{\n\t\t\t\t\tDuelPlayer pl = (DuelPlayer)p.Players[j];\n\t\t\t\t\tif ( pl == null )\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\tif ( pl.Mobile is PlayerMobile )\n\t\t\t\t\t\t((PlayerMobile)pl.Mobile).DuelPlayer = null;\n\t\t\t\t\tfor ( int k = 0; k < types.Length; ++k )\n\t\t\t\t\t\tpl.Mobile.CloseGump( types[k] );\n\t\t\t\t}\n\t\t\t}\n\t\t\tif ( queryRematch && m_Tournament == null )\n\t\t\t\tQueryRematch();\n\t\t}\n\t\tpublic void QueryRematch()\n\t\t{\n\t\t\tDuelContext dc = new DuelContext( m_Initiator, m_Ruleset.Layout, false );\n\t\t\tdc.m_Ruleset = m_Ruleset;\n\t\t\tdc.m_Rematch = true;\n\t\t\tdc.m_Participants.Clear();\n\t\t\tfor ( int i = 0; i < m_Participants.Count; ++i )\n\t\t\t{\n\t\t\t\tParticipant oldPart = (Participant)m_Participants[i];\n\t\t\t\tParticipant newPart = new Participant( dc, oldPart.Players.Length );\n\t\t\t\tfor ( int j = 0; j < oldPart.Players.Length; ++j )\n\t\t\t\t{\n\t\t\t\t\tDuelPlayer oldPlayer = oldPart.Players[j];\n\t\t\t\t\tif ( oldPlayer != null )\n\t\t\t\t\t\tnewPart.Players[j] = new DuelPlayer( oldPlayer.Mobile, newPart );\n\t\t\t\t}\n\t\t\t\tdc.m_Participants.Add( newPart );\n\t\t\t}\n\t\t\tdc.CloseAllGumps();\n\t\t\tdc.SendReadyUpGump();\n\t\t}\n\t\tpublic DuelPlayer Find( Mobile mob )\n\t\t{\n\t\t\tif ( mob is PlayerMobile )\n\t\t\t{\n\t\t\t\tPlayerMobile pm = (PlayerMobile)mob;\n\t\t\t\tif ( pm.DuelContext == this )\n\t\t\t\t\treturn pm.DuelPlayer;\n\t\t\t\treturn null;\n\t\t\t}\n\t\t\tfor ( int i = 0; i < m_Participants.Count; ++i )\n\t\t\t{\n\t\t\t\tParticipant p = (Participant)m_Participants[i];\n\t\t\t\tDuelPlayer pl = p.Find( mob );\n\t\t\t\tif ( pl != null )\n\t\t\t\t\treturn pl;\n\t\t\t}\n\t\t\treturn null;\n\t\t}\n\t\tpublic bool IsAlly( Mobile m1, Mobile m2 )\n\t\t{\n\t\t\tDuelPlayer pl1 = Find( m1 );\n\t\t\tDuelPlayer pl2 = Find( m2 );\n\t\t\treturn ( pl1 != null && pl2 != null && pl1.Participant == pl2.Participant );\n\t\t}\n\t\tpublic Participant CheckCompletion()\n\t\t{\n\t\t\tParticipant winner = null;\n\t\t\tbool hasWinner = false;\n\t\t\tint eliminated = 0;\n\t\t\tfor ( int i = 0; i < m_Participants.Count; ++i )\n\t\t\t{\n\t\t\t\tParticipant p = (Participant)m_Participants[i];\n\t\t\t\tif ( p.Eliminated )\n\t\t\t\t{\n\t\t\t\t\t++eliminated;\n\t\t\t\t\tif ( eliminated == (m_Participants.Count - 1) )\n\t\t\t\t\t\thasWinner = true;\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\twinner = p;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif ( hasWinner )\n\t\t\t\treturn winner == null ? (Participant) m_Participants[0] : winner;\n\t\t\treturn null;\n\t\t}\n\t\tprivate Timer m_Countdown;\n\t\tpublic void StartCountdown( int count, CountdownCallback cb )\n\t\t{\n\t\t\tcb(count);\n\t\t\tm_Countdown=Timer.DelayCall( TimeSpan.FromSeconds( 1.0 ), TimeSpan.FromSeconds( 1.0 ), count, new TimerStateCallback( Countdown_Callback ), new object[]{ count-1, cb } );\n\t\t}\n\t\tpublic void StopCountdown()\n\t\t{\n\t\t\tif ( m_Countdown != null )\n\t\t\t\tm_Countdown.Stop();\n\t\t\tm_Countdown = null;\n\t\t}\n\t\tprivate void Countdown_Callback( object state )\n\t\t{\n\t\t\tobject[] states = (object[])state;\n\t\t\tint count = (int)states[0];\n\t\t\tCountdownCallback cb = (CountdownCallback)states[1];\n\t\t\tif ( count==0 )\n\t\t\t{\n\t\t\t\tif ( m_Countdown != null )\n\t\t\t\t\tm_Countdown.Stop();\n\t\t\t\tm_Countdown=null;\n\t\t\t}\n\t\t\tcb( count );\n\t\t\tstates[0] = count - 1;\n\t\t}\n\t\tprivate Timer m_AutoTieTimer;\n\t\tprivate bool m_Tied;\n\t\tpublic bool Tied{ get{ return m_Tied; } }\n\t\tprivate bool m_IsSuddenDeath;\n\t\tpublic bool IsSuddenDeath{ get{ return m_IsSuddenDeath; } set{ m_IsSuddenDeath = value; } }\n\t\tprivate Timer m_SDWarnTimer, m_SDActivateTimer;\n\t\tpublic void StopSDTimers()\n\t\t{\n\t\t\tif ( m_SDWarnTimer != null )\n\t\t\t\tm_SDWarnTimer.Stop();\n\t\t\tm_SDWarnTimer = null;\n\t\t\tif ( m_SDActivateTimer != null )\n\t\t\t\tm_SDActivateTimer.Stop();\n\t\t\tm_SDActivateTimer = null;\n\t\t}\n\t\tpublic void StartSuddenDeath( TimeSpan timeUntilActive )\n\t\t{\n\t\t\tif ( m_SDWarnTimer != null )\n\t\t\t\tm_SDWarnTimer.Stop();\n\t\t\tm_SDWarnTimer = Timer.DelayCall( TimeSpan.FromMinutes( timeUntilActive.TotalMinutes * 0.9 ), new TimerCallback( WarnSuddenDeath ) );\n\t\t\tif ( m_SDActivateTimer != null )\n\t\t\t\tm_SDActivateTimer.Stop();\n\t\t\tm_SDActivateTimer = Timer.DelayCall( timeUntilActive, new TimerCallback( ActivateSuddenDeath ) );\n\t\t}\n\t\tpublic void WarnSuddenDeath()\n\t\t{\n\t\t\tfor ( int i = 0; i < m_Participants.Count; ++i )\n\t\t\t{\n\t\t\t\tParticipant p = (Participant)m_Participants[i];\n\t\t\t\tfor ( int j = 0; j < p.Players.Length; ++j )\n\t\t\t\t{\n\t\t\t\t\tDuelPlayer pl = p.Players[j];\n\t\t\t\t\tif ( pl == null || pl.Eliminated )\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\tpl.Mobile.SendSound( 0x1E1 );\n\t\t\t\t\tpl.Mobile.SendMessage( 0x22, \"Warning! Warning! Warning!\" );\n\t\t\t\t\tpl.Mobile.SendMessage( 0x22, \"Sudden death will be active soon!\" );\n\t\t\t\t}\n\t\t\t}\n\t\t\tif ( m_Tournament != null )\n\t\t\t\tm_Tournament.Alert( m_Arena, \"Sudden death will be active soon!\" );\n\t\t\tif ( m_SDWarnTimer != null )\n\t\t\t\tm_SDWarnTimer.Stop();\n\t\t\tm_SDWarnTimer = null;\n\t\t}\n\t\tpublic static bool CheckSuddenDeath( Mobile mob )\n\t\t{\n\t\t\tif ( mob is PlayerMobile )\n\t\t\t{\n\t\t\t\tPlayerMobile pm = (PlayerMobile)mob;\n\t\t\t\tif ( pm.DuelPlayer != null && !pm.DuelPlayer.Eliminated && pm.DuelContext != null && pm.DuelContext.IsSuddenDeath )\n\t\t\t\t\treturn true;\n\t\t\t}\n\t\t\treturn false;\n\t\t}\n\t\tpublic void ActivateSuddenDeath()\n\t\t{\n\t\t\tfor ( int i = 0; i < m_Participants.Count; ++i )\n\t\t\t{\n\t\t\t\tParticipant p = (Participant)m_Participants[i];\n\t\t\t\tfor ( int j = 0; j < p.Players.Length; ++j )\n\t\t\t\t{\n\t\t\t\t\tDuelPlayer pl = p.Players[j];\n\t\t\t\t\tif ( pl == null || pl.Eliminated )\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\tpl.Mobile.SendSound( 0x1E1 );\n\t\t\t\t\tpl.Mobile.SendMessage( 0x22, \"Warning! Warning! Warning!\" );\n\t\t\t\t\tpl.Mobile.SendMessage( 0x22, \"Sudden death has ACTIVATED. You are now unable to perform any beneficial actions.\" );\n\t\t\t\t}\n\t\t\t}\n\t\t\tif ( m_Tournament != null )\n\t\t\t\tm_Tournament.Alert( m_Arena, \"Sudden death has been activated!\" );\n\t\t\tm_IsSuddenDeath = true;\n\t\t\tif ( m_SDActivateTimer != null )\n\t\t\t\tm_SDActivateTimer.Stop();\n\t\t\tm_SDActivateTimer = null;\n\t\t}\n\t\tpublic void BeginAutoTie()\n\t\t{\n\t\t\tif ( m_AutoTieTimer != null )\n\t\t\t\tm_AutoTieTimer.Stop();\n\t\t\tTimeSpan ts = ( m_Tournament == null || m_Tournament.TournyType == TournyType.Standard )\n\t\t\t\t? AutoTieDelay\n\t\t\t\t: TimeSpan.FromMinutes( 90.0 );\n\t\t\tm_AutoTieTimer = Timer.DelayCall( ts, new TimerCallback( InvokeAutoTie ) );\n\t\t}\n\t\tpublic void EndAutoTie()\n\t\t{\n\t\t\tif ( m_AutoTieTimer != null )\n\t\t\t\tm_AutoTieTimer.Stop();\n\t\t\tm_AutoTieTimer = null;\n\t\t}\n\t\tpublic void InvokeAutoTie()\n\t\t{\n\t\t\tm_AutoTieTimer = null;\n\t\t\tif ( !m_Started || m_Finished )\n\t\t\t\treturn;\n\t\t\tm_Tied = true;\n\t\t\tm_Finished = true;\n\t\t\tStopSDTimers();\n\t\t\tArrayList remaining = new ArrayList();\n\t\t\tfor ( int i = 0; i < m_Participants.Count; ++i )\n\t\t\t{\n\t\t\t\tParticipant p = (Participant)m_Participants[i];\n\t\t\t\tif ( p.Eliminated )\n\t\t\t\t{\n\t\t\t\t\tp.Broadcast( 0x22, null, p.Players.Length == 1 ? \"{0} has lost the duel.\" : \"{0} and {1} team have lost the duel.\", p.Players.Length == 1 ? \"You have lost the duel.\" : \"Your team has lost the duel.\" );\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tp.Broadcast( 0x59, null, p.Players.Length == 1 ? \"{0} has tied the duel due to time expiration.\" : \"{0} and {1} team have tied the duel due to time expiration.\", p.Players.Length == 1 ? \"You have tied the duel due to time expiration.\" : \"Your team has tied the duel due to time expiration.\" );\n\t\t\t\t\tfor ( int j = 0; j < p.Players.Length; ++j )\n\t\t\t\t\t{\n\t\t\t\t\t\tDuelPlayer pl = p.Players[j];\n\t\t\t\t\t\tif ( pl != null && !pl.Eliminated )\n\t\t\t\t\t\t\tDelayBounce( TimeSpan.FromSeconds( 8.0 ), pl.Mobile, null );\n\t\t\t\t\t}\n\t\t\t\t\tif ( p.TournyPart != null )\n\t\t\t\t\t\tremaining.Add( p.TournyPart );\n\t\t\t\t}\n\t\t\t\tfor ( int j = 0; j < p.Players.Length; ++j )\n\t\t\t\t{\n\t\t\t\t\tDuelPlayer pl = p.Players[j];\n\t\t\t\t\tif ( pl != null )\n\t\t\t\t\t{\n\t\t\t\t\t\tpl.Mobile.Delta( MobileDelta.Noto );\n\t\t\t\t\t\tpl.Mobile.SendEverything();\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif ( m_Tournament != null )\n\t\t\t\tm_Tournament.HandleTie( m_Arena, m_Match, remaining );\n\t\t\tTimer.DelayCall( TimeSpan.FromSeconds( 10.0 ), new TimerCallback( Unregister ) );\n\t\t}\n\t\tpublic bool IsOneVsOne\n\t\t{\n\t\t\tget\n\t\t\t{\n\t\t\t\tif ( m_Participants.Count != 2 )\n\t\t\t\t\treturn false;\n\t\t\t\tif ( ((Participant)m_Participants[0]).Players.Length != 1 )\n\t\t\t\t\treturn false;\n\t\t\t\tif ( ((Participant)m_Participants[1]).Players.Length != 1 )\n\t\t\t\t\treturn false;\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\tpublic static void Initialize()\n\t\t{\n\t\t\tEventSink.Speech += new SpeechEventHandler( EventSink_Speech );\n\t\t\tEventSink.Login += new LoginEventHandler( EventSink_Login );\n\t\t\tCommandSystem.Register( \"vli\", AccessLevel.GameMaster, new CommandEventHandler( vli_oc ) );\n\t\t}\n\t\tprivate static void vli_oc( CommandEventArgs e )\n\t\t{\n\t\t\te.Mobile.BeginTarget( -1, false, Targeting.TargetFlags.None, new TargetCallback( vli_ot ) );\n\t\t}\n\t\tprivate static void vli_ot( Mobile from, object obj )\n\t\t{\n\t\t\tif ( obj is PlayerMobile )\n\t\t\t{\n\t\t\t\tPlayerMobile pm = (PlayerMobile)obj;\n\t\t\t\tLadder ladder = Ladder.Instance;\n\t\t\t\tif ( ladder == null )\n\t\t\t\t\treturn;\n\t\t\t\tLadderEntry entry = ladder.Find( pm );\n\t\t\t\tif ( entry != null )\n\t\t\t\t\tfrom.SendGump( new PropertiesGump( from, entry ) );\n\t\t\t}\n\t\t}\n\t\tprivate static TimeSpan CombatDelay = TimeSpan.FromSeconds( 30.0 );\n\t\tprivate static TimeSpan AutoTieDelay = TimeSpan.FromMinutes( 15.0 );\n\t\tpublic static bool CheckCombat( Mobile m )\n\t\t{\n\t\t\tfor ( int i = 0; i < m.Aggressed.Count; ++i )\n\t\t\t{\n\t\t\t\tAggressorInfo info = m.Aggressed[i];\n\t\t\t\tif ( info.Defender.Player && (DateTime.UtcNow - info.LastCombatTime) < CombatDelay )\n\t\t\t\t\treturn true;\n\t\t\t}\n\t\t\tfor ( int i = 0; i < m.Aggressors.Count; ++i )\n\t\t\t{\n\t\t\t\tAggressorInfo info = m.Aggressors[i];\n\t\t\t\tif ( info.Attacker.Player && (DateTime.UtcNow - info.LastCombatTime) < CombatDelay )\n\t\t\t\t\treturn true;\n\t\t\t}\n\t\t\treturn false;\n\t\t}\n\t\tprivate static void EventSink_Login( LoginEventArgs e )\n\t\t{\n\t\t\tPlayerMobile pm = e.Mobile as PlayerMobile;\n\t\t\tif ( pm == null )\n\t\t\t\treturn;\n\t\t\tDuelContext dc = pm.DuelContext;\n\t\t\tif ( dc == null )\n\t\t\t\treturn;\n\t\t\tif ( dc.ReadyWait && pm.DuelPlayer.Ready && !dc.Started && !dc.StartedBeginCountdown && !dc.Finished )\n\t\t\t{\n\t\t\t\tif ( dc.m_Tournament == null )\n\t\t\t\t\tpm.SendGump( new ReadyGump( pm, dc, dc.m_ReadyCount ) );\n\t\t\t}\n\t\t\telse if ( dc.ReadyWait && !dc.StartedBeginCountdown && !dc.Started && !dc.Finished )\n\t\t\t{\n\t\t\t\tif ( dc.m_Tournament == null )\n\t\t\t\t\tpm.SendGump( new ReadyUpGump( pm, dc ) );\n\t\t\t}\n\t\t\telse if ( dc.Initiator == pm && !dc.ReadyWait && !dc.StartedBeginCountdown && !dc.Started && !dc.Finished )\n\t\t\t\tpm.SendGump( new DuelContextGump( pm, dc ) );\n\t\t}\n\t\tprivate static void ViewLadder_OnTarget( Mobile from, object obj, object state )\n\t\t{\n\t\t\tif ( obj is PlayerMobile )\n\t\t\t{\n\t\t\t\tPlayerMobile pm = (PlayerMobile)obj;\n\t\t\t\tLadder ladder = (Ladder)state;\n\t\t\t\tLadderEntry entry = ladder.Find( pm );\n\t\t\t\tif ( entry == null )\n\t\t\t\t\treturn; // sanity\n\t\t\t\tstring text = String.Format( \"{{0}} are ranked {0} at level {1}.\", LadderGump.Rank( entry.Index + 1 ), Ladder.GetLevel( entry.Experience ) );\n\t\t\t\tpm.PrivateOverheadMessage( MessageType.Regular, pm.SpeechHue, true, String.Format( text, from==pm?\"You\":\"They\" ), from.NetState );\n\t\t\t}\n\t\t\telse if ( obj is Mobile )\n\t\t\t{\n\t\t\t\tMobile mob = (Mobile)obj;\n\t\t\t\tif ( mob.Body.IsHuman )\n\t\t\t\t\tmob.PrivateOverheadMessage( MessageType.Regular, mob.SpeechHue, false, \"I'm not a duelist, and quite frankly, I resent the implication.\", from.NetState );\n\t\t\t\telse\n\t\t\t\t\tmob.PrivateOverheadMessage( MessageType.Regular, 0x3B2, true, \"It's probably better than you.\", from.NetState );\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tfrom.SendMessage( \"That's not a player.\" );\n\t\t\t}\n\t\t}\n\t\tprivate static void EventSink_Speech( SpeechEventArgs e )\n\t\t{\n\t\t\tif ( e.Handled )\n\t\t\t\treturn;\n\t\t\tPlayerMobile pm = e.Mobile as PlayerMobile;\n\t\t\tif ( pm == null )\n\t\t\t\treturn;\n\t\t\tif ( Insensitive.Contains( e.Speech, \"i wish to duel\" ) )\n\t\t\t{\n\t\t\t\tif ( !pm.CheckAlive() )\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t\telse if ( pm.Region.IsPartOf( typeof( Regions.Jail ) ) )\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t\telse if ( CheckCombat( pm ) )\n\t\t\t\t{\n\t\t\t\t\te.Mobile.SendMessage( 0x22, \"You have recently been in combat with another player and must wait before starting a duel.\" );\n\t\t\t\t}\n\t\t\t\telse if ( pm.DuelContext != null )\n\t\t\t\t{\n\t\t\t\t\tif ( pm.DuelContext.Initiator == pm )\n\t\t\t\t\t\te.Mobile.SendMessage( 0x22, \"You have already started a duel.\" );\n\t\t\t\t\telse\n\t\t\t\t\t\te.Mobile.SendMessage( 0x22, \"You have already been challenged in a duel.\" );\n\t\t\t\t}\n\t\t\t\telse if ( TournamentController.IsActive )\n\t\t\t\t{\n\t\t\t\t\te.Mobile.SendMessage( 0x22, \"You may not start a duel while a tournament is active.\" );\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tpm.SendGump( new DuelContextGump( pm, new DuelContext( pm, RulesetLayout.Root ) ) );\n\t\t\t\t\te.Handled = true;\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if ( Insensitive.Equals( e.Speech, \"change arena preferences\" ) )\n\t\t\t{\n\t\t\t\tif ( !pm.CheckAlive() )\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tPreferences prefs = Preferences.Instance;\n\t\t\t\t\tif ( prefs != null )\n\t\t\t\t\t{\n\t\t\t\t\t\te.Mobile.CloseGump( typeof( PreferencesGump ) );\n\t\t\t\t\t\te.Mobile.SendGump( new PreferencesGump( e.Mobile, prefs ) );\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if ( Insensitive.Equals( e.Speech, \"showladder\" ) )\n\t\t\t{\n\t\t\t\te.Blocked=true;\n\t\t\t\tif ( !pm.CheckAlive() )\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tLadder instance = Ladder.Instance;\n\t\t\t\t\tif ( instance == null )\n\t\t\t\t\t{\n\t\t\t\t\t\t//pm.SendMessage( \"Ladder not yet initialized.\" );\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\tLadderEntry entry = instance.Find( pm );\n\t\t\t\t\t\tif ( entry == null )\n\t\t\t\t\t\t\treturn; // sanity\n\t\t\t\t\t\tstring text = String.Format( \"{{0}} {{1}} ranked {0} at level {1}.\", LadderGump.Rank( entry.Index + 1 ), Ladder.GetLevel( entry.Experience ) );\n\t\t\t\t\t\tpm.LocalOverheadMessage( MessageType.Regular, pm.SpeechHue, true, String.Format( text, \"You\", \"are\" ) );\n\t\t\t\t\t\tpm.NonlocalOverheadMessage( MessageType.Regular, pm.SpeechHue, true, String.Format( text, pm.Name, \"is\" ) );\n\t\t\t\t\t\t//pm.PublicOverheadMessage( MessageType.Regular, pm.SpeechHue, true, String.Format( \"Level {0} with {1} win{2} and {3} loss{4}.\", Ladder.GetLevel( entry.Experience ), entry.Wins, entry.Wins==1?\"\":\"s\", entry.Losses, entry.Losses==1?\"\":\"es\" ) );\n\t\t\t\t\t\t//pm.PublicOverheadMessage( MessageType.Regular, pm.SpeechHue, true, String.Format( \"Level {0} with {1} win{2} and {3} loss{4}.\", Ladder.GetLevel( entry.Experience ), entry.Wins, entry.Wins==1?\"\":\"s\", entry.Losses, entry.Losses==1?\"\":\"es\" ) );\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if ( Insensitive.Equals( e.Speech, \"viewladder\" ) )\n\t\t\t{\n\t\t\t\te.Blocked=true;\n\t\t\t\tif ( !pm.CheckAlive() )\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tLadder instance = Ladder.Instance;\n\t\t\t\t\tif ( instance == null )\n\t\t\t\t\t{\n\t\t\t\t\t\t//pm.SendMessage( \"Ladder not yet initialized.\" );\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\tpm.SendMessage( \"Target a player to view their ranking and level.\" );\n\t\t\t\t\t\tpm.BeginTarget( 16, false, Targeting.TargetFlags.None, new TargetStateCallback( ViewLadder_OnTarget ), instance );\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if ( Insensitive.Contains( e.Speech, \"i yield\" ) )\n\t\t\t{\n\t\t\t\tif ( !pm.CheckAlive() )\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t\telse if ( pm.DuelContext == null )\n\t\t\t\t{\n\t\t\t\t}\n\t\t\t\telse if ( pm.DuelContext.Finished )\n\t\t\t\t{\n\t\t\t\t\te.Mobile.SendMessage( 0x22, \"The duel is already finished.\" );\n\t\t\t\t}\n\t\t\t\telse if ( !pm.DuelContext.Started )\n\t\t\t\t{\n\t\t\t\t\tDuelContext dc = pm.DuelContext;\n\t\t\t\t\tMobile init = dc.Initiator;\n\t\t\t\t\tif ( pm.DuelContext.StartedBeginCountdown )\n\t\t\t\t\t{\n\t\t\t\t\t\te.Mobile.SendMessage( 0x22, \"The duel has not yet started.\" );\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\tDuelPlayer pl = pm.DuelContext.Find( pm );\n\t\t\t\t\t\tif ( pl == null )\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\tParticipant p = pl.Participant;\n\t\t\t\t\t\tif ( !pm.DuelContext.ReadyWait ) // still setting stuff up\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tp.Broadcast( 0x22, null, \"{0} has yielded.\", \"You have yielded.\" );\n\t\t\t\t\t\t\tif ( init == pm )\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tdc.Unregister();\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\telse\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tp.Nullify( pl );\n\t\t\t\t\t\t\t\tpm.DuelPlayer=null;\n\t\t\t\t\t\t\t\tNetState ns = init.NetState;\n\t\t\t\t\t\t\t\tif ( ns != null )\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\tforeach ( Gump g in ns.Gumps )\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tif ( g is ParticipantGump )\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\tParticipantGump pg = (ParticipantGump)g;\n\t\t\t\t\t\t\t\t\t\t\tif ( pg.Participant == p )\n\t\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\tinit.SendGump( new ParticipantGump( init, dc, p ) );\n\t\t\t\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\telse if ( g is DuelContextGump )\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\tDuelContextGump dcg = (DuelContextGump)g;\n\t\t\t\t\t\t\t\t\t\t\tif ( dcg.Context == dc )\n\t\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\tinit.SendGump( new DuelContextGump( init, dc ) );\n\t\t\t\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse if ( !pm.DuelContext.StartedReadyCountdown ) // at ready stage\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tp.Broadcast( 0x22, null, \"{0} has yielded.\", \"You have yielded.\" );\n\t\t\t\t\t\t\tdc.m_Yielding=true;\n\t\t\t\t\t\t\tdc.RejectReady( pm, null );\n\t\t\t\t\t\t\tdc.m_Yielding=false;\n\t\t\t\t\t\t\tif ( init == pm )\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tdc.Unregister();\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\telse if ( dc.m_Registered )\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tp.Nullify( pl );\n\t\t\t\t\t\t\t\tpm.DuelPlayer=null;\n\t\t\t\t\t\t\t\tNetState ns = init.NetState;\n\t\t\t\t\t\t\t\tif ( ns != null )\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\tbool send=true;\n\t\t\t\t\t\t\t\t\tforeach ( Gump g in ns.Gumps )\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tif ( g is ParticipantGump )\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\tParticipantGump pg = (ParticipantGump)g;\n\t\t\t\t\t\t\t\t\t\t\tif ( pg.Participant == p )\n\t\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\tinit.SendGump( new ParticipantGump( init, dc, p ) );\n\t\t\t\t\t\t\t\t\t\t\t\tsend=false;\n\t\t\t\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\telse if ( g is DuelContextGump )\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\tDuelContextGump dcg = (DuelContextGump)g;\n\t\t\t\t\t\t\t\t\t\t\tif ( dcg.Context == dc )\n\t\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\tinit.SendGump( new DuelContextGump( init, dc ) );\n\t\t\t\t\t\t\t\t\t\t\t\tsend=false;\n\t\t\t\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\tif ( send )\n\t\t\t\t\t\t\t\t\t\tinit.SendGump( new DuelContextGump( init, dc ) );\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tif ( pm.DuelContext.m_Countdown != null )\n\t\t\t\t\t\t\t\tpm.DuelContext.m_Countdown.Stop();\n\t\t\t\t\t\t\tpm.DuelContext.m_Countdown= null;\n\t\t\t\t\t\t\tpm.DuelContext.m_StartedReadyCountdown=false;\n\t\t\t\t\t\t\tp.Broadcast( 0x22, null, \"{0} has yielded.\", \"You have yielded.\" );\n\t\t\t\t\t\t\tdc.m_Yielding=true;\n\t\t\t\t\t\t\tdc.RejectReady( pm, null );\n\t\t\t\t\t\t\tdc.m_Yielding=false;\n\t\t\t\t\t\t\tif ( init == pm )\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tdc.Unregister();\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\telse if ( dc.m_Registered )\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tp.Nullify( pl );\n\t\t\t\t\t\t\t\tpm.DuelPlayer=null;\n\t\t\t\t\t\t\t\tNetState ns = init.NetState;\n\t\t\t\t\t\t\t\tif ( ns != null )\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\tbool send=true;\n\t\t\t\t\t\t\t\t\tforeach ( Gump g in ns.Gumps )\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tif ( g is ParticipantGump )\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\tParticipantGump pg = (ParticipantGump)g;\n\t\t\t\t\t\t\t\t\t\t\tif ( pg.Participant == p )\n\t\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\tinit.SendGump( new ParticipantGump( init, dc, p ) );\n\t\t\t\t\t\t\t\t\t\t\t\tsend=false;\n\t\t\t\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\telse if ( g is DuelContextGump )\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\tDuelContextGump dcg = (DuelContextGump)g;\n\t\t\t\t\t\t\t\t\t\t\tif ( dcg.Context == dc )\n\t\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\tinit.SendGump( new DuelContextGump( init, dc ) );\n\t\t\t\t\t\t\t\t\t\t\t\tsend=false;\n\t\t\t\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\tif ( send )\n\t\t\t\t\t\t\t\t\t\tinit.SendGump( new DuelContextGump( init, dc ) );\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tDuelPlayer pl = pm.DuelContext.Find( pm );\n\t\t\t\t\tif ( pl != null )\n\t\t\t\t\t{\n\t\t\t\t\t\tif ( pm.DuelContext.IsOneVsOne )\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\te.Mobile.SendMessage( 0x22, \"You may not yield a 1 on 1 match.\" );\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse if ( pl.Eliminated )\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\te.Mobile.SendMessage( 0x22, \"You have already been eliminated.\" );\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tpm.LocalOverheadMessage( MessageType.Regular, 0x22, false, \"You have yielded.\" );\n\t\t\t\t\t\t\tpm.NonlocalOverheadMessage( MessageType.Regular, 0x22, false, String.Format( \"{0} has yielded.\", pm.Name ) );\n\t\t\t\t\t\t\tpm.DuelContext.m_Yielding=true;\n\t\t\t\t\t\t\tpm.Kill();\n\t\t\t\t\t\t\tpm.DuelContext.m_Yielding=false;\n\t\t\t\t\t\t\tif ( pm.Alive ) // invul, ...\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tpl.Eliminated = true;\n\t\t\t\t\t\t\t\tpm.DuelContext.RemoveAggressions( pm );\n\t\t\t\t\t\t\t\tpm.DuelContext.SendOutside( pm );\n\t\t\t\t\t\t\t\tpm.DuelContext.Refresh( pm, null );\n\t\t\t\t\t\t\t\tDebuff( pm );\n\t\t\t\t\t\t\t\tCancelSpell( pm );\n\t\t\t\t\t\t\t\tpm.Frozen = false;\n\t\t\t\t\t\t\t\tParticipant winner = pm.DuelContext.CheckCompletion();\n\t\t\t\t\t\t\t\tif ( winner != null )\n\t\t\t\t\t\t\t\t\tpm.DuelContext.Finish( winner );\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\te.Mobile.SendMessage( 0x22, \"BUG: Unable to find duel context.\" );\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tpublic DuelContext( Mobile initiator, RulesetLayout layout ) : this( initiator, layout, true )\n\t\t{\n\t\t}\n\t\tpublic DuelContext( Mobile initiator, RulesetLayout layout, bool addNew )\n\t\t{\n\t\t\tm_Initiator = initiator;\n\t\t\tm_Participants = new ArrayList();\n\t\t\tm_Ruleset = new Ruleset( layout );\n\t\t\tm_Ruleset.ApplyDefault( layout.Defaults[0] );\n\t\t\tif ( addNew )\n\t\t\t{\n\t\t\t\tm_Participants.Add( new Participant( this, 1 ) );\n\t\t\t\tm_Participants.Add( new Participant( this, 1 ) );\n\t\t\t\t((Participant)m_Participants[0]).Add( initiator );\n\t\t\t}\n\t\t}\n\t\tpublic void CloseAllGumps()\n\t\t{\n\t\t\tType[] types = new Type[]{ typeof( DuelContextGump ), typeof( ParticipantGump ), typeof( RulesetGump ) };\n\t\t\tint[] defs = new int[]{ -1, -1, -1 };\n\t\t\tfor ( int i = 0; i < m_Participants.Count; ++i )\n\t\t\t{\n", "outputs": ["\t\t\t\tParticipant p = (Participant)m_Participants[i];"], "input_length": 7536, "output_length": 11, "length": 7547, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "e21dd1f012046b274d5832035c6fb7068e1a006078f8d8a0eca57a16da5a4798"}
{"input": "", "context": "from django import forms\nfrom django.forms import ValidationError\nfrom django.contrib.auth.models import Group\nfrom common.forms import ModelFormWithHelper\nfrom common.helpers import SubmitCancelFormHelper\nfrom community.constants import COMMUNITY_ADMIN, COMMUNITY_PRESENCE_CHOICES\nfrom community.models import Community, CommunityPage, RequestCommunity\nfrom community.utils import get_groups\nfrom users.models import SystersUser\nclass AddCommunityForm(ModelFormWithHelper):\n    \"\"\" Form to create a new Community by admin. \"\"\"\n    class Meta:\n        model = Community\n        fields = ('name', 'slug', 'order', 'location', 'email', 'mailing_list',\n                  'parent_community', 'website', 'facebook', 'googleplus',\n                  'twitter')\n        helper_class = SubmitCancelFormHelper\n        helper_cancel_href = \"{% url 'index' %}\"\n    def __init__(self, *args, **kwargs):\n        self.admin = kwargs.pop('admin')\n        super(AddCommunityForm, self).__init__(*args, **kwargs)\n    def save(self, commit=True):\n        \"\"\"Override save to add admin to the instance\"\"\"\n        instance = super(AddCommunityForm, self).save(commit=False)\n        instance.admin = self.admin\n        if commit:\n            instance.save()\n        return instance\nclass RequestCommunityForm(ModelFormWithHelper):\n    \"\"\"Form to request a new Community\"\"\"\n    def __init__(self, *args, **kwargs):\n        \"\"\"Makes some fields required and modifies a field to use widget\"\"\"\n        self.user = kwargs.pop('user')\n        super(RequestCommunityForm, self).__init__(*args, **kwargs)\n        self.fields['social_presence'] = forms.MultipleChoiceField(\n            choices=COMMUNITY_PRESENCE_CHOICES, label=\"Check off all \\\n            the social media accounts you can manage for your proposed community:\",\n            required=False, widget=forms.CheckboxSelectMultiple)\n        self.fields['email'].required = True\n        self.fields['demographic_target_count'].required = True\n        self.fields['purpose'].required = True\n        self.fields['content_developer'].required = True\n        self.fields['selection_criteria'].required = True\n        self.fields['is_real_time'].required = True\n    class Meta:\n        model = RequestCommunity\n        fields = ('is_member', 'email_id', 'email', 'name', 'slug', 'order', 'location',\n                  'type_community', 'other_community_type', 'parent_community',\n                  'community_channel', 'mailing_list', 'website', 'facebook',\n                  'googleplus', 'twitter', 'social_presence', 'other_account',\n                  'demographic_target_count',\n                  'purpose', 'is_avail_volunteer', 'count_avail_volunteer', 'content_developer',\n                  'selection_criteria', 'is_real_time')\n        helper_class = SubmitCancelFormHelper\n        helper_cancel_href = \"{% url 'index' %}\"\n    def clean_social_presence(self):\n        \"\"\"Converts the checkbox input into char to save it to the instance's field.\"\"\"\n        social_presence = ', '.join(\n            map(str, self.cleaned_data['social_presence']))\n        return social_presence\n    def save(self, commit=True):\n        \"\"\"Override save to add user to the instance\"\"\"\n        instance = super(RequestCommunityForm, self).save(commit=False)\n        instance.user = SystersUser.objects.get(user=self.user)\n        if commit:\n            instance.save()\n        return instance\nclass EditCommunityRequestForm(ModelFormWithHelper):\n    \"\"\"Form to edit a community request\"\"\"\n    def __init__(self, *args, **kwargs):\n        \"\"\"Makes some fields required and modifies a field to use widget\"\"\"\n        super(EditCommunityRequestForm, self).__init__(*args, **kwargs)\n        self.fields['social_presence'] = forms.MultipleChoiceField(\n            choices=COMMUNITY_PRESENCE_CHOICES, label=\"Check off all \\\n            the social media accounts you can manage for your proposed community:\",\n            required=False, widget=forms.CheckboxSelectMultiple)\n        self.fields['email'].required = True\n        self.fields['demographic_target_count'].required = True\n        self.fields['purpose'].required = True\n        self.fields['content_developer'].required = True\n        self.fields['selection_criteria'].required = True\n        self.fields['is_real_time'].required = True\n    class Meta:\n        model = RequestCommunity\n        fields = ('is_member', 'email_id', 'email', 'name', 'slug', 'order', 'location',\n                  'type_community', 'other_community_type', 'parent_community',\n                  'community_channel', 'mailing_list', 'website', 'facebook',\n                  'googleplus', 'twitter', 'social_presence', 'other_account',\n                  'demographic_target_count',\n                  'purpose', 'is_avail_volunteer', 'count_avail_volunteer', 'content_developer',\n                  'selection_criteria', 'is_real_time')\n        widgets = {'social_presence': forms.CheckboxSelectMultiple}\n        helper_class = SubmitCancelFormHelper\n        helper_cancel_href = \"{% url 'view_community_request' community_request.slug %}\"\n    def clean_social_presence(self):\n        \"\"\"Converts the checkbox input into char to save it to the instance's field.\"\"\"\n        social_presence = ', '.join(\n            map(str, self.cleaned_data['social_presence']))\n        return social_presence\n    def clean_slug(self):\n        \"\"\"Checks if the slug exists in the Community objects' slug\"\"\"\n        slug = self.cleaned_data['slug']\n        slug_community_values = Community.objects.all().values_list('order', flat=True)\n        if slug in slug_community_values:\n            msg = \"Slug by this value already exists. Please choose a different slug\\\n                   other than {0}!\"\n            string_slug_values = ', '.join(map(str, slug_community_values))\n            raise ValidationError(msg.format(string_slug_values))\n        else:\n            return slug\n    def clean_order(self):\n        \"\"\"Checks if the order exists in the Community objects' order\"\"\"\n        order = self.cleaned_data['order']\n        order_community_values = list(\n            Community.objects.all().values_list('order', flat=True))\n        order_community_values.sort()\n        if order is None:\n            raise ValidationError(\"Order must not be None.\")\n        elif order in order_community_values:\n            msg = \"Choose order value other than {0}\"\n            string_order_values = ', '.join(map(str, order_community_values))\n            raise ValidationError(msg.format(string_order_values))\n        else:\n            return order\nclass EditCommunityForm(ModelFormWithHelper):\n    \"\"\"Form to edit Community profile\"\"\"\n    class Meta:\n        model = Community\n        fields = ('name', 'slug', 'order', 'location', 'email', 'mailing_list',\n                  'parent_community', 'website', 'facebook', 'googleplus',\n                  'twitter')\n        helper_class = SubmitCancelFormHelper\n        helper_cancel_href = \"{% url 'view_community_profile' \" \\\n                             \"community.slug %}\"\nclass AddCommunityPageForm(ModelFormWithHelper):\n    \"\"\"Form to create new CommunityPage. The author and the community of the\n    page are expected to be provided when initializing the form:\n    * author - currently logged in user, aka the author of the page\n    * community - to which Community the CommunityPage belongs\n    \"\"\"\n    class Meta:\n        model = CommunityPage\n        fields = ('title', 'slug', 'order', 'content')\n        helper_class = SubmitCancelFormHelper\n        helper_cancel_href = \"{% url 'view_community_landing' \" \\\n                             \"community.slug %}\"\n    def __init__(self, *args, **kwargs):\n        self.author = kwargs.pop('author')\n        self.community = kwargs.pop('community')\n        super(AddCommunityPageForm, self).__init__(*args, **kwargs)\n    def save(self, commit=True):\n        \"\"\"Override save to add author and community to the instance\"\"\"\n        instance = super(AddCommunityPageForm, self).save(commit=False)\n        instance.author = SystersUser.objects.get(user=self.author)\n        instance.community = self.community\n        if commit:\n            instance.save()\n        return instance\nclass EditCommunityPageForm(ModelFormWithHelper):\n    \"\"\"Form to edit a CommunityPage.\"\"\"\n    class Meta:\n        model = CommunityPage\n        fields = ('slug', 'title', 'order', 'content')\n        helper_class = SubmitCancelFormHelper\n        helper_cancel_href = \"{% url 'view_community_page' community.slug \" \\\n                             \"object.slug %}\"\nclass PermissionGroupsForm(forms.Form):\n    \"\"\"Form to manage (select/deselect) user permission groups\"\"\"\n    def __init__(self, *args, **kwargs):\n        self.user = kwargs.pop('user')\n        community = kwargs.pop('community')\n        super(PermissionGroupsForm, self).__init__(*args, **kwargs)\n        # get all community groups and remove community admin group\n        # from the list of choices\n        self.groups = list(get_groups(community.name))\n        admin_group = Group.objects.get(\n            name=COMMUNITY_ADMIN.format(community.name))\n        self.groups.remove(admin_group)\n        choices = [(group.pk, group.name) for group in self.groups]\n        self.fields['groups'] = forms. \\\n            MultipleChoiceField(choices=choices, label=\"\", required=False,\n                                widget=forms.CheckboxSelectMultiple)\n", "outputs": ["        self.member_groups = self.user.get_member_groups(self.groups)"], "input_length": 1504, "output_length": 6, "length": 1510, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "efd0ed9e37546e1aafa3bec5e0a256ac648b8a6feeea0e1d11e9bd843e53042f"}
{"input": "", "context": "#!/usr/bin/env python\n\"\"\"Time-variable calibration for ATCA\nUsage:\n  timevariation_cal.py <dataset> [--calibrator=<cal>] [--segment=<min>] [--slop=<min>]\n-h --help             show this\n-c --calibrator CAL   the name of the calibrator [default: 1934-638]\n-s --segment LEN      the length of each calibration segment, in minutes [default: 2]\n-S --slop SLOP        a tolerance on the segment length, if it makes sense to extend it, in minutes [default: 1]\n\"\"\"\nfrom docopt import docopt\nfrom mirpy import miriad\nimport ephem\nfrom datetime import date, datetime, timedelta\nimport fnmatch\nimport os\nimport shutil\nimport numpy as np\nimport sys\nimport json\nimport math\nimport re\n# A routine to turn a Miriad type time string into a ephem Date.\ndef mirtime_to_date(mt):\n    year = 2000 + int(mt[0:2])\n    monthShort = mt[2:5]\n    date = int(mt[5:7])\n    hour = int(mt[8:10])\n    minute = int(mt[11:13])\n    second = int(round(float(mt[14:18])))\n    monthDict = { 'JAN': 1, 'FEB': 2, 'MAR': 3, 'APR': 4, 'MAY': 5, 'JUN': 6,\n                  'JUL': 7, 'AUG': 8, 'SEP': 9, 'OCT': 10, 'NOV': 11, 'DEC': 12 }\n    dateString = \"%4d/%02d/%02d %02d:%02d:%02d\" % (year, monthDict[monthShort], date,\n                                                   hour, minute, second)\n    return ephem.Date(dateString)\ndef datetime_to_mirtime(dt):\n    # Output a Miriad formatted date.\n    rs = dt.strftime(\"%y%b%d:%H:%M:%S\").lower()\n    return rs\n# Use a uvlist log to get the cycle time.\ndef filter_uvlist_variables(logfile_name):\n    # We send back a dictionary.\n    rd = { 'cycle_time': -1. }\n    with open(logfile_name, \"r\") as fp:\n        loglines = fp.readlines()\n    for i in xrange(0, len(loglines)):\n        index_elements = loglines[i].split()\n        if ((len(index_elements) > 2) and\n            (index_elements[0] == \"inttime\") and (index_elements[1] == \":\")):\n            rd['cycle_time'] = float(index_elements[2])\n    return rd\ndef filter_uvlist_antennas(output):\n    # We send back a dictionary.\n    rd = { 'telescope': \"\", 'latitude': \"\", 'longitude': \"\", 'antennas': [] }\n    outlines = output.split('\\n')\n    coords = 0\n    for i in xrange(0, len(outlines)):\n        index_elements = outlines[i].split()\n        if (len(index_elements) > 0):\n            if (index_elements[0] == \"Telescope:\"):\n                rd['telescope'] = index_elements[1]\n            elif (index_elements[0] == \"Latitude:\"):\n                rd['latitude'] = index_elements[1]\n            elif (index_elements[0] == \"Longitude:\"):\n                rd['longitude'] = index_elements[1]\n            elif ((len(index_elements) == 3) and (index_elements[1] == \"----------\")):\n                coords = 1\n            elif (coords == 1):\n                ant = { 'number': int(index_elements[0]),\n                        'coord_x': float(index_elements[1]),\n                        'coord_y': float(index_elements[2]),\n                        'coord_z': float(index_elements[3]) }\n                rd['antennas'].append(ant)\n    return rd\n# Use uvindex to work out the necessary parameters of this dataset.\ndef filter_uvindex(output):\n    # We send back a dictionary.\n    rd = { 'index': { 'time': [], 'source': [], 'calcode': [], 'antennas': [],\n                      'spectral_channels': [], 'wideband_channels': [], 'freq_config': [],\n                      'record_number': [] },\n           'total_time': 0,\n           'freq_configs': [], 'polarisations': [], 'sources': [] }\n    outlines = output.split('\\n')\n    section = 0\n    freqconfig_n = 0\n    freqconfig_found = 0\n    fc = None\n    sourcearea = 0\n    for i in xrange(0, len(outlines)):\n        index_elements = outlines[i].split()\n        if ((section == 0) and (len(outlines[i]) >= 74)):\n            indexTime = mirtime_to_date(outlines[i][0:18])\n            if ((index_elements[1] != \"Total\") and (index_elements[2] != \"number\")):\n                # This is a regular line.\n                offset = 0\n                rd['index']['time'].append(indexTime)\n                rd['index']['source'].append(index_elements[1])\n                # Check if we have a calibrator code.\n                calcode = outlines[i][36:37]\n                if (calcode == \" \"):\n                    # No calibrator code.\n                    offset = 1\n                rd['index']['calcode'].append(calcode)\n                rd['index']['antennas'].append(int(index_elements[3 - offset]))\n                rd['index']['spectral_channels'].append(int(index_elements[4 - offset]))\n                rd['index']['wideband_channels'].append(int(index_elements[5 - offset]))\n                rd['index']['freq_config'].append(int(index_elements[6 - offset]))\n                rd['index']['record_number'].append(int(index_elements[7 - offset]))\n            else:\n                # We've moved to the next section\n                section = 1\n        elif ((section == 1) and (len(index_elements) > 0) and (index_elements[0] == \"Total\") and\n              (index_elements[1] == \"observing\")):\n            # We've found the total amount of observing time.\n            rd['total_time'] = float(index_elements[4])\n            section = 2\n        elif (section == 2):\n            if ((len(index_elements) > 0) and (index_elements[0] == \"Frequency\")\n                and (index_elements[1] == \"Configuration\")):\n                freqconfig_n = int(index_elements[2])\n                freqconfig_found = 1\n                if (fc is not None):\n                    rd['freq_configs'].append(fc)\n                fc = { 'number': freqconfig_n, 'nchannels': [],\n                       'frequency1': [], 'frequency_increment': [],\n                       'rest_frequency': [], 'ifchain': [] }\n            elif (freqconfig_found == 1):\n                freqconfig_found = 2\n            elif (freqconfig_found == 2):\n                if (outlines[i] == \"\"):\n                    freqconfig_found = 0\n                else:\n                    # This is the actual line.\n                    fc['nchannels'].append(int(index_elements[0]))\n                    fc['frequency1'].append(float(index_elements[1]))\n                    fc['frequency_increment'].append(float(index_elements[2]))\n                    fc['rest_frequency'].append(float(index_elements[3]))\n                    fc['ifchain'].append(int(index_elements[5]))\n            elif (outlines[i] == \"------------------------------------------------\"):\n                if (fc is not None):\n                    rd['freq_configs'].append(fc)\n                section = 3\n        elif (section == 3):\n            if ((len(index_elements) > 0) and (index_elements[0] == \"There\") and\n                (index_elements[3] == \"records\") and (index_elements[5] == \"polarization\")):\n                rd['polarisations'].append(index_elements[6])\n            elif (outlines[i] == \"------------------------------------------------\"):\n                section = 4\n        elif (section == 4):\n            if ((len(index_elements) > 0) and (index_elements[0] == \"Source\")):\n                sourcearea = 1\n            elif ((len(index_elements) > 2) and (sourcearea == 1)):\n                src = { 'name': index_elements[0], 'calcode': index_elements[1],\n                        'right_ascension': index_elements[2], 'declination': index_elements[3],\n                        'dra': index_elements[4], 'ddec': index_elements[5] }\n                rd['sources'].append(src)\n    # Convert things into numpy arrays for easy where-ing later.\n    rd['index']['time'] = np.array(rd['index']['time'])\n    rd['index']['source'] = np.array(rd['index']['source'])\n    rd['index']['calcode'] = np.array(rd['index']['calcode'])\n    rd['index']['antennas'] = np.array(rd['index']['antennas'])\n    rd['index']['spectral_channels'] = np.array(rd['index']['spectral_channels'])\n    rd['index']['wideband_channels'] = np.array(rd['index']['wideband_channels'])\n    rd['index']['freq_config'] = np.array(rd['index']['freq_config'])\n    rd['index']['record_number'] = np.array(rd['index']['record_number'])\n    \n    return rd\ndef split_into_segments(idx):\n    # We go through a uvindex dictionary and return segments.\n    # Each segment is a single source, at a single frequency,\n    # with a start and end time.\n    segs = []\n    oldsrc = \"\"\n    oldconfig = -1\n    sseg = None\n    for i in xrange(0, len(idx['index']['source'])):\n        if ((idx['index']['source'][i] != oldsrc) or\n            (idx['index']['freq_config'][i] != oldconfig)):\n            if ((oldsrc != \"\") and (oldconfig != -1)):\n                # Put the segment on the list.\n                segs.append(sseg)\n            oldsrc = idx['index']['source'][i]\n            oldconfig = idx['index']['freq_config'][i]\n            sseg = { 'source': idx['index']['source'][i],\n                     'freq_config': idx['index']['freq_config'][i],\n                     'start_time': ephem.Date(idx['index']['time'][i]),\n                     'end_time': ephem.Date(idx['index']['time'][i]) }\n        else:\n            sseg['end_time'] = ephem.Date(idx['index']['time'][i])\n    # Have to push the last segment on.\n    segs.append(sseg)\n    return segs\ndef dataset_find(srcname, freq=None):\n    srcpat = \"%s.*\" % srcname\n    if (freq is not None):\n        srcpat = \"%s.%d\" % (srcname, freq)\n    matches = []\n    for root, dirnames, filenames in os.walk('.'):\n        for filename in fnmatch.filter(dirnames, srcpat):\n            # Check if this has data.\n            fname = os.path.join(root, filename)\n            cname = \"%s/visdata\" % fname\n            if ((os.path.isdir(fname)) and (os.path.isfile(cname))):\n                matches.append(fname)\n    return matches\ndef filter_uvplt(output):\n    outlines = output.split('\\n')\n    rd = { 'nvisibilities': 0 }\n    for i in xrange(0, len(outlines)):\n        index_elements = outlines[i].split()\n        if (len(index_elements) < 3):\n            continue\n        if ((index_elements[0] == \"Read\") and\n            (index_elements[2] == \"visibilities\")):\n            rd['nvisibilities'] = int(index_elements[1])\n    return rd\ndef filter_closure(output):\n    outlines = output.split('\\n')\n    rd = { 'theoretical_rms': 0, 'measured_rms': 0 }\n    for i in xrange(0, len(outlines)):\n        index_elements = outlines[i].split()\n        if (len(index_elements) < 1):\n            continue\n        if (index_elements[0] == \"Actual\"):\n            rd['measured_rms'] = float(index_elements[-1])\n        elif (index_elements[0] == \"Theoretical\"):\n            rd['theoretical_rms'] = float(index_elements[-1])\n    return rd\ndef filter_uvfstats(output):\n    outlines = output.split('\\n')\n    rd = { 'flagged_fraction': 0 }\n    strt = 0\n    nchans = 0\n    nflagged = 0\n    for i in xrange(0, len(outlines)):\n        index_elements = outlines[i].split()\n        if (len(index_elements) < 1):\n            continue\n        if (strt == 1):\n            nchans = nchans + 1\n            if (index_elements[1] < 15):\n                nflagged = nflagged + 1\n        else:\n            if (index_elements[0] == \"-------\"):\n                strt = 1\n    rd['flagged_fraction'] = \"%.2f\" % (nflagged / nchans)\n    return rd\ndef calibrate(srcname, calname, fconfig, stime, etime):\n    smtime = datetime_to_mirtime(stime)\n    emtime = datetime_to_mirtime(etime)\n    selstring = \"time(%s,%s)\" % (smtime, emtime)\n    print \"  calibrating source %s with selection %s\" % (srcname, selstring)\n    # Find all the relevant datasets.\n    dsets = dataset_find(srcname)\n    \n    cfreqs = []\n    rv = { 'code': 0, 'frequencies': [] }\n    for i in xrange(0, len(dsets)):\n        fname = dsets[i]\n        # Check if this is one of the frequencies in this configuration.\n        setf = int(fname.split(\".\")[-1])\n        for j in xrange(0, len(fconfig['nchannels'])):\n            c = (fconfig['frequency1'][j] + (fconfig['nchannels'][j] - 1) *\n                 fconfig['frequency_increment'][j] / 2.) * 1000.\n            fdiff = abs(c - setf)\n            if (fdiff <= abs(fconfig['frequency_increment'][j] * 1000.)):\n                cfreqs.append([ setf, j, fname ])\n                rv['frequencies'].append(setf)\n    # Calibrate per frequency.\n    for i in xrange(0, len(cfreqs)):\n        dset = cfreqs[i][2]\n        csets = dataset_find(calname, cfreqs[i][0])\n        cset = csets[0]\n        # Check that we actually have data in this time range.\n        miriad.set_filter('uvplt', filter_uvplt)\n        \n        uvout = miriad.uvplt(vis=dset, axis=\"time,amp\", device=\"/null\",\n                             options=\"nopol,nocal,nopass\", stokes=\"xx,yy\",\n                             select=selstring)\n        if (uvout['nvisibilities'] > 0):\n            # Do the calibration.\n            print \"  calibrating frequency %d MHz\" % cfreqs[i][0]\n            miriad.gpcopy(vis=cset, out=dset)\n            miriad.gpcal(vis=dset, interval=\"0.1\", options=\"xyvary,nopol,qusolve\",\n                         nfbin=\"2\", refant=\"3\", select=selstring)\n            miriad.gpboot(vis=dset, cal=cset, select=selstring)\n            rv['code'] = 1\n        else:\n            print \"  Unable to find any data for this time range!\" % selstring\n            rv['code'] = 0\n    return rv\ndef measure_closure_phase(srcname, freq, stime, etime):\n    print \"    closure phase %.1f MHz\" % freq\n    closurelog = \"closure_log.txt\"\n    selstring = \"time(%s,%s)\" % (datetime_to_mirtime(stime),\n                                 datetime_to_mirtime(etime))\n    if (os.path.isfile(closurelog)):\n        os.remove(closurelog)\n    # Find the data set.\n    dsets = dataset_find(srcname, freq)\n    miriad.set_filter('closure', filter_closure)\n    cout = miriad.closure(vis=dsets[0], stokes=\"i\", device=\"/null\",\n                          options=\"log\", select=selstring)\n    rv = { 'closure_phase': { 'theoretical_rms': cout['theoretical_rms'],\n                              'measured_rms': cout['measured_rms'],\n                              'average_value': -999 } }\n    if (os.path.isfile(closurelog)):\n        with open(closurelog, \"r\") as fp:\n            loglines = fp.readlines()\n        pvals = []\n        for i in xrange(0, len(loglines)):\n            lels = loglines[i].split()\n            if (len(lels) < 1):\n                continue\n            if (lels[0] == \"Antennas\"):\n                continue\n            pvals.append(float(lels[-1]))\n        rv['closure_phase']['average_value'] = np.average(pvals)\n    return rv\ndef measure_flagging_statistic(srcname, freq, stime, etime):\n    print \"    flagging %.1f MHz\" % freq\n    miriad.set_filter('uvfstats', filter_uvfstats)\n    selstring = \"time(%s,%s)\" % (datetime_to_mirtime(stime),\n                                 datetime_to_mirtime(etime))\n    # Find the data set.\n    dsets = dataset_find(srcname, freq)\n    uo = miriad.uvfstats(vis=dsets[0], mode=\"channel\",\n                         options=\"absolute,unflagged\",\n                         select=selstring)\n    return uo['flagged_fraction']\ndef calculate_hourangle(obs, obstime, src):\n    obs.date = obstime\n    src.compute(obs)\n    lst = obs.sidereal_time() * 180. / (15. * math.pi)\n    ra = src.ra * 180. / (15. * math.pi)\n    ha = lst - ra\n    if (ha < -12):\n        ha = ha + 24\n    elif (ha > 12):\n        ha = ha - 24\n    return ha\ndef findWholeWord(w):\n    return re.compile(r'\\b({0})\\b'.format(w), flags=re.IGNORECASE).search\ndef determine_array(srcname, freq):\n    print \"    determining array\"\n    dsets = dataset_find(srcname, freq)\n    # The strings for the station configurations.\n    configs = {\n        '6A': \"W4   W45  W102 W173 W195 W392\",\n        '6B': \"W2   W64  W147 W182 W196 W392\",\n        '6C': \"W0   W10  W113 W140 W182 W392\",\n        '6D': \"W8   W32  W84  W168 W173 W392\",\n        '1.5A': \"W100 W110 W147 W168 W196 W392\",\n        '1.5B': \"W111 W113 W163 W182 W195 W392\",\n        '1.5C': \"W98  W128 W173 W190 W195 W392\",\n        '1.5D': \"W102 W109 W140 W182 W196 W392\",\n        '750A': \"W147 W163 W172 W190 W195 W392\",\n        '750B': \"W98  W109 W113 W140 W148 W392\",\n        '750C': \"W64  W84  W100 W110 W113 W392\",\n        '750D': \"W100 W102 W128 W140 W147 W392\",\n        'EW367': \"W104 W110 W113 W124 W128 W392\",\n        'EW352': \"W102 W104 W109 W112 W125 W392\",\n        'H214': \"W98  W104 W113 N5   N14  W392\",\n        'H168': \"W100 W104 W111 N7   N11  W392\",\n        'H75': \"W104 W106 W109 N2   N5   W392\",\n        'EW214': \"W98  W102 W104 W109 W112 W392\",\n        'NS214': \"W106 N2   N7   N11  N14  W392\",\n        '122C': \"W98  W100 W102 W104 W106 W392\",\n        '375': \"W2   W10  W14  W16  W32  W392\",\n        '210': \"W98  W100 W102 W109 W112 W392\",\n        '122B': \"W8   W10  W12  W14  W16  W392\",\n        '122A': \"W0   W2   W4   W6   W8   W392\"\n    }\n    # Get the antenna positions.\n    miriad.set_filter('uvlist', filter_uvlist_antennas)\n    antlist = miriad.uvlist(vis=dsets[0], options=\"full,array\")\n    antpos = antlist['antennas']\n    # Adjust to make CA06 the reference.\n    for i in xrange(0, 6):\n        antpos[i]['coord_x'] = -1. * (antpos[i]['coord_x'] - antpos[5]['coord_x'])\n        antpos[i]['coord_y'] = -1. * (antpos[i]['coord_y'] - antpos[5]['coord_y'])\n        antpos[i]['coord_z'] = -1. * (antpos[i]['coord_z'] - antpos[5]['coord_z'])\n    station_interval = 15.3\n    array_stations = []\n    for i in xrange(0, 6):\n        ew_offset = math.floor((antpos[i]['coord_y'] / station_interval) + 0.5) + 392\n        ns_offset = math.floor((antpos[i]['coord_x'] / station_interval) + 0.5) + 0\n        if (ns_offset == 0):\n            array_stations.append(\"W%d\" % ew_offset)\n        else:\n            array_stations.append(\"N%d\" % ns_offset)\n    # Find the best match.\n    max_matches = 0\n    match_array = \"\"\n    for a in configs:\n        curr_match_count = 0\n        for i in xrange(0, len(array_stations)):\n            if (findWholeWord(array_stations[i])(configs[a]) is not None):\n                curr_match_count = curr_match_count + 1\n        if (curr_match_count > max_matches):\n            max_matches = curr_match_count\n            match_array = a\n    return match_array\ndef filter_uvfmeas(output):\n    outlines = output.split('\\n')\n    rv = { 'fitCoefficients': [], 'alphaCoefficients': [],\n           'alphaReference': { 'fluxDensity': 0, 'frequency': 0 },\n           'fitScatter': 0, 'mode': \"\", 'stokes': \"\"\n    }\n    for i in xrange(0, len(outlines)):\n        index_elements = outlines[i].split()\n        if (len(index_elements) < 1):\n            continue\n        #print \"UVFMEAS: %s\" % outlines[i]\n        if (index_elements[0] == \"Coeff:\"):\n            for j in xrange(1, len(index_elements)):\n                try:\n                    rv['fitCoefficients'].append(float(index_elements[j]))\n                except ValueError as e:\n                    rv['fitCoefficients'].append(index_elements[j])\n        elif (index_elements[0] == \"MFCAL\"):\n            comma_elements = outlines[i][11:].split(\",\")\n            if (comma_elements[0] != \"*******\"):\n                rv['alphaReference']['fluxDensity'] = float(comma_elements[0])\n            if (comma_elements[1] != \"*******\"):\n                rv['alphaReference']['frequency'] = float(comma_elements[1])\n        elif (index_elements[0] == \"Alpha:\"):\n            for j in xrange(1, len(index_elements)):\n                if (index_elements[j] != \"*******\"):\n                    rv['alphaCoefficients'].append(float(index_elements[j]))\n", "outputs": ["        elif (index_elements[0] == \"Scatter\"):"], "input_length": 4467, "output_length": 12, "length": 4479, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "a273d9ae653a0841fb5c9b24dfd8575f0c71ccf76c8c0ccbf5da306b0638b2d3"}
{"input": "", "context": "#!/usr/bin/env python\n# This Source Code Form is subject to the terms of the Mozilla Public\n# License, v. 2.0. If a copy of the MPL was not distributed with this\n# file, You can obtain one at http://mozilla.org/MPL/2.0/.\nimport argparse\nimport glob\nimport json\nfrom math import sqrt\nimport re\nimport sys\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as plticker\nimport numpy as np\nfrom scipy.stats import norm, t\nVC = 'startup > moz-app-visually-complete'\ndef add_application_to_results(results, app_result_set,\n                               app_pattern=None, test_pattern=None,\n                               first_repetition=None, last_repetition=None):\n    app_name = app_result_set['stats']['application'].strip()\n    if app_pattern and not re.search(app_pattern, app_name):\n        return\n    if not app_result_set.get('passes'):\n        return\n    app_results = results.get(app_name, {})\n    tests_added = 0\n    for test_result_set in app_result_set['passes']:\n        if add_test_to_results(app_results, test_result_set, test_pattern,\n                               first_repetition, last_repetition):\n            tests_added += 1\n    if tests_added > 0:\n        results[app_name] = app_results\ndef add_test_to_results(app_results, test_result_set,\n                        test_pattern=None,\n                        first_repetition=None, last_repetition=None):\n    test_name = test_result_set['title'].strip()\n    if test_pattern and not re.search(test_pattern, test_name):\n        return False\n    if not test_result_set.get('mozPerfDurations'):\n        return False\n    test_results = app_results.get(test_name, {'durations': []})\n    # TODO: use slices\n    durations_added = 0\n    for index, duration in enumerate(test_result_set['mozPerfDurations'],\n                                     start=1):\n        if first_repetition and index < first_repetition:\n            continue\n        if last_repetition and index > last_repetition:\n            break\n        test_results['durations'].append(duration)\n        durations_added += 1\n    if durations_added:\n        app_results[test_name] = test_results\n        return True\n    else:\n        return False\ndef add_result_set(result_set, results,\n                   app_pattern=None, test_pattern=None,\n                   first_repetition=None, last_repetition=None):\n    for app_result_set in result_set:\n        add_application_to_results(results, app_result_set,\n                                   app_pattern, test_pattern,\n                                   first_repetition, last_repetition)\ndef get_stats(values, intervals=True):\n    stats = {}\n    values_array = np.array(values, dtype=np.float64)\n    stats['min'] = np.asscalar(np.amin(values_array))\n    stats['max'] = np.asscalar(np.amax(values_array))\n    stats['mean'] = np.asscalar(np.mean(values_array))\n    stats['median'] = np.asscalar(np.median(values_array))\n    if values_array.size > 1:\n        stats['std_dev'] = np.asscalar(np.std(values_array, ddof=1))\n    else:\n        stats['std_dev'] = 0\n    if intervals:\n        stats['intervals'] = []\n        loc = stats['mean']\n        scale = stats['std_dev'] / sqrt(values_array.size)\n        for alpha in (.95, .99, .90, .85, .80, .50):\n            if values_array.size > 30:\n                interval = norm.interval(alpha, loc=loc, scale=scale)\n            else:\n                interval = t.interval(alpha, values_array.size - 1, loc, scale)\n            stats['intervals'].append(\n                {'confidence': alpha, 'interval': interval})\n    return stats\ndef add_stats_to_results(results):\n    for app in results:\n        for test in results[app]:\n            stats = get_stats(results[app][test]['durations'])\n            results[app][test]['stats'] = stats\ndef add_stats_to_pivot(pivot):\n    for app in pivot:\n        for test in pivot[app]:\n            for stat in pivot[app][test]:\n                stats = get_stats(pivot[app][test][stat]['values'],\n                                  intervals=True)\n                pivot[app][test][stat]['stats'] = stats\ndef add_stats_pivot_to_crunched_results(crunched_results):\n    # pivot -> app -> test -> stat[]\n    pivot = {}\n    for run_num, run_results in enumerate(crunched_results['runs']):\n        # print 'Run %d:' % (run_num)\n        for app in run_results:\n            if app not in pivot:\n                pivot[app] = {}\n            for test in run_results[app]:\n                if test not in pivot[app]:\n                    pivot[app][test] = {}\n                for stat in run_results[app][test]['stats']:\n                    if stat == 'intervals':\n                        continue\n                    if stat not in pivot[app][test]:\n                        pivot[app][test][stat] = {'values': []}\n                    pivot[app][test][stat]['values'].append(\n                        run_results[app][test]['stats'][stat])\n                    # print '  Added %s.%s.%s' % (app, test, stat)\n    add_stats_to_pivot(pivot)\n    crunched_results['pivot'] = pivot\ndef crunch_result_sets(result_sets, app_pattern=None, test_pattern=None,\n                       first_repetition=None, last_repetition=None):\n    crunched_results = {'args': {'app_pattern': app_pattern,\n                                 'test_pattern': test_pattern,\n                                 'first_repetition': first_repetition,\n                                 'last_repetition': last_repetition},\n                        'combined': {},\n                        'runs': []}\n    if app_pattern:\n        app_pattern = re.compile(app_pattern, re.IGNORECASE)\n    if test_pattern:\n        test_pattern = re.compile(test_pattern, re.IGNORECASE)\n    for result_set in result_sets:\n        results = {}\n        add_result_set(result_set, results, app_pattern, test_pattern,\n                       first_repetition, last_repetition)\n        add_stats_to_results(results)\n        crunched_results['runs'].append(results)\n        # TODO: make it so it aggregates the last call instead\n        add_result_set(result_set, crunched_results['combined'], app_pattern,\n                       test_pattern, first_repetition, last_repetition)\n    add_stats_to_results(crunched_results['combined'])\n    add_stats_pivot_to_crunched_results(crunched_results)\n    return crunched_results\ndef load_result_sets(filenames):\n    if isinstance(filenames, basestring):\n        filenames = glob.glob(filenames)\n    result_sets = []\n    for filename in filenames:\n        with open(filename) as f:\n            results = f.read()\n            try:\n                result_sets.append(json.loads(results))\n            except Exception as e:\n                sys.stderr.write('Discarding %s: %s\\n' % (filename, str(e)))\n    return result_sets\ndef load_and_crunch_result_sets(filenames, app_pattern=None, test_pattern=None,\n                                first_repetition=None, last_repetition=None):\n    rs = load_result_sets(filenames)\n    return crunch_result_sets(rs, app_pattern, test_pattern, first_repetition, last_repetition)\ndef plot_app_vc(cr, app, test=VC, stat='mean'):\n    loc = plticker.MultipleLocator(base=1.0)\n    fig, ax = plt.subplots()\n    ax.xaxis.set_major_locator(loc)\n    plt.xlabel('Runs')\n    plt.ylabel('Time in ms')\n    plt.title('%s, %s, individual %ss vs. %d-count 95%% CI' %\n              (app, test, stat, len(cr['combined'][app][VC]['durations'])))\n    csi_95 = cr['combined'][app][VC]['stats']['intervals'][0]['interval']\n    print csi_95\n", "outputs": ["    ymin = csi_95[0]"], "input_length": 1254, "output_length": 6, "length": 1260, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "a6b80b4d2489d94be0f62f89513ca0fdfceee1e3685b6c901a2a628f806ab2f9"}
{"input": "", "context": "/*\n * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n *\n * This code is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License version 2 only, as\n * published by the Free Software Foundation.  Oracle designates this\n * particular file as subject to the \"Classpath\" exception as provided\n * by Oracle in the LICENSE file that accompanied this code.\n *\n * This code is distributed in the hope that it will be useful, but WITHOUT\n * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n * version 2 for more details (a copy is included in the LICENSE file that\n * accompanied this code).\n *\n * You should have received a copy of the GNU General Public License version\n * 2 along with this work; if not, write to the Free Software Foundation,\n * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n *\n * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n * or visit www.oracle.com if you need additional information or have any\n * questions.\n */\n/*\n * This file is available under and governed by the GNU General Public\n * License version 2 only, as published by the Free Software Foundation.\n * However, the following notice accompanied the original version of this\n * file:\n *\n * ASM: a very small and fast Java bytecode manipulation framework\n * Copyright (c) 2000-2011 INRIA, France Telecom\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. Neither the name of the copyright holders nor the names of its\n *    contributors may be used to endorse or promote products derived from\n *    this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF\n * THE POSSIBILITY OF SUCH DAMAGE.\n */\npackage jdk.internal.org.objectweb.asm;\n/**\n * A label represents a position in the bytecode of a method. Labels are used\n * for jump, goto, and switch instructions, and for try catch blocks. A label\n * designates the <i>instruction</i> that is just after. Note however that\n * there can be other elements between a label and the instruction it\n * designates (such as other labels, stack map frames, line numbers, etc.).\n *\n * @author Eric Bruneton\n */\npublic class Label {\n    /**\n     * Indicates if this label is only used for debug attributes. Such a label\n     * is not the start of a basic block, the target of a jump instruction, or\n     * an exception handler. It can be safely ignored in control flow graph\n     * analysis algorithms (for optimization purposes).\n     */\n    static final int DEBUG = 1;\n    /**\n     * Indicates if the position of this label is known.\n     */\n    static final int RESOLVED = 2;\n    /**\n     * Indicates if this label has been updated, after instruction resizing.\n     */\n    static final int RESIZED = 4;\n    /**\n     * Indicates if this basic block has been pushed in the basic block stack.\n     * See {@link MethodWriter#visitMaxs visitMaxs}.\n     */\n    static final int PUSHED = 8;\n    /**\n     * Indicates if this label is the target of a jump instruction, or the start\n     * of an exception handler.\n     */\n    static final int TARGET = 16;\n    /**\n     * Indicates if a stack map frame must be stored for this label.\n     */\n    static final int STORE = 32;\n    /**\n     * Indicates if this label corresponds to a reachable basic block.\n     */\n    static final int REACHABLE = 64;\n    /**\n     * Indicates if this basic block ends with a JSR instruction.\n     */\n    static final int JSR = 128;\n    /**\n     * Indicates if this basic block ends with a RET instruction.\n     */\n    static final int RET = 256;\n    /**\n     * Indicates if this basic block is the start of a subroutine.\n     */\n    static final int SUBROUTINE = 512;\n    /**\n     * Indicates if this subroutine basic block has been visited by a\n     * visitSubroutine(null, ...) call.\n     */\n    static final int VISITED = 1024;\n    /**\n     * Indicates if this subroutine basic block has been visited by a\n     * visitSubroutine(!null, ...) call.\n     */\n    static final int VISITED2 = 2048;\n    /**\n     * Field used to associate user information to a label. Warning: this field\n     * is used by the ASM tree package. In order to use it with the ASM tree\n     * package you must override the {@link\n     * jdk.internal.org.objectweb.asm.tree.MethodNode#getLabelNode} method.\n     */\n    public Object info;\n    /**\n     * Flags that indicate the status of this label.\n     *\n     * @see #DEBUG\n     * @see #RESOLVED\n     * @see #RESIZED\n     * @see #PUSHED\n     * @see #TARGET\n     * @see #STORE\n     * @see #REACHABLE\n     * @see #JSR\n     * @see #RET\n     */\n    int status;\n    /**\n     * The line number corresponding to this label, if known.\n     */\n    int line;\n    /**\n     * The position of this label in the code, if known.\n     */\n    int position;\n    /**\n     * Number of forward references to this label, times two.\n     */\n    private int referenceCount;\n    /**\n     * Informations about forward references. Each forward reference is\n     * described by two consecutive integers in this array: the first one is the\n     * position of the first byte of the bytecode instruction that contains the\n     * forward reference, while the second is the position of the first byte of\n     * the forward reference itself. In fact the sign of the first integer\n     * indicates if this reference uses 2 or 4 bytes, and its absolute value\n     * gives the position of the bytecode instruction. This array is also used\n     * as a bitset to store the subroutines to which a basic block belongs. This\n     * information is needed in {@linked  MethodWriter#visitMaxs}, after all\n     * forward references have been resolved. Hence the same array can be used\n     * for both purposes without problems.\n     */\n    private int[] srcAndRefPositions;\n    // ------------------------------------------------------------------------\n    /*\n     * Fields for the control flow and data flow graph analysis algorithms (used\n     * to compute the maximum stack size or the stack map frames). A control\n     * flow graph contains one node per \"basic block\", and one edge per \"jump\"\n     * from one basic block to another. Each node (i.e., each basic block) is\n     * represented by the Label object that corresponds to the first instruction\n     * of this basic block. Each node also stores the list of its successors in\n     * the graph, as a linked list of Edge objects.\n     *\n     * The control flow analysis algorithms used to compute the maximum stack\n     * size or the stack map frames are similar and use two steps. The first\n     * step, during the visit of each instruction, builds information about the\n     * state of the local variables and the operand stack at the end of each\n     * basic block, called the \"output frame\", <i>relatively</i> to the frame\n     * state at the beginning of the basic block, which is called the \"input\n     * frame\", and which is <i>unknown</i> during this step. The second step,\n     * in {@link MethodWriter#visitMaxs}, is a fix point algorithm that\n     * computes information about the input frame of each basic block, from the\n     * input state of the first basic block (known from the method signature),\n     * and by the using the previously computed relative output frames.\n     *\n     * The algorithm used to compute the maximum stack size only computes the\n     * relative output and absolute input stack heights, while the algorithm\n     * used to compute stack map frames computes relative output frames and\n     * absolute input frames.\n     */\n    /**\n     * Start of the output stack relatively to the input stack. The exact\n     * semantics of this field depends on the algorithm that is used.\n     *\n     * When only the maximum stack size is computed, this field is the number of\n     * elements in the input stack.\n     *\n     * When the stack map frames are completely computed, this field is the\n     * offset of the first output stack element relatively to the top of the\n     * input stack. This offset is always negative or null. A null offset means\n     * that the output stack must be appended to the input stack. A -n offset\n     * means that the first n output stack elements must replace the top n input\n     * stack elements, and that the other elements must be appended to the input\n     * stack.\n     */\n    int inputStackTop;\n    /**\n     * Maximum height reached by the output stack, relatively to the top of the\n     * input stack. This maximum is always positive or null.\n     */\n    int outputStackMax;\n    /**\n     * Information about the input and output stack map frames of this basic\n     * block. This field is only used when {@link ClassWriter#COMPUTE_FRAMES}\n     * option is used.\n     */\n    Frame frame;\n    /**\n     * The successor of this label, in the order they are visited. This linked\n     * list does not include labels used for debug info only. If\n     * {@link ClassWriter#COMPUTE_FRAMES} option is used then, in addition, it\n     * does not contain successive labels that denote the same bytecode position\n     * (in this case only the first label appears in this list).\n     */\n    Label successor;\n    /**\n     * The successors of this node in the control flow graph. These successors\n     * are stored in a linked list of {@link Edge Edge} objects, linked to each\n     * other by their {@link Edge#next} field.\n     */\n    Edge successors;\n    /**\n     * The next basic block in the basic block stack. This stack is used in the\n     * main loop of the fix point algorithm used in the second step of the\n     * control flow analysis algorithms. It is also used in\n     * {@link #visitSubroutine} to avoid using a recursive method.\n     *\n     * @see MethodWriter#visitMaxs\n     */\n    Label next;\n    // ------------------------------------------------------------------------\n    // Constructor\n    // ------------------------------------------------------------------------\n    /**\n     * Constructs a new label.\n     */\n    public Label() {\n    }\n    // ------------------------------------------------------------------------\n    // Methods to compute offsets and to manage forward references\n    // ------------------------------------------------------------------------\n    /**\n     * Returns the offset corresponding to this label. This offset is computed\n     * from the start of the method's bytecode. <i>This method is intended for\n     * {@link Attribute} sub classes, and is normally not needed by class\n     * generators or adapters.</i>\n     *\n     * @return the offset corresponding to this label.\n     * @throws IllegalStateException if this label is not resolved yet.\n     */\n    public int getOffset() {\n        if ((status & RESOLVED) == 0) {\n            throw new IllegalStateException(\"Label offset position has not been resolved yet\");\n        }\n        return position;\n    }\n    /**\n     * Puts a reference to this label in the bytecode of a method. If the\n     * position of the label is known, the offset is computed and written\n     * directly. Otherwise, a null offset is written and a new forward reference\n     * is declared for this label.\n     *\n     * @param owner the code writer that calls this method.\n     * @param out the bytecode of the method.\n     * @param source the position of first byte of the bytecode instruction that\n     *        contains this label.\n     * @param wideOffset <tt>true</tt> if the reference must be stored in 4\n     *        bytes, or <tt>false</tt> if it must be stored with 2 bytes.\n     * @throws IllegalArgumentException if this label has not been created by\n     *         the given code writer.\n     */\n    void put(\n        final MethodWriter owner,\n        final ByteVector out,\n        final int source,\n        final boolean wideOffset)\n    {\n        if ((status & RESOLVED) == 0) {\n            if (wideOffset) {\n                addReference(-1 - source, out.length);\n                out.putInt(-1);\n            } else {\n                addReference(source, out.length);\n                out.putShort(-1);\n            }\n        } else {\n            if (wideOffset) {\n                out.putInt(position - source);\n            } else {\n                out.putShort(position - source);\n            }\n        }\n    }\n    /**\n     * Adds a forward reference to this label. This method must be called only\n     * for a true forward reference, i.e. only if this label is not resolved\n     * yet. For backward references, the offset of the reference can be, and\n     * must be, computed and stored directly.\n     *\n     * @param sourcePosition the position of the referencing instruction. This\n     *        position will be used to compute the offset of this forward\n     *        reference.\n     * @param referencePosition the position where the offset for this forward\n     *        reference must be stored.\n     */\n    private void addReference(\n        final int sourcePosition,\n        final int referencePosition)\n    {\n        if (srcAndRefPositions == null) {\n            srcAndRefPositions = new int[6];\n        }\n        if (referenceCount >= srcAndRefPositions.length) {\n            int[] a = new int[srcAndRefPositions.length + 6];\n            System.arraycopy(srcAndRefPositions,\n                    0,\n                    a,\n                    0,\n                    srcAndRefPositions.length);\n            srcAndRefPositions = a;\n        }\n        srcAndRefPositions[referenceCount++] = sourcePosition;\n        srcAndRefPositions[referenceCount++] = referencePosition;\n    }\n    /**\n     * Resolves all forward references to this label. This method must be called\n     * when this label is added to the bytecode of the method, i.e. when its\n     * position becomes known. This method fills in the blanks that where left\n     * in the bytecode by each forward reference previously added to this label.\n     *\n     * @param owner the code writer that calls this method.\n     * @param position the position of this label in the bytecode.\n     * @param data the bytecode of the method.\n     * @return <tt>true</tt> if a blank that was left for this label was to\n     *         small to store the offset. In such a case the corresponding jump\n     *         instruction is replaced with a pseudo instruction (using unused\n     *         opcodes) using an unsigned two bytes offset. These pseudo\n     *         instructions will need to be replaced with true instructions with\n     *         wider offsets (4 bytes instead of 2). This is done in\n     *         {@link MethodWriter#resizeInstructions}.\n     * @throws IllegalArgumentException if this label has already been resolved,\n     *         or if it has not been created by the given code writer.\n     */\n    boolean resolve(\n        final MethodWriter owner,\n        final int position,\n        final byte[] data)\n    {\n        boolean needUpdate = false;\n        this.status |= RESOLVED;\n        this.position = position;\n        int i = 0;\n        while (i < referenceCount) {\n            int source = srcAndRefPositions[i++];\n            int reference = srcAndRefPositions[i++];\n            int offset;\n            if (source >= 0) {\n                offset = position - source;\n                if (offset < Short.MIN_VALUE || offset > Short.MAX_VALUE) {\n                    /*\n                     * changes the opcode of the jump instruction, in order to\n                     * be able to find it later (see resizeInstructions in\n                     * MethodWriter). These temporary opcodes are similar to\n                     * jump instruction opcodes, except that the 2 bytes offset\n                     * is unsigned (and can therefore represent values from 0 to\n                     * 65535, which is sufficient since the size of a method is\n                     * limited to 65535 bytes).\n                     */\n                    int opcode = data[reference - 1] & 0xFF;\n                    if (opcode <= Opcodes.JSR) {\n                        // changes IFEQ ... JSR to opcodes 202 to 217\n                        data[reference - 1] = (byte) (opcode + 49);\n                    } else {\n                        // changes IFNULL and IFNONNULL to opcodes 218 and 219\n                        data[reference - 1] = (byte) (opcode + 20);\n                    }\n                    needUpdate = true;\n                }\n                data[reference++] = (byte) (offset >>> 8);\n                data[reference] = (byte) offset;\n            } else {\n                offset = position + source + 1;\n                data[reference++] = (byte) (offset >>> 24);\n                data[reference++] = (byte) (offset >>> 16);\n                data[reference++] = (byte) (offset >>> 8);\n                data[reference] = (byte) offset;\n            }\n        }\n        return needUpdate;\n    }\n    /**\n     * Returns the first label of the series to which this label belongs. For an\n     * isolated label or for the first label in a series of successive labels,\n     * this method returns the label itself. For other labels it returns the\n     * first label of the series.\n     *\n     * @return the first label of the series to which this label belongs.\n     */\n    Label getFirst() {\n        return !ClassReader.FRAMES || frame == null ? this : frame.owner;\n    }\n    // ------------------------------------------------------------------------\n    // Methods related to subroutines\n    // ------------------------------------------------------------------------\n    /**\n     * Returns true is this basic block belongs to the given subroutine.\n     *\n     * @param id a subroutine id.\n     * @return true is this basic block belongs to the given subroutine.\n     */\n    boolean inSubroutine(final long id) {\n        if ((status & Label.VISITED) != 0) {\n            return (srcAndRefPositions[(int) (id >>> 32)] & (int) id) != 0;\n        }\n        return false;\n    }\n    /**\n     * Returns true if this basic block and the given one belong to a common\n     * subroutine.\n     *\n     * @param block another basic block.\n     * @return true if this basic block and the given one belong to a common\n     *         subroutine.\n     */\n    boolean inSameSubroutine(final Label block) {\n        if ((status & VISITED) == 0 || (block.status & VISITED) == 0) {\n            return false;\n        }\n        for (int i = 0; i < srcAndRefPositions.length; ++i) {\n            if ((srcAndRefPositions[i] & block.srcAndRefPositions[i]) != 0) {\n                return true;\n            }\n        }\n        return false;\n    }\n    /**\n     * Marks this basic block as belonging to the given subroutine.\n     *\n     * @param id a subroutine id.\n     * @param nbSubroutines the total number of subroutines in the method.\n     */\n    void addToSubroutine(final long id, final int nbSubroutines) {\n        if ((status & VISITED) == 0) {\n            status |= VISITED;\n            srcAndRefPositions = new int[(nbSubroutines - 1) / 32 + 1];\n        }\n        srcAndRefPositions[(int) (id >>> 32)] |= (int) id;\n    }\n    /**\n     * Finds the basic blocks that belong to a given subroutine, and marks these\n     * blocks as belonging to this subroutine. This method follows the control\n     * flow graph to find all the blocks that are reachable from the current\n     * block WITHOUT following any JSR target.\n     *\n     * @param JSR a JSR block that jumps to this subroutine. If this JSR is not\n     *        null it is added to the successor of the RET blocks found in the\n     *        subroutine.\n     * @param id the id of this subroutine.\n     * @param nbSubroutines the total number of subroutines in the method.\n     */\n    void visitSubroutine(final Label JSR, final long id, final int nbSubroutines)\n    {\n        // user managed stack of labels, to avoid using a recursive method\n        // (recursivity can lead to stack overflow with very large methods)\n        Label stack = this;\n        while (stack != null) {\n            // removes a label l from the stack\n            Label l = stack;\n            stack = l.next;\n            l.next = null;\n            if (JSR != null) {\n", "outputs": ["                if ((l.status & VISITED2) != 0) {"], "input_length": 4193, "output_length": 12, "length": 4205, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "afb981a3e5761a30252cfef904d307b779f8e3602f25059c76aafd7024bd8b52"}
{"input": "", "context": "import os\nimport sys\nimport pyfits\nimport config as c\nfrom os.path import exists\nfrom numpy import log10\nfrom readlog import ReadLog\nfrom runsexfunc import *\nfrom flagfunc import *\nclass ConfigIter:\n    \"\"\"The class making configuration file for GALFIT. The configuration file \n       consists of bulge and disk component of the object and only Sersic \n       component for the neighbours, if any. The sky is always fixed and has\n       the value of SExtractor. The disk/boxy parameter is also fixed to zero.\n       The initial value for Sersic index 'n' is 4.The configuration file has \n       the name G_string(galid).in. The output image has the name \n       O_string(galid).fits\"\"\"\n    def __init__(self, cutimage, whtimage, xcntr, ycntr, NXPTS, NYPTS, line_s, psffile):\n        self.cutimage = cutimage\n        self.line_s  = line_s\n        self.whtimage = whtimage\n        self.xcntr = xcntr\n        self.ycntr = ycntr\n        self.NXPTS = NXPTS\n        self.NYPTS = NYPTS \n        self.psffile = psffile\n        self.confiter    = confiter(cutimage, whtimage, xcntr, ycntr, NXPTS, NYPTS, line_s, psffile)\ndef confiter(cutimage, whtimage, xcntr, ycntr, NXPTS, NYPTS, line_s, psffile):\n    RunSex(cutimage, whtimage, 'TEMP.SEX.cat', 9999, 9999, 0)\n    imagefile = c.imagefile\n    sex_cata = 'TEMP.SEX.cat'\n    threshold = c.threshold\n    thresh_area = c.thresh_area\n    mask_reg = c.mask_reg\n    try:\n        ComP = c.components \n    except:\n        ComP = ['bulge', 'disk']\n    if len(ComP) == 0:\n        ComP = ['bulge', 'disk']\n    values = line_s.split()\n    outfile   = 'O_' + c.fstring + '.fits'\n    mask_file = 'M_' + c.fstring + '.fits'\n    config_file = 'G_' + c.fstring + '.in' #Name of the GALFIT configuration file\n    constrain_file = c.fstring + '.con'\n    try:\n    \tc.center_constrain = c.center_constrain\n    except:\n\t    c.center_constrain = 2.0\n    def SersicMainConstrain(constrain_file, cO):\n        f_constrain = open(constrain_file, 'ab')\n        f_constrain.write(str(cO) + '      n      ' + str(c.LN) + \\\n                          ' to ' + str(c.UN) +  '\\n')\n        f_constrain.write(str(cO) + '      x      ' + \\\n                          str(-c.center_constrain) + '     ' + \\\n                          str(c.center_constrain) + '\\n')\n        f_constrain.write(str(cO) + '      y      ' + \\\n                          str(-c.center_constrain) + '     ' + \\\n                          str(c.center_constrain) + '\\n')\n        f_constrain.write(str(cO) + '     mag     ' + str(c.UMag) + \\\n                          ' to ' + str(c.LMag) + '\\n')\n        f_constrain.write(str(cO) + '      re     ' + str(c.LRe) +\\\n                          ' to ' + str(c.URe) + '\\n')\n        f_constrain.write(str(cO) + '      q       0.0 to 1.0\\n')\n        f_constrain.write(str(cO) + '      pa       -360.0 to 360.0\\n')\n        f_constrain.close()\n    def BarConstrain(constrain_file, cO):\n        f_constrain = open(constrain_file, 'ab')\n        f_constrain.write(str(cO) + '      n      ' + str('0.1') + \\\n                          ' to ' + str('2.2') +  '\\n')\n        f_constrain.write(str(cO) + '      x      ' + \\\n                          str(-c.center_constrain) + '     ' + \\\n                          str(c.center_constrain) + '\\n')\n        f_constrain.write(str(cO) + '      y      ' + \\\n                          str(-c.center_constrain) + '     ' + \\\n                          str(c.center_constrain) + '\\n')\n        f_constrain.write(str(cO) + '     mag     ' + str(c.UMag) + \\\n                          ' to ' + str(c.LMag) + '\\n')\n        f_constrain.write(str(cO) + '      re     ' + str(c.LRe) +\\\n                          ' to ' + str(c.URe) + '\\n')\n        f_constrain.write(str(cO) + '      q       0.0 to 0.5\\n')\n        f_constrain.write(str(cO) + '      pa       -360.0 to 360.0\\n')\n        f_constrain.close()\n    def ExpdiskConstrain(constrain_file, cO):\n        f_constrain = open(constrain_file, 'ab')\n        f_constrain.write(str(cO) + '       x       ' + \\\n                          str(-c.center_constrain) + '     ' + \\\n                          str(c.center_constrain) + '\\n')\n        f_constrain.write(str(cO) + '       y       ' + \\\n                          str(-c.center_constrain) + '     ' + \\\n                          str(c.center_constrain) + '\\n')\n        f_constrain.write(str(cO) + '     mag     ' + str(c.UMag) + \\\n                          ' to ' + str(c.LMag) + '\\n')\n        f_constrain.write(str(cO) + '      rs     ' + str(c.LRd) + \\\n                          ' to ' + str(c.URd) + '\\n')\n        f_constrain.write(str(cO) + '      q       0.0 to 1.0\\n')\n        f_constrain.write(str(cO) + '      pa       -360.0 to 360.0\\n')\n        f_constrain.close()\n    def SersicConstrain(constrain_file, cO):\n        f_constrain = open(constrain_file, 'ab')\n        f_constrain.write(str(cO) + '      n      0.02 to 20.0  \\n')\n        f_constrain.write(str(cO) + '     mag    -100.0 to 100.0\\n')\n        f_constrain.write(str(cO) + '      re      0.0 to 500.0\\n')\n        f_constrain.write(str(cO) + '      q       0.0 to 1.0\\n')\n        f_constrain.write(str(cO) + '      pa    -360.0 to 360.0\\n')\n        f_constrain.close()\n    xcntr_o  = xcntr #float(values[1]) #x center of the object\n    ycntr_o  = ycntr #float(values[2]) #y center of the object\n    mag    = float(values[7]) #Magnitude\n    radius = float(values[9]) #Half light radius\n    mag_zero = c.mag_zero #magnitude zero point\n    sky\t = float(values[10]) #sky \n    pos_ang = float(values[11]) - 90.0 #position angle\n    axis_rat = 1.0/float(values[12]) #axis ration b/a\n    area_o = float(values[13])   # object's area\n    major_axis = float(values[14])\t#major axis of the object\n    ParamDict = {}\n    #Add components\n    AdComp = 1\n    if 'bulge' in ComP:\n        c.Flag = SetFlag(c.Flag, GetFlag('FIT_BULGE'))\n        ParamDict[AdComp] = {}\n        #Bulge Parameters\n        ParamDict[AdComp][1] = 'sersic'\n        ParamDict[AdComp][2] = [xcntr_o, ycntr_o]\n        ParamDict[AdComp][3] = mag\n        ParamDict[AdComp][4] = radius\n        ParamDict[AdComp][5] = 4.0\n        ParamDict[AdComp][6] = axis_rat\n        ParamDict[AdComp][7] = pos_ang\n        ParamDict[AdComp][8] = 0\n        ParamDict[AdComp][9] = 0\n        ParamDict[AdComp][11] = 'Main'\n        AdComp += 1\n    if 'bar' in ComP:\n        c.Flag = SetFlag(c.Flag, GetFlag('FIT_BAR'))\n        ParamDict[AdComp] = {}\n        #Bulge Parameters\n        ParamDict[AdComp][1] = 'bar'\n        ParamDict[AdComp][2] = [xcntr_o, ycntr_o]\n        ParamDict[AdComp][3] = mag + 2.5 * log10(2.0)\n        ParamDict[AdComp][4] = radius\n        ParamDict[AdComp][5] = 0.5\n        ParamDict[AdComp][6] = 0.3\n        ParamDict[AdComp][7] = pos_ang\n        ParamDict[AdComp][8] = 0\n        ParamDict[AdComp][9] = 0\n        ParamDict[AdComp][11] = 'Main'\n        AdComp += 1\n    if 'disk' in ComP:\n        c.Flag = SetFlag(c.Flag, GetFlag('FIT_DISK'))\n        #Disk parameters\n        ParamDict[AdComp] = {}\n        ParamDict[AdComp][1] = 'expdisk'\n        ParamDict[AdComp][2] = [xcntr_o, ycntr_o]\n        ParamDict[AdComp][3] = mag\n        ParamDict[AdComp][4] = radius\n        ParamDict[AdComp][5] = axis_rat\n        ParamDict[AdComp][6] = pos_ang\n        ParamDict[AdComp][7] = 0\n        ParamDict[AdComp][8] = 0\n        ParamDict[AdComp][11] = 'Main'\n        AdComp += 1\n    isneighbour = 0\n    f_constrain = open(constrain_file, 'ab')\n    for line_j in open(sex_cata,'r'):\n        try:\n            values = line_j.split()\n            xcntr_n  = float(values[1]) #x center of the neighbour\n            ycntr_n  = float(values[2]) #y center of the neighbour\n            mag    = float(values[7]) #Magnitude\n            radius = float(values[9]) #Half light radius\n            sky      = float(values[10]) #sky\n            pos_ang = float(values[11]) - 90.0 #position angle\n            axis_rat = 1.0/float(values[12]) #axis ration b/a\n            area_n = float(values[13]) # neighbour area\n            maj_axis = float(values[14])#major axis of neighbour\n            NotFitNeigh = 0\n            if abs(xcntr_n - xcntr_o) > NXPTS / 2.0 + c.avoidme or \\\n               abs(ycntr_n - ycntr_o) > NYPTS / 2.0 + c.avoidme:\n                NotFitNeigh = 1\n            if(abs(xcntr_n - xcntr_o) <= (major_axis + maj_axis) * \\\n               threshold and \\\n               abs(ycntr_n - ycntr_o) <= (major_axis  + maj_axis) * \\\n               threshold and area_n >= thresh_area * area_o and \\\n               xcntr_n != xcntr_o and ycntr_n != ycntr_o and NotFitNeigh == 0):\n                if((xcntr_o - xcntr_n) < 0):\n                    xn = xcntr + abs(xcntr_n - xcntr_o)\n                if((ycntr_o - ycntr_n) < 0):\n                    yn = ycntr + abs(ycntr_n - ycntr_o)\n                if((xcntr_o - xcntr_n) > 0):\n                    xn = xcntr - (xcntr_o - xcntr_n)\n                if((ycntr_o - ycntr_n) > 0):\n                    yn = ycntr - (ycntr_o - ycntr_n)\n                ParamDict[AdComp] = {}\n                ParamDict[AdComp][1] = 'sersic'\n                ParamDict[AdComp][2] = [xn, yn]\n                ParamDict[AdComp][3] = mag\n                ParamDict[AdComp][4] = radius\n                ParamDict[AdComp][5] = 4.0\n                ParamDict[AdComp][6] = axis_rat\n                ParamDict[AdComp][7] = pos_ang\n                ParamDict[AdComp][8] = 0\n                ParamDict[AdComp][9] = 0\n                ParamDict[AdComp][11] = 'Other'\n                isneighbour = 1\n                AdComp += 1\n        except:\n            pass\n    f_constrain.close()\n    if isneighbour:\n        c.Flag  = SetFlag(c.Flag, GetFlag('NEIGHBOUR_FIT'))\n    #Sky component\n    ParamDict[AdComp] = {}\n    ParamDict[AdComp][1] = 'sky'\n    ParamDict[AdComp][2] = sky\n    ParamDict[AdComp][3] = 0\n    ParamDict[AdComp][4] = 0\n    ParamDict[AdComp][5] = 0\n    ParamDict[AdComp][11] = 'Other'\n    #Write Sersic function\n    def SersicFunc(conffile, ParamDict, FitDict, No):\n        f=open(config_file, 'ab')\n        f.write('# Sersic function\\n\\n')\n        f.writelines([' 0) sersic \\n'])\n        f.writelines([' 1) ', str(ParamDict[No][2][0]), ' ', \\\n                              str(ParamDict[No][2][1]), ' ', \\\n                              str(FitDict[No][1][0]),   ' ', \\\n                              str(FitDict[No][1][1]),   '\\n'])\n        f.writelines([' 3) ', str(ParamDict[No][3]), ' ', \\\n                              str(FitDict[No][2]),  '\\n'])\n        f.writelines([' 4) ', str(ParamDict[No][4]), ' ', \\\n                              str(FitDict[No][3]),  '\\n'])\n        f.writelines([' 5) ', str(ParamDict[No][5]), ' ',\\\n                              str(FitDict[No][4]),  '\\n'])\n        f.writelines([' 8) ', str(ParamDict[No][6]), ' ', \\\n                              str(FitDict[No][5]),  '\\n'])\n        f.writelines([' 9) ', str(ParamDict[No][7]), ' ', \\\n                              str(FitDict[No][6]),  '\\n'])\n        if c.bdbox or c.bbox:\n            f.writelines(['10) 0.0 1\t\t\\n'])\n        else:\n            f.writelines(['10) 0.0 0            \\n'])\n        f.writelines([' Z) 0 \t\t\t\\n\\n\\n'])\n        f.close()\n    def ExpFunc(conffile, ParamDict, FitDict, No):\n        f=open(config_file, 'ab')\n        f.writelines(['# Exponential function\\n\\n'])\n        f.writelines([' 0) expdisk \\n'])\n        f.writelines([' 1) ', str(ParamDict[No][2][0]), ' ', \\\n                              str(ParamDict[No][2][1]),' ', \\\n                              str(FitDict[No][1][0]), ' ', \\\n                              str(FitDict[No][1][1]), '\\n'])\n        f.writelines([' 3) ', str(ParamDict[No][3]),  ' ', \\\n                              str(FitDict[No][2]),    '\\n'])\n        f.writelines([' 4) ', str(ParamDict[No][4]),  ' ', \\\n                              str(FitDict[No][3]),    '\\n'])\n        f.writelines([' 8) ', str(ParamDict[No][5]),  ' ', \\\n                              str(FitDict[No][4]),    '\\n'])\n        f.writelines([' 9) ', str(ParamDict[No][6]),  ' ', \\\n                              str(FitDict[No][5]),    '\\n'])\n        if c.bdbox or c.dbox:\n            f.writelines(['10) 0.0 1   \\n']) \n        else:\n            f.writelines(['10) 0.0 0   \\n'])\n        f.writelines([' Z) 0           \\n\\n\\n'])\n        f.close()\n    def SkyFunc(conffile, ParamDict, FitDict, No):\n        f=open(config_file, 'ab')\n        f.writelines([' 0) sky\\n'])\n        f.writelines([' 1) ', str(ParamDict[No][2]), \\\n                    '      ', str(FitDict[No][1]), '\\n'])\n        f.writelines([' 2) 0.000      0       \\n',\\\n                      ' 3) 0.000      0       \\n',\\\n                      ' Z) 0                  \\n\\n\\n'])\n        f.writelines(['# Neighbour sersic function\\n\\n'])\n        f.close()\n    \n    def DecideFitting(ParamDict, No):\n        FitDict = {}\n#        print ParamDict \n        if No == 1:\n            for j in range(len(ParamDict)):\n                i = j + 1\n                FitDict[i] = {} \n                if ParamDict[i][1] == 'sersic' and ParamDict[i][11] == 'Main':\n                    FitDict[i][1] = [1, 1]\n                    FitDict[i][2] = 1 \n                    FitDict[i][3] = 1 \n                    FitDict[i][4] = 1\n                    FitDict[i][5] = 1       \n                    FitDict[i][6] = 1   \n                if ParamDict[i][1] == 'bar' and ParamDict[i][11] == 'Main':\n                    FitDict[i][1] = [1, 1]\n                    FitDict[i][2] = 1 \n                    FitDict[i][3] = 1 \n                    FitDict[i][4] = 1\n                    FitDict[i][5] = 1       \n                    FitDict[i][6] = 1    \n                if ParamDict[i][1] == 'expdisk' and ParamDict[i][11] == 'Main':\n                    FitDict[i][1] = [1, 1]\n                    FitDict[i][2] = 1 \n                    FitDict[i][3] = 1 \n                    FitDict[i][4] = 1       \n                    FitDict[i][5] = 1    \n                if ParamDict[i][1] == 'sky':\n                    FitDict[i][1] = 1\n                    FitDict[i][2] = 0 \n                    FitDict[i][3] = 0 \n                if ParamDict[i][1] == 'sersic' and ParamDict[i][11] == 'Other':\n                    FitDict[i][1] = [1, 1]\n                    FitDict[i][2] = 1 \n                    FitDict[i][3] = 1 \n                    FitDict[i][4] = 1\n                    FitDict[i][5] = 1       \n                    FitDict[i][6] = 1    \n        if No == 4:\n            for j in range(len(ParamDict)):\n                i = j + 1\n                FitDict[i] = {}  \n                if ParamDict[i][1] == 'sersic' and ParamDict[i][11] == 'Main':\n                    FitDict[i][1] = [1, 1]\n                    FitDict[i][2] = 1 \n                    FitDict[i][3] = 1 \n                    FitDict[i][4] = 0\n                    FitDict[i][5] = 0       \n                    FitDict[i][6] = 0    \n                if ParamDict[i][1] == 'expdisk' and ParamDict[i][11] == 'Main':\n                    FitDict[i][1] = [0, 0]\n                    FitDict[i][2] = 0 \n                    FitDict[i][3] = 0 \n                    FitDict[i][4] = 0       \n                    FitDict[i][5] = 0    \n                if ParamDict[i][1] == 'sky':\n                    FitDict[i][1] = 1\n                    FitDict[i][2] = 0 \n                    FitDict[i][3] = 0 \n                if ParamDict[i][1] == 'sersic' and ParamDict[i][11] == 'Other':\n                    FitDict[i][1] = [0, 0]\n                    FitDict[i][2] = 0 \n                    FitDict[i][3] = 0 \n                    FitDict[i][4] = 0\n                    FitDict[i][5] = 0       \n                    FitDict[i][6] = 0    \n        if No == 3:\n            for j in range(len(ParamDict)):\n                i = j + 1\n                FitDict[i] = {}  \n                if ParamDict[i][1] == 'sersic' and ParamDict[i][11] == 'Main':\n                    FitDict[i][1] = [1, 1]\n                    FitDict[i][2] = 1 \n                    FitDict[i][3] = 1 \n                    FitDict[i][4] = 1\n                    FitDict[i][5] = 1       \n                    FitDict[i][6] = 1\n                if ParamDict[i][1] == 'bar' and ParamDict[i][11] == 'Main':\n                    FitDict[i][1] = [1, 1]\n                    FitDict[i][2] = 1 \n                    FitDict[i][3] = 1 \n                    FitDict[i][4] = 1\n                    FitDict[i][5] = 1       \n                    FitDict[i][6] = 1    \n                if ParamDict[i][1] == 'expdisk' and ParamDict[i][11] == 'Main':\n                    FitDict[i][1] = [1, 1]\n                    FitDict[i][2] = 1 \n                    FitDict[i][3] = 1 \n                    FitDict[i][4] = 1       \n                    FitDict[i][5] = 1    \n                if ParamDict[i][1] == 'sky':\n                    FitDict[i][1] = 1\n                    FitDict[i][2] = 0 \n                    FitDict[i][3] = 0 \n                if ParamDict[i][1] == 'sersic' and ParamDict[i][11] == 'Other':\n                    FitDict[i][1] = [0, 0]\n                    FitDict[i][2] = 0 \n                    FitDict[i][3] = 0 \n                    FitDict[i][4] = 0\n                    FitDict[i][5] = 0       \n                    FitDict[i][6] = 0    \n        if No == 2:\n            for j in range(len(ParamDict)):\n                i = j + 1\n                FitDict[i] = {}  \n                if ParamDict[i][1] == 'sersic' and ParamDict[i][11] == 'Main':\n                    FitDict[i][1] = [1, 1]\n                    FitDict[i][2] = 1 \n                    FitDict[i][3] = 1 \n                    FitDict[i][4] = 1\n                    FitDict[i][5] = 1       \n                    FitDict[i][6] = 1   \n                if ParamDict[i][1] == 'bar' and ParamDict[i][11] == 'Main':\n                    FitDict[i][1] = [1, 1]\n                    FitDict[i][2] = 1 \n                    FitDict[i][3] = 1 \n                    FitDict[i][4] = 1\n                    FitDict[i][5] = 0       \n                    FitDict[i][6] = 0    \n                if ParamDict[i][1] == 'expdisk' and ParamDict[i][11] == 'Main':\n                    FitDict[i][1] = [0, 0]\n                    FitDict[i][2] = 0 \n                    FitDict[i][3] = 0 \n                    FitDict[i][4] = 0       \n                    FitDict[i][5] = 0    \n                if ParamDict[i][1] == 'sky':\n                    FitDict[i][1] = 1\n                    FitDict[i][2] = 0 \n                    FitDict[i][3] = 0 \n                if ParamDict[i][1] == 'sersic' and ParamDict[i][11] == 'Other':\n                    FitDict[i][1] = [0, 0]\n                    FitDict[i][2] = 0 \n                    FitDict[i][3] = 0 \n                    FitDict[i][4] = 0\n                    FitDict[i][5] = 0       \n                    FitDict[i][6] = 0    \n        return FitDict\n    #Write configuration file. RunNo is the number of iteration\n    for RunNo in range(3):\n        f_constrain = open(constrain_file, 'w')\n        f_constrain.close()\n        f=open(config_file,'w')\n        f.write('# IMAGE PARAMETERS\\n')\n        f.writelines(['A) ', str(cutimage), '\t# Input data image',\\\n                      ' (FITS file)\\n'])\n        f.writelines(['B) ', str(outfile), '\t\t# Name for',\\\n                      ' the output image\\n'])\n        f.writelines(['C) ', str(whtimage), '\t\t# Noise image name', \\\n                      ' (made from data if blank or \"none\")\\n'])\n        f.writelines(['D) ', str(psffile), '\t\t\t# Input PSF', \\\n                      ' image for convolution (FITS file)\\n'])\n        f.writelines(['E) 1\t\t\t# PSF oversampling factor '\\\n", "outputs": ["                      'relative to data\\n'])"], "input_length": 4427, "output_length": 6, "length": 4433, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "4fac36db666507f5626c8e535df20fd52d9bb5f43e060bc3717234d328cc15f4"}
{"input": "", "context": "//\n// TrackBarTest.cs: Test cases for TrackBar.\n//\n// Author:\n//   Ritvik Mayank (mritvik@novell.com)\n//\n// (C) 2005 Novell, Inc. (http://www.novell.com)\n//\nusing System;\nusing System.Windows.Forms;\nusing System.Drawing;\nusing System.Reflection;\nusing NUnit.Framework;\nnamespace MonoTests.System.Windows.Forms\n{\n\t[TestFixture]\n\tpublic class TrackBarBaseTest : TestHelper\n\t{\n\t\t[Test]\n\t\tpublic void TrackBarPropertyTest ()\n\t\t{\n\t\t\tTrackBar myTrackBar = new TrackBar ();\n\t\t\t\n\t\t\t// A\n\t\t\tAssert.AreEqual (true, myTrackBar.AutoSize, \"#A1\");\n\t\t\t// L\n\t\t\tAssert.AreEqual (5, myTrackBar.LargeChange, \"#L1\");\n                \t\n\t\t\t// M\n\t\t\tAssert.AreEqual (10, myTrackBar.Maximum, \"#M1\");\n\t\t\tAssert.AreEqual (0, myTrackBar.Minimum, \"#M2\");\n\t\t\t\n\t\t\t// O\n\t\t\tAssert.AreEqual (Orientation.Horizontal, myTrackBar.Orientation, \"#O1\");\n\t\t\t\t\n\t\t\t// S\n\t\t\tAssert.AreEqual (1, myTrackBar.SmallChange, \"#S1\");\n\t\t\t// T\n\t\t\tAssert.AreEqual (1, myTrackBar.TickFrequency, \"#T1\");\n\t\t\tAssert.AreEqual (TickStyle.BottomRight, myTrackBar.TickStyle, \"#T2\");\n\t\t\tAssert.AreEqual (\"\", myTrackBar.Text, \"#T3\");\n\t\t\tmyTrackBar.Text = \"New TrackBar\";\n\t\t\tAssert.AreEqual (\"New TrackBar\", myTrackBar.Text, \"#T4\");\n\t\t\t// V\n\t\t\tAssert.AreEqual (0, myTrackBar.Value, \"#V1\");\n\t\t}\n\t\t\n\t\t[Test]\n\t\t[ExpectedException (typeof (ArgumentOutOfRangeException))]\n\t\tpublic void LargeChangeTest ()\n\t\t{\n\t\t\tTrackBar myTrackBar = new TrackBar ();\n\t\t\tmyTrackBar.LargeChange = -1;\n\t\t}\n\t\t[Test]\n\t\t[ExpectedException (typeof (ArgumentOutOfRangeException))]\n\t\tpublic void SmallChangeTest ()\n\t\t{\n\t\t\tTrackBar myTrackBar = new TrackBar ();\n\t\t\tmyTrackBar.SmallChange = -1;\n\t\t}\n\t\t[Test]\n\t\tpublic void SetRangeTest () \n\t\t{\n\t\t\tTrackBar myTrackBar = new TrackBar ();\n\t\t\tmyTrackBar.SetRange (2,9);\n\t\t\tAssert.AreEqual (9, myTrackBar.Maximum, \"#setM1\");\n\t\t\tAssert.AreEqual (2, myTrackBar.Minimum, \"#setM2\");\n\t\t}\n\t\t[Test]\n\t\tpublic void ToStringMethodTest () \n\t\t{\n\t\t\tTrackBar myTrackBar = new TrackBar ();\n\t\t\tmyTrackBar.Text = \"New TrackBar\";\n\t\t\tAssert.AreEqual (\"System.Windows.Forms.TrackBar, Minimum: 0, Maximum: 10, Value: 0\", myTrackBar.ToString (), \"#T3\");\n\t\t}\n\t\t[Test]\n\t\tpublic void OrientationSizeTest ()\n\t\t{\t\n\t\t\tIntPtr handle;\n\t\t\tint width;\n\t\t\tint height ;\n\t\t\tint default_height = 45;\n\t\t\tint default_height2 = 42;\n\t\t\tusing (TrackBar myTrackBar = new TrackBar()) {\n\t\t\t\twidth = myTrackBar.Width;\n\t\t\t\theight = myTrackBar.Height;\n\t\t\t\tmyTrackBar.Orientation = Orientation.Vertical;\n\t\t\t\tAssert.AreEqual(width, myTrackBar.Width, \"#OS1\");\n\t\t\t\tAssert.AreEqual(height, myTrackBar.Height, \"#OS2\");\n\t\t\t}\n\t\t\t\n\t\t\tusing (Form myForm = new Form()) {\n\t\t\t\tusing ( TrackBar myTrackBar = new TrackBar()) {\n\t\t\t\t\twidth = myTrackBar.Width;\n\t\t\t\t\theight = myTrackBar.Height;\n\t\t\t\t\tmyForm.Controls.Add(myTrackBar);\n\t\t\t\t\thandle = myTrackBar.Handle; // causes the handle to be created.\n\t\t\t\t\tmyTrackBar.Orientation = Orientation.Vertical;\n\t\t\t\t\tAreEqual(default_height, default_height2, myTrackBar.Width,  \"#OS3\");\n\t\t\t\t\tAssert.AreEqual(width, myTrackBar.Height, \"#OS4\");\n\t\t\t\t}\n\t\t\t}\n\t\t\tusing (Form myForm = new Form()) {\n\t\t\t\tusing ( TrackBar myTrackBar = new TrackBar()) {\n\t\t\t\t\tmyForm.Controls.Add(myTrackBar);\n\t\t\t\t\thandle = myTrackBar.Handle; // causes the handle to be created.\n\t\t\t\t\tmyTrackBar.Width = 200;\n\t\t\t\t\tmyTrackBar.Orientation = Orientation.Vertical;\n\t\t\t\t\tAssert.AreEqual(200, myTrackBar.Height, \"#OS5\");\n\t\t\t\t}\n\t\t\t}\n\t\t\tAssert.AreEqual(handle, handle, \"Removes warning\");\n\t\t}\n\t\n\t\tprivate void AreEqual(int expected1, int expected2, int real, string name)\n\t\t{\n\t\t\t// This is needed since the default size vary between XP theme and W2K theme.\n\t\t\tif (real != expected1 && real != expected2) {\n\t\t\t\tAssert.Fail(\"{3}: Expected <{0}> or <{1}>, but was <{2}>\", expected1, expected2, real, name);\n\t\t\t}\n\t\t}\n\t\t[Test]\n\t\t[Category (\"NotWorking\")]\n\t\tpublic void SizeTestSettingOrientation ()\n\t\t{\n\t\t\tIntPtr handle;\n\t\t\tint default_height = 45;\n\t\t\tint default_height2 = 42;\n\t\t\tusing (TrackBar myTrackBar = new TrackBar()) {\n\t\t\t\tmyTrackBar.Width = 200;\n\t\t\t\tmyTrackBar.Height = 250;\n\t\t\t\tmyTrackBar.Orientation = Orientation.Vertical;\n\t\t\t\tAssert.AreEqual(200, myTrackBar.Width, \"#SIZE03\");\n\t\t\t\tAreEqual(default_height, default_height2, myTrackBar.Height, \"#SIZE04\");\n\t\t\t}\n\t\t\tusing (TrackBar myTrackBar = new TrackBar()) {\n\t\t\t\tmyTrackBar.AutoSize = false;\n\t\t\t\tmyTrackBar.Width = 200;\n\t\t\t\tmyTrackBar.Height = 250;\n\t\t\t\tmyTrackBar.Orientation = Orientation.Vertical;\n\t\t\t\tAssert.AreEqual(200, myTrackBar.Width, \"#SIZE07\");\n\t\t\t\tAssert.AreEqual(250, myTrackBar.Height, \"#SIZE08\");\n\t\t\t}\n\t\t\tusing (TrackBar myTrackBar = new TrackBar()) {\n\t\t\t\tmyTrackBar.Width = 200;\n\t\t\t\tmyTrackBar.Height = 250;\n\t\t\t\tmyTrackBar.AutoSize = false;\n\t\t\t\tmyTrackBar.Orientation = Orientation.Vertical;\n\t\t\t\tAssert.AreEqual(200, myTrackBar.Width, \"#SIZE11\");\n\t\t\t\tAreEqual(default_height, default_height2, myTrackBar.Height, \"#SIZE12\");\n\t\t\t}\n\t\t\tusing (TrackBar myTrackBar = new TrackBar()) {\n\t\t\t\tusing (Form myForm = new Form()) {\n\t\t\t\t\tmyForm.Controls.Add(myTrackBar);\n\t\t\t\t\tmyTrackBar.Width = 200;\n\t\t\t\t\tmyTrackBar.Height = 250;\n\t\t\t\t\tmyTrackBar.Orientation = Orientation.Vertical;\n\t\t\t\t\thandle = myTrackBar.Handle;\n\t\t\t\t\t\n\t\t\t\t\tAreEqual(default_height, default_height2, myTrackBar.Width, \"#SIZE17\");\n\t\t\t\t\tAreEqual(default_height, default_height2, myTrackBar.Height, \"#SIZE18\");\n\t\t\t\t}\n\t\t\t}\n\t\t\tusing (TrackBar myTrackBar = new TrackBar()) {\n\t\t\t\tusing (Form myForm = new Form()) {\n\t\t\t\t\tmyForm.Controls.Add(myTrackBar);\n\t\t\t\t\tmyTrackBar.Width = 200;\n\t\t\t\t\tmyTrackBar.Height = 250;\n\t\t\t\t\tmyTrackBar.Orientation = Orientation.Vertical;\n\t\t\t\t\thandle = myTrackBar.Handle;\n\t\t\t\t\t\n\t\t\t\t\tAreEqual(default_height, default_height2, myTrackBar.Width, \"#SIZE19\");\n\t\t\t\t\tAreEqual(default_height, default_height2, myTrackBar.Height, \"#SIZE20\");\n\t\t\t\t}\n\t\t\t}\n\t\t\tusing (TrackBar myTrackBar = new TrackBar()) {\n\t\t\t\tusing (Form myForm = new Form()) {\n\t\t\t\t\tmyForm.Controls.Add(myTrackBar);\n\t\t\t\t\tmyTrackBar.Width = 200;\n\t\t\t\t\tmyTrackBar.Height = 250;\n\t\t\t\t\tmyTrackBar.Orientation = Orientation.Vertical;\n\t\t\t\t\thandle = myTrackBar.Handle;\n\t\t\t\t\t\n\t\t\t\t\tmyTrackBar.Orientation = Orientation.Horizontal;\n\t\t\t\t\t\n\t\t\t\t\tAreEqual(default_height, default_height2, myTrackBar.Width, \"#SIZE23\");\n\t\t\t\t\tAreEqual(default_height, default_height2, myTrackBar.Height, \"#SIZE24\");\n\t\t\t\t}\n\t\t\t}\n\t\t\tusing (TrackBar myTrackBar = new TrackBar()) {\n\t\t\t\tmyTrackBar.AutoSize = false;\n\t\t\t\tmyTrackBar.Height = 50;\n\t\t\t\tmyTrackBar.Width = 80;\n\t\t\t\tmyTrackBar.Orientation = Orientation.Vertical;\n\t\t\t\tmyTrackBar.Width = 100;\n\t\t\t\t\n\t\t\t\tAssert.AreEqual(50, myTrackBar.Height, \"#SIZE2_1\");\n\t\t\t\tAssert.AreEqual(100, myTrackBar.Width, \"#SIZE2_2\");\n\t\t\t\t\n\t\t\t\tusing (Form myForm = new Form()){\n\t\t\t\t\tmyForm.Controls.Add(myTrackBar);\n\t\t\t\t\tmyForm.Show();\n\t\t\t\t\t\n\t\t\t\t\tAssert.AreEqual(50, myTrackBar.Height, \"#SIZE2_3\");\n\t\t\t\t\tAssert.AreEqual(100, myTrackBar.Width, \"#SIZE2_4\");\n\t\t\t\t}\n\t\t\t}\n", "outputs": ["\t\t\tAssert.AreEqual(handle, handle, \"Removes warning\");"], "input_length": 1226, "output_length": 12, "length": 1238, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "08bf842f38a1ec393e338c72728d6b008fde992bce6317b6793f12bcdd7eaa67"}
{"input": "", "context": "/**\n* The contents of this file are subject to the Mozilla Public License\n* Version 1.1 (the \"License\"); you may not use this file except in\n* compliance with the License. You may obtain a copy of the License at\n* http://www.mozilla.org/MPL/\n*\n* Software distributed under the License is distributed on an \"AS IS\"\n* basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the\n* License for the specific language governing rights and limitations under\n* the License.\n*\n* The Original Code is OpenELIS code.\n*\n* Copyright (C) The Minnesota Department of Health.  All Rights Reserved.\n*\n* Contributor(s): CIRG, University of Washington, Seattle WA.\n*/\npackage us.mn.state.health.lims.common.provider.validation;\nimport static us.mn.state.health.lims.common.provider.validation.IAccessionNumberValidator.ValidationResults.PATIENT_STATUS_FAIL;\nimport static us.mn.state.health.lims.common.provider.validation.IAccessionNumberValidator.ValidationResults.SAMPLE_FOUND;\nimport static us.mn.state.health.lims.common.provider.validation.IAccessionNumberValidator.ValidationResults.SAMPLE_STATUS_FAIL;\nimport java.util.List;\nimport org.apache.commons.validator.GenericValidator;\nimport us.mn.state.health.lims.common.action.IActionConstants;\nimport us.mn.state.health.lims.common.services.StatusService;\nimport us.mn.state.health.lims.common.services.StatusService.RecordStatus;\nimport us.mn.state.health.lims.common.services.StatusSet;\nimport us.mn.state.health.lims.common.util.StringUtil;\nimport us.mn.state.health.lims.observationhistory.dao.ObservationHistoryDAO;\nimport us.mn.state.health.lims.observationhistory.daoimpl.ObservationHistoryDAOImpl;\nimport us.mn.state.health.lims.observationhistory.valueholder.ObservationHistory;\nimport us.mn.state.health.lims.observationhistorytype.ObservationHistoryTypeMap;\nimport us.mn.state.health.lims.patient.valueholder.Patient;\nimport us.mn.state.health.lims.project.dao.ProjectDAO;\nimport us.mn.state.health.lims.project.daoimpl.ProjectDAOImpl;\nimport us.mn.state.health.lims.project.valueholder.Project;\nimport us.mn.state.health.lims.sample.dao.SampleDAO;\nimport us.mn.state.health.lims.sample.daoimpl.SampleDAOImpl;\nimport us.mn.state.health.lims.sample.util.AccessionNumberUtil;\nimport us.mn.state.health.lims.sample.valueholder.Sample;\npublic class ProgramAccessionValidator implements IAccessionNumberValidator {\n\tprivate static final String INCREMENT_STARTING_VALUE  = \"00001\";\n\tprivate static final int UPPER_INC_RANGE = 99999;\n\tprivate static final int INCREMENT_START = 4;\n\tprivate static final int PROGRAM_START = 0;\n\tprivate static final int PROGRAM_END = 4;\n\tprivate static final int LENGTH = 9;\n\tprivate static final boolean NEED_PROGRAM_CODE = true;\n\tprivate static ProjectDAO projectDAO;\n\t\n\tpublic boolean needProgramCode() {\n\t\treturn NEED_PROGRAM_CODE;\n\t}\n\tpublic String createFirstAccessionNumber(String programCode) {\n\t\treturn programCode + INCREMENT_STARTING_VALUE;\n\t}\n\tpublic String incrementAccessionNumber(String currentHighAccessionNumber) {\n\t\tint increment = Integer.parseInt(currentHighAccessionNumber.substring(INCREMENT_START));\n\t\tString incrementAsString = INCREMENT_STARTING_VALUE;\n\t\tif( increment < UPPER_INC_RANGE){\n\t\t\tincrement++;\n\t\t\tincrementAsString = String.format(\"%05d\", increment);\n\t\t}else{\n\t\t\tthrow new IllegalArgumentException(\"AccessionNumber has no next value\");\n\t\t}\n\t\tStringBuilder builder = new StringBuilder( currentHighAccessionNumber.substring(PROGRAM_START, PROGRAM_END).toUpperCase());\n\t\tbuilder.append(incrementAsString);\n\t\treturn builder.toString();\n\t}\n\tpublic ValidationResults validFormat(String accessionNumber, boolean checkDate) {\n\t\t// The rule is 4 digit program code and 4 incremented numbers\n\t\tif (accessionNumber.length() != LENGTH) {\n\t\t\treturn ValidationResults.LENGTH_FAIL;\n\t\t}\n\t\tString programCode = accessionNumber.substring(PROGRAM_START, PROGRAM_END).toUpperCase();\n\t\t//check program code validity\n\t\tProjectDAO projectDAO = getProjectDAO();\n\t\tList<Project> programCodes = projectDAO.getAllProjects();\n\t\tboolean found = false;\n\t\tfor ( Project code: programCodes ){\n\t\t\tif ( programCode.equals(code.getProgramCode())){\n\t\t\t\tfound = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t    }\n\t\tif ( !found ) {\n\t\t\treturn ValidationResults.PROGRAM_FAIL;\n\t\t}\n\t\ttry {\n\t\t\tInteger.parseInt(accessionNumber.substring(INCREMENT_START));\n\t\t} catch (NumberFormatException e) {\n\t\t\treturn ValidationResults.FORMAT_FAIL;\n\t\t}\n\t\treturn ValidationResults.SUCCESS;\n\t}\n\tpublic String getInvalidMessage(ValidationResults results){\n\t\tswitch(results){\n\t\t\tcase LENGTH_FAIL: \treturn StringUtil.getMessageForKey(\"sample.entry.invalid.accession.number.length\");\n\t\t\tcase USED_FAIL:\t\treturn StringUtil.getMessageForKey(\"sample.entry.invalid.accession.number.used\");\n\t\t\tcase PROGRAM_FAIL: \treturn StringUtil.getMessageForKey(\"sample.entry.invalid.accession.number.program\");\n\t\t\tcase FORMAT_FAIL:  \treturn StringUtil.getMessageForKey(\"sample.entry.invalid.accession.number.format\");\n\t\t\tcase REQUIRED_FAIL:\treturn StringUtil.getMessageForKey(\"sample.entry.invalid.accession.number.required\");\n            case PATIENT_STATUS_FAIL:   return StringUtil.getMessageForKey(\"sample.entry.invalid.accession.number.patientRecordStatus\");\n            case SAMPLE_STATUS_FAIL:   return StringUtil.getMessageForKey(\"sample.entry.invalid.accession.number.sampleRecordStatus\");\n\t\t\tdefault: \t\t\treturn StringUtil.getMessageForKey(\"sample.entry.invalid.accession.number\");\n\t\t}\n\t}\n    public String getInvalidFormatMessage( ValidationResults results ){\n        return StringUtil.getMessageForKey(\"sample.entry.invalid.accession.number.format\");\n    }\n\tpublic String getNextAvailableAccessionNumber(String prefix){\n\t\tString nextAccessionNumber = null;\n\t\tSampleDAO sampleDAO = new SampleDAOImpl();\n\t\tString curLargestAccessionNumber = sampleDAO.getLargestAccessionNumberWithPrefix(prefix);\n\t\tif( curLargestAccessionNumber == null){\n\t\t\tnextAccessionNumber = createFirstAccessionNumber(prefix);\n\t\t}else{\n\t\t\tnextAccessionNumber = incrementAccessionNumber(curLargestAccessionNumber);\n\t\t}\n\t\treturn nextAccessionNumber;\n\t}\n\tpublic boolean accessionNumberIsUsed(String accessionNumber, String recordType) {\n\t\tboolean accessionNumberUsed = new SampleDAOImpl().getSampleByAccessionNumber(accessionNumber) != null;\n\t\t\n\t\tif( recordType == null){\n\t\t\treturn accessionNumberUsed;\n\t\t}\n\t\tStatusSet statusSet = StatusService.getInstance().getStatusSetForAccessionNumber(accessionNumber);\n\t\tString recordStatus = new String();\n\t\tboolean isSampleEntry = recordType.contains(\"Sample\");\n\t\tboolean isPatientEntry = recordType.contains(\"Patient\");\n\t\tboolean isInitial = recordType.contains(\"initial\");\n\t\tboolean isDouble = recordType.contains(\"double\");\n\t\tif (accessionNumberUsed) {\n\t\t\t\t// sample entry, get SampleRecordStatus\n\t\t\t\tif (isSampleEntry){\n\t\t\t\t\trecordStatus = statusSet.getSampleRecordStatus().toString();\n\t\t\t\t}\n\t\t\t\t// patient entry, get PatientRecordStatus\n\t\t\t\telse if (isPatientEntry) {\n\t\t\t\t\trecordStatus = statusSet.getPatientRecordStatus().toString();\n\t\t\t\t}\n\t\t\t\t// initial entry, the status must be NotRegistered\n\t\t\t\tString notRegistered = RecordStatus.NotRegistered.toString();\n\t\t\t\tString initialReg = RecordStatus.InitialRegistration.toString();\n\t\t\t\tif (isInitial){\n\t\t\t\t\tif(!notRegistered.equals(recordStatus) ){\n\t\t\t\t\t\treturn true;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t// double entry, the status must be InitialRegistration\n\t\t\t\telse if (isDouble) {\n\t\t\t\t\tif ( !initialReg.equals(recordStatus) ) {\n\t\t\t\t\t\treturn false;\n\t\t\t\t\t}\n\t\t\t\t\telse {\n\t\t\t\t\t\treturn true;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t}\n\t\treturn false;\n\t}\n\tpublic int getMaxAccessionLength() {\n\t\treturn LENGTH;\n\t}\n\t/**\n\t * There are many possible samples with various status, only some of which are valid during certain entry steps.\n\t * This method provides validation results identifying whether a given sample is appropriate given all the information.\n\t * @param accessionNumber  the number for the sample\n\t * @param recordType initialPatient, initialSample, doublePatient (double entry for patient), doubleSample\n\t * @param isRequired the step being done expects the sample to exist.  This is used generate appropriate results, either\n\t * REQUIRED_FAIL vs SAMPLE_NOT_FOUND\n\t * @param studyFormName - an additional\n\t * @return\n\t */\n  public ValidationResults checkAccessionNumberValidity(String accessionNumber, String recordType,\n          String isRequired, String studyFormName) {\n    ValidationResults results = validFormat(accessionNumber, true);\n    SampleDAO sampleDAO = new SampleDAOImpl();\n    boolean accessionUsed = (sampleDAO.getSampleByAccessionNumber(accessionNumber) != null);\n    if (results == ValidationResults.SUCCESS) {\n      if (IActionConstants.TRUE.equals(isRequired) && !accessionUsed) {\n        results = ValidationResults.REQUIRED_FAIL;\n        return results;\n      } else {\n        if (recordType == null) {\n          results = ValidationResults.USED_FAIL;\n        }\n        // record Type specified, so work out the detailed response to report\n        if (accessionUsed) {\n          if (recordType.contains(\"initial\")) {\n            if (recordType.contains(\"Patient\")) {\n              results = AccessionNumberUtil.isPatientStatusValid(accessionNumber,\n                      RecordStatus.NotRegistered);\n              if (results != PATIENT_STATUS_FAIL) {\n                results = matchExistingStudyFormName(accessionNumber, studyFormName, false);\n              }\n            } else if (recordType.contains(\"Sample\")) {\n              results = AccessionNumberUtil.isSampleStatusValid(accessionNumber,\n                      RecordStatus.NotRegistered);\n              if (results != SAMPLE_STATUS_FAIL) {\n                results = matchExistingStudyFormName(accessionNumber, studyFormName, false);\n              }\n            }\n          } else if (recordType.contains(\"double\")) {\n            if (recordType.contains(\"Patient\")) {\n              results = AccessionNumberUtil.isPatientStatusValid(accessionNumber,\n                      RecordStatus.InitialRegistration);\n              if (results != PATIENT_STATUS_FAIL) {\n                results = matchExistingStudyFormName(accessionNumber, studyFormName, true);\n              }\n            } else if (recordType.contains(\"Sample\")) {\n              results = AccessionNumberUtil.isSampleStatusValid(accessionNumber,\n                      RecordStatus.InitialRegistration);\n              if (results != SAMPLE_STATUS_FAIL) {\n                results = matchExistingStudyFormName(accessionNumber, studyFormName, true);\n              }\n            }\n          } else if (recordType.contains(\"orderModify\")) {\n            results = ValidationResults.USED_FAIL;\n          }\n        } else {\n          if (recordType.contains(\"initial\")) {\n            results = ValidationResults.SAMPLE_NOT_FOUND;    // initial entry not used is good\n          } else if (recordType.contains(\"double\")) {\n            results = ValidationResults.REQUIRED_FAIL;       // double entry not existing is a\n                                                             // problem\n          } else if (recordType.contains(\"orderModify\")) {\n            results = ValidationResults.SAMPLE_NOT_FOUND;    // modify order page\n          }\n        }\n      }\n    }\n    return results;\n  }\n\t/**\n\t * Can the existing accession number be used in the given form?\n\t * This method is useful when we have an existing accessionNumber and want to ask the question.\n     * @param accessionNumber\n\t * @param existingRequired true => it is required that there is an existing studyFormName?\n     * @return\n     */\n    private static ValidationResults matchExistingStudyFormName(String accessionNumber, String studyFormName, boolean existingRequired) {\n", "outputs": ["        if (GenericValidator.isBlankOrNull(studyFormName)) {"], "input_length": 1513, "output_length": 8, "length": 1521, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "c5d94c704b16a22a2ee5a5fc1fa070d40ae6a2c863898d2dd941434725936280"}
{"input": "", "context": "using System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Runtime.InteropServices.WindowsRuntime;\nusing System.Text;\nusing System.Threading.Tasks;\nusing System.Text.RegularExpressions;\nusing System.Windows.Forms;\nusing SharpDX;\nusing LeagueSharp;\nusing LeagueSharp.Common;\nusing EloBuddy; \n using LeagueSharp.Common; \n namespace BadaoSeries.CustomOrbwalker\n{\n    public static class BadaoPrediction\n    {\n        private static int _wallCastT;\n        private static Vector2 _yasuoWallCastedPos;\n        static BadaoPrediction()\n        {\n            Obj_AI_Base.OnSpellCast += AIHeroClient_OnProcessSpellCast;\n        }\n        private static void AIHeroClient_OnProcessSpellCast(Obj_AI_Base sender, GameObjectProcessSpellCastEventArgs args)\n        {\n            if (sender.IsValid && sender.Team != ObjectManager.Player.Team && args.SData.Name == \"YasuoWMovingWall\")\n            {\n                _wallCastT = Utils.TickCount;\n                _yasuoWallCastedPos = sender.ServerPosition.To2D();\n            }\n        }\n        public class PredictionInput\n        {\n            private Vector3 _from;\n            private Vector3 _rangeCheckFrom;\n            /// <summary>\n            ///     Set to true make the prediction hit as many enemy heroes as posible.\n            /// </summary>\n            public bool Aoe = false;\n            /// <summary>\n            ///     Set to true if the unit collides with units.\n            /// </summary>\n            public bool Collision = false;\n            /// <summary>\n            ///     Array that contains the unit types that the skillshot can collide with.\n            /// </summary>\n            public CollisionableObjects[] CollisionObjects =\n        {\n            CollisionableObjects.Minions, CollisionableObjects.YasuoWall\n        };\n            /// <summary>\n            ///     The skillshot delay in seconds.\n            /// </summary>\n            public float Delay;\n            /// <summary>\n            ///     The skillshot width's radius or the angle in case of the cone skillshots.\n            /// </summary>\n            public float Radius = 1f;\n            /// <summary>\n            ///     The skillshot range in units.\n            /// </summary>\n            public float Range = float.MaxValue;\n            /// <summary>\n            ///     The skillshot speed in units per second.\n            /// </summary>\n            public float Speed = float.MaxValue;\n            /// <summary>\n            ///     The skillshot type.\n            /// </summary>\n            public SkillshotType Type = SkillshotType.SkillshotLine;\n            /// <summary>\n            ///     The unit that the prediction will made for.\n            /// </summary>\n            public Obj_AI_Base Unit = ObjectManager.Player;\n            /// <summary>\n            ///     Set to true to increase the prediction radius by the unit bounding radius.\n            /// </summary>\n            public bool UseBoundingRadius = true;\n            /// <summary>\n            ///     The position from where the skillshot missile gets fired.\n            /// </summary>\n            public Vector3 From\n            {\n                get { return _from.To2D().IsValid() ? _from : ObjectManager.Player.ServerPosition; }\n                set { _from = value; }\n            }\n            /// <summary>\n            ///     The position from where the range is checked.\n            /// </summary>\n            public Vector3 RangeCheckFrom\n            {\n                get\n                {\n                    return _rangeCheckFrom.To2D().IsValid()\n                        ? _rangeCheckFrom\n                        : (From.To2D().IsValid() ? From : ObjectManager.Player.ServerPosition);\n                }\n                set { _rangeCheckFrom = value; }\n            }\n            internal float RealRadius\n            {\n                get { return  Radius; }\n            }\n        }\n        public class PredictionOutput\n        {\n            internal int _aoeTargetsHitCount;\n            private Vector3 _castPosition;\n            private Vector3 _unitPosition;\n            /// <summary>\n            ///     The list of the targets that the spell will hit (only if aoe was enabled).\n            /// </summary>\n            public List<AIHeroClient> AoeTargetsHit = new List<AIHeroClient>();\n            /// <summary>\n            ///     The list of the units that the skillshot will collide with.\n            /// </summary>\n            public List<Obj_AI_Base> CollisionObjects = new List<Obj_AI_Base>();\n            /// <summary>\n            ///     Returns the hitchance.\n            /// </summary>\n            public HitChance Hitchance = HitChance.Impossible;\n            internal PredictionInput Input;\n            /// <summary>\n            ///     The position where the skillshot should be casted to increase the accuracy.\n            /// </summary>\n            public Vector3 CastPosition\n            {\n                get\n                {\n                    return _castPosition.IsValid() && _castPosition.To2D().IsValid()\n                        ? _castPosition.SetZ()\n                        : Input.Unit.ServerPosition;\n                }\n                set { _castPosition = value; }\n            }\n            /// <summary>\n            ///     The number of targets the skillshot will hit (only if aoe was enabled).\n            /// </summary>\n            //public int AoeTargetsHitCount\n            //{\n            //    get { return Math.Max(_aoeTargetsHitCount, AoeTargetsHit.Count); }\n            //}\n            /// <summary>\n            ///     The position where the unit is going to be when the skillshot reaches his position.\n            /// </summary>\n            public Vector3 UnitPosition\n            {\n                get { return _unitPosition.To2D().IsValid() ? _unitPosition.SetZ() : Input.Unit.ServerPosition; }\n                set { _unitPosition = value; }\n            }\n        }\n        //public static bool BadaoCast2(this Spell spell, Obj_AI_Base target)\n        //{\n        //    var prediction = spell.GetBadao2Prediction(target);\n        //    if (!spell.IsSkillshot)\n        //        return false;\n        //    //if (prediction.Hitchance < spell.MinHitChance)\n        //    //    return false;\n        //    return ObjectManager.Player.Spellbook.CastSpell(spell.Slot, prediction);\n        //}\n        //public static Vector3 GetBadao2Prediction(this Spell spell, Obj_AI_Base target)\n        //{\n        //    Vector3 chuot = Prediction.GetPrediction(target, 1).UnitPosition;\n        //    float dis = spell.From.Distance(target.Position);\n        //    float rad = target.BoundingRadius + spell.Width - 50;\n        //    double x = math.t(target.MoveSpeed, spell.Speed, dis, spell.Delay + Game.Ping / 2 / 1000, rad, spell.From.To2D(), target.Position.To2D(), chuot.To2D());\n        //    if (x != 0 && !target.IsDashing()) { return target.Position.Extend(chuot, (float)x * target.MoveSpeed - rad); }\n        //    else return target.Position;\n        //}\n        public static bool BadaoCast(this Spell spell, Obj_AI_Base target)\n        {\n            var prediction = spell.GetBadaoPrediction(target);\n            if (!spell.IsSkillshot)\n                return false;\n            if (prediction.Hitchance < spell.MinHitChance)\n                return false;\n            return ObjectManager.Player.Spellbook.CastSpell(spell.Slot, prediction.CastPosition);\n        }\n        public static PredictionOutput GetBadaoPrediction(this Spell spell, Obj_AI_Base target, bool collideyasuowall = true)\n        {\n            PredictionOutput result = null;\n            if (!target.IsValidTarget(float.MaxValue, false))\n            {\n                return new PredictionOutput();\n            }\n            if (target.IsDashing())\n            {\n                var dashDtata = target.GetDashInfo();\n                result = spell.GetBadaoStandarPrediction(target,\n                    new List<Vector2>() {target.ServerPosition.To2D(), dashDtata.Path.Last()},dashDtata.Speed);\n                if (result.Hitchance >= HitChance.High)\n                    result.Hitchance = HitChance.Dashing;\n            }\n            else\n            {\n                //Unit is immobile.\n                var remainingImmobileT = UnitIsImmobileUntil(target);\n                if (remainingImmobileT >= 0d)\n                {\n                    var timeToReachTargetPosition = spell.Delay + target.Position.To2D().Distance(spell.From.To2D()) / spell.Speed;\n                    if (spell.RangeCheckFrom.To2D().Distance(target.Position.To2D()) <= spell.Range)\n                    {\n                        if (timeToReachTargetPosition <=\n                            remainingImmobileT + (target.BoundingRadius + spell.Width - 40)/target.MoveSpeed)\n                        {\n                            result = new PredictionOutput\n                            {\n                                CastPosition = target.ServerPosition,\n                                UnitPosition = target.ServerPosition,\n                                Hitchance = HitChance.Immobile\n                            };\n                        }\n                        else result =  new PredictionOutput\n                        {\n                            CastPosition = target.ServerPosition,\n                            UnitPosition = target.ServerPosition,\n                            Hitchance = HitChance.High\n                            /*timeToReachTargetPosition - remainingImmobileT + input.RealRadius / input.Unit.MoveSpeed < 0.4d ? HitChance.High : HitChance.Medium*/\n                        };\n                    }\n                    else\n                    {\n                       result = new PredictionOutput();\n                    }\n                }\n            }\n            //Normal prediction\n            if (result == null)\n            {\n                result = spell.GetBadaoStandarPrediction(target,target.Path.ToList().To2D());\n            }\n            //Check for collision\n            if (spell.Collision)\n            {\n                var positions = new List<Vector3> { result.UnitPosition, result.CastPosition, target.Position };\n                var originalUnit = target;\n                result.CollisionObjects = spell.GetCollision(positions);\n                result.CollisionObjects.RemoveAll(x => x.NetworkId == originalUnit.NetworkId);\n                result.Hitchance = result.CollisionObjects.Count > 0 ? HitChance.Collision : result.Hitchance;\n            }\n            //Check yasuo wall collision\n            else if (collideyasuowall)\n            {\n                var positions = new List<Vector3> { result.UnitPosition, result.CastPosition, target.Position };\n                var originalUnit = target;\n                result.CollisionObjects = spell.GetCollision(positions);\n                result.CollisionObjects.Any(x => x.NetworkId == ObjectManager.Player.NetworkId);\n                result.Hitchance = result.CollisionObjects.Any(x => x.NetworkId == ObjectManager.Player.NetworkId) ? HitChance.Collision : result.Hitchance;\n            }\n            return result;\n        }\n        public static PredictionOutput GetBadaoStandarPrediction(this Spell spell, Obj_AI_Base target,\n            List<Vector2> path, float speed = -1)\n        {\n            // check the unit speed input\n            speed = (Math.Abs(speed - (-1)) < float.Epsilon) ? target.MoveSpeed : speed;\n            // set standar output\n            Vector2 castpos = target.ServerPosition.To2D();\n            Vector2 unitpos = target.ServerPosition.To2D();\n            HitChance hitchance = HitChance.Impossible;\n            // target standing like a statue (performing an attack, casting spell, afk, aimbush.....)\n            if (path.Count <= 1)\n            {\n                // set standar position\n                castpos = target.ServerPosition.To2D();\n                unitpos = target.ServerPosition.To2D();\n                // target in range\n                if (spell.RangeCheckFrom.To2D().Distance(castpos) <= spell.Range)\n                    hitchance = HitChance.High;\n                // target out of range\n                else\n                {\n                    // skill shot circle\n                    if (spell.Type == SkillshotType.SkillshotCircle)\n                    {\n                        // check for extra radius\n                        if (spell.RangeCheckFrom.To2D().Distance(castpos) <=\n                            spell.Range + spell.Width + target.BoundingRadius - 40)\n                        {\n                            castpos = spell.RangeCheckFrom.To2D().Extend(castpos, spell.Range);\n                            hitchance = HitChance.Medium;\n                        }\n                        else\n                        {\n                            castpos = spell.RangeCheckFrom.To2D().Extend(castpos, spell.Range);\n                            hitchance = HitChance.OutOfRange;\n                        }\n                    }\n                    else\n                        hitchance = HitChance.OutOfRange;\n                }\n                return new PredictionOutput()\n                {\n                    UnitPosition = unitpos.To3D(),\n                    CastPosition = castpos.To3D(),\n                    Hitchance = hitchance\n                };\n            }\n            //Skillshots with only a delay\n            if (Math.Abs(spell.Speed - float.MaxValue) < float.Epsilon && path.Count >= 2)\n            {\n                var a = path[0];\n                var b = path[1];\n                var distance = a.Distance(b);\n                // skillshot circle\n                if (spell.Type == SkillshotType.SkillshotCircle)\n                {\n                    //standar distance\n                    var x = speed*(spell.Delay + Game.Ping/2000f + 0.06f);\n                    // position 1 properties\n                    var distance01 = x - (target.BoundingRadius + spell.Width)/2;\n                    var pos01 = a.Extend(b, distance01);\n                    // position 2 properties\n                    var distance02 = x;\n                    var pos02 = a.Extend(b, distance02);\n                    // position 3 properties\n                    var distance03 = x + (target.BoundingRadius + spell.Width)/2;\n                    var pos03 = pos02.Extend(spell.From.To2D(), distance03);\n                    // lines length\n                    var length01 = pos01.Distance(pos02);\n                    var length02 = pos02.Distance(pos03);\n                    // set standar position\n                    unitpos = pos02;\n                    castpos = pos02;\n                    // list cast poses\n                    List<Vector2> poses = new List<Vector2>();\n                    for (int i = 0; i <= 10; i++)\n                    {\n                        poses.Add(i <= 5 ? pos01.Extend(pos02, i*length01/6) : pos02.Extend(pos03, (i - 5)*length02/5));\n                    }\n                    // check cast pos\n                    for (int i = 0; i <= 10; i++)\n                    {\n                        if (poses[i].Distance(spell.RangeCheckFrom.To2D()) <= spell.Range &&\n                            poses[i].Distance(a) <= distance)\n                        {\n                            if (i <= 3)\n                            {\n                                hitchance = HitChance.VeryHigh;\n                            }\n                            else if (i <= 6)\n                            {\n                                hitchance = HitChance.High;\n                            }\n                            else\n                                hitchance = HitChance.Medium;\n                            return new PredictionOutput\n                            {\n                                UnitPosition = unitpos.To3D(),\n                                CastPosition = poses[i].To3D(),\n                                Hitchance = hitchance\n                            };\n                        }\n                    }\n                    // hitchance out of range\n                    return new PredictionOutput\n                    {\n                        UnitPosition = unitpos.To3D(),\n                        CastPosition = castpos.To3D(),\n                        Hitchance = HitChance.OutOfRange\n                    };\n                }\n                // skill shot line and cone\n                else\n                {\n                    //standar distance\n                    var x = speed*(spell.Delay + Game.Ping/2000f + 0.06f);\n                    // position properties\n                    var distance01 = x;\n                    var pos01 = a.Extend(b, distance01);\n                    var range01 = spell.RangeCheckFrom.To2D().Distance(pos01);\n                    // set standar position\n                    unitpos = pos01;\n                    castpos = pos01;\n                    // hitchance high\n                    if (distance01 < distance && range01 <= spell.Range)\n                    {\n                        castpos = pos01;\n                        hitchance = HitChance.High;\n                        return new PredictionOutput\n                        {\n                            UnitPosition = unitpos.To3D(),\n                            CastPosition = castpos.To3D(),\n                            Hitchance = hitchance\n                        };\n                    }\n                    // hitchance out of range\n                    return new PredictionOutput\n                    {\n                        UnitPosition = unitpos.To3D(),\n                        CastPosition = castpos.To3D(),\n                        Hitchance = HitChance.OutOfRange\n                    };\n                }\n            }\n            //  skill shot with a delay and speed\n            if (Math.Abs(spell.Speed - float.MaxValue) > float.Epsilon)\n            {\n                var a = path[0];\n                var b = path[1];\n                var distance = a.Distance(b);\n                // standar prediction\n                float dis = spell.From.To2D().Distance(a);\n                float rad = 0;\n                double time = math.t(speed, spell.Speed, dis, spell.Delay + Game.Ping/2f/1000 + 0.06f,\n                    0, spell.From.To2D(), a, b);\n                var unitpos02 = !double.IsNaN(time) ? a.Extend(b, (float) time*speed) : new Vector2();\n                var castpos02 = unitpos02;\n                // very high prediction\n                rad = (target.BoundingRadius + spell.Width)/2;\n                time = math.t(target.MoveSpeed, spell.Speed, dis, spell.Delay + Game.Ping/2f/1000 + 0.06f,\n                    rad, spell.From.To2D(), a, b);\n                var unitpos01 = !double.IsNaN(time) ? a.Extend(b, (float) time*speed- rad) : new Vector2();\n                var castpos01 = unitpos01;\n                // medium prediction\n                time = math.t(target.MoveSpeed, spell.Speed, dis, spell.Delay + Game.Ping/2f/1000 + 0.06f -rad/spell.Speed,\n                    0, spell.From.To2D(), a, b);\n                var unitpos03 = !double.IsNaN(time) ? a.Extend(b, (float) time*speed) : new Vector2();\n                var castpos03 = unitpos03.IsValid()\n                    ? spell.From.To2D().Extend(unitpos03, spell.From.To2D().Distance(unitpos03) - rad)\n                    : new Vector2();\n                if (castpos01.IsValid() && castpos02.IsValid() && castpos03.IsValid())\n                {\n                    var length01 = castpos01.Distance(castpos02);\n                    var length02 = castpos02.Distance(castpos03);\n                    var Acosb =\n                        Math.Acos(\n                            Math.Abs(float.IsNaN(math.CosB(spell.From.To2D(), a, b))\n                                ? 0.99f\n                                : Math.Abs(math.CosB(spell.From.To2D(), a, b))))*(180/Math.PI);\n                    // skillshot circle + line\n                    if (spell.Type == SkillshotType.SkillshotCircle ||\n                        (spell.Type == SkillshotType.SkillshotLine && Acosb <= 110 && Acosb >= 70))\n                    {\n                        List<Vector2> poses = new List<Vector2>();\n                        for (int i = 0; i <= 10; i++)\n                        {\n                            poses.Add(i <= 5\n                                ? castpos01.Extend(castpos02, i*length01/6)\n                                : castpos02.Extend(castpos03, (i - 5)*length02/5));\n                        }\n                        // check cast pos\n                        for (int i = 0; i <= 10; i++)\n                        {\n                            if (poses[i].Distance(spell.RangeCheckFrom.To2D()) <= spell.Range &&\n                                poses[i].Distance(a) <= distance)\n                            {\n                                if (i <= 3)\n                                {\n                                    hitchance = HitChance.VeryHigh;\n                                }\n                                else if (i <= 6)\n                                {\n                                    hitchance = HitChance.High;\n                                }\n                                else\n                                    hitchance = HitChance.Medium;\n                                return new PredictionOutput\n                                {\n                                    UnitPosition = unitpos02.To3D(),\n                                    CastPosition = poses[i].To3D(),\n                                    Hitchance = hitchance\n                                };\n                            }\n                        }\n                        // hitchance out of range\n                        return new PredictionOutput\n                        {\n                            UnitPosition = unitpos02.To3D(),\n                            CastPosition = castpos02.To3D(),\n                            Hitchance = HitChance.OutOfRange\n                        };\n                    }\n                    // skillshot line + cone\n                    else\n                    {\n                        var distance02 = a.Distance(castpos02);\n                        var range01 = spell.RangeCheckFrom.To2D().Distance(castpos02);\n                        // hitchance high\n                        if (distance02 < distance && range01 <= spell.Range)\n                        {\n                            return new PredictionOutput\n                            {\n                                UnitPosition = unitpos02.To3D(),\n                                CastPosition = castpos02.To3D(),\n                                Hitchance = HitChance.High\n                            };\n                        }\n                        // hitchance out of range\n                        return new PredictionOutput\n                        {\n                            UnitPosition = unitpos02.To3D(),\n                            CastPosition = castpos02.To3D(),\n                            Hitchance = HitChance.OutOfRange\n                        };\n                    }\n                }\n            }\n            return new PredictionOutput\n            {\n                UnitPosition = unitpos.To3D(),\n                CastPosition = castpos.To3D(),\n                Hitchance = hitchance\n            };\n        }\n        internal static double UnitIsImmobileUntil(Obj_AI_Base unit)\n        {\n            var result =\n                unit.Buffs.Where(\n                    buff =>\n                        buff.IsActive && Game.Time <= buff.EndTime &&\n                        (buff.Type == BuffType.Charm || buff.Type == BuffType.Knockup || buff.Type == BuffType.Stun ||\n                         buff.Type == BuffType.Suppression || buff.Type == BuffType.Snare))\n                    .Aggregate(0d, (current, buff) => Math.Max(current, buff.EndTime));\n            return (result - Game.Time);\n        }\n        public static List<Obj_AI_Base> GetCollision(this Spell spell, List<Vector3> positions)\n        {\n            var objects = new List<CollisionableObjects>(){CollisionableObjects.YasuoWall,CollisionableObjects.Minions, CollisionableObjects.Heroes};\n            var result = new List<Obj_AI_Base>();\n            foreach (var position in positions)\n            {\n                foreach (var objectType in objects)\n                {\n                    switch (objectType)\n                    {\n                        case CollisionableObjects.Minions:\n                            foreach (var minion in\n                                ObjectManager.Get<Obj_AI_Minion>()\n                                    .Where(\n                                        minion =>\n                                            minion.IsValidTarget(\n                                                Math.Min(spell.Range + spell.Width + 100, 2000), true,\n                                                spell.RangeCheckFrom)))\n                            {\n                                var target = minion;\n                                var minionPrediction = spell.GetBadaoStandarPrediction(target,target.Path.ToList().To2D());\n                                if (\n                                    minionPrediction.UnitPosition.To2D()\n", "outputs": ["                                        .Distance(spell.From.To2D(), position.To2D(), true, true) <="], "input_length": 3028, "output_length": 16, "length": 3044, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "4cef8ebbd53b781320c27759d0a076ef8c6cf20cc3cb50ae4569eaad90a883ed"}
{"input": "", "context": "/*\n * SLD Editor - The Open Source Java SLD Editor\n *\n * Copyright (C) 2016, SCISYS UK Limited\n *\n * This program is free software: you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation, either version 3 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program.  If not, see <http://www.gnu.org/licenses/>.\n */\npackage com.sldeditor.extension.filesystem.database;\nimport com.sldeditor.common.data.DatabaseConnection;\nimport com.sldeditor.common.filesystem.FileSystemInterface;\nimport com.sldeditor.datasource.extension.filesystem.node.FSTree;\nimport com.sldeditor.datasource.extension.filesystem.node.FileSystemNodeManager;\nimport com.sldeditor.datasource.extension.filesystem.node.database.DatabaseFeatureClassNode;\nimport com.sldeditor.datasource.extension.filesystem.node.database.DatabaseNode;\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\nimport javax.swing.tree.DefaultMutableTreeNode;\nimport javax.swing.tree.DefaultTreeModel;\n/**\n * Class that handles the progress of reading databases for data sources.\n *\n * @author Robert Ward (SCISYS)\n */\npublic class DatabaseReadProgress implements DatabaseReadProgressInterface {\n    /** Internal class to handle the state of the operation. */\n    class PopulateState {\n        /** The feature class complete flag. */\n        private boolean featureClassComplete = false;\n        /** Instantiates a new populate state. */\n        PopulateState() {\n            startFeatureClasses();\n        }\n        /** Sets the styles complete. */\n        public void setFeatureClassesComplete() {\n            featureClassComplete = true;\n        }\n        /**\n         * Checks if is complete.\n         *\n         * @return true, if is complete\n         */\n        public boolean isComplete() {\n            return featureClassComplete;\n        }\n        /** Start feature classes. */\n        public void startFeatureClasses() {\n            featureClassComplete = false;\n        }\n    }\n    /** The Constant PROGRESS_NODE_TITLE. */\n    private static final String PROGRESS_NODE_TITLE = \"Progress\";\n    /** The tree model. */\n    private DefaultTreeModel treeModel;\n    /** The tree. */\n    private FSTree tree = null;\n    /** The node map. */\n    private Map<DatabaseConnection, DatabaseNode> nodeMap = new HashMap<>();\n    /** The populate state map. */\n    private Map<DatabaseConnection, PopulateState> populateStateMap = new HashMap<>();\n    /** The feature class map. */\n    private Map<DatabaseConnection, List<String>> databaseFeatureClassMap = new HashMap<>();\n    /** The handler. */\n    private FileSystemInterface handler = null;\n    /** The parse complete. */\n    private DatabaseParseCompleteInterface parseComplete = null;\n    /**\n     * Instantiates a new geo server read progress.\n     *\n     * @param handler the handler\n     * @param parseComplete the parse complete\n     */\n    public DatabaseReadProgress(\n            FileSystemInterface handler, DatabaseParseCompleteInterface parseComplete) {\n        this.handler = handler;\n        this.parseComplete = parseComplete;\n    }\n    /**\n     * Read feature classes complete.\n     *\n     * @param connection the connection\n     * @param featureClassList the feature class list\n     */\n    public void readFeatureClassesComplete(\n            DatabaseConnection connection, List<String> featureClassList) {\n        if (featureClassList == null) {\n            return;\n        }\n        this.databaseFeatureClassMap.put(connection, featureClassList);\n        // Update state\n        PopulateState state = populateStateMap.get(connection);\n        if (state != null) {\n            state.setFeatureClassesComplete();\n        }\n        checkPopulateComplete(connection);\n    }\n    /**\n     * Check populate complete.\n     *\n     * @param connection the connection\n     */\n    private void checkPopulateComplete(DatabaseConnection connection) {\n        PopulateState state = populateStateMap.get(connection);\n        if ((state != null) && state.isComplete()) {\n            DatabaseNode databaseNode = nodeMap.get(connection);\n            if (databaseNode != null) {\n                removeNode(databaseNode, PROGRESS_NODE_TITLE);\n                populateFeatureClasses(connection, databaseNode);\n                if (treeModel != null) {\n                    // this notifies the listeners and changes the GUI\n                    treeModel.reload(databaseNode);\n                }\n            }\n            parseComplete.populateComplete(connection, databaseFeatureClassMap.get(connection));\n        }\n    }\n    /**\n     * Populate feature classes.\n     *\n     * @param connection the connection\n     * @param databaseNode the database node\n     */\n    private void populateFeatureClasses(DatabaseConnection connection, DatabaseNode databaseNode) {\n        List<String> featureClassList = databaseFeatureClassMap.get(connection);\n        for (String featureClass : featureClassList) {\n            DatabaseFeatureClassNode fcNode =\n                    new DatabaseFeatureClassNode(this.handler, connection, featureClass);\n            // It is key to invoke this on the TreeModel, and NOT DefaultMutableTreeNode\n            treeModel.insertNodeInto(fcNode, databaseNode, databaseNode.getChildCount());\n        }\n    }\n    /**\n     * Removes the node.\n     *\n     * @param databaseNode the database node\n     * @param nodeTitleToRemove the node title to remove\n     */\n    public static void removeNode(DatabaseNode databaseNode, String nodeTitleToRemove) {\n        if ((databaseNode != null) && (nodeTitleToRemove != null)) {\n            for (int index = 0; index < databaseNode.getChildCount(); index++) {\n                DefaultMutableTreeNode node =\n                        (DefaultMutableTreeNode) databaseNode.getChildAt(index);\n                String nodeName = (String) node.getUserObject();\n                if ((nodeName != null) && nodeName.startsWith(nodeTitleToRemove)) {\n                    databaseNode.remove(index);\n                    break;\n                }\n            }\n        }\n    }\n    /*\n     * (non-Javadoc)\n     *\n     * @see\n     * com.sldeditor.extension.filesystem.database.DatabaseReadProgressInterface#startPopulating(com\n     * .sldeditor.common.data.DatabaseConnection)\n     */\n    @Override\n    public void startPopulating(DatabaseConnection connection) {\n        PopulateState state = populateStateMap.get(connection);\n        if (state != null) {\n            state.startFeatureClasses();\n        }\n    }\n    /**\n     * Disconnect.\n     *\n     * @param connection the node\n     */\n    public void disconnect(DatabaseConnection connection) {\n        DatabaseNode node = nodeMap.get(connection);\n        node.removeAllChildren();\n        if (treeModel != null) {\n            treeModel.reload(node);\n        }\n    }\n    /**\n     * Sets the tree model.\n     *\n     * @param tree the tree\n     * @param model the model\n     */\n    public void setTreeModel(FSTree tree, DefaultTreeModel model) {\n        this.tree = tree;\n        this.treeModel = model;\n    }\n    /**\n     * Adds the new connection node.\n     *\n     * @param connection the connection\n     * @param node the node\n     */\n    public void addNewConnectionNode(DatabaseConnection connection, DatabaseNode node) {\n        nodeMap.put(connection, node);\n        populateStateMap.put(connection, new PopulateState());\n    }\n    /**\n     * Refresh node.\n     *\n     * @param nodeToRefresh the node to refresh\n     */\n    public void refreshNode(DefaultMutableTreeNode nodeToRefresh) {\n        if (treeModel != null) {\n            treeModel.reload(nodeToRefresh);\n        }\n    }\n    /**\n     * Delete connection.\n     *\n     * @param connection the connection\n     */\n    public void deleteConnection(DatabaseConnection connection) {\n        DatabaseNode node = nodeMap.get(connection);\n        if (treeModel != null) {\n            treeModel.removeNodeFromParent(node);\n        }\n        nodeMap.remove(connection);\n    }\n    /**\n     * Update connection.\n     *\n     * @param originalConnectionDetails the original connection details\n     * @param newConnectionDetails the new connection details\n     */\n    public void updateConnection(\n            DatabaseConnection originalConnectionDetails, DatabaseConnection newConnectionDetails) {\n        if (newConnectionDetails != null) {\n            DatabaseNode databaseNode = nodeMap.get(originalConnectionDetails);\n            originalConnectionDetails.update(newConnectionDetails);\n            if (databaseNode != null) {\n                databaseNode.setUserObject(newConnectionDetails.getConnectionName());\n                refreshNode(databaseNode);\n                setFolder(newConnectionDetails.getDatabaseTypeLabel(), newConnectionDetails, false);\n            }\n        }\n    }\n    /**\n     * Sets the folder.\n     *\n     * @param overallNodeName the overall node name\n     * @param connectionData the connection data\n     * @param disableTreeSelection the disable tree selection\n     */\n    public void setFolder(\n            String overallNodeName,\n            DatabaseConnection connectionData,\n            boolean disableTreeSelection) {\n        if (tree != null) {\n", "outputs": ["            if (disableTreeSelection) {"], "input_length": 1410, "output_length": 5, "length": 1415, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "f8190dcb070f959b2e3a23fdaed9c54988bc87f575a485939495250eed0abe6b"}
{"input": "", "context": "##\n## This file is part of the libsigrokdecode project.\n##\n## Copyright (C) 2012-2014 Uwe Hermann <uwe@hermann-uwe.de>\n##\n## This program is free software; you can redistribute it and/or modify\n## it under the terms of the GNU General Public License as published by\n## the Free Software Foundation; either version 2 of the License, or\n## (at your option) any later version.\n##\n## This program is distributed in the hope that it will be useful,\n## but WITHOUT ANY WARRANTY; without even the implied warranty of\n## MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n## GNU General Public License for more details.\n##\n## You should have received a copy of the GNU General Public License\n## along with this program; if not, write to the Free Software\n## Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA\n##\nimport sigrokdecode as srd\n# Normal commands (CMD)\ncmd_names = {\n    0:  'GO_IDLE_STATE',\n    1:  'SEND_OP_COND',\n    6:  'SWITCH_FUNC',\n    8:  'SEND_IF_COND',\n    9:  'SEND_CSD',\n    10: 'SEND_CID',\n    12: 'STOP_TRANSMISSION',\n    13: 'SEND_STATUS',\n    16: 'SET_BLOCKLEN',\n    17: 'READ_SINGLE_BLOCK',\n    18: 'READ_MULTIPLE_BLOCK',\n    24: 'WRITE_BLOCK',\n    25: 'WRITE_MULTIPLE_BLOCK',\n    27: 'PROGRAM_CSD',\n    28: 'SET_WRITE_PROT',\n    29: 'CLR_WRITE_PROT',\n    30: 'SEND_WRITE_PROT',\n    32: 'ERASE_WR_BLK_START_ADDR',\n    33: 'ERASE_WR_BLK_END_ADDR',\n    38: 'ERASE',\n    42: 'LOCK_UNLOCK',\n    55: 'APP_CMD',\n    56: 'GEN_CMD',\n    58: 'READ_OCR',\n    59: 'CRC_ON_OFF',\n    # CMD60-63: Reserved for manufacturer\n}\n# Application-specific commands (ACMD)\nacmd_names = {\n    13: 'SD_STATUS',\n    18: 'Reserved for SD security applications',\n    22: 'SEND_NUM_WR_BLOCKS',\n    23: 'SET_WR_BLK_ERASE_COUNT',\n    25: 'Reserved for SD security applications',\n    26: 'Reserved for SD security applications',\n    38: 'Reserved for SD security applications',\n    41: 'SD_SEND_OP_COND',\n    42: 'SET_CLR_CARD_DETECT',\n    43: 'Reserved for SD security applications',\n    44: 'Reserved for SD security applications',\n    45: 'Reserved for SD security applications',\n    46: 'Reserved for SD security applications',\n    47: 'Reserved for SD security applications',\n    48: 'Reserved for SD security applications',\n    49: 'Reserved for SD security applications',\n    51: 'SEND_SCR',\n}\nclass Decoder(srd.Decoder):\n    api_version = 2\n    id = 'sdcard_spi'\n    name = 'SD card (SPI mode)'\n    longname = 'Secure Digital card (SPI mode)'\n    desc = 'Secure Digital card (SPI mode) low-level protocol.'\n    license = 'gplv2+'\n    inputs = ['spi']\n    outputs = ['sdcard_spi']\n    annotations = \\\n        tuple(('cmd%d' % i, 'CMD%d' % i) for i in range(64)) + \\\n        tuple(('acmd%d' % i, 'ACMD%d' % i) for i in range(64)) + ( \\\n        ('r1', 'R1 reply'),\n        ('r1b', 'R1B reply'),\n        ('r2', 'R2 reply'),\n        ('r3', 'R3 reply'),\n        ('r7', 'R7 reply'),\n        ('bits', 'Bits'),\n        ('bit-warnings', 'Bit warnings'),\n    )\n    annotation_rows = (\n        ('bits', 'Bits', (134, 135)),\n        ('cmd-reply', 'Commands/replies', tuple(range(134))),\n    )\n    def __init__(self, **kwargs):\n        self.state = 'IDLE'\n        self.samplenum = 0\n        self.ss, self.es = 0, 0\n        self.bit_ss, self.bit_es = 0, 0\n        self.cmd_ss, self.cmd_es = 0, 0\n        self.cmd_token = []\n        self.cmd_token_bits = []\n        self.is_acmd = False # Indicates CMD vs. ACMD\n        self.blocklen = 0\n        self.read_buf = []\n        self.cmd_str = ''\n    def start(self):\n        self.out_ann = self.register(srd.OUTPUT_ANN)\n    def putx(self, data):\n        self.put(self.cmd_ss, self.cmd_es, self.out_ann, data)\n    def putc(self, cmd, desc):\n        self.putx([cmd, ['%s: %s' % (self.cmd_str, desc)]])\n    def putb(self, data):\n        self.put(self.bit_ss, self.bit_es, self.out_ann, data)\n    def cmd_name(self, cmd):\n        c = acmd_names if self.is_acmd else cmd_names\n        return c.get(cmd, 'Unknown')\n    def handle_command_token(self, mosi, miso):\n        # Command tokens (6 bytes) are sent (MSB-first) by the host.\n        #\n        # Format:\n        #  - CMD[47:47]: Start bit (always 0)\n        #  - CMD[46:46]: Transmitter bit (1 == host)\n        #  - CMD[45:40]: Command index (BCD; valid: 0-63)\n        #  - CMD[39:08]: Argument\n        #  - CMD[07:01]: CRC7\n        #  - CMD[00:00]: End bit (always 1)\n        if len(self.cmd_token) == 0:\n            self.cmd_ss = self.ss\n        self.cmd_token.append(mosi)\n        self.cmd_token_bits.append(self.mosi_bits)\n        # All command tokens are 6 bytes long.\n        if len(self.cmd_token) < 6:\n            return\n        self.cmd_es = self.es\n        t = self.cmd_token\n        # CMD or ACMD?\n        s = 'ACMD' if self.is_acmd else 'CMD'\n        def tb(byte, bit):\n            return self.cmd_token_bits[5 - byte][bit]\n        # Bits[47:47]: Start bit (always 0)\n        bit, self.bit_ss, self.bit_es = tb(5, 7)[0], tb(5, 7)[1], tb(5, 7)[2]\n        if bit == 0:\n            self.putb([134, ['Start bit: %d' % bit]])\n        else:\n            self.putb([135, ['Start bit: %s (Warning: Must be 0!)' % bit]])\n        # Bits[46:46]: Transmitter bit (1 == host)\n        bit, self.bit_ss, self.bit_es = tb(5, 6)[0], tb(5, 6)[1], tb(5, 6)[2]\n        if bit == 1:\n            self.putb([134, ['Transmitter bit: %d' % bit]])\n        else:\n            self.putb([135, ['Transmitter bit: %d (Warning: Must be 1!)' % bit]])\n        # Bits[45:40]: Command index (BCD; valid: 0-63)\n        cmd = self.cmd_index = t[0] & 0x3f\n        self.bit_ss, self.bit_es = tb(5, 5)[1], tb(5, 0)[2]\n        self.putb([134, ['Command: %s%d (%s)' % (s, cmd, self.cmd_name(cmd))]])\n        # Bits[39:8]: Argument\n        self.arg = (t[1] << 24) | (t[2] << 16) | (t[3] << 8) | t[4]\n        self.bit_ss, self.bit_es = tb(4, 7)[1], tb(1, 0)[2]\n        self.putb([134, ['Argument: 0x%04x' % self.arg]])\n        # Bits[7:1]: CRC7\n        # TODO: Check CRC7.\n        crc = t[5] >> 1\n        self.bit_ss, self.bit_es = tb(0, 7)[1], tb(0, 1)[2]\n        self.putb([134, ['CRC7: 0x%01x' % crc]])\n        # Bits[0:0]: End bit (always 1)\n        bit, self.bit_ss, self.bit_es = tb(0, 0)[0], tb(0, 0)[1], tb(0, 0)[2]\n        self.putb([134, ['End bit: %d' % bit]])\n        if bit == 1:\n            self.putb([134, ['End bit: %d' % bit]])\n        else:\n            self.putb([135, ['End bit: %d (Warning: Must be 1!)' % bit]])\n        # Handle command.\n        if cmd in (0, 1, 9, 16, 17, 41, 49, 55, 59):\n            self.state = 'HANDLE CMD%d' % cmd\n            self.cmd_str = '%s%d (%s)' % (s, cmd, self.cmd_name(cmd))\n        else:\n            self.state = 'HANDLE CMD999'\n            a = '%s%d: %02x %02x %02x %02x %02x %02x' % ((s, cmd) + tuple(t))\n            self.putx([cmd, [a]])\n    def handle_cmd0(self):\n        # CMD0: GO_IDLE_STATE\n        self.putc(0, 'Reset the SD card')\n        self.state = 'GET RESPONSE R1'\n    def handle_cmd1(self):\n        # CMD1: SEND_OP_COND\n        self.putc(1, 'Send HCS info and activate the card init process')\n        hcs = (self.arg & (1 << 30)) >> 30\n        self.bit_ss = self.cmd_token_bits[5 - 4][6][1]\n        self.bit_es = self.cmd_token_bits[5 - 4][6][2]\n        self.putb([134, ['HCS: %d' % hcs]])\n        self.state = 'GET RESPONSE R1'\n    def handle_cmd9(self):\n        # CMD9: SEND_CSD (128 bits / 16 bytes)\n        self.putc(9, 'Ask card to send its card specific data (CSD)')\n        if len(self.read_buf) == 0:\n            self.cmd_ss = self.ss\n        self.read_buf.append(self.miso)\n        # FIXME\n        ### if len(self.read_buf) < 16:\n        if len(self.read_buf) < 16 + 4:\n            return\n        self.cmd_es = self.es\n        self.read_buf = self.read_buf[4:] ### TODO: Document or redo.\n        self.putx([9, ['CSD: %s' % self.read_buf]])\n        # TODO: Decode all bits.\n        self.read_buf = []\n        ### self.state = 'GET RESPONSE R1'\n        self.state = 'IDLE'\n    def handle_cmd10(self):\n        # CMD10: SEND_CID (128 bits / 16 bytes)\n        self.putc(10, 'Ask card to send its card identification (CID)')\n        self.read_buf.append(self.miso)\n        if len(self.read_buf) < 16:\n            return\n        self.putx([10, ['CID: %s' % self.read_buf]])\n        # TODO: Decode all bits.\n        self.read_buf = []\n        self.state = 'GET RESPONSE R1'\n    def handle_cmd16(self):\n        # CMD16: SET_BLOCKLEN\n        self.blocklen = self.arg\n        # TODO: Sanity check on block length.\n        self.putc(16, 'Set the block length to %d bytes' % self.blocklen)\n        self.state = 'GET RESPONSE R1'\n    def handle_cmd17(self):\n        # CMD17: READ_SINGLE_BLOCK\n        self.putc(17, 'Read a block from address 0x%04x' % self.arg)\n        if len(self.read_buf) == 0:\n            self.cmd_ss = self.ss\n        self.read_buf.append(self.miso)\n        if len(self.read_buf) < self.blocklen + 2: # FIXME\n            return\n        self.cmd_es = self.es\n        self.read_buf = self.read_buf[2:] # FIXME\n        self.putx([17, ['Block data: %s' % self.read_buf]])\n        self.read_buf = []\n        self.state = 'GET RESPONSE R1'\n    def handle_cmd49(self):\n        self.state = 'GET RESPONSE R1'\n    def handle_cmd55(self):\n        # CMD55: APP_CMD\n        self.putc(55, 'Next command is an application-specific command')\n        self.is_acmd = True\n        self.state = 'GET RESPONSE R1'\n    def handle_cmd59(self):\n        # CMD59: CRC_ON_OFF\n        crc_on_off = self.arg & (1 << 0)\n        s = 'on' if crc_on_off == 1 else 'off'\n        self.putc(59, 'Turn the SD card CRC option %s' % s)\n        self.state = 'GET RESPONSE R1'\n    def handle_acmd41(self):\n        # ACMD41: SD_SEND_OP_COND\n        self.putc(64 + 41, 'Send HCS info and activate the card init process')\n        self.state = 'GET RESPONSE R1'\n    def handle_cmd999(self):\n        self.state = 'GET RESPONSE R1'\n    def handle_cid_register(self):\n        # Card Identification (CID) register, 128bits\n        cid = self.cid\n        # Manufacturer ID: CID[127:120] (8 bits)\n        mid = cid[15]\n        # OEM/Application ID: CID[119:104] (16 bits)\n        oid = (cid[14] << 8) | cid[13]\n        # Product name: CID[103:64] (40 bits)\n        pnm = 0\n        for i in range(12, 8 - 1, -1):\n            pnm <<= 8\n            pnm |= cid[i]\n        # Product revision: CID[63:56] (8 bits)\n        prv = cid[7]\n        # Product serial number: CID[55:24] (32 bits)\n        psn = 0\n        for i in range(6, 3 - 1, -1):\n            psn <<= 8\n            psn |= cid[i]\n        # RESERVED: CID[23:20] (4 bits)\n        # Manufacturing date: CID[19:8] (12 bits)\n        # TODO\n        # CRC7 checksum: CID[7:1] (7 bits)\n        # TODO\n        # Not used, always 1: CID[0:0] (1 bit)\n        # TODO\n    def handle_response_r1(self, res):\n        # The R1 response token format (1 byte).\n        # Sent by the card after every command except for SEND_STATUS.\n        self.cmd_ss, self.cmd_es = self.miso_bits[7][1], self.miso_bits[0][2]\n        self.putx([65, ['R1: 0x%02x' % res]])\n        def putbit(bit, data):\n            b = self.miso_bits[bit]\n            self.bit_ss, self.bit_es = b[1], b[2]\n            self.putb([134, data])\n        # Bit 0: 'In idle state' bit\n        s = '' if (res & (1 << 0)) else 'not '\n        putbit(0, ['Card is %sin idle state' % s])\n        # Bit 1: 'Erase reset' bit\n        s = '' if (res & (1 << 1)) else 'not '\n        putbit(1, ['Erase sequence %scleared' % s])\n        # Bit 2: 'Illegal command' bit\n        s = 'I' if (res & (1 << 2)) else 'No i'\n        putbit(2, ['%sllegal command detected' % s])\n        # Bit 3: 'Communication CRC error' bit\n        s = 'failed' if (res & (1 << 3)) else 'was successful'\n        putbit(3, ['CRC check of last command %s' % s])\n        # Bit 4: 'Erase sequence error' bit\n        s = 'E' if (res & (1 << 4)) else 'No e'\n        putbit(4, ['%srror in the sequence of erase commands' % s])\n        # Bit 5: 'Address error' bit\n        s = 'M' if (res & (1 << 4)) else 'No m'\n        putbit(5, ['%sisaligned address used in command' % s])\n        # Bit 6: 'Parameter error' bit\n        s = '' if (res & (1 << 4)) else 'not '\n        putbit(6, ['Command argument %soutside allowed range' % s])\n        # Bit 7: Always set to 0\n        putbit(7, ['Bit 7 (always 0)'])\n        self.state = 'IDLE'\n    def handle_response_r1b(self, res):\n        # TODO\n        pass\n    def handle_response_r2(self, res):\n        # TODO\n        pass\n    def handle_response_r3(self, res):\n        # TODO\n        pass\n    # Note: Response token formats R4 and R5 are reserved for SDIO.\n    # TODO: R6?\n    def handle_response_r7(self, res):\n        # TODO\n        pass\n    def decode(self, ss, es, data):\n        ptype, mosi, miso = data\n        # For now, only use DATA and BITS packets.\n        if ptype not in ('DATA', 'BITS'):\n            return\n        # Store the individual bit values and ss/es numbers. The next packet\n        # is guaranteed to be a 'DATA' packet belonging to this 'BITS' one.\n", "outputs": ["        if ptype == 'BITS':"], "input_length": 3039, "output_length": 6, "length": 3045, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "87a380ef52e7adeaed1e51ca9f8dc57cf54f89c56f5297cf6685507ca7b62333"}
{"input": "", "context": "/*******************************************************************************\n *     ___                  _   ____  ____\n *    / _ \\ _   _  ___  ___| |_|  _ \\| __ )\n *   | | | | | | |/ _ \\/ __| __| | | |  _ \\\n *   | |_| | |_| |  __/\\__ \\ |_| |_| | |_) |\n *    \\__\\_\\\\__,_|\\___||___/\\__|____/|____/\n *\n *  Copyright (c) 2014-2019 Appsicle\n *  Copyright (c) 2019-2022 QuestDB\n *\n *  Licensed under the Apache License, Version 2.0 (the \"License\");\n *  you may not use this file except in compliance with the License.\n *  You may obtain a copy of the License at\n *\n *  http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n ******************************************************************************/\npackage io.questdb.cutlass.text;\nimport io.questdb.cairo.ColumnType;\nimport io.questdb.cutlass.json.JsonException;\nimport io.questdb.cutlass.json.JsonLexer;\nimport io.questdb.cutlass.json.JsonParser;\nimport io.questdb.cutlass.text.types.TypeAdapter;\nimport io.questdb.cutlass.text.types.TypeManager;\nimport io.questdb.griffin.SqlKeywords;\nimport io.questdb.log.Log;\nimport io.questdb.log.LogFactory;\nimport io.questdb.std.*;\nimport io.questdb.std.datetime.DateLocale;\nimport io.questdb.std.datetime.DateLocaleFactory;\nimport io.questdb.std.datetime.microtime.TimestampFormatFactory;\nimport io.questdb.std.datetime.millitime.DateFormatFactory;\nimport io.questdb.std.str.AbstractCharSequence;\nimport java.io.Closeable;\npublic class TextMetadataParser implements JsonParser, Mutable, Closeable {\n    private static final Log LOG = LogFactory.getLog(TextMetadataParser.class);\n    private static final int S_NEED_ARRAY = 1;\n    private static final int S_NEED_OBJECT = 2;\n    private static final int S_NEED_PROPERTY = 3;\n    private static final int P_NAME = 1;\n    private static final int P_TYPE = 2;\n    private static final int P_PATTERN = 3;\n    private static final int P_LOCALE = 4;\n    private static final int P_UTF8 = 5;\n    private static final int P_INDEX = 6;\n    private static final CharSequenceIntHashMap propertyNameMap = new CharSequenceIntHashMap();\n    private final DateLocaleFactory dateLocaleFactory;\n    private final ObjectPool<FloatingCharSequence> csPool;\n    private final DateFormatFactory dateFormatFactory;\n    private final TimestampFormatFactory timestampFormatFactory;\n    private final ObjList<CharSequence> columnNames;\n    private final ObjList<TypeAdapter> columnTypes;\n    private final TypeManager typeManager;\n    private final DateLocale dateLocale;\n    private int state = S_NEED_ARRAY;\n    private CharSequence name;\n    private int type = -1;\n    private CharSequence pattern;\n    private CharSequence locale;\n    private int propertyIndex;\n    private long buf;\n    private long bufCapacity = 0;\n    private int bufSize = 0;\n    private CharSequence tableName;\n    private int localePosition;\n    private boolean utf8 = false;\n    private boolean index = false;\n    public TextMetadataParser(TextConfiguration textConfiguration, TypeManager typeManager) {\n        this.columnNames = new ObjList<>();\n        this.columnTypes = new ObjList<>();\n        this.csPool = new ObjectPool<>(FloatingCharSequence::new, textConfiguration.getMetadataStringPoolCapacity());\n        this.dateLocaleFactory = typeManager.getInputFormatConfiguration().getDateLocaleFactory();\n        this.dateFormatFactory = typeManager.getInputFormatConfiguration().getDateFormatFactory();\n        this.timestampFormatFactory = typeManager.getInputFormatConfiguration().getTimestampFormatFactory();\n        this.typeManager = typeManager;\n        this.dateLocale = textConfiguration.getDefaultDateLocale();\n    }\n    @Override\n    public void clear() {\n        bufSize = 0;\n        state = S_NEED_ARRAY;\n        columnNames.clear();\n        columnTypes.clear();\n        csPool.clear();\n        clearStage();\n    }\n    @Override\n    public void close() {\n        clear();\n        if (bufCapacity > 0) {\n            Unsafe.free(buf, bufCapacity, MemoryTag.NATIVE_DEFAULT);\n            bufCapacity = 0;\n        }\n    }\n    public ObjList<CharSequence> getColumnNames() {\n        return columnNames;\n    }\n    public ObjList<TypeAdapter> getColumnTypes() {\n        return columnTypes;\n    }\n    @Override\n    public void onEvent(int code, CharSequence tag, int position) throws JsonException {\n        switch (code) {\n            case JsonLexer.EVT_ARRAY_START:\n                if (state != S_NEED_ARRAY) {\n                    throw JsonException.$(position, \"Unexpected array\");\n                }\n                state = S_NEED_OBJECT;\n                break;\n            case JsonLexer.EVT_OBJ_START:\n                if (state != S_NEED_OBJECT) {\n                    throw JsonException.$(position, \"Unexpected object\");\n                }\n                state = S_NEED_PROPERTY;\n                break;\n            case JsonLexer.EVT_NAME:\n                this.propertyIndex = propertyNameMap.get(tag);\n                if (this.propertyIndex == -1) {\n                    LOG.info().$(\"unknown [table=\").$(tableName).$(\", tag=\").$(tag).$(']').$();\n                }\n                break;\n            case JsonLexer.EVT_VALUE:\n                switch (propertyIndex) {\n                    case P_NAME:\n                        name = copy(tag);\n                        break;\n                    case P_TYPE:\n                        type = ColumnType.tagOf(tag);\n                        if (type == -1) {\n                            throw JsonException.$(position, \"Invalid type\");\n                        }\n                        break;\n                    case P_PATTERN:\n                        pattern = copy(tag);\n                        break;\n                    case P_LOCALE:\n                        locale = copy(tag);\n                        localePosition = position;\n                        break;\n                    case P_UTF8:\n                        utf8 = SqlKeywords.isTrueKeyword(tag);\n                        break;\n                    case P_INDEX:\n                        index = SqlKeywords.isTrueKeyword(tag);\n                        break;\n                    default:\n                        LOG.info().$(\"ignoring [table=\").$(tableName).$(\", value=\").$(tag).$(']').$();\n                        break;\n                }\n                break;\n            case JsonLexer.EVT_OBJ_END:\n                state = S_NEED_OBJECT;\n                createImportedType(position);\n                break;\n            case JsonLexer.EVT_ARRAY_VALUE:\n                throw JsonException.$(position, \"Must be an object\");\n            default:\n                break;\n        }\n    }\n    private static void strcpyw(final CharSequence value, final int len, final long address) {\n        for (int i = 0; i < len; i++) {\n            Unsafe.getUnsafe().putChar(address + ((long) i << 1), value.charAt(i));\n        }\n    }\n    private static void checkInputs(int position, CharSequence name, int type) throws JsonException {\n        if (name == null) {\n            throw JsonException.$(position, \"Missing 'name' property\");\n        }\n        if (type == -1) {\n            throw JsonException.$(position, \"Missing 'type' property\");\n        }\n    }\n    private void clearStage() {\n        name = null;\n        type = -1;\n        pattern = null;\n        locale = null;\n        localePosition = 0;\n        utf8 = false;\n        index = false;\n    }\n    private CharSequence copy(CharSequence tag) {\n        final int l = tag.length() * 2;\n        final long n = bufSize + l;\n        if (n > bufCapacity) {\n            long ptr = Unsafe.malloc(n * 2, MemoryTag.NATIVE_DEFAULT);\n            Vect.memcpy(ptr, buf, bufSize);\n            if (bufCapacity > 0) {\n                Unsafe.free(buf, bufCapacity, MemoryTag.NATIVE_DEFAULT);\n            }\n            buf = ptr;\n            bufCapacity = n * 2;\n        }\n        strcpyw(tag, l / 2, buf + bufSize);\n        CharSequence cs = csPool.next().of(bufSize, l / 2);\n        bufSize += l;\n        return cs;\n    }\n    private void createImportedType(int position) throws JsonException {\n        checkInputs(position, name, type);\n        columnNames.add(name);\n        switch (ColumnType.tagOf(type)) {\n            case ColumnType.DATE:\n                DateLocale dateLocale = locale == null ? this.dateLocale : dateLocaleFactory.getLocale(locale);\n                if (dateLocale == null) {\n                    throw JsonException.$(localePosition, \"Invalid date locale\");\n                }\n                // date pattern is required\n                if (pattern == null) {\n                    throw JsonException.$(0, \"DATE format pattern is required\");\n                }\n                columnTypes.add(typeManager.nextDateAdapter().of(dateFormatFactory.get(pattern), dateLocale));\n                break;\n            case ColumnType.TIMESTAMP:\n                DateLocale timestampLocale =\n                        locale == null ?\n                                this.dateLocale\n                                : dateLocaleFactory.getLocale(locale);\n                if (timestampLocale == null) {\n                    throw JsonException.$(localePosition, \"Invalid timestamp locale\");\n                }\n                // timestamp pattern is required\n", "outputs": ["                if (pattern == null) {"], "input_length": 1545, "output_length": 7, "length": 1552, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "557ac03a8bbcca0be9aa5df21429561c7a4aba1fd564b601b40a09b4f4e0f46f"}
{"input": "", "context": "#!/usr/bin/env python3\nimport datetime, json, os, requests, rethinkdb, shutil, signal, socket, subprocess, time\nHOSTS = '/node/etc/hosts'\n# POD_NAMESPACE must be explicitly set in deployment yaml using downward api --\n# see https://github.com/kubernetes/kubernetes/blob/release-1.0/docs/user-guide/downward-api.md\nPOD_NAMESPACE = os.environ.get('POD_NAMESPACE', 'default')\ndef log(*args, **kwds):\n    print(time_to_timestamp(), *args, **kwds)\nalarm_time=0\ndef mysig(a,b):\n    raise KeyboardInterrupt\ndef alarm(seconds):\n    seconds = int(seconds)\n    signal.signal(signal.SIGALRM, mysig)\n    global alarm_time\n    alarm_time = seconds\n    signal.alarm(seconds)\ndef cancel_alarm():\n    signal.signal(signal.SIGALRM, signal.SIG_IGN)\ndef run(v, shell=False, path='.', get_output=False, env=None, verbose=True, timeout=20):\n    try:\n        alarm(timeout)\n        t = time.time()\n        if isinstance(v, str):\n            cmd = v\n            shell = True\n        else:\n            cmd = ' '.join([(x if len(x.split())<=1 else '\"%s\"'%x) for x in v])\n        if path != '.':\n            cur = os.path.abspath(os.curdir)\n            if verbose:\n                log('chdir %s'%path)\n            os.chdir(path)\n        try:\n            if verbose:\n                log(cmd)\n            if shell:\n                kwds = {'shell':True, 'executable':'/bin/bash', 'env':env}\n            else:\n                kwds = {'env':env}\n            if get_output:\n                output = subprocess.Popen(v, stdout=subprocess.PIPE, **kwds).stdout.read().decode()\n            else:\n                if subprocess.call(v, **kwds):\n                    raise RuntimeError(\"error running '{cmd}'\".format(cmd=cmd))\n                output = None\n            seconds = time.time() - t\n            if verbose:\n                log(\"TOTAL TIME: {seconds} seconds -- to run '{cmd}'\".format(seconds=seconds, cmd=cmd))\n            return output\n        finally:\n            if path != '.':\n                os.chdir(cur)\n    finally:\n        cancel_alarm()\ndef get_service(service):\n    \"\"\"\n    Get in json format the kubernetes information about the given service.\n    \"\"\"\n    if not os.environ['KUBERNETES_SERVICE_HOST']:\n        log('KUBERNETES_SERVICE_HOST environment variable not set')\n        return None\n    URL = \"https://{KUBERNETES_SERVICE_HOST}:{KUBERNETES_SERVICE_PORT}/api/v1/namespaces/{POD_NAMESPACE}/endpoints/{service}\"\n    URL = URL.format(KUBERNETES_SERVICE_HOST=os.environ['KUBERNETES_SERVICE_HOST'],\n                     KUBERNETES_SERVICE_PORT=os.environ['KUBERNETES_SERVICE_PORT'],\n                     POD_NAMESPACE=POD_NAMESPACE,\n                     service=service)\n    token = open('/var/run/secrets/kubernetes.io/serviceaccount/token').read()\n    headers={'Authorization':'Bearer {token}'.format(token=token)}\n    log(\"Getting k8s information about '{service}' from '{URL}'\".format(service=service, URL=URL))\n    x = requests.get(URL, headers=headers, verify='/var/run/secrets/kubernetes.io/serviceaccount/ca.crt').json()\n    log(\"Got {x}\".format(x=x))\n    return x\ndef update_etc_hosts():\n    log('udpate_etc_hosts')\n    try:\n        v = get_service('storage-projects')\n    except Exception as err:\n        # Expected to happen when node is starting up, etc. - we'll retry later soon!\n        log(\"Failed getting storage service info\", err)\n        return\n    if v.get('status', None) == 'Failure':\n        return\n    try:\n        if 'addresses' not in v['subsets'][0]:\n            return   # nothing to do; no known addresses\n        namespace = v['metadata']['namespace']\n        hosts = [\"{ip}    {namespace}-{name}\".format(ip=x['ip'], namespace=namespace,\n                              name=x['targetRef']['name'].split('-')[0]) for x in v['subsets'][0]['addresses']]\n        start = \"# start smc-storage dns - namespace=\"+namespace+\"\\n\\n\"\n        end = \"# end smc-storage dns - namespace=\"+namespace+\"\\n\\n\"\n        block = '\\n'.join([start] + hosts + [end])\n        current = open(HOSTS).read()\n        if block in current:\n            return\n        i = current.find(start)\n        j = current.find(end)\n        if i == -1 or j == -1:\n            new = current + '\\n' + block\n        else:\n            new = current[:i] + block + current[j+len(end):]\n        open(HOSTS,'w').write(new)\n    except Exception as err:\n        log(\"Problem in update_etc_hosts\", err)\nMINION_IP = 'unknown'\ndef enable_ssh_access_to_minion():\n    global MINION_IP\n    # create our own local ssh key\n    if os.path.exists('/root/.ssh'):\n        shutil.rmtree('/root/.ssh')\n    run(['ssh-keygen', '-b', '2048', '-N', '', '-f', '/root/.ssh/id_rsa'])\n    # make root user of minion allow login using this (and only this) key.\n    run('cat /root/.ssh/id_rsa.pub >> /node/root/.ssh/authorized_keys')\n    open(\"/root/.ssh/config\",'w').write(\"StrictHostKeyChecking no\\nUserKnownHostsFile=/dev/null\\n\")\n    # record hostname of minion\n    for x in open(\"/node/etc/hosts\").readlines():\n        if 'group' in x:\n            MINION_IP = x.split()[0]\n            open(\"/node/minion_ip\",'w').write(MINION_IP)\ndef minion_ip():\n    global MINION_IP\n    if MINION_IP == 'unknown':\n        if os.path.exists(\"/node/minion_ip\"):\n            MINION_IP = open(\"/node/minion_ip\").read()\n            return MINION_IP\n        else:\n            enable_ssh_access_to_minion()\n            if MINION_IP == 'unknown':\n                raise RuntimeError(\"first run enable_ssh_access_to_minion\")\n            else:\n                return MINION_IP\n    else:\n        return MINION_IP\ndef run_on_minion(v, *args, **kwds):\n    if isinstance(v, str):\n        v = \"ssh \" + minion_ip() + \" '%s'\"%v\n    else:\n        v = ['ssh', minion_ip() ] + v\n    return run(v, *args, **kwds)\ndef smc_storage(*args, **kwds):\n    return run_on_minion([\"/usr/libexec/kubernetes/kubelet-plugins/volume/exec/smc~smc-storage/smc-storage\"] + list(args), **kwds)\ndef install_flexvolume_plugin():\n    # we always copy it over, which at least upgrades it if necessary.\n    shutil.copyfile(\"/install/smc-storage\", \"/node/plugin/smc-storage\")\n    shutil.copymode(\"/install/smc-storage\", \"/node/plugin/smc-storage\")\ndef is_plugin_loaded():\n    try:\n        if int(run_on_minion(\"zgrep Loaded /var/log/kubelet*|grep smc-storage|wc -l\", get_output=True).strip()) > 0:\n            return True\n        else:\n            return False\n    except Exception as err:\n        log(err)\n        return False\ndef install_zfs():\n    try:\n        run_on_minion('zpool status')\n        log(\"OK: zfs is installed\")\n    except:\n        log(\"zfs not installed, so installing it\")\n        run(['scp', '-r', '/install/gke-zfs', minion_ip()+\":\"])\n        run_on_minion(\"cd /root/gke-zfs/3.16.0-4-amd64/ && ./install.sh\")\ndef install_bindfs():\n    try:\n        run_on_minion('which bindfs')\n        log(\"OK: bindfs is installed\")\n    except:\n        log(\"bindfs not installed, so installing it\")\n        run_on_minion([\"apt-get\", \"update\"])\n        run_on_minion([\"apt-get\", \"install\", \"-y\", \"bindfs\"])\ndef install_sshfs():\n    try:\n        run_on_minion('which sshfs')\n        log(\"OK: bindfs is installed\")\n    except:\n        log(\"bindfs not installed, so installing it\")\n        run_on_minion([\"apt-get\", \"update\"])\n        run_on_minion([\"apt-get\", \"install\", \"-y\", \"sshfs\"])\ndef install_ssh_keys():\n    # Copy the shared secret ssh keys to the minion so that it is able to sshfs\n    # mount the storage servers.\n    path = '/node/root/.ssh/smc-storage/{POD_NAMESPACE}'.format(POD_NAMESPACE = POD_NAMESPACE)\n    if not os.path.exists(path):\n        os.makedirs(path)\n    for x in ['id-rsa', 'id-rsa.pub']:\n        src = os.path.join('/ssh', x); target = os.path.join(path, x.replace('-', '_'))\n        shutil.copyfile(src, target)\n        os.chmod(target, 0o600)\ndef restart_kubelet():\n    run_on_minion(\"kill `pidof /usr/local/bin/kubelet`\")\nTIMESTAMP_FORMAT = \"%Y-%m-%d-%H%M%S\"      # e.g., 2016-06-27-141131\ndef time_to_timestamp(tm=None):\n    if tm is None:\n        tm = time.time()\n    return datetime.datetime.fromtimestamp(tm).strftime(TIMESTAMP_FORMAT)\ndef timestamp_to_rethinkdb(timestamp):\n    i = timestamp.rfind('-')\n    return rethinkdb.iso8601(timestamp[:i].replace('-','') + 'T' + timestamp[i+1:].replace(':','') + 'Z')\n# TODO: this entire approach is pointless and broken because when multiple processes\n# append to the same file, the result is broken corruption.\ndef update_zpool_active_log():\n    \"\"\"\n    Update log file showing which ZFS filesystems are mounted, which is used by the backup system.\n    \"\"\"\n    prefix = \"/mnt/smc-storage/{namespace}/\".format(namespace=POD_NAMESPACE)\n    try:\n        v = run_on_minion(\"zpool status -PL|grep {prefix}\".format(prefix=prefix),\n                          get_output=True).splitlines()\n    except:\n        # Nothing to do -- get error if no pools are mounted\n        return\n    for x in v:\n        w = x.split()\n        if w:\n            path = w[0].strip()           # '/mnt/smc-storage/test/storage0/foo/bar/abc.zfs/00.img'\n            path = path[len(prefix):]     # 'storage0/foo/bar/abc.zfs/00.img'\n            path = os.path.split(path)[0] # 'storage0/foo/bar/abc.zfs'\n            i = path.find('/')\n            server = path[:i]\n            image = path[i+1:]\n            log = \"{timestamp} {image}\".format(timestamp=time_to_timestamp(), image=image)\n            run_on_minion(\"echo '{log}' >> {prefix}/{server}/log/active.log\".format(\n                    log=log, prefix=prefix, server=server))\ndef update_all_snapshots():\n    v = json.loads(smc_storage(\"zpool-update-snapshots\", get_output=True))\n    db_set_last_snapshot(v['new_snapshots'])\nRETHINKDB_SECRET = '/secrets/rethinkdb/rethinkdb'\nimport rethinkdb\ndef rethinkdb_connection():\n    auth_key = open(RETHINKDB_SECRET).read().strip()\n    if not auth_key:\n        auth_key = None\n    return rethinkdb.connect(host='rethinkdb-driver', timeout=4, auth_key=auth_key)\ndef db_set_last_snapshot(new_snapshots):\n    \"\"\"\n    new_snapshots should be a dictionary with keys the project_id's and values timestamps.\n    This function will connect to the database if possible, and set the last_snapshot field of\n    each project (in the projects table) to the given timestamp.\n    \"\"\"\n    print(\"db_set_last_snapshot\", new_snapshots)\n    if len(new_snapshots) == 0:\n        return\n    # Open connection to the database\n    conn = rethinkdb_connection()\n    # Do the queries\n    for project_id, timestamp in new_snapshots.items():\n", "outputs": ["        last_snapshot = timestamp_to_rethinkdb(timestamp)"], "input_length": 2034, "output_length": 6, "length": 2040, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "d1f0ff917984da4e95b9a56e77c407e14e03bc432b7431d6195260f73a48754b"}
{"input": "", "context": "package gui;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport org.eclipse.jface.dialogs.MessageDialog;\nimport org.eclipse.jface.preference.BooleanFieldEditor;\nimport org.eclipse.jface.preference.FieldEditor;\nimport org.eclipse.jface.preference.FieldEditorPreferencePage;\nimport org.eclipse.jface.preference.IPreferenceStore;\nimport org.eclipse.jface.preference.IntegerFieldEditor;\nimport org.eclipse.jface.preference.PreferenceDialog;\nimport org.eclipse.jface.preference.PreferenceManager;\nimport org.eclipse.jface.preference.PreferenceNode;\nimport org.eclipse.jface.preference.PreferencePage;\nimport org.eclipse.jface.preference.PreferenceStore;\nimport org.eclipse.jface.util.IPropertyChangeListener;\nimport org.eclipse.jface.util.PropertyChangeEvent;\nimport org.eclipse.swt.SWT;\nimport org.eclipse.swt.graphics.Color;\nimport org.eclipse.swt.graphics.FontMetrics;\nimport org.eclipse.swt.graphics.GC;\nimport org.eclipse.swt.graphics.Image;\nimport org.eclipse.swt.graphics.RGB;\nimport org.eclipse.swt.layout.GridData;\nimport org.eclipse.swt.widgets.Composite;\nimport org.eclipse.swt.widgets.Display;\nimport org.eclipse.swt.widgets.Label;\nimport org.eclipse.swt.widgets.Shell;\nimport org.eclipse.swt.widgets.Text;\nimport util.PmTransException;\npublic class Config extends PreferenceStore {\n\tprivate static Config instance = null;\n\t/**\n\t * Non-configurable stuff\n\t */\n\t// Config file path\n\tprivate static String CONFIG_PATH = \"./config.properties\";\n\t// State file path\n\tpublic static String STATE_PATH = \"./state.transcriber\";\n\t// Icon paths\n\tpublic static String ICON_PATH_PLAY = \"/icon/start.png\";\n\tpublic static String ICON_PATH_PAUSE = \"/icon/pause.png\";\n\tpublic static String ICON_PATH_RESTART = \"/icon/restart.png\";\n\tpublic static String ICON_PATH_OPEN_TRANSCRIPTION = \"/icon/open.png\";\n\tpublic static String ICON_PATH_OPEN_AUDIO = \"/icon/openAudio.png\";\n\tpublic static String ICON_PATH_SAVE_TRANSCRIPTION = \"/icon/save.png\";\n\tpublic static String ICON_PATH_LOOP = \"/icon/loop.png\";\n\tpublic static String ICON_PATH_ZOOM_IN = \"/icon/zoom_in.png\";\n\tpublic static String ICON_PATH_ZOOM_OUT = \"/icon/zoom_out.png\";\n\tpublic static String ICON_PATH_COPY = \"/icon/copy.png\";\n\tpublic static String ICON_PATH_CUT = \"/icon/cut.png\";\n\tpublic static String ICON_PATH_PASTE = \"/icon/paste.png\";\n\tpublic static String ICON_PATH_CROSS = \"/icon/cross.png\";\n\tpublic static String ICON_PATH_ADVANCED_SEARCH = \"/icon/advancedSearch.png\";\n\tpublic static String ICON_PATH_CHANGE_BACKGROUND_COLOR = \"/icon/changeBackgroundColor.png\";\n\tpublic static String ICON_PATH_CHANGE_FONT_COLOR = \"/icon/changeFontColor.png\";\n\tpublic static String ICON_PATH_SETTINGS = \"/icon/settings.png\";\n\tpublic static String ICON_PATH_CONTRIBUTE = \"/icon/contribute.png\";\n\tpublic static String DEFAULT_ACCELERATORS = \"cxvfosa\";\n\t// Main shell initial dimensions\n\tprivate int SHELL_HEIGHT_DEFAULT = 600;\n\tprivate int SHELL_LENGHT_DEFAULT = 600;\n\tpublic static String SHELL_HEIGHT = \"window.height\";\n\tpublic static String SHELL_LENGHT = \"window.lenght\";\n\t// Last directory paths for file dialogs\n\tprivate String LAST_OPEN_AUDIO_PATH_DEFAULT = \"\";\n\tpublic static String LAST_OPEN_AUDIO_PATH = \"last.open.audio.path\";\n\tprivate String LAST_OPEN_TEXT_PATH_DEFAULT = \"\";\n\tpublic static String LAST_OPEN_TEXT_PATH = \"last.open.text.path\";\n\t// Last directory path for the export dialog\n\tprivate String LAST_EXPORT_TRANSCRIPTION_PATH_DEFALUT = \"\";\n\tpublic static String LAST_EXPORT_TRANSCRIPTION_PATH = \"last.export.transcription.path\";\n\t// URLs\n\tpublic static String CONTRIBUTE_URL = \"https://github.com/juanerasmoe/pmTrans/wiki/Contribute-to-pmTrans\";\n\t\n\t/**\n\t * Configurable stuff\n\t */\n\t// Duration of the short rewind in seconds\n\tprivate int SHORT_REWIND_DEFAULT = 5;\n\tpublic static String SHORT_REWIND = \"short.rewind.duration\";\n\t// Duration of the long rewind in seconds\n\tprivate int LONG_REWIND_DEFAULT = 10;\n\tpublic static String LONG_REWIND = \"long.rewind.duration\";\n\t// Duration of the rewind-and-play\n\tprivate static int REWIND_AND_PLAY_DEFAULT = 2;\n\tpublic static String REWIND_AND_PLAY = \"rewind.and.play.duration\";\n\t// Max size of the previous-files list\n\tprivate static int AUDIO_FILE_CACHE_LENGHT_DEFAULT = 7;\n\tpublic static String AUDIO_FILE_CACHE_LENGHT = \"audio.file.cache.lenght\";\n\tprivate static int TEXT_FILE_CACHE_LENGHT_DEFAULT = 7;\n\tpublic static String TEXT_FILE_CACHE_LENGHT = \"text.file.cache.lenght\";\n\tprivate static int SLOW_DOWN_PLAYBACK_DEFAULT = -5;\n\tpublic static String SLOW_DOWN_PLAYBACK = \"slow.down.playback\";\n\tprivate static int SPEED_UP_PLAYBACK_DEFAULT = 5;\n\tpublic static String SPEED_UP_PLAYBACK = \"speed.up.plaback\";\n\t// Auto save\n\tprivate static boolean AUTO_SAVE_DEFAULT = true;\n\tpublic static String AUTO_SAVE = \"auto.save\";\n\tprivate static int AUTO_SAVE_TIME_DEFAULT = 2;\n\tpublic static String AUTO_SAVE_TIME = \"auto.save.time\";\n\t// Mini-mode dialog\n\tprivate static boolean SHOW_MINI_MODE_DIALOG_DEFAULT = true;\n\tpublic static String SHOW_MINI_MODE_DIALOG = \"show.mini.mode.dialog\";\n\t// Font and size\n\tprivate static String FONT_DEFAULT = \"Courier New\";\n\tpublic static String FONT = \"font\";\n\tprivate static int FONT_SIZE_DEFAULT = 10;\n\tpublic static String FONT_SIZE = \"font.size\";\n\tprivate static Color FONT_COLOR_DEFAULT = Display.getCurrent()\n\t\t\t.getSystemColor(SWT.COLOR_BLACK);\n\tpublic static String FONT_COLOR = \"font.color\";\n\tprivate static Color BACKGROUND_COLOR_DEFAULT = Display.getCurrent()\n\t\t\t.getSystemColor(SWT.COLOR_WHITE);\n\tpublic static String BACKGROUND_COLOR = \"background.color\";\n\t// CONFIGURABLE ACCELERATORS\n\tprivate String accelerators;\n\t// Pause\n\tprivate static String PAUSE_KEY_DEFAULT = \" \";\n\tpublic static String PAUSE_KEY = \"pause.key\";\n\t// Short rewind\n\tprivate static String SHORT_REWIND_KEY_DEFAULT = \"7\";\n\tpublic static String SHORT_REWIND_KEY = \"short.rewind.key\";\n\t// Long rewind\n\tprivate static String LONG_REWIND_KEY_DEFAULT = \"8\";\n\tpublic static String LONG_REWIND_KEY = \"long.rewind.key\";\n\t// Speed up\n\tprivate static String SPEED_UP_KEY_DEFAULT = \"4\";\n\tpublic static String SPEED_UP_KEY = \"speed.up.key\";\n\t// Slow down\n\tprivate static String SLOW_DOWN_KEY_DEFAULT = \"3\";\n\tpublic static String SLOW_DOWN_KEY = \"slow.down.key\";\n\t// Audio loops\n\tprivate static String AUDIO_LOOPS_KEY_DEFAULT = \"9\";\n\tpublic static String AUDIO_LOOPS_KEY = \"audio.loops.key\";\n\tpublic static String LOOP_FRECUENCY = \"loop.frecuency\";\n\tprivate static int LOOP_FRECUENCY_DEFAULT = 5;\n\tpublic static String LOOP_LENGHT = \"loop.lenght\";\n\tprivate static int LOOP_LENGHT_DEFAULT = 2;\n\t// Timestamps\n\tprivate static String TIMESTAMP_KEY_DEFAULT = \"t\";\n\tpublic static String TIMESTAMP_KEY = \"timestamp.key\";\n\tprivate Config() {\n\t\tsuper(CONFIG_PATH);\n\t\t// Set up the defaults\n\t\tsetDefault(SHORT_REWIND, SHORT_REWIND_DEFAULT);\n\t\tsetDefault(LONG_REWIND, LONG_REWIND_DEFAULT);\n\t\tsetDefault(REWIND_AND_PLAY, REWIND_AND_PLAY_DEFAULT);\n\t\tsetDefault(SHELL_HEIGHT, SHELL_HEIGHT_DEFAULT);\n\t\tsetDefault(SHELL_LENGHT, SHELL_LENGHT_DEFAULT);\n\t\tsetDefault(TEXT_FILE_CACHE_LENGHT, TEXT_FILE_CACHE_LENGHT_DEFAULT);\n\t\tsetDefault(AUDIO_FILE_CACHE_LENGHT, AUDIO_FILE_CACHE_LENGHT_DEFAULT);\n\t\tsetDefault(SLOW_DOWN_PLAYBACK, SLOW_DOWN_PLAYBACK_DEFAULT);\n\t\tsetDefault(SPEED_UP_PLAYBACK, SPEED_UP_PLAYBACK_DEFAULT);\n\t\tsetDefault(AUTO_SAVE, AUTO_SAVE_DEFAULT);\n\t\tsetDefault(AUTO_SAVE_TIME, AUTO_SAVE_TIME_DEFAULT);\n\t\tsetDefault(SHOW_MINI_MODE_DIALOG, SHOW_MINI_MODE_DIALOG_DEFAULT);\n\t\tsetDefault(FONT, FONT_DEFAULT);\n\t\tsetDefault(FONT_SIZE, FONT_SIZE_DEFAULT);\n\t\tsetDefault(FONT_COLOR, FONT_COLOR_DEFAULT);\n\t\tsetDefault(BACKGROUND_COLOR, BACKGROUND_COLOR_DEFAULT);\n\t\t// Pause\n\t\tsetDefault(PAUSE_KEY, PAUSE_KEY_DEFAULT);\n\t\t// Short rewind\n\t\tsetDefault(SHORT_REWIND_KEY, SHORT_REWIND_KEY_DEFAULT);\n\t\t// Long rewind\n\t\tsetDefault(LONG_REWIND_KEY, LONG_REWIND_KEY_DEFAULT);\n\t\t// Playback speed\n\t\tsetDefault(SPEED_UP_KEY, SPEED_UP_KEY_DEFAULT);\n\t\tsetDefault(SLOW_DOWN_KEY, SLOW_DOWN_KEY_DEFAULT);\n\t\t// Audio loops\n\t\tsetDefault(AUDIO_LOOPS_KEY, AUDIO_LOOPS_KEY_DEFAULT);\n\t\tsetDefault(LOOP_FRECUENCY, LOOP_FRECUENCY_DEFAULT);\n\t\tsetDefault(LOOP_LENGHT, LOOP_LENGHT_DEFAULT);\n\t\t// Timestamp\n\t\tsetDefault(TIMESTAMP_KEY, TIMESTAMP_KEY_DEFAULT);\n\t\t// Cache\n\t\tsetDefault(LAST_OPEN_AUDIO_PATH, LAST_OPEN_AUDIO_PATH_DEFAULT);\n\t\tsetDefault(LAST_OPEN_TEXT_PATH, LAST_OPEN_TEXT_PATH_DEFAULT);\n\t\tsetDefault(LAST_EXPORT_TRANSCRIPTION_PATH,\n\t\t\t\tLAST_EXPORT_TRANSCRIPTION_PATH_DEFALUT);\n\t\ttry {\n\t\t\tload();\n\t\t} catch (Exception e) {\n\t\t\t// The properties will start as default values\n\t\t}\n\t\tupdateAccelerators();\n\t\t// Add the listeners\n\t\taddPropertyChangeListener(new IPropertyChangeListener() {\n\t\t\t@Override\n\t\t\tpublic void propertyChange(PropertyChangeEvent event) {\n\t\t\t\ttry {\n\t\t\t\t\tupdateAccelerators();\n\t\t\t\t\tsave();\n\t\t\t\t} catch (IOException e) {\n\t\t\t\t\t// ignore\n\t\t\t\t}\n\t\t\t}\n\t\t});\n\t}\n\tpublic void showConfigurationDialog(Shell parent) throws PmTransException {\n\t\t// Create the preference manager\n\t\tPreferenceManager mgr = new PreferenceManager();\n\t\t// Create the nodes\n\t\tPreferenceNode playbackNode = new PreferenceNode(\"playbackPreferences\");\n\t\tPreferencePage playbackPage = new FieldEditorPreferencePage() {\n\t\t\t@Override\n\t\t\tprotected void createFieldEditors() {\n\t\t\t\taddField(new IntegerFieldEditor(SHORT_REWIND,\n\t\t\t\t\t\t\"Short rewind duration (in sec)\",\n\t\t\t\t\t\tgetFieldEditorParent()));\n\t\t\t\taddField(new IntegerFieldEditor(LONG_REWIND,\n\t\t\t\t\t\t\"Long rewind duration (in sec)\", getFieldEditorParent()));\n\t\t\t\taddField(new IntegerFieldEditor(REWIND_AND_PLAY,\n\t\t\t\t\t\t\"Rewind-and-resume duartion duration (in sec)\",\n\t\t\t\t\t\tgetFieldEditorParent()));\n\t\t\t\taddField(new IntegerFieldEditor(LOOP_FRECUENCY,\n\t\t\t\t\t\t\"Loops frecuency (in seconds)\", getFieldEditorParent()));\n\t\t\t\taddField(new IntegerFieldEditor(LOOP_LENGHT,\n\t\t\t\t\t\t\"Loop rewind lenght (in seconds)\",\n\t\t\t\t\t\tgetFieldEditorParent()));\n\t\t\t}\n\t\t};\n\t\tplaybackPage.setTitle(\"Playback preferences\");\n\t\tplaybackNode.setPage(playbackPage);\n\t\tPreferenceNode shortcutsNode = new PreferenceNode(\n\t\t\t\t\"shortcutsPreferences\");\n\t\tPreferencePage shortcutsPage = new FieldEditorPreferencePage() {\n\t\t\t@Override\n\t\t\tprotected void createFieldEditors() {\n\t\t\t\taddField(new ShortcutFieldEditor(SHORT_REWIND_KEY,\n\t\t\t\t\t\t\"Short rewind\", getFieldEditorParent()));\n\t\t\t\taddField(new ShortcutFieldEditor(LONG_REWIND_KEY,\n\t\t\t\t\t\t\"Long rewind\", getFieldEditorParent()));\n\t\t\t\taddField(new ShortcutFieldEditor(PAUSE_KEY, \"Pause and resume\",\n\t\t\t\t\t\tgetFieldEditorParent()));\n\t\t\t\taddField(new ShortcutFieldEditor(AUDIO_LOOPS_KEY,\n\t\t\t\t\t\t\"Enable audio loops\", getFieldEditorParent()));\n\t\t\t\taddField(new ShortcutFieldEditor(SLOW_DOWN_KEY,\n\t\t\t\t\t\t\"Slow down audio playback\", getFieldEditorParent()));\n\t\t\t\taddField(new ShortcutFieldEditor(SPEED_UP_KEY,\n\t\t\t\t\t\t\"Speed up audio playback\", getFieldEditorParent()));\n\t\t\t\taddField(new ShortcutFieldEditor(TIMESTAMP_KEY,\n\t\t\t\t\t\t\"Insert timestamp\", getFieldEditorParent()));\n\t\t\t}\n\t\t};\n\t\tshortcutsPage.setTitle(\"Shortcuts preferences\");\n\t\tshortcutsNode.setPage(shortcutsPage);\n\t\tPreferenceNode generalNode = new PreferenceNode(\"generalPreferences\");\n", "outputs": ["\t\tPreferencePage generalPage = new FieldEditorPreferencePage() {"], "input_length": 1556, "output_length": 8, "length": 1564, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "07c2831f25d02a220ae9a8c8411a50da3740f57339c5db483925aae6f9ecaa3b"}
{"input": "", "context": "package de.tudresden.slr.ui.chart.settings.pages;\nimport org.eclipse.birt.chart.model.attribute.LineStyle;\nimport org.eclipse.birt.chart.model.attribute.Position;\nimport org.eclipse.swt.SWT;\nimport org.eclipse.swt.events.MouseEvent;\nimport org.eclipse.swt.events.MouseListener;\nimport org.eclipse.swt.events.SelectionEvent;\nimport org.eclipse.swt.events.SelectionListener;\nimport org.eclipse.swt.graphics.Color;\nimport org.eclipse.swt.graphics.RGB;\nimport org.eclipse.swt.layout.FillLayout;\nimport org.eclipse.swt.layout.GridData;\nimport org.eclipse.swt.layout.GridLayout;\nimport org.eclipse.swt.widgets.Button;\nimport org.eclipse.swt.widgets.Combo;\nimport org.eclipse.swt.widgets.Composite;\nimport org.eclipse.swt.widgets.Group;\nimport org.eclipse.swt.widgets.Label;\nimport org.eclipse.swt.widgets.Scale;\nimport org.eclipse.swt.widgets.Text;\nimport de.tudresden.slr.ui.chart.settings.PieChartConfiguration;\nimport de.tudresden.slr.ui.chart.settings.parts.BlockSettings;\nimport de.tudresden.slr.ui.chart.settings.parts.GeneralSettings;\nimport de.tudresden.slr.ui.chart.settings.parts.SeriesSettings;\npublic class GeneralPagePie extends Composite implements SelectionListener, MouseListener, Pages{\n\tprivate Label labelShowColor, labelShowColor2, lblExplosion;\n\tprivate Text text;\n\tprivate Combo comboTitleSize, comboBlockOutline;\n\tprivate Button btnUnderline, btnBolt, btnItalic, btnShowLables;\n\tprivate Scale explosion;\n\t\n\tprivate GeneralSettings settingsGeneral = PieChartConfiguration.get().getGeneralSettings();\n\tprivate BlockSettings settingsBlock = PieChartConfiguration.get().getBlockSettings();\n\tprivate SeriesSettings settingsSeries = PieChartConfiguration.get().getSeriesSettings();\n\tprivate Label lblLabelPosition;\n\tprivate Combo comboLabelPosition;\n\t\n\tpublic GeneralPagePie(Composite parent, int style) {\n\t\t\n\t\tsuper(parent, SWT.NONE);\n\t\t\n\t\tFillLayout fillLayout = new FillLayout(SWT.VERTICAL);\n\t\tfillLayout.marginWidth = 5;\n\t\tfillLayout.marginHeight = 5;\n\t\tsetLayout(fillLayout);\n\t\t\n\t\tGroup grpTitleSettings = new Group(this, SWT.NONE);\n\t\tgrpTitleSettings.setText(\"Title Settings\");\n\t\tgrpTitleSettings.setLayout(new GridLayout(2, false));\n\t\t\n\t\tLabel lblSetTitle = new Label(grpTitleSettings, SWT.NONE);\n\t\tlblSetTitle.setText(\"Chart Title\");\n\t\t\n\t\ttext = new Text(grpTitleSettings, SWT.BORDER);\n\t\ttext.setLayoutData(new GridData(SWT.FILL, SWT.CENTER, true, false, 1, 1));\n\t\t\n\t\tLabel lblFontSize = new Label(grpTitleSettings, SWT.NONE);\n\t\tlblFontSize.setText(\"Title Font Size\");\n\t\t\n\t\tcomboTitleSize = new Combo(grpTitleSettings, SWT.READ_ONLY);\n\t\tcomboTitleSize.setLayoutData(new GridData(SWT.LEFT, SWT.CENTER, true, false, 1, 1));\n\t\tcomboTitleSize.add(\"12\");\n\t\tcomboTitleSize.add(\"14\");\n\t\tcomboTitleSize.add(\"16\");\n\t\tcomboTitleSize.add(\"18\");\n\t\tcomboTitleSize.add(\"20\");\n\t\tcomboTitleSize.add(\"22\");\n\t\tcomboTitleSize.add(\"24\");\n\t\tcomboTitleSize.add(\"26\");\n\t\tcomboTitleSize.add(\"28\");\n\t\tcomboTitleSize.add(\"36\");\n\t\tcomboTitleSize.add(\"48\");\n\t\tcomboTitleSize.add(\"72\");\n\t\tcomboTitleSize.select(0);\n\t\t\n\t\tLabel lblColor = new Label(grpTitleSettings, SWT.NONE);\n\t\tGridData gd_lblColor = new GridData(SWT.LEFT, SWT.CENTER, false, false, 1, 1);\n\t\tgd_lblColor.widthHint = 150;\n\t\tlblColor.setLayoutData(gd_lblColor);\n\t\tlblColor.setText(\"Title Color\");\n\t\t\n\t\tlabelShowColor = new Label(grpTitleSettings, SWT.BORDER);\n\t\tGridData gd_labelShowColor = new GridData(SWT.LEFT, SWT.CENTER, false, false, 1, 1);\n\t\tgd_labelShowColor.widthHint = 100;\n\t\tlabelShowColor.setLayoutData(gd_labelShowColor);\n\t\tlabelShowColor.setBackground(new Color(parent.getShell().getDisplay(), new RGB(255,255,255)));\n\t\t\n\t\tLabel lblFont = new Label(grpTitleSettings, SWT.NONE);\n\t\tlblFont.setText(\"Font\");\n\t\t\n\t\tComposite composite = new Composite(grpTitleSettings, SWT.NONE);\n\t\tcomposite.setLayout(new GridLayout(3, false));\n\t\tcomposite.setLayoutData(new GridData(SWT.FILL, SWT.FILL, false, false, 1, 1));\n\t\t\n\t\tbtnUnderline = new Button(composite, SWT.CHECK);\n\t\tbtnUnderline.setText(\"Underline\");\n\t\t\n\t\tbtnItalic = new Button(composite, SWT.CHECK);\n\t\tbtnItalic.setText(\"Italic\");\n\t\t\n\t\tbtnBolt = new Button(composite, SWT.CHECK);\n\t\tbtnBolt.setText(\"Bolt\");\n\t\tlabelShowColor.addMouseListener(this);\n\t\t\n\t\tGroup grpBlockSettings = new Group(this, SWT.NONE);\n\t\tgrpBlockSettings.setText(\"Block Settings\");\n\t\tgrpBlockSettings.setLayout(new GridLayout(2, false));\n\t\t\n\t\tLabel lblNewLabel = new Label(grpBlockSettings, SWT.NONE);\n\t\tGridData gd_lblNewLabel = new GridData(SWT.LEFT, SWT.CENTER, false, false, 1, 1);\n\t\tgd_lblNewLabel.widthHint = 150;\n\t\tlblNewLabel.setLayoutData(gd_lblNewLabel);\n\t\tlblNewLabel.setText(\"Block Outline Style\");\n\t\t\n\t\tcomboBlockOutline = new Combo(grpBlockSettings, SWT.READ_ONLY);\n\t\tcomboBlockOutline.setLayoutData(new GridData(SWT.LEFT, SWT.CENTER, true, false, 1, 1));\n\t\tcomboBlockOutline.add(\"None\");\n\t\tcomboBlockOutline.add(\"Dotted\");\n\t\tcomboBlockOutline.add(\"Dash-Dotted\");\n\t\tcomboBlockOutline.add(\"Dashed\");\n\t\tcomboBlockOutline.add(\"Solid\");\n\t\tcomboBlockOutline.select(0);\n\t\t\n\t\tLabel lblColor_1 = new Label(grpBlockSettings, SWT.NONE);\n\t\tlblColor_1.setText(\"Block Color\");\n\t\t\n\t\tlabelShowColor2 = new Label(grpBlockSettings, SWT.BORDER);\n\t\tGridData gd_labelShowColor2 = new GridData(SWT.LEFT, SWT.CENTER, false, false, 1, 1);\n\t\tgd_labelShowColor2.widthHint = 100;\n\t\tlabelShowColor2.setLayoutData(gd_labelShowColor2);\n\t\tlabelShowColor2.setText(\" \");\n\t\tlabelShowColor2.setBackground(PageSupport.getColor(parent, 0));\n\t\t\n\t\tLabel lblLables = new Label(grpBlockSettings, SWT.NONE);\n\t\tlblLables.setText(\"Pie Labels\");\n\t\t\n\t\tbtnShowLables = new Button(grpBlockSettings, SWT.CHECK);\n\t\tbtnShowLables.setText(\"Show Labels\");\n\t\t\n\t\tlblExplosion = new Label(grpBlockSettings, SWT.NONE);\n\t\tGridData gd_lblExplosion = new GridData(SWT.FILL, SWT.CENTER, false, false, 1, 1);\n\t\tgd_lblExplosion.widthHint = 106;\n\t\tlblExplosion.setLayoutData(gd_lblExplosion);\n\t\tlblExplosion.setText(\"Pie Explosion\");\n\t\t\n\t\texplosion = new Scale(grpBlockSettings, SWT.NONE);\n\t\texplosion.setLayoutData(new GridData(SWT.FILL, SWT.CENTER, true, false, 1, 1));\n\t\texplosion.setPageIncrement(1);\n\t\texplosion.setMaximum(20);\n\t\t\n\t\tlblLabelPosition = new Label(grpBlockSettings, SWT.NONE);\n\t\tlblLabelPosition.setText(\"Label Position\");\n\t\t\n\t\tcomboLabelPosition = new Combo(grpBlockSettings, SWT.READ_ONLY);\n\t\tcomboLabelPosition.setLayoutData(new GridData(SWT.LEFT, SWT.CENTER, true, false, 1, 1));\n\t\tcomboLabelPosition.addSelectionListener(this);\n\t\tcomboLabelPosition.add(\"Inside\");\n\t\tcomboLabelPosition.add(\"Outside\");\n\t\t\n\t\texplosion.addSelectionListener(this);\n\t\tlabelShowColor2.addMouseListener(this);\n\t\t\n\t\tloadSettings();\n\t}\n\t@Override\n\tpublic void mouseUp(MouseEvent e) {\n\t\tif(e.getSource() == labelShowColor) {\n\t\t\tRGB rgb = PageSupport.openAndGetColor(this.getParent(), labelShowColor);\n\t\t}\n\t\tif(e.getSource() == labelShowColor2) {\n\t\t\tRGB rgb = PageSupport.openAndGetColor(this.getParent(), labelShowColor2);\n\t\t}\t\t\n\t}\n\t@Override\n\tpublic void saveSettings() {\n\t\t\n\t\tsettingsGeneral.setChartTitle(getTitle());\n\t\tsettingsGeneral.setChartTitleColor(getTitleColor());\n\t\tsettingsGeneral.setChartTitleSize(getTitleSize());\n\t\tsettingsGeneral.setChartTitleBold(getBolt());\n\t\tsettingsGeneral.setChartTitleItalic(getItalic());\n\t\tsettingsGeneral.setChartTitleUnderline(getUnterline());\n\t\tsettingsSeries.setSeriesExplosion(getExplosion());\n\t\tsettingsSeries.setSeriesLabelPosition(getPosition());\n\t\t\n\t\tsettingsGeneral.setChartShowLabels(isChartShowLabels());//\n\t\n\t\tsettingsBlock.setBlockBackgroundRGB(getBlockColor());\n\t\t\n\t\tif(getBlockOutline() == null)\n\t\t\tsettingsBlock.setBlockShowOutline(false);\n\t\telse {\n\t\t\tsettingsBlock.setBlockShowOutline(true);\n\t\t\tsettingsBlock.setBlockOutlineStyle(getBlockOutline());\n\t\t}\n\t}\n\t@Override\n\tpublic void loadSettings() {\n\t\tsetTitle(settingsGeneral.getChartTitle());\n\t\tsetTitleColor(settingsGeneral.getChartTitleColor());\n\t\tsetTitleSize(settingsGeneral.getChartTitleSize());\n\t\tsetBolt(settingsGeneral.isChartTitleBold());\n\t\tsetItalic(settingsGeneral.isChartTitleItalic());\n\t\tsetUnterline(settingsGeneral.isChartTitleUnderline());\n\t\tsetBlockColor(settingsBlock.getBlockBackgroundRGB());\n\t\tsetExplosion(settingsSeries.getSeriesExplosion());\n\t\tsetPosition(settingsSeries.getSeriesLabelPosition());\n\t\t\n\t\tsetChartShowLabels(settingsGeneral.isChartShowLabels());//\n\t\t\t\n\t\t\tif(settingsBlock.isBlockShowOutline())\n\t\t\t\tsetBlockOutline(settingsBlock.getBlockOutlineStyle());\n\t\t\telse\n\t\t\t\tsetBlockOutline(null);\n\t\t}\n\t\t\n\t\tprivate boolean getBolt() {return btnBolt.getSelection();}\n\t\tprivate void setBolt(boolean value) {btnBolt.setSelection(value);}\n\t\t\n\t\tprivate boolean getItalic() {return btnItalic.getSelection();}\n\t\tprivate void setItalic(boolean value) {btnItalic.setSelection(value);}\n\t\t\n\t\tprivate boolean getUnterline() {return btnUnderline.getSelection();}\n\t\tprivate void setUnterline(boolean value) {btnUnderline.setSelection(value);}\n\t\t\n\t\tprivate String getTitle() {return text.getText();}\n\t\tpublic void setTitle(String title) {text.setText(title);}\n\t\t\n\t\tprivate int getTitleSize() {return Integer.valueOf(comboTitleSize.getItem(comboTitleSize.getSelectionIndex()));}\n\t\tprivate void setTitleSize(int size) {comboTitleSize.select(PageSupport.setFontSize(size));}\n\t\t\n\t\tprivate LineStyle getBlockOutline() {return PageSupport.getLineStyle(comboBlockOutline.getSelectionIndex());}\n\t\tprivate void setBlockOutline(LineStyle lineStyle) {comboBlockOutline.select((PageSupport.setLineStyle(lineStyle)));}\n\t\t\n\t\tprivate RGB getTitleColor() {return labelShowColor.getBackground().getRGB();}\n\t\tprivate void setTitleColor(RGB rgb) {labelShowColor.setBackground(new Color(this.getDisplay(), rgb));}\n\t\t\n\t\tprivate RGB getBlockColor() {return labelShowColor2.getBackground().getRGB();}\n\t\tprivate void setBlockColor(RGB rgb) {labelShowColor2.setBackground(new Color(this.getDisplay(), rgb));}\n\t\t\n\t\tprivate boolean isChartShowLabels() {return btnShowLables.getSelection();}\n\t\tprivate void setChartShowLabels(boolean value) {btnShowLables.setSelection(value);}\n\t\t\n\t\tprivate int getExplosion() {return explosion.getSelection();}\n\t\tprivate void setExplosion(int explosion) {this.explosion.setSelection(explosion);\n\t\tlblExplosion.setText(\"Pie Explosion: \" + String.valueOf(this.explosion.getSelection()));}\n\t\t\n\t\tprivate void setPosition(Position position) {\n", "outputs": ["\t\t\tif(position == Position.INSIDE_LITERAL) {"], "input_length": 1640, "output_length": 7, "length": 1647, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "0a1eca384900e6947bca71f9c817c5f0e62ec34bbd6a44a6030690802a1489db"}
{"input": "", "context": "#!/usr/bin/python\n# -*- coding: utf-8 -*-\n#\n# Copyright: (c) 2018, F5 Networks Inc.\n# GNU General Public License v3.0 (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)\nfrom __future__ import absolute_import, division, print_function\n__metaclass__ = type\nANSIBLE_METADATA = {'metadata_version': '1.1',\n                    'status': ['preview'],\n                    'supported_by': 'certified'}\nDOCUMENTATION = r'''\n---\nmodule: bigip_monitor_ldap\nshort_description: Manages BIG-IP LDAP monitors\ndescription:\n  - Manages BIG-IP LDAP monitors.\nversion_added: 2.8\noptions:\n  name:\n    description:\n      - Monitor name.\n    required: True\n  description:\n    description:\n      - Specifies descriptive text that identifies the monitor.\n  parent:\n    description:\n      - The parent template of this monitor template. Once this value has\n        been set, it cannot be changed.\n      - By default, this value is the C(ldap) parent on the C(Common) partition.\n    default: \"/Common/ldap\"\n  ip:\n    description:\n      - IP address part of the IP/port definition. If this parameter is not\n        provided when creating a new monitor, then the default value will be\n        '*'.\n  port:\n    description:\n      - Port address part of the IP/port definition. If this parameter is not\n        provided when creating a new monitor, then the default value will be\n        '*'.\n      - Note that if specifying an IP address, a value between 1 and 65535\n        must be specified.\n  interval:\n    description:\n      - Specifies, in seconds, the frequency at which the system issues the\n        monitor check when either the resource is down or the status of the\n        resource is unknown.\n  timeout:\n    description:\n      - Specifies the number of seconds the target has in which to respond to\n        the monitor request.\n      - If the target responds within the set time period, it is considered 'up'.\n        If the target does not respond within the set time period, it is considered\n        'down'. When this value is set to 0 (zero), the system uses the interval\n        from the parent monitor.\n      - Note that C(timeout) and C(time_until_up) combine to control when a\n        resource is set to up.\n  time_until_up:\n    description:\n      - Specifies the number of seconds to wait after a resource first responds\n        correctly to the monitor before setting the resource to 'up'.\n      - During the interval, all responses from the resource must be correct.\n      - When the interval expires, the resource is marked 'up'.\n      - A value of 0, means that the resource is marked up immediately upon\n        receipt of the first correct response.\n  up_interval:\n    description:\n      - Specifies the interval for the system to use to perform the health check\n        when a resource is up.\n      - When C(0), specifies that the system uses the interval specified in\n        C(interval) to check the health of the resource.\n      - When any other number, enables specification of a different interval to\n        use when checking the health of a resource that is up.\n  manual_resume:\n    description:\n      - Specifies whether the system automatically changes the status of a resource\n        to B(enabled) at the next successful monitor check.\n      - If you set this option to C(yes), you must manually re-enable the resource\n        before the system can use it for load balancing connections.\n      - When C(yes), specifies that you must manually re-enable the resource after an\n        unsuccessful monitor check.\n      - When C(no), specifies that the system automatically changes the status of a\n        resource to B(enabled) at the next successful monitor check.\n    type: bool\n  target_username:\n    description:\n      - Specifies the user name, if the monitored target requires authentication.\n  target_password:\n    description:\n      - Specifies the password, if the monitored target requires authentication.\n  base:\n    description:\n      - Specifies the location in the LDAP tree from which the monitor starts the\n        health check.\n  filter:\n    description:\n      - Specifies an LDAP key for which the monitor searches.\n  security:\n    description:\n      - Specifies the secure protocol type for communications with the target.\n    choices:\n      - none\n      - ssl\n      - tls\n  mandatory_attributes:\n    description:\n      - Specifies whether the target must include attributes in its response to be\n        considered up.\n    type: bool\n  chase_referrals:\n    description:\n      - Specifies whether, upon receipt of an LDAP referral entry, the target\n        follows (or chases) that referral.\n    type: bool\n  debug:\n    description:\n      - Specifies whether the monitor sends error messages and additional information\n        to a log file created and labeled specifically for this monitor.\n    type: bool\n  update_password:\n    description:\n      - C(always) will update passwords if the C(target_password) is specified.\n      - C(on_create) will only set the password for newly created monitors.\n    default: always\n    choices:\n      - always\n      - on_create\n  partition:\n    description:\n      - Device partition to manage resources on.\n    default: Common\n  state:\n    description:\n      - When C(present), ensures that the monitor exists.\n      - When C(absent), ensures the monitor is removed.\n    default: present\n    choices:\n      - present\n      - absent\nextends_documentation_fragment: f5\nauthor:\n  - Tim Rupp (@caphrim007)\n'''\nEXAMPLES = r'''\n- name: Create a LDAP monitor\n  bigip_monitor_ldap:\n    name: foo\n    provider:\n      password: secret\n      server: lb.mydomain.com\n      user: admin\n  delegate_to: localhost\n'''\nRETURN = r'''\nparent:\n  description: New parent template of the monitor.\n  returned: changed\n  type: str\n  sample: ldap\ndescription:\n  description: The description of the monitor.\n  returned: changed\n  type: str\n  sample: Important_Monitor\nip:\n  description: The new IP of IP/port definition.\n  returned: changed\n  type: str\n  sample: 10.12.13.14\ninterval:\n  description: The new interval in which to run the monitor check.\n  returned: changed\n  type: int\n  sample: 2\ntimeout:\n  description: The new timeout in which the remote system must respond to the monitor.\n  returned: changed\n  type: int\n  sample: 10\ntime_until_up:\n  description: The new time in which to mark a system as up after first successful response.\n  returned: changed\n  type: int\n  sample: 2\nsecurity:\n  description: The new Security setting of the resource.\n  returned: changed\n  type: str\n  sample: ssl\ndebug:\n  description: The new Debug setting of the resource.\n  returned: changed\n  type: bool\n  sample: yes\nmandatory_attributes:\n  description: The new Mandatory Attributes setting of the resource.\n  returned: changed\n  type: bool\n  sample: no\nchase_referrals:\n  description: The new Chase Referrals setting of the resource.\n  returned: changed\n  type: bool\n  sample: yes\nmanual_resume:\n  description: The new Manual Resume setting of the resource.\n  returned: changed\n  type: bool\n  sample: no\nfilter:\n  description: The new LDAP Filter setting of the resource.\n  returned: changed\n  type: str\n  sample: filter1\nbase:\n  description: The new LDAP Base setting of the resource.\n  returned: changed\n  type: str\n  sample: base\n'''\nfrom ansible.module_utils.basic import AnsibleModule\nfrom ansible.module_utils.basic import env_fallback\ntry:\n    from library.module_utils.network.f5.bigip import F5RestClient\n    from library.module_utils.network.f5.common import F5ModuleError\n    from library.module_utils.network.f5.common import AnsibleF5Parameters\n    from library.module_utils.network.f5.common import cleanup_tokens\n    from library.module_utils.network.f5.common import fq_name\n    from library.module_utils.network.f5.common import f5_argument_spec\n    from library.module_utils.network.f5.common import exit_json\n    from library.module_utils.network.f5.common import fail_json\n    from library.module_utils.network.f5.common import transform_name\n    from library.module_utils.network.f5.common import flatten_boolean\n    from library.module_utils.network.f5.ipaddress import is_valid_ip\n    from library.module_utils.network.f5.compare import cmp_str_with_none\nexcept ImportError:\n    from ansible.module_utils.network.f5.bigip import F5RestClient\n    from ansible.module_utils.network.f5.common import F5ModuleError\n    from ansible.module_utils.network.f5.common import AnsibleF5Parameters\n    from ansible.module_utils.network.f5.common import cleanup_tokens\n    from ansible.module_utils.network.f5.common import fq_name\n    from ansible.module_utils.network.f5.common import f5_argument_spec\n    from ansible.module_utils.network.f5.common import exit_json\n    from ansible.module_utils.network.f5.common import fail_json\n    from ansible.module_utils.network.f5.common import transform_name\n    from ansible.module_utils.network.f5.common import flatten_boolean\n    from ansible.module_utils.network.f5.ipaddress import is_valid_ip\n    from ansible.module_utils.network.f5.compare import cmp_str_with_none\nclass Parameters(AnsibleF5Parameters):\n    api_map = {\n        'timeUntilUp': 'time_until_up',\n        'defaultsFrom': 'parent',\n        'mandatoryAttributes': 'mandatory_attributes',\n        'chaseReferrals': 'chase_referrals',\n        'manualResume': 'manual_resume',\n        'username': 'target_username',\n        'password': 'target_password',\n    }\n    api_attributes = [\n        'timeUntilUp',\n        'defaultsFrom',\n        'interval',\n        'timeout',\n        'destination',\n        'description',\n        'security',\n        'mandatoryAttributes',\n        'chaseReferrals',\n        'debug',\n        'manualResume',\n        'username',\n        'password',\n        'filter',\n        'base',\n    ]\n    returnables = [\n        'parent',\n        'ip',\n        'destination',\n        'port',\n        'interval',\n        'timeout',\n        'time_until_up',\n        'description',\n        'security',\n        'debug',\n        'mandatory_attributes',\n        'chase_referrals',\n        'manual_resume',\n        'filter',\n        'base',\n    ]\n    updatables = [\n        'destination',\n        'interval',\n        'timeout',\n        'time_until_up',\n        'description',\n        'security',\n        'debug',\n        'mandatory_attributes',\n        'chase_referrals',\n        'manual_resume',\n        'target_username',\n        'target_password',\n        'filter',\n        'base',\n    ]\n    @property\n    def timeout(self):\n        if self._values['timeout'] is None:\n            return None\n        return int(self._values['timeout'])\n    @property\n    def time_until_up(self):\n        if self._values['time_until_up'] is None:\n            return None\n        return int(self._values['time_until_up'])\n    @property\n    def mandatory_attributes(self):\n        return flatten_boolean(self._values['mandatory_attributes'])\n    @property\n    def chase_referrals(self):\n        return flatten_boolean(self._values['chase_referrals'])\n    @property\n    def debug(self):\n        return flatten_boolean(self._values['debug'])\n    @property\n    def manual_resume(self):\n        return flatten_boolean(self._values['manual_resume'])\n    @property\n    def security(self):\n        if self._values['security'] in ['none', None]:\n            return ''\n        return self._values['security']\nclass ApiParameters(Parameters):\n    @property\n    def ip(self):\n        ip, port = self._values['destination'].split(':')\n        return ip\n    @property\n    def port(self):\n        ip, port = self._values['destination'].split(':')\n        try:\n            return int(port)\n        except ValueError:\n            return port\n    @property\n    def description(self):\n        if self._values['description'] in [None, 'none']:\n            return None\n        return self._values['description']\nclass ModuleParameters(Parameters):\n    @property\n    def ip(self):\n        if self._values['ip'] is None:\n            return None\n        if self._values['ip'] in ['*', '0.0.0.0']:\n            return '*'\n        elif is_valid_ip(self._values['ip']):\n            return self._values['ip']\n        else:\n            raise F5ModuleError(\n                \"The provided 'ip' parameter is not an IP address.\"\n            )\n    @property\n    def parent(self):\n        if self._values['parent'] is None:\n            return None\n        result = fq_name(self.partition, self._values['parent'])\n        return result\n    @property\n    def port(self):\n        if self._values['port'] is None:\n            return None\n        elif self._values['port'] == '*':\n            return '*'\n        return int(self._values['port'])\n    @property\n    def destination(self):\n        if self.ip is None and self.port is None:\n            return None\n        destination = '{0}:{1}'.format(self.ip, self.port)\n        return destination\n    @destination.setter\n    def destination(self, value):\n        ip, port = value.split(':')\n        self._values['ip'] = ip\n        self._values['port'] = port\n    @property\n    def interval(self):\n        if self._values['interval'] is None:\n            return None\n        if 1 > int(self._values['interval']) > 86400:\n            raise F5ModuleError(\n                \"Interval value must be between 1 and 86400\"\n            )\n        return int(self._values['interval'])\n    @property\n    def type(self):\n        return 'ldap'\n    @property\n    def description(self):\n        if self._values['description'] is None:\n            return None\n        elif self._values['description'] in ['none', '']:\n            return ''\n        return self._values['description']\nclass Changes(Parameters):\n    def to_return(self):\n        result = {}\n        try:\n            for returnable in self.returnables:\n                result[returnable] = getattr(self, returnable)\n            result = self._filter_params(result)\n        except Exception:\n            pass\n        return result\nclass UsableChanges(Changes):\n    @property\n    def manual_resume(self):\n        if self._values['manual_resume'] is None:\n            return None\n        if self._values['manual_resume'] == 'yes':\n            return 'enabled'\n        return 'disabled'\nclass ReportableChanges(Changes):\n    @property\n    def manual_resume(self):\n        return flatten_boolean(self._values['manual_resume'])\n    @property\n    def ip(self):\n        ip, port = self._values['destination'].split(':')\n        return ip\n    @property\n    def port(self):\n        ip, port = self._values['destination'].split(':')\n        return int(port)\nclass Difference(object):\n    def __init__(self, want, have=None):\n        self.want = want\n        self.have = have\n    def compare(self, param):\n        try:\n            result = getattr(self, param)\n            return result\n        except AttributeError:\n            return self.__default(param)\n    @property\n    def parent(self):\n        if self.want.parent != self.have.parent:\n            raise F5ModuleError(\n                \"The parent monitor cannot be changed\"\n            )\n    @property\n    def destination(self):\n        if self.want.ip is None and self.want.port is None:\n            return None\n        if self.want.port is None:\n            self.want.update({'port': self.have.port})\n        if self.want.ip is None:\n            self.want.update({'ip': self.have.ip})\n        if self.want.port in [None, '*'] and self.want.ip != '*':\n            raise F5ModuleError(\n                \"Specifying an IP address requires that a port number be specified\"\n            )\n", "outputs": ["        if self.want.destination != self.have.destination:"], "input_length": 2499, "output_length": 6, "length": 2505, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "29f7649ad280ade8a3ec5f63ae31c49f9d27d233432e1d7dfdfd45aee5067560"}
{"input": "", "context": "/**\n* ===========================================\n* Java Pdf Extraction Decoding Access Library\n* ===========================================\n*\n* Project Info:  http://www.jpedal.org\n* (C) Copyright 1997-2008, IDRsolutions and Contributors.\n*\n* \tThis file is part of JPedal\n*\n    This library is free software; you can redistribute it and/or\n    modify it under the terms of the GNU Lesser General Public\n    License as published by the Free Software Foundation; either\n    version 2.1 of the License, or (at your option) any later version.\n    This library is distributed in the hope that it will be useful,\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n    Lesser General Public License for more details.\n    You should have received a copy of the GNU Lesser General Public\n    License along with this library; if not, write to the Free Software\n    Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA\n*\n* ---------------\n* PdfPanel.java\n* ---------------\n*/\npackage org.jpedal;\nimport java.awt.AlphaComposite;\nimport java.awt.BasicStroke;\nimport java.awt.Color;\nimport java.awt.Composite;\nimport java.awt.Container;\nimport java.awt.Dimension;\nimport java.awt.Font;\nimport java.awt.Graphics;\nimport java.awt.Graphics2D;\nimport java.awt.Point;\nimport java.awt.Rectangle;\nimport java.awt.Shape;\nimport java.awt.Stroke;\nimport java.awt.dnd.DropTarget;\nimport java.awt.event.MouseEvent;\nimport java.awt.font.GlyphVector;\nimport java.awt.geom.AffineTransform;\nimport java.awt.geom.Area;\nimport java.awt.geom.Rectangle2D;\nimport java.awt.image.BufferedImage;\nimport java.util.Map;\nimport javax.swing.border.Border;\nimport org.jpedal.io.ObjectStore;\nimport org.jpedal.objects.PdfPageData;\n//<start-jfr>\n//<start-adobe>\nimport org.jpedal.objects.PageLines;\n//<end-adobe>\nimport org.jpedal.objects.PdfData;\nimport org.jpedal.objects.PrinterOptions;\nimport org.jpedal.objects.raw.PdfArrayIterator;\nimport org.jpedal.objects.layers.PdfLayerList;\nimport org.jpedal.objects.acroforms.rendering.AcroRenderer;\n//<end-jfr>\nimport org.jpedal.render.DynamicVectorRenderer;\nimport org.jpedal.utils.repositories.Vector_Int;\nimport org.jpedal.utils.repositories.Vector_Rectangle;\nimport org.jpedal.utils.repositories.Vector_Shape;\nimport javax.swing.*;\n/**\n * Do not create an instance of this class - provides GUI functionality for\n * PdfDecoder class to extend\n */\npublic class PdfPanel extends JPanel{\n\tprivate static final long serialVersionUID = -5480323101993399978L;\n\t\n\t/** Not part of the JPedal API - Required for Storypad */\n\tpublic JPanel[] extraButton;\n\tpublic boolean useParentButtons = false;\n    protected PdfLayerList layers;    \n    /** Holds the x,y,w,h of the current highlighted image, null if none */\n\tint[] highlightedImage = null;\n\t\n\t/** Enable / Disable Point and Click image extraction */\n\tprivate boolean ImageExtractionAllowed = true;\n\t//<start-jfr>\n\tprotected Display pages;\n\t/** holds the extracted AcroForm data */\n\t//protected PdfFormData currentAcroFormData;\n    //PdfArrayIterator fieldList=null;\n\t/**default renderer for acroforms*/\n\tprotected AcroRenderer formRenderer;//=new DefaultAcroRenderer();\n\t/**hotspots for display*/\n\t//Hotspots displayHotspots;\n\t/**hotspots for printing*/\n\t//Hotspots printHotspots;\n\t//<start-adobe>\n\t/**holds page lines*/\n\tprotected PageLines pageLines;\n\t\n\t\n\t//<end-adobe>\n\t//<end-jfr>\n\t/** \n\t * The colour of the highlighting box around the text\n\t */\n\tpublic static Color highlightColor = new Color(10,100,170);\n\t\n\t/** \n\t * The colour of the text once highlighted\n\t */\n\tpublic static Color backgroundColor = null;\n\t/** \n\t * The transparency of the highlighting box around the text stored as a float\n\t */\n\tpublic static float highlightComposite = 0.35f;\n    protected Rectangle[] alternateOutlines;\n\tString altName;\n\t/**tracks indent so changing to continuous does not disturb display*/\n\tprivate int lastIndent=-1;\n\t//<start-jfr>\n\tPageOffsets currentOffset;\n\t/**copy of flag to tell program whether to create\n\t * (and possibly update) screen display\n\t */\n\tprotected boolean renderPage = false;\n\t/**type of printing*/\n\tprotected boolean isPrintAutoRotateAndCenter=false;\n\t/**flag to show we use PDF page size*/\n\tprotected boolean usePDFPaperSize=false;\n\t/**page scaling mode to use for printing*/\n\tprotected int pageScalingMode=PrinterOptions.PAGE_SCALING_REDUCE_TO_PRINTER_MARGINS;\n\t//<end-jfr>\n\t/**display mode (continuous, facing, single)*/\n\tprotected int displayView=Display.SINGLE_PAGE;\n\t/**amount we scroll screen to make visible*/\n\tprivate int scrollInterval=10;\n\t/** count of how many pages loaded */\n\tprotected int pageCount = 0;\n\t/**\n\t * if true\n\t * show the crop box as a box with cross on it\n\t * and remove the clip.\n\t */\n\tprivate boolean showCrop = false;\n\t/** when true setPageParameters draws the page rotated for use with scale to window */\n    boolean isNewRotationSet=false;\n\t/** displays the viewport border */\n\tprotected boolean displayViewportBorder=false;\n\t/**flag to stop multiple attempts to decode*/\n\tprotected boolean isDecoding=false;\n\tprotected int alignment=Display.DISPLAY_LEFT_ALIGNED;\n\t/** used by setPageParameters to draw rotated pages */\n\tprotected int displayRotation=0;\n\t/**current cursor location*/\n\tprivate Point current_p;\n\t/**allows user to create viewport on page and scale to this*/\n\tprotected Rectangle viewableArea=null;\n\t/**shows merging for debugging*/\n\tprivate Vector_Int merge_level ;\n\tprivate Vector_Shape merge_outline;\n\tprivate boolean[] showDebugLevel;\n\tprivate Color[] debugColors;\n\tprivate boolean showMerging=false;\n\t/**used to draw demo cross*/\n\tAffineTransform demoAf=null;\n\t/**repaint manager*/\n\tprivate RepaintManager currentManager=RepaintManager.currentManager(this);\n\t/**current page*/\n\tprotected int pageNumber=1;\n\t/**used to reduce or increase image size*/\n\tprotected AffineTransform displayScaling;\n\t/**\n\t * used to apply the imageable area to the displayscaling, used instead of\n\t * displayScaling, as to preserve displayScaling\n\t */\n\tprotected AffineTransform viewScaling=null;\n\t/** holds page information used in grouping*/\n\tprotected PdfPageData pageData = new PdfPageData();\n\t/**used to track highlight*/\n\tprivate Rectangle lastHighlight=null;\n\t/**rectangle drawn on screen by user*/\n\tprotected Rectangle cursorBoxOnScreen = null,lastCursorBoxOnScreen=null;\n\t/** whether the cross-hairs are drawn */\n\tprivate boolean drawCrossHairs = false;\n\t/** which box the cursor is currently positioned over */\n\tprivate int boxContained = -1;\n\t/** color to highlight selected handle */\n\tprivate Color selectedHandleColor = Color.red;\n\t/** the gap around each point of reference for cursorBox */\n\tprivate int handlesGap = 5;\n\t/**colour of highlighted rectangle*/\n\tprivate Color outlineColor;\n\t/**rectangle of object currently under cursor*/\n\tprotected Rectangle currentHighlightedObject = null;\n\t/**colour of a shape we highlight on the page*/\n\tprivate Color outlineHighlightColor;\n\t/**preferred colour to highliht page*/\n\tprivate Color[] highlightColors;\n\t/**gap around object to repaint*/\n\tstatic final private int strip=2;\n\t/**highlight around selected area*/\n\tprivate Rectangle2D[] outlineZone = null;\n\tprivate int[] processedByRegularExpression=null;\n\t/**allow for inset of display*/\n\tprotected int insetW=0,insetH=0;\n\t/**flag to show if area selected*/\n\tprivate boolean[] highlightedZonesSelected = null;\n\tprivate boolean[] hasDrownedObjects = null;\n\t/**user defined viewport*/\n\tRectangle userAnnot=null;\n\t/** default height width of bufferedimage in pixels */\n\tprivate int defaultSize = 100;\n\t/**height of the BufferedImage in pixels*/\n    int y_size = defaultSize;\n\t/**unscaled page height*/\n    int max_y;\n\t\n\t/**unscaled page Width*/\n    int max_x;\n\t/**width of the BufferedImage in pixels*/\n    int x_size = defaultSize;\n\t/**used to plot selection*/\n\tint[] cx=null,cy=null;\n\t/**any scaling factor being used to convert co-ords into correct values\n\t * and to alter image size\n\t */\n\tprotected float scaling=1;\n\t/**mode for showing outlines*/\n\tprivate int highlightMode = 0;\n\t/**flag for showing all object outlines in PDFPanel*/\n\tpublic static final int SHOW_OBJECTS = 1;\n\t/**flag for showing all lines on page used for grouping */\n\tpublic static final int SHOW_LINES = 2;\n\t/**flag for showing all lines on page used for grouping */\n\tpublic static final int SHOW_BOXES = 4;\n\t/**size of font for selection order*/\n\tprotected int size=20;\n\t/**font used to show selection order*/\n\tprotected Font highlightFont=null;\n\t/**border for component*/\n\tprotected Border myBorder=null;\n\tprotected DropTarget dropTarget = null;\n\t/** the ObjectStore for this file */\n\tprotected ObjectStore objectStoreRef = new ObjectStore();\n\t/**the actual display object*/\n\tprotected DynamicVectorRenderer currentDisplay=new DynamicVectorRenderer(1,objectStoreRef,false); //\n\t/**flag to show if border appears on printed output*/\n\tprotected boolean useBorder=true;\n\tprivate int[] selectionOrder;\n\t/**stores area of arrays in which text should be highlighted*/\n\tprivate Rectangle[] areas;\n\tprivate int[] areaDirection;\n\tprivate Object[] linkedItems,children;\n\tprivate int[] parents;\n\tprotected boolean useAcceleration=true;\n\t/**all text blocks as a shape*/\n\tprivate Shape[] fragmentShapes;\n\tint x_size_cropped;\n\tint y_size_cropped;\n\tprivate AffineTransform cursorAf;\n\tprivate Rectangle actualBox;\n\tprivate boolean drawInteractively=false;\n\tprotected int lastFormPage=-1,lastStart=-1,lastEnd=-1;\n\tprivate int pageUsedForTransform;\n\tprotected int additionalPageCount=0,xOffset=0;\n\tprivate boolean displayForms = true;\n\t//private GraphicsDevice currentGraphicsDevice = null;\n\tpublic boolean extractingAsImage = false;\n\tprivate int highlightX = 0;\n\tprivate int highlightY = 0;\n\t\n\tpublic void setExtractingAsImage(boolean extractingAsImage) {\n\t\tthis.extractingAsImage = extractingAsImage;\n\t}\n\t\n\t//<start-adobe>\n\tpublic void initNonPDF(PdfDecoder pdf){\n\t\tpages=new SingleDisplay(pageNumber,pageCount,currentDisplay);\n\t\tpages.setup(true,null, pdf);\n\t}\n\t/**workout combined area of shapes are in an area*/\n\tpublic  Rectangle getCombinedAreas(Rectangle targetRectangle,boolean justText){\n\t\tif(this.currentDisplay!=null)\n\t\t\treturn currentDisplay.getCombinedAreas(targetRectangle, justText);\n\t\treturn\n\t\tnull;\n\t}\n\t/**\n\t * put debugging info for grouping onscreen\n\t * to aid in developing and debugging merging algorithms used by Storypad -\n\t * (NOT PART OF API and subject to change)\n\t */\n\tfinal public void addMergingDisplayForDebugging(Vector_Int merge_level,\n\t\t\tVector_Shape merge_outline,int count,Color[] colors) {\n\t\tthis.merge_level=merge_level;\n\t\tthis.merge_outline=merge_outline;\n\t\tthis.showDebugLevel=new boolean[count];\n\t\tthis.debugColors=colors;\n\t}\n\t/**\n\t * debug zone for Storypad - not part of API\n\t */\n\tfinal public void setDebugView(int level, boolean enabled){\n\t\tif(showDebugLevel!=null)\n\t\t\tshowDebugLevel[level]=enabled;\n\t}\n\t//<end-adobe>\n\t/**\n\t * get pdf as Image of current page with height as required height in pixels -\n\t * Page must be decoded first - used to generate thubnails for display.\n\t * Use decodePageAsImage forcreating images of pages\n\t */\n\tfinal public BufferedImage getPageAsThumbnail(int height,DynamicVectorRenderer currentDisplay) {\n\t\tif(currentDisplay==null){\n\t\t\tcurrentDisplay=this.currentDisplay;\n\t\t\t/**\n\t\t\t * save to disk\n\t\t\t */\n\t\t\tObjectStore.cachePage(new Integer(pageNumber), currentDisplay);\n\t\t}\n\t\tBufferedImage image = getImageFromRenderer(height,currentDisplay,pageNumber);\n\t\treturn image;\n\t}\n\t/**\n\t */\n\tprotected BufferedImage getImageFromRenderer(int height,DynamicVectorRenderer rend,int pageNumber) {\n\t\t//int mediaBoxW = pageData.getMediaBoxWidth(pageNumber);\n\t\tint mediaBoxH = pageData.getMediaBoxHeight(pageNumber);\n\t\tint mediaBoxX = pageData.getMediaBoxX(pageNumber);\n\t\tint mediaBoxY = pageData.getMediaBoxY(pageNumber);\n\t\tint crw=pageData.getCropBoxWidth(pageNumber);\n\t\tint crh=pageData.getCropBoxHeight(pageNumber);\n\t\tint crx=pageData.getCropBoxX(pageNumber);\n\t\tint cry=pageData.getCropBoxY(pageNumber);\n\t\tif(cry>0)\n\t\t\tcry=mediaBoxH-crh-cry;\n\t\tfloat scale=(float) height/(crh);\n\t\tint rotation=pageData.getRotation(pageNumber);\n\t\t/**allow for rotation*/\n\t\tint dr=-1;\n\t\tif((rotation==90)|(rotation==270)){\n\t\t\tint tmp=crw;\n\t\t\tcrw=crh;\n\t\t\tcrh=tmp;\n\t\t\tdr=1;\n\t\t\ttmp=crx;\n\t\t\tcrx=cry;\n\t\t\tcry=tmp;\n\t\t}\n\t\tAffineTransform scaleAf = getScalingForImage(pageNumber,rotation,scale);//(int)(mediaBoxW*scale), (int)(mediaBoxH*scale),\n\t\tint cx=mediaBoxX-crx,cy=mediaBoxY-cry;\n\t\tscaleAf.translate(cx,dr*cy);\n\t\treturn rend.getPageAsImage(scale,crx,cry,crw,crh,pageNumber,scaleAf,BufferedImage.TYPE_INT_RGB);\n\t}\n\t//<start-adobe>\n\t/**set zones we want highlighted onscreen\n\t * @deprecated\n\t * please look at  setFoundTextAreas(Rectangle areas),setHighlightedAreas(Rectangle[] areas)\n\t * <b>This is NOT part of the API</b> (used in Storypad)\n\t */\n\tfinal public void setHighlightedZones(\n\t\t\tint mode,\n\t\t\tint[] cx,int[] cy,\n\t\t\tShape[] fragmentShapes,\n\t\t\tObject[] linkedItems,\n\t\t\tint[] parents,\n\t\t\tObject[] childItems,\n\t\t\tint[] childParents,\n\t\t\tRectangle2D[] outlineZone,\n\t\t\tboolean[] highlightedZonesSelected,boolean[] hasDrownedObjects,Color[] highlightColors,int[] selectionOrder,int[] processedByRegularExpression) {\n\t\tthis.cx=cx;\n\t\tthis.cy=cy;\n\t\tthis.fragmentShapes=fragmentShapes;\n\t\tthis.linkedItems=linkedItems;\n\t\tthis.parents=parents;\n\t\tthis.children=childItems;\n\t\tthis.outlineZone = outlineZone;\n\t\tthis.processedByRegularExpression=processedByRegularExpression;\n\t\tthis.highlightedZonesSelected = highlightedZonesSelected;\n\t\tthis.hasDrownedObjects = hasDrownedObjects;\n\t\tthis.highlightMode = mode;\n\t\tthis.highlightColors=highlightColors;\n\t\tthis.selectionOrder=selectionOrder;\n\t\t//and deselect alt highlights\n\t\tthis.alternateOutlines=null;\n\t}\n\t/**set merging option for Storypad (not part of API)*/\n\tpublic void setDebugDisplay(boolean isEnabled){\n\t\tthis.showMerging=isEnabled;\n\t}\n\t/**\n\t * set an inset display so that display will not touch edge of panel*/\n\tfinal public void setInset(int width,int height) {\n\t\tthis.insetW=width;\n\t\tthis.insetH=height;\n\t}\n\t/**\n\t * make screen scroll to ensure point is visible\n\t */\n\tpublic void ensurePointIsVisible(Point p){\n\t\tsuper.scrollRectToVisible(new Rectangle(p.x,y_size-p.y,scrollInterval,scrollInterval));\n\t}\n\t//<end-adobe>\n\t/**\n\t * get sizes of panel <BR>\n\t * This is the PDF pagesize (as set in the PDF from pagesize) -\n\t * It now includes any scaling factor you have set (ie a PDF size 800 * 600\n\t * with a scaling factor of 2 will return 1600 *1200)\n\t */\n\tfinal public Dimension getMaximumSize() {\n\t\tDimension pageSize=null;\n\t\tif(displayView!=Display.SINGLE_PAGE)\n\t\t\tpageSize = pages.getPageSize(displayView);\n\t\tif(pageSize==null){\n\t\t\tif((displayRotation==90)|(displayRotation==270))\n\t\t\t\tpageSize= new Dimension((int)(y_size_cropped+insetW+insetW+(xOffset*scaling)+(additionalPageCount*(insetW+insetW))),x_size_cropped+insetH+insetH);\n\t\t\telse\n\t\t\t\tpageSize= new Dimension((int)(x_size_cropped+insetW+insetW+(xOffset*scaling)+(additionalPageCount*(insetW+insetW))),y_size_cropped+insetH+insetH);\n\t\t}\n        if(pageSize==null)\n        pageSize=getMinimumSize();\n        return pageSize;\n\t}\n\t/**\n\t * get width*/\n\tfinal public Dimension getMinimumSize() {\n\t\treturn new Dimension(100+insetW,100+insetH);\n\t}\n\t/**\n\t * get sizes of panel <BR>\n\t * This is the PDF pagesize (as set in the PDF from pagesize) -\n\t * It now includes any scaling factor you have set (ie a PDF size 800 * 600\n\t * with a scaling factor of 2 will return 1600 *1200)\n\t */\n\tpublic Dimension getPreferredSize() {\n\t\treturn getMaximumSize();\n\t}\n\t\n\tpublic Rectangle[] getHighlightedAreas(){\n\t\tif(areas==null)\n\t\t\treturn null;\n\t\telse{\n\t\t\tint count=areas.length;\n\t\t\tRectangle[] returnValue=new Rectangle[count];\n\t\t\tfor(int ii=0;ii<count;ii++){\n\t\t\t\tif(areas[ii]==null)\n\t\t\t\t\treturnValue[ii]=null;\n\t\t\t\telse\n\t\t\t\t\treturnValue[ii]=new Rectangle(areas[ii].x,areas[ii].y,\n\t\t\t\t\t\t\tareas[ii].width,areas[ii].height);\n\t\t\t}\n\t\t\treturn returnValue;\n\t\t}\n\t}\n\t\n\t/**\n\t * Highlights a section of lines that form a paragraph\n\t */\n\tpublic Rectangle setFoundParagraph(int x, int y){\n\t\tRectangle[] lines = PdfHighlights.getLineAreas();\n\t\tif(lines!=null){\n\t\t\tRectangle point = new Rectangle(x,y,1,1);\n\t\t\tRectangle current = new Rectangle(0,0,0,0);\n\t\t\tboolean lineFound = false;\n\t\t\tint selectedLine = 0;\n\t\t\tfor(int i=0; i!=lines.length; i++){\n\t\t\t\tif(lines[i].intersects(point)){\n\t\t\t\t\tselectedLine = i;\n\t\t\t\t\tlineFound = true;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif(lineFound){\n\t\t\t\tdouble left = lines[selectedLine].x;\n\t\t\t\tdouble cx = lines[selectedLine].getCenterX();\n\t\t\t\tdouble right = lines[selectedLine].x+lines[selectedLine].width;\n\t\t\t\tdouble cy = lines[selectedLine].getCenterY();\n\t\t\t\tint h = lines[selectedLine].height;\n\t\t\t\tcurrent.x=lines[selectedLine].x;\n\t\t\t\tcurrent.y=lines[selectedLine].y;\n\t\t\t\tcurrent.width=lines[selectedLine].width;\n\t\t\t\tcurrent.height=lines[selectedLine].height;\n\t\t\t\tboolean foundTop = true;\n\t\t\t\tboolean foundBottom = true;\n\t\t\t\tVector_Rectangle selected = new Vector_Rectangle(0);\n\t\t\t\tselected.addElement(lines[selectedLine]);\n\t\t\t\twhile(foundTop){\n\t\t\t\t\tfoundTop = false;\n\t\t\t\t\tfor(int i=0; i!=lines.length; i++){\n\t\t\t\t\t\tif(lines[i].contains(left, cy+h) || lines[i].contains(cx, cy+h) || lines[i].contains(right, cy+h)){\n\t\t\t\t\t\t\tselected.addElement(lines[i]);\n\t\t\t\t\t\t\tfoundTop = true;\n\t\t\t\t\t\t\tcy = lines[i].getCenterY();\n\t\t\t\t\t\t\th = lines[i].height;\n\t\t\t\t\t\t\tif(current.x>lines[i].x){\n\t\t\t\t\t\t\t\tcurrent.width = (current.x+current.width)-lines[i].x;\n\t\t\t\t\t\t\t\tcurrent.x = lines[i].x;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif((current.x+current.width)<(lines[i].x+lines[i].width))\n\t\t\t\t\t\t\t\tcurrent.width = (lines[i].x+lines[i].width)-current.x;\n\t\t\t\t\t\t\tif(current.y>lines[i].y){\n\t\t\t\t\t\t\t\tcurrent.height = (current.y+current.height)-lines[i].y;\n\t\t\t\t\t\t\t\tcurrent.y = lines[i].y;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif((current.y+current.height)<(lines[i].y+lines[i].height)){\n\t\t\t\t\t\t\t\tcurrent.height = (lines[i].y+lines[i].height)-current.y;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t//Return to selected item else we have duplicate highlights\n\t\t\t\tleft = lines[selectedLine].x;\n", "outputs": ["\t\t\t\tcx = lines[selectedLine].getCenterX();"], "input_length": 3321, "output_length": 10, "length": 3331, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "5328ef6b5109b2ae4a442cd4c8f068033a42d7e8be7f7c67c07e0c53924d8f18"}
{"input": "", "context": "/*******************************************************************************\n * Copyright (c) 1998, 2012 Oracle and/or its affiliates. All rights reserved.\n * This program and the accompanying materials are made available under the\n * terms of the Eclipse Public License v1.0 and Eclipse Distribution License v. 1.0\n * which accompanies this distribution.\n * The Eclipse Public License is available at http://www.eclipse.org/legal/epl-v10.html\n * and the Eclipse Distribution License is available at\n * http://www.eclipse.org/org/documents/edl-v10.php.\n *\n * Contributors:\n *     Oracle - initial API and implementation from Oracle TopLink\n ******************************************************************************/\npackage org.eclipse.persistence.sdo.helper;\nimport java.util.ArrayList;\nimport java.util.Collection;\nimport java.util.HashMap;\nimport java.util.Iterator;\nimport java.util.Map;\nimport javax.xml.namespace.QName;\nimport javax.xml.transform.Source;\nimport org.eclipse.persistence.exceptions.SDOException;\nimport org.eclipse.persistence.internal.helper.ClassConstants;\nimport org.eclipse.persistence.internal.oxm.XMLConversionManager;\nimport org.eclipse.persistence.internal.oxm.schema.SchemaModelProject;\nimport org.eclipse.persistence.internal.oxm.schema.model.All;\nimport org.eclipse.persistence.internal.oxm.schema.model.Annotation;\nimport org.eclipse.persistence.internal.oxm.schema.model.Any;\nimport org.eclipse.persistence.internal.oxm.schema.model.Attribute;\nimport org.eclipse.persistence.internal.oxm.schema.model.AttributeGroup;\nimport org.eclipse.persistence.internal.oxm.schema.model.Choice;\nimport org.eclipse.persistence.internal.oxm.schema.model.ComplexContent;\nimport org.eclipse.persistence.internal.oxm.schema.model.ComplexType;\nimport org.eclipse.persistence.internal.oxm.schema.model.Element;\nimport org.eclipse.persistence.internal.oxm.schema.model.Extension;\nimport org.eclipse.persistence.internal.oxm.schema.model.Group;\nimport org.eclipse.persistence.internal.oxm.schema.model.Import;\nimport org.eclipse.persistence.internal.oxm.schema.model.Include;\nimport org.eclipse.persistence.internal.oxm.schema.model.List;\nimport org.eclipse.persistence.internal.oxm.schema.model.NestedParticle;\nimport org.eclipse.persistence.internal.oxm.schema.model.Occurs;\nimport org.eclipse.persistence.internal.oxm.schema.model.Restriction;\nimport org.eclipse.persistence.internal.oxm.schema.model.Schema;\nimport org.eclipse.persistence.internal.oxm.schema.model.Sequence;\nimport org.eclipse.persistence.internal.oxm.schema.model.SimpleComponent;\nimport org.eclipse.persistence.internal.oxm.schema.model.SimpleContent;\nimport org.eclipse.persistence.internal.oxm.schema.model.SimpleType;\nimport org.eclipse.persistence.internal.oxm.schema.model.TypeDefParticle;\nimport org.eclipse.persistence.internal.oxm.schema.model.Union;\nimport org.eclipse.persistence.oxm.NamespaceResolver;\nimport org.eclipse.persistence.oxm.XMLConstants;\nimport org.eclipse.persistence.oxm.XMLContext;\nimport org.eclipse.persistence.oxm.XMLDescriptor;\nimport org.eclipse.persistence.oxm.XMLUnmarshaller;\nimport org.eclipse.persistence.sdo.SDOConstants;\nimport org.eclipse.persistence.sdo.SDOProperty;\nimport org.eclipse.persistence.sdo.SDOType;\nimport org.eclipse.persistence.sdo.helper.extension.SDOUtil;\nimport org.eclipse.persistence.sdo.types.SDODataType;\nimport org.eclipse.persistence.sdo.types.SDOWrapperType;\nimport org.eclipse.persistence.sessions.Project;\nimport commonj.sdo.Property;\nimport commonj.sdo.Type;\nimport commonj.sdo.helper.HelperContext;\n/**\n * <p><b>Purpose</b>: Called from XSDHelper define methods to generate SDO Types from a Schema\n *\n * @see commonj.sdo.XSDHelper\n */\npublic class SDOTypesGenerator {\n    private Project schemaProject;\n    private Schema rootSchema;\n    private HashMap processedComplexTypes;\n    private HashMap processedSimpleTypes;\n    private HashMap processedElements;\n    private HashMap processedAttributes;\n    private Map itemNameToSDOName;\n    private boolean processImports;\n    private boolean returnAllTypes;\n    private java.util.List<NamespaceResolver> namespaceResolvers;\n    private boolean inRestriction;\n    // hold the context containing all helpers so that we can preserve inter-helper relationships\n    private HelperContext aHelperContext;\n    private java.util.List<SDOType> anonymousTypes;\n    private java.util.Map<QName, Type> generatedTypes;\n    private java.util.Map<QName, SDOType> generatedTypesByXsdQName;\n    private java.util.Map<QName, Property> generatedGlobalElements;\n    private java.util.Map<QName, Property> generatedGlobalAttributes;\n    private String packageName;\n    private java.util.List<NonContainmentReference> nonContainmentReferences;\n    private Map<Type, java.util.List<GlobalRef>> globalRefs;\n    private boolean isImportProcessor;\n    public SDOTypesGenerator(HelperContext aContext) {\n        anonymousTypes = new ArrayList<SDOType>();\n        generatedTypesByXsdQName = new HashMap<QName, SDOType>();\n        processedComplexTypes = new HashMap();\n        processedSimpleTypes = new HashMap();\n        processedElements = new HashMap();\n        processedAttributes = new HashMap();\n        itemNameToSDOName = new HashMap();\n        namespaceResolvers = new ArrayList();\n        this.aHelperContext = aContext;\n    }\n    public java.util.List<Type> define(Source xsdSource, SchemaResolver schemaResolver) {\n        return define(xsdSource, schemaResolver, false, true);\n    }\n    public java.util.List<Type> define(Source xsdSource, SchemaResolver schemaResolver, boolean includeAllTypes, boolean processImports) {\n        Schema schema = getSchema(xsdSource, schemaResolver);\n        return define(schema, includeAllTypes, processImports);\n    }\n    public java.util.List<Type> define(Schema schema, boolean includeAllTypes, boolean processImports) {\n        // Initialize the List of Types before we process the schema\n        java.util.List<Type> returnList = new ArrayList<Type>();\n        setReturnAllTypes(includeAllTypes);\n        setProcessImports(processImports);\n        processSchema(schema);\n        returnList.addAll(getGeneratedTypes().values());\n        returnList.addAll(anonymousTypes);\n        if (!this.isImportProcessor()) {\n            java.util.List descriptorsToAdd = new ArrayList(returnList);\n            Iterator<Type> iter = descriptorsToAdd.iterator();\n            while (iter.hasNext()) {\n                SDOType nextSDOType = (SDOType) iter.next();\n                if (!nextSDOType.isFinalized()) {\n                    //Only throw this error if we're not processing an import.\n                    throw SDOException.typeReferencedButNotDefined(nextSDOType.getURI(), nextSDOType.getName());\n                }\n                Iterator<Property> propertiesIter = nextSDOType.getProperties().iterator();\n                while (propertiesIter.hasNext()) {\n                    SDOProperty prop = (SDOProperty) propertiesIter.next();\n                    if (prop.getType().isDataType() && prop.isContainment()) {\n                        // If isDataType is true, then isContainment has to be false.\n                        // This property was likely created as a stub, and isContainment never got reset\n                        // when the property was fully defined.\n                        // This problem was uncovered in bug 6809767\n                        prop.setContainment(false);\n                    }\n                }\n            }\n            Iterator<Property> propertiesIter = getGeneratedGlobalElements().values().iterator();\n            while (propertiesIter.hasNext()) {\n                SDOProperty nextSDOProperty = (SDOProperty) propertiesIter.next();\n                if (!nextSDOProperty.isFinalized()) {\n                    //Only throw this error if we're not processing an import.\n                    throw SDOException.referencedPropertyNotFound(nextSDOProperty.getUri(), nextSDOProperty.getName());\n                }\n            }\n            propertiesIter = getGeneratedGlobalAttributes().values().iterator();\n            while (propertiesIter.hasNext()) {\n                SDOProperty nextSDOProperty = (SDOProperty) propertiesIter.next();\n                if (!nextSDOProperty.isFinalized()) {\n                    //Only throw this error if we're not processing an import.\n                    throw SDOException.referencedPropertyNotFound(nextSDOProperty.getUri(), nextSDOProperty.getName());\n                }\n            }\n            iter = getGeneratedTypes().values().iterator();\n            //If we get here all types were finalized correctly\n            while (iter.hasNext()) {\n                SDOType nextSDOType = (SDOType) iter.next();\n                ((SDOTypeHelper) aHelperContext.getTypeHelper()).addType(nextSDOType);\n            }\n            Iterator anonymousIterator = getAnonymousTypes().iterator();\n            while (anonymousIterator.hasNext()) {\n                SDOType nextSDOType = (SDOType) anonymousIterator.next();\n                ((SDOTypeHelper) aHelperContext.getTypeHelper()).getAnonymousTypes().add(nextSDOType);\n            }\n            // add any base types to the list\n            for (int i=0; i<descriptorsToAdd.size(); i++) {\n                SDOType nextSDOType = (SDOType) descriptorsToAdd.get(i);\n                if (!nextSDOType.isDataType() && !nextSDOType.isSubType() && nextSDOType.isBaseType()) {\n                    nextSDOType.setupInheritance(null);\n                } else if (!nextSDOType.isDataType() && nextSDOType.isSubType() && !getGeneratedTypes().values().contains(nextSDOType.getBaseTypes().get(0))) {\n                    SDOType baseType = (SDOType) nextSDOType.getBaseTypes().get(0);\n                    while (baseType != null) {\n                        descriptorsToAdd.add(baseType);\n                        if (baseType.getBaseTypes().size() == 0) {\n                            // baseType should now be root of inheritance\n                            baseType.setupInheritance(null);\n                            baseType = null;\n                        } else {\n                            baseType = (SDOType) baseType.getBaseTypes().get(0);\n                        }\n                    }\n                }\n            }\n            \n            ((SDOXMLHelper) aHelperContext.getXMLHelper()).addDescriptors(descriptorsToAdd);\n            //go through generatedGlobalProperties and add to xsdhelper\n            Iterator<QName> qNameIter = getGeneratedGlobalElements().keySet().iterator();\n            while (qNameIter.hasNext()) {\n                QName nextQName = qNameIter.next();\n                SDOProperty nextSDOProperty = (SDOProperty) getGeneratedGlobalElements().get(nextQName);\n                ((SDOXSDHelper) aHelperContext.getXSDHelper()).addGlobalProperty(nextQName, nextSDOProperty, true);\n            }\n            qNameIter = getGeneratedGlobalAttributes().keySet().iterator();\n            while (qNameIter.hasNext()) {\n                QName nextQName = qNameIter.next();\n                SDOProperty nextSDOProperty = (SDOProperty) getGeneratedGlobalAttributes().get(nextQName);\n                ((SDOXSDHelper) aHelperContext.getXSDHelper()).addGlobalProperty(nextQName, nextSDOProperty, false);\n            }\n            Iterator<java.util.List<GlobalRef>> globalRefsIter = getGlobalRefs().values().iterator();\n            while (globalRefsIter.hasNext()) {\n                java.util.List<GlobalRef> nextList = globalRefsIter.next();\n                if (nextList.size() > 0) {\n                    GlobalRef ref = nextList.get(0);\n                    throw SDOException.referencedPropertyNotFound(((SDOProperty) ref.getProperty()).getUri(), ref.getProperty().getName());\n                }\n            }\n        }\n        return returnList;\n    }\n    private void processSchema(Schema parsedSchema) {\n        rootSchema = parsedSchema;\n        initialize();\n        namespaceResolvers.add(rootSchema.getNamespaceResolver());\n        processIncludes(rootSchema.getIncludes());\n        processImports(rootSchema.getImports());\n        preprocessGlobalTypes(rootSchema);\n        processGlobalAttributes(rootSchema);\n        processGlobalElements(rootSchema);\n        processGlobalSimpleTypes(rootSchema);\n        processGlobalComplexTypes(rootSchema);\n        postProcessing();\n    }\n    private void processImports(java.util.List imports) {\n        if ((imports == null) || (imports.size() == 0) || !isProcessImports()) {\n            return;\n        }\n        Iterator iter = imports.iterator();\n        while (iter.hasNext()) {\n            Import nextImport = (Import) iter.next();\n            try {\n                processImportIncludeInternal(nextImport);\n            } catch (Exception e) {\n                throw SDOException.errorProcessingImport(nextImport.getSchemaLocation(), nextImport.getNamespace(), e);\n            }\n        }\n    }\n    private void processIncludes(java.util.List includes) {\n        if ((includes == null) || (includes.size() == 0) || !isProcessImports()) {\n            return;\n        }\n        Iterator iter = includes.iterator();\n        while (iter.hasNext()) {\n            Include nextInclude = (Include) iter.next();\n            try {\n                processImportIncludeInternal(nextInclude);\n            } catch (Exception e) {\n                throw SDOException.errorProcessingInclude(nextInclude.getSchemaLocation(), e);\n            }\n        }\n    }\n    /**\n     * INTERNAL:\n     * This function is referenced by processImport or processInclude possibly recursively\n     * @param Include theImportOrInclude\n     * @throws Exception\n     */\n    private void processImportIncludeInternal(Include theImportOrInclude) throws Exception {\n        if (theImportOrInclude.getSchema() != null) {\n            SDOTypesGenerator generator = new SDOTypesGenerator(aHelperContext);\n            generator.setAnonymousTypes(getAnonymousTypes());\n            generator.setGeneratedTypes(getGeneratedTypes());\n            generator.setGeneratedTypesByXsdQName(getGeneratedTypesByXsdQName());\n            generator.setGeneratedGlobalElements(getGeneratedGlobalElements());\n            generator.setGeneratedGlobalAttributes(getGeneratedGlobalAttributes());\n            // Both imports and includes are treated the same when checking for a mid-schema tree walk state\n            generator.setIsImportProcessor(true);\n            // May throw an IAE if a global type: local part cannot be null when creating a QName\n            java.util.List<Type> importedTypes = generator.define(theImportOrInclude.getSchema(), isReturnAllTypes(), isProcessImports());\n            processedComplexTypes.putAll(generator.processedComplexTypes);\n            processedSimpleTypes.putAll(generator.processedSimpleTypes);\n            processedElements.putAll(generator.processedElements);\n            processedAttributes.putAll(generator.processedAttributes);\n            if (null != importedTypes) {\n                for (int i = 0, size = importedTypes.size(); i < size; i++) {\n                    SDOType nextType = (SDOType) importedTypes.get(i);\n                    getGeneratedTypes().put(nextType.getQName(), nextType);\n                }\n            }\n            //copy over any global properties\n            Iterator<QName> globalPropsIter = generator.getGeneratedGlobalElements().keySet().iterator();\n            while (globalPropsIter.hasNext()) {\n                QName nextKey = globalPropsIter.next();\n                getGeneratedGlobalElements().put(nextKey, generator.getGeneratedGlobalElements().get(nextKey));\n            }\n            globalPropsIter = generator.getGeneratedGlobalAttributes().keySet().iterator();\n            while (globalPropsIter.hasNext()) {\n                QName nextKey = globalPropsIter.next();\n                getGeneratedGlobalAttributes().put(nextKey, generator.getGeneratedGlobalAttributes().get(nextKey));\n            }\n            //copy over any unfinished globalRefs\n            Iterator<Type> globalRefsIter = generator.getGlobalRefs().keySet().iterator();\n            while (globalRefsIter.hasNext()) {\n                Type nextKey = globalRefsIter.next();\n                getGlobalRefs().put(nextKey, generator.getGlobalRefs().get(nextKey));\n            }\n        }\n    }\n    private boolean typesExists(String targetNamespace, String sdoTypeName) {\n        boolean alreadyProcessed = false;\n        if ((targetNamespace != null) && (targetNamespace.equals(SDOConstants.SDOJAVA_URL) || targetNamespace.equals(SDOConstants.SDO_URL) || targetNamespace.equals(SDOConstants.SDOXML_URL))) {\n            alreadyProcessed = true;\n        } else {\n            QName qname = new QName(targetNamespace, sdoTypeName);\n            Object processed = processedComplexTypes.get(qname);\n            if (processed != null) {\n                alreadyProcessed = true;\n            }\n        }\n        if (!alreadyProcessed) {\n            SDOType lookup = (SDOType) aHelperContext.getTypeHelper().getType(targetNamespace, sdoTypeName);\n            if ((lookup != null) && lookup.isFinalized()) {\n                if (isReturnAllTypes()) {\n                    QName qname = new QName(targetNamespace, sdoTypeName);\n                    getGeneratedTypes().put(qname, lookup);\n                }\n                return true;\n            } else if (lookup == null) {\n", "outputs": ["                QName qname = new QName(targetNamespace, sdoTypeName);"], "input_length": 2357, "output_length": 11, "length": 2368, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "7db0d69f11410617056105b6347ce0d008e5491a6e53d4a348cb275459b9a97c"}
{"input": "", "context": "//--- Aura Script -----------------------------------------------------------\n// Aranwen\n//--- Description -----------------------------------------------------------\n// Teacher\n//---------------------------------------------------------------------------\npublic class AranwenScript : NpcScript\n{\n\tpublic override void Load()\n\t{\n\t\tSetName(\"_aranwen\");\n\t\tSetRace(10001);\n\t\tSetBody(height: 1.15f, weight: 0.9f, upper: 1.1f, lower: 0.8f);\n\t\tSetFace(skinColor: 15, eyeType: 3, eyeColor: 192);\n\t\tSetLocation(14, 43378, 40048, 125);\n\t\tEquipItem(Pocket.Face, 3900, 0x00344300, 0x0000163E, 0x008B0021);\n\t\tEquipItem(Pocket.Hair, 3026, 0x00BDC2E5, 0x00BDC2E5, 0x00BDC2E5);\n\t\tEquipItem(Pocket.Armor, 13008, 0x00C6D8EA, 0x00C6D8EA, 0x00635985);\n\t\tEquipItem(Pocket.Glove, 16503, 0x00C6D8EA, 0x00B20859, 0x00A7131C);\n\t\tEquipItem(Pocket.Shoe, 17504, 0x00C6D8EA, 0x00C6D8EA, 0x003F6577);\n\t\tEquipItem(Pocket.RightHand1, 40012, 0x00C0C0C0, 0x008C84A4, 0x00403C47);\n        \n\t\tAddPhrase(\"...\");\n\t\tAddPhrase(\"A sword does not betray its own will.\");\n\t\tAddPhrase(\"A sword is not a stick. I don't feel any tension from you!\");\n\t\tAddPhrase(\"Aren't you well?\");\n\t\tAddPhrase(\"Focus when you're practicing.\");\n\t\tAddPhrase(\"Hahaha.\");\n\t\tAddPhrase(\"If you're done resting, let's keep practicing!\");\n\t\tAddPhrase(\"It's those people who really need to learn swordsmanship.\");\n\t\tAddPhrase(\"Put more into the wrists!\");\n\t\tAddPhrase(\"That student may need to rest a while.\");\n\t}\n    \n\tprotected override async Task Talk()\n\t{\n\t\tSetBgm(\"NPC_Aranwen.mp3\");\n\t\tawait Intro(\n\t\t\t\"A lady decked out in shining armor is confidently training students in swordsmanship in front of the school.\",\n\t\t\t\"Unlike a typical swordswoman, her moves seem delicate and elegant.\",\n\t\t\t\"Her long, braided silver hair falls down her back, leaving her eyes sternly fixed on me.\"\n\t\t);\n\t\tMsg(\"What brings you here?\", Button(\"Start a Conversation\", \"@talk\"), Button(\"Shop\", \"@shop\"), Button(\"Modify Item\", \"@upgrade\"));\n\t\tswitch (await Select()) \n\t\t{\n\t\t\tcase \"@talk\":\n\t\t\t\tMsg(\"Hmm. <username/>, right?<br/>Of course.\");\n\t\t\t\t// Msg(\"Hmm. <username/>, right?\");\n\t\t\t\t// Msg(\"Yes? Please don't block my view.\");\n\t\t\t\t// if the player is wearing the Savior of Erinn title, she will say this after the first message\n\t\t\t\t// Msg(\"Guardian of Erinn...<br/>If it were anyone else,<br/>I would tell them to stop being so arrogant...\");\n\t\t\t\t// Msg(\"But with you, <username/>, you are definitely qualified.<br/>Good job.\");\n\t\t\t\tawait StartConversation();\n\t\t\t\tbreak;\n\t\t\tcase \"@shop\":\n\t\t\t\tMsg(\"Are you looking for a party quest scroll?\");\n\t\t\t\tOpenShop(\"AranwenShop\");\n\t\t\t\tbreak;\n\t\t\tcase \"@upgrade\":\n\t\t\t\tMsg(\"Please select the weapon you'd like to modify.<br/>Each weapon can be modified according to its kind.<upgrade />\");\n\t\t\t\tMsg(\"Unimplemented\");\n\t\t\t\tMsg(\"A bow is weaker than a crossbow?<br/>That's because you don't know a bow very well.<br/>Crossbows are advanced weapons for sure,<br/>but a weapon that reflects your strength and senses is closer to nature than machinery.\");\n\t\t\t\tbreak;\n\t\t}\n\t}\n\tprotected override async Task Keywords(string keyword) \n\t{\n\t\tswitch (keyword) {\n\t\t\tcase \"personal_info\":\n\t\t\t\tMsg(\"Let me introduce myself.<br/>My name is Aranwen. I teach combat skills at the Dunbarton School.\");\n\t\t\t\tbreak;\n\t\t\tcase \"rumor\":\n\t\t\t\tMsg(\"If you need a weapon for the training,<br/>why don't you go see Nerys in the south side?<br/>She runs the Weapons Shop.\");\n\t\t\t\tbreak;\n\t\t\tcase \"about_skill\":\n\t\t\t\tMsg(\"...I am sorry, but someone that has yet to master the skill<br/>should not be bluntly asking questions about skills like this.\");\n\t\t\t\tMsg(\"...if you are interested in high-leveled bowman skills, then<br/>you should at least master the Fire Arrow skill first.\");\n\t\t\t\tbreak;\n\t\t\tcase \"shop_misc\": // General Shop\n\t\t\t\tMsg(\"Hmm. Looking for the General Shop?<br/>You'll find it down there across the Square.\");\n\t\t\t\tMsg(\"Walter should be standing by the door.<br/>You can buy instruments, music scores, gifts, and tailoring goods such as sewing patterns.\");\n\t\t\t\tbreak;\n\t\t\tcase \"shop_grocery\":\n\t\t\t\tMsg(\"If you are looking to buy cooking ingredients,<br/>the Restaurant will be your best bet.\");\n\t\t\t\tbreak;\n\t\t\tcase \"shop_healing\":\n\t\t\t\tMsg(\"A Healer's House? Are you looking for Manus?<br/>Manus runs a Healer's House near<br/>the Weapons Shop in the southern part of town.\");\n\t\t\t\tMsg(\"Even if you're not ill<br/>and you're simply looking for things like potions,<br/>that's the place to go.\");\n\t\t\t\tbreak;\n\t\t\tcase \"shop_inn\":\n\t\t\t\tMsg(\"There is no inn in this town.\");\n\t\t\t\tbreak;\n\t\t\tcase \"shop_bank\":\n\t\t\t\tMsg(\"If you're looking for a bank, you can go to<br/>the Erskin Bank in the west end of the Square.<br/>Talk to Austeyn there for anything involving money or items.\");\n\t\t\t\tbreak;\n\t\t\tcase \"shop_smith\":\n\t\t\t\tMsg(\"There is no blacksmith's shop in this town, but<br/>if you are looking for anything like weapons or armor,<br/>why don't you head south and visit the Weapons Shop?\");\n\t\t\t\tbreak;\n\t\t\tcase \"skill_range\":\n\t\t\t\tMsg(\"I suppose I could take my time and verbally explain it to you,<br/>but you should be able to quickly get the hang of it<br/>once you equip and use a bow a few times.\");\n\t\t\t\tbreak;\n\t\t\tcase \"skill_tailoring\":\n\t\t\t\tMsg(\"It would be most logical to get Simon's help<br/>at the Clothing Shop.\");\n\t\t\t\tbreak;\n\t\t\tcase \"skill_magnum_shot\":\n\t\t\t\tMsg(\"Magnum Shot?<br/>Haven't you learned such a basic skill alrerady?<br/>You must seriously lack training.\");\n\t\t\t\tMsg(\"It may be rather time-consuming, but<br/>please go back to Tir Chonaill.<br/>Ranald will teach you the skill.\");\n\t\t\t\tbreak;\n\t\t\tcase \"skill_counter_attack\":\n\t\t\t\tMsg(\"If you don't know the Counterattack skill yet, that is definitely a problem.<br/>Very well. First, you'll need to fight a powerful monster and get hit by its Counterattack.\");\n\t\t\t\tMsg(\"Monsters like bears use Counterattack<br/>so watch how they use it and take a hit,<br/>and you should be able to quickly get the hang of it without any particular training.\");\n\t\t\t\tMsg(\"In fact, if you are not willing to take the hit,<br/>there is no other way to learn that skill.<br/>Simply reading books will not help.\");\n\t\t\t\tbreak;\n\t\t\tcase \"skill_smash\":\n\t\t\t\tMsg(\"Smash...<br/>For the Smash skill, why don't you go to the Bookstore and<br/>look for a book on it?\");\n\t\t\t\tMsg(\"You should learn it by yourself before bothering<br/>people with questions.<br/>You should be ashamed of yourself.\");\n\t\t\t\tbreak;\n\t\t\tcase \"square\":\n\t\t\t\tMsg(\"The Square is just over here.<br/>Perhaps it totally escaped you<br/>because it's so large.\");\n\t\t\t\tbreak;\n\t\t\tcase \"farmland\":\n\t\t\t\tMsg(\"Strangely, large rats have been seen<br/>in large numbers in the farmlands recently.<br/>This obviously isn't normal.\");\n\t\t\t\tMsg(\"If you are willing,<br/>would you go and take some out?<br/>You'll be appreciated by many.\");\n\t\t\t\tbreak;\n\t\t\tcase \"brook\": // Adelia Stream\n\t\t\t\tMsg(\"Adelia Stream...<br/>I believe you're speaking of the<br/>stream in Tir Chonaill...\");\n\t\t\t\tMsg(\"Shouldn't you be asking<br/>these questions<br/>in Tir Chonaill?\");\n\t\t\t\tbreak;\n\t\t\tcase \"shop_headman\": // Chief's House\n\t\t\t\tMsg(\"A chief?<br/>This town is ruled by a Lord,<br/>so there is no such person as a chief here.\");\n\t\t\t\tbreak;\n\t\t\tcase \"temple\": // Church\n\t\t\t\tMsg(\"You must have something to discuss with Priestess Kristell.<br/>You'll find her at the Church up north.\");\n\t\t\t\tMsg(\"You can also take the stairs that head<br/>northwest to the Square.<br/>There are other ways to get there, too,<br/>so it shouldn't be too difficult to find it.\");\n\t\t\t\tbreak;\n\t\t\tcase \"school\":\n\t\t\t\tMsg(\"Mmm? This is the only school around here.\");\n\t\t\t\tbreak;\n\t\t\tcase \"skill_windmill\":\n\t\t\t\tPlayer.Keywords.Remove(\"skill_windmill\");\n\t\t\t\tMsg(\"Are you curious about the Windmill skill?<br/>It is a useful skill to have when you're surrounded by enemies.<br/>Very well. I will teach you the Windmill skill.\");\n\t\t\t\tbreak;\n\t\t\tcase \"shop_restaurant\":\n\t\t\t\tMsg(\"If you're looking for a restaurant, you are looking for Glenis' place.<br/>She not only sells food, but also a lot of cooking ingredients, so<br/>you should pay a visit if you need something.\");\n\t\t\t\tMsg(\"The Restaurant is in the north alley of the Square.\");\n\t\t\t\tbreak;\n\t\t\tcase \"shop_armory\": // Weapon Shop\n\t\t\t\tMsg(\"Nerys is the owner of the Weapons Shop.<br/>Keep following the road that leads down south<br/>and you'll see her mending weapons outside.\");\n\t\t\t\tMsg(\"She may seem a little aloof,<br/>but don't let that get to you too much<br/>and you'll get used to it.\");\n\t\t\t\tbreak;\n\t\t\tcase \"shop_cloth\":\n\t\t\t\tMsg(\"There is no decent clothing shop in this town...<br/>But, if you must, go visit Simon's place.<br/>You should be able to find something that fits right away.\");\n\t\t\t\tbreak;\n\t\t\tcase \"shop_bookstore\":\n\t\t\t\tMsg(\"You mean Aeira's Bookstore.<br/>It's just around here.<br/>Follow the road in front of the school up north.\");\n\t\t\t\tMsg(\"Many types of books go through that place,<br/>so even if you don't find what you want right away,<br/>keep visiting and you'll soon get it.\");\n\t\t\t\tbreak;\n\t\t\tcase \"shop_goverment_office\": // Town Office\n\t\t\t\tMsg(\"Are you looking for Eavan?<br/>The Lord and the Captain of the Royal Guards<br/>are very hard to reach. \");\n\t\t\t\tMsg(\"If you're really looking for Eavan,<br/>go over to that large building to the north of the Square.\");\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tRndMsg(\n\t\t\t\t\t\"I don't know anything about it. I'm sorry I can't be much help.\",\n\t\t\t\t\t\"I don't know anything about it. Why don't you ask others?\",\n\t\t\t\t\t\"Being a teacher doesn't mean that I know everything.\",\n\t\t\t\t\t\"Hey! Asking me about such things is a waste of time.\",\n\t\t\t\t\t\"It doesn't seem bad but... I don't think I can help you with it.\",\n\t\t\t\t\t\"I don't know too much about anything other than combat skills.\",\n\t\t\t\t\t\"If you keep bringing up topics like this, I can't say much to you.\",\n\t\t\t\t\t\"Will you tell me about it when you find out more?\"\n\t\t\t\t);\n\t\t\t\tbreak;\n\t\t}\n\t}\n\tpublic override void EndConversation() \n\t{\n\t\tClose(\"Thank you, Aranwen. I'll see you later!\");\n\t}\n}\npublic class AranwenShop : NpcShopScript\n{\n\tpublic override void Setup()\n\t{\n\t\t//----------------\n\t\t// Party Quest\n\t\t//----------------\n\t\t// Page 1\n\t\tAdd(\"Party Quest\", 70025); // Party Quest Scroll [10 Red Bears]\n", "outputs": ["\t\tAdd(\"Party Quest\", 70025); // Party Quest Scroll [30 Red Bears]"], "input_length": 2633, "output_length": 19, "length": 2652, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "57197d5376a84201ee8074748612a878c644ee67fc7e5556b0c9272d324f8120"}
{"input": "", "context": "// Copyright (c) 2004-2008 MySQL AB, 2008-2009 Sun Microsystems, Inc.\n//\n// MySQL Connector/NET is licensed under the terms of the GPLv2\n// <http://www.gnu.org/licenses/old-licenses/gpl-2.0.html>, like most \n// MySQL Connectors. There are special exceptions to the terms and \n// conditions of the GPLv2 as it is applied to this software, see the \n// FLOSS License Exception\n// <http://www.mysql.com/about/legal/licensing/foss-exception.html>.\n//\n// This program is free software; you can redistribute it and/or modify \n// it under the terms of the GNU General Public License as published \n// by the Free Software Foundation; version 2 of the License.\n//\n// This program is distributed in the hope that it will be useful, but \n// WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY \n// or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License \n// for more details.\n//\n// You should have received a copy of the GNU General Public License along \n// with this program; if not, write to the Free Software Foundation, Inc., \n// 51 Franklin St, Fifth Floor, Boston, MA 02110-1301  USA\nusing System;\nusing System.Collections;\nusing System.Collections.Generic;\nusing System.Diagnostics;\nusing System.Threading;\nusing MySql.Data.MySqlClient.Properties;\nnamespace MySql.Data.MySqlClient\n{\n\t/// <summary>\n\t/// Summary description for MySqlPool.\n\t/// </summary>\n\tinternal sealed class MySqlPool\n\t{\n        private List<Driver> inUsePool;\n        private Queue<Driver> idlePool;\n\t\tprivate MySqlConnectionStringBuilder settings;\n\t\tprivate uint minSize;\n\t\tprivate uint maxSize;\n        private ProcedureCache procedureCache;\n        private bool beingCleared;\n        private int available;\n        private AutoResetEvent autoEvent;\n        private void EnqueueIdle(Driver driver)\n        {\n            driver.IdleSince = DateTime.Now;\n            idlePool.Enqueue(driver);\n        }\n\t\tpublic MySqlPool(MySqlConnectionStringBuilder settings)\n\t\t{\n\t\t\tminSize = settings.MinimumPoolSize;\n\t\t\tmaxSize = settings.MaximumPoolSize;\n            available = (int)maxSize;\n            autoEvent = new AutoResetEvent(false);\n            if (minSize > maxSize)\n                minSize = maxSize;\n\t\t\tthis.settings = settings;\n            inUsePool = new List<Driver>((int)maxSize);\n            idlePool = new Queue<Driver>((int)maxSize);\n\t\t\t// prepopulate the idle pool to minSize\n            for (int i = 0; i < minSize; i++)\n               EnqueueIdle(CreateNewPooledConnection());\n            procedureCache = new ProcedureCache((int)settings.ProcedureCacheSize);\n        }\n        #region Properties\n        public MySqlConnectionStringBuilder\tSettings \n\t\t{\n\t\t\tget { return settings; }\n\t\t\tset { settings = value; }\n\t\t}\n        public ProcedureCache ProcedureCache\n        {\n            get { return procedureCache; }\n        }\n        /// <summary>\n        /// It is assumed that this property will only be used from inside an active\n        /// lock.\n        /// </summary>\n        private bool HasIdleConnections\n        {\n            get { return idlePool.Count > 0; }\n        }\n        private int NumConnections\n        {\n            get { return idlePool.Count + inUsePool.Count; }\n        }\n        /// <summary>\n        /// Indicates whether this pool is being cleared.\n        /// </summary>\n        public bool BeingCleared\n        {\n            get { return beingCleared; }\n        }\n        internal Hashtable ServerProperties { get; set; }\n        #endregion\n        /// <summary>\n        /// It is assumed that this method is only called from inside an active lock.\n        /// </summary>\n        private Driver GetPooledConnection()\n\t\t{\n            Driver driver = null;\n            // if we don't have an idle connection but we have room for a new\n            // one, then create it here.\n            lock ((idlePool as ICollection).SyncRoot)\n            {\n                if (HasIdleConnections)\n                    driver = idlePool.Dequeue();\n            }\n            // Obey the connection timeout\n            if (driver != null)\n            {\n                try\n                {\n                    driver.ResetTimeout((int)Settings.ConnectionTimeout * 1000);\n                }\n                catch (Exception)\n                {\n                    driver.Close();\n                    driver = null;\n                }\n            }\n            \n            if (driver != null)\n            {\n                // first check to see that the server is still alive\n                if (!driver.Ping())\n                {\n                    driver.Close();\n                    driver = null;\n                }\n                else if (settings.ConnectionReset)\n                    // if the user asks us to ping/reset pooled connections\n                    // do so now\n                    driver.Reset();\n            }\n            if (driver == null)\n                driver = CreateNewPooledConnection();\n            Debug.Assert(driver != null);\n            lock ((inUsePool as ICollection).SyncRoot)\n            {\n                inUsePool.Add(driver);\n            }\n            return driver;\n        }\n        /// <summary>\n        /// It is assumed that this method is only called from inside an active lock.\n        /// </summary>\n\t\tprivate Driver CreateNewPooledConnection()\n\t\t{\n            Debug.Assert((maxSize - NumConnections) > 0, \"Pool out of sync.\");\n            Driver driver = Driver.Create(settings);\n            driver.Pool = this;\n            return driver;\n        }\n\t\tpublic void ReleaseConnection(Driver driver)\n\t\t{\n            lock ((inUsePool as ICollection).SyncRoot)\n            {\n                if (inUsePool.Contains(driver))\n                    inUsePool.Remove(driver);\n            }\n            if (driver.ConnectionLifetimeExpired() || beingCleared)\n            {\n                driver.Close();\n                Debug.Assert(!idlePool.Contains(driver));\n            }\n            else\n            {\n                lock ((idlePool as ICollection).SyncRoot)\n                {\n                    EnqueueIdle(driver);\n                }\n            }\n            Interlocked.Increment(ref available);\n            autoEvent.Set();\n        }\n        /// <summary>\n        /// Removes a connection from the in use pool.  The only situations where this method \n        /// would be called are when a connection that is in use gets some type of fatal exception\n        /// or when the connection is being returned to the pool and it's too old to be \n        /// returned.\n        /// </summary>\n        /// <param name=\"driver\"></param>\n        public void RemoveConnection(Driver driver)\n        {\n            lock ((inUsePool as ICollection).SyncRoot)\n            {\n                if (inUsePool.Contains(driver))\n                {\n                    inUsePool.Remove(driver);\n                    Interlocked.Increment(ref available);\n                    autoEvent.Set();\n                }\n            }\n            // if we are being cleared and we are out of connections then have\n            // the manager destroy us.\n            if (beingCleared && NumConnections == 0)\n                MySqlPoolManager.RemoveClearedPool(this);\n        }\n        private Driver TryToGetDriver()\n        {\n            int count = Interlocked.Decrement(ref available);\n            if (count < 0)\n            {\n                Interlocked.Increment(ref available);\n                return null;\n            }\n            try\n            {\n                Driver driver = GetPooledConnection();\n                return driver;\n            }\n            catch (Exception ex)\n            {\n                MySqlTrace.LogError(-1, ex.Message);\n                Interlocked.Increment(ref available);\n                throw;\n            }\n        }\n\t\tpublic Driver GetConnection() \n\t\t{\n\t\t\tint fullTimeOut = (int)settings.ConnectionTimeout * 1000;\n            int timeOut = fullTimeOut;\n            DateTime start = DateTime.Now;\n            while (timeOut > 0)\n            {\n                Driver driver = TryToGetDriver();\n                if (driver != null) return driver;\n                // We have no tickets right now, lets wait for one.\n                if (!autoEvent.WaitOne(timeOut, false)) break;\n                timeOut = fullTimeOut - (int)DateTime.Now.Subtract(start).TotalMilliseconds;\n            }\n            throw new MySqlException(Resources.TimeoutGettingConnection);\n\t\t}\n        /// <summary>\n        /// Clears this pool of all idle connections and marks this pool and being cleared\n        /// so all other connections are closed when they are returned.\n        /// </summary>\n        internal void Clear()\n        {\n            lock ((idlePool as ICollection).SyncRoot)\n            {\n                // first, mark ourselves as being cleared\n                beingCleared = true;\n                // then we remove all connections sitting in the idle pool\n                while (idlePool.Count > 0)\n                {\n                    Driver d = idlePool.Dequeue();\n                    d.Close();\n                }\n                // there is nothing left to do here.  Now we just wait for all\n                // in use connections to be returned to the pool.  When they are\n                // they will be closed.  When the last one is closed, the pool will\n                // be destroyed.\n            }\n        }\n        /// <summary>\n        /// Remove expired drivers from the idle pool\n        /// </summary>\n        /// <returns></returns>\n        /// <remarks>\n        /// Closing driver is a potentially lengthy operation involving network\n        /// IO. Therefore we do not close expired drivers while holding \n        /// idlePool.SyncRoot lock. We just remove the old drivers from the idle\n        /// queue and return them to the caller. The caller will need to close \n        /// them (or let GC close them)\n        /// </remarks>\n        internal List<Driver> RemoveOldIdleConnections()\n        {\n            List<Driver> oldDrivers = new List<Driver>();\n            DateTime now = DateTime.Now;\n            lock ((idlePool as ICollection).SyncRoot)\n            {\n                // The drivers appear to be ordered by their age, i.e it is\n                // sufficient to remove them until the first element is not\n                // too old.\n                while(idlePool.Count > minSize)\n                {\n", "outputs": ["                    Driver d = idlePool.Peek();"], "input_length": 1533, "output_length": 7, "length": 1540, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "a66e1e77ced29acefe89b887cc0e0263bf8f4afae31ee71cf43a3bd0b9f9205b"}
{"input": "", "context": "using EloBuddy; namespace KoreanZed\n{\n    using LeagueSharp;\n    using LeagueSharp.Common;\n    using System.Linq;\n    using System;\n    using System.Collections.Generic;\n    using KoreanZed.Enumerators;\n    using KoreanZed.QueueActions;\n    using SharpDX;\n    class ZedShadows\n    {\n        private readonly ZedMenu zedMenu;\n        private readonly ZedSpell q;\n        private readonly ZedSpell w;\n        private readonly ZedSpell e;\n        private readonly ZedEnergyChecker energy;\n        public bool CanCast\n        {\n            get\n            {\n                int currentShadows = GetShadows().Count();\n                return ((!ObjectManager.Player.HasBuff(\"zedwhandler\") && w.IsReady() && Game.Time > lastTimeCast + 0.3F\n                         && Game.Time > buffTime + 1F) && w.IsReady() && w.Instance.ToggleState == 0\n                        && !ObjectManager.Player.HasBuff(\"zedwhandler\")\n                        && ((ObjectManager.Player.HasBuff(\"zedr2\") && currentShadows == 1) || currentShadows == 0));\n            }\n        }\n        public bool CanSwitch\n        {\n            get\n            {\n                return !CanCast && w.Instance.ToggleState != 0 && w.IsReady()\n                       && !ObjectManager.Get<Obj_AI_Turret>()\n                               .Any(ob => ob.Distance(Instance.Position) < 775F && ob.IsEnemy && !ob.IsDead);\n            }\n        }\n        public Obj_AI_Base Instance\n        {\n            get\n            {\n                Obj_AI_Base shadow = GetShadows().FirstOrDefault();\n                if (shadow != null)\n                {\n                    return shadow;\n                }\n                else\n                {\n                    return ObjectManager.Player;\n                }\n            }\n        }\n        private float lastTimeCast;\n        private float buffTime;\n        public ZedShadows(ZedMenu menu, ZedSpells spells, ZedEnergyChecker energy)\n        {\n            zedMenu = menu;\n            q = spells.Q;\n            w = spells.W;\n            e = spells.E;\n            this.energy = energy;\n            Game.OnUpdate += Game_OnUpdate;\n        }\n        private void Game_OnUpdate(EventArgs args)\n        {\n            if (ObjectManager.Player.HasBuff(\"zedwhandler\"))\n            {\n                buffTime = Game.Time;\n            }\n        }\n        public void Cast(Vector3 position)\n        {\n            if (CanCast)\n            {\n                w.Cast(position);\n                lastTimeCast = Game.Time;\n            }\n        }\n        public void Cast(AIHeroClient target)\n        {\n            if (target == null)\n            {\n                return;\n            }\n            Cast(target.Position);\n        }\n        public void Switch()\n        {\n            if (CanSwitch)\n            {\n                w.Cast();\n            }\n        }\n        public List<Obj_AI_Base> GetShadows()\n        {\n            List<Obj_AI_Base> resultList = new List<Obj_AI_Base>();\n            foreach (\n                Obj_AI_Base objAiBase in\n                    ObjectManager.Get<Obj_AI_Base>().Where(obj => obj.BaseSkinName.ToLowerInvariant().Contains(\"shadow\") && !obj.IsDead))\n            {\n                resultList.Add(objAiBase);\n            }\n            return resultList;\n        }\n        public void Combo()\n        {\n            List<Obj_AI_Base> shadows = GetShadows();\n            if (!shadows.Any()\n                || (!q.UseOnCombo && !e.UseOnCombo)\n                || (!q.IsReady() && !e.IsReady()))\n            {\n                return;\n            }\n            foreach (Obj_AI_Base objAiBase in shadows)\n            {\n                if (((q.UseOnCombo && !q.IsReady()) || !q.UseOnCombo)\n                    && ((e.UseOnCombo && !e.IsReady()) || !e.UseOnCombo))\n                {\n                    break;\n                }\n                if (q.UseOnCombo && q.IsReady())\n                {\n                    AIHeroClient target = TargetSelector.GetTarget(\n                        q.Range,\n                        q.DamageType,\n                        true,\n                        null,\n                        objAiBase.Position);\n                    if (target != null)\n                    {\n                        PredictionInput predictionInput = new PredictionInput();\n                        predictionInput.Range = q.Range;\n                        predictionInput.RangeCheckFrom = objAiBase.Position;\n                        predictionInput.From = objAiBase.Position;\n                        predictionInput.Delay = q.Delay;\n                        predictionInput.Speed = q.Speed;\n                        predictionInput.Unit = target;\n                        predictionInput.Type = SkillshotType.SkillshotLine;\n                        predictionInput.Collision = false;\n                        PredictionOutput predictionOutput = Prediction.GetPrediction(predictionInput);\n                        if (predictionOutput.Hitchance >= HitChance.Medium)\n                        {\n                            q.Cast(predictionOutput.CastPosition);\n                        }\n                    }\n                }\n                if (e.UseOnCombo && e.IsReady())\n                {\n                    AIHeroClient target = TargetSelector.GetTarget(e.Range, e.DamageType, true, null, objAiBase.Position);\n                    if (target != null)\n                    {\n                        e.Cast();\n                    }\n                }\n            }\n        }\n        public void Harass()\n        {\n            List<Obj_AI_Base> shadows = GetShadows();\n            if (!shadows.Any() \n                || (!q.UseOnHarass && !e.UseOnHarass)\n                || (!q.IsReady() && !e.IsReady()))\n            {\n                return;\n            }\n           \n            List<AIHeroClient> blackList = zedMenu.GetBlockList(BlockListType.Harass);\n            foreach (Obj_AI_Base objAiBase in shadows)\n            {\n                if (((q.UseOnHarass && !q.IsReady()) || !q.UseOnHarass)\n                    && ((e.UseOnHarass && !e.IsReady()) || !e.UseOnHarass))\n                {\n                    break;\n                }\n                if (q.UseOnHarass && q.IsReady())\n                {\n                    AIHeroClient target = TargetSelector.GetTarget(\n                        q.Range,\n                        q.DamageType,\n                        true,\n                        blackList,\n                        objAiBase.Position);\n                    if (target != null)\n                    {\n                        PredictionInput predictionInput = new PredictionInput();\n                        predictionInput.Range = q.Range;\n                        predictionInput.RangeCheckFrom = objAiBase.Position;\n                        predictionInput.From = objAiBase.Position;\n                        predictionInput.Delay = q.Delay;\n                        predictionInput.Speed = q.Speed;\n                        predictionInput.Unit = target;\n                        predictionInput.Type = SkillshotType.SkillshotLine;\n                        predictionInput.Collision = false;\n                        PredictionOutput predictionOutput = Prediction.GetPrediction(predictionInput);\n                        if (predictionOutput.Hitchance >= HitChance.Medium)\n                        {\n                            q.Cast(predictionOutput.CastPosition);\n                        }\n                    }\n                }\n                if (e.UseOnHarass && e.IsReady())\n                {\n                    AIHeroClient target = TargetSelector.GetTarget(e.Range, e.DamageType, true, blackList, objAiBase.Position);\n                    if (target != null)\n                    {\n                        e.Cast();\n                    }\n                }\n            }\n        }\n        public void LaneClear(ActionQueue actionQueue, ActionQueueList laneClearQueue)\n        {\n            Obj_AI_Base shadow = GetShadows().FirstOrDefault();\n            if (!energy.ReadyToLaneClear || shadow == null)\n            {\n                return;\n            }\n            if (e.UseOnLaneClear && e.IsReady())\n            {\n                int extendedWillHit = MinionManager.GetMinions(shadow.Position, e.Range).Count();\n                int shortenWillHit = MinionManager.GetMinions(e.Range).Count;\n                int param = zedMenu.GetParamSlider(\"koreanzed.laneclearmenu.useeif\");\n                if (extendedWillHit >= param || shortenWillHit >= param)\n                {\n                    actionQueue.EnqueueAction(\n                        laneClearQueue,\n                        () => true,\n                        () => e.Cast(),\n                        () => !e.IsReady());\n                    return;\n                }\n            }\n            if (q.UseOnLaneClear && q.IsReady())\n            {\n                int extendedWillHit = 0;\n                Vector3 extendedFarmLocation = Vector3.Zero;\n                foreach (Obj_AI_Base objAiBase in MinionManager.GetMinions(shadow.Position, q.Range))\n                {\n                    var colisionList = q.GetCollision(\n                        shadow.Position.To2D(),\n                        new List<Vector2>() { objAiBase.Position.To2D() },\n                        w.Delay);\n", "outputs": ["                    if (colisionList.Count > extendedWillHit)"], "input_length": 1093, "output_length": 6, "length": 1099, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "bc2631937a7b6420a989056c446017272b309d9fac9ed5652921b7204bb775b2"}
{"input": "", "context": "using System;\nusing NesHd.Core.Memory;\nusing NesHd.Core.Memory.Mappers;\nnamespace NesHd.Core.Misc\n{\n    [Serializable]\n    public class StateHolder\n    {\n        #region CPU\n        public int CycleCounter;\n        private int _cyclesPerScanline;\n        private bool _flagB;\n        private bool _flagC;\n        private bool _flagD;\n        private bool _flagI = true;\n        private bool _flagN;\n        private bool _flagV;\n        private bool _flagZ;\n        private byte _opCode;\n        private ushort _prevPc;\n        private byte _regA;\n        private ushort _regPc;\n        private byte _regS;\n        private byte _regX;\n        private byte _regY;\n        #endregion\n        #region MEMORY\n        private int _joyData1;\n        private int _joyData2;\n        private byte _joyStrobe;\n        private byte[] _ram;\n        private byte[] _sram;\n        #endregion\n        #region CART\n        private byte[][] _chr;\n        private Mirroring _mirroring;\n        private bool _isVram;\n        private uint _mirroringBase;\n        private bool _saveRAMPresent;\n        #endregion\n        #region _map\n        public uint[] CurrentChrRomPage;\n        public uint[] CurrentPRGRomPage;\n        #endregion\n        #region PPU\n        private bool _backgroundClipping;\n        private bool _backgroundVisibility;\n        private ushort _colorEmphasis;\n        private int _currentScanLine;\n        /*2000*/\n        private bool _executeNMIonVBlank;\n        private byte _hScroll;\n        private bool _monochromeMode;\n        private bool _ppuToggle;\n        private int _patternTableAddress8X8Sprites;\n        private int _patternTableAddressBackground;\n        private byte _reloadBits2000;\n        private byte[] _sprram;\n        private int _scanlineOfVblank;\n        private int _scanlinesPerFrame;\n        private bool _sprite0Hit;\n        /*2001*/\n        private bool _spriteClipping;\n        private int _spriteCrossed;\n        /*2003*/\n        private byte _spriteRamAddress;\n        private bool _spriteSize; //true=8x16, false=8x8\n        private bool _spriteVisibility;\n        private int _tileY;\n        private bool _vblank;\n        private int _vBits;\n        private byte[] _vram;\n        private ushort _vramAddress;\n        private int _vramAddressIncrement = 1;\n        private byte _vramReadBuffer;\n        /*2005,2006*/\n        private ushort _vramTemp;\n        /*Draw stuff*/\n        private int _vScroll;\n        private int _fps;\n        private bool _noLimiter;\n        #endregion\n        #region APU\n        public byte DMCDAC;\n        public ushort DMCDMAAddress;\n        public ushort DMCDMALength;\n        public ushort DMCDMALengthCounter;\n        public ushort DMCDMAStartAddress;\n        public byte DMCDMCBIT;\n        public byte DMCDMCBYTE;\n        public bool DMCDMCIRQEnabled;\n        private bool DMCIRQPending;\n        public bool DMC_Enabled;\n        public double DMC_FreqTimer;\n        public double DMC_Frequency;\n        public bool DMC_Loop;\n        public double DMC_RenderedLength;\n        public double DMC_SampleCount;\n        private bool FrameIRQEnabled;\n        private bool FrameIRQPending;\n        public short NOIZEOUT;\n        public byte NOIZE_DecayCount;\n        public bool NOIZE_DecayDiable;\n        public bool NOIZE_DecayLoopEnable;\n        public bool NOIZE_DecayReset;\n        public byte NOIZE_DecayTimer;\n        //NOIZE\n        public bool NOIZE_Enabled;\n        public byte NOIZE_Envelope;\n        public double NOIZE_FreqTimer;\n        public double NOIZE_Frequency;\n        public byte NOIZE_LengthCount;\n        public int NOIZE_NoiseMode;\n        public double NOIZE_RenderedLength;\n        public double NOIZE_SampleCount;\n        public ushort NOIZE_ShiftReg = 1;\n        public byte NOIZE_Volume;\n        public double Rectangle1DutyPercentage;\n        public bool Rectangle1WaveStatus;\n        public byte Rectangle1_DecayCount;\n        public bool Rectangle1_DecayDiable;\n        public bool Rectangle1_DecayLoopEnable;\n        public bool Rectangle1_DecayReset;\n        public byte Rectangle1_DecayTimer;\n        public int Rectangle1_DutyCycle;\n        public bool Rectangle1_Enabled;\n        public byte Rectangle1_Envelope;\n        public int Rectangle1_FreqTimer;\n        public double Rectangle1_Frequency;\n        public byte Rectangle1_LengthCount;\n        public double Rectangle1_RenderedLength;\n        public double Rectangle1_SampleCount;\n        public byte Rectangle1_SweepCount;\n        public bool Rectangle1_SweepDirection;\n        public bool Rectangle1_SweepEnable;\n        public bool Rectangle1_SweepForceSilence;\n        public byte Rectangle1_SweepRate;\n        public bool Rectangle1_SweepReset;\n        public byte Rectangle1_SweepShift;\n        public byte Rectangle1_Volume;\n        public double Rectangle2DutyPercentage;\n        public bool Rectangle2WaveStatus;\n        public byte Rectangle2_DecayCount;\n        public bool Rectangle2_DecayDiable;\n        public bool Rectangle2_DecayLoopEnable;\n        public bool Rectangle2_DecayReset;\n        public byte Rectangle2_DecayTimer;\n        public int Rectangle2_DutyCycle;\n        public bool Rectangle2_Enabled;\n        public byte Rectangle2_Envelope;\n        public int Rectangle2_FreqTimer;\n        public double Rectangle2_Frequency;\n        public byte Rectangle2_LengthCount;\n        public double Rectangle2_RenderedLength;\n        public double Rectangle2_SampleCount;\n        public byte Rectangle2_SweepCount;\n        public bool Rectangle2_SweepDirection;\n        public bool Rectangle2_SweepEnable;\n        public bool Rectangle2_SweepForceSilence;\n        public byte Rectangle2_SweepRate;\n        public bool Rectangle2_SweepReset;\n        public byte Rectangle2_SweepShift;\n        public byte Rectangle2_Volume;\n        public bool TriangleHALT;\n        public short TriangleOUT;\n        public bool Triangle_Enabled;\n        public int Triangle_FreqTimer;\n        public double Triangle_Frequency;\n        public byte Triangle_LengthCount;\n        public bool Triangle_LengthEnabled;\n        public bool Triangle_LinearControl;\n        public int Triangle_LinearCounter;\n        public int Triangle_LinearCounterLoad;\n        public double Triangle_RenderedLength;\n        public double Triangle_SampleCount;\n        public int Triangle_Sequence;\n        public double VRC6Pulse1DutyPercentage;\n        public short VRC6Pulse1OUT;\n        public bool VRC6Pulse1WaveStatus;\n        public int VRC6Pulse1_DutyCycle;\n        public bool VRC6Pulse1_Enabled;\n        public int VRC6Pulse1_FreqTimer;\n        public double VRC6Pulse1_Frequency;\n        public double VRC6Pulse1_RenderedLength;\n        public double VRC6Pulse1_SampleCount;\n        public byte VRC6Pulse1_Volume;\n        public double VRC6Pulse2DutyPercentage;\n        public short VRC6Pulse2OUT;\n        public bool VRC6Pulse2WaveStatus;\n        public int VRC6Pulse2_DutyCycle;\n        public bool VRC6Pulse2_Enabled;\n        public int VRC6Pulse2_FreqTimer;\n        public double VRC6Pulse2_Frequency;\n        public double VRC6Pulse2_RenderedLength;\n        public double VRC6Pulse2_SampleCount;\n        public byte VRC6Pulse2_Volume;\n        public byte VRC6SawtoothAccum;\n        //VRC6 Sawtooth\n        public byte VRC6SawtoothAccumRate;\n        public byte VRC6SawtoothAccumStep;\n        public short VRC6SawtoothOUT;\n        public bool VRC6Sawtooth_Enabled;\n        public int VRC6Sawtooth_FreqTimer;\n        public double VRC6Sawtooth_Frequency;\n        public double VRC6Sawtooth_RenderedLength;\n        public double VRC6Sawtooth_SampleCount;\n        private int _FrameCounter;\n        private bool _PAL;\n        #endregion\n        #region MAPPERS\n        //MAPPER 1\n        //MAPPER 18\n        private int Mapper18_IRQWidth;\n        private short Mapper18_Timer;\n        private short Mapper18_latch;\n        private bool Mapper18_timer_irq_enabled;\n        private byte[] Mapper18_x = new byte[22];\n        private bool Mapper19_IRQEnabled;\n        //MAPPER 19\n        private bool Mapper19_VROMRAMfor0000;\n        private bool Mapper19_VROMRAMfor1000;\n        private short Mapper19_irq_counter;\n        //MAPPER 21\n        private bool Mapper21_PRGMode = true;\n        private byte[] Mapper21_REG = new byte[8];\n        private int Mapper21_irq_clock;\n        private int Mapper21_irq_counter;\n        private int Mapper21_irq_enable;\n        private int Mapper21_irq_latch;\n        //MAPPER 23\n        //MAPPER 225\n        private byte Mapper225_reg0 = 0xF;\n        private byte Mapper225_reg1 = 0xF;\n        private byte Mapper225_reg2 = 0xF;\n        private byte Mapper225_reg3 = 0xF;\n        private bool Mapper23_PRGMode = true;\n        private byte[] Mapper23_REG = new byte[8];\n        private int Mapper23_irq_clock;\n        private int Mapper23_irq_counter;\n        private int Mapper23_irq_enable;\n        private int Mapper23_irq_latch;\n        private int Mapper24_irq_clock;\n        private int Mapper24_irq_counter;\n        private bool Mapper24_irq_enable;\n        private int Mapper24_irq_latch;\n        private byte Mapper41_CHR_High;\n        private byte Mapper41_CHR_Low;\n        private byte mapper10_latch1;\n        private int mapper10_latch1data1;\n        private int mapper10_latch1data2;\n        private byte mapper10_latch2;\n        private int mapper10_latch2data1;\n        private int mapper10_latch2data2;\n        private bool mapper17_IRQEnabled;\n        private int mapper17_irq_counter;\n        private byte mapper18_control;\n        private byte mapper1_mirroringFlag;\n        private byte mapper1_onePageMirroring;\n        private byte mapper1_prgSwitchingArea;\n        private byte mapper1_prgSwitchingSize;\n        private int mapper1_register8000BitPosition;\n        private int mapper1_register8000Value;\n        private int mapper1_registerA000BitPosition;\n        private int mapper1_registerA000Value;\n        private int mapper1_registerC000BitPosition;\n        private int mapper1_registerC000Value;\n        private int mapper1_registerE000BitPosition;\n        private int mapper1_registerE000Value;\n        private byte mapper1_vromSwitchingSize;\n        //MAPPER 32\n        private int mapper32SwitchingMode;\n        //MAPPER 33\n        private byte mapper33_IRQCounter;\n        private bool mapper33_IRQEabled;\n        private bool mapper33_type1 = true;\n        private int mapper4_chrAddressSelect;\n        private int mapper4_commandNumber;\n        private int mapper4_prgAddressSelect;\n        private uint mapper4_timer_irq_count;\n        private bool mapper4_timer_irq_enabled;\n        private uint mapper4_timer_irq_reload;\n        private byte mapper5_chrBankSize;\n        private byte mapper5_prgBankSize;\n        private int mapper5_scanlineSplit;\n        private bool mapper5_splitIrqEnabled;\n        private byte mapper64_chrAddressSelect;\n        //MAPPER 41\n        //MAPPER 64\n        private byte mapper64_commandNumber;\n        private byte mapper64_prgAddressSelect;\n        private short mapper65_timer_irq_Latch_65;\n        private short mapper65_timer_irq_counter_65;\n        private bool mapper65_timer_irq_enabled;\n        //MAPPER 69\n        private ushort mapper69_reg;\n        private short mapper69_timer_irq_counter_69;\n        private bool mapper69_timer_irq_enabled;\n        private bool mapper6_IRQEnabled;\n        private int mapper6_irq_counter;\n        //MAPPER 8\n        private bool mapper8_IRQEnabled;\n        private int mapper8_irq_counter;\n        //MAPPER 91\n        private int mapper91_IRQCount;\n        private bool mapper91_IRQEnabled;\n        private byte mapper9_latch1;\n        private int mapper9_latch1data1;\n        private int mapper9_latch1data2;\n        private byte mapper9_latch2;\n        private int mapper9_latch2data1;\n        private int mapper9_latch2data2;\n        private short timer_irq_Latch_16;\n        private short timer_irq_counter_16;\n        private bool timer_irq_enabled;\n        #endregion\n        public void LoadNesData(NesEngine _engine)\n        {\n            #region CPU\n            _regA = _engine.Cpu.REG_A;\n            _regX = _engine.Cpu.REG_X;\n            _regY = _engine.Cpu.REG_Y;\n            _regS = _engine.Cpu.REG_S;\n            _regPc = _engine.Cpu.REG_PC;\n            _flagN = _engine.Cpu.Flag_N;\n            _flagV = _engine.Cpu.Flag_V;\n            _flagB = _engine.Cpu.Flag_B;\n            _flagD = _engine.Cpu.Flag_D;\n            _flagI = _engine.Cpu.Flag_I;\n            _flagZ = _engine.Cpu.Flag_Z;\n            _flagC = _engine.Cpu.Flag_C;\n            CycleCounter = _engine.Cpu.CycleCounter;\n            _cyclesPerScanline = _engine.Cpu.CyclesPerScanline;\n            _opCode = _engine.Cpu.OpCode;\n            _prevPc = _engine.Cpu.PrevPc;\n            #endregion\n            #region MEMORY\n            _ram = _engine.Memory.Ram;\n            _sram = _engine.Memory.SRam;\n            _joyData1 = _engine.Memory.JoyData1;\n            _joyData2 = _engine.Memory.JoyData2;\n            _joyStrobe = _engine.Memory.JoyStrobe;\n            #endregion\n            #region CART\n            if (_engine.Memory.Map.Cartridge.ChrPages == 0)\n                _chr = _engine.Memory.Map.Cartridge.Chr;\n            _mirroring = _engine.Memory.Map.Cartridge.Mirroring;\n            _saveRAMPresent = _engine.Memory.Map.Cartridge.IsSaveRam;\n            _isVram = _engine.Memory.Map.Cartridge.IsVram;\n            _mirroringBase = _engine.Memory.Map.Cartridge.MirroringBase;\n            #endregion\n            #region _map\n            CurrentPRGRomPage = _engine.Memory.Map.CurrentPrgRomPage;\n            CurrentChrRomPage = _engine.Memory.Map.CurrentChrRomPage;\n            #endregion\n            #region PPU\n            _sprram = _engine.Ppu.SprRam;\n            _vram = _engine.Ppu.VRam;\n            _currentScanLine = _engine.Ppu.CurrentScanLine;\n            _vramAddress = _engine.Ppu.VRamAddress;\n            _sprite0Hit = _engine.Ppu.Sprite0Hit;\n            _spriteCrossed = _engine.Ppu.SpriteCrossed;\n            _scanlinesPerFrame = _engine.Ppu.ScanlinesPerFrame;\n            _scanlineOfVblank = _engine.Ppu.ScanlineOfVblank;\n            _fps = _engine.Ppu.Fps;\n            _vblank = _engine.Ppu.VBlank;\n            _vramReadBuffer = _engine.Ppu.VRamReadBuffer;\n            _noLimiter = _engine.Ppu.NoLimiter;\n            /*2000*/\n            _executeNMIonVBlank = _engine.Ppu.ExecuteNMIonVBlank;\n            _spriteSize = _engine.Ppu.SpriteSize;\n            _patternTableAddressBackground = _engine.Ppu.PatternTableAddressBackground;\n            _patternTableAddress8X8Sprites = _engine.Ppu.PatternTableAddress8X8Sprites;\n            _vramAddressIncrement = _engine.Ppu.VRamAddressIncrement;\n            _reloadBits2000 = _engine.Ppu.ReloadBits2000;\n            /*2001*/\n            _colorEmphasis = _engine.Ppu.ColorEmphasis;\n            _spriteVisibility = _engine.Ppu.SpriteVisibility;\n            _backgroundVisibility = _engine.Ppu.BackgroundVisibility;\n            _spriteClipping = _engine.Ppu.SpriteClipping;\n            _backgroundClipping = _engine.Ppu.BackgroundClipping;\n            _monochromeMode = _engine.Ppu.MonochromeMode;\n            /*2003*/\n            _spriteRamAddress = _engine.Ppu.SpriteRamAddress;\n            /*2005,2006*/\n            _ppuToggle = _engine.Ppu.PpuToggle;\n            _vramTemp = _engine.Ppu.VRamTemp;\n            /*Draw stuff*/\n            _hScroll = _engine.Ppu.HScroll;\n            _vScroll = _engine.Ppu.VScroll;\n            _vBits = _engine.Ppu.VBits;\n            _tileY = _engine.Ppu.TileY;\n            #endregion\n            #region APU\n            _FrameCounter = _engine.Apu._FrameCounter;\n            _PAL = _engine.Apu._PAL;\n            DMCIRQPending = _engine.Apu.DMCIRQPending;\n            FrameIRQEnabled = _engine.Apu.FrameIRQEnabled;\n            FrameIRQPending = _engine.Apu.FrameIRQPending;\n            _engine.Apu.DMC.SaveState(this);\n            _engine.Apu.NOIZE.SaveState(this);\n            _engine.Apu.RECT1.SaveState(this);\n            _engine.Apu.RECT2.SaveState(this);\n            _engine.Apu.TRIANGLE.SaveState(this);\n            _engine.Apu.VRC6PULSE1.SaveState(this);\n            _engine.Apu.VRC6PULSE2.SaveState(this);\n            _engine.Apu.VRC6SAWTOOTH.SaveState(this);\n            #endregion\n            #region Mappers\n            //MAPPER 1\n            if (_engine.Memory.Map.Cartridge.MapperNo == 1)\n            {\n                var map1 = (Mapper01) _engine.Memory.Map.CurrentMapper;\n                mapper1_register8000BitPosition = map1.Mapper1Register8000BitPosition;\n                mapper1_registerA000BitPosition = map1.Mapper1RegisterA000BitPosition;\n                mapper1_registerC000BitPosition = map1.Mapper1RegisterC000BitPosition;\n                mapper1_registerE000BitPosition = map1.Mapper1RegisterE000BitPosition;\n                mapper1_register8000Value = map1.Mapper1Register8000Value;\n                mapper1_registerA000Value = map1.Mapper1RegisterA000Value;\n                mapper1_registerC000Value = map1.Mapper1RegisterC000Value;\n                mapper1_registerE000Value = map1.Mapper1RegisterE000Value;\n                mapper1_mirroringFlag = map1.Mapper1MirroringFlag;\n                mapper1_onePageMirroring = map1.Mapper1OnePageMirroring;\n                mapper1_prgSwitchingArea = map1.Mapper1PRGSwitchingArea;\n                mapper1_prgSwitchingSize = map1.Mapper1PRGSwitchingSize;\n                mapper1_vromSwitchingSize = map1.Mapper1VromSwitchingSize;\n            }\n            //MAPPER 4\n            if (_engine.Memory.Map.Cartridge.MapperNo == 4)\n            {\n                var map4 = (Mapper04) _engine.Memory.Map.CurrentMapper;\n                mapper4_commandNumber = map4.Mapper4CommandNumber;\n                mapper4_prgAddressSelect = map4.Mapper4PRGAddressSelect;\n                mapper4_chrAddressSelect = map4.Mapper4ChrAddressSelect;\n                mapper4_timer_irq_enabled = map4.TimerIrqEnabled;\n                mapper4_timer_irq_count = map4.TimerIrqCount;\n                mapper4_timer_irq_reload = map4.TimerIrqReload;\n            }\n            //MAPPER 5\n            if (_engine.Memory.Map.Cartridge.MapperNo == 5)\n            {\n                var map5 = (Mapper05) _engine.Memory.Map.CurrentMapper;\n                mapper5_prgBankSize = map5.Mapper5PRGBankSize;\n                mapper5_chrBankSize = map5.Mapper5ChrBankSize;\n                mapper5_scanlineSplit = map5.Mapper5ScanlineSplit;\n                mapper5_splitIrqEnabled = map5.Mapper5SplitIrqEnabled;\n            }\n            //MAPPER 6\n            if (_engine.Memory.Map.Cartridge.MapperNo == 6)\n            {\n                var map6 = (Mapper06) _engine.Memory.Map.CurrentMapper;\n                mapper6_IRQEnabled = map6.IRQEnabled;\n                mapper6_irq_counter = map6.irq_counter;\n            }\n            //MAPPER 8\n            if (_engine.Memory.Map.Cartridge.MapperNo == 8)\n            {\n                var map8 = (Mapper08) _engine.Memory.Map.CurrentMapper;\n                mapper8_IRQEnabled = map8.IRQEnabled;\n                mapper8_irq_counter = map8.irq_counter;\n            }\n            //MAPPER 9\n            if (_engine.Memory.Map.Cartridge.MapperNo == 9)\n            {\n                var map9 = (Mapper09) _engine.Memory.Map.CurrentMapper;\n                mapper9_latch1 = map9.latch1;\n                mapper9_latch2 = map9.latch2;\n                mapper9_latch1data1 = map9.latch1data1;\n                mapper9_latch1data2 = map9.latch1data2;\n                mapper9_latch2data1 = map9.latch2data1;\n                mapper9_latch2data2 = map9.latch2data2;\n            }\n            //MAPPER 10\n            if (_engine.Memory.Map.Cartridge.MapperNo == 10)\n            {\n                var map10 = (Mapper10) _engine.Memory.Map.CurrentMapper;\n                mapper10_latch1 = map10.Latch1;\n                mapper10_latch2 = map10.Latch2;\n                mapper10_latch1data1 = map10.Latch1Data1;\n                mapper10_latch1data2 = map10.Latch1Data2;\n                mapper10_latch2data1 = map10.Latch2Data1;\n                mapper10_latch2data2 = map10.Latch2Data2;\n            }\n            //MAPPER 16\n", "outputs": ["            if (_engine.Memory.Map.Cartridge.MapperNo == 16)"], "input_length": 1917, "output_length": 6, "length": 1923, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "a1dad9302e6c64764bf378d29c95a57e1834a292f3f9c01b6730adb39eaf14f0"}
{"input": "", "context": "# (c) 2016 Matt Clay <matt@mystile.com>\n#\n# This file is part of Ansible\n#\n# Ansible is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# Ansible is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.\nfrom __future__ import (absolute_import, division, print_function)\n__metaclass__ = type\nimport os\nimport time\nimport re\nfrom ansible.module_utils._text import to_bytes, to_text\nfrom ansible.plugins.callback import CallbackBase\ntry:\n    from junit_xml import TestSuite, TestCase\n    HAS_JUNIT_XML = True\nexcept ImportError:\n    HAS_JUNIT_XML = False\ntry:\n    from collections import OrderedDict\n    HAS_ORDERED_DICT = True\nexcept ImportError:\n    try:\n        from ordereddict import OrderedDict\n        HAS_ORDERED_DICT = True\n    except ImportError:\n        HAS_ORDERED_DICT = False\nclass CallbackModule(CallbackBase):\n    \"\"\"\n    This callback writes playbook output to a JUnit formatted XML file.\n    Tasks show up in the report as follows:\n        'ok': pass\n        'failed' with 'EXPECTED FAILURE' in the task name: pass\n        'failed' due to an exception: error\n        'failed' for other reasons: failure\n        'skipped': skipped\n    This plugin makes use of the following environment variables:\n        JUNIT_OUTPUT_DIR (optional): Directory to write XML files to.\n                                     Default: ~/.ansible.log\n        JUNIT_TASK_CLASS (optional): Configure the output to be one class per yaml file\n                                     Default: False\n        JUNIT_FAIL_ON_CHANGE (optional): Consider any tasks reporting \"changed\" as a junit test failure\n                                     Default: False\n    Requires:\n        junit_xml\n    \"\"\"\n    CALLBACK_VERSION = 2.0\n    CALLBACK_TYPE = 'aggregate'\n    CALLBACK_NAME = 'junit'\n    CALLBACK_NEEDS_WHITELIST = True\n    def __init__(self):\n        super(CallbackModule, self).__init__()\n        self._output_dir = os.getenv('JUNIT_OUTPUT_DIR', os.path.expanduser('~/.ansible.log'))\n        self._task_class = os.getenv('JUNIT_TASK_CLASS', 'False').lower()\n        self._fail_on_change = os.getenv('JUNIT_FAIL_ON_CHANGE', 'False').lower()\n        self._playbook_path = None\n        self._playbook_name = None\n        self._play_name = None\n        self._task_data = None\n        self.disabled = False\n        if not HAS_JUNIT_XML:\n            self.disabled = True\n            self._display.warning('The `junit_xml` python module is not installed. '\n                                  'Disabling the `junit` callback plugin.')\n        if HAS_ORDERED_DICT:\n            self._task_data = OrderedDict()\n        else:\n            self.disabled = True\n            self._display.warning('The `ordereddict` python module is not installed. '\n                                  'Disabling the `junit` callback plugin.')\n        if not os.path.exists(self._output_dir):\n            os.mkdir(self._output_dir)\n    def _start_task(self, task):\n        \"\"\" record the start of a task for one or more hosts \"\"\"\n        uuid = task._uuid\n        if uuid in self._task_data:\n            return\n        play = self._play_name\n        name = task.get_name().strip()\n        path = task.get_path()\n        if not task.no_log:\n            args = ', '.join(('%s=%s' % a for a in task.args.items()))\n            if args:\n                name += ' ' + args\n        self._task_data[uuid] = TaskData(uuid, name, path, play)\n    def _finish_task(self, status, result):\n        \"\"\" record the results of a task for a single host \"\"\"\n        task_uuid = result._task._uuid\n        if hasattr(result, '_host'):\n            host_uuid = result._host._uuid\n            host_name = result._host.name\n        else:\n            host_uuid = 'include'\n            host_name = 'include'\n        task_data = self._task_data[task_uuid]\n        if self._fail_on_change == 'true' and status == 'ok' and result._result.get('changed', False):\n            status = 'failed'\n        if status == 'failed' and 'EXPECTED FAILURE' in task_data.name:\n            status = 'ok'\n        task_data.add_host(HostData(host_uuid, host_name, status, result))\n    def _build_test_case(self, task_data, host_data):\n        \"\"\" build a TestCase from the given TaskData and HostData \"\"\"\n        name = '[%s] %s: %s' % (host_data.name, task_data.play, task_data.name)\n        duration = host_data.finish - task_data.start\n        if self._task_class == 'true':\n            junit_classname = re.sub('\\.yml:[0-9]+$', '', task_data.path)\n        else:\n            junit_classname = task_data.path\n        if host_data.status == 'included':\n            return TestCase(name, junit_classname, duration, host_data.result)\n        res = host_data.result._result\n        rc = res.get('rc', 0)\n        dump = self._dump_results(res, indent=0)\n        dump = self._cleanse_string(dump)\n        if host_data.status == 'ok':\n            return TestCase(name, junit_classname, duration, dump)\n        test_case = TestCase(name, junit_classname, duration)\n        if host_data.status == 'failed':\n            if 'exception' in res:\n                message = res['exception'].strip().split('\\n')[-1]\n                output = res['exception']\n                test_case.add_error_info(message, output)\n            elif 'msg' in res:\n                message = res['msg']\n                test_case.add_failure_info(message, dump)\n            else:\n                test_case.add_failure_info('rc=%s' % rc, dump)\n        elif host_data.status == 'skipped':\n            if 'skip_reason' in res:\n                message = res['skip_reason']\n            else:\n                message = 'skipped'\n            test_case.add_skipped_info(message)\n        return test_case\n    def _cleanse_string(self, value):\n        \"\"\" convert surrogate escapes to the unicode replacement character to avoid XML encoding errors \"\"\"\n        return to_text(to_bytes(value, errors='surrogateescape'), errors='replace')\n    def _generate_report(self):\n        \"\"\" generate a TestSuite report from the collected TaskData and HostData \"\"\"\n        test_cases = []\n        for task_uuid, task_data in self._task_data.items():\n            for host_uuid, host_data in task_data.host_data.items():\n                test_cases.append(self._build_test_case(task_data, host_data))\n        test_suite = TestSuite(self._playbook_name, test_cases)\n        report = TestSuite.to_xml_string([test_suite])\n        output_file = os.path.join(self._output_dir, '%s-%s.xml' % (self._playbook_name, time.time()))\n        with open(output_file, 'wb') as xml:\n            xml.write(to_bytes(report, errors='surrogate_or_strict'))\n    def v2_playbook_on_start(self, playbook):\n        self._playbook_path = playbook._file_name\n        self._playbook_name = os.path.splitext(os.path.basename(self._playbook_path))[0]\n    def v2_playbook_on_play_start(self, play):\n        self._play_name = play.get_name()\n    def v2_runner_on_no_hosts(self, task):\n        self._start_task(task)\n    def v2_playbook_on_task_start(self, task, is_conditional):\n        self._start_task(task)\n    def v2_playbook_on_cleanup_task_start(self, task):\n        self._start_task(task)\n    def v2_playbook_on_handler_task_start(self, task):\n        self._start_task(task)\n    def v2_runner_on_failed(self, result, ignore_errors=False):\n        if ignore_errors:\n            self._finish_task('ok', result)\n        else:\n            self._finish_task('failed', result)\n    def v2_runner_on_ok(self, result):\n        self._finish_task('ok', result)\n    def v2_runner_on_skipped(self, result):\n        self._finish_task('skipped', result)\n    def v2_playbook_on_include(self, included_file):\n        self._finish_task('included', included_file)\n    def v2_playbook_on_stats(self, stats):\n        self._generate_report()\nclass TaskData:\n    \"\"\"\n    Data about an individual task.\n    \"\"\"\n    def __init__(self, uuid, name, path, play):\n        self.uuid = uuid\n        self.name = name\n        self.path = path\n        self.play = play\n        self.start = None\n        self.host_data = OrderedDict()\n", "outputs": ["        self.start = time.time()"], "input_length": 1345, "output_length": 5, "length": 1350, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "c3b0244770f2fabb6953dd4c29e24dfdf4567f573e9b66ededb28d0c0e7676bd"}
{"input": "", "context": "from warnings import warn\nfrom copy import deepcopy, copy\nfrom six import iteritems, string_types\nfrom ..solvers import optimize\nfrom .Object import Object\nfrom .Solution import Solution\nfrom .Reaction import Reaction\nfrom .DictList import DictList\n# Note, when a reaction is added to the Model it will no longer keep personal\n# instances of its Metabolites, it will reference Model.metabolites to improve\n# performance.  When doing this, take care to monitor metabolite coefficients.\n# Do the same for Model.reactions[:].genes and Model.genes\nclass Model(Object):\n    \"\"\"Metabolic Model\n    Refers to Metabolite, Reaction, and Gene Objects.\n    \"\"\"\n    def __setstate__(self, state):\n        \"\"\"Make sure all cobra.Objects in the model point to the model\"\"\"\n        self.__dict__.update(state)\n        for y in ['reactions', 'genes', 'metabolites']:\n            for x in getattr(self, y):\n                x._model = self\n        if not hasattr(self, \"name\"):\n            self.name = None\n    def __init__(self, id_or_model=None, name=None):\n        if isinstance(id_or_model, Model):\n            Object.__init__(self, name=name)\n            self.__setstate__(id_or_model.__dict__)\n            if not hasattr(self, \"name\"):\n                self.name = None\n        else:\n            Object.__init__(self, id_or_model, name=name)\n            self._trimmed = False\n            self._trimmed_genes = []\n            self._trimmed_reactions = {}\n            self.genes = DictList()\n            self.reactions = DictList()  # A list of cobra.Reactions\n            self.metabolites = DictList()  # A list of cobra.Metabolites\n            # genes based on their ids {Gene.id: Gene}\n            self.compartments = {}\n            self.solution = Solution(None)\n            self.media_compositions = {}\n    @property\n    def description(self):\n        warn(\"description deprecated\")\n        return self.name if self.name is not None else \"\"\n    @description.setter\n    def description(self, value):\n        self.name = value\n        warn(\"description deprecated\")\n    def __add__(self, other_model):\n        \"\"\"Adds two models. +\n        The issue of reactions being able to exists in multiple Models now\n        arises, the same for metabolites and such.  This might be a little\n        difficult as a reaction with the same name / id in two models might\n        have different coefficients for their metabolites due to pH and whatnot\n        making them different reactions.\n        \"\"\"\n        new_model = self.copy()\n        new_reactions = deepcopy(other_model.reactions)\n        new_model.add_reactions(new_reactions)\n        new_model.id = self.id + '_' + other_model.id\n        return new_model\n    def __iadd__(self, other_model):\n        \"\"\"Adds a Model to this model +=\n        The issue of reactions being able to exists in multiple Models now\n        arises, the same for metabolites and such.  This might be a little\n        difficult as a reaction with the same name / id in two models might\n        have different coefficients for their metabolites due to pH and whatnot\n        making them different reactions.\n        \"\"\"\n        new_reactions = deepcopy(other_model.reactions)\n        self.add_reactions(new_reactions)\n        self.id = self.id + '_' + other_model.id\n        return self\n    def copy(self):\n        \"\"\"Provides a partial 'deepcopy' of the Model.  All of the Metabolite,\n        Gene, and Reaction objects are created anew but in a faster fashion\n        than deepcopy\n        \"\"\"\n        new = self.__class__()\n        do_not_copy = {\"metabolites\", \"reactions\", \"genes\"}\n        for attr in self.__dict__:\n            if attr not in do_not_copy:\n                new.__dict__[attr] = self.__dict__[attr]\n        new.metabolites = DictList()\n        do_not_copy = {\"_reaction\", \"_model\"}\n        for metabolite in self.metabolites:\n            new_met = metabolite.__class__()\n            for attr, value in iteritems(metabolite.__dict__):\n                if attr not in do_not_copy:\n                    new_met.__dict__[attr] = copy(\n                        value) if attr == \"formula\" else value\n            new_met._model = new\n            new.metabolites.append(new_met)\n        new.genes = DictList()\n        for gene in self.genes:\n            new_gene = gene.__class__(None)\n            for attr, value in iteritems(gene.__dict__):\n                if attr not in do_not_copy:\n                    new_gene.__dict__[attr] = copy(\n                        value) if attr == \"formula\" else value\n            new_gene._model = new\n            new.genes.append(new_gene)\n        new.reactions = DictList()\n        do_not_copy = {\"_model\", \"_metabolites\", \"_genes\"}\n        for reaction in self.reactions:\n            new_reaction = reaction.__class__()\n            for attr, value in iteritems(reaction.__dict__):\n                if attr not in do_not_copy:\n                    new_reaction.__dict__[attr] = value\n            new_reaction._model = new\n            new.reactions.append(new_reaction)\n            # update awareness\n            for metabolite, stoic in iteritems(reaction._metabolites):\n                new_met = new.metabolites.get_by_id(metabolite.id)\n                new_reaction._metabolites[new_met] = stoic\n                new_met._reaction.add(new_reaction)\n            for gene in reaction._genes:\n                new_gene = new.genes.get_by_id(gene.id)\n                new_reaction._genes.add(new_gene)\n                new_gene._reaction.add(new_reaction)\n        return new\n    def add_metabolites(self, metabolite_list):\n        \"\"\"Will add a list of metabolites to the the object, if they do not\n        exist and then expand the stochiometric matrix\n        metabolite_list: A list of :class:`~cobra.core.Metabolite` objects\n        \"\"\"\n        if not hasattr(metabolite_list, '__iter__'):\n            metabolite_list = [metabolite_list]\n        # First check whether the metabolites exist in the model\n        metabolite_list = [x for x in metabolite_list\n                           if x.id not in self.metabolites]\n        for x in metabolite_list:\n            x._model = self\n        self.metabolites += metabolite_list\n    def add_reaction(self, reaction):\n        \"\"\"Will add a cobra.Reaction object to the model, if\n        reaction.id is not in self.reactions.\n        reaction: A :class:`~cobra.core.Reaction` object\n        \"\"\"\n        self.add_reactions([reaction])\n    def add_reactions(self, reaction_list):\n        \"\"\"Will add a cobra.Reaction object to the model, if\n        reaction.id is not in self.reactions.\n        reaction_list: A list of :class:`~cobra.core.Reaction` objects\n        \"\"\"\n        # Only add the reaction if one with the same ID is not already\n        # present in the model.\n        # This function really should not used for single reactions\n        if not hasattr(reaction_list, \"__len__\"):\n            reaction_list = [reaction_list]\n            warn(\"Use add_reaction for single reactions\")\n        reaction_list = DictList(reaction_list)\n        reactions_in_model = [\n            i.id for i in reaction_list if self.reactions.has_id(\n                i.id)]\n        if len(reactions_in_model) > 0:\n            raise Exception(\"Reactions already in the model: \" +\n                            \", \".join(reactions_in_model))\n        # Add reactions. Also take care of genes and metabolites in the loop\n        for reaction in reaction_list:\n            reaction._model = self  # the reaction now points to the model\n            # keys() is necessary because the dict will be modified during\n            # the loop\n            for metabolite in list(reaction._metabolites.keys()):\n                # if the metabolite is not in the model, add it\n                # should we be adding a copy instead.\n                if not self.metabolites.has_id(metabolite.id):\n                    self.metabolites.append(metabolite)\n                    metabolite._model = self\n                    # this should already be the case. Is it necessary?\n                    metabolite._reaction = set([reaction])\n                # A copy of the metabolite exists in the model, the reaction\n                # needs to point to the metabolite in the model.\n                else:\n                    stoichiometry = reaction._metabolites.pop(metabolite)\n                    model_metabolite = self.metabolites.get_by_id(\n                        metabolite.id)\n                    reaction._metabolites[model_metabolite] = stoichiometry\n                    model_metabolite._reaction.add(reaction)\n            for gene in list(reaction._genes):\n                # If the gene is not in the model, add it\n                if not self.genes.has_id(gene.id):\n                    self.genes.append(gene)\n                    gene._model = self\n                    # this should already be the case. Is it necessary?\n                    gene._reaction = set([reaction])\n                # Otherwise, make the gene point to the one in the model\n                else:\n                    model_gene = self.genes.get_by_id(gene.id)\n                    if model_gene is not gene:\n                        reaction._dissociate_gene(gene)\n                        reaction._associate_gene(model_gene)\n        self.reactions += reaction_list\n    def to_array_based_model(self, deepcopy_model=False, **kwargs):\n        \"\"\"Makes a :class:`~cobra.core.ArrayBasedModel` from a cobra.Model which\n        may be used to perform linear algebra operations with the\n        stoichiomatric matrix.\n        deepcopy_model: Boolean.  If False then the ArrayBasedModel points\n        to the Model\n        \"\"\"\n        from .ArrayBasedModel import ArrayBasedModel\n        return ArrayBasedModel(self, deepcopy_model=deepcopy_model, **kwargs)\n    def optimize(self, objective_sense='maximize', **kwargs):\n        r\"\"\"Optimize model using flux balance analysis\n        objective_sense: 'maximize' or 'minimize'\n        solver: 'glpk', 'cglpk', 'gurobi', 'cplex' or None\n        quadratic_component: None or :class:`scipy.sparse.dok_matrix`\n            The dimensions should be (n, n) where n is the number of reactions.\n            This sets the quadratic component (Q) of the objective coefficient,\n            adding :math:`\\\\frac{1}{2} v^T \\cdot Q \\cdot v` to the objective.\n        tolerance_feasibility: Solver tolerance for feasibility.\n        tolerance_markowitz: Solver threshold during pivot\n        time_limit: Maximum solver time (in seconds)\n        .. NOTE :: Only the most commonly used parameters are presented here.\n                   Additional parameters for cobra.solvers may be available and\n                   specified with the appropriate keyword argument.\n        \"\"\"\n        solution = optimize(self, objective_sense=objective_sense, **kwargs)\n        self.solution = solution\n        return solution\n    def remove_reactions(self, reactions, delete=True,\n                         remove_orphans=False):\n        \"\"\"remove reactions from the model\n        reactions: [:class:`~cobra.core.Reaction.Reaction`] or [str]\n            The reactions (or their id's) to remove\n        delete: Boolean\n            Whether or not the reactions should be deleted after removal.\n            If the reactions are not deleted, those objects will be\n            recreated with new metabolite and gene objects.\n        remove_orphans: Boolean\n            Remove orphaned genes and metabolites from the model as well\n        \"\"\"\n        if isinstance(reactions, string_types) or hasattr(reactions, \"id\"):\n            warn(\"need to pass in a list\")\n            reactions = [reactions]\n        for reaction in reactions:\n            try:\n                reaction = self.reactions[self.reactions.index(reaction)]\n            except ValueError:\n                warn('%s not in %s' % (reaction, self))\n            else:\n                if delete:\n                    reaction.delete(remove_orphans=remove_orphans)\n                else:\n                    reaction.remove_from_model(remove_orphans=remove_orphans)\n    def repair(self, rebuild_index=True, rebuild_relationships=True):\n        \"\"\"Update all indexes and pointers in a model\"\"\"\n        if rebuild_index:  # DictList indexes\n            self.reactions._generate_index()\n            self.metabolites._generate_index()\n            self.genes._generate_index()\n        if rebuild_relationships:\n            for met in self.metabolites:\n                met._reaction.clear()\n            for gene in self.genes:\n                gene._reaction.clear()\n            for rxn in self.reactions:\n                for met in rxn._metabolites:\n                    met._reaction.add(rxn)\n                for gene in rxn._genes:\n                    gene._reaction.add(rxn)\n        # point _model to self\n", "outputs": ["        for l in (self.reactions, self.genes, self.metabolites):"], "input_length": 1903, "output_length": 11, "length": 1914, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "d059038f71ead15af6dba471c54dd9e8d6c68bed50fbb6f99364e0507980ab29"}
{"input": "", "context": "# Default Django settings. Override these with settings in the module\n# pointed-to by the DJANGO_SETTINGS_MODULE environment variable.\n# This is defined here as a do-nothing function because we can't import\n# django.utils.translation -- that module depends on the settings.\ngettext_noop = lambda s: s\n####################\n# CORE             #\n####################\nDEBUG = False\nTEMPLATE_DEBUG = False\n# Whether the framework should propagate raw exceptions rather than catching\n# them. This is useful under some testing situations and should never be used\n# on a live site.\nDEBUG_PROPAGATE_EXCEPTIONS = False\n# Whether to use the \"Etag\" header. This saves bandwidth but slows down performance.\nUSE_ETAGS = False\n# People who get code error notifications.\n# In the format (('Full Name', 'email@example.com'), ('Full Name', 'anotheremail@example.com'))\nADMINS = ()\n# Tuple of IP addresses, as strings, that:\n#   * See debug comments, when DEBUG is true\n#   * Receive x-headers\nINTERNAL_IPS = ()\n# Hosts/domain names that are valid for this site.\n# \"*\" matches anything, \".example.com\" matches example.com and all subdomains\nALLOWED_HOSTS = []\n# Local time zone for this installation. All choices can be found here:\n# http://en.wikipedia.org/wiki/List_of_tz_zones_by_name (although not all\n# systems may support all possibilities). When USE_TZ is True, this is\n# interpreted as the default user time zone.\nTIME_ZONE = 'America/Chicago'\n# If you set this to True, Django will use timezone-aware datetimes.\nUSE_TZ = False\n# Language code for this installation. All choices can be found here:\n# http://www.i18nguy.com/unicode/language-identifiers.html\nLANGUAGE_CODE = 'en-us'\n# Languages we provide translations for, out of the box.\nLANGUAGES = (\n    ('af', gettext_noop('Afrikaans')),\n    ('ar', gettext_noop('Arabic')),\n    ('az', gettext_noop('Azerbaijani')),\n    ('bg', gettext_noop('Bulgarian')),\n    ('be', gettext_noop('Belarusian')),\n    ('bn', gettext_noop('Bengali')),\n    ('br', gettext_noop('Breton')),\n    ('bs', gettext_noop('Bosnian')),\n    ('ca', gettext_noop('Catalan')),\n    ('cs', gettext_noop('Czech')),\n    ('cy', gettext_noop('Welsh')),\n    ('da', gettext_noop('Danish')),\n    ('de', gettext_noop('German')),\n    ('el', gettext_noop('Greek')),\n    ('en', gettext_noop('English')),\n    ('en-au', gettext_noop('Australian English')),\n    ('en-gb', gettext_noop('British English')),\n    ('eo', gettext_noop('Esperanto')),\n    ('es', gettext_noop('Spanish')),\n    ('es-ar', gettext_noop('Argentinian Spanish')),\n    ('es-mx', gettext_noop('Mexican Spanish')),\n    ('es-ni', gettext_noop('Nicaraguan Spanish')),\n    ('es-ve', gettext_noop('Venezuelan Spanish')),\n    ('et', gettext_noop('Estonian')),\n    ('eu', gettext_noop('Basque')),\n    ('fa', gettext_noop('Persian')),\n    ('fi', gettext_noop('Finnish')),\n    ('fr', gettext_noop('French')),\n    ('fy', gettext_noop('Frisian')),\n    ('ga', gettext_noop('Irish')),\n    ('gl', gettext_noop('Galician')),\n    ('he', gettext_noop('Hebrew')),\n    ('hi', gettext_noop('Hindi')),\n    ('hr', gettext_noop('Croatian')),\n    ('hu', gettext_noop('Hungarian')),\n    ('ia', gettext_noop('Interlingua')),\n    ('id', gettext_noop('Indonesian')),\n    ('is', gettext_noop('Icelandic')),\n    ('it', gettext_noop('Italian')),\n    ('ja', gettext_noop('Japanese')),\n    ('ka', gettext_noop('Georgian')),\n    ('kk', gettext_noop('Kazakh')),\n    ('km', gettext_noop('Khmer')),\n    ('kn', gettext_noop('Kannada')),\n    ('ko', gettext_noop('Korean')),\n    ('lb', gettext_noop('Luxembourgish')),\n    ('lt', gettext_noop('Lithuanian')),\n    ('lv', gettext_noop('Latvian')),\n    ('mk', gettext_noop('Macedonian')),\n    ('ml', gettext_noop('Malayalam')),\n    ('mn', gettext_noop('Mongolian')),\n    ('my', gettext_noop('Burmese')),\n    ('nb', gettext_noop('Norwegian Bokmal')),\n    ('ne', gettext_noop('Nepali')),\n    ('nl', gettext_noop('Dutch')),\n    ('nn', gettext_noop('Norwegian Nynorsk')),\n    ('os', gettext_noop('Ossetic')),\n    ('pa', gettext_noop('Punjabi')),\n    ('pl', gettext_noop('Polish')),\n    ('pt', gettext_noop('Portuguese')),\n    ('pt-br', gettext_noop('Brazilian Portuguese')),\n    ('ro', gettext_noop('Romanian')),\n    ('ru', gettext_noop('Russian')),\n    ('sk', gettext_noop('Slovak')),\n    ('sl', gettext_noop('Slovenian')),\n    ('sq', gettext_noop('Albanian')),\n    ('sr', gettext_noop('Serbian')),\n    ('sr-latn', gettext_noop('Serbian Latin')),\n    ('sv', gettext_noop('Swedish')),\n    ('sw', gettext_noop('Swahili')),\n    ('ta', gettext_noop('Tamil')),\n    ('te', gettext_noop('Telugu')),\n    ('th', gettext_noop('Thai')),\n    ('tr', gettext_noop('Turkish')),\n    ('tt', gettext_noop('Tatar')),\n    ('udm', gettext_noop('Udmurt')),\n    ('uk', gettext_noop('Ukrainian')),\n    ('ur', gettext_noop('Urdu')),\n    ('vi', gettext_noop('Vietnamese')),\n    ('zh-cn', gettext_noop('Simplified Chinese')),\n    ('zh-hans', gettext_noop('Simplified Chinese')),\n    ('zh-hant', gettext_noop('Traditional Chinese')),\n    ('zh-tw', gettext_noop('Traditional Chinese')),\n)\n# Languages using BiDi (right-to-left) layout\nLANGUAGES_BIDI = (\"he\", \"ar\", \"fa\", \"ur\")\n# If you set this to False, Django will make some optimizations so as not\n# to load the internationalization machinery.\nUSE_I18N = True\nLOCALE_PATHS = ()\n# Settings for language cookie\nLANGUAGE_COOKIE_NAME = 'django_language'\nLANGUAGE_COOKIE_AGE = None\nLANGUAGE_COOKIE_DOMAIN = None\nLANGUAGE_COOKIE_PATH = '/'\n# If you set this to True, Django will format dates, numbers and calendars\n# according to user current locale.\nUSE_L10N = False\n# Not-necessarily-technical managers of the site. They get broken link\n# notifications and other various emails.\nMANAGERS = ADMINS\n# Default content type and charset to use for all HttpResponse objects, if a\n# MIME type isn't manually specified. These are used to construct the\n# Content-Type header.\nDEFAULT_CONTENT_TYPE = 'text/html'\nDEFAULT_CHARSET = 'utf-8'\n# Encoding of files read from disk (template and initial SQL files).\nFILE_CHARSET = 'utf-8'\n# Email address that error messages come from.\nSERVER_EMAIL = 'root@localhost'\n# Whether to send broken-link emails. Deprecated, must be removed in 1.8.\nSEND_BROKEN_LINK_EMAILS = False\n# Database connection info. If left empty, will default to the dummy backend.\nDATABASES = {}\n# Classes used to implement DB routing behavior.\nDATABASE_ROUTERS = []\n# The email backend to use. For possible shortcuts see django.core.mail.\n# The default is to use the SMTP backend.\n# Third-party backends can be specified by providing a Python path\n# to a module that defines an EmailBackend class.\nEMAIL_BACKEND = 'django.core.mail.backends.smtp.EmailBackend'\n# Host for sending email.\nEMAIL_HOST = 'localhost'\n# Port for sending email.\nEMAIL_PORT = 25\n# Optional SMTP authentication information for EMAIL_HOST.\nEMAIL_HOST_USER = ''\nEMAIL_HOST_PASSWORD = ''\nEMAIL_USE_TLS = False\nEMAIL_USE_SSL = False\n# List of strings representing installed apps.\nINSTALLED_APPS = ()\n# List of locations of the template source files, in search order.\nTEMPLATE_DIRS = ()\n# List of callables that know how to import templates from various sources.\n# See the comments in django/core/template/loader.py for interface\n# documentation.\nTEMPLATE_LOADERS = (\n    'django.template.loaders.filesystem.Loader',\n    'django.template.loaders.app_directories.Loader',\n    # 'django.template.loaders.eggs.Loader',\n)\n# List of processors used by RequestContext to populate the context.\n# Each one should be a callable that takes the request object as its\n# only parameter and returns a dictionary to add to the context.\nTEMPLATE_CONTEXT_PROCESSORS = (\n    'django.contrib.auth.context_processors.auth',\n    'django.core.context_processors.debug',\n    'django.core.context_processors.i18n',\n    'django.core.context_processors.media',\n    'django.core.context_processors.static',\n    'django.core.context_processors.tz',\n    # 'django.core.context_processors.request',\n    'django.contrib.messages.context_processors.messages',\n)\n# Output to use in template system for invalid (e.g. misspelled) variables.\nTEMPLATE_STRING_IF_INVALID = ''\n# Default email address to use for various automated correspondence from\n# the site managers.\nDEFAULT_FROM_EMAIL = 'webmaster@localhost'\n# Subject-line prefix for email messages send with django.core.mail.mail_admins\n# or ...mail_managers.  Make sure to include the trailing space.\nEMAIL_SUBJECT_PREFIX = '[Django] '\n# Whether to append trailing slashes to URLs.\nAPPEND_SLASH = True\n# Whether to prepend the \"www.\" subdomain to URLs that don't have it.\nPREPEND_WWW = False\n# Override the server-derived value of SCRIPT_NAME\nFORCE_SCRIPT_NAME = None\n# List of compiled regular expression objects representing User-Agent strings\n# that are not allowed to visit any page, systemwide. Use this for bad\n# robots/crawlers. Here are a few examples:\n#     import re\n#     DISALLOWED_USER_AGENTS = (\n#         re.compile(r'^NaverBot.*'),\n#         re.compile(r'^EmailSiphon.*'),\n#         re.compile(r'^SiteSucker.*'),\n#         re.compile(r'^sohu-search')\n#     )\nDISALLOWED_USER_AGENTS = ()\nABSOLUTE_URL_OVERRIDES = {}\n# Tuple of strings representing allowed prefixes for the {% ssi %} tag.\n# Example: ('/home/html', '/var/www')\nALLOWED_INCLUDE_ROOTS = ()\n# If this is a admin settings module, this should be a list of\n# settings modules (in the format 'foo.bar.baz') for which this admin\n# is an admin.\nADMIN_FOR = ()\n# List of compiled regular expression objects representing URLs that need not\n# be reported by BrokenLinkEmailsMiddleware. Here are a few examples:\n#    import re\n#    IGNORABLE_404_URLS = (\n#        re.compile(r'^/apple-touch-icon.*\\.png$'),\n#        re.compile(r'^/favicon.ico$),\n#        re.compile(r'^/robots.txt$),\n#        re.compile(r'^/phpmyadmin/),\n#        re.compile(r'\\.(cgi|php|pl)$'),\n#    )\nIGNORABLE_404_URLS = ()\n# A secret key for this particular Django installation. Used in secret-key\n# hashing algorithms. Set this in your settings, or Django will complain\n# loudly.\nSECRET_KEY = ''\n# Default file storage mechanism that holds media.\nDEFAULT_FILE_STORAGE = 'django.core.files.storage.FileSystemStorage'\n# Absolute filesystem path to the directory that will hold user-uploaded files.\n# Example: \"/var/www/example.com/media/\"\nMEDIA_ROOT = ''\n# URL that handles the media served from MEDIA_ROOT.\n# Examples: \"http://example.com/media/\", \"http://media.example.com/\"\nMEDIA_URL = ''\n# Absolute path to the directory static files should be collected to.\n# Example: \"/var/www/example.com/static/\"\nSTATIC_ROOT = None\n# URL that handles the static files served from STATIC_ROOT.\n# Example: \"http://example.com/static/\", \"http://static.example.com/\"\nSTATIC_URL = None\n# List of upload handler classes to be applied in order.\nFILE_UPLOAD_HANDLERS = (\n    'django.core.files.uploadhandler.MemoryFileUploadHandler',\n    'django.core.files.uploadhandler.TemporaryFileUploadHandler',\n)\n# Maximum size, in bytes, of a request before it will be streamed to the\n# file system instead of into memory.\nFILE_UPLOAD_MAX_MEMORY_SIZE = 2621440  # i.e. 2.5 MB\n# Directory in which upload streamed files will be temporarily saved. A value of\n# `None` will make Django use the operating system's default temporary directory\n# (i.e. \"/tmp\" on *nix systems).\nFILE_UPLOAD_TEMP_DIR = None\n# The numeric mode to set newly-uploaded files to. The value should be a mode\n# you'd pass directly to os.chmod; see http://docs.python.org/lib/os-file-dir.html.\nFILE_UPLOAD_PERMISSIONS = None\n# The numeric mode to assign to newly-created directories, when uploading files.\n# The value should be a mode as you'd pass to os.chmod;\n# see http://docs.python.org/lib/os-file-dir.html.\nFILE_UPLOAD_DIRECTORY_PERMISSIONS = None\n# Python module path where user will place custom format definition.\n# The directory where this setting is pointing should contain subdirectories\n# named as the locales, containing a formats.py file\n# (i.e. \"myproject.locale\" for myproject/locale/en/formats.py etc. use)\nFORMAT_MODULE_PATH = None\n# Default formatting for date objects. See all available format strings here:\n# http://docs.djangoproject.com/en/dev/ref/templates/builtins/#date\nDATE_FORMAT = 'N j, Y'\n# Default formatting for datetime objects. See all available format strings here:\n# http://docs.djangoproject.com/en/dev/ref/templates/builtins/#date\nDATETIME_FORMAT = 'N j, Y, P'\n# Default formatting for time objects. See all available format strings here:\n# http://docs.djangoproject.com/en/dev/ref/templates/builtins/#date\nTIME_FORMAT = 'P'\n# Default formatting for date objects when only the year and month are relevant.\n# See all available format strings here:\n# http://docs.djangoproject.com/en/dev/ref/templates/builtins/#date\nYEAR_MONTH_FORMAT = 'F Y'\n# Default formatting for date objects when only the month and day are relevant.\n# See all available format strings here:\n# http://docs.djangoproject.com/en/dev/ref/templates/builtins/#date\nMONTH_DAY_FORMAT = 'F j'\n# Default short formatting for date objects. See all available format strings here:\n# http://docs.djangoproject.com/en/dev/ref/templates/builtins/#date\nSHORT_DATE_FORMAT = 'm/d/Y'\n# Default short formatting for datetime objects.\n# See all available format strings here:\n# http://docs.djangoproject.com/en/dev/ref/templates/builtins/#date\nSHORT_DATETIME_FORMAT = 'm/d/Y P'\n# Default formats to be used when parsing dates from input boxes, in order\n# See all available format string here:\n# http://docs.python.org/library/datetime.html#strftime-behavior\n# * Note that these format strings are different from the ones to display dates\nDATE_INPUT_FORMATS = (\n    '%Y-%m-%d', '%m/%d/%Y', '%m/%d/%y',  # '2006-10-25', '10/25/2006', '10/25/06'\n    '%b %d %Y', '%b %d, %Y',             # 'Oct 25 2006', 'Oct 25, 2006'\n    '%d %b %Y', '%d %b, %Y',             # '25 Oct 2006', '25 Oct, 2006'\n    '%B %d %Y', '%B %d, %Y',             # 'October 25 2006', 'October 25, 2006'\n    '%d %B %Y', '%d %B, %Y',             # '25 October 2006', '25 October, 2006'\n)\n# Default formats to be used when parsing times from input boxes, in order\n# See all available format string here:\n# http://docs.python.org/library/datetime.html#strftime-behavior\n# * Note that these format strings are different from the ones to display dates\nTIME_INPUT_FORMATS = (\n    '%H:%M:%S',     # '14:30:59'\n    '%H:%M:%S.%f',  # '14:30:59.000200'\n    '%H:%M',        # '14:30'\n)\n# Default formats to be used when parsing dates and times from input boxes,\n# in order\n# See all available format string here:\n# http://docs.python.org/library/datetime.html#strftime-behavior\n# * Note that these format strings are different from the ones to display dates\nDATETIME_INPUT_FORMATS = (\n    '%Y-%m-%d %H:%M:%S',     # '2006-10-25 14:30:59'\n    '%Y-%m-%d %H:%M:%S.%f',  # '2006-10-25 14:30:59.000200'\n    '%Y-%m-%d %H:%M',        # '2006-10-25 14:30'\n    '%Y-%m-%d',              # '2006-10-25'\n    '%m/%d/%Y %H:%M:%S',     # '10/25/2006 14:30:59'\n    '%m/%d/%Y %H:%M:%S.%f',  # '10/25/2006 14:30:59.000200'\n    '%m/%d/%Y %H:%M',        # '10/25/2006 14:30'\n    '%m/%d/%Y',              # '10/25/2006'\n    '%m/%d/%y %H:%M:%S',     # '10/25/06 14:30:59'\n    '%m/%d/%y %H:%M:%S.%f',  # '10/25/06 14:30:59.000200'\n    '%m/%d/%y %H:%M',        # '10/25/06 14:30'\n    '%m/%d/%y',              # '10/25/06'\n)\n# First day of week, to be used on calendars\n# 0 means Sunday, 1 means Monday...\nFIRST_DAY_OF_WEEK = 0\n# Decimal separator symbol\nDECIMAL_SEPARATOR = '.'\n# Boolean that sets whether to add thousand separator when formatting numbers\nUSE_THOUSAND_SEPARATOR = False\n# Number of digits that will be together, when splitting them by\n# THOUSAND_SEPARATOR. 0 means no grouping, 3 means splitting by thousands...\nNUMBER_GROUPING = 0\n# Thousand separator symbol\nTHOUSAND_SEPARATOR = ','\n# Do you want to manage transactions manually?\n# Hint: you really don't!\nTRANSACTIONS_MANAGED = False\n# The tablespaces to use for each model when not specified otherwise.\nDEFAULT_TABLESPACE = ''\nDEFAULT_INDEX_TABLESPACE = ''\n# Default X-Frame-Options header value\nX_FRAME_OPTIONS = 'SAMEORIGIN'\nUSE_X_FORWARDED_HOST = False\n# The Python dotted path to the WSGI application that Django's internal servers\n# (runserver, runfcgi) will use. If `None`, the return value of\n# 'django.core.wsgi.get_wsgi_application' is used, thus preserving the same\n# behavior as previous versions of Django. Otherwise this should point to an\n# actual WSGI application object.\nWSGI_APPLICATION = None\n# If your Django app is behind a proxy that sets a header to specify secure\n# connections, AND that proxy ensures that user-submitted headers with the\n# same name are ignored (so that people can't spoof it), set this value to\n# a tuple of (header_name, header_value). For any requests that come in with\n# that header/value, request.is_secure() will return True.\n# WARNING! Only set this if you fully understand what you're doing. Otherwise,\n# you may be opening yourself up to a security risk.\nSECURE_PROXY_SSL_HEADER = None\n##############\n# MIDDLEWARE #\n##############\n# List of middleware classes to use.  Order is important; in the request phase,\n# this middleware classes will be applied in the order given, and in the\n# response phase the middleware will be applied in reverse order.\nMIDDLEWARE_CLASSES = (\n    'django.middleware.common.CommonMiddleware',\n    'django.contrib.sessions.middleware.SessionMiddleware',\n    'django.middleware.csrf.CsrfViewMiddleware',\n    'django.contrib.auth.middleware.AuthenticationMiddleware',\n    'django.contrib.messages.middleware.MessageMiddleware',\n    # 'django.middleware.http.ConditionalGetMiddleware',\n    # 'django.middleware.gzip.GZipMiddleware',\n)\n############\n# SESSIONS #\n############\nSESSION_CACHE_ALIAS = 'default'                         # Cache to store session data if using the cache session backend.\nSESSION_COOKIE_NAME = 'sessionid'                       # Cookie name. This can be whatever you want.\nSESSION_COOKIE_AGE = 60 * 60 * 24 * 7 * 2               # Age of cookie, in seconds (default: 2 weeks).\nSESSION_COOKIE_DOMAIN = None                            # A string like \".example.com\", or None for standard domain cookie.\nSESSION_COOKIE_SECURE = False                           # Whether the session cookie should be secure (https:// only).\nSESSION_COOKIE_PATH = '/'                               # The path of the session cookie.\nSESSION_COOKIE_HTTPONLY = True                          # Whether to use the non-RFC standard httpOnly flag (IE, FF3+, others)\nSESSION_SAVE_EVERY_REQUEST = False                      # Whether to save the session data on every request.\nSESSION_EXPIRE_AT_BROWSER_CLOSE = False                 # Whether a user's session cookie expires when the Web browser is closed.\nSESSION_ENGINE = 'django.contrib.sessions.backends.db'  # The module to store session data\nSESSION_FILE_PATH = None                                # Directory to store session files if using the file session module. If None, the backend will use a sensible default.\nSESSION_SERIALIZER = 'django.contrib.sessions.serializers.JSONSerializer'  # class to serialize session data\n#########\n# CACHE #\n#########\n# The cache backends to use.\nCACHES = {\n    'default': {\n        'BACKEND': 'django.core.cache.backends.locmem.LocMemCache',\n    }\n}\nCACHE_MIDDLEWARE_KEY_PREFIX = ''\nCACHE_MIDDLEWARE_SECONDS = 600\nCACHE_MIDDLEWARE_ALIAS = 'default'\n####################\n# COMMENTS         #\n####################\nCOMMENTS_ALLOW_PROFANITIES = False\n# The profanities that will trigger a validation error in\n# CommentDetailsForm.clean_comment. All of these should be in lowercase.\nPROFANITIES_LIST = ()\n##################\n# AUTHENTICATION #\n##################\nAUTH_USER_MODEL = 'auth.User'\nAUTHENTICATION_BACKENDS = ('django.contrib.auth.backends.ModelBackend',)\nLOGIN_URL = '/accounts/login/'\n", "outputs": ["LOGOUT_URL = '/accounts/logout/'"], "input_length": 4015, "output_length": 4, "length": 4019, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "44b44ac403515461ed0ebdc393343202cb3d6442002f4b5a4a6e404c1340a298"}
{"input": "", "context": "from ctypes import Structure, c_double, c_int, byref, memmove, sizeof, c_uint32, c_uint, c_ulong\nfrom . import clibrebound\nimport math\nimport ctypes.util\nimport rebound\nimport sys\nimport random\n__all__ = [\"Particle\"]\ndef notNone(a):\n    \"\"\"\n    Returns True if array a contains at least one element that is not None. Returns False otherwise.\n    \"\"\"\n    return a.count(None) != len(a)\nclass Particle(Structure):\n    \"\"\"\n    The main REBOUND particle data structure. \n    This is an abstraction of the reb_particle structure in C.\n    The Particle fields are set at the end of simulation.py to avoid circular references.\n    \n    Attributes\n    ----------\n    x, y, z     : float       \n        Particle positions\n    vx, vy, vz  : float       \n        Particle velocities\n    ax, ay, az  : float       \n        Particle accelerations\n    m           : float       \n        Particle mass\n    r           : float       \n        Particle radius\n    lastcollision : float       \n        Last time the particle had a physical collision (if checking for collisions)\n    c           : c_void_p (C void pointer) \n        Pointer to the cell the particle is currently in (if using tree code)\n    hash          : c_uint32         \n        Particle hash (permanent identifier for the particle)\n    ap          : c_void_p (C void pointer)\n        Pointer to additional parameters one might want to add to particles\n    _sim        : POINTER(rebound.Simulation)\n        Internal pointer to the parent simulation (used in C version of REBOUND)\n    a, e, inc, Omega, omega, f\t: float\n\t    (Kepler Elements) Semi-major axis, eccentricity, inclination, longitude of the ascending node, argument of periapsis, and true anomaly respectively. The Keplerian Elements are in Jacobi coordinates (with mu = G*Minc, where Minc is the total mass from index 0 to the particle's index, inclusive).\n    \"\"\"\n    def __str__(self):\n        \"\"\" \n        Returns a string with the position and velocity of the particle.\n        \"\"\"\n        return \"<rebound.Particle object, m=%s x=%s y=%s z=%s vx=%s vy=%s vz=%s>\"%(self.m,self.x,self.y,self.z,self.vx,self.vy,self.vz)\n   \n    __repr__ = __str__\n    def __init__(self, simulation=None, particle=None, m=None, x=None, y=None, z=None, vx=None, vy=None, vz=None, primary=None, a=None, P=None, e=None, inc=None, Omega=None, omega=None, pomega=None, f=None, M=None, l=None, theta=None, T=None, r=None, date=None, variation=None, variation2=None, h=None, k=None, ix=None, iy=None, hash=0, jacobi_masses=False):\n        \"\"\"\n        Initializes a Particle structure. Rather than explicitly creating \n        a Particle structure, users may use the ``add()`` member function \n        of a Simulation instance, which will both create a Particle and \n        then add it to the simulation with one function call.\n        This function accepts either cartesian positions and velocities, \n        classical orbital elements together with the reference Particle \n        (the primary), as well as orbital parameters defined by Pal (2009).\n        For convenience, optional keywords that are not passed default \n        to zero (mass, cartesian and orbital elements). \n        Whenever initializing a particle from orbital elements, one must \n        specify either the semimajor axis or the period of the orbit.\n        \n        For classical orbital paramerers, one can specify the longitude \n        of the ascending node by passing Omega, to specify the pericenter \n        one can pass either omega or pomega (not both), and for the \n        longitude/anomaly one can pass one of f, M, l or theta.  \n        See ipython_examples/OrbitalElements.ipynb for examples.  \n        See also Murray & Dermott Solar System Dynamics for formal \n        definitions of angles in orbital mechanics.\n        All angles should be specified in radians.\n        \n        Parameters\n        ----------\n        simulation  : Simulation  \n            Simulation instance associated with this particle (Required if passing orbital elements or setting up a variation).\n        particle    : Particle, optional    \n            If a particle is passed, a copy of that particle is returned.\n            If a variational particle is initialized, then ``particle`` is \n            original particle that will be varied. \n        m           : float       \n            Mass        (Default: 0)\n        x, y, z     : float       \n            Positions in Cartesian coordinates  (Default: 0)\n        vx, vy, vz  : float       \n            Velocities in Cartesian coordinates (Default: 0)\n        primary     : Particle    \n            Primary body for converting orbital elements to cartesian (Default: center of mass of the particles in the passed simulation, i.e., this will yield Jacobi coordinates as one progressively adds particles) \n        a           : float       \n            Semimajor axis (a or P required if passing orbital elements)\n        P           : float\n            Orbital period (a or P required if passing orbital elements)\n        e           : float       \n            Eccentricity                (Default: 0)\n        inc         : float       \n            Inclination                 (Default: 0)\n        Omega       : float       \n            Longitude of ascending node (Default: 0)\n        omega       : float       \n            Argument of pericenter      (Default: 0)\n        pomega      : float       \n            Longitude of pericenter     (Default: 0)\n        f           : float       \n            True anomaly                (Default: 0)\n        M           : float       \n            Mean anomaly                (Default: 0)\n        l           : float       \n            Mean longitude              (Default: 0)\n        theta       : float       \n            True longitude              (Default: 0)\n        T           : float \n            Time of pericenter passage  \n        h           : float       \n            h variable, see Pal (2009) for a definition  (Default: 0)\n        k           : float       \n            k variable, see Pal (2009) for a definition  (Default: 0)\n        ix          : float       \n            ix variable, see Pal (2009) for a definition  (Default: 0)\n        iy           : float       \n            iy variable, see Pal (2009) for a definition  (Default: 0)\n        r           : float       \n            Particle radius (only used for collisional simulations)\n        date        : string      \n            For consistency with adding particles through horizons.  Not used here.\n        variation   : string            (Default: None)\n            Set this string to the name of an orbital parameter to initialize the particle as a variational particle.\n            Can be one of the following: m, a, e, inc, omega, Omega, f, k, h, lambda, ix, iy.\n        variation2  : string            (Default: None)\n            Set this string to the name of a second orbital parameter to initialize the particle as a second order variational particle. Only used for second order variational equations. \n            Can be one of the following: m, a, e, inc, omega, Omega, f, k, h, lambda, ix, iy.\n        hash        : c_uint32  \n            Unsigned integer identifier for particle.  Can pass an integer directly, or a string that will be converted to a hash. User is responsible for assigning unique hashes.\n        jacobi_masses: bool\n            Whether to use jacobi primary mass in orbit initialization. Particle mass will still be set to physical value (Default: False)\n        Examples\n        --------\n        >>> sim = rebound.Simulation()\n        >>> sim.add(m=1.)\n        >>> p1 = rebound.Particle(simulation=sim, m=0.001, a=0.5, e=0.01)\n        >>> p2 = rebound.Particle(simulation=sim, m=0.0, x=1., vy=1.)\n        >>> p3 = rebound.Particle(simulation=sim, m=0.001, a=1.5, h=0.1, k=0.2, l=0.1)\n        >>> p4 = rebound.Particle(simulation=sim, m=0.001, a=1.5, omega=\"uniform\")  # omega will be a random number between 0 and 2pi\n        \"\"\"        \n        if Omega == \"uniform\":\n            Omega = random.vonmisesvariate(0.,0.) \n        if omega == \"uniform\":\n            omega = random.vonmisesvariate(0.,0.) \n        if pomega == \"uniform\":\n            pomega = random.vonmisesvariate(0.,0.) \n        if f == \"uniform\":\n            f = random.vonmisesvariate(0.,0.) \n        if M == \"uniform\":\n            M = random.vonmisesvariate(0.,0.) \n        if l == \"uniform\":\n            l = random.vonmisesvariate(0.,0.) \n        if theta == \"uniform\":\n            theta = random.vonmisesvariate(0.,0.) \n        self.hash = hash # set via the property, which checks for type\n        if variation:\n            if primary is None:\n                primary = simulation.particles[0]\n            # Find particle to differenciate\n            lc = locals().copy()\n            del lc[\"self\"]\n            del lc[\"variation\"]\n            del lc[\"variation2\"]\n            if particle is None:\n                particle = Particle(**lc)\n            # First or second order?\n            if variation and variation2:\n                variation_order = 2\n            else:\n                variation_order = 1\n            # Shortcuts for variable names\n            if variation == \"l\":\n                variation = \"lambda\"\n            if variation2 == \"l\":\n                variation2 = \"lambda\"\n            if variation == \"i\":\n                variation = \"inc\"\n            if variation2 == \"i\":\n                variation2 = \"inc\"\n            variationtypes = [\"m\",\"a\",\"e\",\"inc\",\"omega\",\"Omega\",\"f\",\"k\",\"h\",\"lambda\",\"ix\",\"iy\"]\n            if variation_order==1:\n                if variation in variationtypes:\n                    method = getattr(clibrebound, 'reb_derivatives_'+variation)\n                    method.restype = Particle\n                    p = method(c_double(simulation.G), primary, particle)\n                else:\n                    raise ValueError(\"Variational particles can only be initializes using the derivatives with respect to one of the following: %s.\"%\", \".join(variationtypes))\n            elif variation_order==2:\n                if variation in variationtypes and variation2 in variationtypes:\n                    # Swap variations if needed\n                    vi1 = variationtypes.index(variation)\n                    vi2 = variationtypes.index(variation2)\n                    if vi2 < vi1:\n                        variation, variation2 = variation2, variation\n                    method = getattr(clibrebound, 'reb_derivatives_'+variation+'_'+variation2)\n                    method.restype = Particle\n                    p = method(c_double(simulation.G), primary, particle)\n                else:\n                    raise ValueError(\"Variational particles can only be initializes using the derivatives with respect to one of the following: %s.\"%\", \".join(variationtypes))\n            else:\n                raise ValueError(\"Variational equations beyond second order are not implemented.\")\n            self.m = p.m\n            self.x = p.x\n            self.y = p.y\n            self.z = p.z\n            self.vx = p.vx\n            self.vy = p.vy\n            self.vz = p.vz\n            return \n        if particle is not None:\n            memmove(byref(self), byref(particle), sizeof(self))\n            return\n        cart = [x,y,z,vx,vy,vz]\n        orbi = [primary,a,P,e,inc,Omega,omega,pomega,f,M,l,theta,T]\n        pal  = [h,k,ix,iy]\n       \n        self.ax = 0.\n        self.ay = 0.\n        self.az = 0.\n        if m is None:\n            self.m = 0.\n        else:\n            self.m = m \n        if r is None:\n            self.r = 0.\n        else:\n            self.r = r\n        self.lastcollision = 0.\n        self.c = None\n        self.ap = None\n        \n        if notNone([e,inc,omega,pomega,Omega,M,f,theta,T]) and notNone(pal):\n            raise ValueError(\"You cannot mix Pal coordinates (h,k,ix,iy) with the following orbital elements: e,inc,Omega,omega,pomega,f,M,theta,T. If a longitude/anomaly is needed in Pal coordinates, use l.\")\n        if notNone(cart) and notNone(orbi):\n                raise ValueError(\"You cannot pass cartesian coordinates and orbital elements (and/or primary) at the same time.\")\n        if notNone(orbi):\n            if simulation is None:\n                raise ValueError(\"Need to specify simulation when initializing particle with orbital elements.\")\n            if primary is None:\n                clibrebound.reb_get_com.restype = Particle\n                primary = clibrebound.reb_get_com(byref(simulation)) # this corresponds to adding in Jacobi coordinates\n            if jacobi_masses is True:\n                interior_mass = 0\n                for p in simulation.particles:\n                    interior_mass += p.m\n                # orbit conversion uses mu=G*(p.m+primary.m) so set prim.m=Mjac-m so mu=G*Mjac\n                primary.m = simulation.particles[0].m*(self.m + interior_mass)/interior_mass - self.m\n            if a is None and P is None:\n                raise ValueError(\"You need to pass either a semimajor axis or orbital period to initialize the particle using orbital elements.\")\n            if a is not None and P is not None:\n                raise ValueError(\"You can pass either the semimajor axis or orbital period, but not both.\")\n            if a is None:\n                a = (P**2*simulation.G*(primary.m + self.m)/(4.*math.pi**2))**(1./3.)\n            if notNone(pal):\n                # Pal orbital parameters\n                if h is None:\n                    h = 0.\n                if k is None:\n                    k = 0.\n                if l is None:\n                    l = 0.\n                if ix is None:\n                    ix = 0.\n                if iy is None:\n                    iy = 0.\n                if((ix*ix + iy*iy) > 4.0):\n                    raise ValueError(\"Passed (ix, iy) coordinates are not valid, squared sum exceeds 4.\")\n                clibrebound.reb_tools_pal_to_particle.restype = Particle\n                p = clibrebound.reb_tools_pal_to_particle(c_double(simulation.G), primary, c_double(self.m), c_double(a), c_double(l), c_double(k), c_double(h), c_double(ix), c_double(iy))\n            else:\n                # Normal orbital parameters\n                if e is None:\n                    e = 0.\n                if inc is None:\n                    inc = 0.\n                if Omega is None:               # we require that Omega be passed if you want to specify longitude of node\n                    Omega = 0.\n                pericenters = [omega, pomega]   # Need omega for C function. Can specify it either directly or through pomega indirectly. \n                numNones = pericenters.count(None)\n                if numNones == 0:\n                    raise ValueError(\"Can't pass both omega and pomega\")\n                if numNones == 2:                   # Neither passed.  Default to 0.\n                    omega = 0.\n                if numNones == 1:\n                    if pomega is not None:          # Only have to find omega is pomega was passed\n                        if math.cos(inc) > 0:       # inc is in range [-pi/2, pi/2] (prograde), so pomega = Omega + omega\n                            omega = pomega - Omega\n                        else:\n                            omega = Omega - pomega  # for retrograde orbits, pomega = Omega - omega\n                longitudes = [f,M,l,theta,T]      # can specify longitude through any of these four.  Need f for C function.\n                numNones = longitudes.count(None)\n                if numNones < 4:\n                    raise ValueError(\"Can only pass one longitude/anomaly in the set [f, M, l, theta, T]\")\n                if numNones == 5:                           # none of them passed.  Default to 0.\n                    f = 0.\n                if numNones == 4:                           # Only one was passed.\n                    if f is None:                           # Only have to work if f wasn't passed.\n                        if theta is not None:               # theta is next easiest\n                            if math.cos(inc) > 0:           # for prograde orbits, theta = Omega + omega + f\n                                f = theta - Omega - omega\n                            else:\n                                f = Omega - omega - theta   # for retrograde, theta = Omega - omega - f\n                        else:                               # Either M, l, or T was passed.  Will need to find M first (if not passed) to find f\n                            if l is not None:\n                                if math.cos(inc) > 0:       # for prograde orbits, l = Omega + omega + M\n                                    M = l - Omega - omega\n                                else:\n                                    M = Omega - omega - l   # for retrograde, l = Omega - omega - M\n                            else:\n                                if T is not None:           # works for both elliptical and hyperbolic orbits\n                                                            # TODO: has accuracy problems for M=n*(t-T) << 1\n                                    n = (simulation.G*(primary.m+self.m)/abs(a**3))**0.5\n                                    M = n*(simulation.t - T)\n                            clibrebound.reb_tools_M_to_f.restype = c_double\n                            f = clibrebound.reb_tools_M_to_f(c_double(e), c_double(M))\n                err = c_int()\n                clibrebound.reb_tools_orbit_to_particle_err.restype = Particle\n                p = clibrebound.reb_tools_orbit_to_particle_err(c_double(simulation.G), primary, c_double(self.m), c_double(a), c_double(e), c_double(inc), c_double(Omega), c_double(omega), c_double(f), byref(err))\n                if err.value == 1:\n                    raise ValueError(\"Can't set e exactly to 1.\")\n                if err.value == 2:\n                    raise ValueError(\"Eccentricity must be greater than or equal to zero.\")\n                if err.value == 3:\n                    raise ValueError(\"Bound orbit (a > 0) must have e < 1.\")\n                if err.value == 4:\n                    raise ValueError(\"Unbound orbit (a < 0) must have e > 1.\")\n                if err.value == 5:\n                    raise ValueError(\"Unbound orbit can't have f beyond the range allowed by the asymptotes set by the hyperbola.\")\n                if err.value == 6:\n                    raise ValueError(\"Primary has no mass.\")\n            self.x = p.x\n            self.y = p.y\n            self.z = p.z\n            self.vx = p.vx\n            self.vy = p.vy\n            self.vz = p.vz\n        else:\n            if x is None:\n                x = 0.\n            if y is None:\n                y = 0.\n            if z is None:\n                z = 0.\n            if vx is None:\n                vx = 0.\n            if vy is None:\n                vy = 0.\n            if vz is None:\n                vz = 0.\n            self.x = x\n            self.y = y\n            self.z = z\n            self.vx = vx\n            self.vy = vy\n            self.vz = vz\n        \n    def copy(self):\n        \"\"\"\n        Returns a deep copy of the particle. The particle is not added to any simulation by default.\n        \"\"\"\n        np = Particle()\n        memmove(byref(np), byref(self), sizeof(self))\n        return np\n    def calculate_orbit(self, primary=None, G=None):\n        \"\"\" \n        Returns a rebound.Orbit object with the keplerian orbital elements\n        corresponding to the particle around the passed primary\n        (rebound.Particle) If no primary is passed, defaults to Jacobi coordinates\n        (with mu = G*Minc, where Minc is the total mass from index 0 to the particle's index, inclusive). \n        \n        Examples\n        --------\n        \n        >>> sim = rebound.Simulation()\n        >>> sim.add(m=1.)\n        >>> sim.add(x=1.,vy=1.)\n        >>> orbit = sim.particles[1].calculate_orbit(sim.particles[0])\n        >>> print(orbit.e) # gives the eccentricity\n        Parameters\n        ----------\n        primary : rebound.Particle\n            Central body (Optional. Default uses Jacobi coordinates)\n        G : float\n            Gravitational constant (Optional. Default takes G from simulation in which particle is in)\n        \n        Returns\n        -------\n        A rebound.Orbit object \n        \"\"\"\n        if not self._sim:\n            # Particle not in a simulation\n            if primary is None:\n                raise ValueError(\"Particle does not belong to any simulation and no primary given. Cannot calculate orbit.\")\n            if G is None:\n                raise ValueError(\"Particle does not belong to any simulation and G not given. Cannot calculate orbit.\")\n            else:\n                G = c_double(G)\n        else:\n            # First check whether this is particles[0]\n            clibrebound.reb_get_particle_index.restype = c_int\n            index = clibrebound.reb_get_particle_index(byref(self)) # first check this isn't particles[0]\n            if index == 0 and primary is None:\n                raise ValueError(\"Orbital elements for particle[0] not implemented unless primary is provided\")\n            if primary is None:    # Use default, i.e., Jacobi coordinates\n                clibrebound.reb_get_jacobi_com.restype = Particle   # now return jacobi center of mass\n                primary = clibrebound.reb_get_jacobi_com(byref(self))\n            G = c_double(self._sim.contents.G)\n        \n        err = c_int()\n        clibrebound.reb_tools_particle_to_orbit_err.restype = rebound.Orbit\n        o = clibrebound.reb_tools_particle_to_orbit_err(G, self, primary, byref(err))\n        if err.value == 1:\n            raise ValueError(\"Primary has no mass.\")\n        if err.value == 2:\n            raise ValueError(\"Particle and primary positions are the same.\")\n        return o\n    \n    def sample_orbit(self, Npts=100, primary=None, trailing=True, timespan=None, useTrueAnomaly=True):\n        \"\"\"\n        Returns a nested list of xyz positions along the osculating orbit of the particle. \n        If primary is not passed, returns xyz positions along the Jacobi osculating orbit\n        (with mu = G*Minc, where Minc is the total mass from index 0 to the particle's index, inclusive). \n        Parameters\n        ----------\n        Npts    : int, optional  \n            Number of points along the orbit to return  (default: 100)\n        primary : rebound.Particle, optional\n            Primary to use for the osculating orbit (default: Jacobi center of mass)\n        trailing: bool, optional\n            Whether to return points stepping backwards in time (True) or forwards (False). (default: True)\n        timespan: float, optional    \n            Return points (for the osculating orbit) from the current position to timespan (forwards or backwards in time depending on trailing keyword). \n            Defaults to the orbital period for bound orbits, and to the rough time it takes the orbit to move by the current distance from the primary for a hyperbolic orbit. Implementation currently only supports this option if useTrueAnomaly=False.\n        useTrueAnomaly: bool, optional\n            Will sample equally spaced points in true anomaly if True, otherwise in mean anomaly.\n            Latter might be better for hyperbolic orbits, where true anomaly can stay near the limiting value for a long time, and then switch abruptly at pericenter. (Default: True)\n        \"\"\"\n        pts = []\n        if primary is None:\n            primary = self.jacobi_com\n        o = self.calculate_orbit(primary=primary)\n        if timespan is None:\n            if o.a < 0.: # hyperbolic orbit\n                timespan = 2*math.pi*o.d/o.v # rough time to cross display box\n            else:\n                timespan = o.P\n        \n        lim_phase = abs(o.n)*timespan # n is negative for hyperbolic orbits\n        if trailing is True:\n            lim_phase *= -1 # sample phase backwards from current value\n        phase = [lim_phase*i/(Npts-1) for i in range(Npts)]\n        for i,ph in enumerate(phase):\n            if useTrueAnomaly is True:\n                newp = Particle(a=o.a, f=o.f+ph, inc=o.inc, omega=o.omega, Omega=o.Omega, e=o.e, m=self.m, primary=primary, simulation=self._sim.contents)\n            else: \n                newp = Particle(a=o.a, M=o.M+ph, inc=o.inc, omega=o.omega, Omega=o.Omega, e=o.e, m=self.m, primary=primary, simulation=self._sim.contents)\n            pts.append(newp.xyz)\n        \n        return pts\n    # Simple operators for particles.\n    \n    def __add__(self, other):\n        if not isinstance(other, Particle):\n            return NotImplemented \n        c = self.copy()\n        return c.__iadd__(other)\n    \n    def __iadd__(self, other):\n        if not isinstance(other, Particle):\n            return NotImplemented \n        clibrebound.reb_particle_iadd(byref(self), byref(other))\n        return self\n    \n    def __sub__(self, other):\n        if not isinstance(other, Particle):\n            return NotImplemented \n        c = self.copy()\n        return c.__isub__(other)\n    \n    def __isub__(self, other):\n        if not isinstance(other, Particle):\n            return NotImplemented \n        clibrebound.reb_particle_isub(byref(self), byref(other))\n        return self\n    \n    def __mul__(self, other):\n        try:\n            other = float(other)\n        except:\n            return NotImplemented \n        c = self.copy()\n        return c.__imul__(other)\n    \n    def __imul__(self, other):\n        try:\n            other = float(other)\n        except:\n            return NotImplemented \n        clibrebound.reb_particle_imul(byref(self), c_double(other))\n        return self\n    \n    def __rmul__(self, other):\n        try:\n            other = float(other)\n        except:\n            return NotImplemented \n", "outputs": ["        c = self.copy()"], "input_length": 4334, "output_length": 5, "length": 4339, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "b2931b0da189c280c9f897fe4b419bd4608a4f023b47eb35bb34df9f9648aed0"}
{"input": "", "context": "/* -*- tab-width: 4 -*-\n *\n * Electric(tm) VLSI Design System\n *\n * File: CellChangeJobs.java\n *\n * Copyright (c) 2006 Sun Microsystems and Static Free Software\n *\n * Electric(tm) is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 3 of the License, or\n * (at your option) any later version.\n *\n * Electric(tm) is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with Electric(tm); see the file COPYING.  If not, write to\n * the Free Software Foundation, Inc., 59 Temple Place, Suite 330,\n * Boston, Mass 02111-1307, USA.\n */\npackage com.sun.electric.tool.user;\nimport com.sun.electric.database.IdMapper;\nimport com.sun.electric.database.ImmutableArcInst;\nimport com.sun.electric.database.geometry.EGraphics;\nimport com.sun.electric.database.geometry.EPoint;\nimport com.sun.electric.database.geometry.GenMath;\nimport com.sun.electric.database.geometry.Orientation;\nimport com.sun.electric.database.hierarchy.Cell;\nimport com.sun.electric.database.hierarchy.Export;\nimport com.sun.electric.database.hierarchy.Library;\nimport com.sun.electric.database.hierarchy.View;\nimport com.sun.electric.database.id.CellId;\nimport com.sun.electric.database.prototype.NodeProto;\nimport com.sun.electric.database.text.Name;\nimport com.sun.electric.database.topology.ArcInst;\nimport com.sun.electric.database.topology.Geometric;\nimport com.sun.electric.database.topology.NodeInst;\nimport com.sun.electric.database.topology.PortInst;\nimport com.sun.electric.database.variable.ElectricObject;\nimport com.sun.electric.database.variable.TextDescriptor;\nimport com.sun.electric.database.variable.UserInterface;\nimport com.sun.electric.technology.ArcProto;\nimport com.sun.electric.technology.technologies.Artwork;\nimport com.sun.electric.technology.technologies.Generic;\nimport com.sun.electric.tool.Job;\nimport com.sun.electric.tool.JobException;\nimport com.sun.electric.tool.user.ui.EditWindow;\nimport com.sun.electric.tool.user.ui.WindowContent;\nimport com.sun.electric.tool.user.ui.WindowFrame;\nimport java.awt.geom.AffineTransform;\nimport java.awt.geom.Point2D;\nimport java.util.ArrayList;\nimport java.util.HashMap;\nimport java.util.HashSet;\nimport java.util.Iterator;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Set;\n/**\n * Class for Jobs that make changes to the cells.\n */\npublic class CellChangeJobs\n{\n\t// constructor, never used\n\tprivate CellChangeJobs() {}\n\t/****************************** DELETE A CELL ******************************/\n\t/**\n\t * Class to delete a cell in a new thread.\n\t */\n\tpublic static class DeleteCell extends Job\n\t{\n\t\tCell cell;\n\t\tpublic DeleteCell(Cell cell)\n\t\t{\n\t\t\tsuper(\"Delete \" + cell, User.getUserTool(), Job.Type.CHANGE, null, null, Job.Priority.USER);\n\t\t\tthis.cell = cell;\n\t\t\tstartJob();\n\t\t}\n\t\tpublic boolean doIt() throws JobException\n\t\t{\n\t\t\t// check cell usage once more\n\t\t\tif (cell.isInUse(\"delete\", false, true)) return false;\n\t\t\tcell.kill();\n\t\t\treturn true;\n\t\t}\n\t}\n\t/**\n\t * This class implement the command to delete a list of cells.\n\t */\n\tpublic static class DeleteManyCells extends Job\n\t{\n\t\tprivate List<Cell> cellsToDelete;\n\t\tpublic DeleteManyCells(List<Cell> cellsToDelete)\n\t\t{\n\t\t\tsuper(\"Delete Multiple Cells\", User.getUserTool(), Job.Type.CHANGE, null, null, Job.Priority.USER);\n\t\t\tthis.cellsToDelete = cellsToDelete;\n\t\t\tstartJob();\n\t\t}\n\t\tpublic boolean doIt() throws JobException\n\t\t{\n\t\t\t// iteratively delete, allowing cells in use to be deferred\n\t\t\tboolean didDelete = true;\n\t\t\twhile (didDelete)\n\t\t\t{\n\t\t\t\tdidDelete = false;\n\t\t\t\tfor (int i=0; i<cellsToDelete.size(); i++)\n\t\t\t\t{\n\t\t\t\t\tCell cell = cellsToDelete.get(i);\n\t\t\t\t\t// if the cell is in use, defer\n\t\t\t\t\tif (cell.isInUse(null, true, true)) continue;\n\t\t\t\t\t// cell not in use: remove it from the list and delete it\n\t\t\t\t\tcellsToDelete.remove(i);\n\t\t\t\t\ti--;\n\t\t\t\t\tSystem.out.println(\"Deleting \" + cell);\n\t\t\t\t\tcell.kill();\n\t\t\t\t\tdidDelete = true;\n\t\t\t\t}\n\t\t\t}\n\t\t\t// warn about remaining cells that were in use\n\t\t\tfor(Cell cell : cellsToDelete)\n\t\t\t\tcell.isInUse(\"delete\", false, true);\n\t\t\treturn true;\n\t\t}\n\t\tpublic void terminateOK()\n\t\t{\n\t\t\tSystem.out.println(\"Deleted \" + cellsToDelete.size() + \" cells\");\n\t\t\tEditWindow.repaintAll();\n\t\t}\n\t}\n\t/****************************** RENAME CELLS ******************************/\n\t/**\n\t * Class to rename a cell in a new thread.\n\t */\n\tpublic static class RenameCell extends Job\n\t{\n\t\tprivate Cell cell;\n\t\tprivate String newName;\n\t\tprivate String newGroupCell;\n\t\tprivate IdMapper idMapper;\n\t\tpublic RenameCell(Cell cell, String newName, String newGroupCell)\n\t\t{\n\t\t\tsuper(\"Rename \" + cell, User.getUserTool(), Job.Type.CHANGE, null, null, Job.Priority.USER);\n\t\t\tthis.cell = cell;\n\t\t\tthis.newName = newName;\n\t\t\tthis.newGroupCell = newGroupCell;\n\t\t\tstartJob();\n\t\t}\n\t\tpublic boolean doIt() throws JobException\n\t\t{\n\t\t\tidMapper = cell.rename(newName, newGroupCell);\n\t\t\tfieldVariableChanged(\"idMapper\");\n\t\t\treturn true;\n\t\t}\n\t\tpublic void terminateOK()\n\t\t{\n\t\t\tUser.fixStaleCellReferences(idMapper);\n\t\t}\n\t}\n\t/**\n\t * Class to rename a cell in a new thread.\n\t */\n\tpublic static class DeleteCellGroup extends Job\n\t{\n\t\tList<Cell> cells;\n\t\tpublic DeleteCellGroup(Cell.CellGroup group)\n\t\t{\n\t\t\tsuper(\"Delete Cell Group\", User.getUserTool(), Job.Type.CHANGE, null, null, Job.Priority.USER);\n\t\t\tcells = new ArrayList<Cell>();\n\t\t\tfor(Iterator<Cell> it = group.getCells(); it.hasNext(); )\n\t\t\t{\n\t\t\t\tcells.add(it.next());\n\t\t\t}\n\t\t\tstartJob();\n\t\t}\n\t\tpublic boolean doIt() throws JobException\n\t\t{\n\t\t\tfor(Cell cell : cells)\n\t\t\t{\n\t\t\t\t// Doesn't check cells in the same group\n\t\t\t\t// check cell usage once more\n\t\t\t\tif (cell.isInUse(\"delete\", false, false))\n\t\t\t\t\treturn false;\n\t\t\t}\n\t\t\t// Now real delete\n\t\t\tfor(Cell cell : cells)\n\t\t\t{\n\t\t\t\tcell.kill();\n\t\t\t}\n\t\t\treturn true;\n\t\t}\n\t}\n\t/**\n\t * Class to rename a cell in a new thread.\n\t */\n\tpublic static class RenameCellGroup extends Job\n\t{\n\t\tCell cellInGroup;\n\t\tString newName;\n\t\tpublic RenameCellGroup(Cell cellInGroup, String newName)\n\t\t{\n\t\t\tsuper(\"Rename Cell Group\", User.getUserTool(), Job.Type.CHANGE, null, null, Job.Priority.USER);\n\t\t\tthis.cellInGroup = cellInGroup;\n\t\t\tthis.newName = newName;\n\t\t\tstartJob();\n\t\t}\n\t\tpublic boolean doIt() throws JobException\n\t\t{\n\t\t\t// see if all cells in the group have the same name\n\t\t\tboolean allSameName = true;\n\t\t\tString lastName = null;\n\t\t\tfor(Iterator<Cell> it = cellInGroup.getCellGroup().getCells(); it.hasNext(); )\n\t\t\t{\n\t\t\t\tString cellName = it.next().getName();\n\t\t\t\tif (lastName != null && !lastName.equals(cellName))\n\t\t\t\t{\n\t\t\t\t\tallSameName = false;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tlastName = cellName;\n\t\t\t}\n\t\t\tList<Cell> cells = new ArrayList<Cell>();\n\t\t\tfor(Iterator<Cell> it = cellInGroup.getCellGroup().getCells(); it.hasNext(); )\n\t\t\t\tcells.add(it.next());\n\t\t\tString newGroupCell = null;\n\t\t\tfor(Cell cell : cells)\n\t\t\t{\n\t\t\t\tif (allSameName)\n\t\t\t\t{\n\t\t\t\t\tcell.rename(newName, newName);\n\t\t\t\t} else\n\t\t\t\t{\n\t\t\t\t\tif (newGroupCell == null)\n\t\t\t\t\t{\n\t\t\t\t\t\tSystem.out.println(\"Renaming is not possible because cells in group don't have same root name.\");\n\t\t\t\t\t\tSystem.out.println(\"'\" + newName + \"' was added as prefix.\");\n\t\t\t\t\t\tnewGroupCell = newName + cell.getName();\n\t\t\t\t\t}\n\t\t\t\t\tcell.rename(newName+cell.getName(), newGroupCell);\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn true;\n\t\t}\n\t}\n\t/****************************** SHOW CELLS GRAPHICALLY ******************************/\n\t/**\n\t * This class implement the command to make a graph of the cells.\n\t */\n\tpublic static class GraphCells extends Job\n\t{\n\t\tprivate static final double TEXTHEIGHT = 2;\n\t\tprivate Cell top;\n\t\tprivate Cell graphCell;\n\t\tprivate static class GraphNode\n\t\t{\n\t\t\tString    name;\n\t\t\tint       depth;\n\t\t\tint       clock;\n\t\t\tdouble    x, y;\n\t\t\tdouble    yoff;\n\t\t\tNodeInst  pin;\n\t\t\tNodeInst  topPin;\n\t\t\tNodeInst  botPin;\n\t\t\tGraphNode main;\n\t\t}\n\t\tpublic GraphCells(Cell top)\n\t\t{\n\t\t\tsuper(\"Graph Cells\", User.getUserTool(), Job.Type.CHANGE, null, null, Job.Priority.USER);\n\t\t\tthis.top = top;\n\t\t\tstartJob();\n\t\t}\n\t\tpublic boolean doIt() throws JobException\n\t\t{\n\t\t\t// create the graph cell\n\t\t\tgraphCell = Cell.newInstance(Library.getCurrent(), \"CellStructure\");\n\t\t\tfieldVariableChanged(\"graphCell\");\n\t\t\tif (graphCell == null) return false;\n\t\t\tif (graphCell.getNumVersions() > 1)\n\t\t\t\tSystem.out.println(\"Creating new version of cell: \" + graphCell.getName()); else\n\t\t\t\t\tSystem.out.println(\"Creating cell: \" + graphCell.getName());\n\t\t\t// create GraphNodes for every cell and initialize the depth to -1\n\t\t\tMap<Cell,GraphNode> graphNodes = new HashMap<Cell,GraphNode>();\n\t\t\tfor(Iterator<Library> it = Library.getLibraries(); it.hasNext(); )\n\t\t\t{\n\t\t\t\tLibrary lib = it.next();\n\t\t\t\tif (lib.isHidden()) continue;\n\t\t\t\tfor(Iterator<Cell> cIt = lib.getCells(); cIt.hasNext(); )\n\t\t\t\t{\n\t\t\t\t\tCell cell = cIt.next();\n\t\t\t\t\tGraphNode cgn = new GraphNode();\n\t\t\t\t\tcgn.name = cell.describe(false);\n\t\t\t\t\tcgn.depth = -1;\n\t\t\t\t\tgraphNodes.put(cell, cgn);\n\t\t\t\t}\n\t\t\t}\n\t\t\t// find all top-level cells\n\t\t\tint maxDepth = 0;\n\t\t\tif (top != null)\n\t\t\t{\n\t\t\t\tGraphNode cgn = graphNodes.get(top);\n\t\t\t\tcgn.depth = 0;\n\t\t\t} else\n\t\t\t{\n\t\t\t\tfor(Iterator<Cell> cIt = Library.getCurrent().getCells(); cIt.hasNext(); )\n\t\t\t\t{\n\t\t\t\t\tCell cell = cIt.next();\n\t\t\t\t\tif (cell.getNumUsagesIn() == 0)\n\t\t\t\t\t{\n\t\t\t\t\t\tGraphNode cgn = graphNodes.get(cell);\n\t\t\t\t\t\tcgn.depth = 0;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tdouble xScale = 2.0 / 3.0;\n\t\t\tdouble yScale = 20;\n\t\t\tdouble yOffset = TEXTHEIGHT * 1.25;\n\t\t\tdouble maxWidth = 0;\n\t\t\t// now place all cells at their proper depth\n\t\t\tboolean more = true;\n\t\t\twhile (more)\n\t\t\t{\n\t\t\t\tmore = false;\n\t\t\t\tfor(Iterator<Library> it = Library.getLibraries(); it.hasNext(); )\n\t\t\t\t{\n\t\t\t\t\tLibrary lib = it.next();\n\t\t\t\t\tif (lib.isHidden()) continue;\n\t\t\t\t\tfor(Iterator<Cell> cIt = lib.getCells(); cIt.hasNext(); )\n\t\t\t\t\t{\n\t\t\t\t\t\tCell cell = cIt.next();\n", "outputs": ["\t\t\t\t\t\tGraphNode cgn = graphNodes.get(cell);"], "input_length": 1986, "output_length": 8, "length": 1994, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "28bfab4ec62a973892dd1ed71dbfbcc8992ee830c7a66a577a9fe7e35466eb02"}
{"input": "", "context": "# -*- coding: utf-8 -*-\nfrom __future__ import absolute_import\nfrom __future__ import print_function\nimport behave\nimport re\nimport os\nimport tempfile\nimport glob\nfrom lib.file import decompress_file_by_extension_to_dir\nfrom common.lib.behave_ext import check_context_table\nfrom common.lib.diff import print_lines_diff\nfrom common.lib.file import get_compression_suffix\nfrom lib.sqlite_repodata import load_sqlite\nfrom lib.xml_repodata import xml_parse_repodata\nfrom lib.repodata import regex_find_file_from_list\nfrom lib.repodata import verify_repomd_item_with_file\nfrom lib.repodata import build_nevra\nfrom lib.file import get_checksum_regex\nfrom lib.file import decompression_iter\nfrom lib.file import checksum_of_file\nfrom string import Template\n# namespaces\nns = {\"pri_ns\": \"http://linux.duke.edu/metadata/common\",\n      \"fil_ns\": \"http://linux.duke.edu/metadata/filelists\",\n      \"oth_ns\": \"http://linux.duke.edu/metadata/other\",\n      \"md_ns\": \"http://linux.duke.edu/metadata/repo\"}\ndef keys_do_not_differ(prim, flist, oth):\n    if prim.keys() != flist.keys():\n        print_lines_diff(prim.keys(), flist.keys())\n        raise AssertionError(\"Primary and Filelists have different package sets.\")\n    if prim.keys() != oth.keys():\n        print_lines_diff(prim.keys(), oth.keys())\n        raise AssertionError(\"Primary and Other have different package sets.\")\ndef repodata_do_not_differ(prim1, prim2, flist1, flist2, oth1, oth2):\n        # Compare packages by checksums\n        if prim1.keys() != prim2.keys():\n            print_lines_diff(prim1.keys(), prim2.keys())\n            raise AssertionError(\"Primary repodata have different package sets.\")\n        # Compare packages by name\n        if prim1.packages() != prim2.packages():\n            print_lines_diff(prim1.packages(), prim2.packages())\n            raise AssertionError(\"Primary repodata have different sets of package names.\")\n        diff = prim1.diff(prim2)\n        if diff:\n            raise AssertionError(\"Primary repodata are different.\\n\"\n                                 \"Difference: %s\" % (diff))\n        diff = flist1.diff(flist2)\n        if diff:\n            raise AssertionError(\"Filelists repodata are different.\\n\"\n                                 \"Difference: %s\" % (diff))\n        diff = oth1.diff(oth2)\n        if diff:\n            raise AssertionError(\"Other repodata are different.\\n\"\n                                 \"Difference: %s\" % (diff))\n@behave.step(\"repodata \\\"{path}\\\" are consistent\")\ndef repodata_are_consistent(context, path):\n    repopath = os.path.join(context.tempdir_manager.tempdir, path.lstrip('/'))\n    tmpdir = tempfile.mkdtemp()\n    prim_path_sqlite = None\n    prim_zck_path = None\n    # REPOMD\n    md_path = os.path.join(repopath, \"repomd.xml\")\n    if not os.path.exists(md_path):\n        raise AssertionError(\"Error: repomd.xml is missing (%s)\" % md_path)\n    repomd = xml_parse_repodata(md_path, \"{%s}data\" % ns[\"md_ns\"], \"repomd\")\n    for key in repomd.keys():\n        item = repomd.items[key]\n        if not item.location_href:\n            continue\n        # Remove /repodata/ from path\n        basename = os.path.basename(item.location_href)\n        p = os.path.join(repopath, basename.lstrip('/'))\n        if not os.path.isfile(p):\n            raise AssertionError(\"Error: repomd.xml contains: \\\"%s\\\"\"\n                                 \"but it is not present in %s\" % (p, repopath))\n        decompressed_p = decompress_file_by_extension_to_dir(p, tmpdir)\n        if item.name == \"primary_db\":\n            prim_path_sqlite = decompressed_p\n        elif item.name == \"filelists_db\":\n            filelists_path_sqlite = decompressed_p\n        elif item.name == \"other_db\":\n            other_path_sqlite = decompressed_p\n        elif item.name == \"primary\":\n            prim_path = decompressed_p\n        elif item.name == \"filelists\":\n            filelists_path = decompressed_p\n        elif item.name == \"other\":\n            other_path = decompressed_p\n        elif item.name == \"primary_zck\":\n            prim_zck_path = decompressed_p\n        elif item.name == \"filelists_zck\":\n            filelists_zck_path = decompressed_p\n        elif item.name == \"other_zck\":\n            other_zck_path = decompressed_p\n        else:\n            # Skip unsupported updateinfo, comps, etc..\n            # TODO(amatej): we could technically check for updateinfo,\n            # comps, modules and even verify some stuff\n            continue\n        verify_repomd_item_with_file(item, p, decompressed_p)\n    # XML\n    primary = xml_parse_repodata(prim_path, \"{%s}package\" % ns[\"pri_ns\"], \"primary\")\n    filelists = xml_parse_repodata(filelists_path, \"{%s}package\" % ns[\"fil_ns\"], \"filelists\")\n    other = xml_parse_repodata(other_path, \"{%s}package\" % ns[\"oth_ns\"], \"other\")\n    keys_do_not_differ(primary, filelists, other)\n    # SQLITE\n    if prim_path_sqlite: # All three sqlite files have to be present at the same time\n        primary_sql = load_sqlite(prim_path_sqlite, \"primary\")\n        filelists_sql = load_sqlite(filelists_path_sqlite, \"filelists\")\n        other_sql = load_sqlite(other_path_sqlite, \"other\")\n        keys_do_not_differ(primary_sql, filelists_sql, other_sql)\n        repodata_do_not_differ(primary, primary_sql, filelists, filelists_sql, other, other_sql)\n    # ZCK\n    if prim_zck_path: # All three zck files have to be present at the same time\n        primary_zck = xml_parse_repodata(prim_zck_path, \"{%s}package\" % ns[\"pri_ns\"], \"primary\")\n        filelists_zck = xml_parse_repodata(filelists_zck_path, \"{%s}package\" % ns[\"fil_ns\"], \"filelists\")\n        other_zck = xml_parse_repodata(other_zck_path, \"{%s}package\" % ns[\"oth_ns\"], \"other\")\n        keys_do_not_differ(primary_zck, filelists_zck, other_zck)\n        repodata_do_not_differ(primary, primary_zck, filelists, filelists_zck, other, other_zck)\n    return\n@behave.step(\"repodata in \\\"{path}\\\" is\")\ndef repodata_in_path_is(context, path):\n    check_context_table(context, [\"Type\", \"File\", \"Checksum Type\", \"Compression Type\"])\n    # repomd.xml is mandatory in this form\n    repomd_filepath = os.path.join(context.tempdir_manager.tempdir, path.lstrip(\"/\"), \"repomd.xml\")\n    if not os.path.exists(repomd_filepath):\n        raise AssertionError(\"Error: repomd.xml is missing (%s)\" % repomd_filepath)\n    files = os.listdir(os.path.dirname(repomd_filepath))\n    files.remove(\"repomd.xml\")\n    for repodata_type, repodata_file, checksum_type, compression_type in context.table:\n        checksum_regex = get_checksum_regex(checksum_type)\n        filename_parts = repodata_file.split(\"-\")\n        if (len(filename_parts) == 1):\n            pass # Simple-md-filenames\n        elif (filename_parts[0] == \"${checksum}\"):\n            filename_parts[0] = Template(filename_parts[0]).substitute(checksum=checksum_regex)\n        else:\n            if checksum_regex:\n                if not (re.compile(checksum_regex + \"$\")).match(filename_parts[0]):\n                    raise ValueError(\"Checksum type: \" + checksum_type + \" does not\"\n                                     \" match to File: \" + repodata_file)\n        filepath = os.path.join(context.tempdir_manager.tempdir, path.lstrip(\"/\"), '-'.join(filename_parts))\n        # Final path to file, even when specified as regex\n        # At the same time verifies that file exists\n        filepath = regex_find_file_from_list(filepath, files)\n        files.remove(os.path.basename(filepath))\n        # Verify checksum\n        checksum = checksum_of_file(filepath, checksum_type)\n        if (checksum_regex):\n            filename_parts_final = os.path.basename(filepath).split(\"-\")\n            if (len(filename_parts_final) == 1):\n                pass # Simple-md-filenames\n            elif not checksum == filename_parts_final[0]:\n                raise ValueError(\"Checksum of File: \" + repodata_file + \" doesn't match checksum\"\n                                 \" in the name of the File: \" + os.path.basename(filepath))\n        # Verify compression\n        compression_suffix = get_compression_suffix(compression_type)\n        if compression_suffix:\n            if not filepath.endswith(compression_suffix):\n                raise ValueError(\"Compression type: \" + compression_type + \" does\"\n                                 \" not match suffix of File: \" + repodata_file)\n        try:\n            tmp = next(decompression_iter(filepath, compression_type, blocksize=100))\n            if compression_suffix and filepath.endswith(compression_suffix):\n                filepath = filepath[:-(len(compression_suffix))]\n            if tmp:\n                if filepath.endswith(\".sqlite\"):\n                    assert(\"SQLite\" in str(tmp))\n                elif filepath.endswith(\".xml\"):\n                    assert(\"xml\" in str(tmp))\n                elif filepath.endswith(\".yaml\"):\n                    # Assume all yaml files are modulemd documents\n                    assert(\"modulemd\" in str(tmp))\n                elif filepath.endswith(\".txt\"):\n                    pass\n                else:\n                    raise\n        except (AssertionError, IOError):\n            raise AssertionError(\"Cannot decompress File: \" + repodata_file + \" using\"\n                                 \" compression type: \" + compression_type)\n    if len(files) > 0:\n        raise AssertionError(\"repodata directory contains additional metadata files:\\n{0}\".format('\\n'.join(files)))\n@behave.step(\"primary in \\\"{path}\\\" has only packages\")\ndef primary_in_path_contains_only_packages(context, path):\n    check_context_table(context, [\"Name\", \"Epoch\", \"Version\", \"Release\", \"Architecture\"])\n    filepath = os.path.join(context.tempdir_manager.tempdir, path.lstrip('/'), \"*-primary.xml.*\")\n    primary_filepath = glob.glob(filepath)[0]\n    primary = xml_parse_repodata(primary_filepath, \"{%s}package\" % ns[\"pri_ns\"], \"primary\")\n    for name, epoch, version, release, architecture in context.table:\n        nevra = build_nevra(name, epoch, version, release, architecture)\n        found = False\n        for key in primary.keys():\n            pkg = primary.items[key]\n            if (nevra == pkg.nevra()):\n                del primary.items[key]\n                found = True\n                break\n        if not found:\n            print(\"primary.xml yet unmatched packages:\")\n            for key in primary.keys():\n                pkg = primary.items[key]\n                print(\"\\t\" + build_nevra(pkg.name, pkg.epoch, pkg.version, pkg.release, pkg.arch))\n            raise AssertionError(\"Package \" + nevra + \" not found\")\n    if (len(primary.keys()) > 0):\n        print(\"primary.xml contains additional packages:\")\n        for key in primary.keys():\n            pkg = primary.items[key]\n            print(\"\\t\" + build_nevra(pkg.name, pkg.epoch, pkg.version, pkg.release, pkg.arch))\n        raise AssertionError(\"Additional packages in primary.xml\")\n@behave.step(\"primary in \\\"{path}\\\" doesn't have any packages\")\ndef primary_in_path_doesnt_contain_any_packages(context, path):\n    filepath = os.path.join(context.tempdir_manager.tempdir, path.lstrip('/'), \"*-primary.xml.*\")\n    primary_filepath = glob.glob(filepath)[0]\n    primary = xml_parse_repodata(primary_filepath, \"{%s}package\" % ns[\"pri_ns\"], \"primary\")\n", "outputs": ["    if (len(primary.keys()) > 0):"], "input_length": 1942, "output_length": 12, "length": 1954, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "1efa7fbab15fc18f8f51030de4fe334660efdda6002ff9780748b7acd21b1df8"}
{"input": "", "context": "# -*- coding: utf-8 -*-\nimport copy\nimport re\nimport simplejson\nimport werkzeug\nfrom lxml import etree, html\nfrom openerp import SUPERUSER_ID\nfrom openerp.addons.website.models import website\nfrom openerp.http import request\nfrom openerp.osv import osv, fields\nclass view(osv.osv):\n    _inherit = \"ir.ui.view\"\n    _columns = {\n        'page': fields.boolean(\"Whether this view is a web page template (complete)\"),\n        'website_meta_title': fields.char(\"Website meta title\", size=70, translate=True),\n        'website_meta_description': fields.text(\"Website meta description\", size=160, translate=True),\n        'website_meta_keywords': fields.char(\"Website meta keywords\", translate=True),\n    }\n    _defaults = {\n        'page': False,\n    }\n    def _view_obj(self, cr, uid, view_id, context=None):\n        if isinstance(view_id, basestring):\n            return self.pool['ir.model.data'].xmlid_to_object(\n                cr, uid, view_id, raise_if_not_found=True, context=context\n            )\n        elif isinstance(view_id, (int, long)):\n            return self.browse(cr, uid, view_id, context=context)\n        # assume it's already a view object (WTF?)\n        return view_id\n    # Returns all views (called and inherited) related to a view\n    # Used by translation mechanism, SEO and optional templates\n    def _views_get(self, cr, uid, view_id, options=True, context=None, root=True):\n        \"\"\" For a given view ``view_id``, should return:\n        * the view itself\n        * all views inheriting from it, enabled or not\n          - but not the optional children of a non-enabled child\n        * all views called from it (via t-call)\n        \"\"\"\n        try:\n            view = self._view_obj(cr, uid, view_id, context=context)\n        except ValueError:\n            # Shall we log that ?\n            return []\n        while root and view.inherit_id:\n            view = view.inherit_id\n        result = [view]\n        node = etree.fromstring(view.arch)\n        for child in node.xpath(\"//t[@t-call]\"):\n            try:\n                called_view = self._view_obj(cr, uid, child.get('t-call'), context=context)\n            except ValueError:\n                continue\n            if called_view not in result:\n                result += self._views_get(cr, uid, called_view, options=options, context=context)\n        extensions = view.inherit_children_ids\n        if not options:\n            # only active children\n            extensions = (v for v in view.inherit_children_ids\n                          if v.application in ('always', 'enabled'))\n        # Keep options in a deterministic order regardless of their applicability\n        for extension in sorted(extensions, key=lambda v: v.id):\n            for r in self._views_get(\n                    cr, uid, extension,\n                    # only return optional grandchildren if this child is enabled\n                    options=extension.application in ('always', 'enabled'),\n                    context=context, root=False):\n                if r not in result:\n                    result.append(r)\n        return result\n    def extract_embedded_fields(self, cr, uid, arch, context=None):\n        return arch.xpath('//*[@data-oe-model != \"ir.ui.view\"]')\n    def save_embedded_field(self, cr, uid, el, context=None):\n        Model = self.pool[el.get('data-oe-model')]\n        field = el.get('data-oe-field')\n        column = Model._all_columns[field].column\n        converter = self.pool['website.qweb'].get_converter_for(\n            el.get('data-oe-type'))\n        value = converter.from_html(cr, uid, Model, column, el)\n        if value is not None:\n            # TODO: batch writes?\n            Model.write(cr, uid, [int(el.get('data-oe-id'))], {\n                field: value\n            }, context=context)\n    def to_field_ref(self, cr, uid, el, context=None):\n        # filter out meta-information inserted in the document\n        attributes = dict((k, v) for k, v in el.items()\n                          if not k.startswith('data-oe-'))\n        attributes['t-field'] = el.get('data-oe-expression')\n        out = html.html_parser.makeelement(el.tag, attrib=attributes)\n        out.tail = el.tail\n        return out\n    def replace_arch_section(self, cr, uid, view_id, section_xpath, replacement, context=None):\n        # the root of the arch section shouldn't actually be replaced as it's\n        # not really editable itself, only the content truly is editable.\n        [view] = self.browse(cr, uid, [view_id], context=context)\n        arch = etree.fromstring(view.arch.encode('utf-8'))\n        # => get the replacement root\n        if not section_xpath:\n            root = arch\n        else:\n            # ensure there's only one match\n            [root] = arch.xpath(section_xpath)\n        root.text = replacement.text\n        root.tail = replacement.tail\n        # replace all children\n        del root[:]\n        for child in replacement:\n            root.append(copy.deepcopy(child))\n        return arch\n    def render(self, cr, uid, id_or_xml_id, values=None, engine='ir.qweb', context=None):\n        if request and getattr(request, 'website_enabled', False):\n            engine='website.qweb'\n            if isinstance(id_or_xml_id, list):\n                id_or_xml_id = id_or_xml_id[0]\n            if not context:\n                context = {}\n            qcontext = dict(\n                context.copy(),\n                website=request.website,\n                url_for=website.url_for,\n                slug=website.slug,\n                res_company=request.website.company_id,\n                user_id=self.pool.get(\"res.users\").browse(cr, uid, uid),\n                translatable=context.get('lang') != request.website.default_lang_code,\n                editable=request.website.is_publisher(),\n                menu_data=self.pool['ir.ui.menu'].load_menus_root(cr, uid, context=context) if request.website.is_user() else None,\n            )\n            # add some values\n            if values:\n                qcontext.update(values)\n            # in edit mode ir.ui.view will tag nodes\n            context['inherit_branding'] = qcontext.get('editable', False)\n            view_obj = request.website.get_template(id_or_xml_id)\n            if 'main_object' not in qcontext:\n                qcontext['main_object'] = view_obj\n            values = qcontext\n        return super(view, self).render(cr, uid, id_or_xml_id, values=values, engine=engine, context=context)\n    def _pretty_arch(self, arch):\n        # remove_blank_string does not seem to work on HTMLParser, and\n        # pretty-printing with lxml more or less requires stripping\n        # whitespace: http://lxml.de/FAQ.html#why-doesn-t-the-pretty-print-option-reformat-my-xml-output\n        # so serialize to XML, parse as XML (remove whitespace) then serialize\n        # as XML (pretty print)\n        arch_no_whitespace = etree.fromstring(\n            etree.tostring(arch, encoding='utf-8'),\n            parser=etree.XMLParser(encoding='utf-8', remove_blank_text=True))\n        return etree.tostring(\n            arch_no_whitespace, encoding='unicode', pretty_print=True)\n    def save(self, cr, uid, res_id, value, xpath=None, context=None):\n        \"\"\" Update a view section. The view section may embed fields to write\n        :param str model:\n        :param int res_id:\n        :param str xpath: valid xpath to the tag to replace\n        \"\"\"\n        res_id = int(res_id)\n        arch_section = html.fromstring(\n            value, parser=html.HTMLParser(encoding='utf-8'))\n        if xpath is None:\n            # value is an embedded field on its own, not a view section\n            self.save_embedded_field(cr, uid, arch_section, context=context)\n            return\n        for el in self.extract_embedded_fields(cr, uid, arch_section, context=context):\n            self.save_embedded_field(cr, uid, el, context=context)\n            # transform embedded field back to t-field\n            el.getparent().replace(el, self.to_field_ref(cr, uid, el, context=context))\n        arch = self.replace_arch_section(cr, uid, res_id, xpath, arch_section, context=context)\n        self.write(cr, uid, res_id, {\n            'arch': self._pretty_arch(arch)\n        }, context=context)\n", "outputs": ["        view = self.browse(cr, SUPERUSER_ID, res_id, context=context)"], "input_length": 1316, "output_length": 12, "length": 1328, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "615d3bd6016f9b1887e4465c524431af2258cb5b64794b4bd541f0aaa7ff55bd"}
{"input": "", "context": "\"\"\"\nData models for the announcements app.\n\"\"\"\nfrom django.db import models\nfrom django.conf import settings\nfrom django.core.urlresolvers import reverse\nfrom django.utils import timezone\nfrom django.utils.translation import ugettext_lazy as _\nfrom apps.tools.utils import unique_slug\nfrom apps.tools.models import ModelDiffMixin\nfrom apps.txtrender.fields import RenderTextField\nfrom apps.txtrender.utils import render_document\nfrom apps.txtrender.signals import render_engine_changed\nfrom .managers import (AnnouncementManager,\n                       AnnouncementTwitterCrossPublicationManager)\nfrom .constants import (ANNOUNCEMENTS_TYPE_CHOICES,\n                        ANNOUNCEMENTS_TYPE_DEFAULT)\nclass Announcement(ModelDiffMixin, models.Model):\n    \"\"\"\n    Announcement data model. Use to quickly broadcast information about the site.\n    An announcement is made of:\n    - a title,\n    - a slug (unique and indexed),\n    - an author,\n    - a creation, last content modification and publication date,\n    - a type,\n    - a \"site wide\" flag, used to determine if the announcement should be displayed on the front page.\n    - some text (source and HTML version).\n    Announcements made by a specific user are available using the reverse relation ``authored_announcements``.\n    \"\"\"\n    title = models.CharField(_('Title'),\n                             max_length=255)\n    # FIXME AutoSlugField\n    slug = models.SlugField(_('Slug'),\n                            max_length=255,\n                            unique=True)\n    author = models.ForeignKey(settings.AUTH_USER_MODEL,\n                               db_index=True,  # Database optimization\n                               related_name='authored_announcements',\n                               verbose_name=_('Author'))\n    creation_date = models.DateTimeField(_('Creation date'),\n                                         auto_now_add=True,\n                                         db_index=True)  # Database optimization\n    last_content_modification_date = models.DateTimeField(_('Last content modification date'),\n                                                          default=None,\n                                                          editable=False,\n                                                          blank=True,\n                                                          null=True,\n                                                          db_index=True)  # Database optimization\n    pub_date = models.DateTimeField(_('Publication date'),\n                                    default=None,\n                                    blank=True,\n                                    null=True,\n                                    db_index=True)  # Database optimization\n    type = models.CharField(_('Type'),\n                            max_length=10,\n                            choices=ANNOUNCEMENTS_TYPE_CHOICES,\n                            default=ANNOUNCEMENTS_TYPE_DEFAULT)\n    site_wide = models.BooleanField(_('Broadcast all over the site'),\n                                    default=False)\n    content = RenderTextField(_('Content'))\n    content_html = models.TextField(_('Content (raw HTML)'))\n    content_text = models.TextField(_('Content (raw text)'))\n    tags = models.ManyToManyField('AnnouncementTag',\n                                  related_name='announcements',\n                                  verbose_name=_('Announcement\\'s tags'),\n                                  blank=True)\n    last_modification_date = models.DateTimeField(_('Last modification date'),\n                                                  auto_now=True)\n    objects = AnnouncementManager()\n    class Meta:\n        verbose_name = _('Announcement')\n        verbose_name_plural = _('Announcements')\n        permissions = (\n            ('can_see_preview', 'Can see any announcements in preview'),\n        )\n        get_latest_by = 'pub_date'\n        ordering = ('-pub_date',)\n    def __str__(self):\n        return self.title\n    def get_absolute_url(self):\n        \"\"\"\n        Return the permalink to this announcement.\n        \"\"\"\n        return reverse('announcements:announcement_detail', kwargs={'slug': self.slug})\n    def save(self, *args, **kwargs):\n        \"\"\"\n        Save the announcement, fix non-unique slug, fix/update last content modification date and render the text.\n        :param args: For super()\n        :param kwargs: For super()\n        \"\"\"\n        # Avoid duplicate slug\n        # FIXME AutoSlugField\n        self.slug = unique_slug(Announcement, self, self.slug, 'slug', self.title)\n        # Fix the modification date if necessary\n        self.fix_last_content_modification_date()\n        # Render the content\n        self.render_text()\n        # Save the model\n        super(Announcement, self).save(*args, **kwargs)\n    def save_no_rendering(self, *args, **kwargs):\n        \"\"\"\n        Save the announcement without doing any text rendering or fields cleanup.\n        This method just call the parent ``save`` method.\n        :param args: For super()\n        :param kwargs: For super()\n        \"\"\"\n        super(Announcement, self).save(*args, **kwargs)\n    def fix_last_content_modification_date(self):\n        \"\"\"\n        Fix the ``last_content_modification_date`` field according to ``pub_date`` and other fields.\n        \"\"\"\n        if self.pub_date:\n            changed_fields = self.changed_fields\n            if self.pk and 'title' in changed_fields or 'content' in changed_fields:\n                self.last_content_modification_date = timezone.now()\n            if self.last_content_modification_date \\\n                    and self.last_content_modification_date <= self.pub_date:\n                self.last_content_modification_date = None\n        else:\n            self.last_content_modification_date = None\n    def is_published(self):\n        \"\"\"\n        Return ``True`` if this announcement is published and so, readable by anyone.\n        \"\"\"\n        now = timezone.now()\n        return self.pub_date is not None and self.pub_date <= now\n    is_published.boolean = True\n    is_published.short_description = _('Published')\n    def can_see_preview(self, user):\n        \"\"\"\n        Return True if the given user can see this announcement in preview mode.\n        :param user: The user to be checked for permission\n        \"\"\"\n        return user == self.author or user.has_perm('announcements.can_see_preview')\n    def has_been_modified_after_publication(self):\n        \"\"\"\n        Return True if the announcement has been modified after publication.\n        \"\"\"\n        return self.last_content_modification_date is not None \\\n               and self.last_content_modification_date != self.pub_date\n    def render_text(self, save=False):\n        \"\"\"\n        Render the content.\n        :param save: Save the model field ``content_html`` if ``True``.\n        \"\"\"\n        # Render HTML\n        content_html, content_text, _ = render_document(self.content,\n                                                        allow_titles=True,\n                                                        allow_code_blocks=True,\n                                                        allow_text_formating=True,\n                                                        allow_text_extra=True,\n                                                        allow_text_alignments=True,\n                                                        allow_text_directions=True,\n                                                        allow_text_modifiers=True,\n                                                        allow_text_colors=True,\n                                                        allow_spoilers=True,\n                                                        allow_figures=True,\n                                                        allow_lists=True,\n                                                        allow_todo_lists=True,\n                                                        allow_definition_lists=True,\n                                                        allow_tables=True,\n                                                        allow_quotes=True,\n                                                        allow_footnotes=True,\n                                                        allow_acronyms=True,\n                                                        allow_links=True,\n                                                        allow_medias=True,\n                                                        allow_cdm_extra=True,\n                                                        force_nofollow=False,\n                                                        render_text_version=True,\n                                                        merge_footnotes_html=True,\n                                                        merge_footnotes_text=True)\n        self.content_html = content_html\n        self.content_text = content_text\n        # Save if required\n        if save:\n            self.save_no_rendering(update_fields=('content_html', 'content_text'))\ndef _redo_announcements_text_rendering(sender, **kwargs):\n    \"\"\"\n    Redo text rendering of all announcements.\n    :param sender: Not used.\n    :param kwargs: Not used.\n    \"\"\"\n    for announcement in Announcement.objects.all():\n        announcement.render_text(save=True)\nrender_engine_changed.connect(_redo_announcements_text_rendering)\nclass AnnouncementTag(models.Model):\n    \"\"\"\n    Announcement tag data model.\n    An announcement's tag is made of:\n    - a slug (unique and indexed in database),\n    - a name (human readable).\n    \"\"\"\n    # FIXME AutoSlugField\n    slug = models.SlugField(_('Slug'),\n                            max_length=255,\n                            unique=True)\n    name = models.CharField(_('Name'),\n                            max_length=255)\n    class Meta:\n        verbose_name = _('Announcement tag')\n        verbose_name_plural = _('Announcement tags')\n    def __str__(self):\n        return self.name\n    def get_absolute_url(self):\n        \"\"\"\n        Return the permalink to this announcement's tag.\n        \"\"\"\n        return reverse('announcements:tag_detail', kwargs={'slug': self.slug})\n    def get_latest_announcements_rss_feed_url(self):\n        \"\"\"\n        Return the permalink to \"latest announcements\" RSS feed for this tag.\n        \"\"\"\n        return reverse('announcements:latest_tag_announcements_rss', kwargs={'slug': self.slug})\n    def get_latest_announcements_atom_feed_url(self):\n        \"\"\"\n        Return the permalink to \"latest announcements\" Atom feed for this tag.\n        \"\"\"\n        return reverse('announcements:latest_tag_announcements_atom', kwargs={'slug': self.slug})\n    def save(self, *args, **kwargs):\n        \"\"\"\n        Save the model\n        :param args: For super()\n        :param kwargs: For super()\n        \"\"\"\n        # Avoid duplicate slug\n        # FIXME AutoSlugField\n        self.slug = unique_slug(AnnouncementTag, self, self.slug, 'slug', self.name)\n        # Save the tag\n        super(AnnouncementTag, self).save(*args, **kwargs)\nclass AnnouncementTwitterCrossPublication(models.Model):\n    \"\"\"\n    Cross-publication marker for the Twitter platform.\n    This simple model store three information:\n    - the cross-published announcement,\n    - the tweet ID of the cross-publication (for history in case of problem),\n    - the date of cross-publication.\n    \"\"\"\n    announcement = models.ForeignKey('Announcement',\n                                     db_index=True,  # Database optimization\n                                     related_name='twitter_pubs',\n                                     verbose_name=_('Announcement'))\n    tweet_id = models.CharField(_('Tweet ID'),\n                                db_index=True,  # Database optimization\n                                max_length=255)\n    pub_date = models.DateTimeField(_('Creation date'),\n                                    auto_now_add=True,\n                                    db_index=True)  # Database optimization\n    objects = AnnouncementTwitterCrossPublicationManager()\n    class Meta:\n        verbose_name = _('Twitter cross-publication')\n        verbose_name_plural = _('Twitter cross-publications')\n        get_latest_by = 'pub_date'\n        ordering = ('-pub_date', )\n    def __str__(self):\n", "outputs": ["        return '%s -> %s' % (self.announcement, self.tweet_id)"], "input_length": 1494, "output_length": 15, "length": 1509, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "d9b704fc747853eb6e9f9b94c5448ff44c404b7f61d83cb8afce63ca4d96a3dd"}
{"input": "", "context": "# This file is part of Scapy\n# See http://www.secdev.org/projects/scapy for more information\n# Copyright (C) Andreas Korb <andreas.d.korb@gmail.com>\n# Copyright (C) Nils Weiss <nils@we155.de>\n# This program is published under a GPLv2 license\nfrom scapy.fields import StrFixedLenField, BitEnumField, BitField, \\\n    ScalingField, FlagsField, XByteEnumField, ShortField\nfrom scapy.contrib.automotive.obd.packet import OBD_Packet\n# See https://en.wikipedia.org/wiki/OBD-II_PIDs for further information\n# PID = Parameter IDentification\nclass OBD_PID00(OBD_Packet):\n    name = \"PID_00_PIDsSupported\"\n    fields_desc = [\n        FlagsField('supported_pids', b'', 32, [\n            'PID20',\n            'PID1F',\n            'PID1E',\n            'PID1D',\n            'PID1C',\n            'PID1B',\n            'PID1A',\n            'PID19',\n            'PID18',\n            'PID17',\n            'PID16',\n            'PID15',\n            'PID14',\n            'PID13',\n            'PID12',\n            'PID11',\n            'PID10',\n            'PID0F',\n            'PID0E',\n            'PID0D',\n            'PID0C',\n            'PID0B',\n            'PID0A',\n            'PID09',\n            'PID08',\n            'PID07',\n            'PID06',\n            'PID05',\n            'PID04',\n            'PID03',\n            'PID02',\n            'PID01'\n        ])\n    ]\nclass OBD_PID01(OBD_Packet):\n    name = \"PID_01_MonitorStatusSinceDtcsCleared\"\n    onOff = {\n        0: 'off',\n        1: 'on'\n    }\n    fields_desc = [\n        BitEnumField('mil', 0, 1, onOff),\n        BitField('dtc_count', 0, 7),\n        BitField('reserved1', 0, 1),\n        FlagsField('continuous_tests_ready', b'', 3, [\n            'misfire',\n            'fuelSystem',\n            'components'\n        ]),\n        BitField('reserved2', 0, 1),\n        FlagsField('continuous_tests_supported', b'', 3, [\n            'misfire',\n            'fuel_system',\n            'components'\n        ]),\n        FlagsField('once_per_trip_tests_supported', b'', 8, [\n            'egr',\n            'oxygenSensorHeater',\n            'oxygenSensor',\n            'acSystemRefrigerant',\n            'secondaryAirSystem',\n            'evaporativeSystem',\n            'heatedCatalyst',\n            'catalyst'\n        ]),\n        FlagsField('once_per_trip_tests_ready', b'', 8, [\n            'egr',\n            'oxygenSensorHeater',\n            'oxygenSensor',\n            'acSystemRefrigerant',\n            'secondaryAirSystem',\n            'evaporativeSystem',\n            'heatedCatalyst',\n            'catalyst'\n        ])\n    ]\nclass OBD_PID02(OBD_Packet):\n    name = \"PID_02_FreezeDtc\"\n    fields_desc = [\n        ShortField('data', 0)\n    ]\nclass OBD_PID03(OBD_Packet):\n    name = \"PID_03_FuelSystemStatus\"\n    loopStates = {\n        0x00: 'OpenLoopInsufficientEngineTemperature',\n        0x02: 'ClosedLoop',\n        0x04: 'OpenLoopEngineLoadOrFuelCut',\n        0x08: 'OpenLoopDueSystemFailure',\n        0x10: 'ClosedLoopWithFault'\n    }\n    fields_desc = [\n        XByteEnumField('fuel_system1', 0, loopStates),\n        XByteEnumField('fuel_system2', 0, loopStates)\n    ]\nclass OBD_PID04(OBD_Packet):\n    name = \"PID_04_CalculatedEngineLoad\"\n    fields_desc = [\n        ScalingField('data', 0, scaling=100 / 255., unit=\"%\")\n    ]\nclass OBD_PID05(OBD_Packet):\n    name = \"PID_05_EngineCoolantTemperature\"\n    fields_desc = [\n        ScalingField('data', 0, unit=\"deg. C\", offset=-40.0)\n    ]\nclass OBD_PID06(OBD_Packet):\n    name = \"PID_06_ShortTermFuelTrimBank1\"\n    fields_desc = [\n        ScalingField('data', 0, scaling=100 / 128.,\n                     unit=\"%\", offset=-100.0)\n    ]\nclass OBD_PID07(OBD_Packet):\n    name = \"PID_07_LongTermFuelTrimBank1\"\n    fields_desc = [\n        ScalingField('data', 0, scaling=100 / 128.,\n                     unit=\"%\", offset=-100.0)\n    ]\nclass OBD_PID08(OBD_Packet):\n    name = \"PID_08_ShortTermFuelTrimBank2\"\n    fields_desc = [\n        ScalingField('data', 0, scaling=100 / 128.,\n                     unit=\"%\", offset=-100.0)\n    ]\nclass OBD_PID09(OBD_Packet):\n    name = \"PID_09_LongTermFuelTrimBank2\"\n    fields_desc = [\n        ScalingField('data', 0, scaling=100 / 128.,\n                     unit=\"%\", offset=-100.0)\n    ]\nclass OBD_PID0A(OBD_Packet):\n    name = \"PID_0A_FuelPressure\"\n    fields_desc = [\n        ScalingField('data', 0, scaling=3, unit=\"kPa\")\n    ]\nclass OBD_PID0B(OBD_Packet):\n    name = \"PID_0B_IntakeManifoldAbsolutePressure\"\n    fields_desc = [\n        ScalingField('data', 0, scaling=1, unit=\"kPa\")\n    ]\nclass OBD_PID0C(OBD_Packet):\n    name = \"PID_0C_EngineRpm\"\n    fields_desc = [\n        ScalingField('data', 0, scaling=1 / 4., unit=\"min-1\", fmt=\"H\")\n    ]\nclass OBD_PID0D(OBD_Packet):\n    name = \"PID_0D_VehicleSpeed\"\n    fields_desc = [\n        ScalingField('data', 0, unit=\"km/h\")\n    ]\nclass OBD_PID0E(OBD_Packet):\n    name = \"PID_0E_TimingAdvance\"\n    fields_desc = [\n        ScalingField('data', 0, scaling=1 / 2., unit=\"deg.\", offset=-64.0)\n    ]\nclass OBD_PID0F(OBD_Packet):\n    name = \"PID_0F_IntakeAirTemperature\"\n    fields_desc = [\n        ScalingField('data', 0, scaling=1, unit=\"deg. C\", offset=-40.0)\n    ]\nclass OBD_PID10(OBD_Packet):\n    name = \"PID_10_MafAirFlowRate\"\n    fields_desc = [\n        ScalingField('data', 0, scaling=1 / 100., unit=\"g/s\")\n    ]\nclass OBD_PID11(OBD_Packet):\n    name = \"PID_11_ThrottlePosition\"\n    fields_desc = [\n        ScalingField('data', 0, scaling=100 / 255., unit=\"%\")\n    ]\nclass OBD_PID12(OBD_Packet):\n    name = \"PID_12_CommandedSecondaryAirStatus\"\n    states = {\n        0x00: 'upstream',\n        0x02: 'downstreamCatalyticConverter',\n        0x04: 'outsideAtmosphereOrOff',\n        0x08: 'pumpCommanded'\n    }\n    fields_desc = [\n        XByteEnumField('data', 0, states)\n    ]\nclass OBD_PID13(OBD_Packet):\n    name = \"PID_13_OxygenSensorsPresent\"\n    fields_desc = [\n        StrFixedLenField('data', b'', 1)\n    ]\nclass _OBD_PID14_1B(OBD_Packet):\n    fields_desc = [\n        ScalingField('outputVoltage', 0, scaling=0.005, unit=\"V\"),\n        ScalingField('trim', 0, scaling=100 / 128.,\n                     unit=\"%\", offset=-100)\n    ]\nclass OBD_PID14(_OBD_PID14_1B):\n    name = \"PID_14_OxygenSensor1\"\nclass OBD_PID15(_OBD_PID14_1B):\n    name = \"PID_15_OxygenSensor2\"\nclass OBD_PID16(_OBD_PID14_1B):\n    name = \"PID_16_OxygenSensor3\"\nclass OBD_PID17(_OBD_PID14_1B):\n    name = \"PID_17_OxygenSensor4\"\nclass OBD_PID18(_OBD_PID14_1B):\n    name = \"PID_18_OxygenSensor5\"\nclass OBD_PID19(_OBD_PID14_1B):\n    name = \"PID_19_OxygenSensor6\"\nclass OBD_PID1A(_OBD_PID14_1B):\n    name = \"PID_1A_OxygenSensor7\"\nclass OBD_PID1B(_OBD_PID14_1B):\n    name = \"PID_1B_OxygenSensor8\"\nclass OBD_PID1C(OBD_Packet):\n    name = \"PID_1C_ObdStandardsThisVehicleConformsTo\"\n    obdStandards = {\n        0x01: 'OBD-II as defined by the CARB',\n        0x02: 'OBD as defined by the EPA',\n        0x03: 'OBD and OBD-II ',\n        0x04: 'OBD-I ',\n        0x05: 'Not OBD compliant',\n", "outputs": ["        0x06: 'EOBD (Europe) ',"], "input_length": 1168, "output_length": 8, "length": 1176, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "5b0fabd5c9d8e6ef6d59f66cf5b2bff339c9ecc7840e8ab481ad4e837a1c6516"}
{"input": "", "context": "/*\n  Copyright (C) 2002-2010 Jeroen Frijters\n  This software is provided 'as-is', without any express or implied\n  warranty.  In no event will the authors be held liable for any damages\n  arising from the use of this software.\n  Permission is granted to anyone to use this software for any purpose,\n  including commercial applications, and to alter it and redistribute it\n  freely, subject to the following restrictions:\n  1. The origin of this software must not be misrepresented; you must not\n     claim that you wrote the original software. If you use this software\n     in a product, an acknowledgment in the product documentation would be\n     appreciated but is not required.\n  2. Altered source versions must be plainly marked as such, and must not be\n     misrepresented as being the original software.\n  3. This notice may not be removed or altered from any source distribution.\n  Jeroen Frijters\n  jeroen@frijters.net\n  \n*/\nusing System;\nusing System.Collections.Generic;\nusing System.Xml.Serialization;\nusing IKVM.Reflection;\nusing IKVM.Reflection.Emit;\nusing Type = IKVM.Reflection.Type;\nusing System.Diagnostics;\nusing IKVM.Attributes;\nusing IKVM.Internal;\nnamespace IKVM.Internal.MapXml\n{\n\tsealed class CodeGenContext\n\t{\n\t\tprivate ClassLoaderWrapper classLoader;\n\t\tprivate readonly Dictionary<string, object> h = new Dictionary<string, object>();\n\t\tinternal CodeGenContext(ClassLoaderWrapper classLoader)\n\t\t{\n\t\t\tthis.classLoader = classLoader;\n\t\t}\n\t\tinternal object this[string key]\n\t\t{\n\t\t\tget\n\t\t\t{\n\t\t\t\tobject val;\n\t\t\t\th.TryGetValue(key, out val);\n\t\t\t\treturn val;\n\t\t\t}\n\t\t\tset { h[key] = value; }\n\t\t}\n\t\tinternal ClassLoaderWrapper ClassLoader { get { return classLoader; } }\n\t}\n\tpublic abstract class Instruction\n\t{\n\t\tprivate int lineNumber = Root.LineNumber;\n\t\tinternal int LineNumber\n\t\t{\n\t\t\tget\n\t\t\t{\n\t\t\t\treturn lineNumber;\n\t\t\t}\n\t\t}\n\t\tinternal abstract void Generate(CodeGenContext context, CodeEmitter ilgen);\n\t\tpublic override string ToString()\n\t\t{\n\t\t\tSystem.Text.StringBuilder sb = new System.Text.StringBuilder();\n\t\t\tsb.Append('<');\n\t\t\tobject[] attr = GetType().GetCustomAttributes(typeof(XmlTypeAttribute), false);\n\t\t\tif (attr.Length == 1)\n\t\t\t{\n\t\t\t\tsb.Append(((XmlTypeAttribute)attr[0]).TypeName);\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tsb.Append(GetType().Name);\n\t\t\t}\n\t\t\tforeach (System.Reflection.FieldInfo field in GetType().GetFields())\n\t\t\t{\n\t\t\t\tif (!field.IsStatic)\n\t\t\t\t{\n\t\t\t\t\tobject value = field.GetValue(this);\n\t\t\t\t\tif (value != null)\n\t\t\t\t\t{\n\t\t\t\t\t\tattr = field.GetCustomAttributes(typeof(XmlAttributeAttribute), false);\n\t\t\t\t\t\tif (attr.Length == 1)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tsb.AppendFormat(\" {0}=\\\"{1}\\\"\", ((XmlAttributeAttribute)attr[0]).AttributeName, value);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tsb.Append(\" />\");\n\t\t\treturn sb.ToString();\n\t\t}\n\t}\n\t[XmlType(\"ldstr\")]\n\tpublic sealed class Ldstr : Instruction\n\t{\n\t\t[XmlAttribute(\"value\")]\n\t\tpublic string Value;\n\t\tinternal override void Generate(CodeGenContext context, CodeEmitter ilgen)\n\t\t{\n\t\t\tilgen.Emit(OpCodes.Ldstr, Value);\n\t\t}\n\t}\n\t[XmlType(\"ldnull\")]\n\tpublic sealed class Ldnull : Simple\n\t{\n\t\tpublic Ldnull() : base(OpCodes.Ldnull)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"call\")]\n\tpublic class Call : Instruction\n\t{\n\t\tpublic Call() : this(OpCodes.Call)\n\t\t{\n\t\t}\n\t\tinternal Call(OpCode opcode)\n\t\t{\n\t\t\tthis.opcode = opcode;\n\t\t}\n\t\t[XmlAttribute(\"class\")]\n\t\tpublic string Class;\n\t\t[XmlAttribute(\"type\")]\n\t\tpublic string type;\n\t\t[XmlAttribute(\"name\")]\n\t\tpublic string Name;\n\t\t[XmlAttribute(\"sig\")]\n\t\tpublic string Sig;\n\t\tprivate OpCode opcode;\n\t\tinternal sealed override void Generate(CodeGenContext context, CodeEmitter ilgen)\n\t\t{\n\t\t\tDebug.Assert(Name != null);\n\t\t\tif(Name == \".ctor\")\n\t\t\t{\n\t\t\t\tDebug.Assert(Class == null && type != null);\n\t\t\t\tType[] argTypes = context.ClassLoader.ArgTypeListFromSig(Sig);\n\t\t\t\tConstructorInfo ci = StaticCompiler.GetTypeForMapXml(context.ClassLoader, type).GetConstructor(BindingFlags.Public | BindingFlags.NonPublic | BindingFlags.Instance, null, CallingConventions.Standard, argTypes, null);\n\t\t\t\tif(ci == null)\n\t\t\t\t{\n\t\t\t\t\tthrow new InvalidOperationException(\"Missing .ctor: \" + type + \"..ctor\" + Sig);\n\t\t\t\t}\n\t\t\t\tilgen.Emit(opcode, ci);\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tDebug.Assert(Class == null ^ type == null);\n\t\t\t\tif(Class != null)\n\t\t\t\t{\n\t\t\t\t\tDebug.Assert(Sig != null);\n\t\t\t\t\tMethodWrapper method = context.ClassLoader.LoadClassByDottedName(Class).GetMethodWrapper(Name, Sig, false);\n\t\t\t\t\tif(method == null)\n\t\t\t\t\t{\n\t\t\t\t\t\tthrow new InvalidOperationException(\"method not found: \" + Class + \".\" + Name + Sig);\n\t\t\t\t\t}\n\t\t\t\t\tmethod.Link();\n\t\t\t\t\t// TODO this code is part of what Compiler.CastInterfaceArgs (in compiler.cs) does,\n\t\t\t\t\t// it would be nice if we could avoid this duplication...\n\t\t\t\t\tTypeWrapper[] argTypeWrappers = method.GetParameters();\n\t\t\t\t\tfor(int i = 0; i < argTypeWrappers.Length; i++)\n\t\t\t\t\t{\n\t\t\t\t\t\tif(argTypeWrappers[i].IsGhost)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tCodeEmitterLocal[] temps = new CodeEmitterLocal[argTypeWrappers.Length + (method.IsStatic ? 0 : 1)];\n\t\t\t\t\t\t\tfor(int j = temps.Length - 1; j >= 0; j--)\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tTypeWrapper tw;\n\t\t\t\t\t\t\t\tif(method.IsStatic)\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\ttw = argTypeWrappers[j];\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\telse\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\tif(j == 0)\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\ttw = method.DeclaringType;\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\telse\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\ttw = argTypeWrappers[j - 1];\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tif(tw.IsGhost)\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\ttw.EmitConvStackTypeToSignatureType(ilgen, null);\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\ttemps[j] = ilgen.DeclareLocal(tw.TypeAsSignatureType);\n\t\t\t\t\t\t\t\tilgen.Emit(OpCodes.Stloc, temps[j]);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tfor(int j = 0; j < temps.Length; j++)\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tilgen.Emit(OpCodes.Ldloc, temps[j]);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif(opcode.Value == OpCodes.Call.Value)\n\t\t\t\t\t{\n\t\t\t\t\t\tmethod.EmitCall(ilgen);\n\t\t\t\t\t}\n\t\t\t\t\telse if(opcode.Value == OpCodes.Callvirt.Value)\n\t\t\t\t\t{\n\t\t\t\t\t\tmethod.EmitCallvirt(ilgen);\n\t\t\t\t\t}\n\t\t\t\t\telse if(opcode.Value == OpCodes.Newobj.Value)\n\t\t\t\t\t{\n\t\t\t\t\t\tmethod.EmitNewobj(ilgen);\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\t// ldftn or ldvirtftn\n\t\t\t\t\t\tilgen.Emit(opcode, (MethodInfo)method.GetMethod());\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tType[] argTypes;\n\t\t\t\t\tif(Sig.StartsWith(\"(\"))\n\t\t\t\t\t{\n\t\t\t\t\t\targTypes = context.ClassLoader.ArgTypeListFromSig(Sig);\n\t\t\t\t\t}\n\t\t\t\t\telse if(Sig == \"\")\n\t\t\t\t\t{\n\t\t\t\t\t\targTypes = Type.EmptyTypes;\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\tstring[] types = Sig.Split(';');\n\t\t\t\t\t\targTypes = new Type[types.Length];\n\t\t\t\t\t\tfor(int i = 0; i < types.Length; i++)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\targTypes[i] = StaticCompiler.GetTypeForMapXml(context.ClassLoader, types[i]);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tMethodInfo mi = StaticCompiler.GetTypeForMapXml(context.ClassLoader, type).GetMethod(Name, BindingFlags.Public | BindingFlags.NonPublic | BindingFlags.Instance | BindingFlags.Static, null, argTypes, null);\n\t\t\t\t\tif(mi == null)\n\t\t\t\t\t{\n\t\t\t\t\t\tthrow new InvalidOperationException(\"Missing method: \" + type + \".\" + Name + Sig);\n\t\t\t\t\t}\n\t\t\t\t\tilgen.Emit(opcode, mi);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t[XmlType(\"callvirt\")]\n\tpublic sealed class Callvirt : Call\n\t{\n\t\tpublic Callvirt() : base(OpCodes.Callvirt)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"newobj\")]\n\tpublic sealed class NewObj : Call\n\t{\n\t\tpublic NewObj() : base(OpCodes.Newobj)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"ldftn\")]\n\tpublic sealed class Ldftn : Call\n\t{\n\t\tpublic Ldftn() : base(OpCodes.Ldftn)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"ldvirtftn\")]\n\tpublic sealed class Ldvirtftn : Call\n\t{\n\t\tpublic Ldvirtftn() : base(OpCodes.Ldvirtftn)\n\t\t{\n\t\t}\n\t}\n\tpublic abstract class Simple : Instruction\n\t{\n\t\tprivate OpCode opcode;\n\t\tpublic Simple(OpCode opcode)\n\t\t{\n\t\t\tthis.opcode = opcode;\n\t\t}\n\t\tinternal sealed override void Generate(CodeGenContext context, CodeEmitter ilgen)\n\t\t{\n\t\t\tilgen.Emit(opcode);\n\t\t}\n\t}\n\t[XmlType(\"dup\")]\n\tpublic sealed class Dup : Simple\n\t{\n\t\tpublic Dup() : base(OpCodes.Dup)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"pop\")]\n\tpublic sealed class Pop : Instruction\n\t{\n\t\tinternal override void Generate(CodeGenContext context, CodeEmitter ilgen)\n\t\t{\n\t\t\tilgen.Emit(OpCodes.Pop);\n\t\t}\n\t}\n\tpublic abstract class TypeOrTypeWrapperInstruction : Instruction\n\t{\n\t\t[XmlAttribute(\"class\")]\n\t\tpublic string Class;\n\t\t[XmlAttribute(\"type\")]\n\t\tpublic string type;\n\t\tinternal TypeWrapper typeWrapper;\n\t\tinternal Type typeType;\n\t\tinternal override void Generate(CodeGenContext context, CodeEmitter ilgen)\n\t\t{\n\t\t\tif(typeWrapper == null && typeType == null)\n\t\t\t{\n\t\t\t\tDebug.Assert(Class == null ^ type == null);\n\t\t\t\tif(Class != null)\n\t\t\t\t{\n\t\t\t\t\ttypeWrapper = context.ClassLoader.LoadClassByDottedName(Class);\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\ttypeType = StaticCompiler.GetTypeForMapXml(context.ClassLoader, type);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t[XmlType(\"isinst\")]\n\tpublic sealed class IsInst : TypeOrTypeWrapperInstruction\n\t{\n\t\tpublic IsInst()\n\t\t{\n\t\t}\n\t\tinternal override void Generate(CodeGenContext context, CodeEmitter ilgen)\n\t\t{\n\t\t\tbase.Generate(context, ilgen);\n\t\t\tif(typeType != null)\n\t\t\t{\n\t\t\t\tilgen.Emit(OpCodes.Isinst, typeType);\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tif(typeWrapper.IsGhost || typeWrapper.IsGhostArray)\n\t\t\t\t{\n\t\t\t\t\tilgen.Emit(OpCodes.Dup);\n\t\t\t\t\ttypeWrapper.EmitInstanceOf(ilgen);\n\t\t\t\t\tCodeEmitterLabel endLabel = ilgen.DefineLabel();\n\t\t\t\t\tilgen.EmitBrtrue(endLabel);\n\t\t\t\t\tilgen.Emit(OpCodes.Pop);\n\t\t\t\t\tilgen.Emit(OpCodes.Ldnull);\n\t\t\t\t\tilgen.MarkLabel(endLabel);\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tilgen.Emit(OpCodes.Isinst, typeWrapper.TypeAsTBD);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t[XmlType(\"castclass\")]\n\tpublic sealed class Castclass : TypeOrTypeWrapperInstruction\n\t{\n\t\tpublic Castclass()\n\t\t{\n\t\t}\n\t\tinternal override void Generate(CodeGenContext context, CodeEmitter ilgen)\n\t\t{\n\t\t\tbase.Generate(context, ilgen);\n\t\t\tif(typeType != null)\n\t\t\t{\n\t\t\t\tilgen.Emit(OpCodes.Castclass, typeType);\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\ttypeWrapper.EmitCheckcast(ilgen);\n\t\t\t}\n\t\t}\n\t}\n\t[XmlType(\"castclass_impl\")]\n\tpublic sealed class Castclass_impl : Instruction\n\t{\n\t\t[XmlAttribute(\"class\")]\n\t\tpublic string Class;\n\t\tpublic Castclass_impl()\n\t\t{\n\t\t}\n\t\tinternal override void Generate(CodeGenContext context, CodeEmitter ilgen)\n\t\t{\n\t\t\tilgen.Emit(OpCodes.Castclass, context.ClassLoader.LoadClassByDottedName(Class).TypeAsBaseType);\n\t\t}\n\t}\n\tpublic abstract class TypeInstruction : Instruction\n\t{\n\t\t[XmlAttribute(\"type\")]\n\t\tpublic string type;\n\t\tprivate OpCode opcode;\n\t\tprivate Type typeType;\n\t\tinternal TypeInstruction(OpCode opcode)\n\t\t{\n\t\t\tthis.opcode = opcode;\n\t\t}\n\t\tinternal override void Generate(CodeGenContext context, CodeEmitter ilgen)\n\t\t{\n\t\t\tif(typeType == null)\n\t\t\t{\n\t\t\t\tDebug.Assert(type != null);\n\t\t\t\ttypeType = StaticCompiler.GetTypeForMapXml(context.ClassLoader, type);\n\t\t\t}\n\t\t\tilgen.Emit(opcode, typeType);\n\t\t}\n\t}\n\t[XmlType(\"ldobj\")]\n\tpublic sealed class Ldobj : TypeInstruction\n\t{\n\t\tpublic Ldobj() : base(OpCodes.Ldobj)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"unbox\")]\n\tpublic sealed class Unbox : TypeInstruction\n\t{\n\t\tpublic Unbox() : base(OpCodes.Unbox)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"box\")]\n\tpublic sealed class Box : TypeInstruction\n\t{\n\t\tpublic Box() : base(OpCodes.Box)\n\t\t{\n\t\t}\n\t}\n\tpublic abstract class Branch : Instruction\n\t{\n\t\tinternal sealed override void Generate(CodeGenContext context, CodeEmitter ilgen)\n\t\t{\n\t\t\tCodeEmitterLabel l;\n\t\t\tif(context[Name] == null)\n\t\t\t{\n\t\t\t\tl = ilgen.DefineLabel();\n\t\t\t\tcontext[Name] = l;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tl = (CodeEmitterLabel)context[Name];\n\t\t\t}\n\t\t\tEmit(ilgen, l);\n\t\t}\n\t\tinternal abstract void Emit(CodeEmitter ilgen, CodeEmitterLabel label);\n\t\t[XmlAttribute(\"name\")]\n\t\tpublic string Name;\n\t}\n\t[XmlType(\"brfalse\")]\n\tpublic sealed class BrFalse : Branch\n\t{\n\t\tinternal override void Emit(CodeEmitter ilgen, CodeEmitterLabel label)\n\t\t{\n\t\t\tilgen.EmitBrfalse(label);\n\t\t}\n\t}\n\t[XmlType(\"brtrue\")]\n\tpublic sealed class BrTrue : Branch\n\t{\n\t\tinternal override void Emit(CodeEmitter ilgen, CodeEmitterLabel label)\n\t\t{\n\t\t\tilgen.EmitBrtrue(label);\n\t\t}\n\t}\n\t[XmlType(\"br\")]\n\tpublic sealed class Br : Branch\n\t{\n\t\tinternal override void Emit(CodeEmitter ilgen, CodeEmitterLabel label)\n\t\t{\n\t\t\tilgen.EmitBr(label);\n\t\t}\n\t}\n\t[XmlType(\"beq\")]\n\tpublic sealed class Beq : Branch\n\t{\n\t\tinternal override void Emit(CodeEmitter ilgen, CodeEmitterLabel label)\n\t\t{\n\t\t\tilgen.EmitBeq(label);\n\t\t}\n\t}\n\t[XmlType(\"bne_un\")]\n\tpublic sealed class Bne_Un : Branch\n\t{\n\t\tinternal override void Emit(CodeEmitter ilgen, CodeEmitterLabel label)\n\t\t{\n\t\t\tilgen.EmitBne_Un(label);\n\t\t}\n\t}\n\t[XmlType(\"bge_un\")]\n\tpublic sealed class Bge_Un : Branch\n\t{\n\t\tinternal override void Emit(CodeEmitter ilgen, CodeEmitterLabel label)\n\t\t{\n\t\t\tilgen.EmitBge_Un(label);\n\t\t}\n\t}\n\t[XmlType(\"ble_un\")]\n\tpublic sealed class Ble_Un : Branch\n\t{\n\t\tinternal override void Emit(CodeEmitter ilgen, CodeEmitterLabel label)\n\t\t{\n\t\t\tilgen.EmitBle_Un(label);\n\t\t}\n\t}\n\t[XmlType(\"blt\")]\n\tpublic sealed class Blt : Branch\n\t{\n\t\tinternal override void Emit(CodeEmitter ilgen, CodeEmitterLabel label)\n\t\t{\n\t\t\tilgen.EmitBlt(label);\n\t\t}\n\t}\n\t[XmlType(\"blt_un\")]\n\tpublic sealed class Blt_Un : Branch\n\t{\n\t\tinternal override void Emit(CodeEmitter ilgen, CodeEmitterLabel label)\n\t\t{\n\t\t\tilgen.EmitBlt_Un(label);\n\t\t}\n\t}\n\t[XmlType(\"label\")]\n\tpublic sealed class BrLabel : Instruction\n\t{\n\t\t[XmlAttribute(\"name\")]\n\t\tpublic string Name;\n\t\tinternal override void Generate(CodeGenContext context, CodeEmitter ilgen)\n\t\t{\n\t\t\tCodeEmitterLabel l;\n\t\t\tif(context[Name] == null)\n\t\t\t{\n\t\t\t\tl = ilgen.DefineLabel();\n\t\t\t\tcontext[Name] = l;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tl = (CodeEmitterLabel)context[Name];\n\t\t\t}\n\t\t\tilgen.MarkLabel(l);\n\t\t}\n\t}\n\t[XmlType(\"stloc\")]\n\tpublic sealed class StLoc : Instruction\n\t{\n\t\t[XmlAttribute(\"name\")]\n\t\tpublic string Name;\n\t\t[XmlAttribute(\"class\")]\n\t\tpublic string Class;\n\t\t[XmlAttribute(\"type\")]\n\t\tpublic string type;\n\t\tprivate TypeWrapper typeWrapper;\n\t\tprivate Type typeType;\n\t\tinternal override void Generate(CodeGenContext context, CodeEmitter ilgen)\n\t\t{\n\t\t\tCodeEmitterLocal lb = (CodeEmitterLocal)context[Name];\n\t\t\tif(lb == null)\n\t\t\t{\n\t\t\t\tif(typeWrapper == null && typeType == null)\n\t\t\t\t{\n\t\t\t\t\tDebug.Assert(Class == null ^ type == null);\n\t\t\t\t\tif(type != null)\n\t\t\t\t\t{\n\t\t\t\t\t\ttypeType = StaticCompiler.GetTypeForMapXml(context.ClassLoader, type);\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\ttypeWrapper = context.ClassLoader.LoadClassByDottedName(Class);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tlb = ilgen.DeclareLocal(typeType != null ? typeType : typeWrapper.TypeAsTBD);\n\t\t\t\tcontext[Name] = lb;\n\t\t\t}\n\t\t\tilgen.Emit(OpCodes.Stloc, lb);\n\t\t}\n\t}\n\t[XmlType(\"ldloc\")]\n\tpublic sealed class LdLoc : Instruction\n\t{\n\t\t[XmlAttribute(\"name\")]\n\t\tpublic string Name;\n\t\tinternal override void Generate(CodeGenContext context, CodeEmitter ilgen)\n\t\t{\n\t\t\tilgen.Emit(OpCodes.Ldloc, (CodeEmitterLocal)context[Name]);\n\t\t}\n\t}\n\t[XmlType(\"ldarga\")]\n\tpublic sealed class LdArga : Instruction\n\t{\n\t\t[XmlAttribute(\"argNum\")]\n\t\tpublic ushort ArgNum;\n\t\tinternal override void Generate(CodeGenContext context, CodeEmitter ilgen)\n\t\t{\n\t\t\tilgen.EmitLdarga(ArgNum);\n\t\t}\n\t}\n\t[XmlType(\"ldarg_s\")]\n\tpublic sealed class LdArg_S : Instruction\n\t{\n\t\t[XmlAttribute(\"argNum\")]\n\t\tpublic byte ArgNum;\n\t\tinternal override void Generate(CodeGenContext context, CodeEmitter ilgen)\n\t\t{\n\t\t\tilgen.EmitLdarg(ArgNum);\n\t\t}\n\t}\n\t[XmlType(\"ldarg_0\")]\n\tpublic sealed class LdArg_0 : Simple\n\t{\n\t\tpublic LdArg_0() : base(OpCodes.Ldarg_0)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"ldarg_1\")]\n\tpublic sealed class LdArg_1 : Simple\n\t{\n\t\tpublic LdArg_1() : base(OpCodes.Ldarg_1)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"ldarg_2\")]\n\tpublic sealed class LdArg_2 : Simple\n\t{\n\t\tpublic LdArg_2() : base(OpCodes.Ldarg_2)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"ldarg_3\")]\n\tpublic sealed class LdArg_3 : Simple\n\t{\n\t\tpublic LdArg_3() : base(OpCodes.Ldarg_3)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"ldind_i1\")]\n\tpublic sealed class Ldind_i1 : Simple\n\t{\n\t\tpublic Ldind_i1() : base(OpCodes.Ldind_I1)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"ldind_i2\")]\n\tpublic sealed class Ldind_i2 : Simple\n\t{\n\t\tpublic Ldind_i2() : base(OpCodes.Ldind_I2)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"ldind_i4\")]\n\tpublic sealed class Ldind_i4 : Simple\n\t{\n\t\tpublic Ldind_i4() : base(OpCodes.Ldind_I4)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"ldind_i8\")]\n\tpublic sealed class Ldind_i8 : Simple\n\t{\n\t\tpublic Ldind_i8() : base(OpCodes.Ldind_I8)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"ldind_r4\")]\n\tpublic sealed class Ldind_r4 : Simple\n\t{\n\t\tpublic Ldind_r4() : base(OpCodes.Ldind_R4)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"ldind_r8\")]\n\tpublic sealed class Ldind_r8 : Simple\n\t{\n\t\tpublic Ldind_r8() : base(OpCodes.Ldind_R8)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"ldind_ref\")]\n\tpublic sealed class Ldind_ref : Simple\n\t{\n\t\tpublic Ldind_ref() : base(OpCodes.Ldind_Ref)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"stind_i1\")]\n\tpublic sealed class Stind_i1 : Simple\n\t{\n\t\tpublic Stind_i1() : base(OpCodes.Stind_I1)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"stind_i2\")]\n\tpublic sealed class Stind_i2 : Simple\n\t{\n\t\tpublic Stind_i2() : base(OpCodes.Stind_I2)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"stind_i4\")]\n\tpublic sealed class Stind_i4 : Simple\n\t{\n\t\tpublic Stind_i4() : base(OpCodes.Stind_I4)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"stind_i8\")]\n\tpublic sealed class Stind_i8 : Simple\n\t{\n\t\tpublic Stind_i8()\n\t\t\t: base(OpCodes.Stind_I8)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"stind_ref\")]\n\tpublic sealed class Stind_ref : Simple\n\t{\n\t\tpublic Stind_ref() : base(OpCodes.Stind_Ref)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"ret\")]\n\tpublic sealed class Ret : Simple\n\t{\n\t\tpublic Ret() : base(OpCodes.Ret)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"throw\")]\n\tpublic sealed class Throw : Simple\n\t{\n\t\tpublic Throw() : base(OpCodes.Throw)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"ldflda\")]\n\tpublic sealed class Ldflda : Instruction\n\t{\n\t\t[XmlAttribute(\"class\")]\n\t\tpublic string Class;\n\t\t[XmlAttribute(\"name\")]\n\t\tpublic string Name;\n\t\t[XmlAttribute(\"sig\")]\n\t\tpublic string Sig;\n\t\tinternal override void Generate(CodeGenContext context, CodeEmitter ilgen)\n\t\t{\n\t\t\tilgen.Emit(OpCodes.Ldflda, StaticCompiler.GetFieldForMapXml(context.ClassLoader, Class, Name, Sig).GetField());\n\t\t}\n\t}\n\t[XmlType(\"ldfld\")]\n\tpublic sealed class Ldfld : Instruction\n\t{\n\t\t[XmlAttribute(\"class\")]\n\t\tpublic string Class;\n\t\t[XmlAttribute(\"name\")]\n\t\tpublic string Name;\n\t\t[XmlAttribute(\"sig\")]\n\t\tpublic string Sig;\n\t\tinternal override void Generate(CodeGenContext context, CodeEmitter ilgen)\n\t\t{\n\t\t\t// we don't use fw.EmitGet because we don't want automatic unboxing and whatever\n\t\t\tilgen.Emit(OpCodes.Ldfld, StaticCompiler.GetFieldForMapXml(context.ClassLoader, Class, Name, Sig).GetField());\n\t\t}\n\t}\n\t[XmlType(\"ldsfld\")]\n\tpublic sealed class Ldsfld : Instruction\n\t{\n\t\t[XmlAttribute(\"class\")]\n\t\tpublic string Class;\n\t\t[XmlAttribute(\"type\")]\n\t\tpublic string Type;\n\t\t[XmlAttribute(\"name\")]\n\t\tpublic string Name;\n\t\t[XmlAttribute(\"sig\")]\n\t\tpublic string Sig;\n\t\tinternal override void Generate(CodeGenContext context, CodeEmitter ilgen)\n\t\t{\n\t\t\tif(Type != null)\n\t\t\t{\n\t\t\t\tilgen.Emit(OpCodes.Ldsfld, StaticCompiler.GetTypeForMapXml(context.ClassLoader, Type).GetField(Name, BindingFlags.Static | BindingFlags.Public | BindingFlags.NonPublic));\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\t// we don't use fw.EmitGet because we don't want automatic unboxing and whatever\n\t\t\t\tilgen.Emit(OpCodes.Ldsfld, StaticCompiler.GetFieldForMapXml(context.ClassLoader, Class, Name, Sig).GetField());\n\t\t\t}\n\t\t}\n\t}\n\t[XmlType(\"stfld\")]\n\tpublic sealed class Stfld : Instruction\n\t{\n\t\t[XmlAttribute(\"class\")]\n\t\tpublic string Class;\n\t\t[XmlAttribute(\"name\")]\n\t\tpublic string Name;\n\t\t[XmlAttribute(\"sig\")]\n\t\tpublic string Sig;\n\t\tinternal override void Generate(CodeGenContext context, CodeEmitter ilgen)\n\t\t{\n\t\t\t// we don't use fw.EmitSet because we don't want automatic unboxing and whatever\n\t\t\tilgen.Emit(OpCodes.Stfld, StaticCompiler.GetFieldForMapXml(context.ClassLoader, Class, Name, Sig).GetField());\n\t\t}\n\t}\n\t[XmlType(\"stsfld\")]\n\tpublic sealed class Stsfld : Instruction\n\t{\n\t\t[XmlAttribute(\"class\")]\n\t\tpublic string Class;\n\t\t[XmlAttribute(\"name\")]\n\t\tpublic string Name;\n\t\t[XmlAttribute(\"sig\")]\n\t\tpublic string Sig;\n\t\tinternal override void Generate(CodeGenContext context, CodeEmitter ilgen)\n\t\t{\n\t\t\t// we don't use fw.EmitSet because we don't want automatic unboxing and whatever\n\t\t\tilgen.Emit(OpCodes.Stsfld, StaticCompiler.GetFieldForMapXml(context.ClassLoader, Class, Name, Sig).GetField());\n\t\t}\n\t}\n\t[XmlType(\"ldc_i4\")]\n\tpublic sealed class Ldc_I4 : Instruction\n\t{\n\t\t[XmlAttribute(\"value\")]\n\t\tpublic int val;\n\t\tinternal override void Generate(CodeGenContext context, CodeEmitter ilgen)\n\t\t{\n\t\t\tilgen.EmitLdc_I4(val);\n\t\t}\n\t}\n\t[XmlType(\"ldc_i4_0\")]\n\tpublic sealed class Ldc_I4_0 : Simple\n\t{\n\t\tpublic Ldc_I4_0() : base(OpCodes.Ldc_I4_0)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"ldc_i4_1\")]\n\tpublic sealed class Ldc_I4_1 : Simple\n\t{\n\t\tpublic Ldc_I4_1() : base(OpCodes.Ldc_I4_1)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"ldc_i4_m1\")]\n\tpublic sealed class Ldc_I4_M1 : Simple\n\t{\n\t\tpublic Ldc_I4_M1() : base(OpCodes.Ldc_I4_M1)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"conv_i\")]\n\tpublic sealed class Conv_I : Simple\n\t{\n\t\tpublic Conv_I() : base(OpCodes.Conv_I)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"conv_i1\")]\n\tpublic sealed class Conv_I1 : Simple\n\t{\n\t\tpublic Conv_I1() : base(OpCodes.Conv_I1)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"conv_u1\")]\n\tpublic sealed class Conv_U1 : Simple\n\t{\n\t\tpublic Conv_U1() : base(OpCodes.Conv_U1)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"conv_i2\")]\n\tpublic sealed class Conv_I2 : Simple\n\t{\n\t\tpublic Conv_I2() : base(OpCodes.Conv_I2)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"conv_u2\")]\n\tpublic sealed class Conv_U2 : Simple\n\t{\n\t\tpublic Conv_U2() : base(OpCodes.Conv_U2)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"conv_i4\")]\n\tpublic sealed class Conv_I4 : Simple\n\t{\n\t\tpublic Conv_I4() : base(OpCodes.Conv_I4)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"conv_u4\")]\n\tpublic sealed class Conv_U4 : Simple\n\t{\n\t\tpublic Conv_U4() : base(OpCodes.Conv_U4)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"conv_i8\")]\n\tpublic sealed class Conv_I8 : Simple\n\t{\n\t\tpublic Conv_I8() : base(OpCodes.Conv_I8)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"conv_u8\")]\n\tpublic sealed class Conv_U8 : Simple\n\t{\n\t\tpublic Conv_U8() : base(OpCodes.Conv_U8)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"ldlen\")]\n\tpublic sealed class Ldlen : Simple\n\t{\n\t\tpublic Ldlen() : base(OpCodes.Ldlen)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"add\")]\n\tpublic sealed class Add : Simple\n\t{\n\t\tpublic Add() : base(OpCodes.Add)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"sub\")]\n\tpublic sealed class Sub : Simple\n\t{\n\t\tpublic Sub()\n\t\t\t: base(OpCodes.Sub)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"mul\")]\n\tpublic sealed class Mul : Simple\n\t{\n\t\tpublic Mul() : base(OpCodes.Mul)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"div_un\")]\n\tpublic sealed class Div_Un : Simple\n\t{\n\t\tpublic Div_Un()\n\t\t\t: base(OpCodes.Div_Un)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"rem_un\")]\n\tpublic sealed class Rem_Un : Simple\n\t{\n\t\tpublic Rem_Un()\n\t\t\t: base(OpCodes.Rem_Un)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"and\")]\n\tpublic sealed class And : Simple\n\t{\n\t\tpublic And()\n\t\t\t: base(OpCodes.And)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"or\")]\n\tpublic sealed class Or : Simple\n\t{\n\t\tpublic Or()\n\t\t\t: base(OpCodes.Or)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"xor\")]\n\tpublic sealed class Xor : Simple\n\t{\n\t\tpublic Xor()\n\t\t\t: base(OpCodes.Xor)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"not\")]\n\tpublic sealed class Not : Simple\n\t{\n\t\tpublic Not()\n\t\t\t: base(OpCodes.Not)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"unaligned\")]\n\tpublic sealed class Unaligned : Instruction\n\t{\n\t\t[XmlAttribute(\"alignment\")]\n\t\tpublic int Alignment;\n\t\tinternal override void Generate(CodeGenContext context, CodeEmitter ilgen)\n\t\t{\n\t\t\tilgen.EmitUnaligned((byte)Alignment);\n\t\t}\n\t}\n\t[XmlType(\"cpblk\")]\n\tpublic sealed class Cpblk : Simple\n\t{\n\t\tpublic Cpblk() : base(OpCodes.Cpblk)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"ceq\")]\n\tpublic sealed class Ceq : Simple\n\t{\n\t\tpublic Ceq() : base(OpCodes.Ceq)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"leave\")]\n\tpublic sealed class Leave : Branch\n\t{\n\t\tinternal override void Emit(CodeEmitter ilgen, CodeEmitterLabel label)\n\t\t{\n\t\t\tilgen.EmitLeave(label);\n\t\t}\n\t}\n\t[XmlType(\"endfinally\")]\n\tpublic sealed class Endfinally : Simple\n\t{\n\t\tpublic Endfinally() : base(OpCodes.Endfinally)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"exceptionBlock\")]\n\tpublic sealed class ExceptionBlock : Instruction\n\t{\n\t\tpublic InstructionList @try;\n\t\tpublic CatchBlock @catch;\n\t\tpublic InstructionList @finally;\n\t\tinternal override void Generate(CodeGenContext context, CodeEmitter ilgen)\n\t\t{\n\t\t\tilgen.BeginExceptionBlock();\n\t\t\t@try.Generate(context, ilgen);\n\t\t\tif(@catch != null)\n\t\t\t{\n\t\t\t\tType type;\n\t\t\t\tif(@catch.type != null)\n\t\t\t\t{\n\t\t\t\t\ttype = StaticCompiler.GetTypeForMapXml(context.ClassLoader, @catch.type);\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\ttype = context.ClassLoader.LoadClassByDottedName(@catch.Class).TypeAsExceptionType;\n\t\t\t\t}\n\t\t\t\tilgen.BeginCatchBlock(type);\n\t\t\t\t@catch.Generate(context, ilgen);\n\t\t\t}\n\t\t\tif(@finally != null)\n\t\t\t{\n\t\t\t\tilgen.BeginFinallyBlock();\n\t\t\t\t@finally.Generate(context, ilgen);\n\t\t\t}\n\t\t\tilgen.EndExceptionBlock();\n\t\t}\n\t}\n\tpublic sealed class CatchBlock : InstructionList\n\t{\n\t\t[XmlAttribute(\"type\")]\n\t\tpublic string type;\n\t\t[XmlAttribute(\"class\")]\n\t\tpublic string Class;\n\t}\n\t[XmlType(\"conditional\")]\n\tpublic sealed class ConditionalInstruction : Instruction\n\t{\n\t\t[XmlAttribute(\"framework\")]\n\t\tpublic string framework;\n\t\tpublic InstructionList code;\n\t\tinternal override void Generate(CodeGenContext context, CodeEmitter ilgen)\n\t\t{\n\t\t\tif (Environment.Version.ToString().StartsWith(framework))\n\t\t\t{\n\t\t\t\tcode.Generate(context, ilgen);\n\t\t\t}\n\t\t}\n\t}\n\t[XmlType(\"volatile\")]\n\tpublic sealed class Volatile : Simple\n\t{\n\t\tpublic Volatile() : base(OpCodes.Volatile)\n\t\t{\n\t\t}\n\t}\n\t[XmlType(\"ldelema\")]\n\tpublic sealed class Ldelema : Instruction\n\t{\n\t\t[XmlAttribute(\"sig\")]\n\t\tpublic string Sig;\n\t\tinternal override void Generate(CodeGenContext context, CodeEmitter ilgen)\n\t\t{\n\t\t\tilgen.Emit(OpCodes.Ldelema, context.ClassLoader.FieldTypeWrapperFromSig(Sig, LoadMode.LoadOrThrow).TypeAsArrayType);\n\t\t}\n\t}\n\t[XmlType(\"newarr\")]\n\tpublic sealed class Newarr : Instruction\n\t{\n\t\t[XmlAttribute(\"sig\")]\n\t\tpublic string Sig;\n\t\tinternal override void Generate(CodeGenContext context, CodeEmitter ilgen)\n\t\t{\n\t\t\tilgen.Emit(OpCodes.Newarr, context.ClassLoader.FieldTypeWrapperFromSig(Sig, LoadMode.LoadOrThrow).TypeAsArrayType);\n\t\t}\n\t}\n\t[XmlType(\"ldtoken\")]\n\tpublic sealed class Ldtoken : Instruction\n\t{\n\t\t[XmlAttribute(\"type\")]\n\t\tpublic string type;\n\t\t[XmlAttribute(\"class\")]\n\t\tpublic string Class;\n\t\t[XmlAttribute(\"method\")]\n\t\tpublic string Method;\n\t\t[XmlAttribute(\"field\")]\n\t\tpublic string Field;\n\t\t[XmlAttribute(\"sig\")]\n\t\tpublic string Sig;\n\t\tinternal override void Generate(CodeGenContext context, CodeEmitter ilgen)\n\t\t{\n\t\t\tif (!Validate())\n\t\t\t{\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tMemberInfo member = Resolve(context);\n\t\t\tType type = member as Type;\n\t\t\tMethodInfo method = member as MethodInfo;\n\t\t\tConstructorInfo constructor = member as ConstructorInfo;\n\t\t\tFieldInfo field = member as FieldInfo;\n\t\t\tif (type != null)\n\t\t\t{\n\t\t\t\tilgen.Emit(OpCodes.Ldtoken, type);\n\t\t\t}\n\t\t\telse if (method != null)\n\t\t\t{\n\t\t\t\tilgen.Emit(OpCodes.Ldtoken, method);\n\t\t\t}\n\t\t\telse if (constructor != null)\n\t\t\t{\n\t\t\t\tilgen.Emit(OpCodes.Ldtoken, constructor);\n\t\t\t}\n\t\t\telse if (field != null)\n\t\t\t{\n\t\t\t\tilgen.Emit(OpCodes.Ldtoken, field);\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tStaticCompiler.IssueMessage(Message.MapXmlUnableToResolveOpCode, ToString());\n\t\t\t}\n\t\t}\n\t\tprivate bool Validate()\n\t\t{\n\t\t\tif (type != null && Class == null)\n\t\t\t{\n\t\t\t\tif (Method != null || Field != null || Sig != null)\n\t\t\t\t{\n\t\t\t\t\tStaticCompiler.IssueMessage(Message.MapXmlError, \"not implemented: cannot use 'type' attribute with 'method' or 'field' attribute for ldtoken\");\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t\treturn true;\n\t\t\t}\n", "outputs": ["\t\t\telse if (Class != null && type == null)"], "input_length": 5274, "output_length": 13, "length": 5287, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "2b7e32bab460d1f2ed533e28a3a14689f83aa265945c7ee06b3ed5f91e82c916"}
{"input": "", "context": "#region Copyright & License Information\n/*\n * Copyright 2007-2021 The OpenRA Developers (see AUTHORS)\n * This file is part of OpenRA, which is free software. It is made\n * available to you under the terms of the GNU General Public License\n * as published by the Free Software Foundation, either version 3 of\n * the License, or (at your option) any later version. For more\n * information, see COPYING.\n */\n#endregion\nusing System.Collections.Generic;\nusing System.Linq;\nusing OpenRA.Traits;\nnamespace OpenRA.Mods.Common.Traits\n{\n\t[Desc(\"Manages AI base construction.\")]\n\tpublic class BaseBuilderBotModuleInfo : ConditionalTraitInfo\n\t{\n\t\t[Desc(\"Tells the AI what building types are considered construction yards.\")]\n\t\tpublic readonly HashSet<string> ConstructionYardTypes = new HashSet<string>();\n\t\t[Desc(\"Tells the AI what building types are considered vehicle production facilities.\")]\n\t\tpublic readonly HashSet<string> VehiclesFactoryTypes = new HashSet<string>();\n\t\t[Desc(\"Tells the AI what building types are considered refineries.\")]\n\t\tpublic readonly HashSet<string> RefineryTypes = new HashSet<string>();\n\t\t[Desc(\"Tells the AI what building types are considered power plants.\")]\n\t\tpublic readonly HashSet<string> PowerTypes = new HashSet<string>();\n\t\t[Desc(\"Tells the AI what building types are considered infantry production facilities.\")]\n\t\tpublic readonly HashSet<string> BarracksTypes = new HashSet<string>();\n\t\t[Desc(\"Tells the AI what building types are considered production facilities.\")]\n\t\tpublic readonly HashSet<string> ProductionTypes = new HashSet<string>();\n\t\t[Desc(\"Tells the AI what building types are considered naval production facilities.\")]\n\t\tpublic readonly HashSet<string> NavalProductionTypes = new HashSet<string>();\n\t\t[Desc(\"Tells the AI what building types are considered silos (resource storage).\")]\n\t\tpublic readonly HashSet<string> SiloTypes = new HashSet<string>();\n\t\t[Desc(\"Production queues AI uses for buildings.\")]\n\t\tpublic readonly HashSet<string> BuildingQueues = new HashSet<string> { \"Building\" };\n\t\t[Desc(\"Production queues AI uses for defenses.\")]\n\t\tpublic readonly HashSet<string> DefenseQueues = new HashSet<string> { \"Defense\" };\n\t\t[Desc(\"Minimum distance in cells from center of the base when checking for building placement.\")]\n\t\tpublic readonly int MinBaseRadius = 2;\n\t\t[Desc(\"Radius in cells around the center of the base to expand.\")]\n\t\tpublic readonly int MaxBaseRadius = 20;\n\t\t[Desc(\"Minimum excess power the AI should try to maintain.\")]\n\t\tpublic readonly int MinimumExcessPower = 0;\n\t\t[Desc(\"The targeted excess power the AI tries to maintain cannot rise above this.\")]\n\t\tpublic readonly int MaximumExcessPower = 0;\n\t\t[Desc(\"Increase maintained excess power by this amount for every ExcessPowerIncreaseThreshold of base buildings.\")]\n\t\tpublic readonly int ExcessPowerIncrement = 0;\n\t\t[Desc(\"Increase maintained excess power by ExcessPowerIncrement for every N base buildings.\")]\n\t\tpublic readonly int ExcessPowerIncreaseThreshold = 1;\n\t\t[Desc(\"Number of refineries to build before building a barracks.\")]\n\t\tpublic readonly int InititalMinimumRefineryCount = 1;\n\t\t[Desc(\"Number of refineries to build additionally after building a barracks.\")]\n\t\tpublic readonly int AdditionalMinimumRefineryCount = 1;\n\t\t[Desc(\"Additional delay (in ticks) between structure production checks when there is no active production.\",\n\t\t\t\"StructureProductionRandomBonusDelay is added to this.\")]\n\t\tpublic readonly int StructureProductionInactiveDelay = 125;\n\t\t[Desc(\"Additional delay (in ticks) added between structure production checks when actively building things.\",\n\t\t\t\"Note: this should be at least as large as the typical order latency to avoid duplicated build choices.\")]\n\t\tpublic readonly int StructureProductionActiveDelay = 25;\n\t\t[Desc(\"A random delay (in ticks) of up to this is added to active/inactive production delays.\")]\n\t\tpublic readonly int StructureProductionRandomBonusDelay = 10;\n\t\t[Desc(\"Delay (in ticks) until retrying to build structure after the last 3 consecutive attempts failed.\")]\n\t\tpublic readonly int StructureProductionResumeDelay = 1500;\n\t\t[Desc(\"After how many failed attempts to place a structure should AI give up and wait\",\n\t\t\t\"for StructureProductionResumeDelay before retrying.\")]\n\t\tpublic readonly int MaximumFailedPlacementAttempts = 3;\n\t\t[Desc(\"How many randomly chosen cells with resources to check when deciding refinery placement.\")]\n\t\tpublic readonly int MaxResourceCellsToCheck = 3;\n\t\t[Desc(\"Delay (in ticks) until rechecking for new BaseProviders.\")]\n\t\tpublic readonly int CheckForNewBasesDelay = 1500;\n\t\t[Desc(\"Chance that the AI will place the defenses in the direction of the closest enemy building.\")]\n\t\tpublic readonly int PlaceDefenseTowardsEnemyChance = 100;\n\t\t[Desc(\"Minimum range at which to build defensive structures near a combat hotspot.\")]\n\t\tpublic readonly int MinimumDefenseRadius = 5;\n\t\t[Desc(\"Maximum range at which to build defensive structures near a combat hotspot.\")]\n\t\tpublic readonly int MaximumDefenseRadius = 20;\n\t\t[Desc(\"Try to build another production building if there is too much cash.\")]\n\t\tpublic readonly int NewProductionCashThreshold = 5000;\n\t\t[Desc(\"Radius in cells around a factory scanned for rally points by the AI.\")]\n\t\tpublic readonly int RallyPointScanRadius = 8;\n\t\t[Desc(\"Radius in cells around each building with ProvideBuildableArea\",\n\t\t\t\"to check for a 3x3 area of water where naval structures can be built.\",\n\t\t\t\"Should match maximum adjacency of naval structures.\")]\n\t\tpublic readonly int CheckForWaterRadius = 8;\n\t\t[Desc(\"Terrain types which are considered water for base building purposes.\")]\n\t\tpublic readonly HashSet<string> WaterTerrainTypes = new HashSet<string> { \"Water\" };\n\t\t[Desc(\"What buildings to the AI should build.\", \"What integer percentage of the total base must be this type of building.\")]\n\t\tpublic readonly Dictionary<string, int> BuildingFractions = null;\n\t\t[Desc(\"What buildings should the AI have a maximum limit to build.\")]\n\t\tpublic readonly Dictionary<string, int> BuildingLimits = null;\n\t\t[Desc(\"When should the AI start building specific buildings.\")]\n\t\tpublic readonly Dictionary<string, int> BuildingDelays = null;\n\t\tpublic override object Create(ActorInitializer init) { return new BaseBuilderBotModule(init.Self, this); }\n\t}\n\tpublic class BaseBuilderBotModule : ConditionalTrait<BaseBuilderBotModuleInfo>, IGameSaveTraitData,\n\t\tIBotTick, IBotPositionsUpdated, IBotRespondToAttack, IBotRequestPauseUnitProduction\n\t{\n\t\tpublic CPos GetRandomBaseCenter()\n\t\t{\n\t\t\tvar randomConstructionYard = world.Actors.Where(a => a.Owner == player &&\n\t\t\t\tInfo.ConstructionYardTypes.Contains(a.Info.Name))\n\t\t\t\t.RandomOrDefault(world.LocalRandom);\n\t\t\treturn randomConstructionYard?.Location ?? initialBaseCenter;\n\t\t}\n\t\tpublic CPos DefenseCenter => defenseCenter;\n\t\treadonly World world;\n\t\treadonly Player player;\n\t\tPowerManager playerPower;\n\t\tPlayerResources playerResources;\n\t\tIResourceLayer resourceLayer;\n\t\tIBotPositionsUpdated[] positionsUpdatedModules;\n\t\tCPos initialBaseCenter;\n\t\tCPos defenseCenter;\n\t\tList<BaseBuilderQueueManager> builders = new List<BaseBuilderQueueManager>();\n\t\tpublic BaseBuilderBotModule(Actor self, BaseBuilderBotModuleInfo info)\n\t\t\t: base(info)\n\t\t{\n\t\t\tworld = self.World;\n\t\t\tplayer = self.Owner;\n\t\t}\n\t\tprotected override void Created(Actor self)\n\t\t{\n\t\t\tplayerPower = self.Owner.PlayerActor.TraitOrDefault<PowerManager>();\n\t\t\tplayerResources = self.Owner.PlayerActor.Trait<PlayerResources>();\n\t\t\tresourceLayer = self.World.WorldActor.TraitOrDefault<IResourceLayer>();\n\t\t\tpositionsUpdatedModules = self.Owner.PlayerActor.TraitsImplementing<IBotPositionsUpdated>().ToArray();\n\t\t}\n\t\tprotected override void TraitEnabled(Actor self)\n\t\t{\n\t\t\tforeach (var building in Info.BuildingQueues)\n\t\t\t\tbuilders.Add(new BaseBuilderQueueManager(this, building, player, playerPower, playerResources, resourceLayer));\n\t\t\tforeach (var defense in Info.DefenseQueues)\n\t\t\t\tbuilders.Add(new BaseBuilderQueueManager(this, defense, player, playerPower, playerResources, resourceLayer));\n\t\t}\n\t\tvoid IBotPositionsUpdated.UpdatedBaseCenter(CPos newLocation)\n\t\t{\n\t\t\tinitialBaseCenter = newLocation;\n\t\t}\n\t\tvoid IBotPositionsUpdated.UpdatedDefenseCenter(CPos newLocation)\n\t\t{\n\t\t\tdefenseCenter = newLocation;\n\t\t}\n\t\tbool IBotRequestPauseUnitProduction.PauseUnitProduction => !IsTraitDisabled && !HasAdequateRefineryCount;\n\t\tvoid IBotTick.BotTick(IBot bot)\n\t\t{\n\t\t\tSetRallyPointsForNewProductionBuildings(bot);\n\t\t\tforeach (var b in builders)\n\t\t\t\tb.Tick(bot);\n\t\t}\n\t\tvoid IBotRespondToAttack.RespondToAttack(IBot bot, Actor self, AttackInfo e)\n\t\t{\n\t\t\tif (e.Attacker == null || e.Attacker.Disposed)\n\t\t\t\treturn;\n\t\t\tif (e.Attacker.Owner.RelationshipWith(self.Owner) != PlayerRelationship.Enemy)\n\t\t\t\treturn;\n\t\t\tif (!e.Attacker.Info.HasTraitInfo<ITargetableInfo>())\n\t\t\t\treturn;\n\t\t\t// Protect buildings\n\t\t\tif (self.Info.HasTraitInfo<BuildingInfo>())\n\t\t\t\tforeach (var n in positionsUpdatedModules)\n\t\t\t\t\tn.UpdatedDefenseCenter(e.Attacker.Location);\n\t\t}\n\t\tvoid SetRallyPointsForNewProductionBuildings(IBot bot)\n\t\t{\n", "outputs": ["\t\t\tforeach (var rp in world.ActorsWithTrait<RallyPoint>())"], "input_length": 1648, "output_length": 12, "length": 1660, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "b7530cc0bbc4f43c00f57e7ef4549b20a9a89346a655e6ff49bbfb1932be1d59"}
{"input": "", "context": "using System;\nusing System.Collections.Generic;\nusing System.Collections.ObjectModel;\nusing System.ComponentModel;\nusing System.Diagnostics.CodeAnalysis;\nusing System.Globalization;\nusing System.IO;\nusing System.Linq;\nusing System.Net.Http;\nusing System.Net.Http.Formatting;\nusing System.Net.Http.Headers;\nusing System.Web.Http.Description;\nusing System.Xml.Linq;\nusing Newtonsoft.Json;\nnamespace CalendarSyncPlus.Web.WebApi.Areas.HelpPage\n{\n    /// <summary>\n    /// This class will generate the samples for the help page.\n    /// </summary>\n    public class HelpPageSampleGenerator\n    {\n        /// <summary>\n        /// Initializes a new instance of the <see cref=\"HelpPageSampleGenerator\"/> class.\n        /// </summary>\n        public HelpPageSampleGenerator()\n        {\n            ActualHttpMessageTypes = new Dictionary<HelpPageSampleKey, Type>();\n            ActionSamples = new Dictionary<HelpPageSampleKey, object>();\n            SampleObjects = new Dictionary<Type, object>();\n            SampleObjectFactories = new List<Func<HelpPageSampleGenerator, Type, object>>\n            {\n                DefaultSampleObjectFactory,\n            };\n        }\n        /// <summary>\n        /// Gets CLR types that are used as the content of <see cref=\"HttpRequestMessage\"/> or <see cref=\"HttpResponseMessage\"/>.\n        /// </summary>\n        public IDictionary<HelpPageSampleKey, Type> ActualHttpMessageTypes { get; internal set; }\n        /// <summary>\n        /// Gets the objects that are used directly as samples for certain actions.\n        /// </summary>\n        public IDictionary<HelpPageSampleKey, object> ActionSamples { get; internal set; }\n        /// <summary>\n        /// Gets the objects that are serialized as samples by the supported formatters.\n        /// </summary>\n        public IDictionary<Type, object> SampleObjects { get; internal set; }\n        /// <summary>\n        /// Gets factories for the objects that the supported formatters will serialize as samples. Processed in order,\n        /// stopping when the factory successfully returns a non-<see langref=\"null\"/> object.\n        /// </summary>\n        /// <remarks>\n        /// Collection includes just <see cref=\"ObjectGenerator.GenerateObject(Type)\"/> initially. Use\n        /// <code>SampleObjectFactories.Insert(0, func)</code> to provide an override and\n        /// <code>SampleObjectFactories.Add(func)</code> to provide a fallback.</remarks>\n        [SuppressMessage(\"Microsoft.Design\", \"CA1006:DoNotNestGenericTypesInMemberSignatures\",\n            Justification = \"This is an appropriate nesting of generic types\")]\n        public IList<Func<HelpPageSampleGenerator, Type, object>> SampleObjectFactories { get; private set; }\n        /// <summary>\n        /// Gets the request body samples for a given <see cref=\"ApiDescription\"/>.\n        /// </summary>\n        /// <param name=\"api\">The <see cref=\"ApiDescription\"/>.</param>\n        /// <returns>The samples keyed by media type.</returns>\n        public IDictionary<MediaTypeHeaderValue, object> GetSampleRequests(ApiDescription api)\n        {\n            return GetSample(api, SampleDirection.Request);\n        }\n        /// <summary>\n        /// Gets the response body samples for a given <see cref=\"ApiDescription\"/>.\n        /// </summary>\n        /// <param name=\"api\">The <see cref=\"ApiDescription\"/>.</param>\n        /// <returns>The samples keyed by media type.</returns>\n        public IDictionary<MediaTypeHeaderValue, object> GetSampleResponses(ApiDescription api)\n        {\n            return GetSample(api, SampleDirection.Response);\n        }\n        /// <summary>\n        /// Gets the request or response body samples.\n        /// </summary>\n        /// <param name=\"api\">The <see cref=\"ApiDescription\"/>.</param>\n        /// <param name=\"sampleDirection\">The value indicating whether the sample is for a request or for a response.</param>\n        /// <returns>The samples keyed by media type.</returns>\n        public virtual IDictionary<MediaTypeHeaderValue, object> GetSample(ApiDescription api, SampleDirection sampleDirection)\n        {\n            if (api == null)\n            {\n                throw new ArgumentNullException(\"api\");\n            }\n            string controllerName = api.ActionDescriptor.ControllerDescriptor.ControllerName;\n            string actionName = api.ActionDescriptor.ActionName;\n            IEnumerable<string> parameterNames = api.ParameterDescriptions.Select(p => p.Name);\n            Collection<MediaTypeFormatter> formatters;\n            Type type = ResolveType(api, controllerName, actionName, parameterNames, sampleDirection, out formatters);\n            var samples = new Dictionary<MediaTypeHeaderValue, object>();\n            // Use the samples provided directly for actions\n            var actionSamples = GetAllActionSamples(controllerName, actionName, parameterNames, sampleDirection);\n            foreach (var actionSample in actionSamples)\n            {\n                samples.Add(actionSample.Key.MediaType, WrapSampleIfString(actionSample.Value));\n            }\n            // Do the sample generation based on formatters only if an action doesn't return an HttpResponseMessage.\n            // Here we cannot rely on formatters because we don't know what's in the HttpResponseMessage, it might not even use formatters.\n            if (type != null && !typeof(HttpResponseMessage).IsAssignableFrom(type))\n            {\n                object sampleObject = GetSampleObject(type);\n                foreach (var formatter in formatters)\n                {\n                    foreach (MediaTypeHeaderValue mediaType in formatter.SupportedMediaTypes)\n                    {\n                        if (!samples.ContainsKey(mediaType))\n                        {\n                            object sample = GetActionSample(controllerName, actionName, parameterNames, type, formatter, mediaType, sampleDirection);\n                            // If no sample found, try generate sample using formatter and sample object\n                            if (sample == null && sampleObject != null)\n                            {\n                                sample = WriteSampleObjectUsingFormatter(formatter, sampleObject, type, mediaType);\n                            }\n                            samples.Add(mediaType, WrapSampleIfString(sample));\n                        }\n                    }\n                }\n            }\n            return samples;\n        }\n        /// <summary>\n        /// Search for samples that are provided directly through <see cref=\"ActionSamples\"/>.\n        /// </summary>\n        /// <param name=\"controllerName\">Name of the controller.</param>\n        /// <param name=\"actionName\">Name of the action.</param>\n        /// <param name=\"parameterNames\">The parameter names.</param>\n        /// <param name=\"type\">The CLR type.</param>\n        /// <param name=\"formatter\">The formatter.</param>\n        /// <param name=\"mediaType\">The media type.</param>\n        /// <param name=\"sampleDirection\">The value indicating whether the sample is for a request or for a response.</param>\n        /// <returns>The sample that matches the parameters.</returns>\n        public virtual object GetActionSample(string controllerName, string actionName, IEnumerable<string> parameterNames, Type type, MediaTypeFormatter formatter, MediaTypeHeaderValue mediaType, SampleDirection sampleDirection)\n        {\n            object sample;\n            // First, try to get the sample provided for the specified mediaType, sampleDirection, controllerName, actionName and parameterNames.\n            // If not found, try to get the sample provided for the specified mediaType, sampleDirection, controllerName and actionName regardless of the parameterNames.\n            // If still not found, try to get the sample provided for the specified mediaType and type.\n            // Finally, try to get the sample provided for the specified mediaType.\n            if (ActionSamples.TryGetValue(new HelpPageSampleKey(mediaType, sampleDirection, controllerName, actionName, parameterNames), out sample) ||\n                ActionSamples.TryGetValue(new HelpPageSampleKey(mediaType, sampleDirection, controllerName, actionName, new[] { \"*\" }), out sample) ||\n                ActionSamples.TryGetValue(new HelpPageSampleKey(mediaType, type), out sample) ||\n                ActionSamples.TryGetValue(new HelpPageSampleKey(mediaType), out sample))\n            {\n                return sample;\n            }\n            return null;\n        }\n        /// <summary>\n        /// Gets the sample object that will be serialized by the formatters. \n        /// First, it will look at the <see cref=\"SampleObjects\"/>. If no sample object is found, it will try to create\n        /// one using <see cref=\"DefaultSampleObjectFactory\"/> (which wraps an <see cref=\"ObjectGenerator\"/>) and other\n        /// factories in <see cref=\"SampleObjectFactories\"/>.\n        /// </summary>\n        /// <param name=\"type\">The type.</param>\n        /// <returns>The sample object.</returns>\n        [SuppressMessage(\"Microsoft.Design\", \"CA1031:DoNotCatchGeneralExceptionTypes\",\n            Justification = \"Even if all items in SampleObjectFactories throw, problem will be visible as missing sample.\")]\n        public virtual object GetSampleObject(Type type)\n        {\n            object sampleObject;\n            if (!SampleObjects.TryGetValue(type, out sampleObject))\n            {\n                // No specific object available, try our factories.\n                foreach (Func<HelpPageSampleGenerator, Type, object> factory in SampleObjectFactories)\n                {\n                    if (factory == null)\n                    {\n                        continue;\n                    }\n                    try\n                    {\n                        sampleObject = factory(this, type);\n                        if (sampleObject != null)\n                        {\n                            break;\n                        }\n                    }\n                    catch\n                    {\n                        // Ignore any problems encountered in the factory; go on to the next one (if any).\n                    }\n                }\n            }\n            return sampleObject;\n        }\n        /// <summary>\n        /// Resolves the actual type of <see cref=\"System.Net.Http.ObjectContent{T}\"/> passed to the <see cref=\"System.Net.Http.HttpRequestMessage\"/> in an action.\n        /// </summary>\n        /// <param name=\"api\">The <see cref=\"ApiDescription\"/>.</param>\n        /// <returns>The type.</returns>\n        public virtual Type ResolveHttpRequestMessageType(ApiDescription api)\n        {\n            string controllerName = api.ActionDescriptor.ControllerDescriptor.ControllerName;\n            string actionName = api.ActionDescriptor.ActionName;\n            IEnumerable<string> parameterNames = api.ParameterDescriptions.Select(p => p.Name);\n            Collection<MediaTypeFormatter> formatters;\n            return ResolveType(api, controllerName, actionName, parameterNames, SampleDirection.Request, out formatters);\n        }\n        /// <summary>\n        /// Resolves the type of the action parameter or return value when <see cref=\"HttpRequestMessage\"/> or <see cref=\"HttpResponseMessage\"/> is used.\n        /// </summary>\n        /// <param name=\"api\">The <see cref=\"ApiDescription\"/>.</param>\n        /// <param name=\"controllerName\">Name of the controller.</param>\n        /// <param name=\"actionName\">Name of the action.</param>\n        /// <param name=\"parameterNames\">The parameter names.</param>\n        /// <param name=\"sampleDirection\">The value indicating whether the sample is for a request or a response.</param>\n        /// <param name=\"formatters\">The formatters.</param>\n        [SuppressMessage(\"Microsoft.Design\", \"CA1021:AvoidOutParameters\", Justification = \"This is only used in advanced scenarios.\")]\n        public virtual Type ResolveType(ApiDescription api, string controllerName, string actionName, IEnumerable<string> parameterNames, SampleDirection sampleDirection, out Collection<MediaTypeFormatter> formatters)\n        {\n", "outputs": ["            if (!Enum.IsDefined(typeof(SampleDirection), sampleDirection))"], "input_length": 1915, "output_length": 13, "length": 1928, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "c0a3f20694ded4b02d1848f87310793678e487e53a58ded8ce3d1a0dce4b3da6"}
{"input": "", "context": "using System;\nusing System.Collections;\nusing Server.Network;\nusing System.Collections.Generic;\nusing Server.ContextMenus;\nnamespace Server.Items\n{\n\tpublic abstract class Food : Item\n\t{\n\t\tprivate Mobile m_Poisoner;\n\t\tprivate Poison m_Poison;\n\t\tprivate int m_FillFactor;\n\t\t[CommandProperty( AccessLevel.GameMaster )]\n\t\tpublic Mobile Poisoner\n\t\t{\n\t\t\tget { return m_Poisoner; }\n\t\t\tset { m_Poisoner = value; }\n\t\t}\n\t\t[CommandProperty( AccessLevel.GameMaster )]\n\t\tpublic Poison Poison\n\t\t{\n\t\t\tget { return m_Poison; }\n\t\t\tset { m_Poison = value; }\n\t\t}\n\t\t[CommandProperty( AccessLevel.GameMaster )]\n\t\tpublic int FillFactor\n\t\t{\n\t\t\tget { return m_FillFactor; }\n\t\t\tset { m_FillFactor = value; }\n\t\t}\n\t\tpublic Food( int itemID ) : this( 1, itemID )\n\t\t{\n\t\t}\n\t\tpublic Food( int amount, int itemID ) : base( itemID )\n\t\t{\n\t\t\tStackable = true;\n\t\t\tAmount = amount;\n\t\t\tm_FillFactor = 1;\n\t\t}\n\t\tpublic Food( Serial serial ) : base( serial )\n\t\t{\n\t\t}\n\t\tpublic override void GetContextMenuEntries( Mobile from, List<ContextMenuEntry> list )\n\t\t{\n\t\t\tbase.GetContextMenuEntries( from, list );\n\t\t\tif ( from.Alive )\n\t\t\t\tlist.Add( new ContextMenus.EatEntry( from, this ) );\n\t\t}\n\t\tpublic override void OnDoubleClick( Mobile from )\n\t\t{\n\t\t\tif ( !Movable )\n\t\t\t\treturn;\n\t\t\tif ( from.InRange( this.GetWorldLocation(), 1 ) )\n\t\t\t{\n\t\t\t\tEat( from );\n\t\t\t}\n\t\t}\n\t\tpublic virtual bool Eat( Mobile from )\n\t\t{\n\t\t\t// Fill the Mobile with FillFactor\n\t\t\tif ( CheckHunger( from ) )\n\t\t\t{\n\t\t\t\t// Play a random \"eat\" sound\n\t\t\t\tfrom.PlaySound( Utility.Random( 0x3A, 3 ) );\n\t\t\t\tif ( from.Body.IsHuman && !from.Mounted )\n\t\t\t\t\tfrom.Animate( 34, 5, 1, true, false, 0 );\n\t\t\t\tif ( m_Poison != null )\n\t\t\t\t\tfrom.ApplyPoison( m_Poisoner, m_Poison );\n\t\t\t\tConsume();\n\t\t\t\treturn true;\n\t\t\t}\n\t\t\treturn false;\n\t\t}\n\t\tpublic virtual bool CheckHunger( Mobile from )\n\t\t{\n\t\t\treturn FillHunger( from, m_FillFactor );\n\t\t}\n\t\tpublic static bool FillHunger( Mobile from, int fillFactor )\n\t\t{\n\t\t\tif ( from.Hunger >= 20 )\n\t\t\t{\n\t\t\t\tfrom.SendLocalizedMessage( 500867 ); // You are simply too full to eat any more!\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\tint iHunger = from.Hunger + fillFactor;\n\t\t\tif ( from.Stam < from.StamMax )\n\t\t\t\tfrom.Stam += Utility.Random( 6, 3 ) + fillFactor / 5;\n\t\t\tif ( iHunger >= 20 )\n\t\t\t{\n\t\t\t\tfrom.Hunger = 20;\n\t\t\t\tfrom.SendLocalizedMessage( 500872 ); // You manage to eat the food, but you are stuffed!\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tfrom.Hunger = iHunger;\n\t\t\t\tif ( iHunger < 5 )\n\t\t\t\t\tfrom.SendLocalizedMessage( 500868 ); // You eat the food, but are still extremely hungry.\n\t\t\t\telse if ( iHunger < 10 )\n\t\t\t\t\tfrom.SendLocalizedMessage( 500869 ); // You eat the food, and begin to feel more satiated.\n\t\t\t\telse if ( iHunger < 15 )\n\t\t\t\t\tfrom.SendLocalizedMessage( 500870 ); // After eating the food, you feel much less hungry.\n\t\t\t\telse\n\t\t\t\t\tfrom.SendLocalizedMessage( 500871 ); // You feel quite full after consuming the food.\n\t\t\t}\n\t\t\tMisc.FoodDecayTimer.ApplyHungerStatMod(from);\n\t\t\treturn true;\n\t\t}\n\t\tpublic override void Serialize( GenericWriter writer )\n\t\t{\n\t\t\tbase.Serialize( writer );\n\t\t\twriter.Write( (int) 4 ); // version\n\t\t\twriter.Write( m_Poisoner );\n\t\t\tPoison.Serialize( m_Poison, writer );\n\t\t\twriter.Write( m_FillFactor );\n\t\t}\n\t\tpublic override void Deserialize( GenericReader reader )\n\t\t{\n\t\t\tbase.Deserialize( reader );\n\t\t\tint version = reader.ReadInt();\n\t\t\tswitch ( version )\n\t\t\t{\n\t\t\t\tcase 1:\n\t\t\t\t{\n\t\t\t\t\tswitch ( reader.ReadInt() )\n\t\t\t\t\t{\n\t\t\t\t\t\tcase 0: m_Poison = null; break;\n\t\t\t\t\t\tcase 1: m_Poison = Poison.Lesser; break;\n\t\t\t\t\t\tcase 2: m_Poison = Poison.Regular; break;\n\t\t\t\t\t\tcase 3: m_Poison = Poison.Greater; break;\n\t\t\t\t\t\tcase 4: m_Poison = Poison.Deadly; break;\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcase 2:\n\t\t\t\t{\n\t\t\t\t\tm_Poison = Poison.Deserialize( reader );\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcase 3:\n\t\t\t\t{\n\t\t\t\t\tm_Poison = Poison.Deserialize( reader );\n\t\t\t\t\tm_FillFactor = reader.ReadInt();\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcase 4:\n\t\t\t\t{\n\t\t\t\t\tm_Poisoner = reader.ReadMobile();\n\t\t\t\t\tgoto case 3;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tpublic class BreadLoaf : Food\n\t{\n\t\t[Constructable]\n\t\tpublic BreadLoaf() : this( 1 )\n\t\t{\n\t\t}\n\t\t[Constructable]\n\t\tpublic BreadLoaf( int amount ) : base( amount, 0x103B )\n\t\t{\n\t\t\tthis.Weight = 1.0;\n\t\t\tthis.FillFactor = 3;\n\t\t}\n\t\tpublic BreadLoaf( Serial serial ) : base( serial )\n\t\t{\n\t\t}\n\t\tpublic override void Serialize( GenericWriter writer )\n\t\t{\n\t\t\tbase.Serialize( writer );\n\t\t\twriter.Write( (int) 0 ); // version\n\t\t}\n\t\tpublic override void Deserialize( GenericReader reader )\n\t\t{\n\t\t\tbase.Deserialize( reader );\n\t\t\tint version = reader.ReadInt();\n\t\t}\n\t}\n\tpublic class Bacon : Food\n\t{\n\t\t[Constructable]\n\t\tpublic Bacon() : this( 1 )\n\t\t{\n\t\t}\n\t\t[Constructable]\n\t\tpublic Bacon( int amount ) : base( amount, 0x979 )\n\t\t{\n\t\t\tthis.Weight = 1.0;\n\t\t\tthis.FillFactor = 1;\n\t\t}\n\t\tpublic Bacon( Serial serial ) : base( serial )\n\t\t{\n\t\t}\n\t\tpublic override void Serialize( GenericWriter writer )\n\t\t{\n\t\t\tbase.Serialize( writer );\n\t\t\twriter.Write( (int) 0 ); // version\n\t\t}\n\t\tpublic override void Deserialize( GenericReader reader )\n\t\t{\n\t\t\tbase.Deserialize( reader );\n\t\t\tint version = reader.ReadInt();\n\t\t}\n\t}\n\tpublic class SlabOfBacon : Food\n\t{\n\t\t[Constructable]\n\t\tpublic SlabOfBacon() : this( 1 )\n\t\t{\n\t\t}\n\t\t[Constructable]\n\t\tpublic SlabOfBacon( int amount ) : base( amount, 0x976 )\n\t\t{\n\t\t\tthis.Weight = 1.0;\n\t\t\tthis.FillFactor = 3;\n\t\t}\n\t\tpublic SlabOfBacon( Serial serial ) : base( serial )\n\t\t{\n\t\t}\n\t\tpublic override void Serialize( GenericWriter writer )\n\t\t{\n\t\t\tbase.Serialize( writer );\n\t\t\twriter.Write( (int) 0 ); // version\n\t\t}\n\t\tpublic override void Deserialize( GenericReader reader )\n\t\t{\n\t\t\tbase.Deserialize( reader );\n\t\t\tint version = reader.ReadInt();\n\t\t}\n\t}\n\tpublic class FishSteak : Food\n\t{\n\t\tpublic override double DefaultWeight\n\t\t{\n\t\t\tget { return 0.1; }\n\t\t}\n\t\t[Constructable]\n\t\tpublic FishSteak() : this( 1 )\n\t\t{\n\t\t}\n\t\t[Constructable]\n\t\tpublic FishSteak( int amount ) : base( amount, 0x97B )\n\t\t{\n\t\t\tthis.FillFactor = 3;\n\t\t}\n\t\tpublic FishSteak( Serial serial ) : base( serial )\n\t\t{\n\t\t}\n\t\tpublic override void Serialize( GenericWriter writer )\n\t\t{\n\t\t\tbase.Serialize( writer );\n\t\t\twriter.Write( (int) 0 ); // version\n\t\t}\n\t\tpublic override void Deserialize( GenericReader reader )\n\t\t{\n\t\t\tbase.Deserialize( reader );\n\t\t\tint version = reader.ReadInt();\n\t\t}\n\t}\n\tpublic class CheeseWheel : Food\n\t{\n\t\tpublic override double DefaultWeight\n\t\t{\n\t\t\tget { return 0.1; }\n\t\t}\n\t\t[Constructable]\n\t\tpublic CheeseWheel() : this( 1 )\n\t\t{\n\t\t}\n\t\t[Constructable]\n\t\tpublic CheeseWheel( int amount ) : base( amount, 0x97E )\n\t\t{\n\t\t\tthis.FillFactor = 3;\n\t\t}\n\t\tpublic CheeseWheel( Serial serial ) : base( serial )\n\t\t{\n\t\t}\n\t\tpublic override void Serialize( GenericWriter writer )\n\t\t{\n\t\t\tbase.Serialize( writer );\n\t\t\twriter.Write( (int) 0 ); // version\n\t\t}\n\t\tpublic override void Deserialize( GenericReader reader )\n\t\t{\n\t\t\tbase.Deserialize( reader );\n\t\t\tint version = reader.ReadInt();\n\t\t}\n\t}\n\tpublic class CheeseWedge : Food\n\t{\n\t\tpublic override double DefaultWeight\n\t\t{\n\t\t\tget { return 0.1; }\n\t\t}\n\t\t[Constructable]\n\t\tpublic CheeseWedge() : this( 1 )\n\t\t{\n\t\t}\n\t\t[Constructable]\n\t\tpublic CheeseWedge( int amount ) : base( amount, 0x97D )\n\t\t{\n\t\t\tthis.FillFactor = 3;\n\t\t}\n\t\tpublic CheeseWedge( Serial serial ) : base( serial )\n\t\t{\n\t\t}\n\t\tpublic override void Serialize( GenericWriter writer )\n\t\t{\n\t\t\tbase.Serialize( writer );\n\t\t\twriter.Write( (int) 0 ); // version\n\t\t}\n\t\tpublic override void Deserialize( GenericReader reader )\n\t\t{\n\t\t\tbase.Deserialize( reader );\n\t\t\tint version = reader.ReadInt();\n\t\t}\n\t}\n\tpublic class CheeseSlice : Food\n\t{\n\t\tpublic override double DefaultWeight\n\t\t{\n\t\t\tget { return 0.1; }\n\t\t}\n\t\t[Constructable]\n\t\tpublic CheeseSlice() : this( 1 )\n\t\t{\n\t\t}\n\t\t[Constructable]\n\t\tpublic CheeseSlice( int amount ) : base( amount, 0x97C )\n\t\t{\n\t\t\tthis.FillFactor = 1;\n\t\t}\n\t\tpublic CheeseSlice( Serial serial ) : base( serial )\n\t\t{\n\t\t}\n\t\tpublic override void Serialize( GenericWriter writer )\n\t\t{\n\t\t\tbase.Serialize( writer );\n\t\t\twriter.Write( (int) 0 ); // version\n\t\t}\n\t\tpublic override void Deserialize( GenericReader reader )\n\t\t{\n\t\t\tbase.Deserialize( reader );\n\t\t\tint version = reader.ReadInt();\n\t\t}\n\t}\n\tpublic class FrenchBread : Food\n\t{\n\t\t[Constructable]\n\t\tpublic FrenchBread() : this( 1 )\n\t\t{\n\t\t}\n\t\t[Constructable]\n\t\tpublic FrenchBread( int amount ) : base( amount, 0x98C )\n\t\t{\n\t\t\tthis.Weight = 2.0;\n\t\t\tthis.FillFactor = 3;\n\t\t}\n\t\tpublic FrenchBread( Serial serial ) : base( serial )\n\t\t{\n\t\t}\n\t\tpublic override void Serialize( GenericWriter writer )\n\t\t{\n\t\t\tbase.Serialize( writer );\n\t\t\twriter.Write( (int) 0 ); // version\n\t\t}\n\t\tpublic override void Deserialize( GenericReader reader )\n\t\t{\n\t\t\tbase.Deserialize( reader );\n\t\t\tint version = reader.ReadInt();\n\t\t}\n\t}\n\tpublic class FriedEggs : Food\n\t{\n\t\t[Constructable]\n\t\tpublic FriedEggs() : this( 1 )\n\t\t{\n\t\t}\n\t\t[Constructable]\n\t\tpublic FriedEggs( int amount ) : base( amount, 0x9B6 )\n\t\t{\n\t\t\tthis.Weight = 1.0;\n\t\t\tthis.FillFactor = 4;\n\t\t}\n\t\tpublic FriedEggs( Serial serial ) : base( serial )\n\t\t{\n\t\t}\n\t\tpublic override void Serialize( GenericWriter writer )\n\t\t{\n\t\t\tbase.Serialize( writer );\n\t\t\twriter.Write( (int) 0 ); // version\n\t\t}\n\t\tpublic override void Deserialize( GenericReader reader )\n\t\t{\n\t\t\tbase.Deserialize( reader );\n\t\t\tint version = reader.ReadInt();\n\t\t}\n\t}\n\tpublic class CookedBird : Food\n\t{\n\t\t[Constructable]\n\t\tpublic CookedBird() : this( 1 )\n\t\t{\n\t\t}\n\t\t[Constructable]\n\t\tpublic CookedBird( int amount ) : base( amount, 0x9B7 )\n\t\t{\n\t\t\tthis.Weight = 1.0;\n\t\t\tthis.FillFactor = 5;\n\t\t}\n\t\tpublic CookedBird( Serial serial ) : base( serial )\n\t\t{\n\t\t}\n\t\tpublic override void Serialize( GenericWriter writer )\n\t\t{\n\t\t\tbase.Serialize( writer );\n\t\t\twriter.Write( (int) 0 ); // version\n\t\t}\n\t\tpublic override void Deserialize( GenericReader reader )\n\t\t{\n\t\t\tbase.Deserialize( reader );\n\t\t\tint version = reader.ReadInt();\n\t\t}\n\t}\n\tpublic class RoastPig : Food\n\t{\n\t\t[Constructable]\n\t\tpublic RoastPig() : this( 1 )\n\t\t{\n\t\t}\n\t\t[Constructable]\n\t\tpublic RoastPig( int amount ) : base( amount, 0x9BB )\n\t\t{\n\t\t\tthis.Weight = 45.0;\n\t\t\tthis.FillFactor = 20;\n\t\t}\n\t\tpublic RoastPig( Serial serial ) : base( serial )\n\t\t{\n\t\t}\n\t\tpublic override void Serialize( GenericWriter writer )\n\t\t{\n\t\t\tbase.Serialize( writer );\n\t\t\twriter.Write( (int) 0 ); // version\n\t\t}\n\t\tpublic override void Deserialize( GenericReader reader )\n\t\t{\n\t\t\tbase.Deserialize( reader );\n\t\t\tint version = reader.ReadInt();\n\t\t}\n\t}\n\tpublic class Sausage : Food\n\t{\n\t\t[Constructable]\n\t\tpublic Sausage() : this( 1 )\n\t\t{\n\t\t}\n\t\t[Constructable]\n\t\tpublic Sausage( int amount ) : base( amount, 0x9C0 )\n\t\t{\n\t\t\tthis.Weight = 1.0;\n\t\t\tthis.FillFactor = 4;\n\t\t}\n\t\tpublic Sausage( Serial serial ) : base( serial )\n\t\t{\n\t\t}\n\t\tpublic override void Serialize( GenericWriter writer )\n\t\t{\n\t\t\tbase.Serialize( writer );\n\t\t\twriter.Write( (int) 0 ); // version\n\t\t}\n\t\tpublic override void Deserialize( GenericReader reader )\n\t\t{\n\t\t\tbase.Deserialize( reader );\n\t\t\tint version = reader.ReadInt();\n\t\t}\n\t}\n\tpublic class Ham : Food\n\t{\n\t\t[Constructable]\n\t\tpublic Ham() : this( 1 )\n\t\t{\n\t\t}\n\t\t[Constructable]\n\t\tpublic Ham( int amount ) : base( amount, 0x9C9 )\n\t\t{\n\t\t\tthis.Weight = 1.0;\n\t\t\tthis.FillFactor = 5;\n\t\t}\n\t\tpublic Ham( Serial serial ) : base( serial )\n\t\t{\n\t\t}\n\t\tpublic override void Serialize( GenericWriter writer )\n\t\t{\n\t\t\tbase.Serialize( writer );\n\t\t\twriter.Write( (int) 0 ); // version\n\t\t}\n\t\tpublic override void Deserialize( GenericReader reader )\n\t\t{\n\t\t\tbase.Deserialize( reader );\n\t\t\tint version = reader.ReadInt();\n\t\t}\n\t}\n\tpublic class Cake : Food\n\t{\n\t\t[Constructable]\n\t\tpublic Cake() : base( 0x9E9 )\n\t\t{\n\t\t\tStackable = false;\n\t\t\tthis.Weight = 1.0;\n\t\t\tthis.FillFactor = 10;\n\t\t}\n\t\tpublic Cake( Serial serial ) : base( serial )\n\t\t{\n\t\t}\n\t\tpublic override void Serialize( GenericWriter writer )\n\t\t{\n\t\t\tbase.Serialize( writer );\n\t\t\twriter.Write( (int) 0 ); // version\n\t\t}\n\t\tpublic override void Deserialize( GenericReader reader )\n\t\t{\n\t\t\tbase.Deserialize( reader );\n\t\t\tint version = reader.ReadInt();\n\t\t}\n\t}\n\tpublic class Ribs : Food\n\t{\n\t\t[Constructable]\n\t\tpublic Ribs() : this( 1 )\n\t\t{\n\t\t}\n\t\t[Constructable]\n\t\tpublic Ribs( int amount ) : base( amount, 0x9F2 )\n\t\t{\n\t\t\tthis.Weight = 1.0;\n\t\t\tthis.FillFactor = 5;\n\t\t}\n\t\tpublic Ribs( Serial serial ) : base( serial )\n\t\t{\n\t\t}\n\t\tpublic override void Serialize( GenericWriter writer )\n\t\t{\n\t\t\tbase.Serialize( writer );\n\t\t\twriter.Write( (int) 0 ); // version\n\t\t}\n\t\tpublic override void Deserialize( GenericReader reader )\n\t\t{\n\t\t\tbase.Deserialize( reader );\n\t\t\tint version = reader.ReadInt();\n\t\t}\n\t}\n\tpublic class Cookies : Food\n\t{\n\t\t[Constructable]\n\t\tpublic Cookies() : base( 0x160b )\n\t\t{\n\t\t\tStackable = Core.ML;\n\t\t\tthis.Weight = 1.0;\n\t\t\tthis.FillFactor = 4;\n\t\t}\n\t\tpublic Cookies( Serial serial ) : base( serial )\n\t\t{\n\t\t}\n\t\tpublic override void Serialize( GenericWriter writer )\n\t\t{\n\t\t\tbase.Serialize( writer );\n\t\t\twriter.Write( (int) 0 ); // version\n\t\t}\n\t\tpublic override void Deserialize( GenericReader reader )\n\t\t{\n\t\t\tbase.Deserialize( reader );\n\t\t\tint version = reader.ReadInt();\n\t\t}\n\t}\n\tpublic class Muffins : Food\n\t{\n\t\t[Constructable]\n\t\tpublic Muffins() : base( 0x9eb )\n\t\t{\n\t\t\tStackable = false;\n\t\t\tthis.Weight = 1.0;\n\t\t\tthis.FillFactor = 4;\n\t\t}\n\t\tpublic Muffins( Serial serial ) : base( serial )\n\t\t{\n\t\t}\n\t\tpublic override void Serialize( GenericWriter writer )\n\t\t{\n\t\t\tbase.Serialize( writer );\n\t\t\twriter.Write( (int) 0 ); // version\n\t\t}\n\t\tpublic override void Deserialize( GenericReader reader )\n\t\t{\n\t\t\tbase.Deserialize( reader );\n\t\t\tint version = reader.ReadInt();\n\t\t}\n\t}\n", "outputs": ["\t[TypeAlias( \"Server.Items.Pizza\" )]"], "input_length": 2535, "output_length": 8, "length": 2543, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "06b7b268ce3c3db57ec4f9201426b9dd3f1a05e5dd1d0db3a59be1fad8b4046b"}
{"input": "", "context": "#region Copyright & License Information\n/*\n * Copyright 2007-2014 The OpenRA Developers (see AUTHORS)\n * This file is part of OpenRA, which is free software. It is made\n * available to you under the terms of the GNU General Public License\n * as published by the Free Software Foundation. For more information,\n * see COPYING.\n */\n#endregion\nusing System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing OpenRA.Graphics;\nusing OpenRA.Orders;\nusing OpenRA.Traits;\nnamespace OpenRA.Widgets\n{\n\tpublic enum WorldTooltipType { None, Unexplored, Actor, FrozenActor }\n\tpublic class ViewportControllerWidget : Widget\n\t{\n\t\tpublic readonly string TooltipTemplate = \"WORLD_TOOLTIP\";\n\t\tpublic readonly string TooltipContainer;\n\t\tLazy<TooltipContainerWidget> tooltipContainer;\n\t\tpublic WorldTooltipType TooltipType { get; private set; }\n\t\tpublic IToolTip ActorTooltip { get; private set; }\n\t\tpublic FrozenActor FrozenActorTooltip { get; private set; }\n\t\tpublic int EdgeScrollThreshold = 15;\n\t\tpublic int EdgeCornerScrollThreshold = 35;\n\t\tstatic readonly Dictionary<ScrollDirection, string> ScrollCursors = new Dictionary<ScrollDirection, string>\n\t\t{\n\t\t\t{ ScrollDirection.Up | ScrollDirection.Left, \"scroll-tl\" },\n\t\t\t{ ScrollDirection.Up | ScrollDirection.Right, \"scroll-tr\" },\n\t\t\t{ ScrollDirection.Down | ScrollDirection.Left, \"scroll-bl\" },\n\t\t\t{ ScrollDirection.Down | ScrollDirection.Right, \"scroll-br\" },\n\t\t\t{ ScrollDirection.Up, \"scroll-t\" },\n\t\t\t{ ScrollDirection.Down, \"scroll-b\" },\n\t\t\t{ ScrollDirection.Left, \"scroll-l\" },\n\t\t\t{ ScrollDirection.Right, \"scroll-r\" },\n\t\t};\n\t\tstatic readonly Dictionary<ScrollDirection, float2> ScrollOffsets = new Dictionary<ScrollDirection, float2>\n\t\t{\n\t\t\t{ ScrollDirection.Up, new float2(0, -1) },\n\t\t\t{ ScrollDirection.Down, new float2(0, 1) },\n\t\t\t{ ScrollDirection.Left, new float2(-1, 0) },\n\t\t\t{ ScrollDirection.Right, new float2(1, 0) },\n\t\t};\n\t\tScrollDirection keyboardDirections;\n\t\tScrollDirection edgeDirections;\n\t\tWorld world;\n\t\tWorldRenderer worldRenderer;\n\t\t[ObjectCreator.UseCtor]\n\t\tpublic ViewportControllerWidget(World world, WorldRenderer worldRenderer)\n\t\t{\n\t\t\tthis.world = world;\n\t\t\tthis.worldRenderer = worldRenderer;\n\t\t\ttooltipContainer = Exts.Lazy(() =>\n\t\t\t\tUi.Root.Get<TooltipContainerWidget>(TooltipContainer));\n\t\t}\n\t\tpublic override void MouseEntered()\n\t\t{\n\t\t\tif (TooltipContainer == null)\n\t\t\t\treturn;\n\t\t\ttooltipContainer.Value.SetTooltip(TooltipTemplate,\n\t\t\t\tnew WidgetArgs() {{ \"world\", world }, { \"viewport\", this }});\n\t\t}\n\t\tpublic override void MouseExited()\n\t\t{\n\t\t\tif (TooltipContainer == null)\n\t\t\t\treturn;\n\t\t\ttooltipContainer.Value.RemoveTooltip();\n\t\t}\n\t\tpublic override void Draw()\n\t\t{\n\t\t\tUpdateMouseover();\n\t\t\tbase.Draw();\n\t\t}\n\t\tpublic void UpdateMouseover()\n\t\t{\n\t\t\tTooltipType = WorldTooltipType.None;\n\t\t\tvar cell = worldRenderer.Viewport.ViewToWorld(Viewport.LastMousePos);\n\t\t\tif (!world.Map.Contains(cell))\n\t\t\t\treturn;\n\t\t\tif (world.ShroudObscures(cell))\n\t\t\t{\n\t\t\t\tTooltipType = WorldTooltipType.Unexplored;\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tvar underCursor = world.ScreenMap.ActorsAt(worldRenderer.Viewport.ViewToWorldPx(Viewport.LastMousePos))\n\t\t\t\t.Where(a => !world.FogObscures(a) && a.HasTrait<IToolTip>())\n\t\t\t\t.WithHighestSelectionPriority();\n\t\t\tif (underCursor != null)\n\t\t\t{\n\t\t\t\tActorTooltip = underCursor.TraitsImplementing<IToolTip>().First();\n\t\t\t\tTooltipType = WorldTooltipType.Actor;\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tvar frozen = world.ScreenMap.FrozenActorsAt(world.RenderPlayer, worldRenderer.Viewport.ViewToWorldPx(Viewport.LastMousePos))\n\t\t\t\t.Where(a => a.TooltipName != null && a.IsValid)\n\t\t\t\t.WithHighestSelectionPriority();\n\t\t\tif (frozen != null)\n\t\t\t{\n\t\t\t\tFrozenActorTooltip = frozen;\n\t\t\t\tTooltipType = WorldTooltipType.FrozenActor;\n\t\t\t}\n\t\t}\n\t\tpublic override string GetCursor(int2 pos)\n\t\t{\n\t\t\tif (!Game.Settings.Game.ViewportEdgeScroll || Ui.MouseOverWidget != this)\n\t\t\t\treturn null;\n\t\t\tvar blockedDirections = worldRenderer.Viewport.GetBlockedDirections();\n\t\t\tforeach (var dir in ScrollCursors)\n\t\t\t\tif (edgeDirections.Includes(dir.Key))\n\t\t\t\t\treturn dir.Value + (blockedDirections.Includes(dir.Key) ? \"-blocked\" : \"\");\n\t\t\treturn null;\n\t\t}\n\t\tpublic override bool HandleMouseInput(MouseInput mi)\n\t\t{\n\t\t\tvar scrolltype = Game.Settings.Game.MouseScroll;\n\t\t\tif (scrolltype == MouseScrollType.Disabled)\n\t\t\t\treturn false;\n\t\t\tif (mi.Event == MouseInputEvent.Move &&\n\t\t\t\t(mi.Button == MouseButton.Middle || mi.Button == (MouseButton.Left | MouseButton.Right)))\n\t\t\t{\n\t\t\t\tvar d = scrolltype == MouseScrollType.Inverted ? -1 : 1;\n\t\t\t\tworldRenderer.Viewport.Scroll((Viewport.LastMousePos - mi.Location) * d, false);\n\t\t\t\treturn true;\n\t\t\t}\n\t\t\treturn false;\n\t\t}\n\t\tpublic override bool YieldKeyboardFocus()\n\t\t{\n\t\t\tkeyboardDirections = ScrollDirection.None;\n\t\t\treturn base.YieldKeyboardFocus();\n\t\t}\n\t\tpublic override bool HandleKeyPress(KeyInput e)\n\t\t{\n\t\t\tswitch (e.Key)\n\t\t\t{\n\t\t\t\tcase Keycode.UP: keyboardDirections = keyboardDirections.Set(ScrollDirection.Up, e.Event == KeyInputEvent.Down); return true;\n\t\t\t\tcase Keycode.DOWN: keyboardDirections = keyboardDirections.Set(ScrollDirection.Down, e.Event == KeyInputEvent.Down); return true;\n\t\t\t\tcase Keycode.LEFT: keyboardDirections = keyboardDirections.Set(ScrollDirection.Left, e.Event == KeyInputEvent.Down); return true;\n\t\t\t\tcase Keycode.RIGHT: keyboardDirections = keyboardDirections.Set(ScrollDirection.Right, e.Event == KeyInputEvent.Down); return true;\n\t\t\t}\n\t\t\treturn false;\n\t\t}\n\t\tpublic override void Tick()\n\t\t{\n\t\t\tedgeDirections = ScrollDirection.None;\n\t\t\tif (Game.Settings.Game.ViewportEdgeScroll && Game.HasInputFocus)\n\t\t\t\tedgeDirections = CheckForDirections();\n\t\t\tif (keyboardDirections != ScrollDirection.None || edgeDirections != ScrollDirection.None)\n\t\t\t{\n\t\t\t\tvar scroll = float2.Zero;\n\t\t\t\tforeach (var kv in ScrollOffsets)\n\t\t\t\t\tif (keyboardDirections.Includes(kv.Key) || edgeDirections.Includes(kv.Key))\n\t\t\t\t\t\tscroll += kv.Value;\n\t\t\t\tvar length = Math.Max(1, scroll.Length);\n\t\t\t\tscroll *= (1f / length) * Game.Settings.Game.ViewportEdgeScrollStep;\n\t\t\t\tworldRenderer.Viewport.Scroll(scroll, false);\n\t\t\t}\n\t\t}\n\t\tScrollDirection CheckForDirections()\n\t\t{\n\t\t\tvar directions = ScrollDirection.None;\n\t\t\tif (Viewport.LastMousePos.X < EdgeScrollThreshold)\n\t\t\t\tdirections |= ScrollDirection.Left;\n\t\t\tif (Viewport.LastMousePos.Y < EdgeScrollThreshold)\n\t\t\t\tdirections |= ScrollDirection.Up;\n\t\t\tif (Viewport.LastMousePos.X >= Game.Renderer.Resolution.Width - EdgeScrollThreshold)\n", "outputs": ["\t\t\t\tdirections |= ScrollDirection.Right;"], "input_length": 988, "output_length": 4, "length": 992, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "656ee8478b6c3f6e0e12de78b2cec4d0ed64cf6456e8f7ff1c2f47d9cebeacd3"}
{"input": "", "context": "# -*- coding: utf-8 -*-\n# Copyright 2011,2013 Christoph Reiter\n#\n# This program is free software; you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation; either version 2 of the License, or\n# (at your option) any later version.\nimport json\nimport collections\nimport threading\nimport gzip\nfrom xml.dom.minidom import parseString\nfrom gi.repository import GLib\nfrom quodlibet.util import print_w\nfrom quodlibet.compat import iteritems, urlencode, queue, cBytesIO\nfrom quodlibet.util.urllib import urlopen, Request\nfrom .util import get_api_key, GateKeeper\nAPP_KEY = \"C6IduH7D\"\ngatekeeper = GateKeeper(requests_per_sec=3)\nclass AcoustidSubmissionThread(threading.Thread):\n    URL = \"https://api.acoustid.org/v2/submit\"\n    SONGS_PER_SUBMISSION = 50\n    TIMEOUT = 10.0\n    def __init__(self, results, progress_cb, done_cb):\n        super(AcoustidSubmissionThread, self).__init__()\n        self.__callback = done_cb\n        self.__results = results\n        self.__stopped = False\n        self.__progress_cb = progress_cb\n        self.__done = 0\n        self.start()\n    def __idle(self, func, *args, **kwargs):\n        def delayed():\n            if self.__stopped:\n                return\n            func(*args, **kwargs)\n        GLib.idle_add(delayed)\n    def __send(self, urldata):\n        if self.__stopped:\n            return\n        gatekeeper.wait()\n        self.__done += len(urldata)\n        basedata = urlencode({\n            \"format\": \"xml\",\n            \"client\": APP_KEY,\n            \"user\": get_api_key(),\n        })\n        urldata = \"&\".join([basedata] + list(map(urlencode, urldata)))\n        obj = cBytesIO()\n        gzip.GzipFile(fileobj=obj, mode=\"wb\").write(urldata.encode())\n        urldata = obj.getvalue()\n        headers = {\n            \"Content-Encoding\": \"gzip\",\n            \"Content-type\": \"application/x-www-form-urlencoded\"\n        }\n        req = Request(self.URL, urldata, headers)\n        error = None\n        try:\n            response = urlopen(req, timeout=self.TIMEOUT)\n        except EnvironmentError as e:\n            error = \"urllib error: \" + str(e)\n        else:\n            xml = response.read()\n            try:\n                dom = parseString(xml)\n            except:\n                error = \"xml error\"\n            else:\n                status = dom.getElementsByTagName(\"status\")\n                if not status or not status[0].childNodes or not \\\n                    status[0].childNodes[0].nodeValue == \"ok\":\n                    error = \"response status error\"\n        if error:\n            print_w(\"[fingerprint] Submission failed: \" + error)\n        # emit progress\n        self.__idle(self.__progress_cb,\n                float(self.__done) / len(self.__results))\n    def run(self):\n        urldata = []\n        for i, result in enumerate(self.__results):\n            song = result.song\n            track = {\n                \"duration\": int(round(result.length)),\n                \"fingerprint\": result.chromaprint,\n                \"bitrate\": song(\"~#bitrate\"),\n                \"fileformat\": song(\"~format\"),\n                \"mbid\": song(\"musicbrainz_trackid\"),\n                \"track\": song(\"title\"),\n                \"artist\": song.list(\"artist\"),\n                \"album\": song(\"album\"),\n                \"albumartist\": song(\"albumartist\"),\n                \"year\": song(\"~year\"),\n                \"trackno\": song(\"~#track\"),\n                \"discno\": song(\"~#disc\"),\n            }\n            tuples = []\n            for key, value in iteritems(track):\n                # this also dismisses 0.. which should be ok here.\n                if not value:\n                    continue\n                # the postfixes don't have to start at a specific point,\n                # they just need to be different and numbers\n                key += \".%d\" % i\n                if isinstance(value, list):\n                    for val in value:\n                        tuples.append((key, val))\n                else:\n                    tuples.append((key, value))\n            urldata.append(tuples)\n            if len(urldata) >= self.SONGS_PER_SUBMISSION:\n                self.__send(urldata)\n                urldata = []\n            if self.__stopped:\n                return\n        if urldata:\n            self.__send(urldata)\n        self.__idle(self.__callback)\n    def stop(self):\n        self.__stopped = True\nclass LookupResult(object):\n    def __init__(self, fresult, releases, error):\n        self.fresult = fresult\n        self.releases = releases\n        self.error = error\n    @property\n    def song(self):\n        return self.fresult.song\nRelease = collections.namedtuple(\n    \"Release\", [\"id\", \"score\", \"sources\", \"all_sources\",\n                \"medium_count\", \"tags\"])\ndef parse_acoustid_response(json_data):\n    \"\"\"Get all possible tag combinations including the release ID and score.\n    The idea is that for multiple songs the variant for each wins where\n    the release ID is present for more songs and if equal\n    (one song for example) the score wins.\n    Needs meta=releases+recordings+tracks responses.\n    \"\"\"\n    VARIOUS_ARTISTS_ARTISTID = \"89ad4ac3-39f7-470e-963a-56509c546377\"\n    releases = []\n    for res in json_data.get(\"results\", []):\n        score = res[\"score\"]\n        all_sources = 0\n        recordings = []\n        for rec in res.get(\"recordings\", []):\n            sources = rec[\"sources\"]\n            all_sources += sources\n            rec_id = rec[\"id\"]\n            artists = [a[\"name\"] for a in rec.get(\"artists\", [])]\n            artist_ids = [a[\"id\"] for a in rec.get(\"artists\", [])]\n            for release in rec.get(\"releases\", []):\n                # release\n                id_ = release[\"id\"]\n                date = release.get(\"date\", {})\n                album = release.get(\"title\", \"\")\n                album_id = release[\"id\"]\n                parts = [date.get(k) for k in [\"year\", \"month\", \"day\"]]\n                date = \"-\".join([u\"%02d\" % p for p in parts if p is not None])\n                albumartists = []\n                albumartist_ids = []\n                for artist in release.get(\"artists\", []):\n                    if artist[\"id\"] != VARIOUS_ARTISTS_ARTISTID:\n                        albumartists.append(artist[\"name\"])\n                        albumartist_ids.append(artist[\"id\"])\n                discs = release.get(\"medium_count\", 1)\n                # meadium\n                medium = release[\"mediums\"][0]\n                disc = medium.get(\"position\", 0)\n                tracks = medium.get(\"track_count\", 1)\n                # track\n                track_info = medium[\"tracks\"][0]\n                track_id = track_info[\"id\"]\n                track = track_info.get(\"position\", 0)\n                title = track_info.get(\"title\", \"\")\n                if disc and discs > 1:\n                    discnumber = u\"%d/%d\" % (disc, discs)\n                else:\n                    discnumber = u\"\"\n                if track and tracks > 1:\n                    tracknumber = u\"%d/%d\" % (track, tracks)\n                else:\n                    tracknumber = u\"\"\n                tags = {\n                    \"title\": title,\n                    \"artist\": \"\\n\".join(artists),\n                    \"albumartist\": \"\\n\".join(albumartists),\n                    \"date\": date,\n                    \"discnumber\": discnumber,\n                    \"tracknumber\": tracknumber,\n                    \"album\": album,\n                }\n                mb = {\n                    \"musicbrainz_releasetrackid\": track_id,\n                    \"musicbrainz_trackid\": rec_id,\n                    \"musicbrainz_albumid\": album_id,\n                    \"musicbrainz_albumartistid\": \"\\n\".join(albumartist_ids),\n                    \"musicbrainz_artistid\": \"\\n\".join(artist_ids),\n                }\n                # not that useful, ignore for now\n                del mb[\"musicbrainz_releasetrackid\"]\n                tags.update(mb)\n                recordings.append([id_, score, sources, 0, discs, tags])\n        for rec in recordings:\n            rec[3] = all_sources\n            releases.append(Release(*rec))\n    return releases\nclass AcoustidLookupThread(threading.Thread):\n    URL = \"https://api.acoustid.org/v2/lookup\"\n    MAX_SONGS_PER_SUBMISSION = 5\n    TIMEOUT = 10.0\n    def __init__(self, progress_cb):\n        super(AcoustidLookupThread, self).__init__()\n        self.__progress_cb = progress_cb\n        self.__queue = queue.Queue()\n        self.__stopped = False\n        self.start()\n    def put(self, result):\n        \"\"\"Queue a FingerPrintResult\"\"\"\n        self.__queue.put(result)\n    def __idle(self, func, *args, **kwargs):\n        def delayed():\n            if self.__stopped:\n                return\n            func(*args, **kwargs)\n        GLib.idle_add(delayed)\n    def __process(self, results):\n        req_data = []\n        req_data.append(urlencode({\n            \"format\": \"json\",\n            \"client\": APP_KEY,\n            \"batch\": \"1\",\n        }))\n        for i, result in enumerate(results):\n            postfix = \".%d\" % i\n            req_data.append(urlencode({\n                \"duration\" + postfix: str(int(round(result.length))),\n                \"fingerprint\" + postfix: result.chromaprint,\n            }))\n        req_data.append(\"meta=releases+recordings+tracks+sources\")\n        urldata = \"&\".join(req_data)\n        obj = cBytesIO()\n        gzip.GzipFile(fileobj=obj, mode=\"wb\").write(urldata.encode())\n        urldata = obj.getvalue()\n        headers = {\n            \"Content-Encoding\": \"gzip\",\n            \"Content-type\": \"application/x-www-form-urlencoded\"\n        }\n        req = Request(self.URL, urldata, headers)\n        releases = {}\n        error = \"\"\n        try:\n            response = urlopen(req, timeout=self.TIMEOUT)\n        except EnvironmentError as e:\n            error = \"urllib error: \" + str(e)\n        else:\n            try:\n                data = response.read()\n                data = json.loads(data.decode())\n            except ValueError as e:\n                error = str(e)\n            else:\n                if data[\"status\"] == \"ok\":\n                    for result_data in data.get(\"fingerprints\", []):\n                        if \"index\" not in result_data:\n                            continue\n                        index = result_data[\"index\"]\n                        releases[index] = parse_acoustid_response(result_data)\n", "outputs": ["        for i, result in enumerate(results):"], "input_length": 1857, "output_length": 10, "length": 1867, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "af07340e710800b6936ef6edff4be31162b3cee43df42272190716a6270b1c8c"}
{"input": "", "context": "# Copyright (C) 2003-2007  Robey Pointer <robeypointer@gmail.com>\n# Copyright (C) 2013-2014 science + computing ag\n# Author: Sebastian Deiss <sebastian.deiss@t-online.de>\n#\n#\n# This file is part of paramiko.\n#\n# Paramiko is free software; you can redistribute it and/or modify it under the\n# terms of the GNU Lesser General Public License as published by the Free\n# Software Foundation; either version 2.1 of the License, or (at your option)\n# any later version.\n#\n# Paramiko is distributed in the hope that it will be useful, but WITHOUT ANY\n# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR\n# A PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more\n# details.\n#\n# You should have received a copy of the GNU Lesser General Public License\n# along with Paramiko; if not, write to the Free Software Foundation, Inc.,\n# 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA.\n\"\"\"\nThis module provides GSS-API / SSPI Key Exchange as defined in :rfc:`4462`.\n.. note:: Credential delegation is not supported in server mode.\n.. note::\n    `RFC 4462 Section 2.2\n    <https://tools.ietf.org/html/rfc4462.html#section-2.2>`_ says we are not\n    required to implement GSS-API error messages. Thus, in many methods within\n    this module, if an error occurs an exception will be thrown and the\n    connection will be terminated.\n.. seealso:: :doc:`/api/ssh_gss`\n.. versionadded:: 1.15\n\"\"\"\nimport os\nfrom hashlib import sha1\nfrom paramiko.common import DEBUG, max_byte, zero_byte\nfrom paramiko import util\nfrom paramiko.message import Message\nfrom paramiko.py3compat import byte_chr, byte_mask, byte_ord\nfrom paramiko.ssh_exception import SSHException\nMSG_KEXGSS_INIT, MSG_KEXGSS_CONTINUE, MSG_KEXGSS_COMPLETE, MSG_KEXGSS_HOSTKEY,\\\n    MSG_KEXGSS_ERROR = range(30, 35)\nMSG_KEXGSS_GROUPREQ, MSG_KEXGSS_GROUP = range(40, 42)\nc_MSG_KEXGSS_INIT, c_MSG_KEXGSS_CONTINUE, c_MSG_KEXGSS_COMPLETE,\\\n    c_MSG_KEXGSS_HOSTKEY, c_MSG_KEXGSS_ERROR = [\n        byte_chr(c) for c in range(30, 35)\n    ]\nc_MSG_KEXGSS_GROUPREQ, c_MSG_KEXGSS_GROUP = [\n    byte_chr(c) for c in range(40, 42)\n]\nclass KexGSSGroup1(object):\n    \"\"\"\n    GSS-API / SSPI Authenticated Diffie-Hellman Key Exchange as defined in `RFC\n    4462 Section 2 <https://tools.ietf.org/html/rfc4462.html#section-2>`_\n    \"\"\"\n    # draft-ietf-secsh-transport-09.txt, page 17\n    P = 0xFFFFFFFFFFFFFFFFC90FDAA22168C234C4C6628B80DC1CD129024E088A67CC74020BBEA63B139B22514A08798E3404DDEF9519B3CD3A431B302B0A6DF25F14374FE1356D6D51C245E485B576625E7EC6F44C42E9A637ED6B0BFF5CB6F406B7EDEE386BFB5A899FA5AE9F24117C4B1FE649286651ECE65381FFFFFFFFFFFFFFFF  # noqa\n    G = 2\n    b7fffffffffffffff = byte_chr(0x7f) + max_byte * 7  # noqa\n    b0000000000000000 = zero_byte * 8  # noqa\n    NAME = \"gss-group1-sha1-toWM5Slw5Ew8Mqkay+al2g==\"\n    def __init__(self, transport):\n        self.transport = transport\n        self.kexgss = self.transport.kexgss_ctxt\n        self.gss_host = None\n        self.x = 0\n        self.e = 0\n        self.f = 0\n    def start_kex(self):\n        \"\"\"\n        Start the GSS-API / SSPI Authenticated Diffie-Hellman Key Exchange.\n        \"\"\"\n        self._generate_x()\n        if self.transport.server_mode:\n            # compute f = g^x mod p, but don't send it yet\n            self.f = pow(self.G, self.x, self.P)\n            self.transport._expect_packet(MSG_KEXGSS_INIT)\n            return\n        # compute e = g^x mod p (where g=2), and send it\n        self.e = pow(self.G, self.x, self.P)\n        # Initialize GSS-API Key Exchange\n        self.gss_host = self.transport.gss_host\n        m = Message()\n        m.add_byte(c_MSG_KEXGSS_INIT)\n        m.add_string(self.kexgss.ssh_init_sec_context(target=self.gss_host))\n        m.add_mpint(self.e)\n        self.transport._send_message(m)\n        self.transport._expect_packet(MSG_KEXGSS_HOSTKEY,\n                                      MSG_KEXGSS_CONTINUE,\n                                      MSG_KEXGSS_COMPLETE,\n                                      MSG_KEXGSS_ERROR)\n    def parse_next(self, ptype, m):\n        \"\"\"\n        Parse the next packet.\n        :param ptype: The (string) type of the incoming packet\n        :param `.Message` m: The paket content\n        \"\"\"\n        if self.transport.server_mode and (ptype == MSG_KEXGSS_INIT):\n            return self._parse_kexgss_init(m)\n        elif not self.transport.server_mode and (ptype == MSG_KEXGSS_HOSTKEY):\n            return self._parse_kexgss_hostkey(m)\n        elif self.transport.server_mode and (ptype == MSG_KEXGSS_CONTINUE):\n            return self._parse_kexgss_continue(m)\n        elif not self.transport.server_mode and (ptype == MSG_KEXGSS_COMPLETE):\n            return self._parse_kexgss_complete(m)\n        elif ptype == MSG_KEXGSS_ERROR:\n            return self._parse_kexgss_error(m)\n        raise SSHException('GSS KexGroup1 asked to handle packet type %d'\n                           % ptype)\n    # ##  internals...\n    def _generate_x(self):\n        \"\"\"\n        generate an \"x\" (1 < x < q), where q is (p-1)/2.\n        p is a 128-byte (1024-bit) number, where the first 64 bits are 1.\n        therefore q can be approximated as a 2^1023.  we drop the subset of\n        potential x where the first 63 bits are 1, because some of those will\n        be larger than q (but this is a tiny tiny subset of potential x).\n        \"\"\"\n        while 1:\n            x_bytes = os.urandom(128)\n            x_bytes = byte_mask(x_bytes[0], 0x7f) + x_bytes[1:]\n            first = x_bytes[:8]\n            if first not in (self.b7fffffffffffffff, self.b0000000000000000):\n                break\n        self.x = util.inflate_long(x_bytes)\n    def _parse_kexgss_hostkey(self, m):\n        \"\"\"\n        Parse the SSH2_MSG_KEXGSS_HOSTKEY message (client mode).\n        :param `.Message` m: The content of the SSH2_MSG_KEXGSS_HOSTKEY message\n        \"\"\"\n        # client mode\n        host_key = m.get_string()\n        self.transport.host_key = host_key\n        sig = m.get_string()\n        self.transport._verify_key(host_key, sig)\n        self.transport._expect_packet(MSG_KEXGSS_CONTINUE,\n                                      MSG_KEXGSS_COMPLETE)\n    def _parse_kexgss_continue(self, m):\n        \"\"\"\n        Parse the SSH2_MSG_KEXGSS_CONTINUE message.\n        :param `.Message` m: The content of the SSH2_MSG_KEXGSS_CONTINUE\n            message\n        \"\"\"\n        if not self.transport.server_mode:\n            srv_token = m.get_string()\n            m = Message()\n            m.add_byte(c_MSG_KEXGSS_CONTINUE)\n            m.add_string(self.kexgss.ssh_init_sec_context(\n                target=self.gss_host, recv_token=srv_token))\n            self.transport.send_message(m)\n            self.transport._expect_packet(\n                MSG_KEXGSS_CONTINUE,\n                MSG_KEXGSS_COMPLETE,\n                MSG_KEXGSS_ERROR\n            )\n        else:\n            pass\n    def _parse_kexgss_complete(self, m):\n        \"\"\"\n        Parse the SSH2_MSG_KEXGSS_COMPLETE message (client mode).\n        :param `.Message` m: The content of the\n            SSH2_MSG_KEXGSS_COMPLETE message\n        \"\"\"\n        # client mode\n        if self.transport.host_key is None:\n            self.transport.host_key = NullHostKey()\n        self.f = m.get_mpint()\n        if (self.f < 1) or (self.f > self.P - 1):\n            raise SSHException('Server kex \"f\" is out of range')\n        mic_token = m.get_string()\n        # This must be TRUE, if there is a GSS-API token in this message.\n        bool = m.get_boolean()\n        srv_token = None\n        if bool:\n            srv_token = m.get_string()\n        K = pow(self.f, self.x, self.P)\n        # okay, build up the hash H of\n        # (V_C || V_S || I_C || I_S || K_S || e || f || K)\n        hm = Message()\n        hm.add(self.transport.local_version, self.transport.remote_version,\n        self.transport.local_kex_init, self.transport.remote_kex_init)\n        hm.add_string(self.transport.host_key.__str__())\n        hm.add_mpint(self.e)\n        hm.add_mpint(self.f)\n        hm.add_mpint(K)\n        H = sha1(str(hm)).digest()\n        self.transport._set_K_H(K, H)\n        if srv_token is not None:\n            self.kexgss.ssh_init_sec_context(target=self.gss_host,\n                                             recv_token=srv_token)\n            self.kexgss.ssh_check_mic(mic_token, H)\n        else:\n            self.kexgss.ssh_check_mic(mic_token, H)\n        self.transport.gss_kex_used = True\n        self.transport._activate_outbound()\n    def _parse_kexgss_init(self, m):\n        \"\"\"\n        Parse the SSH2_MSG_KEXGSS_INIT message (server mode).\n        :param `.Message` m: The content of the SSH2_MSG_KEXGSS_INIT message\n        \"\"\"\n        # server mode\n        client_token = m.get_string()\n        self.e = m.get_mpint()\n        if (self.e < 1) or (self.e > self.P - 1):\n            raise SSHException('Client kex \"e\" is out of range')\n        K = pow(self.e, self.x, self.P)\n        self.transport.host_key = NullHostKey()\n        key = self.transport.host_key.__str__()\n        # okay, build up the hash H of\n        # (V_C || V_S || I_C || I_S || K_S || e || f || K)\n        hm = Message()\n        hm.add(self.transport.remote_version, self.transport.local_version,\n               self.transport.remote_kex_init, self.transport.local_kex_init)\n        hm.add_string(key)\n        hm.add_mpint(self.e)\n        hm.add_mpint(self.f)\n        hm.add_mpint(K)\n        H = sha1(hm.asbytes()).digest()\n        self.transport._set_K_H(K, H)\n        srv_token = self.kexgss.ssh_accept_sec_context(self.gss_host,\n                                                       client_token)\n        m = Message()\n        if self.kexgss._gss_srv_ctxt_status:\n            mic_token = self.kexgss.ssh_get_mic(self.transport.session_id,\n                                                gss_kex=True)\n            m.add_byte(c_MSG_KEXGSS_COMPLETE)\n            m.add_mpint(self.f)\n            m.add_string(mic_token)\n            if srv_token is not None:\n                m.add_boolean(True)\n                m.add_string(srv_token)\n            else:\n                m.add_boolean(False)\n            self.transport._send_message(m)\n            self.transport.gss_kex_used = True\n            self.transport._activate_outbound()\n        else:\n            m.add_byte(c_MSG_KEXGSS_CONTINUE)\n            m.add_string(srv_token)\n            self.transport._send_message(m)\n            self.transport._expect_packet(MSG_KEXGSS_CONTINUE,\n                                          MSG_KEXGSS_COMPLETE,\n                                          MSG_KEXGSS_ERROR)\n    def _parse_kexgss_error(self, m):\n        \"\"\"\n        Parse the SSH2_MSG_KEXGSS_ERROR message (client mode).\n        The server may send a GSS-API error message. if it does, we display\n        the error by throwing an exception (client mode).\n        :param `.Message` m: The content of the SSH2_MSG_KEXGSS_ERROR message\n        :raise SSHException: Contains GSS-API major and minor status as well as\n                             the error message and the language tag of the\n                             message\n        \"\"\"\n        maj_status = m.get_int()\n        min_status = m.get_int()\n        err_msg = m.get_string()\n        m.get_string()   # we don't care about the language!\n        raise SSHException(\"GSS-API Error:\\nMajor Status: %s\\nMinor Status: %s\\\n                            \\nError Message: %s\\n\") % (str(maj_status),\n                                                       str(min_status),\n                                                       err_msg)\nclass KexGSSGroup14(KexGSSGroup1):\n    \"\"\"\n    GSS-API / SSPI Authenticated Diffie-Hellman Group14 Key Exchange as defined\n    in `RFC 4462 Section 2\n    <https://tools.ietf.org/html/rfc4462.html#section-2>`_\n    \"\"\"\n    P = 0xFFFFFFFFFFFFFFFFC90FDAA22168C234C4C6628B80DC1CD129024E088A67CC74020BBEA63B139B22514A08798E3404DDEF9519B3CD3A431B302B0A6DF25F14374FE1356D6D51C245E485B576625E7EC6F44C42E9A637ED6B0BFF5CB6F406B7EDEE386BFB5A899FA5AE9F24117C4B1FE649286651ECE45B3DC2007CB8A163BF0598DA48361C55D39A69163FA8FD24CF5F83655D23DCA3AD961C62F356208552BB9ED529077096966D670C354E4ABC9804F1746C08CA18217C32905E462E36CE3BE39E772C180E86039B2783A2EC07A28FB5C55DF06F4C52C9DE2BCBF6955817183995497CEA956AE515D2261898FA051015728E5A8AACAA68FFFFFFFFFFFFFFFF  # noqa\n    G = 2\n    NAME = \"gss-group14-sha1-toWM5Slw5Ew8Mqkay+al2g==\"\nclass KexGSSGex(object):\n    \"\"\"\n    GSS-API / SSPI Authenticated Diffie-Hellman Group Exchange as defined in\n    `RFC 4462 Section 2 <https://tools.ietf.org/html/rfc4462.html#section-2>`_\n    \"\"\"\n    NAME = \"gss-gex-sha1-toWM5Slw5Ew8Mqkay+al2g==\"\n    min_bits = 1024\n    max_bits = 8192\n    preferred_bits = 2048\n    def __init__(self, transport):\n        self.transport = transport\n        self.kexgss = self.transport.kexgss_ctxt\n        self.gss_host = None\n        self.p = None\n        self.q = None\n        self.g = None\n        self.x = None\n        self.e = None\n        self.f = None\n        self.old_style = False\n    def start_kex(self):\n        \"\"\"\n        Start the GSS-API / SSPI Authenticated Diffie-Hellman Group Exchange\n        \"\"\"\n        if self.transport.server_mode:\n            self.transport._expect_packet(MSG_KEXGSS_GROUPREQ)\n            return\n        # request a bit range: we accept (min_bits) to (max_bits), but prefer\n        # (preferred_bits).  according to the spec, we shouldn't pull the\n        # minimum up above 1024.\n        self.gss_host = self.transport.gss_host\n        m = Message()\n        m.add_byte(c_MSG_KEXGSS_GROUPREQ)\n        m.add_int(self.min_bits)\n        m.add_int(self.preferred_bits)\n        m.add_int(self.max_bits)\n        self.transport._send_message(m)\n        self.transport._expect_packet(MSG_KEXGSS_GROUP)\n    def parse_next(self, ptype, m):\n        \"\"\"\n        Parse the next packet.\n        :param ptype: The (string) type of the incoming packet\n        :param `.Message` m: The paket content\n        \"\"\"\n        if ptype == MSG_KEXGSS_GROUPREQ:\n            return self._parse_kexgss_groupreq(m)\n        elif ptype == MSG_KEXGSS_GROUP:\n            return self._parse_kexgss_group(m)\n        elif ptype == MSG_KEXGSS_INIT:\n            return self._parse_kexgss_gex_init(m)\n        elif ptype == MSG_KEXGSS_HOSTKEY:\n            return self._parse_kexgss_hostkey(m)\n        elif ptype == MSG_KEXGSS_CONTINUE:\n            return self._parse_kexgss_continue(m)\n        elif ptype == MSG_KEXGSS_COMPLETE:\n            return self._parse_kexgss_complete(m)\n        elif ptype == MSG_KEXGSS_ERROR:\n            return self._parse_kexgss_error(m)\n        raise SSHException('KexGex asked to handle packet type %d' % ptype)\n    # ##  internals...\n    def _generate_x(self):\n        # generate an \"x\" (1 < x < (p-1)/2).\n        q = (self.p - 1) // 2\n        qnorm = util.deflate_long(q, 0)\n        qhbyte = byte_ord(qnorm[0])\n        byte_count = len(qnorm)\n        qmask = 0xff\n        while not (qhbyte & 0x80):\n            qhbyte <<= 1\n            qmask >>= 1\n        while True:\n            x_bytes = os.urandom(byte_count)\n            x_bytes = byte_mask(x_bytes[0], qmask) + x_bytes[1:]\n            x = util.inflate_long(x_bytes, 1)\n            if (x > 1) and (x < q):\n                break\n        self.x = x\n    def _parse_kexgss_groupreq(self, m):\n        \"\"\"\n        Parse the SSH2_MSG_KEXGSS_GROUPREQ message (server mode).\n        :param `.Message` m: The content of the\n            SSH2_MSG_KEXGSS_GROUPREQ message\n        \"\"\"\n        minbits = m.get_int()\n        preferredbits = m.get_int()\n        maxbits = m.get_int()\n        # smoosh the user's preferred size into our own limits\n        if preferredbits > self.max_bits:\n            preferredbits = self.max_bits\n        if preferredbits < self.min_bits:\n            preferredbits = self.min_bits\n        # fix min/max if they're inconsistent.  technically, we could just pout\n        # and hang up, but there's no harm in giving them the benefit of the\n        # doubt and just picking a bitsize for them.\n        if minbits > preferredbits:\n            minbits = preferredbits\n        if maxbits < preferredbits:\n            maxbits = preferredbits\n        # now save a copy\n        self.min_bits = minbits\n        self.preferred_bits = preferredbits\n        self.max_bits = maxbits\n        # generate prime\n        pack = self.transport._get_modulus_pack()\n        if pack is None:\n            raise SSHException(\n                'Can\\'t do server-side gex with no modulus pack')\n        self.transport._log(\n            DEBUG,  # noqa\n            'Picking p (%d <= %d <= %d bits)' % (\n                minbits, preferredbits, maxbits))\n        self.g, self.p = pack.get_modulus(minbits, preferredbits, maxbits)\n        m = Message()\n        m.add_byte(c_MSG_KEXGSS_GROUP)\n        m.add_mpint(self.p)\n        m.add_mpint(self.g)\n        self.transport._send_message(m)\n        self.transport._expect_packet(MSG_KEXGSS_INIT)\n    def _parse_kexgss_group(self, m):\n        \"\"\"\n        Parse the SSH2_MSG_KEXGSS_GROUP message (client mode).\n        :param `Message` m: The content of the SSH2_MSG_KEXGSS_GROUP message\n        \"\"\"\n        self.p = m.get_mpint()\n        self.g = m.get_mpint()\n        # reject if p's bit length < 1024 or > 8192\n        bitlen = util.bit_length(self.p)\n        if (bitlen < 1024) or (bitlen > 8192):\n            raise SSHException(\n                'Server-generated gex p (don\\'t ask) is out of range '\n                '(%d bits)' % bitlen)\n        self.transport._log(DEBUG, 'Got server p (%d bits)' % bitlen)  # noqa\n        self._generate_x()\n        # now compute e = g^x mod p\n        self.e = pow(self.g, self.x, self.p)\n        m = Message()\n        m.add_byte(c_MSG_KEXGSS_INIT)\n        m.add_string(self.kexgss.ssh_init_sec_context(target=self.gss_host))\n        m.add_mpint(self.e)\n        self.transport._send_message(m)\n        self.transport._expect_packet(MSG_KEXGSS_HOSTKEY,\n                                      MSG_KEXGSS_CONTINUE,\n                                      MSG_KEXGSS_COMPLETE,\n                                      MSG_KEXGSS_ERROR)\n    def _parse_kexgss_gex_init(self, m):\n        \"\"\"\n        Parse the SSH2_MSG_KEXGSS_INIT message (server mode).\n        :param `Message` m: The content of the SSH2_MSG_KEXGSS_INIT message\n        \"\"\"\n        client_token = m.get_string()\n        self.e = m.get_mpint()\n        if (self.e < 1) or (self.e > self.p - 1):\n            raise SSHException('Client kex \"e\" is out of range')\n        self._generate_x()\n        self.f = pow(self.g, self.x, self.p)\n        K = pow(self.e, self.x, self.p)\n        self.transport.host_key = NullHostKey()\n        key = self.transport.host_key.__str__()\n        # okay, build up the hash H of\n        # (V_C || V_S || I_C || I_S || K_S || min || n || max || p || g || e || f || K)  # noqa\n        hm = Message()\n        hm.add(self.transport.remote_version, self.transport.local_version,\n               self.transport.remote_kex_init, self.transport.local_kex_init,\n               key)\n        hm.add_int(self.min_bits)\n        hm.add_int(self.preferred_bits)\n        hm.add_int(self.max_bits)\n        hm.add_mpint(self.p)\n        hm.add_mpint(self.g)\n        hm.add_mpint(self.e)\n        hm.add_mpint(self.f)\n        hm.add_mpint(K)\n        H = sha1(hm.asbytes()).digest()\n        self.transport._set_K_H(K, H)\n        srv_token = self.kexgss.ssh_accept_sec_context(self.gss_host,\n                                                       client_token)\n        m = Message()\n        if self.kexgss._gss_srv_ctxt_status:\n            mic_token = self.kexgss.ssh_get_mic(self.transport.session_id,\n                                                gss_kex=True)\n            m.add_byte(c_MSG_KEXGSS_COMPLETE)\n            m.add_mpint(self.f)\n            m.add_string(mic_token)\n            if srv_token is not None:\n                m.add_boolean(True)\n                m.add_string(srv_token)\n            else:\n                m.add_boolean(False)\n            self.transport._send_message(m)\n            self.transport.gss_kex_used = True\n            self.transport._activate_outbound()\n        else:\n            m.add_byte(c_MSG_KEXGSS_CONTINUE)\n            m.add_string(srv_token)\n            self.transport._send_message(m)\n            self.transport._expect_packet(MSG_KEXGSS_CONTINUE,\n                                          MSG_KEXGSS_COMPLETE,\n                                          MSG_KEXGSS_ERROR)\n    def _parse_kexgss_hostkey(self, m):\n        \"\"\"\n        Parse the SSH2_MSG_KEXGSS_HOSTKEY message (client mode).\n        :param `Message` m: The content of the SSH2_MSG_KEXGSS_HOSTKEY message\n        \"\"\"\n        # client mode\n        host_key = m.get_string()\n        self.transport.host_key = host_key\n        sig = m.get_string()\n        self.transport._verify_key(host_key, sig)\n        self.transport._expect_packet(MSG_KEXGSS_CONTINUE,\n                                      MSG_KEXGSS_COMPLETE)\n    def _parse_kexgss_continue(self, m):\n        \"\"\"\n        Parse the SSH2_MSG_KEXGSS_CONTINUE message.\n        :param `Message` m: The content of the SSH2_MSG_KEXGSS_CONTINUE message\n        \"\"\"\n        if not self.transport.server_mode:\n            srv_token = m.get_string()\n            m = Message()\n            m.add_byte(c_MSG_KEXGSS_CONTINUE)\n            m.add_string(self.kexgss.ssh_init_sec_context(target=self.gss_host,\n                                                        recv_token=srv_token))\n            self.transport.send_message(m)\n            self.transport._expect_packet(MSG_KEXGSS_CONTINUE,\n                                          MSG_KEXGSS_COMPLETE,\n                                          MSG_KEXGSS_ERROR)\n        else:\n            pass\n    def _parse_kexgss_complete(self, m):\n        \"\"\"\n        Parse the SSH2_MSG_KEXGSS_COMPLETE message (client mode).\n        :param `Message` m: The content of the SSH2_MSG_KEXGSS_COMPLETE message\n        \"\"\"\n        if self.transport.host_key is None:\n            self.transport.host_key = NullHostKey()\n        self.f = m.get_mpint()\n        mic_token = m.get_string()\n        # This must be TRUE, if there is a GSS-API token in this message.\n        bool = m.get_boolean()\n        srv_token = None\n        if bool:\n            srv_token = m.get_string()\n", "outputs": ["        if (self.f < 1) or (self.f > self.p - 1):"], "input_length": 3128, "output_length": 15, "length": 3143, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "e041f63adbaf3b0f4427791bf11f029a379fd50ce2616217b16353390ea10a8f"}
{"input": "", "context": "//#############################################################################\n//#                                                                           #\n//#  Copyright (C) <2015>  <IMS MAXIMS>                                       #\n//#                                                                           #\n//#  This program is free software: you can redistribute it and/or modify     #\n//#  it under the terms of the GNU Affero General Public License as           #\n//#  published by the Free Software Foundation, either version 3 of the       #\n//#  License, or (at your option) any later version.                          # \n//#                                                                           #\n//#  This program is distributed in the hope that it will be useful,          #\n//#  but WITHOUT ANY WARRANTY; without even the implied warranty of           #\n//#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the            #\n//#  GNU Affero General Public License for more details.                      #\n//#                                                                           #\n//#  You should have received a copy of the GNU Affero General Public License #\n//#  along with this program.  If not, see <http://www.gnu.org/licenses/>.    #\n//#                                                                           #\n//#  IMS MAXIMS provides absolutely NO GUARANTEE OF THE CLINICAL SAFTEY of    #\n//#  this program.  Users of this software do so entirely at their own risk.  #\n//#  IMS MAXIMS only ensures the Clinical Safety of unaltered run-time        #\n//#  software that it builds, deploys and maintains.                          #\n//#                                                                           #\n//#############################################################################\n//#EOH\n// This code was generated by Barbara Worwood using IMS Development Environment (version 1.80 build 5589.25814)\n// Copyright (C) 1995-2015 IMS MAXIMS. All rights reserved.\n// WARNING: DO NOT MODIFY the content of this file\npackage ims.pci.forms.gpcontracts;\nimport ims.framework.*;\nimport ims.framework.controls.*;\nimport ims.framework.enumerations.*;\nimport ims.framework.utils.RuntimeAnchoring;\npublic class GenForm extends FormBridge\n{\n\tprivate static final long serialVersionUID = 1L;\n\tpublic boolean canProvideData(IReportSeed[] reportSeeds)\n\t{\n\t\treturn new ReportDataProvider(reportSeeds, this.getFormReportFields()).canProvideData();\n\t}\n\tpublic boolean hasData(IReportSeed[] reportSeeds)\n\t{\n\t\treturn new ReportDataProvider(reportSeeds, this.getFormReportFields()).hasData();\n\t}\n\tpublic IReportField[] getData(IReportSeed[] reportSeeds)\n\t{\n\t\treturn getData(reportSeeds, false);\n\t}\n\tpublic IReportField[] getData(IReportSeed[] reportSeeds, boolean excludeNulls)\n\t{\n\t\treturn new ReportDataProvider(reportSeeds, this.getFormReportFields(), excludeNulls).getData();\n\t}\n\tpublic static class ctnContractDetailsContainer extends ContainerBridge\n\t{\n\t\tprivate static final long serialVersionUID = 1L;\n\t\tpublic static class qmbGPSelectedComboBox extends ComboBoxBridge\n\t\t{\n\t\t\tprivate static final long serialVersionUID = 1L;\n\t\t\t\n\t\t\tpublic void newRow(ims.core.vo.GpLiteWithNameVo value, String text)\n\t\t\t{\n\t\t\t\tsuper.control.newRow(value, text);\n\t\t\t}\n\t\t\tpublic void newRow(ims.core.vo.GpLiteWithNameVo value, String text, ims.framework.utils.Image image)\n\t\t\t{\n\t\t\t\tsuper.control.newRow(value, text, image);\n\t\t\t}\n\t\t\tpublic void newRow(ims.core.vo.GpLiteWithNameVo value, String text, ims.framework.utils.Color textColor)\n\t\t\t{\n\t\t\t\tsuper.control.newRow(value, text, textColor);\n\t\t\t}\n\t\t\tpublic void newRow(ims.core.vo.GpLiteWithNameVo value, String text, ims.framework.utils.Image image, ims.framework.utils.Color textColor)\n\t\t\t{\n\t\t\t\tsuper.control.newRow(value, text, image, textColor);\n\t\t\t}\n\t\t\tpublic boolean removeRow(ims.core.vo.GpLiteWithNameVo value)\n\t\t\t{\n\t\t\t\treturn super.control.removeRow(value);\n\t\t\t}\n\t\t\tpublic ims.core.vo.GpLiteWithNameVo getValue()\n\t\t\t{\n\t\t\t\treturn (ims.core.vo.GpLiteWithNameVo)super.control.getValue();\n\t\t\t}\n\t\t\tpublic void setValue(ims.core.vo.GpLiteWithNameVo value)\n\t\t\t{\n\t\t\t\tsuper.control.setValue(value);\n\t\t\t}\n\t\t\tpublic void setEditedText(String text)\n\t\t\t{\n\t\t\t\tsuper.control.setEditedText(text);\n\t\t\t}\n\t\t\tpublic String getEditedText()\n\t\t\t{\n\t\t\t\treturn super.control.getEditedText();\n\t\t\t}\n\t\t}\n\t\tprotected void setContext(Form form, ims.framework.interfaces.IAppForm appForm, Control control, FormLoader loader, Images form_images_local, ContextMenus contextMenus, Integer startControlID, ims.framework.utils.SizeInfo designSize, ims.framework.utils.SizeInfo runtimeSize, Integer startTabIndex, boolean skipContextValidation) throws Exception\n\t\t{\n\t\t\tif(form == null)\n\t\t\t\tthrow new RuntimeException(\"Invalid form\");\n\t\t\tif(appForm == null)\n\t\t\t\tthrow new RuntimeException(\"Invalid application form\");\n\t\t\tif(control == null); // this is to avoid eclipse warning only.\n\t\t\tif(loader == null); // this is to avoid eclipse warning only.\n\t\t\tif(form_images_local == null); // this is to avoid eclipse warning only.\n\t\t\tif(contextMenus == null); // this is to avoid eclipse warning only.\n\t\t\tif(startControlID == null)\n\t\t\t\tthrow new RuntimeException(\"Invalid startControlID\");\n\t\t\tif(designSize == null); // this is to avoid eclipse warning only.\n\t\t\tif(runtimeSize == null); // this is to avoid eclipse warning only.\n\t\t\tif(startTabIndex == null)\n\t\t\t\tthrow new RuntimeException(\"Invalid startTabIndex\");\n\t\n\t\n\t\t\t// Label Controls\n\t\t\tRuntimeAnchoring anchoringHelper1 = new RuntimeAnchoring(designSize, runtimeSize, 16, 50, 75, 17, ims.framework.enumerations.ControlAnchoring.TOPLEFT);\n\t\t\tsuper.addControl(factory.getControl(Label.class, new Object[] { control, new Integer(startControlID.intValue() + 1000), new Integer(anchoringHelper1.getX()), new Integer(anchoringHelper1.getY()), new Integer(anchoringHelper1.getWidth()), new Integer(anchoringHelper1.getHeight()), ControlState.UNKNOWN, ControlState.UNKNOWN, ims.framework.enumerations.ControlAnchoring.TOPLEFT, \"Contract ID:\", new Integer(1), null, new Integer(0)}));\n\t\t\tRuntimeAnchoring anchoringHelper2 = new RuntimeAnchoring(designSize, runtimeSize, 16, 18, 61, 17, ims.framework.enumerations.ControlAnchoring.TOPLEFT);\n\t\t\tsuper.addControl(factory.getControl(Label.class, new Object[] { control, new Integer(startControlID.intValue() + 1001), new Integer(anchoringHelper2.getX()), new Integer(anchoringHelper2.getY()), new Integer(anchoringHelper2.getWidth()), new Integer(anchoringHelper2.getHeight()), ControlState.UNKNOWN, ControlState.UNKNOWN, ims.framework.enumerations.ControlAnchoring.TOPLEFT, \"GP Name:\", new Integer(1), null, new Integer(0)}));\n\t\t\tRuntimeAnchoring anchoringHelper3 = new RuntimeAnchoring(designSize, runtimeSize, 512, 18, 119, 17, ims.framework.enumerations.ControlAnchoring.TOPRIGHT);\n\t\t\tsuper.addControl(factory.getControl(Label.class, new Object[] { control, new Integer(startControlID.intValue() + 1002), new Integer(anchoringHelper3.getX()), new Integer(anchoringHelper3.getY()), new Integer(anchoringHelper3.getWidth()), new Integer(anchoringHelper3.getHeight()), ControlState.UNKNOWN, ControlState.UNKNOWN, ims.framework.enumerations.ControlAnchoring.TOPRIGHT, \"Contract Start Date:\", new Integer(1), null, new Integer(0)}));\n\t\t\tRuntimeAnchoring anchoringHelper4 = new RuntimeAnchoring(designSize, runtimeSize, 512, 50, 112, 17, ims.framework.enumerations.ControlAnchoring.TOPRIGHT);\n\t\t\tsuper.addControl(factory.getControl(Label.class, new Object[] { control, new Integer(startControlID.intValue() + 1003), new Integer(anchoringHelper4.getX()), new Integer(anchoringHelper4.getY()), new Integer(anchoringHelper4.getWidth()), new Integer(anchoringHelper4.getHeight()), ControlState.UNKNOWN, ControlState.UNKNOWN, ims.framework.enumerations.ControlAnchoring.TOPRIGHT, \"Contract End Date:\", new Integer(1), null, new Integer(0)}));\n\t\n\t\t\t// TextBox Controls\n\t\t\tRuntimeAnchoring anchoringHelper5 = new RuntimeAnchoring(designSize, runtimeSize, 96, 48, 392, 21, ims.framework.enumerations.ControlAnchoring.TOPLEFTRIGHT);\n\t\t\tsuper.addControl(factory.getControl(TextBox.class, new Object[] { control, new Integer(startControlID.intValue() + 1004), new Integer(anchoringHelper5.getX()), new Integer(anchoringHelper5.getY()), new Integer(anchoringHelper5.getWidth()), new Integer(anchoringHelper5.getHeight()), new Integer(startTabIndex.intValue() + 8), ControlState.DISABLED, ControlState.ENABLED, ims.framework.enumerations.ControlAnchoring.TOPLEFTRIGHT,Boolean.FALSE, new Integer(50), Boolean.TRUE, Boolean.FALSE, null, null, Boolean.TRUE, ims.framework.enumerations.CharacterCasing.NORMAL, ims.framework.enumerations.TextTrimming.NONE, \"\", \"\"}));\n\t\n\t\t\t// Date Controls\n\t\t\tRuntimeAnchoring anchoringHelper6 = new RuntimeAnchoring(designSize, runtimeSize, 640, 48, 176, 20, ims.framework.enumerations.ControlAnchoring.TOPRIGHT);\n\t\t\tsuper.addControl(factory.getControl(DateControl.class, new Object[] { control, new Integer(startControlID.intValue() + 1005), new Integer(anchoringHelper6.getX()), new Integer(anchoringHelper6.getY()), new Integer(anchoringHelper6.getWidth()), new Integer(anchoringHelper6.getHeight()), new Integer(startTabIndex.intValue() + 10), ControlState.DISABLED, ControlState.ENABLED, ims.framework.enumerations.ControlAnchoring.TOPRIGHT,Boolean.TRUE, null, Boolean.FALSE, null, Boolean.FALSE, null}));\n\t\t\tRuntimeAnchoring anchoringHelper7 = new RuntimeAnchoring(designSize, runtimeSize, 640, 16, 176, 20, ims.framework.enumerations.ControlAnchoring.TOPRIGHT);\n\t\t\tsuper.addControl(factory.getControl(DateControl.class, new Object[] { control, new Integer(startControlID.intValue() + 1006), new Integer(anchoringHelper7.getX()), new Integer(anchoringHelper7.getY()), new Integer(anchoringHelper7.getWidth()), new Integer(anchoringHelper7.getHeight()), new Integer(startTabIndex.intValue() + 9), ControlState.DISABLED, ControlState.ENABLED, ims.framework.enumerations.ControlAnchoring.TOPRIGHT,Boolean.TRUE, null, Boolean.FALSE, null, Boolean.TRUE, null}));\n\t\n\t\t\t// Query ComboBox Controls\n\t\t\tRuntimeAnchoring anchoringHelper8 = new RuntimeAnchoring(designSize, runtimeSize, 96, 16, 392, 21, ims.framework.enumerations.ControlAnchoring.TOPLEFTRIGHT);\n\t\t\tComboBox m_qmbGPSelectedTemp = (ComboBox)factory.getControl(ComboBox.class, new Object[] { control, new Integer(startControlID.intValue() + 1007), new Integer(anchoringHelper8.getX()), new Integer(anchoringHelper8.getY()), new Integer(anchoringHelper8.getWidth()), new Integer(anchoringHelper8.getHeight()), new Integer(startTabIndex.intValue() + 7), ControlState.DISABLED, ControlState.ENABLED, ims.framework.enumerations.ControlAnchoring.TOPLEFTRIGHT,Boolean.TRUE, Boolean.TRUE, SortOrder.NONE, Boolean.TRUE, new Integer(3), null, Boolean.TRUE, new Integer(-1), Boolean.FALSE});\n\t\t\taddControl(m_qmbGPSelectedTemp);\n\t\t\tqmbGPSelectedComboBox qmbGPSelected = (qmbGPSelectedComboBox)ComboBoxFlyweightFactory.getInstance().createComboBoxBridge(qmbGPSelectedComboBox.class, m_qmbGPSelectedTemp);\n\t\t\tsuper.addComboBox(qmbGPSelected);\n\t\t}\n\t\tprotected void setCollapsed(boolean value)\n\t\t{\n\t\t\tsuper.container.setCollapsed(value);\n\t\t}\n\t\t//protected boolean isCollapsed()\n\t\t//{\n\t\t\t//return super.container.isCollapsed();\n\t\t//}\n\t\tprotected void setCaption(String value)\n\t\t{\n\t\t\tsuper.container.setCaption(value);\n\t\t}\n\t\tpublic TextBox txtContractID()\n\t\t{\n\t\t\treturn (TextBox)super.getControl(4);\n\t\t}\n\t\tpublic DateControl dteEndDate()\n\t\t{\n\t\t\treturn (DateControl)super.getControl(5);\n\t\t}\n\t\tpublic DateControl dteStartDate()\n\t\t{\n\t\t\treturn (DateControl)super.getControl(6);\n\t\t}\n\t\tpublic qmbGPSelectedComboBox qmbGPSelected()\n\t\t{\n\t\t\treturn (qmbGPSelectedComboBox)super.getComboBox(0);\n\t\t}\n\t}\n\tpublic static class qmbGPSearchComboBox extends ComboBoxBridge\n\t{\n\t\tprivate static final long serialVersionUID = 1L;\n\t\t\n\t\tpublic void newRow(ims.core.vo.GpLiteWithNameVo value, String text)\n\t\t{\n\t\t\tsuper.control.newRow(value, text);\n\t\t}\n\t\tpublic void newRow(ims.core.vo.GpLiteWithNameVo value, String text, ims.framework.utils.Image image)\n\t\t{\n\t\t\tsuper.control.newRow(value, text, image);\n\t\t}\n\t\tpublic void newRow(ims.core.vo.GpLiteWithNameVo value, String text, ims.framework.utils.Color textColor)\n\t\t{\n\t\t\tsuper.control.newRow(value, text, textColor);\n\t\t}\n\t\tpublic void newRow(ims.core.vo.GpLiteWithNameVo value, String text, ims.framework.utils.Image image, ims.framework.utils.Color textColor)\n\t\t{\n\t\t\tsuper.control.newRow(value, text, image, textColor);\n\t\t}\n\t\tpublic boolean removeRow(ims.core.vo.GpLiteWithNameVo value)\n\t\t{\n\t\t\treturn super.control.removeRow(value);\n\t\t}\n\t\tpublic ims.core.vo.GpLiteWithNameVo getValue()\n\t\t{\n\t\t\treturn (ims.core.vo.GpLiteWithNameVo)super.control.getValue();\n\t\t}\n\t\tpublic void setValue(ims.core.vo.GpLiteWithNameVo value)\n\t\t{\n\t\t\tsuper.control.setValue(value);\n\t\t}\n\t\tpublic void setEditedText(String text)\n\t\t{\n\t\t\tsuper.control.setEditedText(text);\n\t\t}\n\t\tpublic String getEditedText()\n\t\t{\n\t\t\treturn super.control.getEditedText();\n\t\t}\n\t}\n\tpublic static class grdResultGridRow extends GridRowBridge\n\t{\n\t\tprivate static final long serialVersionUID = 1L;\n\t\t\n\t\tprotected grdResultGridRow(GridRow row)\n\t\t{\n\t\t\tsuper(row);\n\t\t}\n\t\tpublic void showOpened(int column)\n\t\t{\n\t\t\tsuper.row.showOpened(column);\n\t\t}\n\t\tpublic void setColGPReadOnly(boolean value)\n\t\t{\n\t\t\tsuper.row.setReadOnly(0, value);\n\t\t}\n\t\tpublic boolean isColGPReadOnly()\n\t\t{\n\t\t\treturn super.row.isReadOnly(0);\n\t\t}\n\t\tpublic void showColGPOpened()\n\t\t{\n\t\t\tsuper.row.showOpened(0);\n\t\t}\n\t\tpublic String getColGP()\n\t\t{\n\t\t\treturn (String)super.row.get(0);\n\t\t}\n\t\tpublic void setColGP(String value)\n\t\t{\n\t\t\tsuper.row.set(0, value);\n\t\t}\n\t\tpublic void setCellColGPTooltip(String value)\n\t\t{\n\t\t\tsuper.row.setTooltip(0, value);\n\t\t}\n\t\tpublic void setColContractIDReadOnly(boolean value)\n\t\t{\n\t\t\tsuper.row.setReadOnly(1, value);\n\t\t}\n\t\tpublic boolean isColContractIDReadOnly()\n\t\t{\n\t\t\treturn super.row.isReadOnly(1);\n\t\t}\n\t\tpublic void showColContractIDOpened()\n\t\t{\n\t\t\tsuper.row.showOpened(1);\n\t\t}\n\t\tpublic String getColContractID()\n\t\t{\n\t\t\treturn (String)super.row.get(1);\n\t\t}\n\t\tpublic void setColContractID(String value)\n\t\t{\n\t\t\tsuper.row.set(1, value);\n\t\t}\n\t\tpublic void setCellColContractIDTooltip(String value)\n\t\t{\n\t\t\tsuper.row.setTooltip(1, value);\n\t\t}\n\t\tpublic void setColStartDateReadOnly(boolean value)\n\t\t{\n\t\t\tsuper.row.setReadOnly(2, value);\n\t\t}\n\t\tpublic boolean isColStartDateReadOnly()\n\t\t{\n\t\t\treturn super.row.isReadOnly(2);\n\t\t}\n\t\tpublic void showColStartDateOpened()\n\t\t{\n\t\t\tsuper.row.showOpened(2);\n\t\t}\n\t\tpublic String getColStartDate()\n\t\t{\n\t\t\treturn (String)super.row.get(2);\n\t\t}\n\t\tpublic void setColStartDate(String value)\n\t\t{\n\t\t\tsuper.row.set(2, value);\n\t\t}\n\t\tpublic void setCellColStartDateTooltip(String value)\n\t\t{\n\t\t\tsuper.row.setTooltip(2, value);\n\t\t}\n\t\tpublic void setColEndDateReadOnly(boolean value)\n\t\t{\n\t\t\tsuper.row.setReadOnly(3, value);\n\t\t}\n\t\tpublic boolean isColEndDateReadOnly()\n\t\t{\n\t\t\treturn super.row.isReadOnly(3);\n\t\t}\n\t\tpublic void showColEndDateOpened()\n\t\t{\n\t\t\tsuper.row.showOpened(3);\n\t\t}\n\t\tpublic String getColEndDate()\n\t\t{\n\t\t\treturn (String)super.row.get(3);\n\t\t}\n\t\tpublic void setColEndDate(String value)\n\t\t{\n\t\t\tsuper.row.set(3, value);\n\t\t}\n\t\tpublic void setCellColEndDateTooltip(String value)\n\t\t{\n\t\t\tsuper.row.setTooltip(3, value);\n\t\t}\n\t\tpublic ims.pci.vo.GpContractVo getValue()\n\t\t{\n\t\t\treturn (ims.pci.vo.GpContractVo)super.row.getValue();\n\t\t}\n\t\tpublic void setValue(ims.pci.vo.GpContractVo value)\n\t\t{\n\t\t\tsuper.row.setValue(value);\n\t\t}\n\t}\n\tpublic static class grdResultGridRowCollection extends GridRowCollectionBridge\n\t{\n\t\tprivate static final long serialVersionUID = 1L;\n\t\t\n\t\tprivate grdResultGridRowCollection(GridRowCollection collection)\n\t\t{\n\t\t\tsuper(collection);\n\t\t}\n\t\tpublic grdResultGridRow get(int index)\n\t\t{\n\t\t\treturn new grdResultGridRow(super.collection.get(index));\n\t\t}\n\t\tpublic grdResultGridRow newRow()\n\t\t{\n\t\t\treturn new grdResultGridRow(super.collection.newRow());\n\t\t}\n\t\tpublic grdResultGridRow newRow(boolean autoSelect)\n\t\t{\n\t\t\treturn new grdResultGridRow(super.collection.newRow(autoSelect));\n\t\t}\n\t\tpublic grdResultGridRow newRowAt(int index)\n\t\t{\n\t\t\treturn new grdResultGridRow(super.collection.newRowAt(index));\n\t\t}\n\t\tpublic grdResultGridRow newRowAt(int index, boolean autoSelect)\n\t\t{\n\t\t\treturn new grdResultGridRow(super.collection.newRowAt(index, autoSelect));\n\t\t}\n\t}\n\tpublic static class grdResultGridGrid extends GridBridge\n\t{\n\t\tprivate static final long serialVersionUID = 1L;\n\t\t\n\t\tprivate void addStringColumn(String caption, int captionAlignment, int alignment, int width, boolean readOnly, boolean bold, int sortOrder, int maxLength, boolean canGrow, ims.framework.enumerations.CharacterCasing casing)\n\t\t{\n\t\t\tsuper.grid.addStringColumn(caption, captionAlignment, alignment, width, readOnly, bold, sortOrder, maxLength, canGrow, casing);\n\t\t}\n\t\tpublic ims.pci.vo.GpContractVoCollection getValues()\n\t\t{\n\t\t\tims.pci.vo.GpContractVoCollection listOfValues = new ims.pci.vo.GpContractVoCollection();\n\t\t\tfor(int x = 0; x < this.getRows().size(); x++)\n\t\t\t{\n\t\t\t\tlistOfValues.add(this.getRows().get(x).getValue());\n\t\t\t}\n\t\t\treturn listOfValues;\n\t\t}\n\t\tpublic ims.pci.vo.GpContractVo getValue()\n\t\t{\n\t\t\treturn (ims.pci.vo.GpContractVo)super.grid.getValue();\n\t\t}\n\t\tpublic void setValue(ims.pci.vo.GpContractVo value)\n\t\t{\n\t\t\tsuper.grid.setValue(value);\n\t\t}\n\t\tpublic grdResultGridRow getSelectedRow()\n\t\t{\n\t\t\treturn super.grid.getSelectedRow() == null ? null : new grdResultGridRow(super.grid.getSelectedRow());\n\t\t}\n\t\tpublic int getSelectedRowIndex()\n\t\t{\n\t\t\treturn super.grid.getSelectedRowIndex();\n\t\t}\n\t\tpublic grdResultGridRowCollection getRows()\n\t\t{\n\t\t\treturn new grdResultGridRowCollection(super.grid.getRows());\n\t\t}\n\t\tpublic grdResultGridRow getRowByValue(ims.pci.vo.GpContractVo value)\n\t\t{\n\t\t\tGridRow row = super.grid.getRowByValue(value);\n\t\t\treturn row == null?null:new grdResultGridRow(row);\n\t\t}\n\t\tpublic void setColGPHeaderTooltip(String value)\n\t\t{\n\t\t\tsuper.grid.setColumnHeaderTooltip(0, value);\n\t\t}\n\t\tpublic String getColGPHeaderTooltip()\n\t\t{\n\t\t\treturn super.grid.getColumnHeaderTooltip(0);\n\t\t}\n\t\tpublic void setColContractIDHeaderTooltip(String value)\n\t\t{\n\t\t\tsuper.grid.setColumnHeaderTooltip(1, value);\n\t\t}\n\t\tpublic String getColContractIDHeaderTooltip()\n\t\t{\n\t\t\treturn super.grid.getColumnHeaderTooltip(1);\n\t\t}\n\t\tpublic void setColStartDateHeaderTooltip(String value)\n\t\t{\n\t\t\tsuper.grid.setColumnHeaderTooltip(2, value);\n\t\t}\n\t\tpublic String getColStartDateHeaderTooltip()\n\t\t{\n\t\t\treturn super.grid.getColumnHeaderTooltip(2);\n\t\t}\n\t\tpublic void setColEndDateHeaderTooltip(String value)\n\t\t{\n\t\t\tsuper.grid.setColumnHeaderTooltip(3, value);\n\t\t}\n\t\tpublic String getColEndDateHeaderTooltip()\n\t\t{\n\t\t\treturn super.grid.getColumnHeaderTooltip(3);\n\t\t}\n\t}\n\tprivate void validateContext(ims.framework.Context context)\n\t{\n\t\tif(context == null)\n\t\t\treturn;\n\t}\n\tpublic boolean supportsRecordedInError()\n\t{\n\t\treturn false;\n\t}\n\tpublic ims.vo.ValueObject getRecordedInErrorVo()\n\t{\n\t\treturn null;\n\t}\n\tprotected void setContext(FormLoader loader, Form form, ims.framework.interfaces.IAppForm appForm, UIFactory factory, Context context) throws Exception\n\t{\n\t\tsetContext(loader, form, appForm, factory, context, Boolean.FALSE, new Integer(0), null, null, new Integer(0));\n\t}\n\tprotected void setContext(FormLoader loader, Form form, ims.framework.interfaces.IAppForm appForm, UIFactory factory, Context context, Boolean skipContextValidation) throws Exception\n\t{\n\t\tsetContext(loader, form, appForm, factory, context, skipContextValidation, new Integer(0), null, null, new Integer(0));\n\t}\n\tprotected void setContext(FormLoader loader, Form form, ims.framework.interfaces.IAppForm appForm, UIFactory factory, ims.framework.Context context, Boolean skipContextValidation, Integer startControlID, ims.framework.utils.SizeInfo runtimeSize, ims.framework.Control control, Integer startTabIndex) throws Exception\n\t{\n\t\tif(loader == null); // this is to avoid eclipse warning only.\n\t\tif(factory == null); // this is to avoid eclipse warning only.\n\t\tif(runtimeSize == null); // this is to avoid eclipse warning only.\n\t\tif(appForm == null)\n\t\t\tthrow new RuntimeException(\"Invalid application form\");\n\t\tif(startControlID == null)\n\t\t\tthrow new RuntimeException(\"Invalid startControlID\");\n\t\tif(control == null); // this is to avoid eclipse warning only.\n\t\tif(startTabIndex == null)\n\t\t\tthrow new RuntimeException(\"Invalid startTabIndex\");\n\t\tthis.context = context;\n\t\tthis.componentIdentifier = startControlID.toString();\n\t\tthis.formInfo = form.getFormInfo();\n\t\tthis.globalContext = new GlobalContext(context);\n\t\n\t\tif(skipContextValidation == null || !skipContextValidation.booleanValue())\n\t\t{\n\t\t\tvalidateContext(context);\n\t\t}\n\t\n\t\tsuper.setContext(form);\n\t\tims.framework.utils.SizeInfo designSize = new ims.framework.utils.SizeInfo(848, 632);\n\t\tif(runtimeSize == null)\n\t\t\truntimeSize = designSize;\n\t\tform.setWidth(runtimeSize.getWidth());\n\t\tform.setHeight(runtimeSize.getHeight());\n\t\tsuper.setFormReferences(FormReferencesFlyweightFactory.getInstance().create(Forms.class));\n\t\tsuper.setImageReferences(ImageReferencesFlyweightFactory.getInstance().create(Images.class));\n\t\tsuper.setGlobalContext(ContextBridgeFlyweightFactory.getInstance().create(GlobalContextBridge.class, context, false));\n\t\tsuper.setLocalContext(new LocalContext(context, form.getFormInfo(), componentIdentifier));\n\t\t// Context Menus\n", "outputs": ["\t\tcontextMenus = new ContextMenus();"], "input_length": 3530, "output_length": 7, "length": 3537, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "217f506c14dc7cc8c1b62fcf79c3becbbcc3695c16cbeb393f2a995b6ed31d75"}
{"input": "", "context": "/*\n * Copyright (c) 2011, 2014, Oracle and/or its affiliates. All rights reserved.\n * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n *\n * This code is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License version 2 only, as\n * published by the Free Software Foundation.\n *\n * This code is distributed in the hope that it will be useful, but WITHOUT\n * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n * version 2 for more details (a copy is included in the LICENSE file that\n * accompanied this code).\n *\n * You should have received a copy of the GNU General Public License version\n * 2 along with this work; if not, write to the Free Software Foundation,\n * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n *\n * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n * or visit www.oracle.com if you need additional information or have any\n * questions.\n */\npackage com.oracle.graal.phases.common.inlining.walker;\nimport static com.oracle.graal.compiler.common.GraalOptions.Intrinsify;\nimport static com.oracle.graal.compiler.common.GraalOptions.MaximumRecursiveInlining;\nimport static com.oracle.graal.compiler.common.GraalOptions.MegamorphicInliningMinMethodProbability;\nimport static com.oracle.graal.compiler.common.GraalOptions.OptCanonicalizer;\nimport java.util.ArrayDeque;\nimport java.util.ArrayList;\nimport java.util.BitSet;\nimport java.util.Collection;\nimport java.util.Iterator;\nimport java.util.List;\nimport java.util.Set;\nimport jdk.vm.ci.code.BailoutException;\nimport jdk.vm.ci.common.JVMCIError;\nimport jdk.vm.ci.meta.Assumptions.AssumptionResult;\nimport jdk.vm.ci.meta.JavaTypeProfile;\nimport jdk.vm.ci.meta.ResolvedJavaMethod;\nimport jdk.vm.ci.meta.ResolvedJavaType;\nimport com.oracle.graal.compiler.common.type.ObjectStamp;\nimport com.oracle.graal.debug.Debug;\nimport com.oracle.graal.debug.DebugMetric;\nimport com.oracle.graal.graph.Graph;\nimport com.oracle.graal.graph.Node;\nimport com.oracle.graal.nodes.CallTargetNode;\nimport com.oracle.graal.nodes.Invoke;\nimport com.oracle.graal.nodes.ParameterNode;\nimport com.oracle.graal.nodes.StructuredGraph;\nimport com.oracle.graal.nodes.ValueNode;\nimport com.oracle.graal.nodes.java.AbstractNewObjectNode;\nimport com.oracle.graal.nodes.java.MethodCallTargetNode;\nimport com.oracle.graal.nodes.virtual.AllocatedObjectNode;\nimport com.oracle.graal.nodes.virtual.VirtualObjectNode;\nimport com.oracle.graal.phases.OptimisticOptimizations;\nimport com.oracle.graal.phases.common.CanonicalizerPhase;\nimport com.oracle.graal.phases.common.inlining.InliningUtil;\nimport com.oracle.graal.phases.common.inlining.info.AssumptionInlineInfo;\nimport com.oracle.graal.phases.common.inlining.info.ExactInlineInfo;\nimport com.oracle.graal.phases.common.inlining.info.InlineInfo;\nimport com.oracle.graal.phases.common.inlining.info.MultiTypeGuardInlineInfo;\nimport com.oracle.graal.phases.common.inlining.info.TypeGuardInlineInfo;\nimport com.oracle.graal.phases.common.inlining.info.elem.Inlineable;\nimport com.oracle.graal.phases.common.inlining.info.elem.InlineableGraph;\nimport com.oracle.graal.phases.common.inlining.policy.InliningPolicy;\nimport com.oracle.graal.phases.tiers.HighTierContext;\nimport com.oracle.graal.phases.util.Providers;\n/**\n * <p>\n * The space of inlining decisions is explored depth-first with the help of a stack realized by\n * {@link InliningData}. At any point in time, the topmost element of that stack consists of:\n * <ul>\n * <li>the callsite under consideration is tracked as a {@link MethodInvocation}.</li>\n * <li>\n * one or more {@link CallsiteHolder}s, all of them associated to the callsite above. Why more than\n * one? Depending on the type-profile for the receiver more than one concrete method may be feasible\n * target.</li>\n * </ul>\n * </p>\n *\n * <p>\n * The bottom element in the stack consists of:\n * <ul>\n * <li>\n * a single {@link MethodInvocation} (the\n * {@link com.oracle.graal.phases.common.inlining.walker.MethodInvocation#isRoot root} one, ie the\n * unknown caller of the root graph)</li>\n * <li>\n * a single {@link CallsiteHolder} (the root one, for the method on which inlining was called)</li>\n * </ul>\n * </p>\n *\n * @see #moveForward()\n */\npublic class InliningData {\n    // Metrics\n    private static final DebugMetric metricInliningPerformed = Debug.metric(\"InliningPerformed\");\n    private static final DebugMetric metricInliningRuns = Debug.metric(\"InliningRuns\");\n    private static final DebugMetric metricInliningConsidered = Debug.metric(\"InliningConsidered\");\n    /**\n     * Call hierarchy from outer most call (i.e., compilation unit) to inner most callee.\n     */\n    private final ArrayDeque<CallsiteHolder> graphQueue = new ArrayDeque<>();\n    private final ArrayDeque<MethodInvocation> invocationQueue = new ArrayDeque<>();\n    private final HighTierContext context;\n    private final int maxMethodPerInlining;\n    private final CanonicalizerPhase canonicalizer;\n    private final InliningPolicy inliningPolicy;\n    private final StructuredGraph rootGraph;\n    private int maxGraphs;\n    public InliningData(StructuredGraph rootGraph, HighTierContext context, int maxMethodPerInlining, CanonicalizerPhase canonicalizer, InliningPolicy inliningPolicy) {\n        assert rootGraph != null;\n        this.context = context;\n        this.maxMethodPerInlining = maxMethodPerInlining;\n        this.canonicalizer = canonicalizer;\n        this.inliningPolicy = inliningPolicy;\n        this.maxGraphs = 1;\n        this.rootGraph = rootGraph;\n        invocationQueue.push(new MethodInvocation(null, 1.0, 1.0, null));\n        graphQueue.push(new CallsiteHolderExplorable(rootGraph, 1.0, 1.0, null));\n    }\n    public static boolean isFreshInstantiation(ValueNode arg) {\n        return (arg instanceof AbstractNewObjectNode) || (arg instanceof AllocatedObjectNode) || (arg instanceof VirtualObjectNode);\n    }\n    private String checkTargetConditionsHelper(ResolvedJavaMethod method, int invokeBci) {\n        if (method == null) {\n            return \"the method is not resolved\";\n        } else if (method.isNative() && (!Intrinsify.getValue() || !InliningUtil.canIntrinsify(context.getReplacements(), method, invokeBci))) {\n            return \"it is a non-intrinsic native method\";\n        } else if (method.isAbstract()) {\n            return \"it is an abstract method\";\n        } else if (!method.getDeclaringClass().isInitialized()) {\n            return \"the method's class is not initialized\";\n        } else if (!method.canBeInlined()) {\n            return \"it is marked non-inlinable\";\n        } else if (countRecursiveInlining(method) > MaximumRecursiveInlining.getValue()) {\n            return \"it exceeds the maximum recursive inlining depth\";\n        } else if (new OptimisticOptimizations(rootGraph.getProfilingInfo(method)).lessOptimisticThan(context.getOptimisticOptimizations())) {\n            return \"the callee uses less optimistic optimizations than caller\";\n        } else {\n            return null;\n        }\n    }\n    private boolean checkTargetConditions(Invoke invoke, ResolvedJavaMethod method) {\n        final String failureMessage = checkTargetConditionsHelper(method, invoke.bci());\n        if (failureMessage == null) {\n            return true;\n        } else {\n            InliningUtil.logNotInlined(invoke, inliningDepth(), method, failureMessage);\n            return false;\n        }\n    }\n    /**\n     * Determines if inlining is possible at the given invoke node.\n     *\n     * @param invoke the invoke that should be inlined\n     * @return an instance of InlineInfo, or null if no inlining is possible at the given invoke\n     */\n    private InlineInfo getInlineInfo(Invoke invoke) {\n        final String failureMessage = InliningUtil.checkInvokeConditions(invoke);\n        if (failureMessage != null) {\n            InliningUtil.logNotInlinedMethod(invoke, failureMessage);\n            return null;\n        }\n        MethodCallTargetNode callTarget = (MethodCallTargetNode) invoke.callTarget();\n        ResolvedJavaMethod targetMethod = callTarget.targetMethod();\n        if (callTarget.invokeKind() == CallTargetNode.InvokeKind.Special || targetMethod.canBeStaticallyBound()) {\n            return getExactInlineInfo(invoke, targetMethod);\n        }\n        assert callTarget.invokeKind().isIndirect();\n        ResolvedJavaType holder = targetMethod.getDeclaringClass();\n        if (!(callTarget.receiver().stamp() instanceof ObjectStamp)) {\n            return null;\n        }\n        ObjectStamp receiverStamp = (ObjectStamp) callTarget.receiver().stamp();\n        if (receiverStamp.alwaysNull()) {\n            // Don't inline if receiver is known to be null\n            return null;\n        }\n        ResolvedJavaType contextType = invoke.getContextType();\n        if (receiverStamp.type() != null) {\n            // the invoke target might be more specific than the holder (happens after inlining:\n            // parameters lose their declared type...)\n            ResolvedJavaType receiverType = receiverStamp.type();\n            if (receiverType != null && holder.isAssignableFrom(receiverType)) {\n                holder = receiverType;\n                if (receiverStamp.isExactType()) {\n                    assert targetMethod.getDeclaringClass().isAssignableFrom(holder) : holder + \" subtype of \" + targetMethod.getDeclaringClass() + \" for \" + targetMethod;\n                    ResolvedJavaMethod resolvedMethod = holder.resolveConcreteMethod(targetMethod, contextType);\n                    if (resolvedMethod != null) {\n                        return getExactInlineInfo(invoke, resolvedMethod);\n                    }\n                }\n            }\n        }\n        if (holder.isArray()) {\n            // arrays can be treated as Objects\n            ResolvedJavaMethod resolvedMethod = holder.resolveConcreteMethod(targetMethod, contextType);\n            if (resolvedMethod != null) {\n                return getExactInlineInfo(invoke, resolvedMethod);\n            }\n        }\n        if (callTarget.graph().getAssumptions() != null) {\n            AssumptionResult<ResolvedJavaType> leafConcreteSubtype = holder.findLeafConcreteSubtype();\n            if (leafConcreteSubtype != null) {\n                ResolvedJavaMethod resolvedMethod = leafConcreteSubtype.getResult().resolveConcreteMethod(targetMethod, contextType);\n                if (resolvedMethod != null) {\n                    return getAssumptionInlineInfo(invoke, resolvedMethod, leafConcreteSubtype);\n                }\n            }\n            AssumptionResult<ResolvedJavaMethod> concrete = holder.findUniqueConcreteMethod(targetMethod);\n            if (concrete != null) {\n                return getAssumptionInlineInfo(invoke, concrete.getResult(), concrete);\n            }\n        }\n        // type check based inlining\n        return getTypeCheckedInlineInfo(invoke, targetMethod);\n    }\n    private InlineInfo getTypeCheckedInlineInfo(Invoke invoke, ResolvedJavaMethod targetMethod) {\n        JavaTypeProfile typeProfile = ((MethodCallTargetNode) invoke.callTarget()).getProfile();\n        if (typeProfile == null) {\n            InliningUtil.logNotInlined(invoke, inliningDepth(), targetMethod, \"no type profile exists\");\n            return null;\n        }\n        JavaTypeProfile.ProfiledType[] ptypes = typeProfile.getTypes();\n        if (ptypes == null || ptypes.length <= 0) {\n            InliningUtil.logNotInlined(invoke, inliningDepth(), targetMethod, \"no types in profile\");\n            return null;\n        }\n        ResolvedJavaType contextType = invoke.getContextType();\n        double notRecordedTypeProbability = typeProfile.getNotRecordedProbability();\n        final OptimisticOptimizations optimisticOpts = context.getOptimisticOptimizations();\n        if (ptypes.length == 1 && notRecordedTypeProbability == 0) {\n            if (!optimisticOpts.inlineMonomorphicCalls()) {\n                InliningUtil.logNotInlined(invoke, inliningDepth(), targetMethod, \"inlining monomorphic calls is disabled\");\n                return null;\n            }\n            ResolvedJavaType type = ptypes[0].getType();\n            assert type.isArray() || type.isConcrete();\n            ResolvedJavaMethod concrete = type.resolveConcreteMethod(targetMethod, contextType);\n            if (!checkTargetConditions(invoke, concrete)) {\n                return null;\n            }\n            return new TypeGuardInlineInfo(invoke, concrete, type);\n        } else {\n            invoke.setPolymorphic(true);\n            if (!optimisticOpts.inlinePolymorphicCalls() && notRecordedTypeProbability == 0) {\n                InliningUtil.logNotInlinedInvoke(invoke, inliningDepth(), targetMethod, \"inlining polymorphic calls is disabled (%d types)\", ptypes.length);\n                return null;\n            }\n            if (!optimisticOpts.inlineMegamorphicCalls() && notRecordedTypeProbability > 0) {\n                // due to filtering impossible types, notRecordedTypeProbability can be > 0 although\n                // the number of types is lower than what can be recorded in a type profile\n                InliningUtil.logNotInlinedInvoke(invoke, inliningDepth(), targetMethod, \"inlining megamorphic calls is disabled (%d types, %f %% not recorded types)\", ptypes.length,\n                                notRecordedTypeProbability * 100);\n                return null;\n            }\n            // Find unique methods and their probabilities.\n            ArrayList<ResolvedJavaMethod> concreteMethods = new ArrayList<>();\n            ArrayList<Double> concreteMethodsProbabilities = new ArrayList<>();\n            for (int i = 0; i < ptypes.length; i++) {\n                ResolvedJavaMethod concrete = ptypes[i].getType().resolveConcreteMethod(targetMethod, contextType);\n                if (concrete == null) {\n                    InliningUtil.logNotInlined(invoke, inliningDepth(), targetMethod, \"could not resolve method\");\n                    return null;\n                }\n                int index = concreteMethods.indexOf(concrete);\n                double curProbability = ptypes[i].getProbability();\n                if (index < 0) {\n                    index = concreteMethods.size();\n                    concreteMethods.add(concrete);\n                    concreteMethodsProbabilities.add(curProbability);\n                } else {\n                    concreteMethodsProbabilities.set(index, concreteMethodsProbabilities.get(index) + curProbability);\n                }\n            }\n            // Clear methods that fall below the threshold.\n            if (notRecordedTypeProbability > 0) {\n                ArrayList<ResolvedJavaMethod> newConcreteMethods = new ArrayList<>();\n                ArrayList<Double> newConcreteMethodsProbabilities = new ArrayList<>();\n                for (int i = 0; i < concreteMethods.size(); ++i) {\n                    if (concreteMethodsProbabilities.get(i) >= MegamorphicInliningMinMethodProbability.getValue()) {\n                        newConcreteMethods.add(concreteMethods.get(i));\n                        newConcreteMethodsProbabilities.add(concreteMethodsProbabilities.get(i));\n                    }\n                }\n                if (newConcreteMethods.isEmpty()) {\n                    // No method left that is worth inlining.\n                    InliningUtil.logNotInlinedInvoke(invoke, inliningDepth(), targetMethod, \"no methods remaining after filtering less frequent methods (%d methods previously)\",\n                                    concreteMethods.size());\n                    return null;\n                }\n                concreteMethods = newConcreteMethods;\n                concreteMethodsProbabilities = newConcreteMethodsProbabilities;\n            }\n            if (concreteMethods.size() > maxMethodPerInlining) {\n                InliningUtil.logNotInlinedInvoke(invoke, inliningDepth(), targetMethod, \"polymorphic call with more than %d target methods\", maxMethodPerInlining);\n                return null;\n            }\n            // Clean out types whose methods are no longer available.\n            ArrayList<JavaTypeProfile.ProfiledType> usedTypes = new ArrayList<>();\n            ArrayList<Integer> typesToConcretes = new ArrayList<>();\n            for (JavaTypeProfile.ProfiledType type : ptypes) {\n                ResolvedJavaMethod concrete = type.getType().resolveConcreteMethod(targetMethod, contextType);\n                int index = concreteMethods.indexOf(concrete);\n                if (index == -1) {\n                    notRecordedTypeProbability += type.getProbability();\n                } else {\n                    assert type.getType().isArray() || !type.getType().isAbstract() : type + \" \" + concrete;\n                    usedTypes.add(type);\n                    typesToConcretes.add(index);\n                }\n            }\n            if (usedTypes.isEmpty()) {\n                // No type left that is worth checking for.\n                InliningUtil.logNotInlinedInvoke(invoke, inliningDepth(), targetMethod, \"no types remaining after filtering less frequent types (%d types previously)\", ptypes.length);\n                return null;\n            }\n            for (ResolvedJavaMethod concrete : concreteMethods) {\n                if (!checkTargetConditions(invoke, concrete)) {\n                    InliningUtil.logNotInlined(invoke, inliningDepth(), targetMethod, \"it is a polymorphic method call and at least one invoked method cannot be inlined\");\n                    return null;\n                }\n            }\n            return new MultiTypeGuardInlineInfo(invoke, concreteMethods, usedTypes, typesToConcretes, notRecordedTypeProbability);\n        }\n    }\n    private InlineInfo getAssumptionInlineInfo(Invoke invoke, ResolvedJavaMethod concrete, AssumptionResult<?> takenAssumption) {\n        assert concrete.isConcrete();\n        if (checkTargetConditions(invoke, concrete)) {\n            return new AssumptionInlineInfo(invoke, concrete, takenAssumption);\n        }\n        return null;\n    }\n    private InlineInfo getExactInlineInfo(Invoke invoke, ResolvedJavaMethod targetMethod) {\n        assert targetMethod.isConcrete();\n        if (checkTargetConditions(invoke, targetMethod)) {\n            return new ExactInlineInfo(invoke, targetMethod);\n        }\n        return null;\n    }\n    @SuppressWarnings(\"try\")\n    private void doInline(CallsiteHolderExplorable callerCallsiteHolder, MethodInvocation calleeInvocation) {\n        StructuredGraph callerGraph = callerCallsiteHolder.graph();\n        InlineInfo calleeInfo = calleeInvocation.callee();\n        try {\n            try (Debug.Scope scope = Debug.scope(\"doInline\", callerGraph)) {\n                Set<Node> canonicalizedNodes = Node.newSet();\n                calleeInfo.invoke().asNode().usages().snapshotTo(canonicalizedNodes);\n                Collection<Node> parameterUsages = calleeInfo.inline(new Providers(context));\n                canonicalizedNodes.addAll(parameterUsages);\n                metricInliningRuns.increment();\n                Debug.dump(callerGraph, \"after %s\", calleeInfo);\n                if (OptCanonicalizer.getValue()) {\n                    Graph.Mark markBeforeCanonicalization = callerGraph.getMark();\n                    canonicalizer.applyIncremental(callerGraph, context, canonicalizedNodes);\n                    // process invokes that are possibly created during canonicalization\n                    for (Node newNode : callerGraph.getNewNodes(markBeforeCanonicalization)) {\n                        if (newNode instanceof Invoke) {\n                            callerCallsiteHolder.pushInvoke((Invoke) newNode);\n                        }\n                    }\n                }\n                callerCallsiteHolder.computeProbabilities();\n                metricInliningPerformed.increment();\n            }\n        } catch (BailoutException bailout) {\n            throw bailout;\n        } catch (AssertionError | RuntimeException e) {\n            throw new JVMCIError(e).addContext(calleeInfo.toString());\n        } catch (JVMCIError e) {\n            throw e.addContext(calleeInfo.toString());\n        } catch (Throwable e) {\n            throw Debug.handle(e);\n        }\n    }\n    /**\n     *\n     * This method attempts:\n     * <ol>\n     * <li>\n     * to inline at the callsite given by <code>calleeInvocation</code>, where that callsite belongs\n     * to the {@link CallsiteHolderExplorable} at the top of the {@link #graphQueue} maintained in\n     * this class.</li>\n     * <li>\n     * otherwise, to devirtualize the callsite in question.</li>\n     * </ol>\n     *\n     * @return true iff inlining was actually performed\n     */\n    private boolean tryToInline(MethodInvocation calleeInvocation, int inliningDepth) {\n        CallsiteHolderExplorable callerCallsiteHolder = (CallsiteHolderExplorable) currentGraph();\n        InlineInfo calleeInfo = calleeInvocation.callee();\n        assert callerCallsiteHolder.containsInvoke(calleeInfo.invoke());\n        metricInliningConsidered.increment();\n        if (inliningPolicy.isWorthInlining(context.getReplacements(), calleeInvocation, inliningDepth, true)) {\n            doInline(callerCallsiteHolder, calleeInvocation);\n            return true;\n        }\n        if (context.getOptimisticOptimizations().devirtualizeInvokes()) {\n            calleeInfo.tryToDevirtualizeInvoke(new Providers(context));\n        }\n        return false;\n    }\n    /**\n     * This method picks one of the callsites belonging to the current\n     * {@link CallsiteHolderExplorable}. Provided the callsite qualifies to be analyzed for\n     * inlining, this method prepares a new stack top in {@link InliningData} for such callsite,\n     * which comprises:\n     * <ul>\n     * <li>preparing a summary of feasible targets, ie preparing an {@link InlineInfo}</li>\n     * <li>based on it, preparing the stack top proper which consists of:</li>\n     * <ul>\n     * <li>one {@link MethodInvocation}</li>\n     * <li>a {@link CallsiteHolder} for each feasible target</li>\n     * </ul>\n     * </ul>\n     *\n     * <p>\n     * The thus prepared \"stack top\" is needed by {@link #moveForward()} to explore the space of\n     * inlining decisions (each decision one of: backtracking, delving, inlining).\n     * </p>\n     *\n     * <p>\n     * The {@link InlineInfo} used to get things rolling is kept around in the\n     * {@link MethodInvocation}, it will be needed in case of inlining, see\n     * {@link InlineInfo#inline(Providers)}\n     * </p>\n     */\n    private void processNextInvoke() {\n        CallsiteHolderExplorable callsiteHolder = (CallsiteHolderExplorable) currentGraph();\n        Invoke invoke = callsiteHolder.popInvoke();\n        InlineInfo info = getInlineInfo(invoke);\n        if (info != null) {\n            info.populateInlinableElements(context, currentGraph().graph(), canonicalizer);\n            double invokeProbability = callsiteHolder.invokeProbability(invoke);\n            double invokeRelevance = callsiteHolder.invokeRelevance(invoke);\n            MethodInvocation methodInvocation = new MethodInvocation(info, invokeProbability, invokeRelevance, freshlyInstantiatedArguments(invoke, callsiteHolder.getFixedParams()));\n            pushInvocationAndGraphs(methodInvocation);\n        }\n    }\n    /**\n     * Gets the freshly instantiated arguments.\n     * <p>\n     * A freshly instantiated argument is either:\n     * <uL>\n     * <li>an {@link InliningData#isFreshInstantiation(com.oracle.graal.nodes.ValueNode)}</li>\n     * <li>a fixed-param, ie a {@link ParameterNode} receiving a freshly instantiated argument</li>\n     * </uL>\n     * </p>\n     *\n     * @return the positions of freshly instantiated arguments in the argument list of the\n     *         <code>invoke</code>, or null if no such positions exist.\n     */\n    public static BitSet freshlyInstantiatedArguments(Invoke invoke, Set<ParameterNode> fixedParams) {\n        assert fixedParams != null;\n        assert paramsAndInvokeAreInSameGraph(invoke, fixedParams);\n        BitSet result = null;\n        int argIdx = 0;\n        for (ValueNode arg : invoke.callTarget().arguments()) {\n            assert arg != null;\n            if (isFreshInstantiation(arg) || fixedParams.contains(arg)) {\n                if (result == null) {\n                    result = new BitSet();\n                }\n                result.set(argIdx);\n            }\n            argIdx++;\n        }\n        return result;\n    }\n    private static boolean paramsAndInvokeAreInSameGraph(Invoke invoke, Set<ParameterNode> fixedParams) {\n        if (fixedParams.isEmpty()) {\n            return true;\n        }\n        for (ParameterNode p : fixedParams) {\n            if (p.graph() != invoke.asNode().graph()) {\n                return false;\n            }\n        }\n        return true;\n    }\n    public int graphCount() {\n        return graphQueue.size();\n    }\n    public boolean hasUnprocessedGraphs() {\n        return !graphQueue.isEmpty();\n    }\n    private CallsiteHolder currentGraph() {\n        return graphQueue.peek();\n    }\n    private void popGraph() {\n        graphQueue.pop();\n        assert graphQueue.size() <= maxGraphs;\n    }\n    private void popGraphs(int count) {\n        assert count >= 0;\n        for (int i = 0; i < count; i++) {\n            graphQueue.pop();\n        }\n    }\n    private static final Object[] NO_CONTEXT = {};\n    /**\n     * Gets the call hierarchy of this inlining from outer most call to inner most callee.\n     */\n    private Object[] inliningContext() {\n        if (!Debug.isDumpEnabled()) {\n            return NO_CONTEXT;\n        }\n        Object[] result = new Object[graphQueue.size()];\n        int i = 0;\n        for (CallsiteHolder g : graphQueue) {\n            result[i++] = g.method();\n        }\n        return result;\n    }\n    private MethodInvocation currentInvocation() {\n        return invocationQueue.peekFirst();\n    }\n    private void pushInvocationAndGraphs(MethodInvocation methodInvocation) {\n        invocationQueue.addFirst(methodInvocation);\n        InlineInfo info = methodInvocation.callee();\n        maxGraphs += info.numberOfMethods();\n        assert graphQueue.size() <= maxGraphs;\n        for (int i = 0; i < info.numberOfMethods(); i++) {\n            CallsiteHolder ch = methodInvocation.buildCallsiteHolderForElement(i);\n            assert !contains(ch.graph());\n            graphQueue.push(ch);\n            assert graphQueue.size() <= maxGraphs;\n        }\n    }\n    private void popInvocation() {\n        maxGraphs -= invocationQueue.peekFirst().callee().numberOfMethods();\n", "outputs": ["        assert graphQueue.size() <= maxGraphs;"], "input_length": 3900, "output_length": 8, "length": 3908, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "50c5bea7aef1febdd6c7b7611a99ccab815ae5c25200827c2b6bf0b20b499a9a"}
{"input": "", "context": "#region License\n// Copyright (c) 2013, ClearCanvas Inc.\n// All rights reserved.\n// http://www.ClearCanvas.ca\n//\n// This file is part of the ClearCanvas RIS/PACS open source project.\n//\n// The ClearCanvas RIS/PACS open source project is free software: you can\n// redistribute it and/or modify it under the terms of the GNU General Public\n// License as published by the Free Software Foundation, either version 3 of the\n// License, or (at your option) any later version.\n//\n// The ClearCanvas RIS/PACS open source project is distributed in the hope that it\n// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of\n// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General\n// Public License for more details.\n//\n// You should have received a copy of the GNU General Public License along with\n// the ClearCanvas RIS/PACS open source project.  If not, see\n// <http://www.gnu.org/licenses/>.\n#endregion\nusing System;\nusing System.Collections.Generic;\nusing Macro.Common;\nusing Macro.Common.Utilities;\nusing Macro.Desktop;\nusing Macro.Desktop.Validation;\nusing Macro.ImageViewer.StudyManagement;\n#pragma warning disable 0419,1574,1587,1591\nnamespace Macro.ImageViewer.Clipboard.CopyToClipboard\n{\n\tpublic sealed class CopySubsetToClipboardComponentViewExtensionPoint : ExtensionPoint<IApplicationComponentView>\n\t{\n\t}\n\t[AssociateView(typeof(CopySubsetToClipboardComponentViewExtensionPoint))]\n\tpublic partial class CopySubsetToClipboardComponent : ApplicationComponent\n\t{\n\t\tprivate enum RangeSelectionOption\n\t\t{\n\t\t\tInstanceNumber = 0,\n\t\t\tPosition \n\t\t}\n\t\tprivate enum CopyOption\n\t\t{\n\t\t\tCopyRange = 0,\n\t\t\tCopyCustom\n\t\t}\n\t\tprivate enum CopyRangeOption\n\t\t{\n\t\t\tCopyAll = 0,\n\t\t\tCopyAtInterval\n\t\t}\n\t\tprivate readonly IDesktopWindow _desktopWindow;\n\t\tprivate IImageViewer _activeViewer;\n\t\tprivate IDisplaySet _currentDisplaySet;\n\t\tprivate int _numberOfImages;\n\t\tprivate RangeSelectionOption _rangeSelectionOption;\n\t\tprivate int _minInstanceNumber;\n\t\tprivate int _maxInstanceNumber;\n\t\tprivate CopyOption _copyOption;\n\t\tprivate CopyRangeOption _copyRangeOption;\n\t\tprivate int _copyRangeStart;\n\t\tprivate int _copyRangeEnd;\n\t\tprivate int _rangeMinimum;\n\t\tprivate int _rangeMaximum;\n\t\tprivate bool _updatingCopyRange;\n\t\tprivate int _copyRangeInterval;\n\t\tprivate static readonly int _rangeMinInterval = 2;\n\t\tprivate int _rangeMaxInterval;\n\t\tprivate string _customRange;\n\t\tinternal CopySubsetToClipboardComponent(IDesktopWindow desktopWindow)\n\t\t{\n\t\t\tPlatform.CheckForNullReference(desktopWindow, \"desktopWindow\");\n\t\t\t_desktopWindow = desktopWindow;\n\t\t}\n\t\t#region Internal / Private Methods\n\t\tinternal IDesktopWindow DesktopWindow\n\t\t{\n\t\t\tget { return _desktopWindow; }\t\n\t\t}\n\t\tinternal void Close()\n\t\t{\n\t\t\tthis.Host.Exit();\n\t\t}\n\t\tprivate void OnWorkspaceChanged(object sender, ItemEventArgs<Workspace> e)\n\t\t{\n\t\t\tIImageViewer viewer = null;\n\t\t\tif (_desktopWindow.ActiveWorkspace != null)\n\t\t\t\tviewer = ImageViewerComponent.GetAsImageViewer(_desktopWindow.ActiveWorkspace);\n\t\t\t\n\t\t\tSetActiveViewer(viewer);\n\t\t}\n\t\tprivate void OnImageBoxSelected(object sender, ImageBoxSelectedEventArgs e)\n\t\t{\n\t\t\tCurrentDisplaySet = e.SelectedImageBox.DisplaySet;\n\t\t}\n\t\tprivate void OnDisplaySetSelected(object sender, DisplaySetSelectedEventArgs e)\n\t\t{\n\t\t\tCurrentDisplaySet = e.SelectedDisplaySet;\n\t\t}\n\t\tprivate void SetActiveViewer(IImageViewer viewer)\n\t\t{\n\t\t\tif (_activeViewer != null)\n\t\t\t{\n\t\t\t\t_activeViewer.EventBroker.ImageBoxSelected -= OnImageBoxSelected;\n\t\t\t\t_activeViewer.EventBroker.DisplaySetSelected -= OnDisplaySetSelected;\n\t\t\t}\n\t\t\t_activeViewer = viewer;\n\t\t\tIDisplaySet displaySet = null;\n\t\t\tif (_activeViewer != null)\n\t\t\t{\n\t\t\t\t_activeViewer.EventBroker.ImageBoxSelected += OnImageBoxSelected;\n\t\t\t\t_activeViewer.EventBroker.DisplaySetSelected += OnDisplaySetSelected;\n\t\t\t\tif (_activeViewer.SelectedImageBox != null)\n\t\t\t\t\tdisplaySet = _activeViewer.SelectedImageBox.DisplaySet;\n\t\t\t}\n\t\t\tCurrentDisplaySet = displaySet;\n\t\t}\n\t\tprivate void CopyToClipboardInternal()\n\t\t{\n\t\t\tif (this.HasValidationErrors)\n\t\t\t{\n\t\t\t\tbase.ShowValidation(true);\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tIImageSelectionStrategy strategy;\n\t\t\t\tif (CopyRange)\n\t\t\t\t{\n\t\t\t\t\tint interval = 1;\n\t\t\t\t\tif (CopyRangeAtInterval)\n\t\t\t\t\t\tinterval = CopyRangeInterval;\n\t\t\t\t\tstrategy = new RangeImageSelectionStrategy(CopyRangeStart, CopyRangeEnd, interval, UseInstanceNumber);\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tstrategy = new CustomImageSelectionStrategy(CustomRange, RangeMinimum, RangeMaximum, UseInstanceNumber);\n\t\t\t\t}\n\t\t\t\tClipboard.Add(CurrentDisplaySet, strategy);\n\t\t\t\tthis.Host.Exit();\n\t\t\t}\n\t\t}\n\t\t#endregion\n\t\tpublic override void Start()\n\t\t{\n\t\t\t_desktopWindow.Workspaces.ItemActivationChanged += OnWorkspaceChanged;\n\t\t\tOnWorkspaceChanged(null, null);\n\t\t\tbase.Start();\n\t\t}\n\t\tpublic override void Stop()\n\t\t{\n\t\t\t_desktopWindow.Workspaces.ItemActivationChanged -= OnWorkspaceChanged;\n\t\t\tSetActiveViewer(null);\n\t\t\tbase.Stop();\n\t\t}\n\t\t#region Validation Methods\n\t\t[ValidationMethodFor(\"CustomRange\")]\n\t\tprivate ValidationResult ValidateCustomRange()\n\t\t{\n\t\t\tList<Range> ranges;\n\t\t\tif (CopyCustom && !CustomImageSelectionStrategy.Parse(CustomRange, RangeMinimum, RangeMaximum, out ranges))\n\t\t\t\treturn new ValidationResult(false, SR.MessageCustomRangeInvalid);\n\t\t\treturn new ValidationResult(true, \"\");\n\t\t}\n\t\t[ValidationMethodFor(\"CopyRangeStart\")]\n\t\tprivate ValidationResult ValidateCopyRangeStart()\n\t\t{\n\t\t\tif (CopyRange && (CopyRangeStart < RangeMinimum || CopyRangeStart > CopyRangeEnd))\n\t\t\t\treturn new ValidationResult(false, SR.MessageStartValueOutOfRange);\n\t\t\treturn new ValidationResult(true, \"\");\n\t\t}\n\t\t[ValidationMethodFor(\"CopyRangeEnd\")]\n\t\tprivate ValidationResult ValidateCopyRangeEnd()\n\t\t{\n\t\t\tif (CopyRange)\n\t\t\t{\n\t\t\t\tif (CopyRangeEnd < CopyRangeStart || CopyRangeEnd > RangeMaximum)\n\t\t\t\t\treturn new ValidationResult(false, SR.MessageEndValueOutOfRange);\n\t\t\t}\n\t\t\treturn new ValidationResult(true, \"\");\n\t\t}\n\t\t[ValidationMethodFor(\"CopyRangeInterval\")]\n\t\tprivate ValidationResult ValidateCopyRangeInterval()\n\t\t{\n\t\t\tif (CopyRange && CopyRangeAtInterval)\n\t\t\t{\n\t\t\t\tif (CopyRangeInterval < RangeMinInterval || CopyRangeInterval > RangeMaxInterval)\n\t\t\t\t\treturn new ValidationResult(false, SR.MessageRangeIntervalInvalid);\n\t\t\t}\n\t\t\treturn new ValidationResult(true, \"\");\n\t\t}\n\t\t#endregion\n\t\tprivate IDisplaySet CurrentDisplaySet\n\t\t{\n\t\t\tget { return _currentDisplaySet; }\n\t\t\tset\n\t\t\t{\n\t\t\t\tif (_currentDisplaySet == value)\n\t\t\t\t\treturn;\n\t\t\t\t_currentDisplaySet = value;\n\t\t\t\tUpdateUseInstanceNumber();\n\t\t\t\tUpdateCopyRange();\n\t\t\t\tUpdateCopyCustom();\n\t\t\t\tNotifyPropertyChanged(\"SourceDisplaySetDescription\");\n\t\t\t\tNotifyPropertyChanged(\"UsePositionNumberEnabled\");\n\t\t\t\tNotifyPropertyChanged(\"CopyRangeEnabled\");\n\t\t\t\tNotifyPropertyChanged(\"CopyRangeAllEnabled\");\n\t\t\t\tNotifyPropertyChanged(\"CopyRangeStartEnabled\");\n\t\t\t\tNotifyPropertyChanged(\"CopyRangeEndEnabled\");\n\t\t\t\tNotifyPropertyChanged(\"Enabled\");\n\t\t\t}\n\t\t}\n\t\tprivate void UpdateUseInstanceNumber()\n\t\t{\n\t\t\t//only change values when there is a display set.\n\t\t\tif (CurrentDisplaySet != null)\n\t\t\t{\n\t\t\t\t_numberOfImages = 0;\n\t\t\t\t_minInstanceNumber = int.MaxValue;\n\t\t\t\t_maxInstanceNumber = int.MinValue;\n\t\t\t\t_numberOfImages = CurrentDisplaySet.PresentationImages.Count;\n\t\t\t\tforeach (IPresentationImage image in CurrentDisplaySet.PresentationImages)\n\t\t\t\t{\n\t\t\t\t\tif (image is IImageSopProvider)\n\t\t\t\t\t{\n\t\t\t\t\t\tIImageSopProvider provider = (IImageSopProvider)image;\n\t\t\t\t\t\tif (provider.ImageSop.InstanceNumber < _minInstanceNumber)\n\t\t\t\t\t\t\t_minInstanceNumber = provider.ImageSop.InstanceNumber;\n\t\t\t\t\t\tif (provider.ImageSop.InstanceNumber > _maxInstanceNumber)\n\t\t\t\t\t\t\t_maxInstanceNumber = provider.ImageSop.InstanceNumber;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (!UseInstanceNumberEnabled)\n\t\t\t\t\tUseInstanceNumber = false;\n\t\t\t}\n\t\t\tNotifyPropertyChanged(\"UseInstanceNumberEnabled\");\n\t\t}\n\t\tprivate void UpdateCopyRange()\n\t\t{\n\t\t\tif (CurrentDisplaySet == null)\n\t\t\t\treturn;\n\t\t\t_updatingCopyRange = true;\n\t\t\tif (UseInstanceNumber)\n\t\t\t{\n\t\t\t\tRangeMinimum = _minInstanceNumber;\n\t\t\t\tRangeMaximum = _maxInstanceNumber;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tRangeMinimum = 1;\n\t\t\t\tRangeMaximum = _currentDisplaySet == null ? 1 : _currentDisplaySet.PresentationImages.Count;\n\t\t\t}\n\t\t\tCopyRangeStart = RangeMinimum;\n\t\t\tCopyRangeEnd = RangeMaximum;\n\t\t\t_updatingCopyRange = false;\n\t\t\tUpdateRangeInterval();\n\t\t}\n\t\tprivate void UpdateRangeInterval()\n\t\t{\n\t\t\tif (_updatingCopyRange)\n\t\t\t\treturn;\n\t\t\tif (CurrentDisplaySet != null)\n\t\t\t{\n\t\t\t\tRangeMaxInterval = Math.Max(RangeMinInterval, CopyRangeEnd - CopyRangeStart);\n\t\t\t\tCopyRangeInterval = Math.Min(CopyRangeInterval, RangeMaxInterval);\n\t\t\t\tCopyRangeInterval = Math.Max(CopyRangeInterval, RangeMinInterval);\n\t\t\t\tif (!CopyRangeAtIntervalEnabled)\n\t\t\t\t\tCopyRangeAtInterval = false;\n\t\t\t}\n\t\t\tNotifyPropertyChanged(\"CopyRangeIntervalEnabled\");\n\t\t\tNotifyPropertyChanged(\"CopyRangeAtIntervalEnabled\");\n\t\t}\n\t\tprivate void UpdateCopyCustom()\n\t\t{\n\t\t\tif (CurrentDisplaySet != null)\n\t\t\t{\n\t\t\t\tif (!CopyCustomEnabled)\n\t\t\t\t\tCopyCustom = false;\n\t\t\t}\n\t\t\tNotifyPropertyChanged(\"CustomRangeEnabled\");\n\t\t\tNotifyPropertyChanged(\"CopyCustomEnabled\");\n\t\t}\n\t\t#region Presentation Model\n\t\tpublic string SourceDisplaySetDescription\n\t\t{\n\t\t\tget\n\t\t\t{\n\t\t\t\tif (this.CurrentDisplaySet != null)\n\t\t\t\t\treturn this.CurrentDisplaySet.Name;\n\t\t\t\telse\n\t\t\t\t\treturn SR.MessageNotApplicable;\n\t\t\t}\t\n\t\t}\n\t\tpublic bool UsePositionNumber\n\t\t{\n\t\t\tget { return _rangeSelectionOption == RangeSelectionOption.Position; }\n\t\t\tset\n\t\t\t{\n\t\t\t\tif (!value)\n\t\t\t\t{\n\t\t\t\t\t_rangeSelectionOption = RangeSelectionOption.InstanceNumber;\n\t\t\t\t\tNotifyPropertyChanged(\"UsePositionNumber\");\n\t\t\t\t\tNotifyPropertyChanged(\"UseInstanceNumber\");\n\t\t\t\t\tUpdateCopyRange();\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tpublic bool UsePositionNumberEnabled\n\t\t{\n\t\t\tget { return Enabled; }\t\n\t\t}\n\t\tpublic bool UseInstanceNumber\n\t\t{\n\t\t\tget { return _rangeSelectionOption == RangeSelectionOption.InstanceNumber; }\n\t\t\tset\n\t\t\t{\n\t\t\t\tif (!value)\n\t\t\t\t{\n\t\t\t\t\t_rangeSelectionOption = RangeSelectionOption.Position;\n\t\t\t\t\tNotifyPropertyChanged(\"UseInstanceNumber\");\n\t\t\t\t\tNotifyPropertyChanged(\"UsePositionNumber\");\n\t\t\t\t\tUpdateCopyRange();\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tpublic bool UseInstanceNumberEnabled\n\t\t{\n\t\t\tget { return Enabled && _minInstanceNumber != int.MaxValue && _maxInstanceNumber != int.MinValue; }\n\t\t}\n\t\tpublic int RangeMinimum\n\t\t{\n\t\t\tget { return _rangeMinimum; }\n\t\t\tprivate set\n\t\t\t{\n\t\t\t\tif (_rangeMinimum == value)\n\t\t\t\t\treturn;\n\t\t\t\t_rangeMinimum = value;\n\t\t\t\tNotifyPropertyChanged(\"RangeMinimum\");\n\t\t\t}\n\t\t}\n\t\tpublic int RangeMaximum\n\t\t{\n\t\t\tget { return _rangeMaximum; }\n\t\t\tprivate set\n\t\t\t{\n\t\t\t\tif (_rangeMaximum == value)\n\t\t\t\t\treturn;\n\t\t\t\t_rangeMaximum = value;\n\t\t\t\tNotifyPropertyChanged(\"RangeMaximum\");\n\t\t\t}\n\t\t}\n\t\tpublic int RangeMinInterval\n\t\t{\n\t\t\tget { return _rangeMinInterval; }\t\n\t\t}\n\t\tpublic int RangeMaxInterval\n\t\t{\n\t\t\tget { return _rangeMaxInterval; }\n\t\t\tprivate set\n\t\t\t{\n\t\t\t\tif (value == _rangeMaxInterval)\n\t\t\t\t\treturn;\n\t\t\t\t_rangeMaxInterval = value;\n\t\t\t\tNotifyPropertyChanged(\"RangeMaxInterval\");\n\t\t\t}\n\t\t}\n\t\t\n\t\tpublic bool CopyRange\n\t\t{\n\t\t\tget { return _copyOption == CopyOption.CopyRange; }\n\t\t\tset\n\t\t\t{\n\t\t\t\tif (!value)\n\t\t\t\t{\n\t\t\t\t\t_copyOption = CopyOption.CopyCustom;\n\t\t\t\t\tNotifyPropertyChanged(\"CopyRange\");\n\t\t\t\t\tNotifyPropertyChanged(\"CopyCustom\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tpublic bool CopyRangeEnabled\n\t\t{\n\t\t\tget { return Enabled; }\t\n\t\t}\n\t\tpublic bool CopyRangeAll\n\t\t{\n\t\t\tget { return _copyRangeOption == CopyRangeOption.CopyAll; }\n\t\t\tset\n\t\t\t{\n\t\t\t\tif (!value)\n\t\t\t\t{\n\t\t\t\t\t_copyRangeOption = CopyRangeOption.CopyAtInterval;\n\t\t\t\t\tNotifyPropertyChanged(\"CopyRangeAll\");\n\t\t\t\t\tNotifyPropertyChanged(\"CopyRangeAtInterval\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tpublic bool CopyRangeAllEnabled\n\t\t{\n\t\t\tget { return Enabled && CopyRange; }\t\n\t\t}\n\t\tpublic int CopyRangeStart\n\t\t{\n\t\t\tget { return _copyRangeStart; }\n\t\t\tset\n\t\t\t{\n\t\t\t\tif (value == _copyRangeStart)\n\t\t\t\t\treturn;\n\t\t\t\t_copyRangeStart = value;\n\t\t\t\tNotifyPropertyChanged(\"CopyRangeStart\");\n\t\t\t\tUpdateRangeInterval();\n\t\t\t}\n\t\t}\n\t\tpublic bool CopyRangeStartEnabled\n\t\t{\n\t\t\tget { return Enabled && CopyRange; }\n\t\t}\n\t\tpublic int CopyRangeEnd\n\t\t{\n\t\t\tget { return _copyRangeEnd; }\n\t\t\tset\n\t\t\t{\n\t\t\t\tif (value == _copyRangeEnd)\n\t\t\t\t\treturn;\n\t\t\t\t_copyRangeEnd = value;\n\t\t\t\tNotifyPropertyChanged(\"CopyRangeEnd\");\n\t\t\t\tUpdateRangeInterval();\n\t\t\t}\n\t\t}\n\t\tpublic bool CopyRangeEndEnabled\n\t\t{\n\t\t\tget { return Enabled && CopyRange; }\n\t\t}\n\t\tpublic bool CopyRangeAtInterval\n\t\t{\n\t\t\tget { return _copyRangeOption == CopyRangeOption.CopyAtInterval; }\n\t\t\tset\n\t\t\t{\n\t\t\t\tif (!value)\n\t\t\t\t{\n\t\t\t\t\t_copyRangeOption = CopyRangeOption.CopyAll;\n\t\t\t\t\tNotifyPropertyChanged(\"CopyRangeAtInterval\");\n\t\t\t\t\tNotifyPropertyChanged(\"CopyRangeAll\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tpublic bool CopyRangeAtIntervalEnabled\n\t\t{\n\t\t\tget { return CopyRange && CopyRangeEnabled && (CopyRangeEnd - CopyRangeStart) >= RangeMinInterval; }\n\t\t}\n\t\tpublic int CopyRangeInterval\n\t\t{\n\t\t\tget { return _copyRangeInterval; }\n\t\t\tset\n\t\t\t{\n\t\t\t\tif (value == _copyRangeInterval)\n\t\t\t\t\treturn;\n\t\t\t\t_copyRangeInterval = value;\n\t\t\t\tNotifyPropertyChanged(\"CopyRangeInterval\");\n\t\t\t}\n\t\t}\n\t\tpublic bool CopyRangeIntervalEnabled\n\t\t{\n\t\t\tget { return CopyRangeAtInterval && CopyRangeAtIntervalEnabled; }\n\t\t}\n\t\tpublic bool CopyCustom\n\t\t{\n\t\t\tget { return _copyOption == CopyOption.CopyCustom; }\n\t\t\tset\n\t\t\t{\n\t\t\t\tif (!value)\n\t\t\t\t{\n\t\t\t\t\t_copyOption = CopyOption.CopyRange;\n\t\t\t\t\tNotifyPropertyChanged(\"CopyCustom\");\n\t\t\t\t\tNotifyPropertyChanged(\"CopyRange\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tpublic bool CopyCustomEnabled\n\t\t{\n", "outputs": ["\t\t\tget { return Enabled && _numberOfImages > 2; }"], "input_length": 1874, "output_length": 11, "length": 1885, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "d9f7aad3f79be6323ef225f46f48f395bed42f2a1d788093f86c2810238f50c4"}
{"input": "", "context": "#!/usr/bin/python\n# -*- coding: utf-8 -*-\n# (c) 2013, Nimbis Services, Inc.\n#\n# This file is part of Ansible\n#\n# Ansible is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# Ansible is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.\n#\nDOCUMENTATION = \"\"\"\nmodule: htpasswd\nversion_added: \"1.3\"\nshort_description: manage user files for basic authentication\ndescription:\n  - Add and remove username/password entries in a password file using htpasswd.\n  - This is used by web servers such as Apache and Nginx for basic authentication.\noptions:\n  path:\n    required: true\n    aliases: [ dest, destfile ]\n    description:\n      - Path to the file that contains the usernames and passwords\n  name:\n    required: true\n    aliases: [ username ]\n    description:\n      - User name to add or remove\n  password:\n    required: false\n    description:\n      - Password associated with user.\n      - Must be specified if user does not exist yet.\n  crypt_scheme:\n    required: false\n    choices: [\"apr_md5_crypt\", \"des_crypt\", \"ldap_sha1\", \"plaintext\"]\n    default: \"apr_md5_crypt\"\n    description:\n      - Encryption scheme to be used.\n  state:\n    required: false\n    choices: [ present, absent ]\n    default: \"present\"\n    description:\n      - Whether the user entry should be present or not\n  create:\n    required: false\n    choices: [ \"yes\", \"no\" ]\n    default: \"yes\"\n    description:\n      - Used with C(state=present). If specified, the file will be created\n        if it does not already exist. If set to \"no\", will fail if the\n        file does not exist\nnotes:\n  - \"This module depends on the I(passlib) Python library, which needs to be installed on all target systems.\"\n  - \"On Debian, Ubuntu, or Fedora: install I(python-passlib).\"\n  - \"On RHEL or CentOS: Enable EPEL, then install I(python-passlib).\"\nrequires: [ passlib>=1.6 ]\nauthor: \"Lorin Hochstein (@lorin)\"\n\"\"\"\nEXAMPLES = \"\"\"\n# Add a user to a password file and ensure permissions are set\n- htpasswd: path=/etc/nginx/passwdfile name=janedoe password=9s36?;fyNp owner=root group=www-data mode=0640\n# Remove a user from a password file\n- htpasswd: path=/etc/apache2/passwdfile name=foobar state=absent\n\"\"\"\nimport os\nimport tempfile\nfrom distutils.version import StrictVersion\ntry:\n    from passlib.apache import HtpasswdFile\n    import passlib\nexcept ImportError:\n    passlib_installed = False\nelse:\n    passlib_installed = True\ndef create_missing_directories(dest):\n    destpath = os.path.dirname(dest)\n    if not os.path.exists(destpath):\n        os.makedirs(destpath)\ndef present(dest, username, password, crypt_scheme, create, check_mode):\n    \"\"\" Ensures user is present\n    Returns (msg, changed) \"\"\"\n    if not os.path.exists(dest):\n        if not create:\n            raise ValueError('Destination %s does not exist' % dest)\n        if check_mode:\n            return (\"Create %s\" % dest, True)\n        create_missing_directories(dest)\n        if StrictVersion(passlib.__version__) >= StrictVersion('1.6'):\n            ht = HtpasswdFile(dest, new=True, default_scheme=crypt_scheme)\n        else:\n            ht = HtpasswdFile(dest, autoload=False, default=crypt_scheme)\n        if getattr(ht, 'set_password', None):\n            ht.set_password(username, password)\n        else:\n            ht.update(username, password)\n        ht.save()\n        return (\"Created %s and added %s\" % (dest, username), True)\n    else:\n        if StrictVersion(passlib.__version__) >= StrictVersion('1.6'):\n            ht = HtpasswdFile(dest, new=False, default_scheme=crypt_scheme)\n        else:\n            ht = HtpasswdFile(dest, default=crypt_scheme)\n        found = None\n        if getattr(ht, 'check_password', None):\n            found = ht.check_password(username, password)\n        else:\n            found = ht.verify(username, password)\n        if found:\n            return (\"%s already present\" % username, False)\n        else:\n            if not check_mode:\n                if getattr(ht, 'set_password', None):\n                    ht.set_password(username, password)\n                else:\n                    ht.update(username, password)\n                ht.save()\n            return (\"Add/update %s\" % username, True)\ndef absent(dest, username, check_mode):\n    \"\"\" Ensures user is absent\n    Returns (msg, changed) \"\"\"\n    if not os.path.exists(dest):\n        raise ValueError(\"%s does not exists\" % dest)\n    if StrictVersion(passlib.__version__) >= StrictVersion('1.6'):\n        ht = HtpasswdFile(dest, new=False)\n    else:\n        ht = HtpasswdFile(dest)\n    if username not in ht.users():\n        return (\"%s not present\" % username, False)\n    else:\n        if not check_mode:\n            ht.delete(username)\n            ht.save()\n        return (\"Remove %s\" % username, True)\ndef check_file_attrs(module, changed, message):\n    file_args = module.load_file_common_arguments(module.params)\n    if module.set_fs_attributes_if_different(file_args, False):\n        if changed:\n            message += \" and \"\n        changed = True\n        message += \"ownership, perms or SE linux context changed\"\n    return message, changed\ndef main():\n    arg_spec = dict(\n        path=dict(required=True, aliases=[\"dest\", \"destfile\"]),\n        name=dict(required=True, aliases=[\"username\"]),\n        password=dict(required=False, default=None),\n        crypt_scheme=dict(required=False, default=None),\n        state=dict(required=False, default=\"present\"),\n        create=dict(type='bool', default='yes'),\n    )\n    module = AnsibleModule(argument_spec=arg_spec,\n                           add_file_common_args=True,\n                           supports_check_mode=True)\n    path = module.params['path']\n    username = module.params['name']\n    password = module.params['password']\n    crypt_scheme = module.params['crypt_scheme']\n    state = module.params['state']\n    create = module.params['create']\n    check_mode = module.check_mode\n    if not passlib_installed:\n        module.fail_json(msg=\"This module requires the passlib Python library\")\n    # Check file for blank lines in effort to avoid \"need more than 1 value to unpack\" error.\n    try:\n        f = open(path, \"r\")\n    except IOError:\n        # No preexisting file to remove blank lines from\n        f = None\n    else:\n        try:\n", "outputs": ["            lines = f.readlines()"], "input_length": 1244, "output_length": 5, "length": 1249, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "970a2104d69ce52feafc5efa8f3415c71de14af9b3d9c6303289bdcd9c56c15a"}
{"input": "", "context": "// This is a MOD of Nerun's Distro SpawnGen (Engine r117) that works with default runuo proximity spawners.\nusing System;\nusing System.Collections.Generic;\nusing System.IO;\nusing Server.Mobiles;\nusing Server.Commands;\nnamespace Server\n{\n    public class SpawnGenerator\n    {\n        private static int m_Count;\n        private static int m_MapOverride = -1;\n        private static int m_IDOverride = -1;\n        private static double m_MinTimeOverride = -1;\n        private static double m_MaxTimeOverride = -1;\n        private const bool TotalRespawn = false;\n        private const int Team = 0;\n        public static void Initialize()\n        {\n            CommandSystem.Register(\"SpawnGen\", AccessLevel.Administrator, new CommandEventHandler(SpawnGen_OnCommand));\n        }\n        [Usage(\"SpawnGen [<filename>]|[unload <id>]|[remove <region>|<rect>]|[save <region>|<rect>][savebyhand][cleanfacet]\")]\n        [Description(\"Complex command, it generate and remove spawners.\")]\n        private static void SpawnGen_OnCommand(CommandEventArgs e)\n        {\n            //wrong use\n            if (e.ArgString == null || e.ArgString == \"\")\n            {\n                e.Mobile.SendMessage(\"Usage: SpawnGen [<filename>]|[remove <region>|<rect>|<ID>]|[save <region>|<rect>|<ID>]\");\n            }\n            //[spawngen remove and [spawngen remove region\n            else if (e.Arguments[0].ToLower() == \"remove\" && e.Arguments.Length == 2)\n            {\n                Remove(e.Mobile, e.Arguments[1].ToLower());\n            }\n            //[spawngen remove x1 y1 x2 y2\n            else if (e.Arguments[0].ToLower() == \"remove\" && e.Arguments.Length == 5)\n            {\n                int x1 = Utility.ToInt32(e.Arguments[1]);\n                int y1 = Utility.ToInt32(e.Arguments[2]);\n                int x2 = Utility.ToInt32(e.Arguments[3]);\n                int y2 = Utility.ToInt32(e.Arguments[4]);\n                RemoveByCoord(e.Mobile, x1, y1, x2, y2);\n            }\n            //[spawngen remove\n            else if (e.ArgString.ToLower() == \"remove\")\n            {\n                Remove(e.Mobile, \"\");\n            }\n            //[spawngen save and [spawngen save region\n            else if (e.Arguments[0].ToLower() == \"save\" && e.Arguments.Length == 2)\n            {\n                Save(e.Mobile, e.Arguments[1].ToLower());\n            }\n            //[spawngen savebyhand\n            else if (e.Arguments[0].ToLower() == \"savebyhand\")\n            {\n                SaveByHand();\n            }\n            //[spawngen cleanfacet\n            else if (e.Arguments[0].ToLower() == \"cleanfacet\")\n            {\n                CleanFacet(e.Mobile);\n            }\n            ////[spawngen save x1 y1 x2 y2\n            else if (e.Arguments[0].ToLower() == \"save\" && e.Arguments.Length == 5)\n            {\n                int x1 = Utility.ToInt32(e.Arguments[1]);\n                int y1 = Utility.ToInt32(e.Arguments[2]);\n                int x2 = Utility.ToInt32(e.Arguments[3]);\n                int y2 = Utility.ToInt32(e.Arguments[4]);\n                SaveByCoord(e.Mobile, x1, y1, x2, y2);\n            }\n            //[spawngen save\n            else if (e.ArgString.ToLower() == \"save\")\n            {\n                Save(e.Mobile, \"\");\n            }\n            else\n            {\n                Parse(e.Mobile, e.ArgString);\n            }\n        }\n        public static void Talk(string alfa)\n        {\n            World.Broadcast(0x35, true, \"Spawns are being {0}, please wait.\", alfa);\n        }\n        public static string GetRegion(Item item)\n        {\n            Region re = Region.Find(item.Location, item.Map);\n            string regname = re.ToString().ToLower();\n            return regname;\n        }\n        //[spawngen remove and [spawngen remove region\n        private static void Remove(Mobile from, string region)\n        {\n            DateTime aTime = DateTime.Now;\n            int count = 0;\n            List<Item> itemtodo = new List<Item>();\n            string prefix = Server.Commands.CommandSystem.Prefix;\n            if (region == null || region == \"\")\n            {\n                CommandSystem.Handle(from, String.Format(\"{0}Global remove where IntelliSpawner\", prefix));\n            }\n            else\n            {\n                foreach (Item itemdel in World.Items.Values)\n                {\n                    if (itemdel is IntelliSpawner && itemdel.Map == from.Map)\n                    {\n                        if (GetRegion(itemdel) == region)\n                        {\n                            itemtodo.Add(itemdel);\n                            count += 1;\n                        }\n                    }\n                }\n                GenericRemove(itemtodo, count, aTime);\n            }\n        }\n        //[spawngen remove x1 y1 x2 y2\n        private static void RemoveByCoord(Mobile from, int x1, int y1, int x2, int y2)\n        {\n            DateTime aTime = DateTime.Now;\n            int count = 0;\n            List<Item> itemtodo = new List<Item>();\n            foreach (Item itemremove in World.Items.Values)\n            {\n                if (itemremove is IntelliSpawner && ((itemremove.X >= x1 && itemremove.X <= x2) && (itemremove.Y >= y1 && itemremove.Y <= y2) && itemremove.Map == from.Map))\n                {\n                    itemtodo.Add(itemremove);\n                    count += 1;\n                }\n            }\n            GenericRemove(itemtodo, count, aTime);\n        }\n        //[spawngen cleanfacet\n        public static void CleanFacet(Mobile from)\n        {\n            DateTime aTime = DateTime.Now;\n            int count = 0;\n            List<Item> itemtodo = new List<Item>();\n            foreach (Item itemremove in World.Items.Values)\n            {\n                if (itemremove is IntelliSpawner && itemremove.Map == from.Map && itemremove.Parent == null)\n                {\n                    itemtodo.Add(itemremove);\n                    count += 1;\n                }\n            }\n            GenericRemove(itemtodo, count, aTime);\n        }\n        private static void GenericRemove(List<Item> colecao, int count, DateTime aTime)\n        {\n            if (colecao.Count == 0)\n            {\n                World.Broadcast(0x35, true, \"There are no IntelliSpawners to be removed.\");\n            }\n            else\n            {\n                Talk(\"removed\");\n                foreach (Item item in colecao)\n                {\n                    item.Delete();\n                }\n                DateTime bTime = DateTime.Now;\n                World.Broadcast(0x35, true, \"{0} IntelliSpawners have been removed in {1:F1} seconds.\", count, (bTime - aTime).TotalSeconds);\n            }\n        }\n        //[spawngen save and [spawngen save region\n        private static void Save(Mobile from, string region)\n        {\n            DateTime aTime = DateTime.Now;\n            int count = 0;\n            List<Item> itemtodo = new List<Item>();\n            string mapanome = region;\n            if (region == \"\")\n                mapanome = \"Spawns\";\n            foreach (Item itemsave in World.Items.Values)\n            {\n                if (itemsave is IntelliSpawner && (region == null || region == \"\"))\n                {\n                    itemtodo.Add(itemsave);\n                    count += 1;\n                }\n                else if (itemsave is IntelliSpawner && itemsave.Map == from.Map)\n                {\n                    if (GetRegion(itemsave) == region)\n                    {\n                        itemtodo.Add(itemsave);\n                        count += 1;\n                    }\n                }\n            }\n            GenericSave(itemtodo, mapanome, count, aTime);\n        }\n        //[spawngen SaveByHand\n        private static void SaveByHand()\n        {\n            DateTime aTime = DateTime.Now;\n            int count = 0;\n            List<Item> itemtodo = new List<Item>();\n            string mapanome = \"SpawnsByHand\";\n            foreach (Item itemsave in World.Items.Values)\n            {\n                itemtodo.Add(itemsave);\n                count += 1;\n            }\n            GenericSave(itemtodo, mapanome, count, aTime);\n        }\n        //[spawngen save x1 y1 x2 y2\n        private static void SaveByCoord(Mobile from, int x1, int y1, int x2, int y2)\n        {\n            DateTime aTime = DateTime.Now;\n            int count = 0;\n            List<Item> itemtodo = new List<Item>();\n            string mapanome = \"SpawnsByCoords\";\n            foreach (Item itemsave in World.Items.Values)\n            {\n                if (itemsave is IntelliSpawner && ((itemsave.X >= x1 && itemsave.X <= x2) && (itemsave.Y >= y1 && itemsave.Y <= y2) && itemsave.Map == from.Map))\n                {\n                    itemtodo.Add(itemsave);\n                    count += 1;\n                }\n            }\n            GenericSave(itemtodo, mapanome, count, aTime);\n        }\n        private static void GenericSave(List<Item> colecao, string mapa, int count, DateTime startTime)\n        {\n            List<Item> itemssave = new List<Item>(colecao);\n            string mapanome = mapa;\n            if (itemssave.Count == 0)\n            {\n                World.Broadcast(0x35, true, \"There are no IntelliSpawners to be saved.\");\n            }\n            else\n            {\n                Talk(\"saved\");\n                if (!Directory.Exists(\"Data/Nerun's Distro/Spawns\"))\n                    Directory.CreateDirectory(\"Data/Nerun's Distro/Spawns\");\n                string escreva = \"Data/Nerun's Distro/Spawns/\" + mapanome + \".map\";\n                using (StreamWriter op = new StreamWriter(escreva))\n                {\n                    foreach (IntelliSpawner itemsave2 in itemssave)\n                    {\n                        int mapnumber = 0;\n                        switch (itemsave2.Map.ToString())\n                        {\n                            case \"Felucca\":\n                                mapnumber = 1;\n                                break;\n                            case \"Trammel\":\n                                mapnumber = 2;\n                                break;\n                            case \"Ilshenar\":\n                                mapnumber = 3;\n                                break;\n                            case \"Malas\":\n                                mapnumber = 4;\n                                break;\n                            case \"Tokuno\":\n                                mapnumber = 5;\n                                break;\n                            case \"TerMur\":\n                                mapnumber = 6;\n                                break;\n                            default:\n                                mapnumber = 7;\n                                Console.WriteLine(\"Monster Parser: Warning, unknown map {0}\", itemsave2.Map);\n                                break;\n                        }\n                        string timer1a = itemsave2.MinDelay.ToString();\n                        string[] timer1b = timer1a.Split(':'); //Broke the string hh:mm:ss in an array (hh, mm, ss)\n                        int timer1c = (Utility.ToInt32(timer1b[0]) * 60) + Utility.ToInt32(timer1b[1]); //multiply hh * 60 to find mm, then add mm\n                        string timer1d = timer1c.ToString();\n                        if (Utility.ToInt32(timer1b[0]) == 0 && Utility.ToInt32(timer1b[1]) == 0) //If hh and mm are 0, use seconds, else drop ss\n                            timer1d = Utility.ToInt32(timer1b[2]) + \"s\";\n                        string timer2a = itemsave2.MaxDelay.ToString();\n                        string[] timer2b = timer2a.Split(':');\n                        int timer2c = (Utility.ToInt32(timer2b[0]) * 60) + Utility.ToInt32(timer2b[1]);\n                        string timer2d = timer2c.ToString();\n                        if (Utility.ToInt32(timer2b[0]) == 0 && Utility.ToInt32(timer2b[1]) == 0)\n                            timer2d = Utility.ToInt32(timer2b[2]) + \"s\";\n                        string towrite = \"\";\n                        string towriteA = \"\";\n                        string towriteB = \"\";\n                        string towriteC = \"\";\n                        string towriteD = \"\";\n                        string towriteE = \"\";\n                        if (itemsave2.SpawnNames.Count > 0)\n                            towrite = itemsave2.SpawnNames[0].ToString();\n                        for (int i = 1; i < itemsave2.SpawnNames.Count; ++i)\n                        {\n                            towrite = towrite + \":\" + itemsave2.SpawnNames[i].ToString();\n                        }\n                        op.WriteLine(\"*|{0}|{1}|{2}|{3}|{4}|{5}|{6}|{7}|{8}|{9}|{10}|{11}|{12}|{13}|{14}|{15}|{16}|{17}|{18}|{19}|{20}\", towrite, towriteA, towriteB, towriteC, towriteD, towriteE, itemsave2.X, itemsave2.Y, itemsave2.Z, mapnumber, timer1d, timer2d, itemsave2.HomeRange, itemsave2.WalkingRange, 1, itemsave2.Count, 0, 0, 0, 0, 0);\n                    }\n                }\n                DateTime endTime = DateTime.Now;\n                World.Broadcast(0x35, true, \"{0} spawns have been saved. The entire process took {1:F1} seconds.\", count, (endTime - startTime).TotalSeconds);\n            }\n        }\n        public static void Parse(Mobile from, string filename)\n        {\n            string monster_path1 = Path.Combine(Core.BaseDirectory, \"Data/Nerun's Distro/Spawns\");\n            string monster_path = Path.Combine(monster_path1, filename);\n            m_Count = 0;\n            if (File.Exists(monster_path))\n            {\n                from.SendMessage(\"Spawning {0}...\", filename);\n                m_MapOverride = -1;\n                m_IDOverride = -1;\n                m_MinTimeOverride = -1;\n                m_MaxTimeOverride = -1;\n                using (StreamReader ip = new StreamReader(monster_path))\n                {\n                    string line;\n                    while ((line = ip.ReadLine()) != null)\n                    {\n                        string[] split = line.Split('|');\n                        string[] splitA = line.Split(' ');\n                        if (splitA.Length == 2)\n                        {\n                            if (splitA[0].ToLower() == \"overridemap\")\n                                m_MapOverride = Utility.ToInt32(splitA[1]);\n                            if (splitA[0].ToLower() == \"overrideid\")\n                                m_IDOverride = Utility.ToInt32(splitA[1]);\n                            if (splitA[0].ToLower() == \"overridemintime\")\n                                m_MinTimeOverride = Utility.ToDouble(splitA[1]);\n                            if (splitA[0].ToLower() == \"overridemaxtime\")\n                                m_MaxTimeOverride = Utility.ToDouble(splitA[1]);\n                        }\n                        if (split.Length < 19)\n                            continue;\n                        switch (split[0].ToLower())\n                        {\n                            //Comment Line\n                            case \"##\":\n                                break;\n                            //Place By class\n                            case \"*\":\n                                PlaceNPC(split[2].Split(':'), split[3].Split(':'), split[4].Split(':'), split[5].Split(':'), split[6].Split(':'), split[7], split[8], split[9], split[10], split[11], split[12], split[14], split[13], split[15], split[16], split[17], split[18], split[19], split[20], split[21], split[1].Split(':'));\n                                break;\n                            //Place By Type\n                            case \"r\":\n                                PlaceNPC(split[2].Split(':'), split[3].Split(':'), split[4].Split(':'), split[5].Split(':'), split[6].Split(':'), split[7], split[8], split[9], split[10], split[11], split[12], split[14], split[13], split[15], split[16], split[17], split[18], split[19], split[20], split[1], \"bloodmoss\", \"sulfurousash\", \"spiderssilk\", \"mandrakeroot\", \"gravedust\", \"nightshade\", \"ginseng\", \"garlic\", \"batwing\", \"pigiron\", \"noxcrystal\", \"daemonblood\", \"blackpearl\");\n                                break;\n                        }\n                    }\n                }\n                m_MapOverride = -1;\n                m_IDOverride = -1;\n                m_MinTimeOverride = -1;\n                m_MaxTimeOverride = -1;\n                from.SendMessage(\"Done, added {0} spawners\", m_Count);\n            }\n            else\n            {\n                from.SendMessage(\"{0} not found!\", monster_path);\n            }\n        }\n        public static void PlaceNPC(string[] fakespawnsA, string[] fakespawnsB, string[] fakespawnsC, string[] fakespawnsD, string[] fakespawnsE, string sx, string sy, string sz, string sm, string smintime, string smaxtime, string swalkingrange, string shomerange, string sspawnid, string snpccount, string sfakecountA, string sfakecountB, string sfakecountC, string sfakecountD, string sfakecountE, params string[] types)\n        {\n            if (types.Length == 0)\n                return;\n            int x = Utility.ToInt32(sx);\n            int y = Utility.ToInt32(sy);\n            int z = Utility.ToInt32(sz);\n            int map = Utility.ToInt32(sm);\n            //MinTime\n            string samintime = smintime;\n            if (smintime.Contains(\"s\") || smintime.Contains(\"m\") || smintime.Contains(\"h\"))\n                samintime = smintime.Remove(smintime.Length - 1);\n            double dmintime = Utility.ToDouble(samintime);\n            if (m_MinTimeOverride != -1)\n                dmintime = m_MinTimeOverride;\n            TimeSpan mintime = TimeSpan.FromMinutes(dmintime);\n            if (smintime.Contains(\"s\"))\n                mintime = TimeSpan.FromSeconds(dmintime);\n            else if (smintime.Contains(\"m\"))\n                mintime = TimeSpan.FromMinutes(dmintime);\n            else if (smintime.Contains(\"h\"))\n                mintime = TimeSpan.FromHours(dmintime);\n            //MaxTime\n            string samaxtime = smaxtime;\n            if (smaxtime.Contains(\"s\") || smaxtime.Contains(\"m\") || smaxtime.Contains(\"h\"))\n                samaxtime = smaxtime.Remove(smaxtime.Length - 1);\n            double dmaxtime = Utility.ToDouble(samaxtime);\n            if (m_MaxTimeOverride != -1)\n            {\n                if (m_MaxTimeOverride < dmintime)\n                    dmaxtime = dmintime;\n                else\n                    dmaxtime = m_MaxTimeOverride;\n            }\n            TimeSpan maxtime = TimeSpan.FromMinutes(dmaxtime);\n            if (smaxtime.Contains(\"s\"))\n                maxtime = TimeSpan.FromSeconds(dmaxtime);\n            else if (smaxtime.Contains(\"m\"))\n                maxtime = TimeSpan.FromMinutes(dmaxtime);\n", "outputs": ["            else if (smaxtime.Contains(\"h\"))"], "input_length": 3214, "output_length": 10, "length": 3224, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "aac87a71c3a93e3775c56ca71b502fe7b11bdb1b8482860da049d26f32545952"}
{"input": "", "context": "/*\n * Copyright (C) 2018. OpenLattice, Inc.\n *\n * This program is free software: you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation, either version 3 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program.  If not, see <http://www.gnu.org/licenses/>.\n *\n * You can contact the owner of the copyright at support@openlattice.com\n *\n */\npackage com.openlattice.datastore.directory.controllers;\nimport com.auth0.client.mgmt.ManagementAPI;\nimport com.auth0.exception.Auth0Exception;\nimport com.auth0.json.mgmt.users.User;\nimport com.codahale.metrics.annotation.Timed;\nimport com.openlattice.assembler.Assembler;\nimport com.openlattice.authorization.*;\nimport com.openlattice.authorization.securable.SecurableObjectType;\nimport com.openlattice.directory.MaterializedViewAccount;\nimport com.openlattice.directory.PrincipalApi;\nimport com.openlattice.directory.UserDirectoryService;\nimport com.openlattice.directory.pojo.Auth0UserBasic;\nimport com.openlattice.directory.pojo.DirectedAclKeys;\nimport com.openlattice.organization.roles.Role;\nimport com.openlattice.organizations.HazelcastOrganizationService;\nimport com.openlattice.organizations.roles.SecurePrincipalsManager;\nimport com.openlattice.users.Auth0SyncService;\nimport com.openlattice.users.Auth0UtilsKt;\nimport org.springframework.http.MediaType;\nimport org.springframework.security.authentication.BadCredentialsException;\nimport org.springframework.web.bind.annotation.*;\nimport javax.inject.Inject;\nimport java.util.EnumSet;\nimport java.util.Map;\nimport java.util.Objects;\nimport java.util.Set;\nimport java.util.function.Function;\nimport java.util.stream.Collectors;\nimport static com.google.common.base.Preconditions.checkNotNull;\n@RestController\n@RequestMapping( PrincipalApi.CONTROLLER )\npublic class PrincipalDirectoryController implements PrincipalApi, AuthorizingComponent {\n    @Inject\n    private DbCredentialService dbCredService;\n    @Inject\n    private UserDirectoryService userDirectoryService;\n    @Inject\n    private SecurePrincipalsManager spm;\n    @Inject\n    private AuthorizationManager authorizations;\n    @Inject\n    private ManagementAPI managementApi;\n    @Inject\n    private Auth0SyncService syncService;\n    @Inject\n    private HazelcastOrganizationService organizationService;\n    @Inject\n    private Assembler assembler;\n    @Timed\n    @Override\n    @RequestMapping(\n            method = RequestMethod.POST,\n            produces = MediaType.APPLICATION_JSON_VALUE )\n    public SecurablePrincipal getSecurablePrincipal( @RequestBody Principal principal ) {\n        AclKey aclKey = spm.lookup( principal );\n        if ( !principal.getType().equals( PrincipalType.USER ) ) {\n            ensureReadAccess( aclKey );\n        }\n        return spm.getSecurablePrincipal( aclKey );\n    }\n    @Timed\n    @Override\n    @RequestMapping(\n            path = USERS,\n            method = RequestMethod.GET,\n            produces = MediaType.APPLICATION_JSON_VALUE )\n    public Map<String, User> getAllUsers() {\n        return userDirectoryService.getAllUsers();\n    }\n    @Timed\n    @Override\n    @RequestMapping(\n            path = { ROLES + CURRENT },\n            method = RequestMethod.GET,\n            produces = MediaType.APPLICATION_JSON_VALUE )\n    public Set<SecurablePrincipal> getCurrentRoles() {\n        return Principals.getCurrentPrincipals()\n                .stream()\n                .filter( principal -> principal.getType().equals( PrincipalType.ROLE ) )\n                .map( spm::lookup )\n                .filter( Objects::nonNull )\n                .map( aclKey -> spm.getSecurablePrincipal( aclKey ) )\n                .collect( Collectors.toSet() );\n    }\n    @Timed\n    @Override\n    @RequestMapping(\n            path = ROLES,\n            method = RequestMethod.GET,\n            produces = MediaType.APPLICATION_JSON_VALUE )\n    public Map<AclKey, Role> getAvailableRoles() {\n        return authorizations.getAuthorizedObjectsOfType(\n                Principals.getCurrentPrincipals(),\n                SecurableObjectType.Role,\n                EnumSet.of( Permission.READ ) )\n                .map( AclKey::new )\n                .collect( Collectors\n                        .toMap( Function.identity(), aclKey -> (Role) spm.getSecurablePrincipal( aclKey ) ) );\n    }\n    @Timed\n    @Override\n    @RequestMapping(\n            path = USERS + USER_ID_PATH,\n            method = RequestMethod.GET,\n            produces = MediaType.APPLICATION_JSON_VALUE )\n    public User getUser( @PathVariable( USER_ID ) String userId ) {\n        ensureAdminAccess();\n        return userDirectoryService.getUser( userId );\n    }\n    @Timed\n    @Override\n    @RequestMapping(\n            path = SYNC,\n            method = RequestMethod.GET )\n    public Void syncCallingUser() {\n        /*\n         * Important note: getCurrentUser() reads the principal id directly from auth token.\n         *\n         * This is safe since token has been validated and has an auth0 assigned unique id.\n         *\n         * It is very important that this is the *first* call for a new user.\n         */\n        Principal principal = checkNotNull( Principals.getCurrentUser() );\n        try {\n            final var user = Auth0UtilsKt.getUser( managementApi, principal.getId() );\n            syncService.syncUser( user );\n        } catch ( IllegalArgumentException | Auth0Exception e ) {\n            throw new BadCredentialsException( \"Unable to retrieve user profile information from auth0\", e );\n        }\n        return null;\n    }\n    @Timed\n    @Override\n    @RequestMapping(\n            path = DB,\n            method = RequestMethod.GET,\n            produces = MediaType.APPLICATION_JSON_VALUE )\n    public MaterializedViewAccount getMaterializedViewAccount() {\n        return dbCredService.getDbCredential( Principals.getCurrentSecurablePrincipal() );\n    }\n    @Timed\n    @Override\n    @RequestMapping(\n            path = DB + CREDENTIAL,\n            method = RequestMethod.POST,\n            produces = MediaType.APPLICATION_JSON_VALUE )\n    public MaterializedViewAccount regenerateCredential() {\n        var sp = Principals.getCurrentSecurablePrincipal();\n        return assembler.rollIntegrationAccount( sp.getId(), sp.getPrincipalType() );\n    }\n    @Timed\n    @Override\n    @GetMapping(\n            path = USERS + SEARCH + SEARCH_QUERY_PATH,\n            produces = MediaType.APPLICATION_JSON_VALUE )\n    public Map<String, Auth0UserBasic> searchAllUsers( @PathVariable( SEARCH_QUERY ) String searchQuery ) {\n        String wildcardSearchQuery = searchQuery + \"*\";\n        return userDirectoryService.searchAllUsers( wildcardSearchQuery );\n    }\n    @Timed\n    @Override\n    @GetMapping(\n            path = USERS + SEARCH_EMAIL + EMAIL_SEARCH_QUERY_PATH,\n            produces = MediaType.APPLICATION_JSON_VALUE )\n    public Map<String, Auth0UserBasic> searchAllUsersByEmail( @PathVariable( SEARCH_QUERY ) String emailSearchQuery ) {\n        // to search by an exact email, the search query must be in this format: email.raw:\"hristo@openlattice.com\"\n        // https://auth0.com/docs/api/management/v2/user-search#search-by-email\n        String exactEmailSearchQuery = \"email.raw:\\\"\" + emailSearchQuery + \"\\\"\";\n        return userDirectoryService.searchAllUsers( exactEmailSearchQuery );\n    }\n    @Override\n    public AuthorizationManager getAuthorizationManager() {\n        return authorizations;\n    }\n    @Timed\n    @Override\n    @PostMapping(\n            path = UPDATE,\n            consumes = MediaType.APPLICATION_JSON_VALUE )\n    public Void addPrincipalToPrincipal( @RequestBody DirectedAclKeys directedAclKeys ) {\n", "outputs": ["        ensureWriteAccess( directedAclKeys.getTarget() );"], "input_length": 1009, "output_length": 7, "length": 1016, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "164aec864a51cf8b5ba57ee33f90f6f54c16205eaba077c9aabcbb578fb05ea6"}
{"input": "", "context": "package ch.sfdr.fractals.gui.component;\nimport java.awt.GridBagConstraints;\nimport java.awt.Insets;\n/**\n * GBC, a small helper class to create GridBagConstraints in a more readable way\n * with less typing: just use the static methods when adding a component, eg.\n * <code>\n * \t\tcontainer.add(someComponent, GBC.get(0, 0, 1, 1, 'b'));\n * </code>\n * Imported from another (old) project, adopted a bit\n */\npublic final class GBC\n{\n\tprivate static char DEFAULT_FILL = 'n';\n\tprivate static String DEFAULT_ANCHOR = \"W\";\n\tprivate static String[] ANCHOR_STRINGS = {\n\t\t\"n\", \"ne\", \"e\", \"se\", \"s\", \"sw\", \"w\", \"nw\", \"c\"\n\t};\n\tprivate static int[] ANCHOR_VALUES = {\n\t\tGridBagConstraints.NORTH, GridBagConstraints.NORTHEAST,\n\t\tGridBagConstraints.EAST, GridBagConstraints.SOUTHEAST,\n\t\tGridBagConstraints.SOUTH, GridBagConstraints.SOUTHWEST,\n\t\tGridBagConstraints.WEST, GridBagConstraints.NORTHWEST,\n\t\tGridBagConstraints.CENTER\n\t};\n\tprivate static int getAnchor(String str)\n\t{\n\t\tstr = str.toLowerCase();\n\t\tfor (int i = 0; i < ANCHOR_STRINGS.length; i++) {\n\t\t\tif (str.equals(ANCHOR_STRINGS[i]))\n\t\t\t\treturn ANCHOR_VALUES[i];\n\t\t}\n\t\treturn -1;\n\t}\n\tprivate static int getFill(char c)\n\t{\n\t\tswitch (c) {\n\t\tcase 'n':\n\t\tcase 'N':\n\t\t\treturn GridBagConstraints.NONE;\n\t\tcase 'v':\n\t\tcase 'V':\n\t\t\treturn GridBagConstraints.VERTICAL;\n\t\tcase 'h':\n\t\tcase 'H':\n\t\t\treturn GridBagConstraints.HORIZONTAL;\n\t\tcase 'b':\n\t\tcase 'B':\n\t\t\treturn GridBagConstraints.BOTH;\n\t\t}\n\t\treturn -1;\n\t}\n\t/**\n\t * Returns a GridBagConstraint, setting all values directly\n\t * @param x\n\t * @param y\n\t * @param width\n\t * @param height\n\t * @param wx\n\t * @param wy\n\t * @param insetTop\n\t * @param insetLeft\n\t * @param insetBottom\n\t * @param insetRight\n\t * @param fill\n\t * @param anchor\n\t * @return GridBagConstraints\n\t */\n\tpublic static GridBagConstraints get(int x, int y, int width, int height,\n\t\t\tdouble wx, double wy, int insetTop, int insetLeft, int insetBottom,\n\t\t\tint insetRight, char fill, String anchor)\n\t{\n\t\treturn new GridBagConstraints(x, y, width, height,\n\t\t\twx, wy, getAnchor(anchor), getFill(fill),\n\t\t\tnew Insets(insetTop, insetLeft, insetBottom, insetRight),\n\t\t\t0, 0);\n\t}\n\t/**\n\t * Returns a GridBagConstraint\n\t * @param x\n\t * @param y\n\t * @param width\n\t * @param height\n\t * @param wx\n\t * @param wy\n\t * @param fill\n\t * @param anchor\n\t * @return GridBagConstraints\n\t */\n\tpublic static GridBagConstraints get(int x, int y, int width, int height,\n\t\t\tdouble wx, double wy, char fill, String anchor)\n\t{\n\t\treturn get(x, y, width, height, wx, wy, 2, 2, 2, 2, fill, anchor);\n\t}\n\t/**\n\t * Returns a GridBagConstraint\n\t * @param x\n\t * @param y\n\t * @param width\n\t * @param height\n\t * @param wx\n\t * @param wy\n\t * @param fill\n\t * @return GridBagConstraints\n\t */\n\tpublic static GridBagConstraints get(int x, int y, int width, int height,\n\t\t\tdouble wx, double wy, char fill)\n\t{\n\t\treturn get(x, y, width, height, wx, wy, fill, DEFAULT_ANCHOR);\n\t}\n\t/**\n\t * Returns a GridBagConstraint\n\t * @param x\n\t * @param y\n\t * @param width\n\t * @param height\n\t * @param wx\n\t * @param wy\n\t * @return GridBagConstraints\n\t */\n\tpublic static GridBagConstraints get(int x, int y, int width, int height,\n\t\t\tdouble wx, double wy)\n\t{\n\t\treturn get(x, y, width, height, wx, wy, DEFAULT_FILL, DEFAULT_ANCHOR);\n\t}\n\t/**\n\t * Returns a GridBagConstraint\n\t * @param x\n\t * @param y\n\t * @param width\n\t * @param height\n\t * @param wx\n\t * @param wy\n\t * @param anchor\n\t * @return GridBagConstraints\n\t */\n\tpublic static GridBagConstraints get(int x, int y, int width, int height,\n\t\t\tdouble wx, double wy, String anchor)\n\t{\n\t\treturn get(x, y, width, height, wx, wy, DEFAULT_FILL, anchor);\n\t}\n\t/**\n\t * Returns a GridBagConstraint\n\t * @param x\n\t * @param y\n\t * @param width\n\t * @param height\n\t * @param fill\n\t * @param anchor\n\t * @return GridBagConstraints\n\t */\n\tpublic static GridBagConstraints get(int x, int y, int width, int height,\n\t\t\tchar fill, String anchor)\n\t{\n\t\treturn get(x, y, width, height, 0.0, 0.0, fill, anchor);\n\t}\n\t/**\n\t * Returns a GridBagConstraint\n\t * @param x\n\t * @param y\n\t * @param width\n\t * @param height\n\t * @param fill\n\t * @return GridBagConstraints\n\t */\n\tpublic static GridBagConstraints get(int x, int y, int width, int height,\n\t\t\tchar fill)\n\t{\n\t\treturn get(x, y, width, height, 0.0, 0.0, fill, DEFAULT_ANCHOR);\n\t}\n\t/**\n\t * Returns a GridBagConstraint\n\t * @param x\n\t * @param y\n\t * @param width\n\t * @param height\n\t * @return GridBagConstraints\n\t */\n\tpublic static GridBagConstraints get(int x, int y, int width, int height)\n\t{\n\t\treturn get(x, y, width, height, 0.0, 0.0, DEFAULT_FILL, DEFAULT_ANCHOR);\n\t}\n\t/**\n\t * Returns a GridBagConstraint\n\t * @param x\n\t * @param y\n\t * @param width\n\t * @param height\n\t * @param anchor\n\t * @return GridBagConstraints\n\t */\n\tpublic static GridBagConstraints get(int x, int y, int width, int height,\n\t\t\tString anchor)\n\t{\n", "outputs": ["\t\treturn get(x, y, width, height, 0.0, 0.0, DEFAULT_FILL, anchor);"], "input_length": 1095, "output_length": 20, "length": 1115, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "669b80479cb88521b0cdbdb60711fe5d939011f462ad8f7fc9f49fd2e4610e61"}
{"input": "", "context": "# Copyright 2013 The Servo Project Developers. See the COPYRIGHT\n# file at the top-level directory of this distribution.\n#\n# Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n# http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n# <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n# option. This file may not be copied, modified, or distributed\n# except according to those terms.\nimport os\nfrom os import path\nimport contextlib\nimport subprocess\nfrom subprocess import PIPE\nimport sys\nimport toml\nfrom mach.registrar import Registrar\n@contextlib.contextmanager\ndef cd(new_path):\n    \"\"\"Context manager for changing the current working directory\"\"\"\n    previous_path = os.getcwd()\n    try:\n        os.chdir(new_path)\n        yield\n    finally:\n        os.chdir(previous_path)\ndef host_triple():\n    os_type = subprocess.check_output([\"uname\", \"-s\"]).strip().lower()\n    if os_type == \"linux\":\n        os_type = \"unknown-linux-gnu\"\n    elif os_type == \"darwin\":\n        os_type = \"apple-darwin\"\n    elif os_type == \"android\":\n        os_type = \"linux-androideabi\"\n    else:\n        os_type = \"unknown\"\n    cpu_type = subprocess.check_output([\"uname\", \"-m\"]).strip().lower()\n    if cpu_type in [\"i386\", \"i486\", \"i686\", \"i768\", \"x86\"]:\n        cpu_type = \"i686\"\n    elif cpu_type in [\"x86_64\", \"x86-64\", \"x64\", \"amd64\"]:\n        cpu_type = \"x86_64\"\n    elif cpu_type == \"arm\":\n        cpu_type = \"arm\"\n    else:\n        cpu_type = \"unknown\"\n    return \"%s-%s\" % (cpu_type, os_type)\nclass CommandBase(object):\n    \"\"\"Base class for mach command providers.\n    This mostly handles configuration management, such as .servobuild.\"\"\"\n    def __init__(self, context):\n        self.context = context\n        def resolverelative(category, key):\n            # Allow ~\n            self.config[category][key] = path.expanduser(self.config[category][key])\n            # Resolve relative paths\n            self.config[category][key] = path.join(context.topdir,\n                                                   self.config[category][key])\n        if not hasattr(self.context, \"bootstrapped\"):\n            self.context.bootstrapped = False\n        config_path = path.join(context.topdir, \".servobuild\")\n        if path.exists(config_path):\n            with open(config_path) as f:\n                self.config = toml.loads(f.read())\n        else:\n            self.config = {}\n        # Handle missing/default items\n        self.config.setdefault(\"tools\", {})\n        default_cache_dir = os.environ.get(\"SERVO_CACHE_DIR\",\n                                           path.join(context.topdir, \".servo\"))\n        self.config[\"tools\"].setdefault(\"cache-dir\", default_cache_dir)\n        resolverelative(\"tools\", \"cache-dir\")\n        self.config[\"tools\"].setdefault(\"cargo-home-dir\",\n                                        path.join(context.topdir, \".cargo\"))\n        resolverelative(\"tools\", \"cargo-home-dir\")\n        context.sharedir = self.config[\"tools\"][\"cache-dir\"]\n        self.config[\"tools\"].setdefault(\"system-rust\", False)\n        self.config[\"tools\"].setdefault(\"system-cargo\", False)\n        self.config[\"tools\"].setdefault(\"rust-root\", \"\")\n        self.config[\"tools\"].setdefault(\"cargo-root\", \"\")\n        if not self.config[\"tools\"][\"system-rust\"]:\n            self.config[\"tools\"][\"rust-root\"] = path.join(\n                context.sharedir, \"rust\", self.rust_snapshot_path())\n        if not self.config[\"tools\"][\"system-cargo\"]:\n            self.config[\"tools\"][\"cargo-root\"] = path.join(\n                context.sharedir, \"cargo\", self.cargo_build_id())\n        self.config[\"tools\"].setdefault(\"rustc-with-gold\", True)\n        self.config.setdefault(\"build\", {})\n        self.config[\"build\"].setdefault(\"android\", False)\n        self.config[\"build\"].setdefault(\"mode\", \"\")\n        self.config[\"build\"].setdefault(\"debug-mozjs\", False)\n        self.config[\"build\"].setdefault(\"ccache\", \"\")\n        self.config.setdefault(\"android\", {})\n        self.config[\"android\"].setdefault(\"sdk\", \"\")\n        self.config[\"android\"].setdefault(\"ndk\", \"\")\n        self.config[\"android\"].setdefault(\"toolchain\", \"\")\n        self.config[\"android\"].setdefault(\"target\", \"arm-linux-androideabi\")\n        self.config.setdefault(\"gonk\", {})\n        self.config[\"gonk\"].setdefault(\"b2g\", \"\")\n        self.config[\"gonk\"].setdefault(\"product\", \"flame\")\n    _rust_snapshot_path = None\n    _cargo_build_id = None\n    def rust_snapshot_path(self):\n        if self._rust_snapshot_path is None:\n            filename = path.join(self.context.topdir, \"rust-snapshot-hash\")\n            with open(filename) as f:\n                snapshot_hash = f.read().strip()\n            self._rust_snapshot_path = (\"%s/rustc-nightly-%s\" %\n                                        (snapshot_hash, host_triple()))\n        return self._rust_snapshot_path\n    def cargo_build_id(self):\n        if self._cargo_build_id is None:\n            filename = path.join(self.context.topdir, \"cargo-nightly-build\")\n            with open(filename) as f:\n                self._cargo_build_id = f.read().strip()\n        return self._cargo_build_id\n    def get_top_dir(self):\n        return self.context.topdir\n    def get_target_dir(self):\n        if \"CARGO_TARGET_DIR\" in os.environ:\n            return os.environ[\"CARGO_TARGET_DIR\"]\n        else:\n            return path.join(self.context.topdir, \"target\")\n    def get_binary_path(self, release, dev, android=False):\n        base_path = self.get_target_dir()\n        if android:\n            base_path = path.join(base_path, self.config[\"android\"][\"target\"])\n        release_path = path.join(base_path, \"release\", \"servo\")\n        dev_path = path.join(base_path, \"debug\", \"servo\")\n        # Prefer release if both given\n        if release and dev:\n            dev = False\n        release_exists = path.exists(release_path)\n        dev_exists = path.exists(dev_path)\n        if not release_exists and not dev_exists:\n            print(\"No Servo binary found. Please run './mach build' and try again.\")\n            sys.exit()\n        if release and release_exists:\n            return release_path\n        if dev and dev_exists:\n            return dev_path\n        if not dev and not release and release_exists and dev_exists:\n            print(\"You have multiple profiles built. Please specify which \"\n                  \"one to run with '--release' or '--dev'.\")\n            sys.exit()\n        if not dev and not release:\n            if release_exists:\n                return release_path\n            else:\n                return dev_path\n        print(\"The %s profile is not built. Please run './mach build%s' \"\n              \"and try again.\" % (\"release\" if release else \"dev\",\n                                  \" --release\" if release else \"\"))\n        sys.exit()\n    def build_env(self, gonk=False, hosts_file_path=None):\n        \"\"\"Return an extended environment dictionary.\"\"\"\n        env = os.environ.copy()\n        extra_path = []\n        extra_lib = []\n        if not self.config[\"tools\"][\"system-rust\"] \\\n                or self.config[\"tools\"][\"rust-root\"]:\n            env[\"RUST_ROOT\"] = self.config[\"tools\"][\"rust-root\"]\n            # These paths are for when rust-root points to an unpacked installer\n            extra_path += [path.join(self.config[\"tools\"][\"rust-root\"], \"rustc\", \"bin\")]\n            extra_lib += [path.join(self.config[\"tools\"][\"rust-root\"], \"rustc\", \"lib\")]\n            # These paths are for when rust-root points to a rustc sysroot\n            extra_path += [path.join(self.config[\"tools\"][\"rust-root\"], \"bin\")]\n            extra_lib += [path.join(self.config[\"tools\"][\"rust-root\"], \"lib\")]\n        if not self.config[\"tools\"][\"system-cargo\"] \\\n                or self.config[\"tools\"][\"cargo-root\"]:\n            # This path is for when rust-root points to an unpacked installer\n            extra_path += [\n                path.join(self.config[\"tools\"][\"cargo-root\"], \"cargo\", \"bin\")]\n            # This path is for when rust-root points to a rustc sysroot\n            extra_path += [\n                path.join(self.config[\"tools\"][\"cargo-root\"], \"bin\")]\n        if extra_path:\n", "outputs": ["            env[\"PATH\"] = \"%s%s%s\" % ("], "input_length": 1570, "output_length": 17, "length": 1587, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "0266642783ac7d8214ccdc396e626d6b2147466e30b65c216e74f90c11332eeb"}
{"input": "", "context": "package de.tink.minecraft.plugin.safari;\n/*\nCopyright (C) 2012 Thomas Starl\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <http://www.gnu.org/licenses/>\n*/\nimport java.util.Date;\nimport java.util.List;\nimport java.util.Set;\nimport org.bukkit.ChatColor;\nimport org.bukkit.configuration.Configuration;\nimport org.bukkit.configuration.ConfigurationSection;\nimport org.bukkit.entity.EntityType;\nimport org.bukkit.entity.LivingEntity;\nimport org.bukkit.entity.Player;\nimport org.bukkit.event.EventHandler;\nimport org.bukkit.event.Listener;\nimport org.bukkit.event.entity.EntityDeathEvent;\nimport org.bukkit.inventory.ItemStack;\npublic class SafariEventListener implements Listener {\n\tSafariPlugin plugin;\n\t\n\tprivate String SAFARI_FINISHED = \"Congratulations, you have successfully completed this safari!\";\n\tprivate String SAFARI_KILL_COUNTS = \"This kill is counting for your current safari! ?1/?2 mobs killed.\";\n\tprivate String SAFARI_DROPS_MESSAGES = \"Your reward for the completed safari:\";\n\tprivate String SAFARI_PLAYER_CREATED_NEW_RECORD_FEEDBACK = \"You scored a new record for this safari!\";\n\tprivate String SAFARI_PLAYER_CREATED_NEW_RECORD_WORLDSAY = \"Congratulations! ?1 managed to complete the \\\"?2\\\" safari within a new record-time of: ?3!\";\n\t\n\t@EventHandler\n\tpublic void onMobKill(EntityDeathEvent deathEvent) {\n\t\tLivingEntity killedMob = deathEvent.getEntity();\n\t\tEntityType killedMobType = deathEvent.getEntityType();\n\t\tPlayer player = killedMob.getKiller();\n\t\tif ( player == null ) {\n\t\t\treturn;\n\t\t}\n\t\tConfiguration playerConfig = plugin.getPlayerConfig();\n\t\tConfiguration safariConfig = plugin.getConfig();\n\t\tConfiguration groupsConfig = plugin.getGroupsConfig();\n\t\tConfigurationSection registeredPlayerSection = null;\n\t\tboolean playerIsInSafari = false;\n\t\tboolean killedByPlayer = false;\n\t\tboolean killIsInSafariTimeframe = false;\n\t\tboolean safariIsFulfilled = false;\n\t\tboolean newRecordForSafari = false;\n\t\tLong duration = null;\n\t\tString basePath = null;\n\t\t\n\t\tif ( player != null ) {\n\t\t\tkilledByPlayer = true;\n\t\t\tregisteredPlayerSection = playerConfig.getConfigurationSection(\"registered_players.\"+player.getName());\n\t\t}\n\t\tif ( registeredPlayerSection != null ) {\n\t\t\tplayerIsInSafari = true;\n\t\t}\n\t\tString currentSafari = playerConfig.getString(\"registered_players.\"+player.getName()+\".safari\");\n\t\t// check Safari Config for Night/Day Config\n\t\tkillIsInSafariTimeframe = false;\n\t\tLong currentHourLong = (player.getWorld().getFullTime())/1000;\n\t\tInteger currentHour = (Integer) currentHourLong.intValue();\n\t\tList<String> safariHours = safariConfig.getStringList(\"safaris.\"+currentSafari+\".valid_hours\");\n\t\tif ( safariHours == null || ( safariHours != null && safariHours.size() == 0 ) ) {\n\t\t\tkillIsInSafariTimeframe = true;\n\t\t} else {\n\t\t\tfor ( String safariHour : safariHours ) {\n\t\t\t\tInteger safariHourInt = Integer.parseInt(safariHour);\n\t\t\t\tif ( safariHourInt == currentHour ) {\n\t\t\t\t\tkillIsInSafariTimeframe = true;\n\t\t\t\t}\n\t\t\t}\n\t\t}\t\n\t\t\n\t\t\n\t\t/*\n\t\t *  Skip/ignore the kill if\n\t\t *  a) the killing player is not registered for a safari\n\t\t *  or\n\t\t *  b) the mob was not killed by a player\n\t\t *  or\n\t\t *  c) the Safari is bound to a given Timeframe (e.g.: day, night, dusk, dawn) \n\t\t */\n\t\tif ( !killedByPlayer || !playerIsInSafari || !killIsInSafariTimeframe ) {\n\t\t\treturn;\n\t\t}\n\t\t\n\t\t\n\t\tInteger currentSafariMobsToKill = playerConfig.getInt(\"registered_players.\"+player.getName()+\".mobs_to_kill\");\n\t\tInteger currentSafariMobsKilled = playerConfig.getInt(\"registered_players.\"+player.getName()+\".mobs_killed\");\n\t\tif ( currentSafariMobsKilled == null ) {\n\t\t\tcurrentSafariMobsKilled = 0; \n\t\t}\n\t\tString mobKey = \"safaris.\"+currentSafari+\".types_of_mobs_to_kill\";\n\t\tList<String> relevantMobs = safariConfig.getStringList(mobKey);\n\t\tboolean isRelevantMob = false;\n\t\tfor (String mobToKill : relevantMobs ) {\n\t\t\tif ( \"ANY\".equals(mobToKill) || killedMobType.getName().toLowerCase().equals(mobToKill.toLowerCase())) {\n\t\t\t\tisRelevantMob = true;\n\t\t\t}\n\t\t}\n\t\t\n\t\t// add 1 to mobs_killed\n\t\tif ( isRelevantMob ) {\n\t\t\tcurrentSafariMobsKilled++;\n\t\t\tplayerConfig.set(\"registered_players.\"+player.getName()+\".mobs_killed\",currentSafariMobsKilled);\n\t\t\tplayer.sendMessage(SAFARI_KILL_COUNTS.replace(\"?1\", currentSafariMobsKilled.toString()).replace(\"?2\",currentSafariMobsToKill.toString()));\n\t\t\tplugin.savePlayerConfig();\n\t\t\tif ( currentSafariMobsKilled == currentSafariMobsToKill ) {\n\t\t\t\tplayer.sendMessage(SAFARI_FINISHED);\n\t\t\t\tplayer.sendMessage(SAFARI_DROPS_MESSAGES);\n\t\t\t\tbasePath = \"safaris.\"+currentSafari;\n\t\t\t\t// should we add drops?\n\t\t\t\tConfigurationSection addDropsSection = safariConfig.getConfigurationSection(basePath + \".addDrops\");\n\t\t\t\tif ( addDropsSection != null ){\n\t\t\t\t\tSet<String> addDrops = addDropsSection.getKeys(false);\n\t\t\t\t\tList<ItemStack> drops = deathEvent.getDrops();\n\t\t\t\t\tfor(String drop : addDrops) {\n\t\t\t\t\t\tString amount = plugin.getConfig().getString(basePath + \".addDrops.\" + drop);\n\t\t\t\t\t\tint itemAmount = parseInt(amount);\n\t\t\t\t\t\tif(itemAmount > 0) {\n\t\t\t\t\t\t\tItemStack newDrop = new ItemStack(Integer.parseInt(drop), itemAmount);\n\t\t\t\t\t\t\tdrops.add(newDrop);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t// calculate time needed to complete the safari and check for new record\n\t\t\t\tLong safariStartedAt = playerConfig.getLong(\"registered_players.\"+player.getName()+\".safari_started\");\n\t\t\t\tif ( safariStartedAt == null ) {\n\t\t\t\t\tsafariStartedAt = 0L;\n\t\t\t\t}\n\t\t\t\tLong currentSafariRecordTime = safariConfig.getLong(\"safaris.\"+ currentSafari + \".current_recordtime\");\n\t\t\t\tif ( currentSafariRecordTime == null ) {\n\t\t\t\t\tcurrentSafariRecordTime = 0L;\n\t\t\t\t}\n\t\t\t\tLong now = (new Date()).getTime();\n\t\t\t\tduration = now - safariStartedAt;\n\t\t\t\t// Yippie, new record achieved!\n\t\t\t\tif ( duration < currentSafariRecordTime || currentSafariRecordTime == 0 ) {\n\t\t\t\t\tnewRecordForSafari = true;\n\t\t\t\t}\n\t\t\t\tsafariIsFulfilled = true;\t\n\t\t\t}\n\t\t}\n\t\t\n\t\tif ( newRecordForSafari ) {\n\t\t\tsafariConfig.set(\"safaris.\"+ currentSafari + \".current_recordtime\",duration);\n\t\t\tsafariConfig.set(\"safaris.\"+ currentSafari + \".current_recordholder\",player.getName());\n\t\t\tplugin.saveConfig();\n\t\t\tint minutes = (int) ((duration / (1000*60)) % 60);\n\t\t\tint hours   = (int) ((duration / (1000*60*60)) % 24);\n\t\t\tString durationString = hours+\":\"+minutes;\n\t\t\tplayer.sendMessage(ChatColor.BLUE+SAFARI_PLAYER_CREATED_NEW_RECORD_FEEDBACK);\n\t\t\tplugin.getServer().broadcastMessage(ChatColor.BLUE+SAFARI_PLAYER_CREATED_NEW_RECORD_WORLDSAY.replace(\"?1\",player.getName()).replace(\"?2\", currentSafari).replace(\"?3\",durationString));\n\t\t\tConfigurationSection addDropsSection = safariConfig.getConfigurationSection(basePath + \".addRecordDrops\");\n\t\t\tif ( addDropsSection != null ){\n\t\t\t\tSet<String> addDrops = addDropsSection.getKeys(false);\n\t\t\t\tList<ItemStack> drops = deathEvent.getDrops();\n\t\t\t\tfor(String drop : addDrops) {\n\t\t\t\t\tString amount = plugin.getConfig().getString(basePath + \".addRecordDrops.\" + drop);\n\t\t\t\t\tint itemAmount = parseInt(amount);\n\t\t\t\t\tif(itemAmount > 0) {\n\t\t\t\t\t\tItemStack newDrop = new ItemStack(Integer.parseInt(drop), itemAmount);\n\t\t\t\t\t\tdrops.add(newDrop);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\n\t\tif ( safariIsFulfilled ) {\n\t\t\tplugin.fulfillSafari(player);\n\t\t}\n\t}\n\t\n\t/*\n\t * Used to determine/calculate the drop(s) for the accomplished Safari\n\t * thanks to metakiwi: http://dev.bukkit.org/profiles/metakiwi/\n\t * for this nice piece of code which evolved from his\n\t * \"LessFood\" Plugin: http://dev.bukkit.org/server-mods/lessfood/\n\t * \n\t */\n\t\n\tprivate int parseInt(String number) {\n\t\tif(number == null) return 0;\n\t\tString[] splitNumber = number.split(\" \"); \n\t\tfloat chance=100;\n", "outputs": ["\t\tint min = -1;"], "input_length": 1376, "output_length": 5, "length": 1381, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "c2d719ea092a488c789b9d9c455560b62b9e1001745aa3d209f3bd36d3b5fade"}
{"input": "", "context": "# -*- coding: utf-8 -*-\nfrom io import BytesIO as StringIO\nfrom amoco.config import conf\nfrom amoco.logger import Log\nlogger = Log(__name__)\nlogger.debug(\"loading module\")\nimport re\ntry:\n    from pygments.token import Token\n    from pygments.style import Style\n    from pygments.lexer import RegexLexer\n    from pygments.formatters import *\nexcept ImportError:\n    logger.info(\"pygments package not found, no renderer defined\")\n    has_pygments = False\n    # metaclass definition, with a syntax compatible with python2 and python3\n    class TokenType(type):\n        def __getattr__(cls, key):\n            return key\n    Token_base = TokenType(\"Token_base\", (), {})\n    class Token(Token_base):\n        pass\n    class NullFormatter(object):\n        def __init__(self, **options):\n            self.options = options\n        def format(self, tokensource, outfile):\n            for t, v in tokensource:\n                outfile.write(v.encode(\"latin1\"))\n    Formats = {\n        \"Null\": NullFormatter(),\n    }\nelse:\n    logger.info(\"pygments package imported\")\n    has_pygments = True\n    class DarkStyle(Style):\n        default_style = \"\"\n        styles = {\n            # Token.Literal:  '#fff',\n            Token.Address: \"#fb0\",\n            Token.Constant: \"#f30\",\n            # Token.Prefix:   '#fff',\n            Token.Mnemonic: \"bold\",\n            Token.Register: \"#33f\",\n            Token.Memory: \"#3ff\",\n            Token.Comment: \"#8f8\",\n            Token.Name: \"underline\",\n            Token.Tainted: \"bold #f00\",\n            Token.Column: \"#bbb\",\n            Token.Hide: \"#222\",\n        }\n    class LightStyle(Style):\n        default_style = \"\"\n        styles = {\n            Token.Literal: \"#000\",\n            Token.Address: \"#b58900\",\n            Token.Constant: \"#dc322f\",\n            Token.Prefix: \"#000\",\n            Token.Mnemonic: \"bold\",\n            Token.Register: \"#268bd2\",\n            Token.Memory: \"#859900\",\n            Token.Comment: \"#93a1a1\",\n            Token.Name: \"underline\",\n            Token.Tainted: \"bold #f00\",\n            Token.Column: \"#222\",\n            Token.Hide: \"#bbb\",\n        }\n    DefaultStyle = DarkStyle\n    Formats = {\n        \"Null\": NullFormatter(encoding=\"utf-8\"),\n        \"Terminal\": TerminalFormatter(style=DefaultStyle, encoding=\"utf-8\"),\n        \"Terminal256\": Terminal256Formatter(style=DefaultStyle, encoding=\"utf-8\"),\n        \"TerminalDark\": Terminal256Formatter(style=DarkStyle, encoding=\"utf-8\"),\n        \"TerminalLight\": Terminal256Formatter(style=LightStyle, encoding=\"utf-8\"),\n        \"Html\": HtmlFormatter(style=LightStyle, encoding=\"utf-8\"),\n    }\ndef highlight(toks, formatter=None, outfile=None):\n    formatter = formatter or Formats.get(conf.UI.formatter)\n    if isinstance(formatter, str):\n        formatter = Formats[formatter]\n    outfile = outfile or StringIO()\n    formatter.format(toks, outfile)\n    return outfile.getvalue().decode(\"utf-8\")\ndef TokenListJoin(j, lst):\n    if isinstance(j, str):\n        j = (Token.Literal, j)\n    res = lst[0:1]\n    for x in lst[1:]:\n        res.append(j)\n        res.append(x)\n    return res\nclass vltable(object):\n    \"\"\"\n    variable length table:\n    \"\"\"\n    def __init__(self, rows=None, formatter=None, outfile=None):\n        if rows is None:\n            rows = []\n        self.rows = rows\n        self.rowparams = {\n            \"colsize\": {},\n            \"hidden_c\": set(),\n            \"squash_c\": True,\n            \"formatter\": formatter,\n            \"outfile\": outfile,\n        }\n        self.maxlength = float(\"inf\")\n        self.hidden_r = set()\n        self.hidden_c = self.rowparams[\"hidden_c\"]\n        self.squash_r = True\n        self.colsize = self.rowparams[\"colsize\"]\n        self.update()\n        self.header = \"\"\n        self.footer = \"\"\n    def update(self, *rr):\n        for c in range(self.ncols):\n            cz = self.colsize.get(c, 0) if len(rr) > 0 else 0\n            self.colsize[c] = max(cz, self.getcolsize(c, rr, squash=False))\n    def getcolsize(self, c, rr=None, squash=True):\n        cz = 0\n        if not rr:\n            rr = range(self.nrows)\n        for i in rr:\n            if self.rowparams[\"squash_c\"] and (i in self.hidden_r):\n                if squash:\n                    continue\n            cz = max(cz, self.rows[i].colsize(c))\n        return cz\n    @property\n    def width(self):\n        sep = self.rowparams.get(\"sep\", \"\")\n        cs = self.ncols * len(sep)\n        return sum(self.colsize.values(), cs)\n    def setcolsize(self, c, value):\n        self.colsize[c] = value\n    def addrow(self, toks):\n        self.rows.append(tokenrow(toks))\n        self.update(-1)\n        return self\n    def hiderow(self, n):\n        self.hidden_r.add(n)\n    def showrow(self, n):\n        self.hidden_r.remove(n)\n    def hidecolumn(self, n):\n        self.hidden_c.add(n)\n    def showcolumn(self, n):\n        self.hidden_c.remove(n)\n    def showall(self):\n        self.hidden_r = set()\n        self.rowparams[\"hidden_c\"] = set()\n        self.hidden_c = self.rowparams[\"hidden_c\"]\n        return self\n    def grep(self, regex, col=None, invert=False):\n        L = set()\n        R = range(self.nrows)\n        for i in R:\n            if i in self.hidden_r:\n                continue\n            C = self.rows[i].rawcols(col)\n            for c, s in enumerate(C):\n                if c in self.hidden_c:\n                    continue\n                if re.search(regex, s):\n                    L.add(i)\n                    break\n        if not invert:\n            L = set(R) - L\n        for n in L:\n            self.hiderow(n)\n        return self\n    @property\n    def nrows(self):\n        return len(self.rows)\n    @property\n    def ncols(self):\n        if self.nrows > 0:\n            return max((r.ncols for r in self.rows))\n        else:\n            return 0\n    def __str__(self):\n        s = []\n        formatter = self.rowparams[\"formatter\"]\n        outfile = self.rowparams[\"outfile\"]\n        for i in range(self.nrows):\n            if i in self.hidden_r:\n                if not self.squash_r:\n                    s.append(\n                        highlight(\n                            [\n                                (\n                                    Token.Hide,\n                                    self.rows[i].show(raw=True, **self.rowparams),\n                                )\n                            ],\n                            formatter,\n                            outfile,\n                        )\n                    )\n            else:\n                s.append(self.rows[i].show(**self.rowparams))\n        if len(s) > self.maxlength:\n            s = s[: self.maxlength - 1]\n            s.append(highlight([(Token.Literal, \"...\")], formatter, outfile))\n        if self.header:\n            s.insert(0, self.header)\n        if self.footer:\n            s.append(self.footer)\n        return \"\\n\".join(s)\nclass tokenrow(object):\n    def __init__(self, toks=None):\n        if toks is None:\n            toks = []\n        self.toks = [(t, \"%s\" % s) for (t, s) in toks]\n        self.maxwidth = float(\"inf\")\n        self.align = \"<\"\n        self.fill = \" \"\n        self.separator = \"\"\n        self.cols = self.cut()\n    def cut(self):\n        C = []\n        c = []\n        for t in self.toks:\n            c.append(t)\n            if t[0] == Token.Column:\n                C.append(c)\n                c = []\n        C.append(c)\n        return C\n    def colsize(self, c):\n        if c >= len(self.cols):\n            return 0\n        return sum((len(t[1]) for t in self.cols[c] if t[0] != Token.Column))\n    @property\n    def ncols(self):\n        return len(self.cols)\n    def rawcols(self, j=None):\n        r = []\n        cols = self.cols\n        if j is not None:\n            cols = self.cols[j : j + 1]\n        for c in cols:\n            r.append(\"\".join([t[1] for t in c]))\n        return r\n    def show(self, raw=False, **params):\n        formatter = params.get(\"formatter\", None)\n        outfile = params.get(\"outfile\", None)\n        align = params.get(\"align\", self.align)\n        fill = params.get(\"fill\", self.fill)\n        sep = params.get(\"sep\", self.separator)\n        width = params.get(\"maxwidth\", self.maxwidth)\n        colsz = params.get(\"colsize\")\n        hidden_c = params.get(\"hidden_c\", set())\n        squash_c = params.get(\"squash_c\", True)\n        head = params.get(\"head\", \"\")\n        tail = params.get(\"tail\", \"\")\n        if raw:\n            formatter = \"Null\"\n            outfile = None\n", "outputs": ["        r = [head]"], "input_length": 1624, "output_length": 5, "length": 1629, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "15da89fdfadaf23f3ec1c7bb27ba31f5fe8ad2f7af316eaa18909a04cbd0539c"}
{"input": "", "context": "namespace App.Mvc.Controllers\n{\n    using Contracts;\n    using Mvc;\n    using Contracts.Services;\n    using Models;\n    using Filters;\n    using System.Collections.Generic;\n    using System.Linq;\n    using System.Web.Mvc;\n    using System.Web;\n\t[Filters.ExceptionHandler]\n    public class DelegateController : Controller\n    {\n\t\tprivate readonly ILogProvider log ; \n\t\tprivate const string LogName = \"Delegate\";\n        private readonly IDelegateService service ;   \n        public DelegateController(ILogProvider log, IDelegateService service )\n        {\n            this.service = service;\n\t\t\tthis.log = log;\n            \n        }\n        protected override void OnActionExecuting(ActionExecutingContext filterContext)\n        {\n            base.OnActionExecuting(filterContext);\n\t\t\tlog.LogActionExecuting(LogName,filterContext);\n\t\t\tViewBag.Title = \"App\";\n            ViewBag.SectionTitle = \"Delegate\";\n        }\n        // GET: Delegate\n\t\t[RolesRequired(\"Admin\",\"ListDelegate\")]\n        public ActionResult Index()\n        {\n            var errors = new List<IModelError>();\n            var models = service.GetAll(x => x != null, errors);\n            ViewBag.Errors = errors;\n            ViewBag.ToolButtons = \"VED\"; // View Edit Delete \n\t\t\tViewBag.Title = \"List Delegate\" ; \n            return View(models);            \n        }\n        // Display a form for viewing Delegate\n\t\t[RolesRequired(\"Admin\",\"ViewDelegate\")]\n        public ActionResult View(int id = -1)\n        {\t\t\t \n            var errors = new List<IModelError>();\n            ViewBag.Readonly = true;\n            ViewBag.ButtonFlag = \"\";\n\t\t\tViewBag.Title = \"View Delegate\" ; \n            var model = GetViewModel(id,errors);\n            return View(\"Form\",model);\n        }\n        // Display a form for editing Delegate\n\t\t[RolesRequired(\"Admin\",\"SaveDelegate\")]        \n        public ActionResult Edit(int id = -1)\n        {\n            var errors = new List<IModelError>();\n            ViewBag.Readonly = false;\n\t\t\tViewBag.ButtonFlag = \"RS\"; // Relationship Submit\n\t\t\tViewBag.Title = \"Edit Delegate\" ; \n            var model = GetViewModel(id,errors);\n            return View(\"Form\",model);\n        }\n\t\t[RolesRequired(\"Admin\",\"SaveDelegate\")]   \n        [HttpPost]\n        public ActionResult Edit(DelegateViewModel model)\n        {\n            var errors = new List<IModelError>();\n            service.TrySave(model, errors);          \n\t\t\tif (errors.Any())\n            {\n                this.AddModelErrors(errors);\n                ViewBag.Readonly = false;\n\t\t\t\tViewBag.ButtonFlag = \"RS\"; // Relationship Submit\n\t\t\t\tViewBag.Title = \"Edit Delegate\" ; \n                return View(\"Form\", model);\n            }\n            else\n            {\n                return RedirectToAction(\"index\", new { updated = model.Id });\n            } \n        }\n        // Display a form for creating Delegate\n\t\t[RolesRequired(\"Admin\",\"SaveDelegate\")]   \n        public ActionResult Create(int id = -1)\n        {\n            var errors = new List<IModelError>();\n            ViewBag.Readonly = false;\n\t\t\tViewBag.ButtonFlag = \"S\"; // Submit\n\t\t\tViewBag.Title = \"New Delegate\" ; \n            var model = GetViewModel(id,errors);\n            return View(\"Form\",model);\n        }\n\t\t[RolesRequired(\"Admin\",\"SaveDelegate\")]   \n        [HttpPost]\n        public ActionResult Create(DelegateViewModel model)\n        {\n            var errors = new List<IModelError>();\n\t\t\tservice.TrySave(model, errors);  \n\t\t\tif (errors.Any())\n            {\n                this.AddModelErrors(errors);\n                ViewBag.Readonly = false;\n                ViewBag.ButtonFlag = \"S\"; // Submit\n\t\t\t\tViewBag.Title = \"New Delegate\" ; \n                return View(\"Form\", model);\n            }\n            else\n            {\n                return RedirectToAction(\"index\", new { creaated = model.Id });\n            } \n        }\n        // Display a form for deleting Delegate\n\t\t[RolesRequired(\"Admin\",\"DeleteDelegate\")]   \n        public ActionResult Delete(int id = -1)\n        {\n            var errors = new List<IModelError>();\n            ViewBag.Readonly = true;\n            ViewBag.ShowRelationships = false;\n\t\t\tViewBag.Title = \"Delete Delegate\" ; \n            var model = GetViewModel(id,errors);\n            return View(\"Form\",model);\n        }\n\t\t[RolesRequired(\"Admin\", \"DeleteDelegate\")]\n        [HttpPost]\n        public ActionResult Delete(DelegateViewModel model, int _post)\n        {\n            var errors = new List<IModelError>();\n            var result = service.TryDelete(model.Id, errors);\n            ViewBag.Title = \"Delete Delegate\";\n            if (errors.Any())\n            {\n                model = GetViewModel(model.Id, errors);\n                this.AddModelErrors(errors);\n                ViewBag.Readonly = false;\n                ViewBag.ButtonFlag = \"S\"; // Submit\n                ViewBag.Title = \"Delete Delegate\";\n                return View(\"Form\", model);\n            }\n            else\n            {\n                return RedirectToAction(\"index\", new { deleted = model.Id });\n            }\n        }\n\t\t\n        // list all Delegate entities\n\t\t[RolesRequired(\"Admin\",\"ListDelegate\")]  \n        public ActionResult List() \n        {\n            var errors = new List<IModelError>();\n            var models = service.GetAll(x =>x != null, errors);\n            ViewBag.Errors = errors;\n            ViewBag.ToolButtons = \"VP\"; // View Pick \n            ViewBag.PickState = false;\n            return View(\"DelegateList\", models);\n        }\n                \n        \n        // Supports the many to many relationship (DelegateEvent) between Delegate (parent) Event (child)\n        //[Authorize(Roles = \"Admin,ListDelegateEvent\")]\n\t\t[RolesRequired(\"Admin\",\"ListDelegateEvent\")]  \n        public ActionResult GetDelegateEvent(int id, bool selected = false) \n        {\n            var models = service.GetAllForDelegateEvent(id);\n            ViewBag.ToolButtons = \"VP\"; // View Pick \n            ViewBag.PickState = selected;\n            return View(\"DelegateList\", models);\n        }\n        // Add a relationship (DelegateEvent) between Delegate (parent) Event (child)\n        //[Authorize(Roles = \"Admin,SaveDelegateEvent\")]\n\t\t[RolesRequired(\"Admin\",\"SaveDelegateEvent\")]  \n        public ActionResult AddDelegateEvent(int id)\n        {\n            ViewBag.Readonly = false;\n            ViewBag.ShowRelationships = false;\n            ViewBag.ModelId = new int?(id);\n            return View(\"Form\", new DelegateViewModel());\n        }\n        // Add a relationship (DelegateEvent) between Delegate (parent) Event (child)\n        [HttpPost]\n        //[Authorize(Roles = \"Admin,SaveDelegateEvent\")]\n\t\t[RolesRequired(\"Admin\",\"SaveDelegateEvent\")]\n        public ActionResult SaveDelegateEvent(DelegateViewModel model, int modelId)\n        {\n            var errors = new List<IModelError>();\n            model.Id = 0 ; // force a new object regardless\n            var result = service.TrySave(model, errors);\n            if (result)\n            {\n                service.AddEventToDelegateForDelegateEvent(model.Id, modelId);\n            }\n            return Json(new\n            {\n                Model = model,\n                Success = result,\n                Errors = errors\n            });\n        }\n        // remove a relationship (DelegateEvent) between Delegate (parent) Event (child) \n        [HttpPost]\n\t\t[RolesRequired(\"Admin\",\"SaveDelegateEvent\")]       \n        public ActionResult UnLinkDelegateEvent(int modelId , int[] items)\n        {\n            var result = true;\n            try\n            {\n                items.DefaultIfNull().AsParallel().ToList().ForEach(i => {\n\t\t\t\t\tservice.RemoveEventFromDelegateForDelegateEvent(modelId, i);\t\t\t\t\t                  \n                });\n            }\n            catch \n            {\n\t\t\t\titems.DefaultIfNull().AsParallel().ToList().ForEach(i => {                    \n\t\t\t\t\tservice.AddEventToDelegateForDelegateEvent(modelId, i);  \n                });\n                result = false;  \n            }\n                                   \n            return Json(new\n            {\n                Success = result\n            });\n        }\n        // add a relationship (DelegateEvent) between existing Delegate (parent) Event (child) \n        [HttpPost]\n        [RolesRequired(\"Admin\",\"SaveDelegateEvent\")]  \n        public ActionResult LinkDelegateEvent(int modelId , int[] items)\n        {\n            var result = true;\n            try\n            {\n                items.DefaultIfNull().AsParallel().ToList().ForEach(i => {\n\t\t\t\t\tservice.AddEventToDelegateForDelegateEvent(modelId, i);                    \n                });\n            }\n            catch \n            {\n\t\t\t\titems.DefaultIfNull().AsParallel().ToList().ForEach(i => {                    \n\t\t\t\t\tservice.RemoveEventFromDelegateForDelegateEvent(modelId, i);\n                });\n                result = false;  \n            }\n                                   \n            return Json(new\n            {\n                Success = result\n            });\n        }\n                \n        // Supports the many to many relationship (DelegateExamResult) between Delegate (parent) ExamResult (child)\n        //[Authorize(Roles = \"Admin,ListDelegateExamResult\")]\n\t\t[RolesRequired(\"Admin\",\"ListDelegateExamResult\")]  \n        public ActionResult GetDelegateExamResult(int id, bool selected = false) \n        {\n            var models = service.GetAllForDelegateExamResult(id);\n            ViewBag.ToolButtons = \"VP\"; // View Pick \n            ViewBag.PickState = selected;\n            return View(\"DelegateList\", models);\n        }\n        // Add a relationship (DelegateExamResult) between Delegate (parent) ExamResult (child)\n        //[Authorize(Roles = \"Admin,SaveDelegateExamResult\")]\n\t\t[RolesRequired(\"Admin\",\"SaveDelegateExamResult\")]  \n        public ActionResult AddDelegateExamResult(int id)\n        {\n            ViewBag.Readonly = false;\n            ViewBag.ShowRelationships = false;\n            ViewBag.ModelId = new int?(id);\n            return View(\"Form\", new DelegateViewModel());\n        }\n        // Add a relationship (DelegateExamResult) between Delegate (parent) ExamResult (child)\n        [HttpPost]\n        //[Authorize(Roles = \"Admin,SaveDelegateExamResult\")]\n\t\t[RolesRequired(\"Admin\",\"SaveDelegateExamResult\")]\n        public ActionResult SaveDelegateExamResult(DelegateViewModel model, int modelId)\n        {\n            var errors = new List<IModelError>();\n            model.Id = 0 ; // force a new object regardless\n            var result = service.TrySave(model, errors);\n            if (result)\n            {\n                service.AddExamResultToDelegateForDelegateExamResult(model.Id, modelId);\n            }\n            return Json(new\n            {\n                Model = model,\n                Success = result,\n                Errors = errors\n            });\n        }\n        // remove a relationship (DelegateExamResult) between Delegate (parent) ExamResult (child) \n        [HttpPost]\n\t\t[RolesRequired(\"Admin\",\"SaveDelegateExamResult\")]       \n        public ActionResult UnLinkDelegateExamResult(int modelId , int[] items)\n        {\n            var result = true;\n            try\n            {\n                items.DefaultIfNull().AsParallel().ToList().ForEach(i => {\n\t\t\t\t\tservice.RemoveExamResultFromDelegateForDelegateExamResult(modelId, i);\t\t\t\t\t                  \n                });\n            }\n            catch \n            {\n\t\t\t\titems.DefaultIfNull().AsParallel().ToList().ForEach(i => {                    \n\t\t\t\t\tservice.AddExamResultToDelegateForDelegateExamResult(modelId, i);  \n                });\n                result = false;  \n            }\n                                   \n            return Json(new\n            {\n                Success = result\n            });\n        }\n        // add a relationship (DelegateExamResult) between existing Delegate (parent) ExamResult (child) \n        [HttpPost]\n        [RolesRequired(\"Admin\",\"SaveDelegateExamResult\")]  \n        public ActionResult LinkDelegateExamResult(int modelId , int[] items)\n        {\n            var result = true;\n            try\n            {\n                items.DefaultIfNull().AsParallel().ToList().ForEach(i => {\n\t\t\t\t\tservice.AddExamResultToDelegateForDelegateExamResult(modelId, i);                    \n                });\n            }\n            catch \n            {\n\t\t\t\titems.DefaultIfNull().AsParallel().ToList().ForEach(i => {                    \n\t\t\t\t\tservice.RemoveExamResultFromDelegateForDelegateExamResult(modelId, i);\n                });\n                result = false;  \n            }\n                                   \n            return Json(new\n            {\n                Success = result\n            });\n        }\n                \n        // Supports the many to many relationship (EventDelegate) between Delegate (child) Event (parent)\n        [RolesRequired(\"Admin\",\"ListEventDelegate\")]  \n        public ActionResult GetEventDelegate(int id) \n        {\n            var models = service.GetAllForEventDelegate(id);\n            ViewBag.ToolButtons = \"VP\"; // View Pick \n            ViewBag.PickState = true;\n            return View(\"DelegateList\", models);\n        }\n        // Add a relationship (EventDelegate) between Event (parent) Delegate (child)\n        [RolesRequired(\"Admin\",\"SaveEventDelegate\")] \n        public ActionResult AddEventDelegate()\n        {\n            ViewBag.Readonly = false;\n            ViewBag.ShowRelationships = false;\n", "outputs": ["            return View(\"Form\", new DelegateViewModel());"], "input_length": 2084, "output_length": 13, "length": 2097, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "ed86ac503ee1b561543e60af41e87358b0c9f3bf74f0397428bb7624efcd22ec"}
{"input": "", "context": "/*\n * ome.testing\n *\n *   Copyright 2006 University of Dundee. All rights reserved.\n *   Use is subject to license terms supplied in LICENSE.txt\n */\npackage ome.testing;\n// Java imports\nimport java.util.ArrayList;\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Random;\nimport javax.sql.DataSource;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.jdbc.core.JdbcTemplate;\nimport org.springframework.jdbc.support.rowset.SqlRowSet;\nimport org.springframework.jdbc.support.rowset.SqlRowSetMetaData;\n// Application-internal dependencies\n/**\n * abstract data container for testing. Sub-classes can set whatever values it\n * would like in <code>init()</code>. After the OMEData instance is inserted\n * into the test class by Spring, it SHOULD not be changed, but this is a matter\n * of opionon. Setting the same <code>seed</code> value for two independent\n * Data instances is also assumed to create identical values.\n * \n * @author Josh Moore &nbsp;&nbsp;&nbsp;&nbsp; <a\n *         href=\"mailto:josh.moore@gmx.de\">josh.moore@gmx.de</a>\n * @version 1.0 <small> (<b>Internal version:</b> $Rev$ $Date$) </small>\n * @since 1.0\n */\npublic class OMEData {\n    final static String emptyColl = \"Collections may not be empty.\\n\"\n            + \"You are currently trying to run a test on an OME database\\n\"\n            + \"that does not appear to have the needed data.\\n\"\n            + \"\\n\"\n            + \"There must be at least one:\\n\"\n            + \"project,dataset,image,experimenter,classification,category,category group,image annotation and dataset annotation\\n\"\n            + \"\\n\"\n            + \"Testing results would be unpredictable without test data.\\n\"\n            + \"Please fill your database and retry.\";\n    private static Logger log = LoggerFactory.getLogger(OMEData.class);\n    boolean initialized = false;\n    DataSource ds;\n    Map properties;\n    Map values = new HashMap();\n    long seed;\n    Random rnd;\n    String[] files = new String[] { \"test_data.properties\" };\n    public void setDataSource(DataSource dataSource) {\n        this.ds = dataSource;\n    }\n    public OMEData() {\n        init();\n    }\n    public OMEData(String[] files) {\n        this.files = files;\n        init();\n    }\n    void init() {\n        properties = SqlPropertiesParser.parse(files);\n        seed = System.currentTimeMillis();\n        rnd = new Random(seed);\n    }\n    /* allows for storing arbitrary objects in data */\n    public void put(String propertyKey, Object value) {\n        toCache(propertyKey, value);\n    }\n    public List get(String propertyKey) {\n        if (inCache(propertyKey)) {\n            return (List) fromCache(propertyKey);\n        }\n        Object obj = properties.get(propertyKey);\n        if (obj == null) {\n            return null;\n        } else if (obj instanceof List) {\n            toCache(propertyKey, obj);\n            return (List) obj;\n        } else if (obj instanceof String) {\n            String sql = (String) obj;\n            List result = runSql(sql);\n            toCache(propertyKey, result);\n            return result;\n        } else {\n            throw new RuntimeException(\"Error in properties. Not expecting \"\n                    + obj == null ? null : obj.getClass().getName());\n        }\n    }\n    List getRandomNumber(List l, Number number) {\n        if (number == null) {\n            return null;\n        }\n        if (l == null || l.size() == 0) {\n            log.warn(emptyColl);\n            return null;\n        }\n        List ordered = new ArrayList(l);\n        List result = new ArrayList();\n        while (ordered.size() > 0 && result.size() < number.longValue()) {\n            int choice = randomChoice(ordered.size());\n            result.add(ordered.remove(choice));\n        }\n        return result;\n    }\n    public List getMax(String propertyKey, int maximum) {\n        List l = get(propertyKey);\n        return getRandomNumber(l, new Integer(maximum));\n    }\n    public List getPercent(String propertyKey, double percent) {\n        List l = get(propertyKey);\n        return getRandomNumber(l, new Double(l.size() * percent));\n    }\n    public Object getRandom(String propertyKey) {\n        List l = get(propertyKey);\n        List result = getRandomNumber(l, new Integer(1));\n        if (result == null || result.size() < 1) {\n            return null;\n        }\n        return result.get(0);\n    }\n    public Object getFirst(String propertyKey) {\n        List l = get(propertyKey);\n        if (l == null || l.size() == 0) {\n            log.warn(emptyColl);\n            return null;\n        }\n        return l.get(0);\n    }\n    boolean inCache(String key) {\n        return values.containsKey(key);\n    }\n    void toCache(String key, Object value) {\n        values.put(key, value);\n    }\n    Object fromCache(String key) {\n        return values.get(key);\n    }\n    /**\n     * returns a list of results from the sql statement. if there is more than\n     * one column in the result set, a map from column name to Object is\n     * returned, else the Object itself.\n     * \n     * @param sql\n     * @return\n     */\n    List runSql(String sql) {\n        JdbcTemplate jt = new JdbcTemplate(ds);\n        SqlRowSet rows = jt.queryForRowSet(sql);\n        List result = new ArrayList();\n        while (rows.next()) {\n            SqlRowSetMetaData meta = rows.getMetaData();\n            int count = meta.getColumnCount();\n            if (count > 1) {\n                Map cols = new HashMap();\n                String[] names = meta.getColumnNames();\n                for (int i = 0; i < names.length; i++) {\n                    cols.put(names[i], rows.getObject(names[i]));\n                }\n                result.add(cols);\n            } else {\n                result.add(rows.getObject(1));\n            }\n        }\n        log.debug(\"SQL:\" + sql + \"\\n\\nResult:\" + result);\n        return result;\n    }\n    public int randomChoice(int size) {\n", "outputs": ["        double value = (size - 1) * rnd.nextDouble();"], "input_length": 1133, "output_length": 13, "length": 1146, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "14e7ba41bb70e416dd3d3789adabc5d001ab6697a970d68acc19bd78264574af"}
{"input": "", "context": "//\n//  LED_Queue.cs\n//\n//  Author:\n//       Shane Synan <digitalcircuit36939@gmail.com>\n//\n//  Copyright (c) 2015 - 2016\n//\n//  This program is free software: you can redistribute it and/or modify\n//  it under the terms of the GNU General Public License as published by\n//  the Free Software Foundation, either version 3 of the License, or\n//  (at your option) any later version.\n//\n//  This program is distributed in the hope that it will be useful,\n//  but WITHOUT ANY WARRANTY; without even the implied warranty of\n//  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n//  GNU General Public License for more details.\n//\n//  You should have received a copy of the GNU General Public License\n//  along with this program.  If not, see <http://www.gnu.org/licenses/>.\nusing System;\nusing System.Collections.Generic;\n// Animation management\nusing Actinic.Animations;\n// Rendering\nusing Actinic.Rendering;\nnamespace Actinic\n{\n\tpublic class LED_Queue\n\t{\n\t\t/// <summary>\n\t\t/// Modifiable list of LEDs representing the desired output state\n\t\t/// </summary>\n\t\tpublic Layer Lights;\n\t\t/// <summary>\n\t\t/// Gets a list of LEDs representing the last state processed by the output system, useful for fades\n\t\t/// </summary>\n\t\t/// <value>Read-only list of LEDs</value>\n\t\tpublic Layer LightsLastProcessed {\n\t\t\tget;\n\t\t\tprivate set;\n\t\t}\n\t\t/// <summary>\n\t\t/// Gets the number of lights\n\t\t/// </summary>\n\t\t/// <value>Number of lights</value>\n\t\tpublic int LightCount {\n\t\t\tget { return Lights.PixelCount; }\n\t\t}\n\t\t/// <summary>\n\t\t/// Gets a value indicating whether the selected animation is active.\n\t\t/// </summary>\n\t\t/// <value><c>true</c> if an animation is active; otherwise, <c>false</c>.</value>\n\t\tpublic bool AnimationActive {\n\t\t\tget { return (SelectedAnimation != null); }\n\t\t}\n\t\t/// <summary>\n\t\t/// If <c>true</c>, force an update for the next frame request in the output system loop\n\t\t/// </summary>\n\t\tpublic bool AnimationForceFrameRequest = false;\n\t\t/// <summary>\n\t\t/// The currently selected animation.\n\t\t/// </summary>\n\t\tpublic AbstractAnimation SelectedAnimation = null;\n\t\t/// <summary>\n\t\t/// How long the output queue has been idle.\n\t\t/// </summary>\n\t\tpublic int QueueIdleTime = 0;\n\t\t/// <summary>\n\t\t/// Gets a value indicating whether the output queue is empty.\n\t\t/// </summary>\n\t\t/// <value><c>true</c> if queue is empty; otherwise, <c>false</c>.</value>\n\t\tpublic bool QueueEmpty {\n\t\t\tget { return (OutputQueue.Count <= 0); }\n\t\t}\n\t\t/// <summary>\n\t\t/// Gets the number of frames currently in the output queue.\n\t\t/// </summary>\n\t\t/// <value>Number representing frames waiting in output queue.</value>\n\t\tpublic int QueueCount {\n\t\t\tget { return OutputQueue.Count; }\n\t\t}\n\t\t/// <summary>\n\t\t/// Gets a value indicating whether this <see cref=\"Actinic.LED_Queue\"/> has any effect on ouput, i.e. LEDs\n\t\t/// are not all black with no brightness.\n\t\t/// </summary>\n\t\t/// <value><c>true</c> if lights have no effect; otherwise, <c>false</c>.</value>\n\t\tpublic bool LightsHaveNoEffect {\n\t\t\tget {\n\t\t\t\tif (AnimationActive == true || QueueEmpty == false)\n\t\t\t\t\treturn false;\n\t\t\t\t// Check if the lights -don't- have an effect.\n\t\t\t\treturn !Lights.HasEffect;\n\t\t\t}\n\t\t}\n\t\t// FIXME: Revisit queue-wide blend-mode after LED Queue update\n\t\tprivate Color.BlendMode blending_mode = Color.BlendMode.Combine;\n\t\t/// <summary>\n\t\t/// When merged down, this defines how the layer should be handled, default of Combine.\n\t\t/// </summary>\n\t\t/// <value>The blending mode.</value>\n\t\tpublic Color.BlendMode BlendMode {\n\t\t\tget {\n\t\t\t\treturn blending_mode;\n\t\t\t}\n\t\t\tset {\n\t\t\t\tblending_mode = value;\n\t\t\t}\n\t\t}\n\t\tprivate Queue<Layer> OutputQueue = new Queue<Layer> ();\n\t\tpublic LED_Queue (int LED_Light_Count)\n\t\t{\n\t\t\tInitializeFromBlanks (LED_Light_Count, false);\n\t\t}\n\t\tpublic LED_Queue (int LED_Light_Count, bool ClearAllLEDs)\n\t\t{\n\t\t\tInitializeFromBlanks (LED_Light_Count, ClearAllLEDs);\n\t\t}\n\t\tprivate void InitializeFromBlanks (\n\t\t\tint LED_Light_Count, bool ClearAllLEDs)\n\t\t{\n\t\t\tbyte brightness = (ClearAllLEDs ? (byte)0 : Color.MAX);\n\t\t\tColor fillColor = new Color (0, 0, 0, brightness);\n\t\t\t// Fill the layer with the given color\n\t\t\tLights =\n\t\t\t\tnew Layer (LED_Light_Count, Color.BlendMode.Combine, fillColor);\n\t\t\t// Copy to the processed list.  When first initializing, skip\n\t\t\t// locking.\n\t\t\tLightsLastProcessed = Lights.Clone ();\n\t\t}\n\t\tpublic LED_Queue (Layer PreviouslyShownFrame)\n\t\t{\n\t\t\tLights = PreviouslyShownFrame.Clone ();\n\t\t\t// Copy to the processed list.  When first initializing, skip\n\t\t\t// locking.\n\t\t\tLightsLastProcessed = Lights.Clone ();\n\t\t}\n\t\t/// <summary>\n\t\t/// Marks the current queue as processed, copying it to LightsLastProcessed\n\t\t/// </summary>\n\t\tpublic void MarkAsProcessed ()\n\t\t{\n\t\t\tlock (Lights) {\n\t\t\t\tlock (LightsLastProcessed) {\n\t\t\t\t\t// Clone the layer over to avoid any reference links\n\t\t\t\t\tLightsLastProcessed = Lights.Clone ();\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t/// <summary>\n\t\t/// Grabs the first frame from the queue if entries are queued, otherwise returns null\n\t\t/// </summary>\n\t\t/// <returns>If multiple frames are queued, returns a Layer, otherwise null</returns>\n\t\tpublic Layer PopFromQueue ()\n\t\t{\n\t\t\tlock (OutputQueue) {\n\t\t\t\tif (OutputQueue.Count > 0) {\n\t\t\t\t\tLayer result = OutputQueue.Dequeue ();\n\t\t\t\t\t// Update the layer blending mode to the queue default\n\t\t\t\t\t// FIXME: Revisit blend-mode coercion after LED Queue update\n\t\t\t\t\tresult.Blending = BlendMode;\n\t\t\t\t\treturn result;\n\t\t\t\t} else {\n\t\t\t\t\treturn null;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t/// <summary>\n\t\t/// Adds the current state of the Lights frame to the end of the output queue\n\t\t/// </summary>\n\t\tpublic void PushToQueue ()\n\t\t{\n\t\t\tPushToQueue (false);\n\t\t}\n\t\t/// <summary>\n\t\t/// Adds a frame to the end of the output queue\n\t\t/// </summary>\n\t\t/// <param name=\"NextFrame\">A Layer representing the desired frame.</param>\n\t\tpublic void PushToQueue (Layer NextFrame)\n\t\t{\n\t\t\tif (NextFrame.PixelCount != LightCount)\n\t\t\t\tthrow new ArgumentOutOfRangeException (\"NextFrame\",\n\t\t\t\t\tstring.Format (\n\t\t\t\t\t\t\"NextFrame must contain same number of LEDs (has {0},\" +\n", "outputs": ["\t\t\t\t\t\t\" expected {1})\", NextFrame.PixelCount, LightCount"], "input_length": 1152, "output_length": 11, "length": 1163, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "faea2d8694e242e184d1c581472e34f23620ac66d41df73b9f3b217a86b1c9cc"}
{"input": "", "context": "import numpy as np\nimport larray as la\nfrom larray_editor.utils import Product, _LazyDimLabels, Axis, get_sample\nfrom larray_editor.commands import ArrayValueChange\nREGISTERED_ADAPTERS = {}\ndef register_adapter(type):\n    \"\"\"Class decorator to register new adapter\n    Parameters\n    ----------\n    type : type\n        Type associated with adapter class.\n    \"\"\"\n    def decorate_class(cls):\n        if type not in REGISTERED_ADAPTERS:\n            REGISTERED_ADAPTERS[type] = cls\n        return  cls\n    return decorate_class\ndef get_adapter(data, bg_value):\n    if data is None:\n        return None\n    data_type = type(data)\n    if data_type not in REGISTERED_ADAPTERS:\n        raise TypeError(\"No Adapter implemented for data with type {}\".format(data_type))\n    adapter_cls = REGISTERED_ADAPTERS[data_type]\n    return adapter_cls(data, bg_value)\nclass AbstractAdapter(object):\n    def __init__(self, data, bg_value):\n        self.data = data\n        self.bg_value = bg_value\n        self.current_filter = {}\n        self.update_filtered_data()\n        self.ndim = None\n        self.size = None\n        self.dtype = None\n    # ===================== #\n    #      PROPERTIES       #\n    # ===================== #\n    @property\n    def data(self):\n        return self._original_data\n    @data.setter\n    def data(self, original_data):\n        assert original_data is not None, \"{} does not accept None as input data\".format(self.__class__)\n        self._original_data = self.prepare_data(original_data)\n    @property\n    def bg_value(self):\n        return self._bg_value\n    @bg_value.setter\n    def bg_value(self, bg_value):\n        self._bg_value = self.prepare_bg_value(bg_value)\n    # ===================== #\n    #  METHODS TO OVERRIDE  #\n    # ===================== #\n    def prepare_data(self, data):\n        \"\"\"Must be overridden if data passed to set_data need some checks and/or transformations\"\"\"\n        return data\n    def prepare_bg_value(self, bg_value):\n        \"\"\"Must be overridden if bg_value passed to set_data need some checks and/or transformations\"\"\"\n        return bg_value\n    def filter_data(self, data, filter):\n        \"\"\"Return filtered data\"\"\"\n        raise NotImplementedError()\n    def get_axes(self, data):\n        \"\"\"Return list of :py:class:`Axis` or an empty list in case of a scalar or an empty array.\n        \"\"\"\n        raise NotImplementedError()\n    def _get_raw_data(self, data):\n        \"\"\"Return internal data as a ND Numpy array\"\"\"\n        raise NotImplementedError()\n    def _get_bg_value(self, bg_value):\n        \"\"\"Return bg_value as ND Numpy array or None.\n        It must have the same shape as data if not None.\n        \"\"\"\n        raise NotImplementedError()\n    def _from_selection(self, raw_data, axes_names, vlabels, hlabels):\n        \"\"\"Create and return an object of type managed by the adapter subclass.\n        Parameters\n        ----------\n        raw_data : Numpy.ndarray\n            Array of selected data.\n        axes_names : list of string\n            List of axis names\n        vlabels : nested list\n            Selected vertical labels\n        hlabels: list\n            Selected horizontal labels\n        Returns\n        -------\n        Object of the type managed by the adapter subclass.\n        \"\"\"\n        raise NotImplementedError()\n    def move_axis(self, data, bg_value, old_index, new_index):\n        \"\"\"Move an axis of the data array and associated bg value.\n        Parameters\n        ----------\n        data : array\n            Array to transpose\n        bg_value : array or None\n            Associated bg_value array.\n        old_index: int\n            Current index of axis to move.\n        new_index: int\n            New index of axis after transpose.\n        Returns\n        -------\n        data : array\n            Transposed input array\n        bg_value: array\n            Transposed associated bg_value\n        \"\"\"\n        raise NotImplementedError()\n    def _map_global_to_filtered(self, data, filtered_data, filter, key):\n        \"\"\"\n        map global (unfiltered) ND key to local (filtered) 2D key\n        Parameters\n        ----------\n        data : array\n            Input array.\n        filtered_data : array\n            Filtered data.\n        filter : dict\n            Current filter.\n        key: tuple\n            Labels associated with the modified element of the non-filtered array.\n        Returns\n        -------\n        tuple\n            Positional index (row, column) of the modified data cell.\n        \"\"\"\n        raise NotImplementedError()\n    def _map_filtered_to_global(self, filtered_data, data, filter, key):\n        \"\"\"\n        map local (filtered data) 2D key to global (unfiltered) ND key.\n        Parameters\n        ----------\n        filtered_data : array\n            Filtered data.\n        data : array\n            Input array.\n        filter : dict\n            Current filter.\n        key: tuple\n            Positional index (row, column) of the modified data cell.\n        Returns\n        -------\n        tuple\n            Labels associated with the modified element of the non-filtered array.\n        \"\"\"\n        raise NotImplementedError()\n    def _to_excel(self, data):\n        \"\"\"Export data to an Excel Sheet\n        Parameters\n        ----------\n        data : array\n            data to export.\n        \"\"\"\n        raise NotImplementedError()\n    def _plot(self, data):\n        \"\"\"Return a matplotlib.Figure object using input data.\n        Parameters\n        ----------\n        data : array\n            Data to plot.\n        Returns\n        -------\n        A matplotlib.Figure object.\n        \"\"\"\n        raise NotImplementedError\n    # =========================== #\n    #       OTHER METHODS         #\n    # =========================== #\n    def get_axes_filtered_data(self):\n        return self.get_axes(self.filtered_data)\n    def get_sample(self):\n        \"\"\"Return a sample of the internal data\"\"\"\n        data = self._get_raw_data(self.filtered_data)\n        # this will yield a data sample of max 200\n        sample = get_sample(data, 200)\n        return sample[np.isfinite(sample)]\n    def get_axes_names(self, fold_last_axis=False):\n        axes_names = [axis.name for axis in self.get_axes_filtered_data()]\n        if fold_last_axis and len(axes_names) >= 2:\n            axes_names = axes_names[:-2] + [axes_names[-2] + '\\\\' + axes_names[-1]]\n        return axes_names\n    def get_vlabels(self):\n        axes = self.get_axes(self.filtered_data)\n        if len(axes) == 0:\n            vlabels = [[]]\n        elif len(axes) == 1:\n            vlabels = [['']]\n        else:\n            vlabels = [axis.labels for axis in axes[:-1]]\n            prod = Product(vlabels)\n            vlabels = [_LazyDimLabels(prod, i) for i in range(len(vlabels))]\n        return vlabels\n    def get_hlabels(self):\n        axes = self.get_axes(self.filtered_data)\n        if len(axes) == 0:\n            hlabels = [[]]\n        else:\n            hlabels = axes[-1].labels\n            hlabels = Product([hlabels])\n        return hlabels\n    def _get_shape_2D(self, np_data):\n        shape, ndim = np_data.shape, np_data.ndim\n        if ndim == 0:\n            shape_2D = (1, 1)\n        elif ndim == 1:\n            shape_2D = (1,) + shape\n        elif ndim == 2:\n            shape_2D = shape\n        else:\n            shape_2D = (np.prod(shape[:-1]), shape[-1])\n        return shape_2D\n    def get_raw_data(self):\n        # get filtered data as Numpy ND array\n        np_data = self._get_raw_data(self.filtered_data)\n        assert isinstance(np_data, np.ndarray)\n        # compute equivalent 2D shape\n        shape_2D = self._get_shape_2D(np_data)\n        assert shape_2D[0] * shape_2D[1] == np_data.size\n        # return data reshaped as 2D array\n        return np_data.reshape(shape_2D)\n    def get_bg_value(self):\n        # get filtered bg value as Numpy ND array or None\n        if self.bg_value is None:\n            return self.bg_value\n        np_bg_value = self._get_bg_value(self.filter_data(self.bg_value, self.current_filter))\n        # compute equivalent 2D shape\n        shape_2D = self._get_shape_2D(np_bg_value)\n        assert shape_2D[0] * shape_2D[1] == np_bg_value.size\n        # return bg_value reshaped as 2D array if not None\n        return np_bg_value.reshape(shape_2D)\n    def update_filtered_data(self):\n        self.filtered_data = self.filter_data(self.data, self.current_filter)\n    def change_filter(self, data, filter, axis, indices):\n        \"\"\"Update current filter for a given axis if labels selection from the array widget has changed\n        Parameters\n        ----------\n        data : array\n            Input array.\n        filter: dict\n            Dictionary {axis_id: labels} representing the current selection.\n        axis: Axis\n             Axis for which selection has changed.\n        indices: list of int\n            Indices of selected labels.\n        \"\"\"\n        axis_id = axis.id\n        if not indices or len(indices) == len(axis):\n            if axis_id in filter:\n                del filter[axis_id]\n        else:\n            if len(indices) == 1:\n                filter[axis_id] = axis.labels[indices[0]]\n            else:\n                filter[axis_id] = axis.labels[indices]\n    def update_filter(self, axis, indices):\n        self.change_filter(self.data, self.current_filter, axis, indices)\n        self.update_filtered_data()\n    def translate_changes(self, data_model_changes):\n        def to_global(key):\n            return self._map_filtered_to_global(self.filtered_data, self.data, self.current_filter, key)\n        global_changes = [ArrayValueChange(to_global(key), old_value, new_value)\n", "outputs": ["                          for key, (old_value, new_value) in data_model_changes.items()]"], "input_length": 1585, "output_length": 13, "length": 1598, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "d633774ed49881d4ce83cd9f52f058801ade314d33f3709bbfa097f290c8c982"}
{"input": "", "context": "using System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing Server.Factions;\nusing Server.Mobiles;\nusing Server.Multis;\nusing Server.Targeting;\nusing Server.Engines.VvV;\nusing Server.Items;\nusing Server.Spells;\nusing Server.Network;\nnamespace Server.Items\n{\n    public interface IRevealableItem\n    {\n        bool CheckReveal(Mobile m);\n        bool CheckPassiveDetect(Mobile m);\n        void OnRevealed(Mobile m);\n        bool CheckWhenHidden { get; }\n    }\n}\nnamespace Server.SkillHandlers\n{\n    public class DetectHidden\n    {\n        public static void Initialize()\n        {\n            SkillInfo.Table[(int)SkillName.DetectHidden].Callback = new SkillUseCallback(OnUse);\n        }\n        public static TimeSpan OnUse(Mobile src)\n        {\n            src.SendLocalizedMessage(500819);//Where will you search?\n            src.Target = new InternalTarget();\n            return TimeSpan.FromSeconds(10.0);\n        }\n        public class InternalTarget : Target\n        {\n            public InternalTarget()\n                : base(12, true, TargetFlags.None)\n            {\n            }\n            protected override void OnTarget(Mobile src, object targ)\n            {\n                bool foundAnyone = false;\n                Point3D p;\n                if (targ is Mobile)\n                    p = ((Mobile)targ).Location;\n                else if (targ is Item)\n                    p = ((Item)targ).Location;\n                else if (targ is IPoint3D)\n                    p = new Point3D((IPoint3D)targ);\n                else\n                    p = src.Location;\n                double srcSkill = src.Skills[SkillName.DetectHidden].Value;\n                int range = Math.Max(2, (int)(srcSkill / 10.0));\n                if (!src.CheckSkill(SkillName.DetectHidden, 0.0, 100.0))\n                    range /= 2;\n                BaseHouse house = BaseHouse.FindHouseAt(p, src.Map, 16);\n                bool inHouse = house != null && house.IsFriend(src);\n                if (inHouse)\n                    range = 22;\n                if (range > 0)\n                {\n                    IPooledEnumerable inRange = src.Map.GetMobilesInRange(p, range);\n                    foreach (Mobile trg in inRange)\n                    {\n                        if (trg.Hidden && src != trg)\n                        {\n                            double ss = srcSkill + Utility.Random(21) - 10;\n                            double ts = trg.Skills[SkillName.Hiding].Value + Utility.Random(21) - 10;\n                            double shadow = Server.Spells.SkillMasteries.ShadowSpell.GetDifficultyFactor(trg);\n                            bool houseCheck = inHouse && house.IsInside(trg);\n                            if (src.AccessLevel >= trg.AccessLevel && (ss >= ts || houseCheck) && Utility.RandomDouble() > shadow)\n                            {\n                               if ((trg is ShadowKnight && (trg.X != p.X || trg.Y != p.Y)) ||\n                                    (!houseCheck && !CanDetect(src, trg)))\n                                    continue;\n                                trg.RevealingAction();\n                                trg.SendLocalizedMessage(500814); // You have been revealed!\n                                trg.PrivateOverheadMessage(MessageType.Regular, 0x3B2, 500814, trg.NetState);\n                                foundAnyone = true;\n                            }\n                        }\n                    }\n                    inRange.Free();\n                    IPooledEnumerable itemsInRange = src.Map.GetItemsInRange(p, range);\n                    foreach (Item item in itemsInRange)\n                    {\n                        if (item is LibraryBookcase && Server.Engines.Khaldun.GoingGumshoeQuest3.CheckBookcase(src, item))\n                        {\n                            foundAnyone = true;\n                        }\n                        else\n                        {\n                            IRevealableItem dItem = item as IRevealableItem;\n                            if (dItem == null || (item.Visible && dItem.CheckWhenHidden))\n                                continue;\n                            if (dItem.CheckReveal(src))\n                            {\n                                dItem.OnRevealed(src);\n                                foundAnyone = true;\n                            }\n                        }\n                    }\n                    itemsInRange.Free();\n                }\n                if (!foundAnyone)\n                {\n                    src.SendLocalizedMessage(500817); // You can see nothing hidden there.\n                }\n            }\n        }\n        public static void DoPassiveDetect(Mobile src)\n        {\n            if (src == null || src.Map == null || src.Location == Point3D.Zero || src.IsStaff())\n                return;\n            double ss = src.Skills[SkillName.DetectHidden].Value;\n            if (ss <= 0)\n                return;\n            IPooledEnumerable eable = src.Map.GetMobilesInRange(src.Location, 4);\n            if (eable == null)\n                return;\n            foreach (Mobile m in eable)\n            {\n                if (m == null || m == src || m is ShadowKnight || !CanDetect(src, m))\n                    continue;\n                double ts = (m.Skills[SkillName.Hiding].Value + m.Skills[SkillName.Stealth].Value) / 2;\n                if (src.Race == Race.Elf)\n                    ss += 20;\n                if (src.AccessLevel >= m.AccessLevel && Utility.Random(1000) < (ss - ts) + 1)\n                {\n                    m.RevealingAction();\n                    m.SendLocalizedMessage(500814); // You have been revealed!\n                }\n            }\n            eable.Free();\n            eable = src.Map.GetItemsInRange(src.Location, 8);\n            foreach (Item item in eable)\n            {\n                if (!item.Visible && item is IRevealableItem && ((IRevealableItem)item).CheckPassiveDetect(src))\n                {\n                    src.SendLocalizedMessage(1153493); // Your keen senses detect something hidden in the area...\n                }\n            }\n            eable.Free();\n        }\n        public static bool CanDetect(Mobile src, Mobile target)\n        {\n            if (src.Map == null || target.Map == null || !src.CanBeHarmful(target, false))\n                return false;\n            // No invulnerable NPC's\n            if (src.Blessed || (src is BaseCreature && ((BaseCreature)src).IsInvulnerable))\n                return false;\n            if (target.Blessed || (target is BaseCreature && ((BaseCreature)target).IsInvulnerable))\n                return false;\n            // pet owner, guild/alliance, party\n            if (!Server.Spells.SpellHelper.ValidIndirectTarget(target, src))\n                return false;\n            // Checked aggressed/aggressors\n            if (src.Aggressed.Any(x => x.Defender == target) || src.Aggressors.Any(x => x.Attacker == target))\n                return true;\n            // In Fel or Follow the same rules as indirect spells such as wither\n", "outputs": ["            return src.Map.Rules == MapRules.FeluccaRules;"], "input_length": 970, "output_length": 5, "length": 975, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "fb9e98e87fde7dd21e1678b59873cdef9384fc217159560fb20eb4795f5115ad"}
{"input": "", "context": "package protocol.xmpp;\nimport android.util.Log;;\nimport protocol.Contact;\nimport protocol.Protocol;\nimport ru.sawim.comm.Util;\nimport ru.sawim.io.RosterStorage;\nimport ru.sawim.listener.OnMoreMessagesLoaded;\nimport ru.sawim.roster.RosterHelper;\nimport java.util.HashSet;\nimport java.util.concurrent.ConcurrentHashMap;\n/**\n * Created by gerc on 05.03.2015.\n */\npublic class MessageArchiveManagement {\n    private static final long MILLISECONDS_IN_DAY = 24 * 60 * 60 * 1000;\n    public static final long MAX_CATCHUP = MILLISECONDS_IN_DAY * 7;\n    public static final long MAX_MESSAGES = 20;\n    private final HashSet<Query> queries = new HashSet<>();\n    private String getQueryMessageArchiveManagement(Contact contact, Query query) {\n        XmlNode xmlNode = new XmlNode(XmlConstants.S_IQ);\n        xmlNode.putAttribute(XmlConstants.S_TYPE, XmlConstants.S_SET);\n        if (contact != null && contact.isConference()) {\n            xmlNode.putAttribute(XmlConstants.S_TO, Util.xmlEscape(contact.getUserId()));\n        }\n        xmlNode.putAttribute(XmlNode.S_ID, XmppConnection.generateId());\n        XmlNode queryNode = new XmlNode(XmlConstants.S_QUERY);\n        queryNode.putAttribute(XmlNode.S_XMLNS, \"urn:xmpp:mam:0\");\n        queryNode.putAttribute(\"queryid\", query.queryId);\n        XmlNode xNode = new XmlNode(\"x\");\n        xNode.putAttribute(XmlNode.S_XMLNS, \"jabber:x:data\");\n        xNode.putAttribute(\"type\", \"submit\");\n        XmlNode formTypeNode = new XmlNode(\"field\");\n        formTypeNode.putAttribute(\"var\", \"FORM_TYPE\");\n        formTypeNode.putAttribute(\"type\", \"hidden\");\n        formTypeNode.setValue(\"value\", \"urn:xmpp:mam:0\");\n        xNode.addNode(formTypeNode);\n    /*    if (query.getStart() > 0) {\n            XmlNode startNode = new XmlNode(\"field\");\n            startNode.putAttribute(\"var\", \"start\");\n            startNode.setValue(\"value\", Util.getTimestamp(query.getStart()));\n            xNode.addNode(startNode);\n        }\n        if (query.getEnd() > 0) {\n            XmlNode endNode = new XmlNode(\"field\");\n            endNode.putAttribute(\"var\", \"end\");\n            endNode.setValue(\"value\", Util.getTimestamp(query.getEnd()));\n            xNode.addNode(endNode);\n        }*/\n        if (query.withJid != null && contact != null && !contact.isConference()) {\n            XmlNode withNode = new XmlNode(\"field\");\n            withNode.putAttribute(\"var\", \"with\");\n            withNode.setValue(\"value\", query.withJid);\n            xNode.addNode(withNode);\n        }\n        XmlNode setNode = XmlNode.addXmlns(\"set\", \"http://jabber.org/protocol/rsm\");\n        setNode.setValue(\"max\", String.valueOf(MAX_MESSAGES));\n        if (query.getPagingOrder() == PagingOrder.REVERSE) {\n            setNode.setValue(\"before\", query.getReference());\n        } else {\n            setNode.setValue(\"after\", query.getReference());\n        }\n        queryNode.addNode(setNode);\n        queryNode.addNode(xNode);\n        xmlNode.addNode(queryNode);\n        return xmlNode.toString();\n    }\n    private void queryMessageArchiveManagement(XmppConnection connection, Query query) {\n        Contact contact = null;\n        if (query.getWith() != null) {\n            contact = connection.getProtocol().getItemByUID(query.getWith());\n        }\n        connection.putPacketIntoQueue(getQueryMessageArchiveManagement(contact, query));\n    }\n    public void catchup(XmppConnection connection) {\n        long startCatchup = getLastMessageTransmitted(connection);\n        long endCatchup = connection.getLastSessionEstablished();\n        if (startCatchup == 0) {\n            return;\n        } else {\n            ConcurrentHashMap<String, Contact> contacts = connection.getProtocol().getContactItems();\n            for (Contact contact : contacts.values()) {\n                queryReverse(connection, contact, startCatchup);\n            }\n        }\n        final Query query = new Query(connection.getXmpp().getUserId(), null, startCatchup, endCatchup);\n        queries.add(query);\n        queryMessageArchiveManagement(connection, query);\n    }\n    private long getLastMessageTransmitted(XmppConnection connection) {\n        long timestamp = 0;\n        for (Contact contact : connection.getProtocol().getContactItems().values()) {\n            long lastMessageTransmitted = contact.getLastMessageTransmitted();\n            if (lastMessageTransmitted > timestamp) {\n                timestamp = lastMessageTransmitted;\n            }\n        }\n        return timestamp;\n    }\n    public Query queryReverse(XmppConnection connection, final Contact contact) {\n        return queryReverse(connection, contact, connection.getLastSessionEstablished());\n    }\n    public Query queryReverse(XmppConnection connection, final Contact contact, long end) {\n        long lastMessageTransmitted = contact.getLastMessageTransmitted();\n        return queryReverse(connection, contact, lastMessageTransmitted, end);\n    }\n    public Query queryReverse(XmppConnection connection, Contact contact, long start, long end) {\n        synchronized (queries) {\n            if (start > end) {\n                return null;\n            }\n            final Query query = new Query(connection.getXmpp().getUserId(), contact.getUserId(),\n                    start, end, PagingOrder.REVERSE);\n            queries.add(query);\n            queryMessageArchiveManagement(connection, query);\n            return query;\n        }\n    }\n    public Query prev(XmppConnection connection, Contact contact) {\n        synchronized (queries) {\n            Query query = new Query(connection.getXmpp().getUserId(), contact.getUserId(), 0, 0)\n                        .prev(contact.firstServerMsgId);\n            queries.add(query);\n            queryMessageArchiveManagement(connection, query);\n            return query;\n        }\n    }\n    public void processFin(XmppConnection connection, XmlNode fin) {\n        Query query = findQuery(fin.getAttribute(\"queryid\"));\n        if (query == null) {\n            return;\n        }\n        boolean complete = XmppConnection.isTrue(fin.getAttribute(\"complete\"));\n        XmlNode set = fin.getFirstNode(\"set\", \"http://jabber.org/protocol/rsm\");\n        String last = set == null ? null : set.getFirstNodeValue(\"last\");\n        String first = set == null ? null : set.getFirstNodeValue(\"first\");\n        String relevant = query.getPagingOrder() == PagingOrder.NORMAL ? last : first;\n        String count = set == null ? null : set.getFirstNodeValue(\"count\");\n        if (count != null) {\n            query.setAllMessageCount(Integer.valueOf(count));\n        }\n        if (relevant != null) {\n            Contact contact = null;\n            if (query.getWith() != null) {\n                contact = connection.getProtocol().getItemByUID(query.getWith());\n            }\n            contact.firstServerMsgId = first;\n            connection.getXmpp().getStorage().updateFirstServerMsgId(contact);\n        }\n        if (complete || relevant == null) {\n            finalizeQuery(connection.getProtocol(), query);\n            Log.d(\"MAM\", \"finished mam after \" + query.getAllMessagesCount() + \" messages\");\n        } else {\n            final Query nextQuery;\n            if (query.getPagingOrder() == PagingOrder.NORMAL) {\n                nextQuery = query.next(last);\n            } else {\n                nextQuery = query.prev(first);\n            }\n        //    queryMessageArchiveManagement(connection, nextQuery);\n            finalizeQuery(connection.getProtocol(), query);\n            synchronized (queries) {\n            //    queries.add(nextQuery);\n            }\n        }\n    }\n    public boolean queryInProgress(Contact contact, OnMoreMessagesLoaded moreMessagesLoadedListener) {\n        synchronized (queries) {\n            for (Query query : queries) {\n                if (query.getWith().equals(contact.getUserId())) {\n                    if (query.onMoreMessagesLoaded == null && moreMessagesLoadedListener != null) {\n                        query.setOnMoreMessagesLoaded(moreMessagesLoadedListener);\n                    }\n                    return true;\n                }\n            }\n            return false;\n        }\n    }\n    private void finalizeQuery(Protocol protocol, Query query) {\n        synchronized (queries) {\n            queries.remove(query);\n        }\n        Contact contact = null;\n        if (query.getWith() != null) {\n            contact = protocol.getItemByUID(query.getWith());\n        }\n        if (contact != null) {\n", "outputs": ["            if (contact.setLastMessageTransmitted(query.getEnd())) {"], "input_length": 1342, "output_length": 10, "length": 1352, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "4a5aebfa6c9bd3ac7a55f7922652d69f34101ee4231bad55953fc9185f270829"}
{"input": "", "context": "/*\n  Copyright (C) 2008-2011 Jeroen Frijters\n  This software is provided 'as-is', without any express or implied\n  warranty.  In no event will the authors be held liable for any damages\n  arising from the use of this software.\n  Permission is granted to anyone to use this software for any purpose,\n  including commercial applications, and to alter it and redistribute it\n  freely, subject to the following restrictions:\n  1. The origin of this software must not be misrepresented; you must not\n     claim that you wrote the original software. If you use this software\n     in a product, an acknowledgment in the product documentation would be\n     appreciated but is not required.\n  2. Altered source versions must be plainly marked as such, and must not be\n     misrepresented as being the original software.\n  3. This notice may not be removed or altered from any source distribution.\n  Jeroen Frijters\n  jeroen@frijters.net\n  \n*/\nusing System;\nusing System.Collections.Generic;\nusing System.Diagnostics;\nusing System.Runtime.InteropServices;\nusing IKVM.Reflection.Impl;\nusing IKVM.Reflection.Metadata;\nusing IKVM.Reflection.Writer;\nnamespace IKVM.Reflection.Emit\n{\n\tpublic sealed class GenericTypeParameterBuilder : TypeInfo\n\t{\n\t\tprivate readonly string name;\n\t\tprivate readonly TypeBuilder type;\n\t\tprivate readonly MethodBuilder method;\n\t\tprivate readonly int paramPseudoIndex;\n\t\tprivate readonly int position;\n\t\tprivate int typeToken;\n\t\tprivate Type baseType;\n\t\tprivate GenericParameterAttributes attr;\n\t\tinternal GenericTypeParameterBuilder(string name, TypeBuilder type, int position)\n\t\t\t: this(name, type, null, position, Signature.ELEMENT_TYPE_VAR)\n\t\t{\n\t\t}\n\t\tinternal GenericTypeParameterBuilder(string name, MethodBuilder method, int position)\n\t\t\t: this(name, null, method, position, Signature.ELEMENT_TYPE_MVAR)\n\t\t{\n\t\t}\n\t\tprivate GenericTypeParameterBuilder(string name, TypeBuilder type, MethodBuilder method, int position, byte sigElementType)\n\t\t\t: base(sigElementType)\n\t\t{\n\t\t\tthis.name = name;\n\t\t\tthis.type = type;\n\t\t\tthis.method = method;\n\t\t\tthis.position = position;\n\t\t\tGenericParamTable.Record rec = new GenericParamTable.Record();\n\t\t\trec.Number = (short)position;\n\t\t\trec.Flags = 0;\n\t\t\trec.Owner = type != null ? type.MetadataToken : method.MetadataToken;\n\t\t\trec.Name = this.ModuleBuilder.Strings.Add(name);\n\t\t\tthis.paramPseudoIndex = this.ModuleBuilder.GenericParam.AddRecord(rec);\n\t\t}\n\t\tpublic override string AssemblyQualifiedName\n\t\t{\n\t\t\tget { return null; }\n\t\t}\n\t\tpublic override bool IsValueType\n\t\t{\n\t\t\tget { return (this.GenericParameterAttributes & GenericParameterAttributes.NotNullableValueTypeConstraint) != 0; }\n\t\t}\n\t\tpublic override Type BaseType\n\t\t{\n\t\t\tget { return baseType; }\n\t\t}\n\t\tpublic override Type[] __GetDeclaredInterfaces()\n\t\t{\n\t\t\tthrow new NotImplementedException();\n\t\t}\n\t\tpublic override TypeAttributes Attributes\n\t\t{\n\t\t\tget { return TypeAttributes.Public; }\n\t\t}\n\t\tpublic override string Namespace\n\t\t{\n\t\t\tget { return DeclaringType.Namespace; }\n\t\t}\n\t\tpublic override string Name\n\t\t{\n\t\t\tget { return name; }\n\t\t}\n\t\tpublic override string FullName\n\t\t{\n\t\t\tget { return null; }\n\t\t}\n\t\tpublic override string ToString()\n\t\t{\n\t\t\treturn this.Name;\n\t\t}\n\t\tprivate ModuleBuilder ModuleBuilder\n\t\t{\n\t\t\tget { return type != null ? type.ModuleBuilder : method.ModuleBuilder; }\n\t\t}\n\t\tpublic override Module Module\n\t\t{\n\t\t\tget { return ModuleBuilder; }\n\t\t}\n\t\tpublic override int GenericParameterPosition\n\t\t{\n\t\t\tget { return position; }\n\t\t}\n\t\tpublic override Type DeclaringType\n\t\t{\n\t\t\tget { return type; }\n\t\t}\n\t\tpublic override MethodBase DeclaringMethod\n\t\t{\n\t\t\tget { return method; }\n\t\t}\n\t\tpublic override Type[] GetGenericParameterConstraints()\n\t\t{\n\t\t\tthrow new NotImplementedException();\n\t\t}\n\t\tpublic override GenericParameterAttributes GenericParameterAttributes\n\t\t{\n\t\t\tget\n\t\t\t{\n\t\t\t\tCheckBaked();\n\t\t\t\treturn attr;\n\t\t\t}\n\t\t}\n\t\tinternal override void CheckBaked()\n\t\t{\n\t\t\tif (type != null)\n\t\t\t{\n\t\t\t\ttype.CheckBaked();\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tmethod.CheckBaked();\n\t\t\t}\n\t\t}\n\t\tprivate void AddConstraint(Type type)\n\t\t{\n\t\t\tGenericParamConstraintTable.Record rec = new GenericParamConstraintTable.Record();\n\t\t\trec.Owner = paramPseudoIndex;\n\t\t\trec.Constraint = this.ModuleBuilder.GetTypeTokenForMemberRef(type);\n\t\t\tthis.ModuleBuilder.GenericParamConstraint.AddRecord(rec);\n\t\t}\n\t\tpublic void SetBaseTypeConstraint(Type baseTypeConstraint)\n\t\t{\n\t\t\tthis.baseType = baseTypeConstraint;\n\t\t\tAddConstraint(baseTypeConstraint);\n\t\t}\n\t\tpublic void SetInterfaceConstraints(params Type[] interfaceConstraints)\n\t\t{\n\t\t\tforeach (Type type in interfaceConstraints)\n\t\t\t{\n\t\t\t\tAddConstraint(type);\n\t\t\t}\n\t\t}\n\t\tpublic void SetGenericParameterAttributes(GenericParameterAttributes genericParameterAttributes)\n\t\t{\n\t\t\tthis.attr = genericParameterAttributes;\n\t\t\t// for now we'll back patch the table\n\t\t\tthis.ModuleBuilder.GenericParam.PatchAttribute(paramPseudoIndex, genericParameterAttributes);\n\t\t}\n\t\tpublic void SetCustomAttribute(CustomAttributeBuilder customBuilder)\n\t\t{\n\t\t\tthis.ModuleBuilder.SetCustomAttribute((GenericParamTable.Index << 24) | paramPseudoIndex, customBuilder);\n\t\t}\n\t\tpublic void SetCustomAttribute(ConstructorInfo con, byte[] binaryAttribute)\n\t\t{\n\t\t\tSetCustomAttribute(new CustomAttributeBuilder(con, binaryAttribute));\n\t\t}\n\t\tpublic override int MetadataToken\n\t\t{\n\t\t\tget\n\t\t\t{\n\t\t\t\tCheckBaked();\n\t\t\t\treturn (GenericParamTable.Index << 24) | paramPseudoIndex;\n\t\t\t}\n\t\t}\n\t\tinternal override int GetModuleBuilderToken()\n\t\t{\n\t\t\tif (typeToken == 0)\n\t\t\t{\n\t\t\t\tByteBuffer spec = new ByteBuffer(5);\n\t\t\t\tSignature.WriteTypeSpec(this.ModuleBuilder, spec, this);\n\t\t\t\ttypeToken = 0x1B000000 | this.ModuleBuilder.TypeSpec.AddRecord(this.ModuleBuilder.Blobs.Add(spec));\n\t\t\t}\n\t\t\treturn typeToken;\n\t\t}\n\t\tinternal override Type BindTypeParameters(IGenericBinder binder)\n\t\t{\n\t\t\tif (type != null)\n\t\t\t{\n\t\t\t\treturn binder.BindTypeParameter(this);\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\treturn binder.BindMethodParameter(this);\n\t\t\t}\n\t\t}\n\t\tinternal override int GetCurrentToken()\n\t\t{\n\t\t\tif (this.ModuleBuilder.IsSaved)\n\t\t\t{\n\t\t\t\treturn (GenericParamTable.Index << 24) | this.Module.GenericParam.GetIndexFixup()[paramPseudoIndex - 1] + 1;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\treturn (GenericParamTable.Index << 24) | paramPseudoIndex;\n\t\t\t}\n\t\t}\n\t\tinternal override bool IsBaked\n\t\t{\n\t\t\tget { return ((MemberInfo)type ?? method).IsBaked; }\n\t\t}\n\t}\n\tpublic sealed class TypeBuilder : TypeInfo, ITypeOwner\n\t{\n\t\tpublic const int UnspecifiedTypeSize = 0;\n\t\tprivate readonly ITypeOwner owner;\n\t\tprivate readonly int token;\n\t\tprivate int extends;\n\t\tprivate Type lazyBaseType;\t\t// (lazyBaseType == null && attribs & TypeAttributes.Interface) == 0) => BaseType == System.Object\n\t\tprivate readonly int typeName;\n\t\tprivate readonly int typeNameSpace;\n\t\tprivate readonly string ns;\n\t\tprivate readonly string name;\n\t\tprivate readonly List<MethodBuilder> methods = new List<MethodBuilder>();\n\t\tprivate readonly List<FieldBuilder> fields = new List<FieldBuilder>();\n\t\tprivate List<PropertyBuilder> properties;\n\t\tprivate List<EventBuilder> events;\n\t\tprivate TypeAttributes attribs;\n\t\tprivate GenericTypeParameterBuilder[] gtpb;\n\t\tprivate List<CustomAttributeBuilder> declarativeSecurity;\n\t\tprivate List<Type> interfaces;\n\t\tprivate int size;\n\t\tprivate short pack;\n\t\tprivate bool hasLayout;\n\t\tinternal TypeBuilder(ITypeOwner owner, string ns, string name)\n\t\t{\n\t\t\tthis.owner = owner;\n\t\t\tthis.token = this.ModuleBuilder.TypeDef.AllocToken();\n\t\t\tthis.ns = ns;\n\t\t\tthis.name = name;\n\t\t\tthis.typeNameSpace = ns == null ? 0 : this.ModuleBuilder.Strings.Add(ns);\n\t\t\tthis.typeName = this.ModuleBuilder.Strings.Add(name);\n\t\t\tMarkKnownType(ns, name);\n\t\t}\n\t\tpublic ConstructorBuilder DefineDefaultConstructor(MethodAttributes attributes)\n\t\t{\n\t\t\tConstructorBuilder cb = DefineConstructor(attributes, CallingConventions.Standard, Type.EmptyTypes);\n\t\t\tILGenerator ilgen = cb.GetILGenerator();\n\t\t\tilgen.Emit(OpCodes.Ldarg_0);\n\t\t\tilgen.Emit(OpCodes.Call, BaseType.GetConstructor(BindingFlags.Instance | BindingFlags.Public | BindingFlags.NonPublic, null, Type.EmptyTypes, null));\n\t\t\tilgen.Emit(OpCodes.Ret);\n\t\t\treturn cb;\n\t\t}\n\t\tpublic ConstructorBuilder DefineConstructor(MethodAttributes attribs, CallingConventions callConv, Type[] parameterTypes)\n\t\t{\n\t\t\treturn DefineConstructor(attribs, callConv, parameterTypes, null, null);\n\t\t}\n\t\tpublic ConstructorBuilder DefineConstructor(MethodAttributes attribs, CallingConventions callingConvention, Type[] parameterTypes, Type[][] requiredCustomModifiers, Type[][] optionalCustomModifiers)\n\t\t{\n\t\t\tattribs |= MethodAttributes.RTSpecialName | MethodAttributes.SpecialName;\n\t\t\tstring name = (attribs & MethodAttributes.Static) == 0 ? ConstructorInfo.ConstructorName : ConstructorInfo.TypeConstructorName;\n\t\t\tMethodBuilder mb = DefineMethod(name, attribs, callingConvention, null, null, null, parameterTypes, requiredCustomModifiers, optionalCustomModifiers);\n\t\t\treturn new ConstructorBuilder(mb);\n\t\t}\n\t\tpublic ConstructorBuilder DefineTypeInitializer()\n\t\t{\n\t\t\tMethodBuilder mb = DefineMethod(ConstructorInfo.TypeConstructorName, MethodAttributes.Private | MethodAttributes.Static | MethodAttributes.RTSpecialName | MethodAttributes.SpecialName, null, Type.EmptyTypes);\n", "outputs": ["\t\t\treturn new ConstructorBuilder(mb);"], "input_length": 1360, "output_length": 7, "length": 1367, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "93853ab228433ad7bcca4bd2181a26ef488d161b4279e6096f90c0f70b1b2b04"}
{"input": "", "context": "#region LGPL License\n/*\nAxiom Graphics Engine Library\nCopyright (C) 2003-2010 Axiom Project Team\nThis file is part of Axiom.RenderSystems.OpenGLES\nC# version developed by bostich.\nThe overall design, and a majority of the core engine and rendering code\ncontained within this library is a derivative of the open source Object Oriented\nGraphics Engine OGRE, which can be found at http://ogre.sourceforge.net.\nMany thanks to the OGRE team for maintaining such a high quality project.\nThis library is free software; you can redistribute it and/or\nmodify it under the terms of the GNU Lesser General Public\nLicense as published by the Free Software Foundation; either\nversion 2.1 of the License, or (at your option) any later version.\nThis library is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\nLesser General Public License for more details.\nYou should have received a copy of the GNU Lesser General Public\nLicense along with this library; if not, write to the Free Software\nFoundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA\n*/\n#endregion LGPL License\n#region SVN Version Information\n// <file>\n//     <license see=\"http://axiomengine.sf.net/wiki/index.php/license.txt\"/>\n//     <id value=\"$Id$\"/>\n// </file>\n#endregion SVN Version Information\n#region Namespace Declarations\nusing System;\nusing Axiom.Graphics;\nusing Axiom.Core;\nusing OpenTK.Graphics.ES11;\nusing OpenGL = OpenTK.Graphics.ES11.GL;\nusing OpenGLOES = OpenTK.Graphics.ES11.GL.Oes;\n#endregion Namespace Declarations\nnamespace Axiom.RenderSystems.OpenGLES\n{\n\t/// <summary>\n\t/// \n\t/// </summary>\n\tpublic class GLESHardwareIndexBuffer : HardwareIndexBuffer\n\t{\n\t\tconst int MapBufferThreshold = 1024 * 32;\n\t\tprivate int _bufferId = 0;\n\t\tIntPtr _scratchPtr;\n\t\tbool _lockedToScratch;\n\t\tbool _scratchUploadOnUnlock;\n\t\tint _scratchOffset;\n\t\tint _scratchSize;\n\t\tpublic int BufferID\n\t\t{\n\t\t\tget\n\t\t\t{\n\t\t\t\treturn _bufferId;\n\t\t\t}\n\t\t}\n\t\tpublic GLESHardwareIndexBuffer( HardwareBufferManager mgr, IndexType idxType, int numIndexes, BufferUsage usage, bool useShadowBuffer )\n\t\t\t: base( idxType, numIndexes, usage, false, useShadowBuffer )\n\t\t{\n\t\t\tif ( idxType == IndexType.Size32 )\n\t\t\t{\n\t\t\t\tthrow new AxiomException( \"32 bit hardware buffers are not allowed in OpenGL ES.\" );\n\t\t\t}\n\t\t\tif ( !useShadowBuffer )\n\t\t\t{\n\t\t\t\tthrow new AxiomException( \"Only support with shadowBuffer\" );\n\t\t\t}\n\t\t\tOpenGL.GenBuffers( 1, ref _bufferId );\n\t\t\tGLESConfig.GlCheckError( this );\n\t\t\tif ( _bufferId == 0 )\n\t\t\t{\n\t\t\t\tthrow new AxiomException( \"Cannot create GL index buffer\" );\n\t\t\t}\n\t\t\tOpenGL.BindBuffer( All.ElementArrayBuffer, _bufferId );\n\t\t\tGLESConfig.GlCheckError( this );\n\t\t\tOpenGL.BufferData( All.ElementArrayBuffer, new IntPtr( sizeInBytes ), IntPtr.Zero, GLESHardwareBufferManager.GetGLUsage( usage ) );\n\t\t\tGLESConfig.GlCheckError( this );\n\t\t}\n\t\t/// <summary>\n\t\t/// \n\t\t/// </summary>\n\t\tprotected override void UnlockImpl()\n\t\t{\n\t\t\tif ( _lockedToScratch )\n\t\t\t{\n\t\t\t\tif ( _scratchUploadOnUnlock )\n\t\t\t\t{\n\t\t\t\t\t// have to write the data back to vertex buffer\n\t\t\t\t\tWriteData( _scratchOffset, _scratchSize, _scratchPtr, _scratchOffset == 0 && _scratchSize == sizeInBytes );\n\t\t\t\t}\n\t\t\t\t// deallocate from scratch buffer\n\t\t\t\t( (GLESHardwareBufferManager)HardwareBufferManager.Instance ).DeallocateScratch( _scratchPtr );\n\t\t\t\t_lockedToScratch = false;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tOpenGL.BindBuffer( All.ElementArrayBuffer, _bufferId );\n\t\t\t\tif ( !OpenGLOES.UnmapBuffer( All.ElementArrayBuffer ) )\n\t\t\t\t{\n\t\t\t\t\tthrow new AxiomException( \"Buffer data corrupted, please reload\" );\n\t\t\t\t}\n\t\t\t}\n\t\t\tisLocked = false;\n\t\t}\n\t\t/// <summary>\n\t\t/// \n\t\t/// </summary>\n\t\t/// <param name=\"offset\"></param>\n\t\t/// <param name=\"length\"></param>\n\t\t/// <param name=\"locking\"></param>\n\t\t/// <returns></returns>\n\t\tprotected override IntPtr LockImpl( int offset, int length, BufferLocking locking )\n\t\t{\n\t\t\tAll access = 0;\n\t\t\tif ( isLocked )\n\t\t\t{\n\t\t\t\tthrow new AxiomException( \"Invalid attempt to lock an index buffer that has already been locked\" );\n\t\t\t}\n\t\t\tIntPtr retPtr = IntPtr.Zero;\n\t\t\tif ( length < MapBufferThreshold )\n\t\t\t{\n\t\t\t\tretPtr = ( (GLESHardwareBufferManager)HardwareBufferManager.Instance ).AllocateScratch( length );\n\t\t\t\tif ( retPtr != IntPtr.Zero )\n\t\t\t\t{\n\t\t\t\t\t_lockedToScratch = true;\n\t\t\t\t\t_scratchOffset = offset;\n\t\t\t\t\t_scratchSize = length;\n\t\t\t\t\t_scratchPtr = retPtr;\n\t\t\t\t\t_scratchUploadOnUnlock = ( locking != BufferLocking.ReadOnly );\n\t\t\t\t\tif ( locking != BufferLocking.Discard )\n\t\t\t\t\t{\n\t\t\t\t\t\tReadData( offset, length, retPtr );\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tthrow new AxiomException( \"Invalid Buffer lockSize\" );\n\t\t\t}\n\t\t\tif ( retPtr == IntPtr.Zero )\n\t\t\t{\n\t\t\t\tOpenGL.BindBuffer( All.ElementArrayBuffer, _bufferId );\n\t\t\t\t// Use glMapBuffer\n\t\t\t\tif ( locking == BufferLocking.Discard )\n\t\t\t\t{\n\t\t\t\t\tOpenGL.BufferData( All.ElementArrayBuffer, new IntPtr( sizeInBytes ), IntPtr.Zero, GLESHardwareBufferManager.GetGLUsage( usage ) );\n\t\t\t\t}\n\t\t\t\tif ( ( usage & BufferUsage.WriteOnly ) != 0 )\n\t\t\t\t{\n\t\t\t\t\taccess = All.WriteOnlyOes;\n\t\t\t\t}\n\t\t\t\tIntPtr pBuffer = OpenGLOES.MapBuffer( All.ElementArrayBuffer, access );\n\t\t\t\tif ( pBuffer == IntPtr.Zero )\n\t\t\t\t{\n\t\t\t\t\tthrow new AxiomException( \"Index Buffer: Out of memory\" );\n\t\t\t\t}\n\t\t\t\tunsafe\n\t\t\t\t{\n\t\t\t\t\t// return offset\n\t\t\t\t\tretPtr = (IntPtr)( (byte*)pBuffer + offset );\n\t\t\t\t}\n\t\t\t\t_lockedToScratch = false;\n\t\t\t}\n\t\t\tisLocked = true;\n\t\t\treturn retPtr;\n\t\t}\n\t\t/// <summary>\n\t\t/// \n\t\t/// </summary>\n\t\t/// <param name=\"offset\"></param>\n\t\t/// <param name=\"length\"></param>\n\t\t/// <param name=\"dest\"></param>\n\t\tpublic override void ReadData( int offset, int length, IntPtr dest )\n\t\t{\n\t\t\tif ( useShadowBuffer )\n\t\t\t{\n\t\t\t\tIntPtr srcData = shadowBuffer.Lock( offset, length, BufferLocking.ReadOnly );\n\t\t\t\tMemory.Copy( srcData, dest, length );\n\t\t\t\tshadowBuffer.Unlock();\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tthrow new AxiomException( \"Reading hardware buffer is not supported.\" );\n\t\t\t}\n\t\t}\n\t\t/// <summary>\n\t\t/// \n\t\t/// </summary>\n\t\t/// <param name=\"offset\"></param>\n\t\t/// <param name=\"length\"></param>\n\t\t/// <param name=\"src\"></param>\n\t\t/// <param name=\"discardWholeBuffer\"></param>\n\t\tpublic override void WriteData( int offset, int length, IntPtr src, bool discardWholeBuffer )\n\t\t{\n", "outputs": ["\t\t\tOpenGL.BindBuffer( All.ElementArrayBuffer, _bufferId );"], "input_length": 1107, "output_length": 7, "length": 1114, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "544badb3d36e50ea65229f4067cd9eb5f4b3a24231b54c1c6f40d3f2fb625cea"}
{"input": "", "context": "#!/usr/bin/python\n#  This program is free software; you can redistribute it and/or modify\n#  it under the terms of the GNU General Public License as published by\n#  the Free Software Foundation; either version 2 of the License, or\n#  (at your option) any later version.\n#\n#  This program is distributed in the hope that it will be useful,\n#  but WITHOUT ANY WARRANTY; without even the implied warranty of\n#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#  GNU Library General Public License for more details.\n#\n#  You should have received a copy of the GNU General Public License\n#  along with this program; if not, write to the Free Software\n#  Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.\n#\n# gen_callbacks.py\n# Copyright (C) 2010 Simon Newton\nimport textwrap\ndef PrintLongLine(line):\n  optional_nolint = ''\n  if len(line) > 80:\n    optional_nolint = '  // NOLINT(whitespace/line_length)'\n  print ('%s%s' % (line, optional_nolint))\ndef Header():\n  print textwrap.dedent(\"\"\"\\\n  /*\n   * This library is free software; you can redistribute it and/or\n   * modify it under the terms of the GNU Lesser General Public\n   * License as published by the Free Software Foundation; either\n   * version 2.1 of the License, or (at your option) any later version.\n   *\n   * This library is distributed in the hope that it will be useful,\n   * but WITHOUT ANY WARRANTY; without even the implied warranty of\n   * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n   * Lesser General Public License for more details.\n   *\n   * You should have received a copy of the GNU Lesser General Public\n   * License along with this library; if not, write to the Free Software\n   * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA\n   *\n   * Callback.h\n   * @brief Function objects.\n   * Copyright (C) 2005-2010 Simon Newton\n   *\n   * THIS FILE IS AUTOGENERATED!\n   * Please run edit & run gen_callbacks.py if you need to add more types.\n   */\n  /**\n   * @defgroup callbacks Callbacks\n   * @brief Function objects.\n   *\n   * Callbacks are powerful objects that behave like function pointers. They\n   * can be constructed with a pointer to a either plain function or member\n   * function. Argments can be provided at either creation time or execution\n   * time.\n   *\n   * The SingleUse varient of a Callback automatically delete itself after it\n   * has been executed.\n   *\n   * Callbacks are used throughout OLA to reduce the coupling between classes\n   * and make for more modular code.\n   *\n   * Avoid creating Callbacks by directly calling the constructor. Instead use\n   * the NewSingleCallback() and NewCallback() helper methods.\n   *\n   * @examplepara Simple function pointer replacement.\n   *   @code\n   *   // wrap a function that takes no args and returns a bool\n   *   SingleUseCallback<bool> *callback1 = NewSingleCallback(&Function0);\n   *\n   *   // some time later\n   *   bool result = callback1->Run();\n   *   // callback1 has deleted itself at this point\n   *   @endcode\n   *\n   * @examplepara Method pointer with a single bound argument\n   *   @code\n   *   // Create a Callback for Method1 of the Object class and bind TEST_VALUE\n   *   // as the first argument.\n   *   Callback<void> *callback2 = NewCallback(object, &Object::Method1,\n   *                                           TEST_VALUE);\n   *\n   *   // This will call object->Method1(TEST_VALUE)\n   *   callback2->Run();\n   *   // this wasn't a SingleUse Callback, so callback is still around and\n   *   // needs to be deleted manually.\n   *   delete callback2;\n   *   @endcode\n   *\n   * @examplepara Method pointer that takes a single argument at execution time.\n   *   @code\n   *   // Create a Callback for a method that takes 1 argument and returns void.\n   *   BaseCallback1<void, unsigned int> *callback3 = NewCallback(\n   *       object, &Object::Method1);\n   *\n   *   // Call object->Method1(TEST_VALUE)\n   *   callback3->Run(TEST_VALUE);\n   *   // callback3 is still around at this stage\n   *   delete callback3;\n   *   @endcode\n   *\n   * @examplepara Method pointer with one bound argument and one execution time\n   * argument.\n   *   @code\n   *   // Create a callback for a method that takes 2 args and returns void\n   *   BaseCallback2<void, int, int> *callback4 = NewSingleCallback(\n   *       object,\n   *       &Object::Method2,\n   *       TEST_VALUE);\n   *\n   *   // This calls object->Method2(TEST_VALUE, TEST_VALUE2);\n   *   callback4->Run(TEST_VALUE2);\n   *   // callback4 is still around\n   *   delete callback4;\n   *   @endcode\n   *\n   * @note The code in Callback.h is autogenerated by gen_callbacks.py. Please\n   * run edit & run gen_callbacks.py if you need to add more types.\n   *\n   */\n  /**\n   * @addtogroup callbacks\n   * @{\n   * @file Callback.h\n   * @}\n   */\n  #ifndef INCLUDE_OLA_CALLBACK_H_\n  #define INCLUDE_OLA_CALLBACK_H_\n  namespace ola {\n  /**\n   * @addtogroup callbacks\n   * @{\n   */\n  \"\"\")\ndef Footer():\n  print textwrap.dedent(\"\"\"\\\n  /**\n   * @}\n   */\n  }  // namespace ola\n  #endif  // INCLUDE_OLA_CALLBACK_H_\"\"\")\ndef GenerateBase(number_of_args):\n  \"\"\"Generate the base Callback classes.\"\"\"\n  optional_comma = ''\n  if number_of_args > 0:\n    optional_comma = ', '\n  typenames = ', '.join('typename Arg%d' % i for i in xrange(number_of_args))\n  arg_list = ', '.join('Arg%d arg%d' % (i, i) for i in xrange(number_of_args))\n  args = ', '.join('arg%d' % i for i in xrange(number_of_args))\n  arg_types = ', '.join('Arg%d' % i for i in xrange(number_of_args))\n  # generate the base callback class\n  print textwrap.dedent(\"\"\"\\\n  /**\n   * @brief The base class for all %d argument callbacks.\n   */\"\"\" % number_of_args)\n  PrintLongLine('template <typename ReturnType%s%s>' %\n                (optional_comma, typenames))\n  print 'class BaseCallback%d {' % number_of_args\n  print '  public:'\n  print '    virtual ~BaseCallback%d() {}' % number_of_args\n  PrintLongLine('    virtual ReturnType Run(%s) = 0;' % arg_list)\n  print '};'\n  print ''\n  # generate the multi-use version of the callback\n  print textwrap.dedent(\"\"\"\\\n  /**\n   * @brief A %d argument callback which can be called multiple times.\n   */\"\"\" % number_of_args)\n  PrintLongLine('template <typename ReturnType%s%s>' %\n                (optional_comma, typenames))\n  print ('class Callback%d: public BaseCallback%d<ReturnType%s%s> {' %\n         (number_of_args, number_of_args, optional_comma, arg_types))\n  print '  public:'\n  print '    virtual ~Callback%d() {}' % number_of_args\n  PrintLongLine('    ReturnType Run(%s) { return this->DoRun(%s); }' %\n         (arg_list, args))\n  print '  private:'\n  print '    virtual ReturnType DoRun(%s) = 0;' % arg_list\n  print '};'\n  print ''\n  # generate the single-use version of the callback\n  print textwrap.dedent(\"\"\"\\\n  /**\n   * @brief A %d argument callback which deletes itself after it's run.\n   */\"\"\" % number_of_args)\n  PrintLongLine('template <typename ReturnType%s%s>' %\n                (optional_comma, typenames))\n  PrintLongLine('class SingleUseCallback%d: public BaseCallback%d<ReturnType%s%s> {' %\n                (number_of_args, number_of_args, optional_comma, arg_types))\n  print '  public:'\n  print '    virtual ~SingleUseCallback%d() {}' % number_of_args\n  print '    ReturnType Run(%s) {' % arg_list\n  print '      ReturnType ret = this->DoRun(%s);' % args\n  print '      delete this;'\n  print '      return ret;'\n  print '    }'\n  print '  private:'\n  print '    virtual ReturnType DoRun(%s) = 0;' % arg_list\n  print '};'\n  print ''\n  # the void specialization\n  print textwrap.dedent(\"\"\"\\\n  /**\n   * @brief A %d arg, single use callback that returns void.\n   */\"\"\" % number_of_args)\n  print 'template <%s>' % typenames\n  PrintLongLine('class SingleUseCallback%d<void%s%s>: public BaseCallback%d<void%s%s> {' %\n                (number_of_args, optional_comma, arg_types, number_of_args,\n                optional_comma, arg_types))\n  print '  public:'\n  print '    virtual ~SingleUseCallback%d() {}' % number_of_args\n  print '    void Run(%s) {' % arg_list\n  print '      this->DoRun(%s);' % args\n  print '      delete this;'\n  print '    }'\n  print '  private:'\n  print '    virtual void DoRun(%s) = 0;' % arg_list\n  print '};'\n  print ''\ndef GenerateHelperFunction(bind_count,\n                           exec_count,\n                           function_name,\n                           parent_class,\n                           is_method=True):\n  \"\"\"Generate the helper functions which create callbacks.\n  Args:\n    bind_count the number of args supplied at create time.\n    exec_count the number of args supplied at exec time.\n    function_name what to call the helper function\n    parent_class the parent class to use\n    is_method True if this is a method callback, False if this is a function\n      callback.\n    \"\"\"\n  optional_comma = ''\n  if bind_count > 0 or exec_count > 0:\n    optional_comma = ', '\n  typenames = (['typename A%d' % i for i in xrange(bind_count)] +\n               ['typename Arg%d' % i for i in xrange(exec_count)])\n  bind_types = ['A%d' % i for i in xrange(bind_count)]\n  exec_types = ['Arg%d' % i for i in xrange(exec_count)]\n  method_types = ', '.join(bind_types + exec_types)\n  if exec_count > 0:\n    exec_types = [''] + exec_types\n  exec_type_str = ', '.join(exec_types)\n  optional_class, ptr_name, signature = '', 'callback', '*callback'\n  if is_method:\n    optional_class, ptr_name, signature = (\n        'typename Class, ', 'method', 'Class::*method')\n  # The single use helper function\n  print textwrap.dedent(\"\"\"\\\n  /**\n   * @brief A helper function to create a new %s with %d\n   * create-time arguments and %d execution time arguments.\"\"\" %\n   (parent_class, bind_count, exec_count))\n  if is_method:\n    print \" * @tparam Class the class with the member function.\"\n  print \" * @tparam ReturnType the return type of the callback.\"\n  for i in xrange(bind_count):\n    print \" * @tparam A%d a create-time argument type.\" % i\n  for i in xrange(exec_count):\n    print \" * @tparam Arg%d an exec-time argument type.\" % i\n  if is_method:\n    print \" * @param object the object to call the member function on.\"\n    print (\" * @param method the member function pointer to use when executing \"\n           \"the callback.\");\n  else:\n    print (\" * @param callback the function pointer to use when executing the \"\n           \"callback.\")\n  for i in xrange(bind_count):\n    print \" * @param a%d a create-time argument.\" % i\n  if is_method:\n    print \" * @returns The same return value as the member function.\"\n  else:\n    print \" * @returns The same return value as the function.\"\n  print \" */\"\n  PrintLongLine('template <%stypename ReturnType%s%s>' %\n                (optional_class, optional_comma, ', '.join(typenames)))\n  PrintLongLine('inline %s%d<ReturnType%s>* %s(' %\n                (parent_class, exec_count, exec_type_str, function_name))\n  if is_method:\n    print '    Class* object,'\n  if bind_count:\n    print '    ReturnType (%s)(%s),' % (signature, method_types)\n    for i in xrange(bind_count):\n      suffix = ','\n      if i == bind_count - 1:\n        suffix = ') {'\n      print '    A%d a%d%s' % (i, i, suffix)\n  else:\n    print '    ReturnType (%s)(%s)) {' % (signature, method_types)\n  if is_method:\n    print '  return new MethodCallback%d_%d<Class,' % (bind_count, exec_count)\n  else:\n    print '  return new FunctionCallback%d_%d<' % (bind_count, exec_count)\n  PrintLongLine('                               %s%d<ReturnType%s>,' %\n                (parent_class, exec_count, exec_type_str))\n", "outputs": ["  if bind_count > 0 or exec_count > 0:"], "input_length": 2444, "output_length": 9, "length": 2453, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "c5d1dd8e57049fb65030d0f52fb853b61fbc511390b9aa4ec8a6c588e25b69e2"}
{"input": "", "context": "package info.deskchan.talking_system;\nimport info.deskchan.core_utils.TextOperations;\nimport org.json.JSONObject;\nimport java.util.*;\npublic class StandardEmotionsController implements EmotionsController{\n\tprivate static class Emotion{\n\t\t/** Emotion name. **/\n\t\tpublic String name;\n\t\t/** Array of pairs [feature index, force multiplier]. **/\n\t\tpublic int[][] influences;\n\t\t/** Current emotion strength. **/\n\t\tpublic int strength = 0;\n\t\t/** Chance of getting into this emotion state. **/\n\t\tpublic float chance = 1;\n\t\tpublic Emotion(String name, int[][] influences) {\n\t\t\tthis.name = name;\n\t\t\tthis.influences = influences;\n\t\t}\n\t\tpublic Emotion(Emotion copy) {\n\t\t\tthis.name = copy.name;\n\t\t\tthis.influences = new int[copy.influences.length][2];\n\t\t\tfor (int i=0; i<influences.length; i++) {\n\t\t\t\tinfluences[i][0] = copy.influences[i][0];\n\t\t\t\tinfluences[i][1] = copy.influences[i][1];\n\t\t\t}\n\t\t}\n\t\tpublic String toString(){\n\t\t\tString print = name + \", chance = \" + chance + \", strength = \" + strength + \"\\n\";\n\t\t\tfor(int i=0; i<influences.length; i++)\n\t\t\t\tprint += \"[feature: \" + CharacterFeatures.getFeatureName(influences[i][0]) + \", force=\" + influences[i][1] + \"\\n\";\n\t\t\treturn print;\n\t\t}\n\t}\n\tprivate static final Emotion[] STANDARD_EMOTIONS = {\n\t\t\tnew Emotion(\"happiness\", new int[][]{{0,  1}, {1,  1}, {4,  2}, {7,  1}}),\n\t\t\tnew Emotion(\"sorrow\",    new int[][]{{2, -1}, {3, -2}, {4, -2}}),\n\t\t\tnew Emotion(\"fun\",       new int[][]{{1,  2}, {3,  2}, {4,  1}}),\n\t\t\tnew Emotion(\"anger\",     new int[][]{{0, -2}, {1,  2}, {2,  1}, {3,  2}, {4,  -1}, {7, -2}}),\n\t\t\tnew Emotion(\"confusion\", new int[][]{{1, -1}, {2, -1}, {5, -1}}),\n\t\t\tnew Emotion(\"affection\", new int[][]{{1,  2}, {3,  1}, {7,  1}})\n\t};\n\tprivate Emotion[] emotions = Arrays.copyOf(STANDARD_EMOTIONS, STANDARD_EMOTIONS.length);\n\tprivate Emotion currentEmotion = null;\n\tStandardEmotionsController() {\n\t\tnormalize();\n\t\treset();\n\t}\n\tprivate UpdateHandler onUpdate = null;\n\tpublic void setUpdater(UpdateHandler handler){\n\t\tonUpdate = handler;\n\t}\n\tprivate void tryInform(){\n\t\tif (onUpdate != null) onUpdate.onUpdate();\n\t}\n\tpublic void reset() {\n\t\tcurrentEmotion = null;\n\t\ttryInform();\n\t}\n\t\n\tpublic String getCurrentEmotionName() {\n\t\treturn currentEmotion != null ? currentEmotion.name : null;\n\t}\n\tpublic void raiseEmotion(String emotionName) {\n\t\traiseEmotion(emotionName, 1);\n\t}\n\tpublic void raiseEmotion(String emotionName, int value) {\n\t\tif (currentEmotion != null){\n\t\t\tcurrentEmotion.strength -= value;\n\t\t\tif (currentEmotion.strength <= 0)\n\t\t\t\tcurrentEmotion = null;\n\t\t\telse return;\n\t\t}\n\t\tfor (Emotion emotion : emotions){\n\t\t\tif (emotion.name.equals(emotionName)){\n\t\t\t\tcurrentEmotion = emotion;\n\t\t\t\temotion.strength = value;\n\t\t\t\ttryInform();\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t\tMain.log(\"No emotion by name: \" + emotionName);\n\t}\n\tpublic void raiseRandomEmotion(){\n\t\tif (currentEmotion != null){\n\t\t\tcurrentEmotion.strength += new Random().nextInt(2) - 1;\n\t\t\tif (currentEmotion.strength <= 0){\n\t\t\t\tcurrentEmotion = null;\n\t\t\t} else {\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t\tfloat chance = (float) Math.random();\n\t\tfor (Emotion emotion : emotions){\n\t\t\tif (emotion.chance > chance){\n\t\t\t\tcurrentEmotion = emotion;\n\t\t\t\temotion.strength = 1 + new Random().nextInt(2);\n\t\t\t\ttryInform();\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tchance -= emotion.chance;\n\t\t}\n\t}\n\tpublic List<String> getEmotionsList(){\n\t\tList<String> res = new ArrayList<>();\n\t\tfor (Emotion e : emotions)\n\t\t\tres.add(e.name);\n\t\treturn res;\n\t}\n\tpublic boolean phraseMatches(Phrase phrase){\n\t\tSet<String> allowedEmotions = phrase.getTag(\"emotion\");\n\t\tif (allowedEmotions == null || allowedEmotions.size() == 0){\n\t\t\treturn true;\n\t\t}\n\t\tif (currentEmotion != null){\n\t\t\treturn allowedEmotions.contains(currentEmotion.name);\n\t\t}\n\t\treturn false;\n\t}\n\tpublic CharacterController construct(CharacterController target) {\n\t\tif (currentEmotion == null) return target;\n\t\tCharacterController New = target.copy();\n\t\tfor (int i = 0; i < currentEmotion.influences.length; i++) {\n\t\t\tint index =  currentEmotion.influences[i][0], multiplier = currentEmotion.influences[i][1];\n\t\t\tNew.setValue(currentEmotion.influences[i][0], target.getValue(index) + currentEmotion.strength * multiplier);\n\t\t}\n\t\treturn New;\n\t}\n\tpublic void setFromJSON(JSONObject json) {\n\t\tif (json == null || json.keySet().size() == 0) return;\n\t\tList<Emotion> newEmotions = new ArrayList<>();\n\t\tfor (String emotionName : json.keySet()) {\n\t\t\tif (!(json.get(emotionName) instanceof JSONObject)) continue;\n\t\t\tJSONObject obj = json.getJSONObject(emotionName);\n\t\t\tList<int[]> influencesList = new ArrayList<>();\n\t\t\tfor (String feature : obj.keySet()) {\n\t\t\t\tint index = CharacterFeatures.getFeatureIndex(feature);\n\t\t\t\tif (index < 0) continue;\n\t\t\t\ttry {\n\t\t\t\t\tint force = obj.getInt(feature);\n\t\t\t\t\tinfluencesList.add(new int[]{index, force});\n\t\t\t\t} catch (Exception e){ }\n\t\t\t}\n\t\t\tif (influencesList.size() > 0) {\n\t\t\t\tint[][] influences = new int[influencesList.size()][];\n\t\t\t\tfor (int i = 0; i < influencesList.size(); i++)\n\t\t\t\t\tinfluences[i] = influencesList.get(i);\n\t\t\t\tEmotion emotion = new Emotion(emotionName, influences);\n\t\t\t\tif (obj.has(\"chance\")) emotion.chance = (float) obj.getDouble(\"chance\");\n\t\t\t\tnewEmotions.add(emotion);\n\t\t\t} else {\n\t\t\t\tfor (int i=0; i<emotions.length; i++)\n\t\t\t\t\tif (emotions[i].name.equals(emotionName)){\n\t\t\t\t\t\tEmotion emotion = new Emotion(emotions[i]);\n\t\t\t\t\t\tif (obj.has(\"chance\")) emotion.chance = (float) obj.getDouble(\"chance\");\n\t\t\t\t\t\tnewEmotions.add(emotion);\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\temotions = newEmotions.toArray(new Emotion[newEmotions.size()]);\n\t\tnormalize();\n\t\treset();\n\t}\n\tpublic JSONObject toJSON() {\n\t\treturn new JSONObject();\n\t}\n\tprivate void normalize(){\n\t\tfloat sum = 0;\n", "outputs": ["\t\tfor(Emotion emotion : emotions)"], "input_length": 1338, "output_length": 7, "length": 1345, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "edb3cae3201713eeeb28132193a4b2cd7265e633b97dd567fd616d0a7f374405"}
{"input": "", "context": "#!/usr/bin/env python2\nfrom cfme.utils.conf import docker as docker_conf\nfrom cfme.utils.net import random_port, my_ip_address\nimport argparse\nimport fauxfactory\nimport requests\nimport os\nimport os.path\nimport docker\nimport re\nimport subprocess\nimport sys\nimport yaml\nfrom six.moves.urllib.parse import urlsplit\ndef _dgci(d, key):\n    # dgci = dict get case-insensitive\n    keymap = {k.lower(): k for k in d.keys()}\n    return d.get(keymap[key.lower()])\ndef _name(docker_info):\n    return _dgci(docker_info, 'name').strip('/')\nif os.getenv(\"DOCKER_MACHINE_NAME\", \"None\") == \"None\":\n    dc = docker.Client(base_url='unix://var/run/docker.sock',\n                       version='1.12',\n                       timeout=10)\nelse:\n    from docker.utils import kwargs_from_env\n    dc = docker.Client(version='1.12',\n                       timeout=10,\n                       **kwargs_from_env(assert_hostname=False))\nclass DockerInstance(object):\n    def process_bindings(self, bindings):\n        self.port_bindings = {}\n        self.ports = []\n        for bind in bindings:\n            self.port_bindings[bindings[bind][0]] = bindings[bind][1]\n            print(\"  {}: {}\".format(bind, bindings[bind][1]))\n            self.ports.append(bindings[bind][1])\n    def wait(self):\n        if not self.dry_run:\n            dc.wait(self.container_id)\n        else:\n            print(\"Waiting for container\")\n    def stop(self):\n        if not self.dry_run:\n            dc.stop(self.container_id)\n        else:\n            print(\"Stopping container\")\n    def remove(self):\n        if not self.dry_run:\n            dc.remove_container(self.container_id, v=True)\n        else:\n            print(\"Removing container\")\n    def kill(self):\n        if not self.dry_run:\n            dc.kill(self.container_id)\n        else:\n            print(\"Killing container\")\nclass SeleniumDocker(DockerInstance):\n    def __init__(self, bindings, image, dry_run=False):\n        self.dry_run = dry_run\n        sel_name = fauxfactory.gen_alphanumeric(8)\n        if not self.dry_run:\n            sel_create_info = dc.create_container(image, tty=True, name=sel_name)\n            self.container_id = _dgci(sel_create_info, 'id')\n            sel_container_info = dc.inspect_container(self.container_id)\n            self.sel_name = _name(sel_container_info)\n        else:\n            self.sel_name = \"SEL_FF_CHROME_TEST\"\n        self.process_bindings(bindings)\n    def run(self):\n        if not self.dry_run:\n            dc.start(self.container_id, privileged=True, port_bindings=self.port_bindings)\n        else:\n            print(\"Dry run running sel_ff_chrome\")\nclass PytestDocker(DockerInstance):\n    def __init__(self, name, bindings, env, log_path, links, pytest_con, artifactor_dir,\n                 dry_run=False):\n        self.dry_run = dry_run\n        self.links = links\n        self.log_path = log_path\n        self.artifactor_dir = artifactor_dir\n        self.process_bindings(bindings)\n        if not self.dry_run:\n            pt_name = name\n            pt_create_info = dc.create_container(pytest_con, tty=True,\n                                                 name=pt_name, environment=env,\n                                                 command='sh /setup.sh',\n                                                 volumes=[artifactor_dir],\n                                                 ports=self.ports)\n            self.container_id = _dgci(pt_create_info, 'id')\n            pt_container_info = dc.inspect_container(self.container_id)\n            pt_name = _name(pt_container_info)\n    def run(self):\n        if not self.dry_run:\n            dc.start(self.container_id, privileged=True, links=self.links,\n                     binds={self.log_path: {'bind': self.artifactor_dir, 'ro': False}},\n                     port_bindings=self.port_bindings)\n        else:\n            print(\"Dry run running pytest\")\nclass DockerBot(object):\n    def __init__(self, **args):\n        links = []\n        self.args = args\n        self.base_branch = 'master'\n        self.validate_args()\n        self.display_banner()\n        self.process_appliance()\n        self.cache_files()\n        self.create_pytest_command()\n        if not self.args['use_wharf']:\n            self.sel_vnc_port = random_port()\n            sel = SeleniumDocker(bindings={'VNC_PORT': (5999, self.sel_vnc_port)},\n                                 image=self.args['selff'], dry_run=self.args['dry_run'])\n            sel.run()\n            sel_container_name = sel.sel_name\n            links = [(sel_container_name, 'selff')]\n        self.pytest_name = self.args['test_id']\n        self.create_pytest_envvars()\n        self.handle_pr()\n        self.log_path = self.create_log_path()\n        self.pytest_bindings = self.create_pytest_bindings()\n        if self.args['dry_run']:\n            for i in self.env_details:\n                print('export {}=\"{}\"'.format(i, self.env_details[i]))\n            print(self.env_details)\n        pytest = PytestDocker(name=self.pytest_name, bindings=self.pytest_bindings,\n                              env=self.env_details, log_path=self.log_path,\n                              links=links,\n                              pytest_con=self.args['pytest_con'],\n                              artifactor_dir=self.args['artifactor_dir'],\n                              dry_run=self.args['dry_run'])\n        pytest.run()\n        if not self.args['nowait']:\n            self.handle_watch()\n            if self.args['dry_run']:\n                with open(os.path.join(self.log_path, 'setup.txt'), \"w\") as f:\n                    f.write(\"finshed\")\n            try:\n                pytest.wait()\n            except KeyboardInterrupt:\n                print(\"  TEST INTERRUPTED....KILLING ALL THE THINGS\")\n                pass\n            pytest.kill()\n            pytest.remove()\n            if not self.args['use_wharf']:\n                sel.kill()\n                sel.remove()\n            self.handle_output()\n    def cache_files(self):\n        if self.args['pr']:\n            self.modified_files = self.find_files_by_pr(self.args['pr'])\n            if self.requirements_update:\n                self.args['update_pip'] = True\n    def get_base_branch(self, pr):\n        token = self.args['gh_token']\n        owner = self.args['gh_owner']\n        repo = self.args['gh_repo']\n        if token:\n            headers = {'Authorization': 'token {}'.format(token)}\n            r = requests.get(\n                'https://api.github.com/repos/{}/{}/pulls/{}'.format(owner, repo, pr),\n                headers=headers)\n            return r.json()['base']['ref']\n    def get_dev_branch(self, pr=None):\n        token = self.args['gh_token']\n        owner = self.args['gh_dev_owner']\n        repo = self.args['gh_dev_repo']\n        if token:\n            headers = {'Authorization': 'token {}'.format(token)}\n            r = requests.get(\n                'https://api.github.com/repos/{}/{}/pulls/{}'.format(owner, repo, pr),\n                headers=headers)\n            user, user_branch = r.json()['head']['label'].split(\":\")\n        return \"https://github.com/{}/{}.git\".format(user, repo), user_branch\n    def get_pr_metadata(self, pr=None):\n        token = self.args['gh_token']\n        owner = self.args['gh_owner']\n        repo = self.args['gh_repo']\n        if token:\n            headers = {'Authorization': 'token {}'.format(token)}\n            r = requests.get(\n                'https://api.github.com/repos/{}/{}/pulls/{}'.format(owner, repo, pr),\n                headers=headers)\n            body = r.json()['body'] or \"\"\n            metadata = re.findall(\"{{(.*?)}}\", body)\n            if not metadata:\n                return {}\n            else:\n                ydata = yaml.safe_load(metadata[0])\n                return ydata\n    def find_files_by_pr(self, pr=None):\n        self.requirements_update = False\n        files = []\n        token = self.args['gh_token']\n        owner = self.args['gh_owner']\n        repo = self.args['gh_repo']\n        if token:\n            headers = {'Authorization': 'token {}'.format(token)}\n            page = 1\n            while True:\n                r = requests.get(\n                    'https://api.github.com/repos/{}/{}/pulls/{}/files?page={}'.format(\n                        owner, repo, pr, page),\n                    headers=headers)\n                try:\n                    if not r.json():\n                        break\n                    for filen in r.json():\n                        if filen['status'] != \"deleted\" and filen['status'] != \"removed\":\n                            if filen['filename'].startswith('cfme/tests') or \\\n                               filen['filename'].startswith('utils/tests'):\n                                files.append(filen['filename'])\n                        if filen['filename'].endswith('requirements/frozen.txt'):\n                            self.requirements_update = True\n                except:\n                    return None\n                page += 1\n            return files\n    def check_arg(self, name, default):\n        self.args[name] = self.args.get(name)\n        if not self.args[name]:\n            self.args[name] = docker_conf.get(name, default)\n    def validate_args(self):\n        ec = 0\n        appliance = self.args.get('appliance', None)\n        if self.args.get('appliance_name', None) and not appliance:\n            self.args['appliance'] = docker_conf['appliances'][self.args['appliance_name']]\n        self.check_arg('nowait', False)\n        self.check_arg('banner', False)\n        self.check_arg('watch', False)\n        self.check_arg('output', True)\n        self.check_arg('dry_run', False)\n        self.check_arg('server_ip', None)\n        if not self.args['server_ip']:\n            self.args['server_ip'] = my_ip_address()\n        self.check_arg('sprout', False)\n        self.check_arg('provision_appliance', False)\n        if self.args['provision_appliance']:\n            if not self.args['provision_template'] or not self.args['provision_provider'] or \\\n               not self.args['provision_vm_name']:\n                print(\"You don't have all the required options to provision an appliance\")\n                ec += 1\n        self.check_arg('sprout_stream', None)\n        if self.args['sprout'] and not self.args['sprout_stream']:\n            print(\"You need to supply a stream for sprout\")\n            ec += 1\n        self.check_arg('appliance_name', None)\n        self.check_arg('appliance', None)\n        if not self.args['appliance_name'] != self.args['appliance'] and \\\n           not self.args['provision_appliance'] and not self.args['sprout']:\n            print(\"You must supply either an appliance OR an appliance name from config\")\n            ec += 1\n        self.check_arg('branch', 'origin/master')\n        self.check_arg('pr', None)\n        self.check_arg('dev_pr', None)\n        self.check_arg('cfme_repo', None)\n        self.check_arg('cfme_repo_dir', '/cfme_tests_te')\n        self.check_arg('cfme_cred_repo', None)\n        self.check_arg('cfme_cred_repo_dir', '/cfme-qe-yamls')\n        self.check_arg('dev_repo', None)\n        if not self.args['cfme_repo']:\n            print(\"You must supply a CFME REPO\")\n            ec += 1\n        if not self.args['cfme_cred_repo']:\n            print(\"You must supply a CFME Credentials REPO\")\n            ec += 1\n        self.check_arg('selff', 'cfme/sel_ff_chrome')\n        self.check_arg('gh_token', None)\n        self.check_arg('gh_owner', None)\n        self.check_arg('gh_repo', None)\n        self.check_arg('gh_dev_repo', None)\n        self.check_arg('gh_dev_owner', None)\n        if self.args['dev_pr']:\n            dev_check = [self.args[i] for i in ['gh_dev_repo', 'gh_dev_owner']]\n            if not all(dev_check):\n                print(\"To use dev_pr you must have a gh_dev_repo and gh_dev_owner defined\")\n                ec += 1\n        self.check_arg('browser', 'firefox')\n        self.check_arg('pytest', None)\n        self.check_arg('pytest_con', 'py_test_base')\n        if not self.args['pytest']:\n            print(\"You must specify a py.test command\")\n            ec += 1\n        self.check_arg('update_pip', False)\n        self.check_arg('wheel_host_url', None)\n        self.check_arg('auto_gen_test', False)\n        self.check_arg('artifactor_dir', '/log_depot')\n        self.check_arg('log_depot', None)\n        if not self.args['log_depot']:\n            print(\"You must specify a log_depot\")\n            ec += 1\n        if self.args['pr'] and self.args['auto_gen_test'] and not \\\n           all([self.args['gh_token'], self.args['gh_owner'], self.args['gh_repo']]):\n            print(\"You chose to use Auto Test Gen, without supplying GitHub details\")\n            ec += 1\n        self.check_arg('capture', False)\n        self.check_arg('test_id', fauxfactory.gen_alphanumeric(8))\n        self.check_arg('prtester', False)\n        self.check_arg('trackerbot', None)\n        self.check_arg('wharf', False)\n        self.check_arg('sprout_username', None)\n        self.check_arg('sprout_password', None)\n        self.check_arg('sprout_description', None)\n        if ec:\n            sys.exit(127)\n    def display_banner(self):\n        if self.args['banner']:\n            banner = \"\"\"\n==================================================================\n               ____             __             ____        __\n     :        / __ \\____  _____/ /_____  _____/ __ )____  / /_\n   [* *]     / / / / __ \\/ ___/ //_/ _ \\/ ___/ __  / __ \\/ __/\n  -[___]-   / /_/ / /_/ / /__/ ,< /  __/ /  / /_/ / /_/ / /_\n           /_____/\\____/\\___/_/|_|\\___/_/  /_____/\\____/\\__/\n==================================================================\n            \"\"\"\n            print(banner)\n    def process_appliance(self):\n        self.appliance = self.args['appliance']\n        self.app_name = self.args.get('appliance_name', \"Unnamed\")\n        print(\"  APPLIANCE: {} ({})\".format(self.appliance, self.app_name))\n    def create_pytest_command(self):\n        if self.args['auto_gen_test'] and self.args['pr']:\n            self.pr_metadata = self.get_pr_metadata(self.args['pr'])\n            pytest = self.pr_metadata.get('pytest', None)\n            sprout_appliances = self.pr_metadata.get('sprouts', 1)\n            if pytest:\n", "outputs": ["                self.args['pytest'] = \"py.test {}\".format(pytest)"], "input_length": 2301, "output_length": 15, "length": 2316, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "dbe2f5f487843a66ceb7d5e2a53760ff804df75c1a8363c5a53d4aea9d95700a"}
{"input": "", "context": "/*\n * ====================================================================\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n * ====================================================================\n *\n * This software consists of voluntary contributions made by many\n * individuals on behalf of the Apache Software Foundation.  For more\n * information on the Apache Software Foundation, please see\n * <http://www.apache.org/>.\n *\n */\npackage ch.boye.httpclientandroidlib.auth;\nimport java.util.Locale;\nimport ch.boye.httpclientandroidlib.HttpHost;\nimport ch.boye.httpclientandroidlib.annotation.Immutable;\nimport ch.boye.httpclientandroidlib.util.Args;\nimport ch.boye.httpclientandroidlib.util.LangUtils;\n/**\n * The class represents an authentication scope consisting of a host name,\n * a port number, a realm name and an authentication scheme name which\n * {@link Credentials Credentials} apply to.\n *\n *\n * @since 4.0\n */\n@Immutable\npublic class AuthScope {\n    /**\n     * The <tt>null</tt> value represents any host. In the future versions of\n     * HttpClient the use of this parameter will be discontinued.\n     */\n    public static final String ANY_HOST = null;\n    /**\n     * The <tt>-1</tt> value represents any port.\n     */\n    public static final int ANY_PORT = -1;\n    /**\n     * The <tt>null</tt> value represents any realm.\n     */\n    public static final String ANY_REALM = null;\n    /**\n     * The <tt>null</tt> value represents any authentication scheme.\n     */\n    public static final String ANY_SCHEME = null;\n    /**\n     * Default scope matching any host, port, realm and authentication scheme.\n     * In the future versions of HttpClient the use of this parameter will be\n     * discontinued.\n     */\n    public static final AuthScope ANY = new AuthScope(ANY_HOST, ANY_PORT, ANY_REALM, ANY_SCHEME);\n    /** The authentication scheme the credentials apply to. */\n    private final String scheme;\n    /** The realm the credentials apply to. */\n    private final String realm;\n    /** The host the credentials apply to. */\n    private final String host;\n    /** The port the credentials apply to. */\n    private final int port;\n    /** Creates a new credentials scope for the given\n     * <tt>host</tt>, <tt>port</tt>, <tt>realm</tt>, and\n     * <tt>authentication scheme</tt>.\n     *\n     * @param host the host the credentials apply to. May be set\n     *   to <tt>null</tt> if credentials are applicable to\n     *   any host.\n     * @param port the port the credentials apply to. May be set\n     *   to negative value if credentials are applicable to\n     *   any port.\n     * @param realm the realm the credentials apply to. May be set\n     *   to <tt>null</tt> if credentials are applicable to\n     *   any realm.\n     * @param scheme the authentication scheme the credentials apply to.\n     *   May be set to <tt>null</tt> if credentials are applicable to\n     *   any authentication scheme.\n     */\n    public AuthScope(final String host, final int port,\n        final String realm, final String scheme)\n    {\n        this.host =   (host == null)   ? ANY_HOST: host.toLowerCase(Locale.ENGLISH);\n        this.port =   (port < 0)       ? ANY_PORT: port;\n        this.realm =  (realm == null)  ? ANY_REALM: realm;\n        this.scheme = (scheme == null) ? ANY_SCHEME: scheme.toUpperCase(Locale.ENGLISH);\n    }\n    /**\n     * @since 4.2\n     */\n    public AuthScope(final HttpHost host, final String realm, final String schemeName) {\n        this(host.getHostName(), host.getPort(), realm, schemeName);\n    }\n    /**\n     * @since 4.2\n     */\n    public AuthScope(final HttpHost host) {\n        this(host, ANY_REALM, ANY_SCHEME);\n    }\n    /** Creates a new credentials scope for the given\n     * <tt>host</tt>, <tt>port</tt>, <tt>realm</tt>, and any\n     * authentication scheme.\n     *\n     * @param host the host the credentials apply to. May be set\n     *   to <tt>null</tt> if credentials are applicable to\n     *   any host.\n     * @param port the port the credentials apply to. May be set\n     *   to negative value if credentials are applicable to\n     *   any port.\n     * @param realm the realm the credentials apply to. May be set\n     *   to <tt>null</tt> if credentials are applicable to\n     *   any realm.\n     */\n    public AuthScope(final String host, final int port, final String realm) {\n        this(host, port, realm, ANY_SCHEME);\n    }\n    /** Creates a new credentials scope for the given\n     * <tt>host</tt>, <tt>port</tt>, any realm name, and any\n     * authentication scheme.\n     *\n     * @param host the host the credentials apply to. May be set\n     *   to <tt>null</tt> if credentials are applicable to\n     *   any host.\n     * @param port the port the credentials apply to. May be set\n     *   to negative value if credentials are applicable to\n     *   any port.\n     */\n    public AuthScope(final String host, final int port) {\n        this(host, port, ANY_REALM, ANY_SCHEME);\n    }\n    /**\n     * Creates a copy of the given credentials scope.\n     */\n    public AuthScope(final AuthScope authscope) {\n        super();\n        Args.notNull(authscope, \"Scope\");\n        this.host = authscope.getHost();\n        this.port = authscope.getPort();\n        this.realm = authscope.getRealm();\n        this.scheme = authscope.getScheme();\n    }\n    /**\n     * @return the host\n     */\n    public String getHost() {\n        return this.host;\n    }\n    /**\n     * @return the port\n     */\n    public int getPort() {\n        return this.port;\n    }\n    /**\n     * @return the realm name\n     */\n    public String getRealm() {\n        return this.realm;\n    }\n    /**\n     * @return the scheme type\n     */\n    public String getScheme() {\n        return this.scheme;\n    }\n    /**\n     * Tests if the authentication scopes match.\n     *\n     * @return the match factor. Negative value signifies no match.\n     *    Non-negative signifies a match. The greater the returned value\n     *    the closer the match.\n     */\n    public int match(final AuthScope that) {\n        int factor = 0;\n        if (LangUtils.equals(this.scheme, that.scheme)) {\n            factor += 1;\n        } else {\n            if (this.scheme != ANY_SCHEME && that.scheme != ANY_SCHEME) {\n                return -1;\n            }\n        }\n        if (LangUtils.equals(this.realm, that.realm)) {\n            factor += 2;\n        } else {\n            if (this.realm != ANY_REALM && that.realm != ANY_REALM) {\n                return -1;\n            }\n        }\n        if (this.port == that.port) {\n            factor += 4;\n        } else {\n            if (this.port != ANY_PORT && that.port != ANY_PORT) {\n                return -1;\n            }\n        }\n        if (LangUtils.equals(this.host, that.host)) {\n            factor += 8;\n        } else {\n            if (this.host != ANY_HOST && that.host != ANY_HOST) {\n                return -1;\n            }\n        }\n        return factor;\n    }\n    /**\n     * @see java.lang.Object#equals(Object)\n     */\n    @Override\n    public boolean equals(final Object o) {\n        if (o == null) {\n            return false;\n        }\n", "outputs": ["        if (o == this) {"], "input_length": 1505, "output_length": 7, "length": 1512, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "b5fcaaa4603beba3cb34d9ee8c769bd23d9e39068a8ca9884cd61bc2e9d388a3"}
{"input": "", "context": "/*******************************************************************************\n * Copyright (c) 2001, 2010 IBM Corporation and others.\n * All rights reserved. This program and the accompanying materials\n * are made available under the terms of the Eclipse Public License v1.0\n * which accompanies this distribution, and is available at\n * http://www.eclipse.org/legal/epl-v10.html\n *\n * Contributors:\n *     IBM Corporation - initial API and implementation\n *******************************************************************************/\npackage org.eclipse.wst.xsd.ui.internal.adt.design.editparts;\nimport java.util.List;\nimport org.eclipse.core.runtime.Assert;\nimport org.eclipse.draw2d.geometry.Rectangle;\nimport org.eclipse.gef.AccessibleEditPart;\nimport org.eclipse.gef.EditPart;\nimport org.eclipse.gef.EditPartFactory;\nimport org.eclipse.gef.GraphicalViewer;\nimport org.eclipse.gef.editparts.AbstractGraphicalEditPart;\nimport org.eclipse.gef.editparts.ScalableRootEditPart;\nimport org.eclipse.gef.editparts.ZoomListener;\nimport org.eclipse.gef.editparts.ZoomManager;\nimport org.eclipse.jface.action.IAction;\nimport org.eclipse.swt.SWT;\nimport org.eclipse.swt.accessibility.AccessibleEvent;\nimport org.eclipse.swt.graphics.Font;\nimport org.eclipse.swt.graphics.FontData;\nimport org.eclipse.swt.widgets.Display;\nimport org.eclipse.ui.IEditorInput;\nimport org.eclipse.ui.IEditorPart;\nimport org.eclipse.ui.IFileEditorInput;\nimport org.eclipse.ui.IWorkbench;\nimport org.eclipse.ui.IWorkbenchPage;\nimport org.eclipse.ui.IWorkbenchWindow;\nimport org.eclipse.ui.PlatformUI;\nimport org.eclipse.ui.ide.FileStoreEditorInput;\nimport org.eclipse.wst.xsd.ui.internal.adt.design.editparts.model.IActionProvider;\nimport org.eclipse.wst.xsd.ui.internal.adt.design.editparts.model.IFeedbackHandler;\nimport org.eclipse.wst.xsd.ui.internal.adt.design.editpolicies.KeyBoardAccessibilityEditPolicy;\nimport org.eclipse.wst.xsd.ui.internal.adt.design.figures.IFigureFactory;\nimport org.eclipse.wst.xsd.ui.internal.adt.editor.CommonMultiPageEditor;\nimport org.eclipse.wst.xsd.ui.internal.adt.facade.IADTObject;\nimport org.eclipse.wst.xsd.ui.internal.adt.facade.IADTObjectListener;\npublic abstract class BaseEditPart extends AbstractGraphicalEditPart implements IActionProvider, IADTObjectListener, IFeedbackHandler\n{\n  protected static final String[] EMPTY_ACTION_ARRAY = {};\n  protected boolean isSelected = false;\n  protected boolean hasFocus = false;\n  protected static boolean isHighContrast = Display.getDefault().getHighContrast();\n  protected AccessibleEditPart accessiblePart;\n  \n  public IFigureFactory getFigureFactory()\n  {\n    EditPartFactory factory = getViewer().getEditPartFactory();\n    Assert.isTrue(factory instanceof IFigureFactory, \"EditPartFactory must be an instanceof of IFigureFactory\");     //$NON-NLS-1$\n    return (IFigureFactory)factory; \n  }\n  \n  public String[] getActions(Object object)\n  {\n    Object model = getModel();\n    if (model instanceof IActionProvider)\n    {\n      return ((IActionProvider)model).getActions(object);\n    }  \n    return EMPTY_ACTION_ARRAY;\n  }\n  \n  protected void addActionsToList(List list, IAction[] actions)\n  {\n    for (int i = 0; i < actions.length; i++)\n    {\n      list.add(actions[i]);\n    }  \n  }\n  \n  public void activate()\n  {\n    super.activate();\n    Object model = getModel();\n    if (model instanceof IADTObject)\n    {\n      IADTObject object = (IADTObject)model;\n      object.registerListener(this);\n    }\n    \n    if (getZoomManager() != null)\n      getZoomManager().addZoomListener(zoomListener);\n  }\n  \n  public void deactivate()\n  {\n    try\n    {\n    Object model = getModel();\n    if (model instanceof IADTObject)\n    {\n      IADTObject object = (IADTObject)model;\n      object.unregisterListener(this);\n    }   \n    \n    if (getZoomManager() != null)\n      getZoomManager().removeZoomListener(zoomListener);    \n    }\n    finally\n    {\n      super.deactivate();\n    }  \n  }  \n  \n  public void propertyChanged(Object object, String property)\n  {\n    refresh();\n  }\n  \n  public void refresh() {\n    \n    boolean doUpdateDesign = doUpdateDesign();\n    if (doUpdateDesign)\n    {\n      super.refresh();\n    }\n  }\n  public void addFeedback()\n  {\n    isSelected = true;\n    refreshVisuals();\n  }\n  public void removeFeedback()\n  {\n    isSelected = false;\n    refreshVisuals();\n  }\n  \n  public ZoomManager getZoomManager()\n  {\n    return ((ScalableRootEditPart)getRoot()).getZoomManager();\n  }\n  \n  public Rectangle getZoomedBounds(Rectangle r)\n  {\n    double factor = getZoomManager().getZoom();\n    int x = (int)Math.round(r.x * factor);\n    int y = (int)Math.round(r.y * factor);\n    int width = (int)Math.round(r.width * factor);\n    int height = (int)Math.round(r.height * factor);\n    return new Rectangle(x, y, width, height);\n  }\n  \n  private ZoomListener zoomListener = new ZoomListener()\n  {\n    public void zoomChanged(double zoom)\n    {\n      handleZoomChanged();\n    }\n  };\n  protected void handleZoomChanged()\n  {\n    refreshVisuals();\n  }\n  public IEditorPart getEditorPart()\n  {\n    IEditorPart editorPart = null;\n    IWorkbench workbench = PlatformUI.getWorkbench();\n    if (workbench != null)\n    {\n      IWorkbenchWindow workbenchWindow = workbench.getActiveWorkbenchWindow();\n      if (workbenchWindow != null)\n      {\n        if (workbenchWindow.getActivePage() != null)\n        {\n          editorPart = workbenchWindow.getActivePage().getActiveEditor();\n        }\n      }\n    }\n//    Assert.isNotNull(editorPart);\n    return editorPart;\n  }\n  \n  protected void createEditPolicies()\n  {\n    installEditPolicy(KeyBoardAccessibilityEditPolicy.KEY, new KeyBoardAccessibilityEditPolicy()\n    {      \n      public EditPart getRelativeEditPart(EditPart editPart, int direction)\n      {\n        return doGetRelativeEditPart(editPart, direction);  \n      }           \n    });        \n  }\n  \n  \n  public EditPart doGetRelativeEditPart(EditPart editPart, int direction)\n  {   \n    return null;      \n  }\n  \n  protected boolean isFileReadOnly()\n  {\n", "outputs": ["    IWorkbench workbench = PlatformUI.getWorkbench();"], "input_length": 956, "output_length": 7, "length": 963, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "81b6924e696147c54b8f56f6a816b5d43dedb1c0e7a4e2a70bb2e405bc8857f2"}
{"input": "", "context": "using System;\nusing System.Collections.Concurrent;\nusing System.Collections.Generic;\nusing System.IO;\nusing System.Linq;\nusing System.Threading.Tasks;\nusing NLog;\nusing NzbDrone.Common.Disk;\nusing NzbDrone.Common.Extensions;\nusing NzbDrone.Common.TPL;\nusing NzbDrone.Core.Configuration;\nusing NzbDrone.Core.Configuration.Events;\nusing NzbDrone.Core.Datastore.Events;\nusing NzbDrone.Core.Lifecycle;\nusing NzbDrone.Core.MediaFiles.Commands;\nusing NzbDrone.Core.Messaging.Commands;\nusing NzbDrone.Core.Messaging.Events;\nusing NzbDrone.Core.RootFolders;\nnamespace NzbDrone.Core.MediaFiles\n{\n    public interface IRootFolderWatchingService\n    {\n        void ReportFileSystemChangeBeginning(params string[] paths);\n    }\n    public sealed class RootFolderWatchingService : IRootFolderWatchingService,\n        IDisposable,\n        IHandle<ModelEvent<RootFolder>>,\n        IHandle<ApplicationStartedEvent>,\n        IHandle<ConfigSavedEvent>\n    {\n        private const int DEBOUNCE_TIMEOUT_SECONDS = 30;\n        private readonly ConcurrentDictionary<string, FileSystemWatcher> _fileSystemWatchers = new ConcurrentDictionary<string, FileSystemWatcher>();\n        private readonly ConcurrentDictionary<string, int> _tempIgnoredPaths = new ConcurrentDictionary<string, int>();\n        private readonly ConcurrentDictionary<string, string> _changedPaths = new ConcurrentDictionary<string, string>();\n        private readonly IRootFolderService _rootFolderService;\n        private readonly IManageCommandQueue _commandQueueManager;\n        private readonly IConfigService _configService;\n        private readonly Logger _logger;\n        private readonly Debouncer _scanDebouncer;\n        private bool _watchForChanges;\n        public RootFolderWatchingService(IRootFolderService rootFolderService,\n                                         IManageCommandQueue commandQueueManager,\n                                         IConfigService configService,\n                                         Logger logger)\n        {\n            _rootFolderService = rootFolderService;\n            _commandQueueManager = commandQueueManager;\n            _configService = configService;\n            _logger = logger;\n            _scanDebouncer = new Debouncer(ScanPending, TimeSpan.FromSeconds(DEBOUNCE_TIMEOUT_SECONDS), true);\n        }\n        public void Dispose()\n        {\n            foreach (var watcher in _fileSystemWatchers.Values)\n            {\n                DisposeWatcher(watcher, false);\n            }\n        }\n        public void ReportFileSystemChangeBeginning(params string[] paths)\n        {\n            foreach (var path in paths.Where(x => x.IsNotNullOrWhiteSpace()))\n            {\n                _logger.Trace($\"reporting start of change to {path}\");\n                _tempIgnoredPaths.AddOrUpdate(path.CleanFilePathBasic(), 1, (key, value) => value + 1);\n            }\n        }\n        public void Handle(ApplicationStartedEvent message)\n        {\n            _watchForChanges = _configService.WatchLibraryForChanges;\n            if (_watchForChanges)\n            {\n                _rootFolderService.All().ForEach(x => StartWatchingPath(x.Path));\n            }\n        }\n        public void Handle(ConfigSavedEvent message)\n        {\n            var oldWatch = _watchForChanges;\n            _watchForChanges = _configService.WatchLibraryForChanges;\n            if (_watchForChanges != oldWatch)\n            {\n                if (_watchForChanges)\n                {\n                    _rootFolderService.All().ForEach(x => StartWatchingPath(x.Path));\n                }\n                else\n                {\n                    _rootFolderService.All().ForEach(x => StopWatchingPath(x.Path));\n                }\n            }\n        }\n        public void Handle(ModelEvent<RootFolder> message)\n        {\n            if (message.Action == ModelAction.Created && _watchForChanges)\n            {\n                StartWatchingPath(message.Model.Path);\n            }\n            else if (message.Action == ModelAction.Deleted)\n            {\n                StopWatchingPath(message.Model.Path);\n            }\n        }\n        private void StartWatchingPath(string path)\n        {\n            // Already being watched\n            if (_fileSystemWatchers.ContainsKey(path))\n            {\n                return;\n            }\n            // Creating a FileSystemWatcher over the LAN can take hundreds of milliseconds, so wrap it in a Task to do them all in parallel\n            Task.Run(() =>\n            {\n                try\n                {\n                    var newWatcher = new FileSystemWatcher(path, \"*\")\n                    {\n                        IncludeSubdirectories = true,\n                        InternalBufferSize = 65536,\n                        NotifyFilter = NotifyFilters.DirectoryName | NotifyFilters.FileName | NotifyFilters.LastWrite\n                    };\n                    newWatcher.Created += Watcher_Changed;\n                    newWatcher.Deleted += Watcher_Changed;\n                    newWatcher.Renamed += Watcher_Changed;\n                    newWatcher.Changed += Watcher_Changed;\n                    newWatcher.Error += Watcher_Error;\n                    if (_fileSystemWatchers.TryAdd(path, newWatcher))\n                    {\n                        newWatcher.EnableRaisingEvents = true;\n                        _logger.Info(\"Watching directory {0}\", path);\n                    }\n                    else\n                    {\n                        DisposeWatcher(newWatcher, false);\n                    }\n                }\n                catch (Exception ex)\n                {\n                    _logger.Error(ex, \"Error watching path: {0}\", path);\n                }\n            });\n        }\n        private void StopWatchingPath(string path)\n        {\n            if (_fileSystemWatchers.TryGetValue(path, out var watcher))\n            {\n                DisposeWatcher(watcher, true);\n            }\n        }\n        private void Watcher_Error(object sender, ErrorEventArgs e)\n        {\n            var ex = e.GetException();\n            var dw = (FileSystemWatcher)sender;\n            if (ex.GetType() == typeof(InternalBufferOverflowException))\n            {\n                _logger.Warn(ex, \"The file system watcher experienced an internal buffer overflow for: {0}\", dw.Path);\n                _changedPaths.TryAdd(dw.Path, dw.Path);\n                _scanDebouncer.Execute();\n            }\n            else\n            {\n                _logger.Error(ex, \"Error in Directory watcher for: {0}\" + dw.Path);\n                DisposeWatcher(dw, true);\n            }\n        }\n        private void Watcher_Changed(object sender, FileSystemEventArgs e)\n        {\n            try\n            {\n                var rootFolder = ((FileSystemWatcher)sender).Path;\n                var path = e.FullPath;\n                if (path.IsNullOrWhiteSpace())\n                {\n                    throw new ArgumentNullException(\"path\");\n                }\n                _changedPaths.TryAdd(path, rootFolder);\n                _scanDebouncer.Execute();\n            }\n            catch (Exception ex)\n            {\n                _logger.Error(ex, \"Exception in ReportFileSystemChanged. Path: {0}\", e.FullPath);\n            }\n        }\n        private void ScanPending()\n        {\n            var pairs = _changedPaths.ToArray();\n            _changedPaths.Clear();\n            var ignored = _tempIgnoredPaths.Keys.ToArray();\n            _tempIgnoredPaths.Clear();\n            var toScan = new HashSet<string>();\n            foreach (var item in pairs)\n            {\n                var path = item.Key.CleanFilePathBasic();\n                var rootFolder = item.Value;\n", "outputs": ["                if (!ShouldIgnoreChange(path, ignored))"], "input_length": 920, "output_length": 10, "length": 930, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "0f25031ab341e8c3fc5f57388331afc5cb9863bf414adc6be514cf9d165c7fa7"}
{"input": "", "context": "#!/usr/bin/python\n# -*- coding: utf-8 -*-\n\"\"\"\nAnsible module to add boundary meters.\n(c) 2013, curtis <curtis@serverascode.com>\nThis file is part of Ansible\nAnsible is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\nAnsible is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\nYou should have received a copy of the GNU General Public License\nalong with Ansible.  If not, see <http://www.gnu.org/licenses/>.\n\"\"\"\nANSIBLE_METADATA = {'status': ['preview'],\n                    'supported_by': 'community',\n                    'version': '1.0'}\nDOCUMENTATION = '''\nmodule: boundary_meter\nshort_description: Manage boundary meters\ndescription:\n    - This module manages boundary meters\nversion_added: \"1.3\"\nauthor: \"curtis (@ccollicutt)\"\nrequirements:\n    - Boundary API access\n    - bprobe is required to send data, but not to register a meter\noptions:\n    name:\n        description:\n            - meter name\n        required: true\n    state:\n        description:\n            - Whether to create or remove the client from boundary\n        required: false\n        default: true\n        choices: [\"present\", \"absent\"]\n    apiid:\n        description:\n            - Organizations boundary API ID\n        required: true\n    apikey:\n        description:\n            - Organizations boundary API KEY\n        required: true\n    validate_certs:\n        description:\n            - If C(no), SSL certificates will not be validated. This should only be used\n              on personally controlled sites using self-signed certificates.\n        required: false\n        default: 'yes'\n        choices: ['yes', 'no']\n        version_added: 1.5.1\nnotes:\n    - This module does not yet support boundary tags.\n'''\nEXAMPLES='''\n- name: Create meter\n  boundary_meter:\n    apiid: AAAAAA\n    apikey: BBBBBB\n    state: present\n    name: '{{ inventory_hostname }}'\n- name: Delete meter\n  boundary_meter:\n    apiid: AAAAAA\n    apikey: BBBBBB\n    state: absent\n    name: '{{ inventory_hostname }}'\n'''\nimport base64\nimport os\ntry:\n    import json\nexcept ImportError:\n    try:\n        import simplejson as json\n    except ImportError:\n        # Let snippet from module_utils/basic.py return a proper error in this case\n        pass\nfrom ansible.module_utils.basic import AnsibleModule\nfrom ansible.module_utils.urls import fetch_url\napi_host = \"api.boundary.com\"\nconfig_directory = \"/etc/bprobe\"\n# \"resource\" like thing or apikey?\ndef auth_encode(apikey):\n    auth = base64.standard_b64encode(apikey)\n    auth.replace(\"\\n\", \"\")\n    return auth\ndef build_url(name, apiid, action, meter_id=None, cert_type=None):\n    if action == \"create\":\n        return 'https://%s/%s/meters' % (api_host, apiid)\n    elif action == \"search\":\n        return \"https://%s/%s/meters?name=%s\" % (api_host, apiid, name)\n    elif action == \"certificates\":\n        return \"https://%s/%s/meters/%s/%s.pem\" % (api_host, apiid, meter_id, cert_type)\n    elif action == \"tags\":\n        return \"https://%s/%s/meters/%s/tags\" % (api_host, apiid, meter_id)\n    elif action == \"delete\":\n        return \"https://%s/%s/meters/%s\" % (api_host, apiid, meter_id)\ndef http_request(module, name, apiid, apikey, action, data=None, meter_id=None, cert_type=None):\n    if meter_id is None:\n        url = build_url(name, apiid, action)\n    else:\n        if cert_type is None:\n            url = build_url(name, apiid, action, meter_id)\n        else:\n            url = build_url(name, apiid, action, meter_id, cert_type)\n    headers = dict()\n    headers[\"Authorization\"] = \"Basic %s\" % auth_encode(apikey)\n    headers[\"Content-Type\"] = \"application/json\"\n    return fetch_url(module, url, data=data, headers=headers)\ndef create_meter(module, name, apiid, apikey):\n    meters = search_meter(module, name, apiid, apikey)\n    if len(meters) > 0:\n        # If the meter already exists, do nothing\n        module.exit_json(status=\"Meter \" + name + \" already exists\",changed=False)\n    else:\n        # If it doesn't exist, create it\n        body = '{\"name\":\"' + name + '\"}'\n        response, info = http_request(module, name, apiid, apikey, data=body, action=\"create\")\n        if info['status'] != 200:\n            module.fail_json(msg=\"Failed to connect to api host to create meter\")\n        # If the config directory doesn't exist, create it\n        if not os.path.exists(config_directory):\n            try:\n                os.makedirs(config_directory)\n            except:\n                module.fail_json(\"Could not create \" + config_directory)\n        # Download both cert files from the api host\n        types = ['key', 'cert']\n        for cert_type in types:\n            try:\n                # If we can't open the file it's not there, so we should download it\n                cert_file = open('%s/%s.pem' % (config_directory,cert_type))\n            except IOError:\n                # Now download the file...\n                rc = download_request(module, name, apiid, apikey, cert_type)\n                if rc == False:\n                    module.fail_json(\"Download request for \" + cert_type + \".pem failed\")\n        return 0, \"Meter \" + name + \" created\"\ndef search_meter(module, name, apiid, apikey):\n    response, info = http_request(module, name, apiid, apikey, action=\"search\")\n    if info['status'] != 200:\n        module.fail_json(\"Failed to connect to api host to search for meter\")\n    # Return meters\n    return json.loads(response.read())\ndef get_meter_id(module, name, apiid, apikey):\n    # In order to delete the meter we need its id\n    meters = search_meter(module, name, apiid, apikey)\n    if len(meters) > 0:\n        return meters[0]['id']\n    else:\n        return None\ndef delete_meter(module, name, apiid, apikey):\n    meter_id = get_meter_id(module, name, apiid, apikey)\n    if meter_id is None:\n        return 1, \"Meter does not exist, so can't delete it\"\n    else:\n        response, info = http_request(module, name, apiid, apikey, action, meter_id)\n        if info['status'] != 200:\n            module.fail_json(\"Failed to delete meter\")\n        # Each new meter gets a new key.pem and ca.pem file, so they should be deleted\n", "outputs": ["        types = ['cert', 'key']"], "input_length": 1268, "output_length": 9, "length": 1277, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "6d3d7c1039e1d58d501a87ed295b635e255b12c91c7011e6197b0aaa8f831e0a"}
{"input": "", "context": "//\n// System.Web.UI.WebControls.FontUnit.cs\n//\n// Authors:\n//   Miguel de Icaza (miguel@novell.com)\n//   Ben Maurer (bmaurer@ximian.com).\n//\n// Copyright (C) 2005-2010 Novell, Inc (http://www.novell.com)\n//\n// Permission is hereby granted, free of charge, to any person obtaining\n// a copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to\n// permit persons to whom the Software is furnished to do so, subject to\n// the following conditions:\n// \n// The above copyright notice and this permission notice shall be\n// included in all copies or substantial portions of the Software.\n// \n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n// EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n// NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\n// LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\n// OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\n// WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n//\nusing System.Threading;\nusing System.Globalization;\nusing System.ComponentModel;\nusing System.Security.Permissions;\nusing System.Web.Util;\nnamespace System.Web.UI.WebControls\n{\n\t[TypeConverter  (typeof (FontUnitConverter))]\n\t[Serializable]\n\tpublic struct FontUnit\n\t{\n\t\tFontSize type;\n\t\tUnit unit;\n\t\t\n\t\tpublic static readonly FontUnit Empty;\n\t\tpublic static readonly FontUnit Smaller = new FontUnit (FontSize.Smaller);\n\t\tpublic static readonly FontUnit Larger = new FontUnit (FontSize.Larger);\n\t\tpublic static readonly FontUnit XXSmall = new FontUnit (FontSize.XXSmall);\n\t\tpublic static readonly FontUnit XSmall = new FontUnit (FontSize.XSmall);\n\t\tpublic static readonly FontUnit Small = new FontUnit (FontSize.Small);\n\t\tpublic static readonly FontUnit Medium = new FontUnit (FontSize.Medium);\n\t\tpublic static readonly FontUnit Large = new FontUnit (FontSize.Large);\n\t\tpublic static readonly FontUnit XLarge = new FontUnit (FontSize.XLarge);\n\t\tpublic static readonly FontUnit XXLarge = new FontUnit (FontSize.XXLarge);\n\t\tstatic string [] font_size_names = new string [] {null, null, \"Smaller\", \"Larger\", \"XX-Small\", \"X-Small\", \"Small\",\n\t\t\t\t\t\t\t\t  \"Medium\", \"Large\", \"X-Large\", \"XX-Large\" };\n\t\t\n\t\tpublic FontUnit (FontSize type)\n\t\t{\n\t\t\tint t = (int) type;\n\t\t\t\n\t\t\tif (t < 0 || t > (int)FontSize.XXLarge)\n\t\t\t\tthrow new ArgumentOutOfRangeException (\"type\");\n\t\t\t\n\t\t\tthis.type = type;\n\t\t\tif (type == FontSize.AsUnit)\n\t\t\t\tunit = new Unit (10, UnitType.Point);\n\t\t\telse\n\t\t\t\tunit = Unit.Empty;\n\t\t}\n\t\tpublic FontUnit (int value) : this (new Unit (value, UnitType.Point))\n\t\t{\n\t\t}\n\t\tpublic FontUnit (double value) : this (new Unit (value, UnitType.Point))\n\t\t{\n\t\t}\n\t\tpublic FontUnit (double value, UnitType type) : this (new Unit (value, type))\n\t\t{\n\t\t}\n\t\tpublic FontUnit (Unit value)\n\t\t{\n\t\t\ttype = FontSize.AsUnit;\n\t\t\tunit = value;\n\t\t}\n\t\t\n\t\tpublic FontUnit (string value) : this (value, Thread.CurrentThread.CurrentCulture)\n\t\t{}\n\t\tpublic FontUnit (string value, CultureInfo culture)\n\t\t{\n\t\t\tif (String.IsNullOrEmpty (value)) {\n\t\t\t\ttype = FontSize.NotSet;\n\t\t\t\tunit = Unit.Empty;\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tswitch (value.ToLower (Helpers.InvariantCulture)) {\n\t\t\t\tcase \"smaller\":\n\t\t\t\t\ttype = FontSize.Smaller;\n\t\t\t\t\tbreak;\n\t\t\t\tcase \"larger\":\n\t\t\t\t\ttype = FontSize.Larger;\n\t\t\t\t\tbreak;\n\t\t\t\tcase \"xxsmall\":\n\t\t\t\t\ttype = FontSize.XXSmall;\n\t\t\t\t\tbreak;\n\t\t\t\tcase \"xx-small\":\n\t\t\t\t\ttype = FontSize.XXSmall;\n\t\t\t\t\tbreak;\n\t\t\t\tcase \"xsmall\":\n\t\t\t\t\ttype = FontSize.XSmall;\n\t\t\t\t\tbreak;\n\t\t\t\tcase \"x-small\":\n\t\t\t\t\ttype = FontSize.XSmall;\n\t\t\t\t\tbreak;\n\t\t\t\tcase \"small\":\n\t\t\t\t\ttype = FontSize.Small;\n\t\t\t\t\tbreak;\n\t\t\t\tcase \"medium\":\n\t\t\t\t\ttype = FontSize.Medium;\n\t\t\t\t\tbreak;\n\t\t\t\tcase \"large\":\n\t\t\t\t\ttype = FontSize.Large;\n\t\t\t\t\tbreak;\n\t\t\t\tcase \"xlarge\":\n\t\t\t\t\ttype = FontSize.XLarge;\n\t\t\t\t\tbreak;\n\t\t\t\tcase \"x-large\":\n\t\t\t\t\ttype = FontSize.XLarge;\n\t\t\t\t\tbreak;\n\t\t\t\tcase \"xxlarge\":\n\t\t\t\t\ttype = FontSize.XXLarge;\n\t\t\t\t\tbreak;\n\t\t\t\tcase \"xx-large\":\n\t\t\t\t\ttype = FontSize.XXLarge;\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\ttype = FontSize.AsUnit;\n\t\t\t\t\tunit = new Unit (value, culture);\n\t\t\t\t\treturn;\n\t\t\t}\n\t\t\tunit = Unit.Empty;\n\t\t}\n\t\t\n\t\tpublic bool IsEmpty {\n\t\t\tget { return type == FontSize.NotSet; }\n\t\t}\n\t\tpublic FontSize Type {\n\t\t\tget { return type; }\n\t\t}\n\t\tpublic Unit Unit {\n\t\t\tget { return unit; }\n\t\t}\n\t\t\n\t\tpublic static FontUnit Parse (string s)\n\t\t{\n\t\t\treturn new FontUnit (s);\n\t\t}\n\t\tpublic static FontUnit Parse (string s, CultureInfo culture)\n\t\t{\n\t\t\treturn new FontUnit (s, culture);\n\t\t}\n\t\tpublic static FontUnit Point (int n)\n\t\t{\n\t\t\treturn new FontUnit (n);\n\t\t}\n\t\t\n\t\tpublic override bool Equals (object obj)\n\t\t{\n\t\t\tif (obj is FontUnit) {\n\t\t\t\tFontUnit other = (FontUnit) obj;\n\t\t\t\treturn (other.type == type && other.unit == unit);\n\t\t\t}\n\t\t\treturn false;\n\t\t}\n\t\t\n\t\tpublic override int GetHashCode ()\n\t\t{\n\t\t\treturn type.GetHashCode () ^ unit.GetHashCode ();\n\t\t}\n\t\t\n\t\tpublic static bool operator == (FontUnit left, FontUnit right)\n\t\t{\n\t\t\treturn left.type == right.type && left.unit == right.unit;\n\t\t}\n\t\tpublic static bool operator != (FontUnit left, FontUnit right)\n\t\t{\n\t\t\treturn left.type != right.type || left.unit != right.unit;\n\t\t}\n\t\t\n\t\tpublic static implicit operator FontUnit (int n)\n\t\t{\n\t\t\treturn new FontUnit (n);\n\t\t}\n\t\tpublic string ToString (IFormatProvider fmt)\n\t\t{\n", "outputs": ["\t\t\tif (type == FontSize.NotSet)"], "input_length": 1043, "output_length": 6, "length": 1049, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "1ebe15917e18f8964c6f4c96091588d020ebc01728b2d4c5cb367bdcfe8d07d6"}
{"input": "", "context": "\"\"\"\nBuilds out filesystem trees/data based on the object tree.\nThis is the code behind 'cobbler sync'.\nCopyright 2006-2009, Red Hat, Inc and Others\nMichael DeHaan <michael.dehaan AT gmail>\nThis program is free software; you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation; either version 2 of the License, or\n(at your option) any later version.\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\nYou should have received a copy of the GNU General Public License\nalong with this program; if not, write to the Free Software\nFoundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA\n02110-1301  USA\n\"\"\"\nimport os\nimport os.path\nimport glob\nimport shutil\nimport time\nimport yaml # Howell-Clark version\nimport sys\nimport glob\nimport traceback\nimport errno\nimport utils\nfrom cexceptions import *\nimport templar \nimport pxegen\nimport item_distro\nimport item_profile\nimport item_repo\nimport item_system\nfrom Cheetah.Template import Template\nimport clogger\nfrom utils import _\nimport cobbler.module_loader as module_loader\nclass BootSync:\n    \"\"\"\n    Handles conversion of internal state to the tftpboot tree layout\n    \"\"\"\n    def __init__(self,config,verbose=True,dhcp=None,dns=None,logger=None,tftpd=None):\n        \"\"\"\n        Constructor\n        \"\"\"\n        self.logger         = logger\n        if logger is None:\n            self.logger     = clogger.Logger()\n        self.verbose      = verbose\n        self.config       = config\n        self.api          = config.api\n        self.distros      = config.distros()\n        self.profiles     = config.profiles()\n        self.systems      = config.systems()\n        self.settings     = config.settings()\n        self.repos        = config.repos()\n        self.templar      = templar.Templar(config, self.logger)\n        self.pxegen       = pxegen.PXEGen(config, self.logger)\n        self.dns          = dns\n        self.dhcp         = dhcp\n        self.tftpd        = tftpd\n        self.bootloc      = utils.tftpboot_location()\n        self.pxegen.verbose = verbose\n        self.dns.verbose    = verbose\n        self.dhcp.verbose   = verbose\n        self.pxelinux_dir = os.path.join(self.bootloc, \"pxelinux.cfg\")\n        self.grub_dir = os.path.join(self.bootloc, \"grub\")\n        self.images_dir = os.path.join(self.bootloc, \"images\")\n        self.yaboot_bin_dir = os.path.join(self.bootloc, \"ppc\")\n        self.yaboot_cfg_dir = os.path.join(self.bootloc, \"etc\")\n        self.s390_dir = os.path.join(self.bootloc, \"s390x\")\n        self.rendered_dir = os.path.join(self.settings.webdir, \"rendered\")\n    def run(self):\n        \"\"\"\n        Syncs the current configuration file with the config tree.\n        Using the Check().run_ functions previously is recommended\n        \"\"\"\n        if not os.path.exists(self.bootloc):\n            utils.die(self.logger,\"cannot find directory: %s\" % self.bootloc)\n        self.logger.info(\"running pre-sync triggers\")\n        # run pre-triggers...\n        utils.run_triggers(self.api, None, \"/var/lib/cobbler/triggers/sync/pre/*\")\n        self.distros  = self.config.distros()\n        self.profiles = self.config.profiles()\n        self.systems  = self.config.systems()\n        self.settings = self.config.settings()\n        self.repos    = self.config.repos()\n        # execute the core of the sync operation\n        self.logger.info(\"cleaning trees\")\n        self.clean_trees()\n        # Have the tftpd module handle copying bootloaders,\n        # distros, images, and all_system_files\n        self.tftpd.sync(self.verbose)\n        # Copy distros to the webdir\n        # Adding in the exception handling to not blow up if files have\n        # been moved (or the path references an NFS directory that's no longer\n        # mounted)\n\tfor d in self.distros:\n            try:\n                self.logger.info(\"copying files for distro: %s\" % d.name)\n                self.pxegen.copy_single_distro_files(d,\n                                                     self.settings.webdir,True)\n                self.pxegen.write_templates(d,write_file=True)\n            except CX, e:\n                self.logger.error(e.value)\n        # make the default pxe menu anyway...\n        self.pxegen.make_pxe_menu()\n        if self.settings.manage_dhcp:\n            self.write_dhcp()\n        if self.settings.manage_dns:\n            self.logger.info(\"rendering DNS files\")\n            self.dns.regen_hosts()\n            self.dns.write_dns_files()\n        if self.settings.manage_tftpd:\n           # xinetd.d/tftpd, basically\n           self.logger.info(\"rendering TFTPD files\")\n           self.tftpd.write_tftpd_files()\n           # copy in boot_files\n           self.tftpd.write_boot_files()\n        self.logger.info(\"cleaning link caches\")\n        self.clean_link_cache()\n        if self.settings.manage_rsync:\n           self.logger.info(\"rendering Rsync files\")\n           self.rsync_gen()\n        # run post-triggers\n        self.logger.info(\"running post-sync triggers\")\n        utils.run_triggers(self.api, None, \"/var/lib/cobbler/triggers/sync/post/*\", logger=self.logger)\n        utils.run_triggers(self.api, None, \"/var/lib/cobbler/triggers/change/*\", logger=self.logger)\n        return True\n    def make_tftpboot(self):\n        \"\"\"\n        Make directories for tftpboot images\n        \"\"\"\n        if not os.path.exists(self.pxelinux_dir):\n            utils.mkdir(self.pxelinux_dir,logger=self.logger)\n        if not os.path.exists(self.grub_dir):\n            utils.mkdir(self.grub_dir,logger=self.logger)\n        grub_images_link = os.path.join(self.grub_dir, \"images\")\n        if not os.path.exists(grub_images_link):\n            os.symlink(\"../images\", grub_images_link)\n        if not os.path.exists(self.images_dir):\n            utils.mkdir(self.images_dir,logger=self.logger)\n        if not os.path.exists(self.s390_dir):\n            utils.mkdir(self.s390_dir,logger=self.logger)\n        if not os.path.exists(self.rendered_dir):\n            utils.mkdir(self.rendered_dir,logger=self.logger)\n        if not os.path.exists(self.yaboot_bin_dir):\n            utils.mkdir(self.yaboot_bin_dir,logger=self.logger)\n        if not os.path.exists(self.yaboot_cfg_dir):\n            utils.mkdir(self.yaboot_cfg_dir,logger=self.logger)\n    def clean_trees(self):\n        \"\"\"\n        Delete any previously built pxelinux.cfg tree and virt tree info and then create\n        directories.\n        Note: for SELinux reasons, some information goes in /tftpboot, some in /var/www/cobbler\n        and some must be duplicated in both.  This is because PXE needs tftp, and auto-kickstart\n        and Virt operations need http.   Only the kernel and initrd images are duplicated, which is\n        unfortunate, though SELinux won't let me give them two contexts, so symlinks are not\n        a solution.  *Otherwise* duplication is minimal.\n        \"\"\"\n        # clean out parts of webdir and all of /tftpboot/images and /tftpboot/pxelinux.cfg\n        for x in os.listdir(self.settings.webdir):\n            path = os.path.join(self.settings.webdir,x)\n            if os.path.isfile(path):\n                if not x.endswith(\".py\"):\n                    utils.rmfile(path,logger=self.logger)\n            if os.path.isdir(path):\n                if not x in [\"aux\", \"web\", \"webui\", \"localmirror\",\"repo_mirror\",\"ks_mirror\",\"images\",\"links\",\"pub\",\"repo_profile\",\"repo_system\",\"svc\",\"rendered\",\".link_cache\"] :\n                    # delete directories that shouldn't exist\n                    utils.rmtree(path,logger=self.logger)\n                if x in [\"kickstarts\",\"kickstarts_sys\",\"images\",\"systems\",\"distros\",\"profiles\",\"repo_profile\",\"repo_system\",\"rendered\"]:\n                    # clean out directory contents\n                    utils.rmtree_contents(path,logger=self.logger)\n        #\n        self.make_tftpboot()\n        utils.rmtree_contents(self.pxelinux_dir,logger=self.logger)\n        utils.rmtree_contents(self.grub_dir,logger=self.logger)\n        utils.rmtree_contents(self.images_dir,logger=self.logger)\n        utils.rmtree_contents(self.s390_dir,logger=self.logger)\n        utils.rmtree_contents(self.yaboot_bin_dir,logger=self.logger)\n        utils.rmtree_contents(self.yaboot_cfg_dir,logger=self.logger)\n        utils.rmtree_contents(self.rendered_dir,logger=self.logger)\n    def write_dhcp(self):\n        self.logger.info(\"rendering DHCP files\")\n        self.dhcp.write_dhcp_file()\n        self.dhcp.regen_ethers()\n    def sync_dhcp(self):\n        restart_dhcp = str(self.settings.restart_dhcp).lower()\n        which_dhcp_module = module_loader.get_module_from_file(\"dhcp\",\"module\",just_name=True).strip()\n        if self.settings.manage_dhcp:\n            self.write_dhcp()\n            if which_dhcp_module == \"manage_isc\":\n                service_name = utils.dhcp_service_name(self.api)\n                if restart_dhcp != \"0\":\n                    rc = utils.subprocess_call(self.logger, \"dhcpd -t -q\", shell=True)\n                    if rc != 0:\n                       self.logger.error(\"dhcpd -t failed\")\n                       return False\n                    service_restart = \"service %s restart\" % service_name\n                    rc = utils.subprocess_call(self.logger, service_restart, shell=True)\n                    if rc != 0:\n", "outputs": ["                       self.logger.error(\"%s failed\" % service_name)"], "input_length": 1370, "output_length": 10, "length": 1380, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "9c106f2b602ce635d4ce8453637d8f013c6d08ff3c4ecd9046017fcc5b96aedd"}
{"input": "", "context": "package fr.nantes.univ.alma.tools.ui;\nimport java.awt.Color;\nimport java.awt.Graphics;\nimport java.awt.Graphics2D;\nimport java.awt.RenderingHints;\nimport java.awt.event.MouseEvent;\nimport java.awt.event.MouseListener;\nimport java.awt.font.FontRenderContext;\nimport java.awt.font.TextLayout;\nimport java.awt.geom.AffineTransform;\nimport java.awt.geom.Area;\nimport java.awt.geom.Ellipse2D;\nimport java.awt.geom.Point2D;\nimport java.awt.geom.Rectangle2D;\nimport javax.swing.JComponent;\npublic class InfiniteProgressPanel extends JComponent implements MouseListener\n{\n\tprivate static final long serialVersionUID = 8770653983557145191L;\n\t\n\tprotected Area[]  ticker     = null;\n    protected Thread  animation  = null;\n    protected boolean started    = false;\n    protected int     alphaLevel = 0;\n    protected int     rampDelay  = 300;\n    protected float   shield     = 0.70f;\n    protected String  text       = \"\";\n    protected int     barsCount  = 14;\n    protected float   fps        = 15.0f;\n    protected RenderingHints hints = null;\n    public InfiniteProgressPanel()\n    {\n        this(\"\");\n    }\n    public InfiniteProgressPanel(String text)\n    {\n        this(text, 14);\n    }\n    public InfiniteProgressPanel(String text, int barsCount)\n    {\n        this(text, barsCount, 0.70f);\n    }\n    public InfiniteProgressPanel(String text, int barsCount, float shield)\n    {\n        this(text, barsCount, shield, 15.0f);\n    }\n    public InfiniteProgressPanel(String text, int barsCount, float shield, float fps)\n    {\n        this(text, barsCount, shield, fps, 300);\n    }\n    public InfiniteProgressPanel(String text, int barsCount, float shield, float fps, int rampDelay)\n    {\n        this.text \t   = text;\n        this.rampDelay = rampDelay >= 0 ? rampDelay : 0;\n        this.shield    = shield >= 0.0f ? shield : 0.0f;\n        this.fps       = fps > 0.0f ? fps : 15.0f;\n        this.barsCount = barsCount > 0 ? barsCount : 14;\n        this.hints = new RenderingHints(RenderingHints.KEY_RENDERING, RenderingHints.VALUE_RENDER_QUALITY);\n        this.hints.put(RenderingHints.KEY_ANTIALIASING, RenderingHints.VALUE_ANTIALIAS_ON);\n        this.hints.put(RenderingHints.KEY_FRACTIONALMETRICS, RenderingHints.VALUE_FRACTIONALMETRICS_ON);\n    }\n    public void setText(String text)\n    {\n        repaint();\n        this.text = text;\n    }\n    public String getText()\n    {\n        return text;\n    }\n    public void start()\n    {\n        addMouseListener(this);\n        setVisible(true);\n        ticker = buildTicker();\n        animation = new Thread(new Animator(true));\n        animation.start();\n    }\n    public void stop()\n    {\n        if (animation != null) {\n\t        animation.interrupt();\n\t        animation = null;\n\t        animation = new Thread(new Animator(false));\n\t        animation.start();\n        }\n    }\n    \n    public void interrupt()\n    {\n        if (animation != null) {\n            animation.interrupt();\n            animation = null;\n            removeMouseListener(this);\n            setVisible(false);\n        }\n    }\n    public void paintComponent(Graphics g)\n    {\n        if (started)\n        {\n            int width  = getWidth();\n            double maxY = 0.0; \n            Graphics2D g2 = (Graphics2D) g;\n            g2.setRenderingHints(hints);\n            \n            g2.setColor(new Color(255, 255, 255, (int) (alphaLevel * shield)));\n            g2.fillRect(0, 0, getWidth(), getHeight());\n            for (int i = 0; i < ticker.length; i++)\n            {\n                int channel = 224 - 128 / (i + 1);\n                g2.setColor(new Color(channel, channel, channel, alphaLevel));\n                g2.fill(ticker[i]);\n                Rectangle2D bounds = ticker[i].getBounds2D();\n                if (bounds.getMaxY() > maxY)\n                    maxY = bounds.getMaxY();\n            }\n            if (text != null && text.length() > 0)\n            {\n\t            FontRenderContext context = g2.getFontRenderContext();\n\t            TextLayout layout = new TextLayout(text, getFont(), context);\n\t            Rectangle2D bounds = layout.getBounds();\n\t            g2.setColor(getForeground());\n\t            layout.draw(g2, (float) (width - bounds.getWidth()) / 2,\n\t                    \t\t(float) (maxY + layout.getLeading() + 2 * layout.getAscent()));\n            }\n        }\n    }\n    private Area[] buildTicker()\n    {\n        Area[] ticker = new Area[barsCount];\n        Point2D.Double center = new Point2D.Double((double) getWidth() / 2, (double) getHeight() / 2);\n        double fixedAngle = 2.0 * Math.PI / ((double) barsCount);\n        for (double i = 0.0; i < (double) barsCount; i++)\n        {\n            Area primitive = buildPrimitive();\n            AffineTransform toCenter = AffineTransform.getTranslateInstance(center.getX(), center.getY());\n            AffineTransform toBorder = AffineTransform.getTranslateInstance(45.0, -6.0);\n            AffineTransform toCircle = AffineTransform.getRotateInstance(-i * fixedAngle, center.getX(), center.getY());\n            AffineTransform toWheel = new AffineTransform();\n            toWheel.concatenate(toCenter);\n            toWheel.concatenate(toBorder);\n            primitive.transform(toWheel);\n            primitive.transform(toCircle);\n            \n            ticker[(int) i] = primitive;\n        }\n        return ticker;\n    }\n    private Area buildPrimitive()\n    {\n        Rectangle2D.Double body = new Rectangle2D.Double(6, 0, 30, 12);\n        Ellipse2D.Double   head = new Ellipse2D.Double(0, 0, 12, 12);\n        Ellipse2D.Double   tail = new Ellipse2D.Double(30, 0, 12, 12);\n        Area tick = new Area(body);\n        tick.add(new Area(head));\n        tick.add(new Area(tail));\n        return tick;\n    }\n    protected class Animator implements Runnable\n    {\n        private boolean rampUp = true;\n        protected Animator(boolean rampUp)\n        {\n            this.rampUp = rampUp;\n        }\n        public void run()\n        {\n            Point2D.Double center = new Point2D.Double((double) getWidth() / 2, (double) getHeight() / 2);\n            double fixedIncrement = 2.0 * Math.PI / ((double) barsCount);\n            AffineTransform toCircle = AffineTransform.getRotateInstance(fixedIncrement, center.getX(), center.getY());\n    \n            long start = System.currentTimeMillis();\n            if (rampDelay == 0)\n                alphaLevel = rampUp ? 255 : 0;\n            started = true;\n            boolean inRamp = rampUp;\n            while (!Thread.interrupted())\n            {\n                if (!inRamp)\n                {\n", "outputs": ["                    for (int i = 0; i < ticker.length; i++)"], "input_length": 1074, "output_length": 13, "length": 1087, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "5401590d5e736e6be964612ce60ecc7bd56792c8389fd6c7b1d40c1c65316d43"}
{"input": "", "context": "#region using directives\nusing System;\nusing System.Threading;\nusing System.Threading.Tasks;\nusing PoGo.NecroBot.Logic.Common;\nusing PoGo.NecroBot.Logic.Event;\nusing PoGo.NecroBot.Logic.Logging;\nusing PoGo.NecroBot.Logic.State;\nusing PoGo.NecroBot.Logic.Utils;\nusing POGOProtos.Inventory.Item;\n#endregion\nnamespace PoGo.NecroBot.Logic.Tasks\n{\n    public class RecycleItemsTask\n    {\n        private static int _diff;\n        private static Random rnd = new Random();\n        public static async Task Execute(ISession session, CancellationToken cancellationToken)\n        {\n            cancellationToken.ThrowIfCancellationRequested();\n            await session.Inventory.RefreshCachedInventory();\n            var currentTotalItems = await session.Inventory.GetTotalItemCount();\n            if ((session.Profile.PlayerData.MaxItemStorage * session.LogicSettings.RecycleInventoryAtUsagePercentage / 100.0f) > currentTotalItems)\n                return;\n            var currentAmountOfPokeballs = await session.Inventory.GetItemAmountByType(ItemId.ItemPokeBall);\n            var currentAmountOfGreatballs = await session.Inventory.GetItemAmountByType(ItemId.ItemGreatBall);\n            var currentAmountOfUltraballs = await session.Inventory.GetItemAmountByType(ItemId.ItemUltraBall);\n            var currentAmountOfMasterballs = await session.Inventory.GetItemAmountByType(ItemId.ItemMasterBall);\n            if (session.LogicSettings.DetailedCountsBeforeRecycling)\n                Logger.Write(session.Translation.GetTranslation(TranslationString.CurrentPokeballInv,\n                    currentAmountOfPokeballs, currentAmountOfGreatballs, currentAmountOfUltraballs,\n                    currentAmountOfMasterballs));\n            var currentPotions = await session.Inventory.GetItemAmountByType(ItemId.ItemPotion);\n            var currentSuperPotions = await session.Inventory.GetItemAmountByType(ItemId.ItemSuperPotion);\n            var currentHyperPotions = await session.Inventory.GetItemAmountByType(ItemId.ItemHyperPotion);\n            var currentMaxPotions = await session.Inventory.GetItemAmountByType(ItemId.ItemMaxPotion);\n            var currentAmountOfPotions = currentPotions + currentSuperPotions + currentHyperPotions + currentMaxPotions;\n            if (session.LogicSettings.DetailedCountsBeforeRecycling)\n                Logger.Write(session.Translation.GetTranslation(TranslationString.CurrentPotionInv,\n                    currentPotions, currentSuperPotions, currentHyperPotions, currentMaxPotions));\n            \n            var currentRevives = await session.Inventory.GetItemAmountByType(ItemId.ItemRevive);\n            var currentMaxRevives = await session.Inventory.GetItemAmountByType(ItemId.ItemMaxRevive);\n            var currentAmountOfRevives = currentRevives + currentMaxRevives;\n            if (session.LogicSettings.DetailedCountsBeforeRecycling)\n                Logger.Write(session.Translation.GetTranslation(TranslationString.CurrentReviveInv,\n                    currentRevives, currentMaxRevives));\n            var currentAmountOfBerries = await session.Inventory.GetItemAmountByType(ItemId.ItemRazzBerry) +\n                await session.Inventory.GetItemAmountByType(ItemId.ItemBlukBerry) +\n                await session.Inventory.GetItemAmountByType(ItemId.ItemNanabBerry) +\n                await session.Inventory.GetItemAmountByType(ItemId.ItemWeparBerry) +\n                await session.Inventory.GetItemAmountByType(ItemId.ItemPinapBerry);\n            var currentAmountOfIncense = await session.Inventory.GetItemAmountByType(ItemId.ItemIncenseOrdinary) +\n                await session.Inventory.GetItemAmountByType(ItemId.ItemIncenseSpicy) +\n                await session.Inventory.GetItemAmountByType(ItemId.ItemIncenseCool) +\n                await session.Inventory.GetItemAmountByType(ItemId.ItemIncenseFloral);\n            var currentAmountOfLuckyEggs = await session.Inventory.GetItemAmountByType(ItemId.ItemLuckyEgg);\n            var currentAmountOfLures = await session.Inventory.GetItemAmountByType(ItemId.ItemTroyDisk);\n            if (session.LogicSettings.DetailedCountsBeforeRecycling)\n                Logger.Write(session.Translation.GetTranslation(TranslationString.CurrentMiscItemInv,\n                    currentAmountOfBerries, currentAmountOfIncense, currentAmountOfLuckyEggs, currentAmountOfLures));\n            if (session.LogicSettings.TotalAmountOfPokeballsToKeep != 0)\n                await OptimizedRecycleBalls(session, cancellationToken);\n            if (!session.LogicSettings.VerboseRecycling)\n                Logger.Write(session.Translation.GetTranslation(TranslationString.RecyclingQuietly), LogLevel.Recycling);\n            if (session.LogicSettings.TotalAmountOfPotionsToKeep>=0)\n                await OptimizedRecyclePotions(session, cancellationToken);\n            if (session.LogicSettings.TotalAmountOfRevivesToKeep>=0)\n                await OptimizedRecycleRevives(session, cancellationToken);\n            if (session.LogicSettings.TotalAmountOfBerriesToKeep >= 0)\n                await OptimizedRecycleBerries(session, cancellationToken);\n            \n            await session.Inventory.RefreshCachedInventory();\n            currentTotalItems = await session.Inventory.GetTotalItemCount();\n            if ((session.Profile.PlayerData.MaxItemStorage * session.LogicSettings.RecycleInventoryAtUsagePercentage / 100.0f) > currentTotalItems)\n                return;\n            var items = await session.Inventory.GetItemsToRecycle(session);\n            foreach (var item in items)\n            {\n                cancellationToken.ThrowIfCancellationRequested();\n                await session.Client.Inventory.RecycleItem(item.ItemId, item.Count);\n                if (session.LogicSettings.VerboseRecycling)\n                    session.EventDispatcher.Send(new ItemRecycledEvent { Id = item.ItemId, Count = item.Count });\n                DelayingUtils.Delay(session.LogicSettings.RecycleActionDelay, 500);\n            }\n            await session.Inventory.RefreshCachedInventory();\n        }\n        private static async Task RecycleItems(ISession session, CancellationToken cancellationToken, int itemCount, ItemId item)\n        {\n            int itemsToRecycle = 0;\n            int itemsToKeep = itemCount - _diff;\n            if (itemsToKeep < 0)\n                itemsToKeep = 0;\n            itemsToRecycle = itemCount - itemsToKeep;\n            if (itemsToRecycle != 0)\n            {\n                _diff -= itemsToRecycle;\n                cancellationToken.ThrowIfCancellationRequested();\n                await session.Client.Inventory.RecycleItem(item, itemsToRecycle);\n                if (session.LogicSettings.VerboseRecycling)\n                    session.EventDispatcher.Send(new ItemRecycledEvent { Id = item, Count = itemsToRecycle });\n                DelayingUtils.Delay(session.LogicSettings.RecycleActionDelay, 500);\n            }\n        }\n        private static async Task OptimizedRecycleBalls(ISession session, CancellationToken cancellationToken)\n        {\n            var pokeBallsCount = await session.Inventory.GetItemAmountByType(ItemId.ItemPokeBall);\n            var greatBallsCount = await session.Inventory.GetItemAmountByType(ItemId.ItemGreatBall);\n            var ultraBallsCount = await session.Inventory.GetItemAmountByType(ItemId.ItemUltraBall);\n            var masterBallsCount = await session.Inventory.GetItemAmountByType(ItemId.ItemMasterBall);\n            int totalBallsCount = pokeBallsCount + greatBallsCount + ultraBallsCount + masterBallsCount;\n            int random = rnd.Next(-1 * session.LogicSettings.RandomRecycleValue, session.LogicSettings.RandomRecycleValue + 1);\n            if (totalBallsCount > session.LogicSettings.TotalAmountOfPokeballsToKeep)\n            {\n                if (session.LogicSettings.RandomizeRecycle)\n                {\n                    _diff = totalBallsCount - session.LogicSettings.TotalAmountOfPokeballsToKeep + random;\n                } else {\n                    _diff = totalBallsCount - session.LogicSettings.TotalAmountOfPokeballsToKeep;\n                }\n                \n                if (_diff > 0)\n                {\n                    await RecycleItems(session, cancellationToken, pokeBallsCount, ItemId.ItemPokeBall);\n                }\n                if (_diff > 0)\n                {\n                    await RecycleItems(session, cancellationToken, greatBallsCount, ItemId.ItemGreatBall); \n                }\n                if (_diff > 0)\n                {\n                    await RecycleItems(session, cancellationToken, ultraBallsCount, ItemId.ItemUltraBall);\n                }\n                if (_diff > 0)\n                {\n                    await RecycleItems(session, cancellationToken, masterBallsCount, ItemId.ItemMasterBall);\n                }\n            }\n        }\n        private static async Task OptimizedRecyclePotions(ISession session, CancellationToken cancellationToken)\n        {\n            var potionCount = await session.Inventory.GetItemAmountByType(ItemId.ItemPotion);\n            var superPotionCount = await session.Inventory.GetItemAmountByType(ItemId.ItemSuperPotion);\n            var hyperPotionsCount = await session.Inventory.GetItemAmountByType(ItemId.ItemHyperPotion);\n            var maxPotionCount = await session.Inventory.GetItemAmountByType(ItemId.ItemMaxPotion);\n            \n            int totalPotionsCount = potionCount + superPotionCount + hyperPotionsCount + maxPotionCount;\n            int random = rnd.Next(-1 * session.LogicSettings.RandomRecycleValue, session.LogicSettings.RandomRecycleValue + 1);\n            if (totalPotionsCount > session.LogicSettings.TotalAmountOfPotionsToKeep)\n            {\n                if (session.LogicSettings.RandomizeRecycle)\n                {\n                    _diff = totalPotionsCount - session.LogicSettings.TotalAmountOfPotionsToKeep + random;\n                }\n                else\n                {\n                    _diff = totalPotionsCount - session.LogicSettings.TotalAmountOfPotionsToKeep;\n                }\n                \n                if (_diff > 0)\n                {\n                    await RecycleItems(session, cancellationToken, potionCount, ItemId.ItemPotion);\n                }\n                if (_diff > 0)\n                {\n                    await RecycleItems(session, cancellationToken, superPotionCount, ItemId.ItemSuperPotion);\n                }\n                if (_diff > 0)\n                {\n                    await RecycleItems(session, cancellationToken, hyperPotionsCount, ItemId.ItemHyperPotion);\n                }\n                if (_diff > 0)\n                {\n                    await RecycleItems(session, cancellationToken, maxPotionCount, ItemId.ItemMaxPotion);\n                }\n            }\n        }\n        private static async Task OptimizedRecycleRevives(ISession session, CancellationToken cancellationToken)\n        {\n            var reviveCount = await session.Inventory.GetItemAmountByType(ItemId.ItemRevive);\n            var maxReviveCount = await session.Inventory.GetItemAmountByType(ItemId.ItemMaxRevive);\n            int totalRevivesCount = reviveCount + maxReviveCount;\n            int random = rnd.Next(-1 * session.LogicSettings.RandomRecycleValue, session.LogicSettings.RandomRecycleValue + 1);\n            if (totalRevivesCount > session.LogicSettings.TotalAmountOfRevivesToKeep)\n            {\n                if (session.LogicSettings.RandomizeRecycle)\n                {\n                    _diff = totalRevivesCount - session.LogicSettings.TotalAmountOfRevivesToKeep + random;\n                }\n                else\n                {\n                    _diff = totalRevivesCount - session.LogicSettings.TotalAmountOfRevivesToKeep;\n                }\n                if (_diff > 0)\n                {\n                    await RecycleItems(session, cancellationToken, reviveCount, ItemId.ItemRevive);\n                }\n                if (_diff > 0)\n                {\n                    await RecycleItems(session, cancellationToken, maxReviveCount, ItemId.ItemMaxRevive);\n                }\n            }\n        }\n        private static async Task OptimizedRecycleBerries(ISession session, CancellationToken cancellationToken)\n        {\n            var razz = await session.Inventory.GetItemAmountByType(ItemId.ItemRazzBerry);\n            var bluk = await session.Inventory.GetItemAmountByType(ItemId.ItemBlukBerry);\n            var nanab = await session.Inventory.GetItemAmountByType(ItemId.ItemNanabBerry);\n            var pinap = await session.Inventory.GetItemAmountByType(ItemId.ItemPinapBerry);\n            var wepar = await session.Inventory.GetItemAmountByType(ItemId.ItemWeparBerry);\n            int totalBerryCount = razz + bluk + nanab + pinap + wepar;\n            int random = rnd.Next(-1 * session.LogicSettings.RandomRecycleValue, session.LogicSettings.RandomRecycleValue + 1);\n            if (totalBerryCount > session.LogicSettings.TotalAmountOfBerriesToKeep)\n            {\n                if (session.LogicSettings.RandomizeRecycle)\n                {\n                    _diff = totalBerryCount - session.LogicSettings.TotalAmountOfBerriesToKeep + random;\n                }\n                else\n                {\n                    _diff = totalBerryCount - session.LogicSettings.TotalAmountOfBerriesToKeep;\n                }\n                \n                if (_diff > 0)\n                {\n                    await RecycleItems(session, cancellationToken, razz, ItemId.ItemRazzBerry);\n                }\n                if (_diff > 0)\n                {\n                    await RecycleItems(session, cancellationToken, bluk, ItemId.ItemBlukBerry);\n                }\n                if (_diff > 0)\n                {\n                    await RecycleItems(session, cancellationToken, nanab, ItemId.ItemNanabBerry);\n                }\n", "outputs": ["                if (_diff > 0)"], "input_length": 1292, "output_length": 6, "length": 1298, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "2d8c4b93c826bd3c22d07960506457971bbbb1b14de7407a6b88d6bc72b239df"}
{"input": "", "context": "package com.entrepidea.swing.components.checkbox;\nimport java.awt.BorderLayout;\nimport java.awt.Component;\nimport java.awt.Graphics;\nimport java.awt.event.ActionListener;\nimport java.awt.event.ItemListener;\nimport java.awt.event.MouseAdapter;\nimport java.awt.event.MouseEvent;\nimport java.io.Serializable;\nimport javax.swing.ButtonGroup;\nimport javax.swing.ButtonModel;\nimport javax.swing.Icon;\nimport javax.swing.JCheckBox;\nimport javax.swing.JFrame;\nimport javax.swing.event.ChangeListener;\nimport javax.swing.plaf.UIResource;\nimport javax.swing.plaf.metal.MetalLookAndFeel;\npublic class TristateCheckbox extends JCheckBox {\n\tprivate static class State {\n\t\tString desc = \"\";\n\t\t//\"NOT_SELECTED\",\"CHECKED\", \"CROSSED\"\n\t\tprivate State(){}\n\t\t\n\t\tprivate State(String s){\n\t\t\tdesc = s;\n\t\t}\n\t\t@Override\n\t\tpublic String toString(){\n\t\t\treturn desc;\n\t\t}\n\t}\n\t\n\tpublic static final State NOT_SELECTED = new State(\"NOT_SELECTED\");\n\tpublic static final State CHECKED = new State(\"CHECKED\");\n\tpublic static final State CROSSED = new State(\"CROSSED\");\n\t\n\tprivate TristateCheckModel model = null;\n\t\n\tpublic TristateCheckbox(){\n\t\tthis(null);\n\t}\n\t\n\tpublic TristateCheckbox(String text){\n\t\tsuper(text);\n\t\t//set properties and model\n\t\tsuper.setIcon(new TristateIcon());\n\t\tsetModel((model = new TristateCheckModel(getModel())));\n\t\tsetState(NOT_SELECTED);\n\t\t\n\t\t//add listeners\n\t\tsuper.addMouseListener(new MouseAdapter(){\n\t\t\t@Override\n\t\t\tpublic void mousePressed(MouseEvent e){\n\t\t\t\tTristateCheckbox.this.mousePressed();\n\t\t\t}\n\t\t\t@Override\n\t\t\tpublic void mouseReleased(MouseEvent e){\n\t\t\t\tTristateCheckbox.this.mouseReleased();\n\t\t\t}\n\t\t});\n\t}\n\t\n\tprivate void mousePressed(){\n\t\tSystem.out.println(\"mouse pressed\");\n\t\tgrabFocus();\n\t\tmodel.setArmed(true);\n\t\tmodel.setPressed(true);\n\t}\n\t\n\tprivate void mouseReleased(){\n\t\tSystem.out.println(\"mouse released\");\n\t\tmodel.nextState();\n\t\tmodel.setArmed(false);\n\t\tmodel.setPressed(false);\n\t}\n\t\n\tpublic void doClick(){\n\t\tmousePressed();\n\t\tmouseReleased();\n\t}\n\tpublic void setState(State s){\n\t\tmodel.setState(s);\n\t}\n\t\n\tpublic State getState(){\n\t\treturn model.getState();\n\t}\n\t\n\t\n\tpublic void setSelected(boolean selected) {\n\t\tif (selected) {\n\t\t\tsetState(CHECKED);\n\t\t} else {\n\t\t\tsetState(NOT_SELECTED);\n\t\t}\n\t}\n\t\n\tprivate class TristateCheckModel implements ButtonModel{\n\t\tButtonModel model = null;\n\t\tState currentState = NOT_SELECTED;\n\t\t\n\t\tpublic TristateCheckModel(ButtonModel model){\n\t\t\tthis.model = model;\n\t\t}\n\t\t\n\t\tpublic void setState(State s){\n\t\t\tcurrentState = s;\n\t\t};\n\t\t\n\t\tpublic State getState(){\n\t\t\treturn currentState;\n\t\t}\n\t\t\n\t\tpublic void nextState(){\n\t\t\tState s = getState();\n\t\t\tSystem.out.println(\"current state: \"+s);\n\t\t\tif(s==NOT_SELECTED){\n\t\t\t\tsetState(CHECKED);\n\t\t\t}\n\t\t\telse if(s == CHECKED){\n\t\t\t\tsetState(CROSSED);\n\t\t\t}\n\t\t\telse if(s== CROSSED){\n\t\t\t\tsetState(NOT_SELECTED);\n\t\t\t}\n\t\t\tSystem.out.println(getState());\n\t\t\tmodel.setSelected(!model.isSelected()); //trigger the fireEvent\n\t\t}\n\t\t\n\t\t\n\t\t\n\t\t@Override\n\t\tpublic Object[] getSelectedObjects() {\n\t\t\treturn model.getSelectedObjects();\n\t\t}\n\t\t@Override\n\t\tpublic boolean isArmed() {\n\t\t\treturn model.isArmed();\n\t\t}\n\t\t@Override\n\t\tpublic boolean isSelected() {\n\t\t\treturn (currentState == CHECKED || currentState == CROSSED);\n\t\t}\n\t\t@Override\n\t\tpublic boolean isEnabled() {\n\t\t\treturn model.isEnabled();\n\t\t}\n\t\t@Override\n\t\tpublic boolean isPressed() {\n\t\t\treturn model.isPressed();\n\t\t}\n\t\t@Override\n\t\tpublic boolean isRollover() {\n\t\t\treturn model.isRollover();\n\t\t}\n\t\t@Override\n\t\tpublic void setArmed(boolean b) {\n\t\t\tmodel.setArmed(b);\n\t\t}\n\t\t@Override\n\t\tpublic void setSelected(boolean b) {\n\t\t\tmodel.setSelected(b);\n\t\t}\n\t\t@Override\n\t\tpublic void setEnabled(boolean b) {\n\t\t\ttry {\n\t\t\t\tsetFocusable(b);\t\n\t\t\t} catch (Exception ex) {\n\t\t\t\tex.printStackTrace();\n\t\t\t}//catch\n\t\t\t\n\t\t\tmodel.setEnabled(b);\n\t\t}\n\t\t@Override\n\t\tpublic void setPressed(boolean b) {\n\t\t\tmodel.setPressed(b);\n\t\t}\n\t\t@Override\n\t\tpublic void setRollover(boolean b) {\n\t\t\tmodel.setRollover(b);\n\t\t}\n\t\t@Override\n\t\tpublic void setMnemonic(int key) {\n\t\t\tmodel.setMnemonic(key);\n\t\t}\n\t\t@Override\n\t\tpublic int getMnemonic() {\n\t\t\treturn model.getMnemonic();\n\t\t}\n\t\t@Override\n\t\tpublic void setActionCommand(String s) {\n\t\t\tmodel.setActionCommand(s);\n\t\t}\n\t\t@Override\n\t\tpublic String getActionCommand() {\n\t\t\treturn model.getActionCommand();\n\t\t}\n\t\t@Override\n\t\tpublic void setGroup(ButtonGroup group) {\n\t\t\tmodel.setGroup(group);\n\t\t}\n\t\t@Override\n\t\tpublic void addActionListener(ActionListener l) {\n\t\t\tmodel.addActionListener(l);\n\t\t}\n\t\t@Override\n\t\tpublic void removeActionListener(ActionListener l) {\n\t\t\tmodel.removeActionListener(l);\n\t\t}\n\t\t@Override\n\t\tpublic void addItemListener(ItemListener l) {\n\t\t\tmodel.addItemListener(l);\n\t\t}\n\t\t@Override\n\t\tpublic void removeItemListener(ItemListener l) {\n\t\t\tmodel.removeItemListener(l);\n\t\t}\n\t\t@Override\n\t\tpublic void addChangeListener(ChangeListener l) {\n\t\t\tmodel.addChangeListener(l);\n\t\t}\n\t\t@Override\n\t\tpublic void removeChangeListener(ChangeListener l) {\n\t\t\tmodel.removeChangeListener(l);\n\t\t}\n\t\t\n\t}\n\t\n\tprivate class TristateIcon implements Icon, UIResource, Serializable{\n \n\t\tprivate static final long serialVersionUID = 1L;\n\t\tprotected int getControlSize() {\n\t\t\treturn 13;\n\t\t}\n \n\t\tpublic void paintIcon(Component c, Graphics g, int x, int y) {\n\t\t\tJCheckBox cb = (JCheckBox)c;\n\t\t\tTristateCheckModel model = (TristateCheckModel)cb.getModel();\n\t\t\t\n\t\t\tboolean bDrawCross = model.getState() == CROSSED;\n\t\t\tboolean bDrawCheck = model.getState() == CHECKED;\n\t\t\t\n\t\t\tint controlSize = getControlSize();\n\t\t\t\n\t\t\tif(model.isEnabled()){\n\t\t\t\tif(model.isPressed() && model.isArmed()){\n\t\t\t\t\tg.setColor(MetalLookAndFeel.getControlShadow());\n\t\t\t\t\tg.fillRect(x, y, controlSize - 1, controlSize - 1);\n", "outputs": ["\t\t\t\t\tdrawPressed3DBorder(g, x, y, controlSize, controlSize);"], "input_length": 1010, "output_length": 13, "length": 1023, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "1986f62d8b9405fc3b861d61d020571023cb2f4d8ab78cdff229977b8245ade2"}
{"input": "", "context": "/*\n * Copyright 2013 Red Hat, Inc. and/or its affiliates.\n *\n * Licensed under the Eclipse Public License version 1.0, available at\n * http://www.eclipse.org/legal/epl-v10.html\n */\npackage org.jboss.forge.addon.ui.util;\nimport java.util.ArrayList;\nimport java.util.Iterator;\nimport java.util.List;\nimport java.util.Set;\nimport org.jboss.forge.addon.convert.CompositeConverter;\nimport org.jboss.forge.addon.convert.Converter;\nimport org.jboss.forge.addon.convert.ConverterFactory;\nimport org.jboss.forge.addon.facets.Facet;\nimport org.jboss.forge.addon.ui.facets.HintsFacet;\nimport org.jboss.forge.addon.ui.hints.InputType;\nimport org.jboss.forge.addon.ui.input.HasCompleter;\nimport org.jboss.forge.addon.ui.input.InputComponent;\nimport org.jboss.forge.addon.ui.input.ManyValued;\nimport org.jboss.forge.addon.ui.input.SelectComponent;\nimport org.jboss.forge.addon.ui.input.SingleValued;\nimport org.jboss.forge.addon.ui.input.UICompleter;\nimport org.jboss.forge.furnace.util.Sets;\nimport org.jboss.forge.furnace.util.Strings;\n/**\n * Utilities for {@link InputComponent} objects\n * \n * @author <a href=\"mailto:ggastald@redhat.com\">George Gastaldi</a>\n * \n */\n@SuppressWarnings({ \"rawtypes\", \"unchecked\" })\npublic final class InputComponents\n{\n   public static final char DEFAULT_SHORT_NAME = ' ';\n   private static final String COLON = \":\";\n   /**\n    * @return the {@link InputType} object associated to this {@link InputComponent}\n    */\n   public static String getInputType(InputComponent<?, ?> input)\n   {\n      String result = InputType.DEFAULT;\n      for (Facet f : input.getFacets())\n      {\n         if (HintsFacet.class.isInstance(f))\n         {\n            result = ((HintsFacet) f).getInputType();\n            break;\n         }\n      }\n      // FIXME: The following code does NOT work when called from Eclipse. Could it be a bug in CLAC ?\n      // if (input.hasFacet(HintsFacet.class))\n      // {\n      // HintsFacet facet = input.getFacet(HintsFacet.class);\n      // result = facet.getInputType();\n      // }\n      return result;\n   }\n   /**\n    * Returns the value stored in this {@link InputComponent}. <code>null</code> if the component is null\n    */\n   public static Object getValueFor(InputComponent<?, ?> component)\n   {\n      return (component == null) ? null : component.getValue();\n   }\n   /**\n    * Sets the value in the provided {@link InputComponent}, making any necessary conversions\n    * \n    * @param component\n    * @param value\n    */\n   public static void setValueFor(final ConverterFactory converterFactory, final InputComponent<?, ?> component,\n            final Object value)\n   {\n      if (component instanceof SingleValued)\n      {\n         setSingleInputValue(converterFactory, component, value, false);\n      }\n      else if (component instanceof ManyValued)\n      {\n         setManyInputValue(converterFactory, component, value, false);\n      }\n   }\n   /**\n    * Sets the default value in the provided {@link InputComponent}, making any necessary conversions\n    * \n    * @param component\n    * @param value\n    */\n   public static void setDefaultValueFor(final ConverterFactory converterFactory,\n            final InputComponent<?, Object> component,\n            final Object value)\n   {\n      if (component instanceof SingleValued)\n      {\n         setSingleInputValue(converterFactory, component, value, true);\n      }\n      else if (component instanceof ManyValued)\n      {\n         setManyInputValue(converterFactory, component, value, true);\n      }\n   }\n   private static void setSingleInputValue(final ConverterFactory converterFactory,\n            final InputComponent<?, ?> input, final Object value, boolean defaultValue)\n   {\n      final Object convertedType;\n      if (value != null)\n      {\n         convertedType = convertToUIInputValue(converterFactory, input, value);\n      }\n      else\n      {\n         convertedType = null;\n      }\n      if (defaultValue)\n      {\n         ((SingleValued) input).setDefaultValue(convertedType);\n      }\n      else\n      {\n         ((SingleValued) input).setValue(convertedType);\n      }\n   }\n   private static void setManyInputValue(final ConverterFactory converterFactory,\n            final InputComponent<?, ?> input, Object value, boolean defaultValue)\n   {\n      final Iterable<Object> convertedValues;\n      if (value != null)\n      {\n         List<Object> convertedValuesList = new ArrayList<>();\n         if (value instanceof Iterable && !input.getValueType().isInstance(value))\n         {\n            for (Object itValue : (Iterable) value)\n            {\n               Object singleValue = convertToUIInputValue(converterFactory, input, itValue);\n               if (singleValue != null)\n               {\n                  convertedValuesList.add(singleValue);\n               }\n            }\n         }\n         else\n         {\n            Object singleValue = convertToUIInputValue(converterFactory, input, value);\n            if (singleValue != null)\n            {\n               convertedValuesList.add(singleValue);\n            }\n         }\n         convertedValues = convertedValuesList;\n      }\n      else\n      {\n         convertedValues = null;\n      }\n      if (defaultValue)\n      {\n         ((ManyValued) input).setDefaultValue(convertedValues);\n      }\n      else\n      {\n         ((ManyValued) input).setValue(convertedValues);\n      }\n   }\n   /**\n    * Returns the converted value that matches the input.\n    */\n   public static Object convertToUIInputValue(final ConverterFactory converterFactory,\n            final InputComponent<?, ?> input, final Object value)\n   {\n      final Object result;\n      Class<Object> sourceType = (Class<Object>) value.getClass();\n      Class<Object> targetType = (Class<Object>) input.getValueType();\n      if (!targetType.isAssignableFrom(sourceType))\n      {\n         if (input instanceof SelectComponent)\n         {\n            SelectComponent<?, Object> selectComponent = (SelectComponent<?, Object>) input;\n            Iterable<Object> valueChoices = selectComponent.getValueChoices();\n            final Converter<Object, ?> selectConverter;\n            if (String.class.isAssignableFrom(sourceType))\n            {\n               selectConverter = getItemLabelConverter(converterFactory, selectComponent);\n            }\n            else\n            {\n               selectConverter = converterFactory.getConverter(targetType, sourceType);\n            }\n            Object chosenObj = null;\n            if (valueChoices != null)\n            {\n               for (Object valueChoice : valueChoices)\n               {\n                  Object convertedObj = selectConverter.convert(valueChoice);\n                  if (convertedObj.equals(value))\n                  {\n                     chosenObj = valueChoice;\n                     break;\n                  }\n               }\n            }\n            result = chosenObj;\n         }\n         else\n         {\n            Converter<String, Object> valueConverter = (Converter<String, Object>) input.getValueConverter();\n            if (valueConverter != null)\n            {\n               if (value instanceof String)\n               {\n                  result = valueConverter.convert((String) value);\n               }\n               else\n               {\n                  Converter<Object, String> stringConverter = converterFactory.getConverter(sourceType, String.class);\n                  CompositeConverter compositeConverter = new CompositeConverter(stringConverter, valueConverter);\n                  result = compositeConverter.convert(value);\n               }\n            }\n            else\n            {\n               Converter<Object, Object> converter = converterFactory.getConverter(sourceType, targetType);\n               result = converter.convert(value);\n            }\n         }\n      }\n      else\n      {\n         Converter<String, Object> valueConverter = (Converter<String, Object>) input.getValueConverter();\n         if (valueConverter != null && value instanceof String)\n         {\n            result = valueConverter.convert((String) value);\n         }\n         else\n         {\n            // FORGE-2493: By setting the system property 'org.jboss.forge.ui.select_one_lenient_value' to true will\n            // allow UISelectOne to set values outside of its value choices. (pre-2.20.0.Final behavior)\n            if (input instanceof SelectComponent && !Boolean.getBoolean(\"org.jboss.forge.ui.select_one_lenient_value\"))\n            {\n               SelectComponent<?, Object> selectComponent = (SelectComponent<?, Object>) input;\n               Set<Object> valueChoices = Sets.toSet(selectComponent.getValueChoices());\n               // Check if the value is contained in the valueChoices set\n               if (valueChoices != null && valueChoices.contains(value))\n               {\n                  result = value;\n               }\n               else\n               {\n                  // equals()/hashCode may not have been implemented. Trying to compare from the String representation\n                  Object chosenObj = null;\n                  if (valueChoices != null)\n                  {\n                     Converter<Object, String> selectConverter = getItemLabelConverter(converterFactory,\n                              selectComponent);\n", "outputs": ["                     String valueLabel = selectConverter.convert(value);"], "input_length": 1331, "output_length": 8, "length": 1339, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "4d09017776884b61d5b135344c96824dba1b13da7b3d7ea288dbe276fe471afe"}
{"input": "", "context": "import os\nimport sys\nimport time\nimport config\nimport numpy as np\nfrom numpy import vectorize\nfrom scipy import interpolate, integrate\nfrom scipy import special\nfrom scipy.interpolate import UnivariateSpline, InterpolatedUnivariateSpline\nfrom scipy.ndimage.filters import gaussian_filter\nimport pylab as pl\nfrom numba import double, float64, float32\nfrom numba import jit\nimport numba as nb\nimport timeit\n#import fastcorr\nfrom CosmologyFunctions import CosmologyFunctions\nfrom mass_function import halo_bias_st, bias_mass_func_tinker, bias_mass_func_bocquet\nfrom convert_NFW_RadMass import MfracToMvir, MvirToMRfrac, MfracToMfrac, MvirTomMRfrac, MfracTomMFrac, dlnMdensitydlnMcritOR200, HuKravtsov\nfrom pressure_profiles import battaglia_profile_2d\n__author__ = (\"Vinu Vikraman <vvinuv@gmail.com>\")\n@jit(nopython=True)\ndef Wk(zl, chil, zsarr, chisarr, Ns, constk):\n    #zl = lens redshift\n    #chil = comoving distant to lens\n    #zsarr = redshift distribution of source\n    #angsarr = angular diameter distance\n    #Ns = Normalized redshift distribution of sources \n    al = 1. / (1. + zl)\n    Wk = constk * chil / al\n    gw = 0.0\n    for i, N in enumerate(Ns):\n        if chisarr[i] < chil:\n            continue\n        gw += ((chisarr[i] - chil) * N / chisarr[i])\n    gw *= (zsarr[1] - zsarr[0])\n    if gw <= 0:\n        gw = 0.\n    Wk = Wk * gw\n    return Wk\n@jit(nopython=True)\ndef integrate_halo(ell, lnzarr, chiarr, dVdzdOm, marr, mf, BDarr, rhobarr, rho_crit_arr, bias, Darr, pk, zsarr, chisarr, Ns, dlnz, dlnm, omega_b0, omega_m0, cosmo_h, constk, consty, input_mvir): \n    '''\n    Eq. 3.1 Ma et al. \n    '''    \n    cl1h = 0.0\n    cl2h = 0.0\n    jj = 0\n    for i, lnzi in enumerate(lnzarr):\n        zi = np.exp(lnzi) - 1.\n        zp = 1. + zi\n        #print  zi, Wk(zi, chiarr[i], zsarr, angsarr, Ns, constk)\n        kl_yl_multi = Wk(zi, chiarr[i], zsarr, chisarr, Ns, constk) * consty / chiarr[i] / chiarr[i] / rhobarr[i] \n        mint = 0.0\n        mk2 = 0.0\n        my2 = 0.0\n        for mi in marr:\n            kint = 0.0\n            yint = 0.0\n            if input_mvir:\n                Mvir, Rvir, M200, R200, rho_s, Rs = MvirToMRfrac(mi, zi, BDarr[i], rho_crit_arr[i], cosmo_h, frac=200.0)\n            else:\n                Mvir, Rvir, M200, R200, rho_s, Rs = MfracToMvir(mi, zi, BDarr[i], rho_crit_arr[i], cosmo_h, frac=200.0)\n            #Eq. 3.2 Ma et al\n            rp = np.linspace(0, config.kRmax*Rvir, config.kRspace)\n            for tr in rp:\n                if tr == 0:\n                    continue \n                kint += (tr * tr * np.sin(ell * tr / chiarr[i]) / (ell * tr / chiarr[i]) * rho_s / (tr/Rs) / (1. + tr/Rs)**2.)\n            kint *= (4. * np.pi * (rp[1] - rp[0]))\n            #Eq. 3.3 Ma et al\n            xmax = config.yRmax * Rvir / Rs #Ma et al paper says that Eq. 3.3 convergence by r=5 rvir.\n            xp = np.linspace(0, xmax, config.yRspace)\n            ells = chiarr[i] / zp / Rs\n            for x in xp:\n                if x == 0:\n                    continue \n                yint += (x * x * np.sin(ell * x / ells) / (ell * x / ells) * battaglia_profile_2d(x, 0., Rs, M200, R200, zi, rho_crit_arr[i], omega_b0, omega_m0, cosmo_h))\n            yint *= (4 * np.pi * Rs * (xp[1] - xp[0]) / ells / ells)\n            mint += (dlnm * mf[jj] * kint * yint)\n            mk2 += (dlnm * bias[jj] * mf[jj] * kint)\n            my2 += (dlnm * bias[jj] * mf[jj] * yint)\n            jj += 1\n        cl1h += (dVdzdOm[i] * kl_yl_multi * mint * zp)\n        cl2h += (dVdzdOm[i] * pk[i] * Darr[i] * Darr[i] * kl_yl_multi * mk2 * my2)\n    cl1h *= dlnz\n    cl2h *= dlnz\n    cl = cl1h + cl2h\n    return cl1h, cl2h, cl\n \n@jit(nopython=True)\ndef integrate_kkhalo(ell, lnzarr, chiarr, dVdzdOm, marr, mf, BDarr, rhobarr, rho_crit_arr, bias, Darr, pk, zsarr, chisarr, Ns, dlnz, dlnm, omega_b0, omega_m0, cosmo_h, constk, consty, input_mvir): \n    '''\n    Eq. 3.1 Ma et al. \n    '''    \n   \n    cl1h = 0.0\n    cl2h = 0.0\n    jj = 0\n    for i, lnzi in enumerate(lnzarr):\n        zi = np.exp(lnzi) - 1.\n        zp = 1. + zi\n        #print  zi, Wk(zi, chiarr[i], zsarr, angsarr, Ns, constk)\n        kl_multi = Wk(zi, chiarr[i], zsarr, chisarr, Ns, constk) / chiarr[i] / chiarr[i] / rhobarr[i] \n        mint = 0.0\n        mk2 = 0.0\n        for mi in marr:\n            kint = 0.0\n            if input_mvir:\n                Mvir, Rvir, M200, R200, rho_s, Rs = MvirToMRfrac(mi, zi, BDarr[i], rho_crit_arr[i], cosmo_h, frac=200.0)\n            else:\n                Mvir, Rvir, M200, R200, rho_s, Rs = MfracToMvir(mi, zi, BDarr[i], rho_crit_arr[i], cosmo_h, frac=200.0)\n            #Eq. 3.2 Ma et al\n            #limit_kk_Rvir.py tests the limit of Rvir. \n            rp = np.linspace(0, config.kRmax * Rvir, config.kRspace)\n            for tr in rp:\n                if tr == 0:\n                    continue \n                kint += (tr * tr * np.sin(ell * tr / chiarr[i]) / (ell * tr / chiarr[i]) * rho_s / (tr/Rs) / (1. + tr/Rs)**2.)\n            kint *= (4. * np.pi * (rp[1] - rp[0]))\n            mint += (dlnm * mf[jj] * kint * kint)\n            mk2 += (dlnm * bias[jj] * mf[jj] * kint)\n            jj += 1\n        cl1h += (dVdzdOm[i] * kl_multi * kl_multi * mint * zp)\n        cl2h += (dVdzdOm[i] * pk[i] * Darr[i] * Darr[i] * kl_multi * kl_multi * mk2 * mk2 * zp)\n    cl1h *= dlnz\n    cl2h *= dlnz\n    cl = cl1h + cl2h\n    return cl1h, cl2h, cl\n \n@jit(nopython=True)\ndef integrate_yyhalo(ell, lnzarr, chiarr, dVdzdOm, marr, mf, BDarr, rhobarr, rho_crit_arr, bias, Darr, pk, dlnz, dlnm, omega_b0, omega_m0, cosmo_h, constk, consty, input_mvir):\n    '''\n    Eq. 3.1 Ma et al. \n    '''\n    cl1h = 0.0\n    cl2h = 0.0\n    jj = 0\n    for i, lnzi in enumerate(lnzarr[:]):\n        zi = np.exp(lnzi) - 1.\n        zp = 1. + zi\n        mint = 0.0\n        my2 = 0.0\n        for j, mi in enumerate(marr[:]):\n            if input_mvir:\n                Mvir, Rvir, M200, R200, rho_s, Rs = MvirToMRfrac(mi/cosmo_h, zi, BDarr[i], rho_crit_arr[i]*cosmo_h*cosmo_h, cosmo_h, frac=200.0)   \n            else:\n                Mvir, Rvir, M200, R200, rho_s, Rs = MfracToMvir(mi, zi, BDarr[i], rho_crit_arr[i], cosmo_h, frac=200.0)\n            xmax = config.yRmax * Rvir / Rs\n            ells = chiarr[i] / cosmo_h / zp / Rs\n            xarr = np.linspace(1e-5, xmax, config.yRspace)\n            yint = 0.\n            for x in xarr:\n                if x == 0:\n                    continue\n                yint += (x * x * np.sin(ell * x / ells) / (ell * x / ells) * battaglia_profile_2d(x, 0., Rs, M200, R200, zi, rho_crit_arr[i]*cosmo_h*cosmo_h, omega_b0, omega_m0, cosmo_h))\n            yint *= (4 * np.pi * Rs * (xarr[1] - xarr[0]) / ells / ells)\n            mint += (dlnm * mf[jj] * yint * yint)\n            my2 += (dlnm * bias[jj] * mf[jj] * yint)\n            jj += 1\n        cl1h += (dVdzdOm[i] * consty * consty * mint * zp)\n        cl2h += (dVdzdOm[i] * pk[i] * Darr[i] * Darr[i] * consty * consty * my2 * my2 * zp)\n    cl1h *= dlnz\n    cl2h *= dlnz\n    cl = cl1h + cl2h\n    return cl1h, cl2h, cl\ndef cl_WL_tSZ(fwhm_k, fwhm_y, kk, yy, ky, zsfile, odir='../data'):\n    '''\n    Compute WL X tSZ halomodel for a given source redshift distribution \n    '''\n    if ky:\n        sigma_k = fwhm_k * np.pi / 2.355 / 60. /180. #angle in radian\n        sigma_y = fwhm_y * np.pi / 2.355 / 60. /180. #angle in radian\n        sigmasq = sigma_k * sigma_y\n    elif kk:\n        sigma_k = fwhm_k * np.pi / 2.355 / 60. /180. #angle in radian\n        sigmasq = sigma_k * sigma_k\n    elif yy:\n        sigma_y = fwhm_y * np.pi / 2.355 / 60. /180. #angle in radian\n        sigmasq = sigma_y * sigma_y\n    else:\n        raise ValueError('Either kk, yy or ky should be True')\n    cosmo0 = CosmologyFunctions(0)\n    omega_b0 = cosmo0._omega_b0\n    omega_m0 = cosmo0._omega_m0\n    cosmo_h = cosmo0._h\n    light_speed = config.light_speed #km/s\n    mpctocm = config.mpctocm\n    kB_kev_K = config.kB_kev_K\n    sigma_t_cm = config.sigma_t_cm #cm^2\n    rest_electron_kev = config.rest_electron_kev #keV\n    constk = 3. * omega_m0 * (cosmo_h * 100. / light_speed)**2. / 2. #Mpc^-2\n    consty = mpctocm * sigma_t_cm / rest_electron_kev \n    fz= np.genfromtxt(zsfile)\n    zsarr = fz[:,0]\n    Ns = fz[:,1]\n    zint = np.sum(Ns) * (zsarr[1] - zsarr[0])\n    Ns /= zint\n    kmin = config.kmin #1/Mpc\n    kmax = config.kmax\n    kspace = config.kspace\n    mmin = config.mmin \n    mmax = config.mmax\n    mspace = config.mspace\n    zmin = config.zmin \n    zmax = config.zmax\n    zspace = config.zspace\n    dlnk = np.log(kmax/kmin) / kspace\n    lnkarr = np.linspace(np.log(kmin), np.log(kmax), kspace)\n    karr = np.exp(lnkarr).astype(np.float64)\n    #No little h\n    #Input Mpc/h to power spectra and get Mpc^3/h^3\n    pk_arr = np.array([cosmo0.linear_power(k/cosmo0._h) for k in karr]).astype(np.float64)\n    pkspl = InterpolatedUnivariateSpline(karr/cosmo0._h, pk_arr, k=2) \n    #pl.loglog(karr, pk_arr)\n    #pl.show()\n    dlnm = np.log(mmax/mmin) / mspace\n    lnmarr = np.linspace(np.log(mmin * cosmo0._h), np.log(mmax * cosmo0._h), mspace)\n    marr = np.exp(lnmarr).astype(np.float64)\n    lnzarr = np.linspace(np.log(1.+zmin), np.log(1.+zmax), zspace)\n    zarr = np.exp(lnzarr) - 1.0\n    dlnz = np.log((1.+zmax)/(1.+zmin)) / zspace\n    print 'dlnk, dlnm dlnz', dlnk, dlnm, dlnz\n    #No little h\n    #Need to give mass * h and get the sigma without little h\n    #The following lines are used only used for ST MF and ST bias\n    sigma_m0 = np.array([cosmo0.sigma_m(m) for m in marr])\n    rho_norm0 = cosmo0.rho_bar()\n    lnMassSigmaSpl = InterpolatedUnivariateSpline(lnmarr, sigma_m0, k=3)\n    hzarr, BDarr, rhobarr, chiarr, dVdzdOm, rho_crit_arr = [], [], [], [], [], []\n    bias, Darr = [], []\n    mf, dlnmdlnm = [], []\n    for i, zi in enumerate(zarr):\n        cosmo = CosmologyFunctions(zi)\n        rcrit = cosmo.rho_crit()\n        rbar = cosmo.rho_bar()\n        bn = cosmo.BryanDelta()\n        BDarr.append(bn) #OK\n        rho_crit_arr.append(rcrit) #OK\n        rhobarr.append(rbar)\n        chiarr.append(cosmo.comoving_distance())\n        hzarr.append(cosmo.E0(zi))\n        #Number of Msun objects/Mpc^3 (i.e. unit is 1/Mpc^3)\n", "outputs": ["        if config.MF =='Tinker':"], "input_length": 2330, "output_length": 5, "length": 2335, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "6802b94708cba4cc68f232ab6bdfe6b48ac467441cf9215e0d5187be35f53646"}
{"input": "", "context": "# Copyright (C) 2013-2016 2ndQuadrant Italia Srl\n#\n# This file is part of Barman.\n#\n# Barman is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# Barman is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with Barman.  If not, see <http://www.gnu.org/licenses/>.\nimport errno\nimport os\nimport select\nimport sys\nfrom datetime import datetime\nfrom logging import DEBUG, INFO, WARNING\nfrom subprocess import PIPE\nimport dateutil.tz\nimport mock\nimport pytest\nfrom barman import command_wrappers\nfrom barman.command_wrappers import CommandFailedException, StreamLineProcessor\ntry:\n    from StringIO import StringIO\nexcept ImportError:  # pragma: no cover\n    from io import StringIO\ndef _mock_pipe(popen, pipe_processor_loop, ret=0, out='', err=''):\n    pipe = popen.return_value\n    pipe.communicate.return_value = (out.encode('utf-8'), err.encode('utf-8'))\n    pipe.returncode = ret\n    # noinspection PyProtectedMember\n    def ppl(processors):\n        for processor in processors:\n            if processor.fileno() == pipe.stdout.fileno.return_value:\n                for line in out.split('\\n'):\n                    processor._handler(line)\n            if processor.fileno() == pipe.stderr.fileno.return_value:\n                for line in err.split('\\n'):\n                    processor._handler(line)\n    pipe_processor_loop.side_effect = ppl\n    return pipe\n# noinspection PyMethodMayBeStatic\n@mock.patch('barman.command_wrappers.Command.pipe_processor_loop')\n@mock.patch('barman.command_wrappers.subprocess.Popen')\nclass TestCommand(object):\n    def test_simple_invocation(self, popen, pipe_processor_loop):\n        command = 'command'\n        ret = 0\n        out = 'out'\n        err = 'err'\n        pipe = _mock_pipe(popen, pipe_processor_loop, ret, out, err)\n        cmd = command_wrappers.Command(command)\n        result = cmd()\n        popen.assert_called_with(\n            [command], shell=False, env=None,\n            stdout=PIPE, stderr=PIPE, stdin=PIPE,\n            preexec_fn=mock.ANY, close_fds=True\n        )\n        assert not pipe.stdin.write.called\n        pipe.stdin.close.assert_called_once_with()\n        assert result == ret\n        assert cmd.ret == ret\n        assert cmd.out == out\n        assert cmd.err == err\n    def test_multiline_output(self, popen, pipe_processor_loop):\n        command = 'command'\n        ret = 0\n        out = 'line1\\nline2\\n'\n        err = 'err1\\nerr2\\n'\n        pipe = _mock_pipe(popen, pipe_processor_loop, ret, out, err)\n        cmd = command_wrappers.Command(command)\n        result = cmd()\n        popen.assert_called_with(\n            [command], shell=False, env=None,\n            stdout=PIPE, stderr=PIPE, stdin=PIPE,\n            preexec_fn=mock.ANY, close_fds=True\n        )\n        assert not pipe.stdin.write.called\n        pipe.stdin.close.assert_called_once_with()\n        assert result == ret\n        assert cmd.ret == ret\n        assert cmd.out == out\n        assert cmd.err == err\n    def test_failed_invocation(self, popen, pipe_processor_loop):\n        command = 'command'\n        ret = 1\n        out = 'out'\n        err = 'err'\n        pipe = _mock_pipe(popen, pipe_processor_loop, ret, out, err)\n        cmd = command_wrappers.Command(command)\n        result = cmd()\n        popen.assert_called_with(\n            [command], shell=False, env=None,\n            stdout=PIPE, stderr=PIPE, stdin=PIPE,\n            preexec_fn=mock.ANY, close_fds=True\n        )\n        assert not pipe.stdin.write.called\n        pipe.stdin.close.assert_called_once_with()\n        assert result == ret\n        assert cmd.ret == ret\n        assert cmd.out == out\n        assert cmd.err == err\n    def test_check_failed_invocation(self, popen, pipe_processor_loop):\n        command = 'command'\n        ret = 1\n        out = 'out'\n        err = 'err'\n        pipe = _mock_pipe(popen, pipe_processor_loop, ret, out, err)\n        cmd = command_wrappers.Command(command, check=True)\n        with pytest.raises(command_wrappers.CommandFailedException) as excinfo:\n            cmd()\n        assert excinfo.value.args[0]['ret'] == ret\n        assert excinfo.value.args[0]['out'] == out\n        assert excinfo.value.args[0]['err'] == err\n        popen.assert_called_with(\n            [command], shell=False, env=None,\n            stdout=PIPE, stderr=PIPE, stdin=PIPE,\n            preexec_fn=mock.ANY, close_fds=True\n        )\n        assert not pipe.stdin.write.called\n        pipe.stdin.close.assert_called_once_with()\n        assert cmd.ret == ret\n        assert cmd.out == out\n        assert cmd.err == err\n    def test_shell_invocation(self, popen, pipe_processor_loop):\n        command = 'test -n'\n        ret = 0\n        out = 'out'\n        err = 'err'\n        pipe = _mock_pipe(popen, pipe_processor_loop, ret, out, err)\n        cmd = command_wrappers.Command(command, shell=True)\n        result = cmd('shell test')\n        popen.assert_called_with(\n            \"test -n 'shell test'\", shell=True, env=None,\n            stdout=PIPE, stderr=PIPE, stdin=PIPE,\n            preexec_fn=mock.ANY, close_fds=True\n        )\n        assert not pipe.stdin.write.called\n        pipe.stdin.close.assert_called_once_with()\n        assert result == ret\n        assert cmd.ret == ret\n        assert cmd.out == out\n        assert cmd.err == err\n    def test_declaration_args_invocation(self, popen, pipe_processor_loop):\n        command = 'command'\n        ret = 0\n        out = 'out'\n        err = 'err'\n        pipe = _mock_pipe(popen, pipe_processor_loop, ret, out, err)\n        cmd = command_wrappers.Command(command, args=['one', 'two'])\n        result = cmd()\n        popen.assert_called_with(\n            [command, 'one', 'two'], shell=False, env=None,\n            stdout=PIPE, stderr=PIPE, stdin=PIPE,\n            preexec_fn=mock.ANY, close_fds=True\n        )\n        assert not pipe.stdin.write.called\n        pipe.stdin.close.assert_called_once_with()\n        assert result == ret\n        assert cmd.ret == ret\n        assert cmd.out == out\n        assert cmd.err == err\n    def test_call_args_invocation(self, popen, pipe_processor_loop):\n        command = 'command'\n        ret = 0\n        out = 'out'\n        err = 'err'\n        pipe = _mock_pipe(popen, pipe_processor_loop, ret, out, err)\n        cmd = command_wrappers.Command(command)\n        result = cmd('one', 'two')\n        popen.assert_called_with(\n            [command, 'one', 'two'], shell=False, env=None,\n            stdout=PIPE, stderr=PIPE, stdin=PIPE,\n            preexec_fn=mock.ANY, close_fds=True\n        )\n        assert not pipe.stdin.write.called\n        pipe.stdin.close.assert_called_once_with()\n        assert result == ret\n        assert cmd.ret == ret\n        assert cmd.out == out\n        assert cmd.err == err\n    def test_both_args_invocation(self, popen, pipe_processor_loop):\n        command = 'command'\n        ret = 0\n        out = 'out'\n        err = 'err'\n        pipe = _mock_pipe(popen, pipe_processor_loop, ret, out, err)\n        cmd = command_wrappers.Command(command, args=['a', 'b'])\n        result = cmd('one', 'two')\n        popen.assert_called_with(\n            [command, 'a', 'b', 'one', 'two'], shell=False, env=None,\n            stdout=PIPE, stderr=PIPE, stdin=PIPE,\n            preexec_fn=mock.ANY, close_fds=True\n        )\n        assert not pipe.stdin.write.called\n        pipe.stdin.close.assert_called_once_with()\n        assert result == ret\n        assert cmd.ret == ret\n        assert cmd.out == out\n        assert cmd.err == err\n    def test_env_invocation(self, popen, pipe_processor_loop):\n        command = 'command'\n        ret = 0\n        out = 'out'\n        err = 'err'\n        pipe = _mock_pipe(popen, pipe_processor_loop, ret, out, err)\n        with mock.patch('os.environ', new={'TEST0': 'VAL0'}):\n            cmd = command_wrappers.Command(command,\n                                           env_append={'TEST1': 'VAL1',\n                                                       'TEST2': 'VAL2'})\n            result = cmd()\n        popen.assert_called_with(\n            [command], shell=False,\n            env={'TEST0': 'VAL0', 'TEST1': 'VAL1', 'TEST2': 'VAL2'},\n            stdout=PIPE, stderr=PIPE, stdin=PIPE,\n            preexec_fn=mock.ANY, close_fds=True\n        )\n        assert not pipe.stdin.write.called\n        pipe.stdin.close.assert_called_once_with()\n        assert result == ret\n        assert cmd.ret == ret\n        assert cmd.out == out\n        assert cmd.err == err\n    def test_path_invocation(self, popen, pipe_processor_loop):\n        command = 'command'\n        ret = 0\n        out = 'out'\n        err = 'err'\n        pipe = _mock_pipe(popen, pipe_processor_loop, ret, out, err)\n        with mock.patch('os.environ', new={'TEST0': 'VAL0'}):\n            cmd = command_wrappers.Command(command,\n                                           path='/path/one:/path/two')\n            result = cmd()\n        popen.assert_called_with(\n            [command], shell=False,\n            env={'TEST0': 'VAL0', 'PATH': '/path/one:/path/two'},\n            stdout=PIPE, stderr=PIPE, stdin=PIPE,\n            preexec_fn=mock.ANY, close_fds=True\n        )\n        assert not pipe.stdin.write.called\n        pipe.stdin.close.assert_called_once_with()\n        assert result == ret\n        assert cmd.ret == ret\n        assert cmd.out == out\n        assert cmd.err == err\n    def test_env_path_invocation(self, popen, pipe_processor_loop):\n        command = 'command'\n        ret = 0\n        out = 'out'\n        err = 'err'\n        pipe = _mock_pipe(popen, pipe_processor_loop, ret, out, err)\n        with mock.patch('os.environ', new={'TEST0': 'VAL0'}):\n            cmd = command_wrappers.Command(command,\n                                           path='/path/one:/path/two',\n                                           env_append={'TEST1': 'VAL1',\n                                                       'TEST2': 'VAL2'})\n            result = cmd()\n        popen.assert_called_with(\n            [command], shell=False,\n            env={'TEST0': 'VAL0', 'TEST1': 'VAL1', 'TEST2': 'VAL2',\n                 'PATH': '/path/one:/path/two'},\n            stdout=PIPE, stderr=PIPE, stdin=PIPE,\n            preexec_fn=mock.ANY, close_fds=True\n        )\n        assert not pipe.stdin.write.called\n        pipe.stdin.close.assert_called_once_with()\n        assert result == ret\n        assert cmd.ret == ret\n        assert cmd.out == out\n        assert cmd.err == err\n    def test_debug_invocation(self, popen, pipe_processor_loop):\n        command = 'command'\n        ret = 1\n        out = 'out'\n        err = 'err'\n        pipe = _mock_pipe(popen, pipe_processor_loop, ret, out, err)\n        stdout = StringIO()\n        stderr = StringIO()\n        with mock.patch.multiple('sys', stdout=stdout, stderr=stderr):\n            cmd = command_wrappers.Command(command, debug=True)\n            result = cmd()\n        popen.assert_called_with(\n            [command], shell=False, env=None,\n            stdout=PIPE, stderr=PIPE, stdin=PIPE,\n            preexec_fn=mock.ANY, close_fds=True\n        )\n        assert not pipe.stdin.write.called\n        pipe.stdin.close.assert_called_once_with()\n        assert result == ret\n        assert cmd.ret == ret\n        assert cmd.out == out\n        assert cmd.err == err\n        assert stdout.getvalue() == \"\"\n        assert stderr.getvalue() == \"Command: ['command']\\n\" \\\n                                    \"Command return code: 1\\n\"\n    def test_getoutput_invocation(self, popen, pipe_processor_loop):\n        command = 'command'\n        ret = 0\n        out = 'out'\n        err = 'err'\n        stdin = 'in'\n        pipe = _mock_pipe(popen, pipe_processor_loop, ret, out, err)\n        with mock.patch('os.environ', new={'TEST0': 'VAL0'}):\n            cmd = command_wrappers.Command(command,\n                                           env_append={'TEST1': 'VAL1',\n                                                       'TEST2': 'VAL2'})\n            result = cmd.getoutput(stdin=stdin)\n        popen.assert_called_with(\n            [command], shell=False,\n            env={'TEST0': 'VAL0', 'TEST1': 'VAL1', 'TEST2': 'VAL2'},\n            stdout=PIPE, stderr=PIPE, stdin=PIPE,\n            preexec_fn=mock.ANY, close_fds=True\n        )\n        pipe.stdin.write.assert_called_with(stdin)\n        pipe.stdin.close.assert_called_once_with()\n        assert result == (out, err)\n        assert cmd.ret == ret\n        assert cmd.out == out\n        assert cmd.err == err\n    def test_execute_invocation(self, popen, pipe_processor_loop,\n                                caplog):\n        command = 'command'\n        ret = 0\n        out = 'out'\n        err = 'err'\n        stdin = 'in'\n        pipe = _mock_pipe(popen, pipe_processor_loop, ret, out, err)\n        with mock.patch('os.environ', new={'TEST0': 'VAL0'}):\n            cmd = command_wrappers.Command(command,\n                                           env_append={'TEST1': 'VAL1',\n                                                       'TEST2': 'VAL2'})\n            result = cmd.execute(stdin=stdin)\n        popen.assert_called_with(\n            [command], shell=False,\n            env={'TEST0': 'VAL0', 'TEST1': 'VAL1', 'TEST2': 'VAL2'},\n            stdout=PIPE, stderr=PIPE, stdin=PIPE,\n            preexec_fn=mock.ANY, close_fds=True\n        )\n        pipe.stdin.write.assert_called_with(stdin)\n        pipe.stdin.close.assert_called_once_with()\n        assert result == ret\n        assert cmd.ret == ret\n        assert cmd.out is None\n        assert cmd.err is None\n        assert ('Command', INFO, out) in caplog.record_tuples\n        assert ('Command', WARNING, err) in caplog.record_tuples\n    def test_execute_invocation_multiline(self, popen, pipe_processor_loop,\n                                          caplog):\n        command = 'command'\n        ret = 0\n        out = 'line1\\nline2\\n'\n        err = 'err1\\nerr2'  # no final newline here\n        stdin = 'in'\n        pipe = _mock_pipe(popen, pipe_processor_loop, ret, out, err)\n        with mock.patch('os.environ', new={'TEST0': 'VAL0'}):\n            cmd = command_wrappers.Command(command,\n                                           env_append={'TEST1': 'VAL1',\n                                                       'TEST2': 'VAL2'})\n            result = cmd.execute(stdin=stdin)\n        popen.assert_called_with(\n            [command], shell=False,\n            env={'TEST0': 'VAL0', 'TEST1': 'VAL1', 'TEST2': 'VAL2'},\n            stdout=PIPE, stderr=PIPE, stdin=PIPE,\n            preexec_fn=mock.ANY, close_fds=True\n        )\n        pipe.stdin.write.assert_called_with(stdin)\n        pipe.stdin.close.assert_called_once_with()\n        assert result == ret\n        assert cmd.ret == ret\n        assert cmd.out is None\n        assert cmd.err is None\n        for line in out.splitlines():\n            assert ('Command', INFO, line) in caplog.record_tuples\n        assert ('Command', INFO, '') not in caplog.record_tuples\n        assert ('Command', INFO, None) not in caplog.record_tuples\n        for line in err.splitlines():\n            assert ('Command', WARNING, line) in caplog.record_tuples\n        assert ('Command', WARNING, '') not in caplog.record_tuples\n        assert ('Command', WARNING, None) not in caplog.record_tuples\n    def test_execute_check_failed_invocation(self, popen,\n                                             pipe_processor_loop,\n                                             caplog):\n        command = 'command'\n        ret = 1\n        out = 'out'\n        err = 'err'\n        pipe = _mock_pipe(popen, pipe_processor_loop, ret, out, err)\n        cmd = command_wrappers.Command(command, check=True)\n        with pytest.raises(command_wrappers.CommandFailedException) as excinfo:\n            cmd.execute()\n        assert excinfo.value.args[0]['ret'] == ret\n        assert excinfo.value.args[0]['out'] is None\n        assert excinfo.value.args[0]['err'] is None\n        popen.assert_called_with(\n            [command], shell=False, env=None,\n            stdout=PIPE, stderr=PIPE, stdin=PIPE,\n            preexec_fn=mock.ANY, close_fds=True\n        )\n        assert not pipe.stdin.write.called\n        pipe.stdin.close.assert_called_once_with()\n        assert cmd.ret == ret\n        assert cmd.out is None\n        assert cmd.err is None\n        assert ('Command', INFO, out) in caplog.record_tuples\n        assert ('Command', WARNING, err) in caplog.record_tuples\n    def test_handlers_multiline(self, popen, pipe_processor_loop, caplog):\n        command = 'command'\n        ret = 0\n        out = 'line1\\nline2\\n'\n        err = 'err1\\nerr2'  # no final newline here\n        stdin = 'in'\n        pipe = _mock_pipe(popen, pipe_processor_loop, ret, out, err)\n        out_list = []\n        err_list = []\n        with mock.patch('os.environ', new={'TEST0': 'VAL0'}):\n            cmd = command_wrappers.Command(command,\n                                           env_append={'TEST1': 'VAL1',\n                                                       'TEST2': 'VAL2'},\n                                           out_handler=out_list.append,\n                                           err_handler=err_list.append)\n            result = cmd.execute(stdin=stdin)\n        popen.assert_called_with(\n            [command], shell=False,\n            env={'TEST0': 'VAL0', 'TEST1': 'VAL1', 'TEST2': 'VAL2'},\n            stdout=PIPE, stderr=PIPE, stdin=PIPE,\n            preexec_fn=mock.ANY, close_fds=True\n        )\n        pipe.stdin.write.assert_called_with(stdin)\n        pipe.stdin.close.assert_called_once_with()\n        assert result == ret\n        assert cmd.ret == ret\n        assert cmd.out is None\n        assert cmd.err is None\n        assert '\\n'.join(out_list) == out\n        assert '\\n'.join(err_list) == err\n    def test_execute_handlers(self, popen, pipe_processor_loop, caplog):\n        command = 'command'\n        ret = 0\n        out = 'out'\n        err = 'err'\n        stdin = 'in'\n        pipe = _mock_pipe(popen, pipe_processor_loop, ret, out, err)\n        with mock.patch('os.environ', new={'TEST0': 'VAL0'}):\n            cmd = command_wrappers.Command(command,\n                                           env_append={'TEST1': 'VAL1',\n                                                       'TEST2': 'VAL2'})\n            result = cmd.execute(\n                stdin=stdin,\n                out_handler=cmd.make_logging_handler(INFO, 'out: '),\n                err_handler=cmd.make_logging_handler(WARNING, 'err: '),\n            )\n        popen.assert_called_with(\n            [command], shell=False,\n            env={'TEST0': 'VAL0', 'TEST1': 'VAL1', 'TEST2': 'VAL2'},\n            stdout=PIPE, stderr=PIPE, stdin=PIPE,\n            preexec_fn=mock.ANY, close_fds=True\n        )\n        pipe.stdin.write.assert_called_with(stdin)\n        pipe.stdin.close.assert_called_once_with()\n        assert result == ret\n        assert cmd.ret == ret\n        assert cmd.out is None\n        assert cmd.err is None\n        assert ('Command', INFO, 'out: ' + out) in caplog.record_tuples\n        assert ('Command', WARNING, 'err: ' + err) in caplog.record_tuples\n# noinspection PyMethodMayBeStatic\nclass TestCommandPipeProcessorLoop(object):\n    @mock.patch('barman.command_wrappers.select.select')\n    @mock.patch('barman.command_wrappers.os.read')\n    def test_ppl(self, read_mock, select_mock):\n        # Simulate the two files\n        stdout = mock.Mock(name='pipe.stdout')\n        stdout.fileno.return_value = 65\n        stderr = mock.Mock(name='pipe.stderr')\n        stderr.fileno.return_value = 66\n        # Recipients for results\n        out_list = []\n        err_list = []\n        # StreamLineProcessors\n        out_proc = StreamLineProcessor(stdout, out_list.append)\n        err_proc = StreamLineProcessor(stderr, err_list.append)\n        # The select call always returns all the streams\n        select_mock.side_effect = [\n            [[out_proc, err_proc], [], []],\n            select.error(errno.EINTR),  # Test interrupted system call\n            [[out_proc, err_proc], [], []],\n            [[out_proc, err_proc], [], []],\n        ]\n        # The read calls return out and err interleaved\n        # Lines are split in various ways, to test all the code paths\n        read_mock.side_effect = ['line1\\nl'.encode('utf-8'),\n                                 'err'.encode('utf-8'),\n                                 'ine2'.encode('utf-8'),\n                                 '1\\nerr2\\n'.encode('utf-8'),\n                                 '', '',\n                                 Exception]  # Make sure it terminates\n        command_wrappers.Command.pipe_processor_loop([out_proc, err_proc])\n        # Check the calls order and the output\n        assert read_mock.mock_calls == [\n            mock.call(65, 4096),\n            mock.call(66, 4096),\n            mock.call(65, 4096),\n            mock.call(66, 4096),\n            mock.call(65, 4096),\n            mock.call(66, 4096),\n        ]\n        assert out_list == ['line1', 'line2']\n        assert err_list == ['err1', 'err2', '']\n    @mock.patch('barman.command_wrappers.select.select')\n    def test_ppl_select_failure(self, select_mock):\n        # Test if select errors are passed through\n        select_mock.side_effect = select.error('not good')\n        with pytest.raises(select.error):\n            command_wrappers.Command.pipe_processor_loop([None])\n# noinspection PyMethodMayBeStatic\n@mock.patch('barman.command_wrappers.Command.pipe_processor_loop')\n@mock.patch('barman.command_wrappers.subprocess.Popen')\nclass TestRsync(object):\n    def test_simple_invocation(self, popen, pipe_processor_loop):\n        ret = 0\n        out = 'out'\n        err = 'err'\n        pipe = _mock_pipe(popen, pipe_processor_loop, ret, out, err)\n        cmd = command_wrappers.Rsync()\n        result = cmd('src', 'dst')\n        popen.assert_called_with(\n            ['rsync', 'src', 'dst'], shell=False, env=None,\n            stdout=PIPE, stderr=PIPE, stdin=PIPE,\n            preexec_fn=mock.ANY, close_fds=True\n        )\n        assert not pipe.stdin.write.called\n        pipe.stdin.close.assert_called_once_with()\n        assert result == ret\n        assert cmd.ret == ret\n        assert cmd.out == out\n        assert cmd.err == err\n    def test_args_invocation(self, popen, pipe_processor_loop):\n        ret = 0\n        out = 'out'\n        err = 'err'\n        pipe = _mock_pipe(popen, pipe_processor_loop, ret, out, err)\n        cmd = command_wrappers.Rsync(args=['a', 'b'])\n        result = cmd('src', 'dst')\n        popen.assert_called_with(\n            ['rsync', 'a', 'b', 'src', 'dst'], shell=False, env=None,\n            stdout=PIPE, stderr=PIPE, stdin=PIPE,\n            preexec_fn=mock.ANY, close_fds=True\n        )\n        assert not pipe.stdin.write.called\n        pipe.stdin.close.assert_called_once_with()\n        assert result == ret\n        assert cmd.ret == ret\n        assert cmd.out == out\n        assert cmd.err == err\n    @mock.patch(\"barman.utils.which\")\n    def test_custom_ssh_invocation(self, mock_which,\n                                   popen, pipe_processor_loop):\n        ret = 0\n        out = 'out'\n        err = 'err'\n        pipe = _mock_pipe(popen, pipe_processor_loop, ret, out, err)\n        mock_which.return_value = True\n        cmd = command_wrappers.Rsync('/custom/rsync', ssh='/custom/ssh',\n                                     ssh_options=['-c', 'arcfour'])\n        result = cmd('src', 'dst')\n        mock_which.assert_called_with('/custom/rsync', None)\n        popen.assert_called_with(\n            ['/custom/rsync', '-e', \"/custom/ssh '-c' 'arcfour'\",\n                'src', 'dst'],\n            shell=False, env=None,\n            stdout=PIPE, stderr=PIPE, stdin=PIPE,\n            preexec_fn=mock.ANY, close_fds=True\n        )\n        assert not pipe.stdin.write.called\n        pipe.stdin.close.assert_called_once_with()\n        assert result == ret\n        assert cmd.ret == ret\n        assert cmd.out == out\n        assert cmd.err == err\n    def test_rsync_build_failure(self, popen, pipe_processor_loop):\n        \"\"\"\n        Simple test that checks if a CommandFailedException is raised\n        when Rsync object is build with an invalid path or rsync\n        is not in system path\n        \"\"\"\n        # Pass an invalid path to Rsync class constructor.\n        # Expect a CommandFailedException\n        with pytest.raises(command_wrappers.CommandFailedException):\n            command_wrappers.Rsync('/invalid/path/rsync')\n        # Force the which method to return false, simulating rsync command not\n        # present in system PATH. Expect a CommandFailedExceptiomn\n        with mock.patch(\"barman.utils.which\") as mock_which:\n            mock_which.return_value = False\n            with pytest.raises(command_wrappers.CommandFailedException):\n                command_wrappers.Rsync(ssh_options=['-c', 'arcfour'])\n    def test_protect_ssh_invocation(self, popen, pipe_processor_loop):\n        ret = 0\n        out = 'out'\n        err = 'err'\n        pipe = _mock_pipe(popen, pipe_processor_loop, ret, out, err)\n        with mock.patch('os.environ.copy') as which_mock:\n            which_mock.return_value = {}\n            cmd = command_wrappers.Rsync(exclude_and_protect=['foo', 'bar'])\n            result = cmd('src', 'dst')\n        popen.assert_called_with(\n            ['rsync',\n             '--exclude=foo', '--filter=P_foo',\n             '--exclude=bar', '--filter=P_bar',\n             'src', 'dst'],\n            shell=False, env=mock.ANY,\n            stdout=PIPE, stderr=PIPE, stdin=PIPE,\n            preexec_fn=mock.ANY, close_fds=True\n        )\n        assert not pipe.stdin.write.called\n        pipe.stdin.close.assert_called_once_with()\n        assert result == ret\n        assert cmd.ret == ret\n        assert cmd.out == out\n        assert cmd.err == err\n    def test_bwlimit_ssh_invocation(self, popen, pipe_processor_loop):\n        ret = 0\n        out = 'out'\n        err = 'err'\n        pipe = _mock_pipe(popen, pipe_processor_loop, ret, out, err)\n        cmd = command_wrappers.Rsync(bwlimit=101)\n        result = cmd('src', 'dst')\n        popen.assert_called_with(\n            ['rsync', '--bwlimit=101', 'src', 'dst'],\n            shell=False, env=None,\n            stdout=PIPE, stderr=PIPE, stdin=PIPE,\n            preexec_fn=mock.ANY, close_fds=True\n        )\n        assert not pipe.stdin.write.called\n        pipe.stdin.close.assert_called_once_with()\n        assert result == ret\n        assert cmd.ret == ret\n        assert cmd.out == out\n        assert cmd.err == err\n    def test_from_file_list_ssh_invocation(self, popen, pipe_processor_loop):\n        ret = 0\n        out = 'out'\n        err = 'err'\n        pipe = _mock_pipe(popen, pipe_processor_loop, ret, out, err)\n        cmd = command_wrappers.Rsync()\n        result = cmd.from_file_list(['a', 'b', 'c'], 'src', 'dst')\n        popen.assert_called_with(\n            ['rsync', '--files-from=-', 'src', 'dst'],\n            shell=False, env=None,\n            stdout=PIPE, stderr=PIPE, stdin=PIPE,\n            preexec_fn=mock.ANY, close_fds=True\n        )\n        pipe.stdin.write.assert_called_with('a\\nb\\nc'.encode('UTF-8'))\n        pipe.stdin.close.assert_called_once_with()\n        assert result == ret\n        assert cmd.ret == ret\n        assert cmd.out == out\n        assert cmd.err == err\n    def test_invocation_list_file(self, popen, pipe_processor_loop):\n        \"\"\"\n        Unit test for dateutil package in list_file\n        This test cover all list_file's code with correct parameters\n        :param tmpdir: temporary folder\n        :param popen: mock popen\n        \"\"\"\n        # variables to be tested\n        ret = 0\n        out = 'drwxrwxrwt       69632 2015/02/09 15:01:00 tmp\\n' \\\n              'drwxrwxrwt       69612 2015/02/19 15:01:22 tmp2'\n        err = 'err'\n        # created mock pipe\n        pipe = _mock_pipe(popen, pipe_processor_loop, ret, out, err)\n        # created rsync and launched list_files\n        cmd = command_wrappers.Rsync()\n        return_values = list(cmd.list_files('some/path'))\n        # returned list must contain two elements\n        assert len(return_values) == 2\n        # assert call\n        popen.assert_called_with(\n            ['rsync', '--no-human-readable', '--list-only', '-r', 'some/path'],\n            shell=False, env=None,\n            stdout=PIPE, stderr=PIPE, stdin=PIPE,\n            preexec_fn=mock.ANY, close_fds=True\n        )\n        # Rsync pipe must be called with no input\n        assert not pipe.stdin.write.called\n        pipe.stdin.close.assert_called_once_with()\n        # assert tmp and tmp2 in test_list\n        assert return_values[0] == cmd.FileItem(\n            'drwxrwxrwt',\n            69632,\n            datetime(year=2015, month=2, day=9,\n                     hour=15, minute=1, second=0,\n                     tzinfo=dateutil.tz.tzlocal()),\n            'tmp')\n        assert return_values[1] == cmd.FileItem(\n            'drwxrwxrwt',\n            69612,\n            datetime(year=2015, month=2, day=19,\n                     hour=15, minute=1, second=22,\n                     tzinfo=dateutil.tz.tzlocal()),\n            'tmp2')\n# noinspection PyMethodMayBeStatic\n@mock.patch('barman.command_wrappers.Command.pipe_processor_loop')\n@mock.patch('barman.command_wrappers.subprocess.Popen')\nclass TestRsyncPgdata(object):\n    def test_simple_invocation(self, popen, pipe_processor_loop):\n        ret = 0\n        out = 'out'\n        err = 'err'\n        pipe = _mock_pipe(popen, pipe_processor_loop, ret, out, err)\n        cmd = command_wrappers.RsyncPgData()\n        result = cmd('src', 'dst')\n        popen.assert_called_with(\n            [\n", "outputs": ["                'rsync', '-rLKpts', '--delete-excluded', '--inplace',"], "input_length": 4288, "output_length": 16, "length": 4304, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "ac91e811483fa73e9409825f621e238eb29303b4522313c5ab419371874381a9"}
{"input": "", "context": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n## This program is free software; you can redistribute it and/or\n## modify it under the terms of the GNU General Public License\n## version 2 as published by the Free Software Foundation.\n##\n## This program is distributed in the hope that it will be useful,\n## but WITHOUT ANY WARRANTY; without even the implied warranty of\n## MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n## GNU General Public License for more details.\n##\n## You should have received a copy of the GNU General Public License\n## along with this program; if not, write to the Free Software\n## Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.\n##\n## author: Leonardo Tonetto\n__author__ = \"Leonardo Tonetto\"\n__copyright__ = \"Copyright 2016, Leonardo Tonetto\"\n__license__ = \"GPLv2\"\n__version__ = \"0.1\"\nimport sys\ntry:\n    import wigle\nexcept ImportError:\n    print >> sys.stderr, 'Please install wigle (eg. pip install wigle)'\n    sys.exit(1)\nimport argparse, pickle, time\ndef drange(start, stop, step):\n    \"\"\"\n    Float point implementation of range()\n    Based on (but not exactly):\n    http://stackoverflow.com/questions/477486/python-decimal-range-step-value\n    \"\"\"\n    ## few sanity checks first\n    if start < stop and step < 0:\n        raise RuntimeError('Wrong input variables, step should be > 0.')\n    if start > stop and step > 0:\n        raise RuntimeError('Wrong input variables, step should be < 0.')\n    r = start\n    while start < stop and r < stop:\n     \tyield r\n     \tr += step\n    while start > stop and r > stop:\n        yield r\n        r += step\nclass WigleDownloader:\n    \"\"\"\n    Downloads AP info from wigle.net\n    [HARDCODED] YEEEAH!\n    lat/lon_min/max : interval of the desired area.\n    lat_lon_div : number of divisions along each axis (used to double check).\n    div_map: initial num. of subdivisions inside each original division\n             this has to have the same number of columns/rows as the *_div arg.\n             Ref.: [0][0] is the upper left box\n             In case none is given, 1 is applied to all boxes\n    \"\"\"\n    ## Some constants\n    wigle_downloads_per_page = wigle.WIGLE_PAGESIZE\n    wigle_max_ap_per_query = 10000\n    ## These add up to 24h, time we would expect to have the quota renewed\n    wigle_timeout_backoff = [0.25*3600, ## 15 minutes\n                             0.25*3600,\n                             0.5*3600,\n                             1*3600,\n                             2*3600,\n                             4*3600,\n                             8*3600,\n                             8*3600]    ##  8 hours\n    file_default_remain = './coord.remain'\n    \n    def __init__( self, user, password, coordfile, outpath ):\n        try:\n            ## Wigle, wigle, wigle :-)\n            self.wigle = wigle.Wigle( user, password )\n        except wigle.WigleAuthenticationError as wae:\n            print >> sys.stderr, 'Authentication error for {1}.'.format(user)\n            print >> sys.stderr, wae.message\n            sys.exit(-1)\n        except wigle.WigleError as werr:\n            print >> sys.stderr, werr.message\n            sys.exit(-2)\n        self.outpath = outpath\n        self.coordfile = coordfile\n        ## This is for the city of Munich-DE\n        ## TODO: replace this with geocoding\n        self.latmin = 47.95\n        self.latmax = 48.43\n        self.lonmin = 11.00\n        self.lonmax = 12.15\n        self.latdiv = 6\n        self.londiv = 10\n        ## For the lazy: use this one\n        ## Do not modify this lazy map after this point since rows will be the same object...\n        #self.div_map = [[1]*self.londiv]*self.latdiv\n        ## Or you can do it like that\n        self.div_map = [[ 2, 2, 2, 2, 2, 2, 8, 2, 2, 2],\n                        [ 2, 2, 2, 2, 4, 3, 2, 5, 2, 2],\n                        [ 2, 4, 5, 4, 4, 5, 2, 4, 2, 2],\n                        [ 2, 4, 4, 8,18, 8, 8, 6, 2, 2],\n                        [ 2, 2, 3, 4,16, 8, 4, 2, 2, 2],\n                        [ 2, 2, 4, 4, 4, 4, 2, 2, 2, 2]]\n        self.INTERVALS = []\n        self.REMAINING_INTERVALS = []\n    def run(self):\n        \"\"\"\n        Just so that it does not look so ugly\n        \"\"\"\n        ## We either call compute_intervals() or parse_coordfile()\n        if self.coordfile:\n            self.parse_coordfile(self.coordfile)\n        else:\n            self.compute_intervals()\n        self.REMAINING_INTERVALS = self.INTERVALS[:]\n        self.REMAINING_INTERVALS.reverse()\n        ## Now we (continue) download(ing)\n        self.download()\n    def download(self):\n        \"\"\"\n        Download whatever is inside self.INTERVALS using\n        wigle pythong API (not official apparently)\n        \"\"\"\n        def callback_newpage(since):\n            pass\n        def _download( lat1, lat2, lon1, lon2, backoff_idx=0 ):\n            \"\"\"\n            This one will be called recursively until the subdivision\n            is fully downloaded. In case it reaches 10k it breaks down\n            this subdivision into two parts by dividing the longitude\n            interval into two. Something like this:\n                         lat2\n                  -----------------\n                 |                 |              ^\n                 |                 |              | N\n            lon1 |                 | lon2\n                 |                 |\n                 |                 |\n                  -----------------\n                         lat1\n            Becomes:\n                         lat2\n                  -----------------\n                 |        |        |              ^\n                 |        |        |              | N\n            lon1 |        |        | lon2\n                 |        |lon1_5  |\n                 |        |        |\n                  -----------------\n                         lat1\n            \"\"\"\n            print >> sys.stdout, 'Downloading ({0},{1},{2},{3})'.format( lat1, lat2, lon1, lon2 )\n            try:\n                RESULTS = self.wigle.search( lat_range   = ( lat1, lat2 ),\n                                             long_range  = ( lon1, lon2 ),\n                                             on_new_page = callback_newpage,\n                                             max_results = WigleDownloader.wigle_max_ap_per_query )\n                # Need to double check this\n                if len(RESULTS) >= 9998:\n                    print >> sys.stderr, 'Subdividing {0} {1} {2} {3}'.format(lat1,lat2,lon1,lon2)\n                    ## Will break down longitude interval into two parts\n                    lon1_5 = (lon2-lon1)/2.0\n                    R1 = _download( lat1, lat2, lon1, lon1_5 )\n                    R2 = _download( lat1, lat2, lon1_5, lon2 )\n                    RESULTS = R1.copy()\n                    RESULTS.update(R2)\n            except wigle.WigleRatelimitExceeded as wrle:\n                wait_s = WigleDownloader.wigle_timeout_backoff[backoff_idx]\n                print >> sys.stderr, 'Already got WigleRatelimitExceeded.'\n                print >> sys.stderr, 'Sleeping for {0} seconds before trying again.'.format(wait_s)\n                time.sleep(wait_s)\n                ## We may enter an infinite loop here...\n                ## TODO: solve it (for now check the stdout for problems)\n                return _download(lat1, lat2, lon1, lon2,\n                                 backoff_idx=(backoff_idx+1)%len(WigleDownloader.wigle_timeout_backoff))\n            except wigle.WigleError as we:\n                print >> sys.stderr, we\n                print >> sys.stderr, 'Something wrong with Wigle, stopping..'\n                raise\n            except KeyboardInterrupt:\n                print >> sys.stderr, 'Stopping the script.'\n                sys.exit(0)\n            except:\n                print >> sys.stderr, 'This looks like a bug.', sys.exc_info()[0]\n                return []\n            else:\n                sucess_string = 'Sucess downloading ({0},{1},{2},{3}) with {4} APs'\n                print >> sys.stdout, sucess_string.format( lat1, lat2, lon1, lon2, len(RESULTS) )\n                return RESULTS\n                \n        try:\n            ##\n            for interval in self.INTERVALS:\n                assert len(interval) == 4, 'Something wrong generating self.INTERVALS.'\n                lat1,lat2,lon1,lon2 = interval\n                AP_SUBDIVISION = _download( lat1, lat2, lon1, lon2 )\n                ## Write this out using pickle\n                ## TODO: write out as sqlite file\n                pickle_file = '{0}/{1}_{2}_{3}_{4}.p'.format( self.outpath, lat1, lat2, lon1, lon2 )\n                pickle.dump(AP_SUBDIVISION, open( pickle_file, \"wb\" ))\n                \n                ## Note: this was .reverse()'ed before\n                ## Pop'ing from the end of the list is much quicker\n                self.REMAINING_INTERVALS.pop()\n                \n                ## Write out coord.remain\n                with open( WigleDownloader.file_default_remain, 'wb' ) as coord_remain_file:\n                    for interval in self.REMAINING_INTERVALS:\n                        print >> coord_remain_file, ','.join(map(str,interval))\n        except KeyboardInterrupt:\n            print >> sys.stderr, 'Stopping the script.'\n            sys.exit(0)\n        except:\n            print >> sys.stderr, 'This looks like a bug.', sys.exc_info()[0]\n            sys.exit(-3)\n            \n    def compute_intervals(self):\n        \"\"\"\n        Returns a list with tuples containing:\n            [(box_lat_min,box_lat_max,box_lon_min,box_lon_max),...]\n        Since [0][0] is the upper left corner, lon grows positively\n        but lat grows negatively.\n        \"\"\"\n        if len(self.div_map) != self.latdiv or len(self.div_map[0]) != self.londiv:\n            raise RuntimeError('Map dimensions not correct!')\n        ## Compute the size of each initial box (in degrees).\n        lat_step = -(self.latmax - self.latmin) / self.latdiv\n        lon_step =  (self.lonmax - self.lonmin) / self.londiv\n        ## Compute the intervals.\n        initial_lat = self.latmax\n        initial_lon = self.lonmin\n        for row in self.div_map:\n            initial_lon = self.lonmin\n            for subdivisions in row:\n                lat_sub_step = lat_step / float(subdivisions)\n                lon_sub_step = lon_step / float(subdivisions)\n                ## min for each subdivision, for max we just add sub_step to it.\n                lats = list(drange(initial_lat,initial_lat+lat_step,lat_sub_step))\n                lons = list(drange(initial_lon,initial_lon+lon_step,lon_sub_step))\n                self.INTERVALS.extend([( lat, lat+lat_sub_step,\n                                         lon, lon+lon_sub_step ) for lat,lon in zip( lats, lons )])\n                initial_lon += lon_step\n            initial_lat += lat_step\n    def parse_coordfile( self, coordfile ):\n        \"\"\"\n        Parses the coord.remain file with the following format:\n        lat1,lat2,lon1,lon2\n        \"\"\"\n        print >> sys.stdout, 'Parsing coord.remain file.'\n        with open(coordfile) as f:\n            line = f.readline()\n            while line:\n                COORDS = line.strip().split(',')\n                assert len(COORDS) == 4, 'Something is wrong with coord.remain file.'\n                self.INTERVALS.append(tuple(COORDS))\n                line = f.readline()\n        print >> sys.stdout, 'Found {0} subdivisions to download'.format(len(self.INTERVALS))\n        \nif __name__ == '__main__':\n    parser = argparse.ArgumentParser(description='Wigle Downloader arguments')\n    parser.add_argument(\n        '-u', '--user', help='Wigle username', required=True )\n    parser.add_argument(\n        '-p', '--password', help='Wigle password', required=True )\n    parser.add_argument(\n        '--coordfile', help='coord.remain file path', required=False, default=None )\n    parser.add_argument(\n        '-o', '--outpath', help='Path to store pickle files.')\n", "outputs": ["    args = parser.parse_args()"], "input_length": 2050, "output_length": 5, "length": 2055, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "d5c205487cd5b7a76b9f7de6ba052231258d70518330ad087389dba3cb520805"}
{"input": "", "context": "#!/usr/bin/python\nimport argparse, sys, time, logging\nlogging.getLogger(\"scapy.runtime\").setLevel(logging.ERROR)\nfrom scapy.all import *\n\"\"\"\nAuthor: mtask@github.com\nProgram: pydump.py\nDescription: Simple packet analyzer.\n\"\"\"\n\"\"\"\nPydump is made also python3 in mind, but haven't been tested how scapy's python3 version works.\n\"\"\"\nclass Pydump(object):\n    def __init__(self):\n        self.blk = '\\033[0m' # Black - Regular\n        self.warn = '\\033[93m' # yellow\n        self.grn = '\\033[92m' # Green\n        self.fatal = '\\033[91m' #red\n        self.packetNumber = 0\n    def arguments(self,custom_arg=None):\n        self.parser = argparse.ArgumentParser(description=\"Packet capturing tool\", prog=\"pydump.py\")\n        self.parser.add_argument(\"-i\", \"--iface\", help=\"Capturing interface\")\n        self.parser.add_argument(\"-n\", \"--num\", help=\"Number of packets to capture\")\n        self.parser.add_argument(\"-r\", \"--read\", help=\"Read .pcap file\")\n        self.parser.add_argument(\"-f\", \"--filter\", help=\"Filter packets. Use quotes(\\\"\\\")\")\n        self.parser.add_argument(\"-w\", \"--write\", help=\"Write capture to file\")\n        self.parser.add_argument(\"-I\", \"--inspect\", action='store_true', help=\"Inspect packets\")\n        \n        try:\n            if custom_arg:\n                self.args = self.parser.parse_args(custom_arg)\n            else:\n                self.args = self.parser.parse_args()\n            if not self.args.iface and not self.args.read:\n                self.parser.print_usage()\n            else:\n                return self.args\n        except SystemExit:\n            if custom_arg:\n                return\n            else:\n                sys.exit(1)\n            \n    def output(self, packet):\n        \"\"\"\n        Standard sniffing output\n        \"\"\"\n        self.packetNumber += 1\n        time.sleep(1)\n        return str(self.packetNumber) + \": \" + packet.summary()\n    def sniffer(self,iface, filter_=None, num=None):\n        ######################################\n        #Sniffing with scapy.                #\n        #sniffer() returns captured packets, #\n        #or False if none captured.          #\n        ######################################\n        self.fil = filter_\n        self.iface = iface\n        self.num = num\n        self.pckts = None\n        self.statement = self.output\n        ###Check if --num/--filter used and start capturing###\n        if self.num:\n            try:\n                print(\"Capturing \"+ self.num + \" packets from \" + self.iface)\n                if self.fil:\n                    self.pckts = sniff(iface=self.iface,filter=self.fil, count=int(num), prn = self.statement)\n                else:\n                    self.pckts = sniff(iface=self.iface,  count=int(num), prn = self.statement)\n            except NameError:\n                print(self.fatal+\"Check your filtering argument\"+self.blk)\n            except socket.error as se:\n                print(self.fatal+str(se)+\": \"+self.iface+self.blk)\n        elif not self.num:\n            try:\n               print(\"Capturing traffic from \"+self.iface)\n               if self.fil:\n                   self.pckts = sniff(iface=self.iface, filter=self.fil, prn = self.statement)\n               else:\n                   self.pckts = sniff(iface=self.iface, prn = self.statement)\n            except NameError:\n                print(self.fatal+\"Check your filtering argument\"+self.blk)\n            except socket.error as se:\n                print(self.fatal+str(se)+\": \"+self.iface+self.blk)\n        if self.pckts:\n            return self.pckts\n        else:\n            return False\n    def main(self, customArgs=None):\n        ###Checking arguments###\n        if customArgs:\n           self.arg = self.arguments(custom_arg=customArgs)\n        else:\n           self.arg = self.arguments()\n        if not self.arg:\n            return\n        self.iface_ = self.arg.iface\n        if self.arg.filter:\n            self.fil_ = self.arg.filter\n        else:\n            self.fil_ = None\n        if self.arg.num:\n            self.num_ = self.arg.num\n        else:\n            self.num_ = None\n        \n        ###If --read###\n        if self.arg.read:\n            self.pcapfile = self.arg.read\n            try:\n                self.rdpkt=rdpcap(self.pcapfile)\n                self.rdpkt.nsummary()\n            except Exception as e:\n                sys.stderr.write(self.fatal+str(e)+self.blk)\n                print(\"\")\n                return\n        ###Start packet sniffing###\n        self.cap = self.sniffer(self.iface_, filter_=self.fil_, num=self.num_)\n        ###Write captured packets to file if --write###\n        if self.cap:\n            if self.arg.write:\n                self.file_ = self.arg.write\n                if \".pcap\" in self.file_:\n                    wrpcap(self.file_, self.cap)\n                else:\n                    self.file_ = self.file_+\".pcap\"\n                    wrpcap(self.file_,  self.cap)\n        ###If inspection mode selected###\n            if self.arg.inspect:\n                self.inspect = Inspect()\n                os.system('clear')\n                print(self.grn+\"[*] Starting inspection mode..\"+self.blk)\n                time.sleep(2)\n                self.inspect.prompt(self.cap)\n        else:\n            print(\"\")\n            print(self.warn+\"[!] No packets were captured\"+self.blk)\nclass Inspect(object):\n    def __init__(self):\n        self.blk = '\\033[0m' # Black - Regular\n        self.warn = '\\033[93m' # yellow\n        self.grn = '\\033[92m' # Green\n        self.fatal = '\\033[91m' #red\n    def get_input(self, prompt):\n        #################################################### #\n        #Get user input maintaining the python compatibility #\n        #with earlier and newer versions.                    #\n        ######################################################\n        if sys.hexversion > 0x03000000:\n            return input(prompt)\n        else:\n            return raw_input(prompt)\n    def print_usage(self):\n        os.system('clear')\n        print('--------------------------')\n        print(self.grn+'Inspection mode'+self.blk)\n        print('--------------------------')\n        print(self.grn+'[*] Captured traffic can be viewed with \"list\" command.')\n        print('[*] Give packet number to inspect packet.')\n        print('[*] Commands: \"help\", \"list\", \"exit\"')\n        print(self.warn+'Press enter to continue'+self.blk)\n        self.get_input('...')\n        return True\n    def print_packets(self,packets):\n        #Print list of captured packets\n        self.packet_number = 1\n        for self.packet in packets:\n            print(str(self.packet_number)+\": \" + self.packet.summary())\n            self.packet_number += 1\n    def prompt(self, cap):\n        self.cap = cap\n        self.option = None\n        self.opts = ['list', 'help', 'exit']\n        self.print_usage()\n        os.system('clear')\n        print(self.grn+'[*] Listing packages'+self.blk)\n        time.sleep(1)\n        self.print_packets(self.cap)\n        while True:\n            try:\n                print(self.grn+\"- - - - - - - - - - - - - - - - - - - - - \")\n                print(\"Give packet number to inspect or try \\\"help\\\":\")\n                print(\"- - - - - - - - - - - - - - - - - - - - - \"+self.blk)\n                ###Get user's option###\n                self.choice = self.get_input(\">>>\")\n                try:\n                    if self.choice in self.opts:\n                        if self.choice.lower() == 'list':\n                            self.parser(self.choice, cap=self.cap)\n                            continue\n                        elif self.choice.lower() == 'exit':\n                            return\n                        else:\n                            self.parser(self.choice)\n                            continue\n                    ###Show selected packet###\n", "outputs": ["                    self.choice = int(self.choice) - 1"], "input_length": 1449, "output_length": 8, "length": 1457, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "c2d2ca3cc0041e73529c55e498ca29d005ff874cf2e72bdc46dda1d0346cfa00"}
{"input": "", "context": "#! /usr/bin/env python\n# Last Change: Sun Dec 14 07:00 PM 2008 J\n\"\"\"Test for the sndfile class.\"\"\"\nfrom os.path import join, dirname\nimport os\nimport sys\nfrom numpy.testing import TestCase, assert_array_equal, dec\nimport numpy as np\nfrom audiolab import Sndfile, Format, available_encodings, available_file_formats\nfrom testcommon import open_tmp_file, close_tmp_file, TEST_DATA_DIR\n_DTYPE_TO_ENC = {np.float64 : 'float64', np.float32: 'float32', \n                 np.int32: 'pcm32', np.int16: 'pcm16'}\n# XXX: there is a lot to refactor here\nclass TestSndfile(TestCase):\n    def test_basic_io(self):\n        \"\"\" Check open, close and basic read/write\"\"\"\n        # dirty !\n        ofilename = join(TEST_DATA_DIR, 'test.wav')\n        rfd, fd, cfilename = open_tmp_file('pysndfiletest.wav')\n        try:\n            nbuff = 22050\n            # Open the test file for reading\n            a = Sndfile(ofilename, 'r')\n            nframes = a.nframes\n            # Open the copy file for writing\n            format = Format('wav', 'pcm16')\n            b = Sndfile(fd, 'w', format, a.channels, a.samplerate)\n            # Copy the data\n            for i in range(nframes / nbuff):\n                tmpa    = a.read_frames(nbuff)\n                assert tmpa.dtype == np.float\n                b.write_frames(tmpa)\n            nrem    = nframes % nbuff\n            tmpa    = a.read_frames(nrem)\n            assert tmpa.dtype == np.float\n            b.write_frames(tmpa)\n            a.close()\n            b.close()\n        finally:\n            close_tmp_file(rfd, cfilename)\n    @dec.skipif(sys.platform=='win32', \n                \"Not testing opening by fd because does not work on win32\")\n    def test_basic_io_fd(self):\n        \"\"\" Check open from fd works\"\"\"\n        ofilename = join(TEST_DATA_DIR, 'test.wav')\n        fd = os.open(ofilename, os.O_RDONLY)\n        hdl = Sndfile(fd, 'r')\n        hdl.close()\n    def test_raw(self):\n        rawname = join(TEST_DATA_DIR, 'test.raw')\n        format = Format('raw', 'pcm16', 'little')\n        a = Sndfile(rawname, 'r', format, 1, 11025)\n        assert a.nframes == 11290\n        a.close()\n    def test_float64(self):\n        \"\"\"Check float64 write/read works\"\"\"\n        self._test_read_write(np.float64)\n    def test_float32(self):\n        \"\"\"Check float32 write/read works\"\"\"\n        self._test_read_write(np.float32)\n    def test_int32(self):\n        \"\"\"Check 32 bits pcm write/read works\"\"\"\n        self._test_read_write(np.int32)\n    def test_int16(self):\n        \"\"\"Check 16 bits pcm write/read works\"\"\"\n        self._test_read_write(np.int16)\n    def _test_read_write(self, dtype):\n        # dirty !\n        ofilename = join(TEST_DATA_DIR, 'test.wav')\n        rfd, fd, cfilename = open_tmp_file('pysndfiletest.wav')\n        try:\n            nbuff = 22050\n            # Open the test file for reading\n            a = Sndfile(ofilename, 'r')\n            nframes = a.nframes\n            # Open the copy file for writing\n            format = Format('wav', _DTYPE_TO_ENC[dtype])\n            b = Sndfile(fd, 'w', format, a.channels, a.samplerate)\n            # Copy the data in the wav file\n            for i in range(nframes / nbuff):\n                tmpa    = a.read_frames(nbuff, dtype=dtype)\n                assert tmpa.dtype == dtype\n                b.write_frames(tmpa)\n            nrem = nframes % nbuff\n            tmpa = a.read_frames(nrem)\n            b.write_frames(tmpa)\n            a.close()\n            b.close()\n            # Now, reopen both files in for reading, and check data are\n            # the same\n            a = Sndfile(ofilename, 'r')\n            b = Sndfile(cfilename, 'r')\n            for i in range(nframes / nbuff):\n                tmpa = a.read_frames(nbuff, dtype=dtype)\n                tmpb = b.read_frames(nbuff, dtype=dtype)\n                assert_array_equal(tmpa, tmpb)\n            a.close()\n            b.close()\n        finally:\n            close_tmp_file(rfd, cfilename)\n    #def test_supported_features(self):\n    #    for i in available_file_formats():\n    #        print \"Available encodings for format %s are : \" % i\n    #        for j in available_encodings(i):\n    #            print '\\t%s' % j\n    def test_short_io(self):\n        self._test_int_io(np.short)\n    def test_int32_io(self):\n        self._test_int_io(np.int32)\n    def _test_int_io(self, dt):\n        # TODO: check if neg or pos value is the highest in abs\n        rfd, fd, cfilename = open_tmp_file('pysndfiletest.wav')\n        try:\n            # Use almost full possible range possible for the given data-type\n            nb = 2 ** (8 * np.dtype(dt).itemsize - 3)\n            fs = 22050\n            nbuff = fs\n            a = np.random.random_integers(-nb, nb, nbuff)\n            a = a.astype(dt)\n            # Open the file for writing\n            format = Format('wav', _DTYPE_TO_ENC[dt])\n            b = Sndfile(fd, 'w', format, 1, fs)\n            b.write_frames(a)\n            b.close()\n            b = Sndfile(cfilename, 'r')\n            read_a  = b.read_frames(nbuff, dtype=dt)\n            b.close()\n            assert_array_equal(a, read_a)\n        finally:\n            close_tmp_file(rfd, cfilename)\n    def test_mismatch(self):\n        \"\"\"Check for bad arguments.\"\"\"\n        # This test open a file for writing, but with bad args (channels and\n        # nframes inverted)\n        rfd, fd, cfilename = open_tmp_file('pysndfiletest.wav')\n        try:\n            # Open the file for writing\n            format = Format('wav', 'pcm16')\n            try:\n                b = Sndfile(fd, 'w', format, channels=22000, samplerate=1)\n                raise AssertionError(\"Try to open a file with more than 256 \"\\\n                                     \"channels, this should not succeed !\")\n            except ValueError, e:\n                pass\n        finally:\n            close_tmp_file(rfd, cfilename)\n    def test_bigframes(self):\n        \"\"\" Try to seek really far.\"\"\"\n        rawname = join(TEST_DATA_DIR, 'test.wav')\n        a = Sndfile(rawname, 'r')\n        try:\n            try:\n                a.seek(2 ** 60)\n                raise Exception, \\\n                      \"Seek really succeded ! This should not happen\"\n            except IOError, e:\n                pass\n        finally:\n            a.close()\n    def test_float_frames(self):\n        \"\"\" Check nframes can be a float\"\"\"\n        rfd, fd, cfilename   = open_tmp_file('pysndfiletest.wav')\n        try:\n            # Open the file for writing\n            format = Format('wav', 'pcm16')\n            a = Sndfile(fd, 'rw', format, channels=1, samplerate=22050)\n            tmp = np.random.random_integers(-100, 100, 1000)\n            tmp = tmp.astype(np.short)\n            a.write_frames(tmp)\n            a.seek(0)\n            a.sync()\n            ctmp = a.read_frames(1e2, dtype=np.short)\n            a.close()\n        finally:\n            close_tmp_file(rfd, cfilename)\n    def test_nofile(self):\n        \"\"\" Check the failure when opening a non existing file.\"\"\"\n        try:\n            f = Sndfile(\"floupi.wav\", \"r\")\n            raise AssertionError(\"call to non existing file should not succeed\")\n        except IOError:\n            pass\n        except Exception, e:\n            raise AssertionError(\"opening non existing file should raise\" \\\n                                 \" a IOError exception, got %s instead\" %\n                                 e.__class__)\nclass TestSeek(TestCase):\n    def test_simple(self):\n        ofilename = join(TEST_DATA_DIR, 'test.wav')\n        # Open the test file for reading\n        a = Sndfile(ofilename, 'r')\n        nframes = a.nframes\n        buffsize = 1024\n        buffsize = min(nframes, buffsize)\n        # First, read some frames, go back, and compare buffers\n        buff = a.read_frames(buffsize)\n        a.seek(0)\n        buff2 = a.read_frames(buffsize)\n        assert_array_equal(buff, buff2)\n        a.close()\n        # Now, read some frames, go back, and compare buffers\n        # (check whence == 1 == SEEK_CUR)\n        a = Sndfile(ofilename, 'r')\n        a.read_frames(buffsize)\n        buff = a.read_frames(buffsize)\n        a.seek(-buffsize, 1)\n        buff2 = a.read_frames(buffsize)\n        assert_array_equal(buff, buff2)\n        a.close()\n        # Now, read some frames, go back, and compare buffers\n        # (check whence == 2 == SEEK_END)\n        a = Sndfile(ofilename, 'r')\n        buff = a.read_frames(nframes)\n        a.seek(-buffsize, 2)\n        buff2 = a.read_frames(buffsize)\n        assert_array_equal(buff[-buffsize:], buff2)\n    def test_rw(self):\n        \"\"\"Test read/write pointers for seek.\"\"\"\n        ofilename = join(TEST_DATA_DIR, 'test.wav')\n", "outputs": ["        rfd, fd, cfilename   = open_tmp_file('rwseektest.wav')"], "input_length": 1552, "output_length": 11, "length": 1563, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "ffd61501842c9197c1641830e1232a4a802c46e7b29f9cf3891120480a472f16"}
{"input": "", "context": "using System;\nusing System.Collections;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Reflection;\nusing System.Reflection.Emit;\nusing System.Runtime.CompilerServices;\nusing System.Runtime.InteropServices;\nusing System.Text;\nusing AutoJIT.Contrib;\nusing AutoJITRuntime.Exceptions;\nusing AutoJITRuntime.Variants;\nusing IndexOutOfRangeException = AutoJITRuntime.Exceptions.IndexOutOfRangeException;\nnamespace AutoJITRuntime.Services\n{\n    public class MarshalService\n    {\n        private readonly Dictionary<string, Type> _delegateStore = new Dictionary<string, Type>();\n        private readonly ModuleBuilder _dynamicMod;\n        private readonly Dictionary<string, UnmanagedType> _marshalAttributeMapping = new Dictionary<string, UnmanagedType> {\n            {\n                \"STR\", UnmanagedType.LPStr\n            }, {\n                \"WSTR\", UnmanagedType.LPWStr\n            }\n        };\n        private readonly Dictionary<string, Type> _structStore = new Dictionary<string, Type>();\n        private readonly Dictionary<string, Type> _typeMapping = new Dictionary<string, Type> {\n            {\n                \"NONE\", typeof (void)\n            }, {\n                \"BYTE\", typeof (byte)\n            }, {\n                \"BOOLEAN\", typeof (byte)\n            }, {\n                \"CHAR\", typeof (char)\n            }, {\n                \"WCHAR\", typeof (char)\n            }, {\n                \"SHORT\", typeof (Int16)\n            }, {\n                \"USHORT\", typeof (UInt16)\n            }, {\n                \"WORD\", typeof (UInt16)\n            }, {\n                \"INT\", typeof (Int32)\n            }, {\n                \"LONG\", typeof (Int32)\n            }, {\n                \"BOOL\", typeof (Int32)\n            }, {\n                \"UINT\", typeof (UInt32)\n            }, {\n                \"ULONG\", typeof (UInt32)\n            }, {\n                \"DWORD\", typeof (UInt32)\n            }, {\n                \"INT64\", typeof (Int64)\n            }, {\n                \"UINT64\", typeof (UInt64)\n            }, {\n                \"PTR\", typeof (IntPtr)\n            }, {\n                \"HWND\", typeof (IntPtr)\n            }, {\n                \"HANDLE\", typeof (IntPtr)\n            }, {\n                \"FLOAT\", typeof (Single)\n            }, {\n                \"DOUBLE\", typeof (double)\n            }, {\n                \"INT_PTR\", typeof (IntPtr)\n            }, {\n                \"LONG_PTR\", typeof (IntPtr)\n            }, {\n                \"LRESULT\", typeof (IntPtr)\n            }, {\n                \"LPARAM\", typeof (IntPtr)\n            }, {\n                \"UINT_PTR\", typeof (UIntPtr)\n            }, {\n                \"ULONG_PTR\", typeof (UIntPtr)\n            }, {\n                \"DWORD_PTR\", typeof (UIntPtr)\n            }, {\n                \"WPARAM\", typeof (UIntPtr)\n            }, {\n                \"WSTR\", typeof (StringBuilder)\n            }, {\n                \"STR\", typeof (StringBuilder)\n            }\n        };\n        public MarshalService() {\n            AssemblyBuilder assemblyBuilder = AppDomain.CurrentDomain.DefineDynamicAssembly( new AssemblyName( \"an\" ), AssemblyBuilderAccess.Run );\n            _dynamicMod = assemblyBuilder.DefineDynamicModule( \"MainModule\" );\n        }\n        [DllImport( \"kernel32.dll\", SetLastError = true )]\n        public static extern IntPtr LoadLibrary( string dllToLoad );\n        [DllImport( \"kernel32.dll\", SetLastError = true )]\n        public static extern IntPtr GetProcAddress( IntPtr hModule, string procedureName );\n        [DllImport( \"kernel32.dll\", SetLastError = true )]\n        public static extern bool FreeLibrary( IntPtr hModule );\n        [DllImport( \"user32.dll\" )]\n        [return: MarshalAs( UnmanagedType.Bool )]\n        public static extern bool IsWindow( IntPtr hWnd );\n        public Variant DllCall( Variant dll, string returnType, string function, Variant[] paramtypen ) {\n            Variant handle;\n            if ( dll.IsPtr ) {\n                handle = dll.GetIntPtr();\n            }\n            else {\n                handle = DllOpen( dll );\n                if ( !handle.IsPtr ) {\n                    throw new UnableToUseTheDllFileException( 1, null, string.Empty );\n                }\n            }\n            IntPtr procAddress = GetProcAddress( handle, function );\n            Variant toReturn = DllCallAddressInternal( returnType, procAddress, paramtypen );\n            if ( dll.IsPtr ) {\n                return toReturn;\n            }\n            DllClose( handle );\n            return toReturn;\n        }\n        public Variant DllCallAddress( Variant returntype, Variant address, Variant[] paramtypen ) {\n            if ( !address.IsPtr ) {\n                throw new AddressParameterIsNotAPointerException( 1, null, string.Empty );\n            }\n            IntPtr ptr = address.GetIntPtr();\n            string returnType = returntype.GetString();\n            return DllCallAddressInternal( returnType, ptr, paramtypen );\n        }\n        private Variant DllCallAddressInternal( string returnType, IntPtr ptr, Variant[] paramtypen ) {\n            if ( ptr == IntPtr.Zero ) {\n                throw new ProcAddressZeroException( 3, null, string.Empty );\n            }\n            List<MarshalInfo> parameterMarshalInfo = GetParameterInfo( paramtypen );\n            Type callingConvention = typeof (CallConvStdcall);\n            if ( returnType.Contains( \":\" ) ) {\n                string[] split = returnType.Split( ':' );\n                string customCallingConvention = split[1];\n                returnType = split[0];\n                callingConvention = GetCallingConvention( customCallingConvention );\n            }\n            MarshalInfo returnMarshalInfo = GetReturnTypeInfo( returnType );\n            Delegate @delegate = GetFunctionDelegate( returnMarshalInfo, parameterMarshalInfo, callingConvention, ptr );\n            object[] args = parameterMarshalInfo.Select( x => x.Parameter ).ToArray();\n            object result = @delegate.DynamicInvoke( args );\n            Variant[] toReturn = MapReturnValues( args, result );\n            return toReturn;\n        }\n        public Variant DllOpen( Variant dll ) {\n            try {\n                IntPtr library = LoadLibrary( dll.GetString() );\n                if ( library == IntPtr.Zero ) {\n                    int error = Marshal.GetLastWin32Error();\n                }\n                return library;\n            }\n            catch (Exception) {\n                return -1;\n            }\n        }\n        private static Variant[] MapReturnValues( object[] args, object result ) {\n            var toReturn = new Variant[args.Length+1];\n            toReturn[0] = Variant.Create( result );\n            Array.Copy( args.Select( Variant.Create ).ToArray(), 0, toReturn, 1, args.Length );\n            return toReturn;\n        }\n        private Delegate GetFunctionDelegate( MarshalInfo returnMarshalInfo, List<MarshalInfo> parameterMarshalInfo, Type callingConvention, IntPtr procAddress ) {\n            Type delegateType = CreateDelegate( returnMarshalInfo, parameterMarshalInfo, callingConvention );\n            Delegate @delegate;\n            try {\n                @delegate = Marshal.GetDelegateForFunctionPointer( procAddress, delegateType );\n            }\n            catch (Exception ex) {\n                throw new BadNumberOfParameterException( 4, null, string.Empty );\n            }\n            return @delegate;\n        }\n        private MarshalInfo GetReturnTypeInfo( string returnType ) {\n            MarshalInfo returnMarshalInfo;\n            try {\n                returnMarshalInfo = GetMarshalInfo( returnType, null );\n            }\n            catch (UnknowTypeNameException) {\n                throw new BadReturnTypeException( 2, null, string.Empty );\n            }\n            return returnMarshalInfo;\n        }\n        private List<MarshalInfo> GetParameterInfo( Variant[] paramtypen ) {\n            var parameterMarshalInfo = new List<MarshalInfo>();\n            for ( int i = 0; i < paramtypen.Length; i += 2 ) {\n                Variant typePart = paramtypen[i];\n                Variant value = paramtypen[i+1];\n                MarshalInfo marshalInfo;\n                try {\n                    marshalInfo = GetMarshalInfo( typePart, value );\n                }\n                catch (UnknowTypeNameException) {\n                    throw new BadParameterException( 5, null, string.Empty );\n                }\n                parameterMarshalInfo.Add( marshalInfo );\n            }\n            return parameterMarshalInfo;\n        }\n        private Type GetCallingConvention( string customCallingConvention ) {\n            switch (customCallingConvention.ToUpper()) {\n                case \"CDECL\":\n                    return typeof (CallConvCdecl);\n                case \"STDCALL\":\n                    return typeof (CallConvStdcall);\n                case \"FASTCALL\":\n                    return typeof (CallConvFastcall);\n                case \"THISCALL\":\n                    return typeof (CallConvThiscall);\n                case \"WINAPI\":\n                    return typeof (CallConvStdcall);\n                default:\n                    throw new UnknowCallConvException( customCallingConvention );\n            }\n        }\n        private Type CreateDelegate( MarshalInfo returntype, List<MarshalInfo> paramtypes, Type callingConvention ) {\n            string cacheKey = String.Format( \"Delegate_{0}{1}{2}\", returntype.Type, String.Join( String.Empty, paramtypes.Select( x => x.Type ) ), callingConvention );\n            if ( _delegateStore.ContainsKey( cacheKey ) ) {\n                return _delegateStore[cacheKey];\n            }\n            TypeBuilder tb = _dynamicMod.DefineType( String.Format( \"_{0}\", Guid.NewGuid().ToString( \"N\" ) ), TypeAttributes.Public|TypeAttributes.Sealed, typeof (MulticastDelegate) );\n            tb.DefineConstructor(\n                MethodAttributes.RTSpecialName|MethodAttributes.SpecialName|MethodAttributes.Public|MethodAttributes.HideBySig,\n                CallingConventions.Standard,\n                new[] {\n                    typeof (object),\n                    typeof (IntPtr)\n                } ).SetImplementationFlags( MethodImplAttributes.Runtime );\n            MethodBuilder inv = tb.DefineMethod(\n                \"Invoke\",\n                MethodAttributes.Public|MethodAttributes.Virtual|MethodAttributes.NewSlot|MethodAttributes.HideBySig,\n                CallingConventions.Standard,\n                returntype.Type,\n                null,\n                new[] {\n                    callingConvention\n                },\n                paramtypes.Select( x => x.Type ).ToArray(),\n                null,\n                null );\n            for ( int index = 0; index < paramtypes.Count; index++ ) {\n                MarshalInfo paramtype = paramtypes[index];\n                ParameterAttributes parameterAttributes = paramtype.IsRef\n                    ? ParameterAttributes.Out\n                    : ParameterAttributes.In;\n                if ( paramtype.Type == typeof (StringBuilder) ) {\n                    parameterAttributes |= ParameterAttributes.Out;\n                }\n                if ( typeof (IRuntimeStruct).IsAssignableFrom( paramtype.Type.GetElementType() ) ) {\n                    parameterAttributes |= ParameterAttributes.In;\n                }\n                ParameterBuilder parameterBuilder = inv.DefineParameter( index+1, parameterAttributes, null );\n                if ( paramtype.MarshalAttribute.HasValue ) {\n                    ConstructorInfo constructorInfo = typeof (MarshalAsAttribute).GetConstructor(\n                        new[] {\n                            typeof (UnmanagedType)\n                        } );\n                    var customAttributeBuilder = new CustomAttributeBuilder(\n                        constructorInfo,\n                        new object[] {\n                            paramtype.MarshalAttribute\n                        } );\n                    parameterBuilder.SetCustomAttribute( customAttributeBuilder );\n                }\n            }\n            inv.SetImplementationFlags( MethodImplAttributes.Runtime );\n            Type t = tb.CreateType();\n            _delegateStore.Add( cacheKey, t );\n            return t;\n        }\n        public MarshalInfo GetMarshalInfo( string typePart, Variant value ) {\n            bool isRef = typePart.EndsWith( \"*\" );\n            if ( isRef ) {\n                typePart = typePart.TrimEnd( '*' );\n            }\n            Type managedType = typePart.Equals( \"struct\", StringComparison.InvariantCultureIgnoreCase )\n                ? value.GetValue().GetType()\n                : GetManagedType( typePart );\n            UnmanagedType? marshalAttribute = GetMarshalAttribute( typePart );\n            object changeType = null;\n            if ( value != null ) {\n                changeType = ConvertAutoitTypeToMarshalType( value, managedType );\n            }\n            var marshalInfo = new MarshalInfo( changeType, managedType, marshalAttribute, isRef );\n            return marshalInfo;\n        }\n        private Type GetManagedType( string typeName ) {\n            string upperTypeName = typeName.ToUpper();\n            if ( _typeMapping.ContainsKey( upperTypeName ) ) {\n                return _typeMapping[upperTypeName];\n            }\n            throw new UnknowTypeNameException( typeName );\n        }\n        private object ConvertAutoitTypeToMarshalType( Variant variant, Type targetType ) {\n            object changeType;\n            if ( variant.GetRealType() == targetType ) {\n                changeType = variant.GetValue();\n            }\n            else if ( targetType == typeof (IntPtr) ) {\n                changeType = new IntPtr( variant.GetInt() );\n            }\n            else if ( targetType == typeof (UIntPtr) ) {\n                changeType = new UIntPtr( (uint) variant.GetInt() );\n            }\n            else if ( variant.IsInt32\n                      &&\n                      targetType == typeof (uint) ) {\n                changeType = unchecked( (uint) variant.GetInt() );\n            }\n            else if ( targetType == typeof (StringBuilder) ) {\n                string s = variant.GetString();\n                changeType = new StringBuilder( s, 0, s.Length, UInt16.MaxValue );\n            }\n            else {\n                changeType = Convert.ChangeType( variant.GetValue(), targetType );\n            }\n            return changeType;\n        }\n        public UnmanagedType? GetMarshalAttribute( string typeName ) {\n            string upperTypeName = typeName.ToUpper();\n            if ( _marshalAttributeMapping.ContainsKey( upperTypeName ) ) {\n                return _marshalAttributeMapping[upperTypeName];\n            }\n            return null;\n        }\n        public Type CreateRuntimeStruct( string @struct ) {\n            string cacheKey = String.Format( \"Struct_{0}\", @struct );\n            if ( _structStore.ContainsKey( cacheKey ) ) {\n                return _structStore[cacheKey];\n            }\n            IEnumerable<StructTypeInfo> typeInfos = GetTypeInfo( @struct );\n            Type res = CreateStruct( typeInfos );\n            _structStore.Add( cacheKey, res );\n            return res;\n        }\n        private Type CreateStruct( IEnumerable<StructTypeInfo> typeInfos ) {\n            ConstructorInfo constructorInfo = typeof (StructLayoutAttribute).GetConstructor(\n                new[] {\n                    typeof (LayoutKind)\n                } );\n            var customAttributeBuilder = new CustomAttributeBuilder(\n                constructorInfo,\n                new object[] {\n                    LayoutKind.Sequential\n                } );\n            TypeBuilder tb = _dynamicMod.DefineType(\n                \"_\"+Guid.NewGuid().ToString( \"N\" ),\n                TypeAttributes.Public,\n                typeof (object),\n                new[] {\n                    typeof (IRuntimeStruct)\n                } );\n            tb.SetCustomAttribute( customAttributeBuilder );\n            ConstructorBuilder constructorBuilder = tb.DefineConstructor( MethodAttributes.Public|MethodAttributes.HideBySig|MethodAttributes.SpecialName|MethodAttributes.RTSpecialName, CallingConventions.Standard, Type.EmptyTypes );\n            ILGenerator ilGenerator = constructorBuilder.GetILGenerator();\n            ilGenerator.Emit( OpCodes.Ldarg_0 );\n            ConstructorInfo superConstructor = typeof (Object).GetConstructor( Type.EmptyTypes );\n            ilGenerator.Emit( OpCodes.Call, superConstructor );\n            ilGenerator.Emit( OpCodes.Nop );\n            ilGenerator.Emit( OpCodes.Nop );\n            foreach (StructTypeInfo typeInfo in typeInfos) {\n                FieldBuilder fieldBuilder = tb.DefineField( typeInfo.VariableName, typeInfo.ManagedType, FieldAttributes.Public );\n                if ( typeInfo.ArraySize > 0 ) {\n                    ilGenerator.Emit( OpCodes.Ldarg_0 );\n                    ilGenerator.Emit( OpCodes.Ldc_I4, typeInfo.ArraySize );\n                    ilGenerator.Emit( OpCodes.Newarr, typeInfo.ManagedType.GetElementType() );\n                    ilGenerator.Emit( OpCodes.Stfld, fieldBuilder );\n                }\n                IEnumerable<CustomAttributeBuilder> attributesToApply = GetCustomAttributes( typeInfo );\n                foreach (CustomAttributeBuilder builder in attributesToApply) {\n                    fieldBuilder.SetCustomAttribute( builder );\n                }\n            }\n            ilGenerator.Emit( OpCodes.Ret );\n            Type t = tb.CreateType();\n            return t;\n        }\n        private static IEnumerable<CustomAttributeBuilder> GetCustomAttributes( StructTypeInfo typeInfo ) {\n            var attributesToApply = new List<CustomAttributeBuilder>();\n            if ( typeInfo.MarshalAs.HasValue ) {\n                ConstructorInfo customAttributeConstructorInfoMarshalAs = typeof (MarshalAsAttribute).GetConstructor(\n                    new[] {\n                        typeof (UnmanagedType)\n                    } );\n                var customAttributeBuilderMarshalAs = new CustomAttributeBuilder(\n                    customAttributeConstructorInfoMarshalAs,\n                    new object[] {\n                        typeInfo.MarshalAs.Value\n                    } );\n                attributesToApply.Add( customAttributeBuilderMarshalAs );\n            }\n            if ( typeInfo.ArraySize > 0 ) {\n                ConstructorInfo customAttributeConstructorMarshalAsArray = typeof (MarshalAsAttribute).GetConstructor(\n                    new[] {\n                        typeof (UnmanagedType)\n                    } );\n                FieldInfo propertyInfoSizeConst = typeof (MarshalAsAttribute).GetFields().Single( x => x.Name.Equals( \"SizeConst\" ) );\n                var customAttributeBuilderMarshalAsArray = new CustomAttributeBuilder(\n                    customAttributeConstructorMarshalAsArray,\n                    new object[] {\n                        UnmanagedType.ByValArray\n                    },\n                    new[] {\n                        propertyInfoSizeConst\n                    },\n                    new object[] {\n                        typeInfo.ArraySize\n                    } );\n                attributesToApply.Add( customAttributeBuilderMarshalAsArray );\n            }\n            return attributesToApply;\n        }\n        private IEnumerable<StructTypeInfo> GetTypeInfo( string @struct ) {\n            return GetTypeInfo( @struct.Split( ';' ) );\n        }\n        private IEnumerable<StructTypeInfo> GetTypeInfo( string[] fragments ) {\n            bool isSingleStruct = fragments.First().Equals( \"STRUCT\", StringComparison.InvariantCultureIgnoreCase ) && fragments.Last().Equals( \"ENDSTRUCT\", StringComparison.InvariantCultureIgnoreCase ) && fragments.Count( x => x.Equals( \"STRUCT\", StringComparison.InvariantCultureIgnoreCase ) ) == 1 && fragments.Count( x => x.Equals( \"ENDSTRUCT\", StringComparison.InvariantCultureIgnoreCase ) ) == 1;\n            if ( isSingleStruct ) {\n                fragments = fragments.Skip( 1 ).Take( fragments.Length-2 ).ToArray();\n            }\n            var toReturn = new List<StructTypeInfo>();\n            for ( int index = 0; index < fragments.Length; index++ ) {\n                string fragment = fragments[index];\n                string[] nametypeFragments = fragment.Split( ' ' );\n                if ( nametypeFragments.Length == 1 ) {\n                    string typeFragmanet = nametypeFragments[0];\n                    string[] typeArraySizeFragments = typeFragmanet.Split(\n                        new[] {\n                            \"[\",\n                            \"]\"\n                        },\n                        StringSplitOptions.RemoveEmptyEntries );\n                    string typePart = typeArraySizeFragments[0];\n                    UnmanagedType? marshalAttribute = GetMarshalAttribute( typePart );\n                    int arraySize = 0;\n                    if ( typeArraySizeFragments.Length == 2 ) {\n                        arraySize = Int32.Parse( typeArraySizeFragments[1] );\n                    }\n                    Type managedType;\n                    if ( typePart.Equals( \"STRUCT\", StringComparison.InvariantCultureIgnoreCase ) ) {\n                        int count = 0;\n                        var structPart = new List<string>();\n                        do {\n                            bool isEndStruct = fragments[index].Equals( \"ENDSTRUCT\", StringComparison.InvariantCultureIgnoreCase );\n                            if ( isEndStruct ) {\n                                count--;\n                            }\n                            else {\n                                bool isStruct = fragments[index].Equals( \"STRUCT\", StringComparison.InvariantCultureIgnoreCase );\n                                if ( isStruct ) {\n                                    count++;\n                                }\n                                else {\n                                    structPart.Add( fragments[index] );\n                                }\n                            }\n                            index++;\n                        } while ( count != 0 );\n                        IEnumerable<StructTypeInfo> structTypeInfos = GetTypeInfo( structPart.ToArray() );\n                        Type innerStructType = CreateStruct( structTypeInfos );\n                        managedType = innerStructType;\n                    }\n                    else {\n                        managedType = GetManagedType( typePart );\n                        if ( arraySize > 0 ) {\n                            managedType = managedType.MakeArrayType();\n                        }\n                    }\n                    toReturn.Add( new StructTypeInfo( \"_\"+Guid.NewGuid().ToString( \"N\" ), managedType, marshalAttribute, arraySize ) );\n                    continue;\n                }\n                if ( nametypeFragments.Length == 2 ) {\n                    string typeFragment = nametypeFragments[0];\n                    string nameArraySizeFragment = nametypeFragments[1];\n                    string[] nameArraySizeFragments = nameArraySizeFragment.Split(\n                        new[] {\n                            \"[\",\n                            \"]\"\n                        },\n                        StringSplitOptions.RemoveEmptyEntries );\n                    Type managedType = GetManagedType( typeFragment );\n                    UnmanagedType? marshalAttribute = GetMarshalAttribute( typeFragment );\n                    int arraySize = 0;\n                    if ( nameArraySizeFragments.Length == 2 ) {\n                        arraySize = Int32.Parse( nameArraySizeFragments[1] );\n                    }\n                    if ( arraySize > 0 ) {\n                        managedType = managedType.MakeArrayType();\n                    }\n", "outputs": ["                    string name = nameArraySizeFragments[0];"], "input_length": 2999, "output_length": 8, "length": 3007, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "12f3e12cd2579448a4f9b2032bef382edefc84b213063c3ecc0668a30bbb2263"}
{"input": "", "context": "# lint-amnesty, pylint: disable=missing-module-docstring\nimport json\nimport logging\nimport sys\nfrom functools import wraps\nimport calc\nimport crum\nfrom django.conf import settings\nfrom django.contrib.auth.decorators import login_required\nfrom django.http import Http404, HttpResponse, HttpResponseForbidden, HttpResponseServerError\nfrom django.views.decorators.csrf import ensure_csrf_cookie, requires_csrf_token\nfrom django.views.defaults import server_error\nfrom django.shortcuts import redirect\nfrom opaque_keys import InvalidKeyError\nfrom opaque_keys.edx.keys import CourseKey, UsageKey\nfrom lms.djangoapps.courseware.access import has_access\nfrom lms.djangoapps.courseware.masquerade import setup_masquerade\nfrom openedx.core.djangoapps.schedules.utils import reset_self_paced_schedule\nfrom openedx.features.course_experience.utils import dates_banner_should_display\nfrom common.djangoapps.track import views as track_views\nfrom common.djangoapps.edxmako.shortcuts import render_to_response\nfrom common.djangoapps.student.roles import GlobalStaff\nlog = logging.getLogger(__name__)\ndef ensure_valid_course_key(view_func):\n    \"\"\"\n    This decorator should only be used with views which have argument course_key_string (studio) or course_id (lms).\n    If course_key_string (studio) or course_id (lms) is not valid raise 404.\n    \"\"\"\n    @wraps(view_func)\n    def inner(request, *args, **kwargs):\n        course_key = kwargs.get('course_key_string') or kwargs.get('course_id')\n        if course_key is not None:\n            try:\n                CourseKey.from_string(course_key)\n            except InvalidKeyError:\n                raise Http404  # lint-amnesty, pylint: disable=raise-missing-from\n        response = view_func(request, *args, **kwargs)\n        return response\n    return inner\ndef ensure_valid_usage_key(view_func):\n    \"\"\"\n    This decorator should only be used with views which have argument usage_key_string.\n    If usage_key_string is not valid raise 404.\n    \"\"\"\n    @wraps(view_func)\n    def inner(request, *args, **kwargs):\n        usage_key = kwargs.get('usage_key_string')\n        if usage_key is not None:\n            try:\n                UsageKey.from_string(usage_key)\n            except InvalidKeyError:\n                raise Http404  # lint-amnesty, pylint: disable=raise-missing-from\n        response = view_func(request, *args, **kwargs)\n        return response\n    return inner\ndef require_global_staff(func):\n    \"\"\"View decorator that requires that the user have global staff permissions. \"\"\"\n    @wraps(func)\n    def wrapped(request, *args, **kwargs):\n        if GlobalStaff().has_user(request.user):\n            return func(request, *args, **kwargs)\n        else:\n            return HttpResponseForbidden(\n                \"Must be {platform_name} staff to perform this action.\".format(\n                    platform_name=settings.PLATFORM_NAME\n                )\n            )\n    return login_required(wrapped)\ndef fix_crum_request(func):\n    \"\"\"\n    A decorator that ensures that the 'crum' package (a middleware that stores and fetches the current request in\n    thread-local storage) can correctly fetch the current request. Under certain conditions, the current request cannot\n    be fetched by crum (e.g.: when HTTP errors are raised in our views via 'raise Http404', et. al.). This decorator\n    manually sets the current request for crum if it cannot be fetched.\n    \"\"\"\n    @wraps(func)\n    def wrapper(request, *args, **kwargs):\n        if not crum.get_current_request():\n            crum.set_current_request(request=request)\n        return func(request, *args, **kwargs)\n    return wrapper\n@requires_csrf_token\ndef jsonable_server_error(request, template_name='500.html'):\n    \"\"\"\n    500 error handler that serves JSON on an AJAX request, and proxies\n    to the Django default `server_error` view otherwise.\n    \"\"\"\n    if request.is_ajax():\n        msg = {\"error\": \"The edX servers encountered an error\"}\n        return HttpResponseServerError(json.dumps(msg))\n    else:\n        return server_error(request, template_name=template_name)\ndef handle_500(template_path, context=None, test_func=None):\n    \"\"\"\n    Decorator for view specific 500 error handling.\n    Custom handling will be skipped only if test_func is passed and it returns False\n    Usage:\n        @handle_500(\n            template_path='certificates/server-error.html',\n            context={'error-info': 'Internal Server Error'},\n            test_func=lambda request: request.GET.get('preview', None)\n        )\n        def my_view(request):\n            # Any unhandled exception in this view would be handled by the handle_500 decorator\n            # ...\n    \"\"\"\n    def decorator(func):\n        \"\"\"\n        Decorator to render custom html template in case of uncaught exception in wrapped function\n        \"\"\"\n        @wraps(func)\n        def inner(request, *args, **kwargs):\n            \"\"\"\n            Execute the function in try..except block and return custom server-error page in case of unhandled exception\n            \"\"\"\n            try:\n                return func(request, *args, **kwargs)\n            except Exception:  # pylint: disable=broad-except\n                if settings.DEBUG:  # lint-amnesty, pylint: disable=no-else-raise\n                    # In debug mode let django process the 500 errors and display debug info for the developer\n                    raise\n                elif test_func is None or test_func(request):\n                    # Display custom 500 page if either\n                    #   1. test_func is None (meaning nothing to test)\n                    #   2. or test_func(request) returns True\n                    log.exception(\"Error in django view.\")\n                    return render_to_response(template_path, context)\n                else:\n                    # Do not show custom 500 error when test fails\n                    raise\n        return inner\n    return decorator\ndef calculate(request):\n    ''' Calculator in footer of every page. '''\n    equation = request.GET['equation']\n    try:\n        result = calc.evaluator({}, {}, equation)\n    except:  # lint-amnesty, pylint: disable=bare-except\n        event = {'error': list(map(str, sys.exc_info())),\n                 'equation': equation}\n        track_views.server_track(request, 'error:calc', event, page='calc')\n        return HttpResponse(json.dumps({'result': 'Invalid syntax'}))  # lint-amnesty, pylint: disable=http-response-with-json-dumps\n    return HttpResponse(json.dumps({'result': str(result)}))  # lint-amnesty, pylint: disable=http-response-with-json-dumps\ndef info(request):\n    \"\"\" Info page (link from main header) \"\"\"\n    return render_to_response(\"info.html\", {})\ndef add_p3p_header(view_func):\n    \"\"\"\n    This decorator should only be used with views which may be displayed through the iframe.\n    It adds additional headers to response and therefore gives IE browsers an ability to save cookies inside the iframe\n    Details:\n    http://blogs.msdn.com/b/ieinternals/archive/2013/09/17/simple-introduction-to-p3p-cookie-blocking-frame.aspx\n    http://stackoverflow.com/questions/8048306/what-is-the-most-broad-p3p-header-that-will-work-with-ie\n    \"\"\"\n    @wraps(view_func)\n    def inner(request, *args, **kwargs):\n        \"\"\"\n        Helper function\n        \"\"\"\n        response = view_func(request, *args, **kwargs)\n        response['P3P'] = settings.P3P_HEADER\n        return response\n    return inner\n@ensure_csrf_cookie\ndef reset_course_deadlines(request):\n    \"\"\"\n    Set the start_date of a schedule to today, which in turn will adjust due dates for\n    sequentials belonging to a self paced course\n    IMPORTANT NOTE: If updates are happening to the logic here, ALSO UPDATE the `reset_course_deadlines`\n    function in openedx/features/course_experience/api/v1/views.py as well.\n    \"\"\"\n    course_key = CourseKey.from_string(request.POST.get('course_id'))\n    _course_masquerade, user = setup_masquerade(\n        request,\n        course_key,\n        has_access(request.user, 'staff', course_key)\n    )\n    missed_deadlines, missed_gated_content = dates_banner_should_display(course_key, user)\n    if missed_deadlines and not missed_gated_content:\n        reset_self_paced_schedule(user, course_key)\n    referrer = request.META.get('HTTP_REFERER')\n    return redirect(referrer) if referrer else HttpResponse()\ndef expose_header(header, response):\n    \"\"\"\n    Add a header name to Access-Control-Expose-Headers to allow client code to access that header's value\n    \"\"\"\n    exposedHeaders = response.get('Access-Control-Expose-Headers', '')\n", "outputs": ["    exposedHeaders += f', {header}' if exposedHeaders else header"], "input_length": 1322, "output_length": 13, "length": 1335, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "f508ef56848340aa9283b1b39298567175a440cef6ab5d5f4001e716d514fa8e"}
{"input": "", "context": "/*\n * Copyright (C) 2005-2010 Alfresco Software Limited.\n *\n * This file is part of Alfresco\n *\n * Alfresco is free software: you can redistribute it and/or modify\n * it under the terms of the GNU Lesser General Public License as published by\n * the Free Software Foundation, either version 3 of the License, or\n * (at your option) any later version.\n *\n * Alfresco is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public License\n * along with Alfresco. If not, see <http://www.gnu.org/licenses/>.\n */\npackage org.alfresco.repo.management.subsystems;\nimport java.util.Collection;\nimport java.util.LinkedHashSet;\nimport java.util.Set;\nimport org.apache.commons.logging.Log;\nimport org.apache.commons.logging.LogFactory;\nimport org.springframework.beans.BeansException;\nimport org.springframework.beans.MutablePropertyValues;\nimport org.springframework.beans.PropertyValue;\nimport org.springframework.beans.factory.NoSuchBeanDefinitionException;\nimport org.springframework.beans.factory.config.BeanFactoryPostProcessor;\nimport org.springframework.beans.factory.config.BeanReference;\nimport org.springframework.beans.factory.config.ConfigurableListableBeanFactory;\nimport org.springframework.beans.factory.config.PropertyPlaceholderConfigurer;\nimport org.springframework.beans.factory.config.RuntimeBeanReference;\nimport org.springframework.beans.factory.config.TypedStringValue;\nimport org.springframework.beans.factory.support.BeanDefinitionRegistry;\nimport org.springframework.beans.factory.support.ManagedList;\nimport org.springframework.core.Ordered;\nimport org.springframework.core.PriorityOrdered;\n/**\n * A {@link BeanFactoryPostProcessor} that upgrades old-style Spring overrides that add location paths to the\n * <code>repository-properties</code> or <code>hibernateConfigProperties</code> beans to instead add these paths to the\n * <code>global-properties</code> bean. To avoid the warning messages output by this class, new property overrides\n * should be added to alfresco-global.properties without overriding any bean definitions.\n * \n * @author dward\n */\npublic class LegacyConfigPostProcessor implements BeanFactoryPostProcessor, PriorityOrdered\n{\n    /** The name of the bean that, in new configurations, holds all properties */\n    private static final String BEAN_NAME_GLOBAL_PROPERTIES = \"global-properties\";\n    /** The name of the bean that expands repository properties. These should now be defaulted from global-properties. */\n    private static final String BEAN_NAME_REPOSITORY_PROPERTIES = \"repository-properties\";\n    /** The name of the bean that holds hibernate properties. These should now be overriden by global-properties. */\n    private static final String BEAN_NAME_HIBERNATE_PROPERTIES = \"hibernateConfigProperties\";\n    /** The name of the property on a Spring property loader that holds a list of property file location paths. */\n    private static final String PROPERTY_LOCATIONS = \"locations\";\n    /** The name of the property on a Spring property loader that holds a local property map. */\n    private static final String PROPERTY_PROPERTIES = \"properties\";\n    /** The logger. */\n    private static Log logger = LogFactory.getLog(LegacyConfigPostProcessor.class);\n    /*\n     * (non-Javadoc)\n     * @see\n     * org.springframework.beans.factory.config.BeanFactoryPostProcessor#postProcessBeanFactory(org.springframework.\n     * beans.factory.config.ConfigurableListableBeanFactory)\n     */\n    @SuppressWarnings(\"unchecked\")\n    public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException\n    {\n        try\n        {\n            // Look up the global-properties bean and its locations list\n            MutablePropertyValues globalProperties = beanFactory.getBeanDefinition(\n                    LegacyConfigPostProcessor.BEAN_NAME_GLOBAL_PROPERTIES).getPropertyValues();\n            PropertyValue pv = globalProperties.getPropertyValue(LegacyConfigPostProcessor.PROPERTY_LOCATIONS);\n            Collection<Object> globalPropertyLocations;\n            Object value;\n            // Use the locations list if there is one, otherwise associate a new empty list\n            if (pv != null && (value = pv.getValue()) != null && value instanceof Collection)\n            {\n                globalPropertyLocations = (Collection<Object>) value;\n            }\n            else\n            {\n                globalPropertyLocations = new ManagedList(10);\n                globalProperties\n                        .addPropertyValue(LegacyConfigPostProcessor.PROPERTY_LOCATIONS, globalPropertyLocations);\n            }\n            // Move location paths added to repository-properties\n            MutablePropertyValues repositoryProperties = processLocations(beanFactory, globalPropertyLocations,\n                    LegacyConfigPostProcessor.BEAN_NAME_REPOSITORY_PROPERTIES, new String[]\n                    {\n                        \"classpath:alfresco/version.properties\"\n                    });\n            // Fix up additional properties to enforce correct order of precedence\n            repositoryProperties.addPropertyValue(\"ignoreUnresolvablePlaceholders\", Boolean.TRUE);\n            repositoryProperties.addPropertyValue(\"localOverride\", Boolean.FALSE);\n            repositoryProperties.addPropertyValue(\"valueSeparator\", null);\n            repositoryProperties.addPropertyValue(\"systemPropertiesModeName\", \"SYSTEM_PROPERTIES_MODE_NEVER\");\n            // Move location paths added to hibernateConfigProperties\n            MutablePropertyValues hibernateProperties = processLocations(beanFactory, globalPropertyLocations,\n                    LegacyConfigPostProcessor.BEAN_NAME_HIBERNATE_PROPERTIES, new String[]\n                    {\n                        \"classpath:alfresco/domain/hibernate-cfg.properties\",\n                        \"classpath*:alfresco/enterprise/cache/hibernate-cfg.properties\"\n                    });\n            // Fix up additional properties to enforce correct order of precedence\n            hibernateProperties.addPropertyValue(\"localOverride\", Boolean.TRUE);\n            // Because Spring gets all post processors in one shot, the bean may already have been created. Let's try to\n            // fix it up!\n            PropertyPlaceholderConfigurer repositoryConfigurer = (PropertyPlaceholderConfigurer) beanFactory\n                    .getSingleton(LegacyConfigPostProcessor.BEAN_NAME_REPOSITORY_PROPERTIES);\n            if (repositoryConfigurer != null)\n            {\n                // Reset locations list\n                repositoryConfigurer.setLocations(null);\n                // Invalidate cached merged bean definitions\n                ((BeanDefinitionRegistry) beanFactory).registerBeanDefinition(\n                        LegacyConfigPostProcessor.BEAN_NAME_REPOSITORY_PROPERTIES, beanFactory\n                                .getBeanDefinition(LegacyConfigPostProcessor.BEAN_NAME_REPOSITORY_PROPERTIES));\n                // Reconfigure the bean according to its new definition\n                beanFactory.configureBean(repositoryConfigurer,\n                        LegacyConfigPostProcessor.BEAN_NAME_REPOSITORY_PROPERTIES);\n            }\n        }\n        catch (NoSuchBeanDefinitionException e)\n        {\n            // Ignore and continue\n        }\n    }\n    /**\n     * Given a bean name (assumed to implement {@link org.springframework.core.io.support.PropertiesLoaderSupport})\n     * checks whether it already references the <code>global-properties</code> bean. If not, 'upgrades' the bean by\n     * appending all additional resources it mentions in its <code>locations</code> property to\n     * <code>globalPropertyLocations</code>, except for those resources mentioned in <code>newLocations</code>. A\n     * reference to <code>global-properties</code> will then be added and the resource list in\n     * <code>newLocations<code> will then become the new <code>locations</code> list for the bean.\n     * \n     * @param beanFactory\n     *            the bean factory\n     * @param globalPropertyLocations\n     *            the list of global property locations to be appended to\n     * @param beanName\n     *            the bean name\n     * @param newLocations\n     *            the new locations to be set on the bean\n     * @return the mutable property values\n     */\n    @SuppressWarnings(\"unchecked\")\n    private MutablePropertyValues processLocations(ConfigurableListableBeanFactory beanFactory,\n            Collection<Object> globalPropertyLocations, String beanName, String[] newLocations)\n    {\n        // Get the bean an check its existing properties value\n        MutablePropertyValues beanProperties = beanFactory.getBeanDefinition(beanName).getPropertyValues();\n        PropertyValue pv = beanProperties.getPropertyValue(LegacyConfigPostProcessor.PROPERTY_PROPERTIES);\n        Object value;\n        // If the properties value already references the global-properties bean, we have nothing else to do. Otherwise,\n        // we have to 'upgrade' the bean definition.\n        if (pv == null || (value = pv.getValue()) == null || !(value instanceof BeanReference)\n                || ((BeanReference) value).getBeanName().equals(LegacyConfigPostProcessor.BEAN_NAME_GLOBAL_PROPERTIES))\n        {\n            // Convert the array of new locations to a managed list of type string values, so that it is\n            // compatible with a bean definition\n            Collection<Object> newLocationList = new ManagedList(newLocations.length);\n            if (newLocations != null && newLocations.length > 0)\n            {\n                for (String preserveLocation : newLocations)\n                {\n                    newLocationList.add(new TypedStringValue(preserveLocation));\n                }\n            }\n            // If there is currently a locations list, process it\n            pv = beanProperties.getPropertyValue(LegacyConfigPostProcessor.PROPERTY_LOCATIONS);\n            if (pv != null && (value = pv.getValue()) != null && value instanceof Collection)\n            {\n                Collection<Object> locations = (Collection<Object>) value;\n                // Compute the set of locations that need to be added to globalPropertyLocations (preserving order) and\n                // warn about each\n                Set<Object> addedLocations = new LinkedHashSet<Object>(locations);\n                addedLocations.removeAll(globalPropertyLocations);\n                addedLocations.removeAll(newLocationList);\n                for (Object location : addedLocations)\n                {\n                    LegacyConfigPostProcessor.logger.warn(\"Legacy configuration detected: adding \"\n                            + (location instanceof TypedStringValue ? ((TypedStringValue) location).getValue()\n                                    : location.toString()) + \" to global-properties definition\");\n                    globalPropertyLocations.add(location);\n                }\n            }\n            // Ensure the bean now references global-properties\n            beanProperties.addPropertyValue(LegacyConfigPostProcessor.PROPERTY_PROPERTIES, new RuntimeBeanReference(\n                    LegacyConfigPostProcessor.BEAN_NAME_GLOBAL_PROPERTIES));\n            // Ensure the new location list is now set on the bean\n", "outputs": ["            if (newLocationList.size() > 0)"], "input_length": 1451, "output_length": 8, "length": 1459, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "9379659d3d157f75a18620d17b3feb1f76c2bf76d7721ff99fc95bf40e5966d7"}
{"input": "", "context": "/*\n * Copyright (c) 2011, 2013, Oracle and/or its affiliates. All rights reserved.\n * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n *\n * This code is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License version 2 only, as\n * published by the Free Software Foundation.\n *\n * This code is distributed in the hope that it will be useful, but WITHOUT\n * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n * version 2 for more details (a copy is included in the LICENSE file that\n * accompanied this code).\n *\n * You should have received a copy of the GNU General Public License version\n * 2 along with this work; if not, write to the Free Software Foundation,\n * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n *\n * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n * or visit www.oracle.com if you need additional information or have any\n * questions.\n */\npackage com.oracle.graal.virtual.phases.ea;\nimport static com.oracle.graal.api.meta.LocationIdentity.*;\nimport java.util.*;\nimport com.oracle.graal.api.meta.*;\nimport com.oracle.graal.compiler.common.type.*;\nimport com.oracle.graal.graph.*;\nimport com.oracle.graal.nodes.*;\nimport com.oracle.graal.nodes.cfg.*;\nimport com.oracle.graal.nodes.extended.*;\nimport com.oracle.graal.nodes.java.*;\nimport com.oracle.graal.nodes.util.*;\nimport com.oracle.graal.virtual.phases.ea.ReadEliminationBlockState.CacheEntry;\nimport com.oracle.graal.virtual.phases.ea.ReadEliminationBlockState.LoadCacheEntry;\nimport com.oracle.graal.virtual.phases.ea.ReadEliminationBlockState.ReadCacheEntry;\nimport com.oracle.graal.virtual.phases.ea.ReadEliminationBlockState.UnsafeLoadCacheEntry;\npublic class ReadEliminationClosure extends EffectsClosure<ReadEliminationBlockState> {\n    public ReadEliminationClosure(ControlFlowGraph cfg) {\n        super(null, cfg);\n    }\n    @Override\n    protected ReadEliminationBlockState getInitialState() {\n        return new ReadEliminationBlockState();\n    }\n    @Override\n    protected boolean processNode(Node node, ReadEliminationBlockState state, GraphEffectList effects, FixedWithNextNode lastFixedNode) {\n        boolean deleted = false;\n        if (node instanceof AccessFieldNode) {\n            AccessFieldNode access = (AccessFieldNode) node;\n            if (access.isVolatile()) {\n                processIdentity(state, ANY_LOCATION);\n            } else {\n                ValueNode object = GraphUtil.unproxify(access.object());\n                LoadCacheEntry identifier = new LoadCacheEntry(object, access.field());\n                ValueNode cachedValue = state.getCacheEntry(identifier);\n                if (node instanceof LoadFieldNode) {\n                    if (cachedValue != null) {\n                        effects.replaceAtUsages(access, cachedValue);\n                        addScalarAlias(access, cachedValue);\n                        deleted = true;\n                    } else {\n                        state.addCacheEntry(identifier, access);\n                    }\n                } else {\n                    assert node instanceof StoreFieldNode;\n                    StoreFieldNode store = (StoreFieldNode) node;\n                    ValueNode value = getScalarAlias(store.value());\n                    if (GraphUtil.unproxify(value) == GraphUtil.unproxify(cachedValue)) {\n                        effects.deleteFixedNode(store);\n                        deleted = true;\n                    }\n                    state.killReadCache(store.field());\n                    state.addCacheEntry(identifier, value);\n                }\n            }\n        } else if (node instanceof ReadNode) {\n            ReadNode read = (ReadNode) node;\n            if (read.location() instanceof ConstantLocationNode) {\n                ValueNode object = GraphUtil.unproxify(read.object());\n                ReadCacheEntry identifier = new ReadCacheEntry(object, read.location());\n                ValueNode cachedValue = state.getCacheEntry(identifier);\n                if (cachedValue != null) {\n                    if (read.getGuard() != null && !(read.getGuard() instanceof FixedNode)) {\n                        effects.addFixedNodeBefore(ValueAnchorNode.create((ValueNode) read.getGuard()), read);\n                    }\n                    effects.replaceAtUsages(read, cachedValue);\n                    addScalarAlias(read, cachedValue);\n                    deleted = true;\n                } else {\n                    state.addCacheEntry(identifier, read);\n                }\n            }\n        } else if (node instanceof WriteNode) {\n            WriteNode write = (WriteNode) node;\n            if (write.location() instanceof ConstantLocationNode) {\n                ValueNode object = GraphUtil.unproxify(write.object());\n                ReadCacheEntry identifier = new ReadCacheEntry(object, write.location());\n                ValueNode cachedValue = state.getCacheEntry(identifier);\n                ValueNode value = getScalarAlias(write.value());\n                if (GraphUtil.unproxify(value) == GraphUtil.unproxify(cachedValue)) {\n                    effects.deleteFixedNode(write);\n                    deleted = true;\n                }\n                processIdentity(state, write.location().getLocationIdentity());\n                state.addCacheEntry(identifier, value);\n            } else {\n                processIdentity(state, write.location().getLocationIdentity());\n            }\n        } else if (node instanceof UnsafeAccessNode) {\n            if (node instanceof UnsafeLoadNode) {\n                UnsafeLoadNode load = (UnsafeLoadNode) node;\n                if (load.offset().isConstant() && load.getLocationIdentity() != LocationIdentity.ANY_LOCATION) {\n                    ValueNode object = GraphUtil.unproxify(load.object());\n                    UnsafeLoadCacheEntry identifier = new UnsafeLoadCacheEntry(object, load.offset(), load.getLocationIdentity());\n                    ValueNode cachedValue = state.getCacheEntry(identifier);\n                    if (cachedValue != null) {\n                        effects.replaceAtUsages(load, cachedValue);\n                        addScalarAlias(load, cachedValue);\n                        deleted = true;\n                    } else {\n                        state.addCacheEntry(identifier, load);\n                    }\n                }\n            } else {\n                assert node instanceof UnsafeStoreNode;\n                UnsafeStoreNode write = (UnsafeStoreNode) node;\n                if (write.offset().isConstant() && write.getLocationIdentity() != LocationIdentity.ANY_LOCATION) {\n                    ValueNode object = GraphUtil.unproxify(write.object());\n                    UnsafeLoadCacheEntry identifier = new UnsafeLoadCacheEntry(object, write.offset(), write.getLocationIdentity());\n                    ValueNode cachedValue = state.getCacheEntry(identifier);\n                    ValueNode value = getScalarAlias(write.value());\n                    if (GraphUtil.unproxify(value) == GraphUtil.unproxify(cachedValue)) {\n                        effects.deleteFixedNode(write);\n                        deleted = true;\n                    }\n                    processIdentity(state, write.getLocationIdentity());\n                    state.addCacheEntry(identifier, value);\n                } else {\n                    processIdentity(state, write.getLocationIdentity());\n                }\n            }\n        } else if (node instanceof MemoryCheckpoint.Single) {\n            LocationIdentity identity = ((MemoryCheckpoint.Single) node).getLocationIdentity();\n            processIdentity(state, identity);\n        } else if (node instanceof MemoryCheckpoint.Multi) {\n            for (LocationIdentity identity : ((MemoryCheckpoint.Multi) node).getLocationIdentities()) {\n                processIdentity(state, identity);\n            }\n        }\n        return deleted;\n    }\n    private static void processIdentity(ReadEliminationBlockState state, LocationIdentity identity) {\n        if (identity == ANY_LOCATION) {\n            state.killReadCache();\n            return;\n        }\n        state.killReadCache(identity);\n    }\n    @Override\n    protected void processLoopExit(LoopExitNode exitNode, ReadEliminationBlockState initialState, ReadEliminationBlockState exitState, GraphEffectList effects) {\n        if (exitNode.graph().hasValueProxies()) {\n            for (Map.Entry<CacheEntry<?>, ValueNode> entry : exitState.getReadCache().entrySet()) {\n                if (initialState.getReadCache().get(entry.getKey()) != entry.getValue()) {\n                    ProxyNode proxy = ValueProxyNode.create(exitState.getCacheEntry(entry.getKey()), exitNode);\n                    effects.addFloatingNode(proxy, \"readCacheProxy\");\n                    entry.setValue(proxy);\n                }\n            }\n        }\n    }\n    @Override\n    protected ReadEliminationBlockState cloneState(ReadEliminationBlockState other) {\n        return new ReadEliminationBlockState(other);\n    }\n    @Override\n    protected MergeProcessor createMergeProcessor(Block merge) {\n        return new ReadEliminationMergeProcessor(merge);\n    }\n    private class ReadEliminationMergeProcessor extends EffectsClosure<ReadEliminationBlockState>.MergeProcessor {\n        private final HashMap<Object, ValuePhiNode> materializedPhis = new HashMap<>();\n        public ReadEliminationMergeProcessor(Block mergeBlock) {\n            super(mergeBlock);\n        }\n        protected <T> PhiNode getCachedPhi(T virtual, Stamp stamp) {\n            ValuePhiNode result = materializedPhis.get(virtual);\n            if (result == null) {\n                result = ValuePhiNode.create(stamp, merge);\n                materializedPhis.put(virtual, result);\n            }\n            return result;\n        }\n        @Override\n        protected void merge(List<ReadEliminationBlockState> states) {\n            super.merge(states);\n            mergeReadCache(states);\n        }\n        private void mergeReadCache(List<ReadEliminationBlockState> states) {\n            for (Map.Entry<CacheEntry<?>, ValueNode> entry : states.get(0).readCache.entrySet()) {\n                CacheEntry<?> key = entry.getKey();\n                ValueNode value = entry.getValue();\n                boolean phi = false;\n                for (int i = 1; i < states.size(); i++) {\n                    ValueNode otherValue = states.get(i).readCache.get(key);\n                    if (otherValue == null) {\n                        value = null;\n                        phi = false;\n                        break;\n                    }\n                    if (!phi && otherValue != value) {\n                        phi = true;\n                    }\n                }\n", "outputs": ["                if (phi) {"], "input_length": 1489, "output_length": 5, "length": 1494, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "733f96090deca501311d5debbfd055d46433af5b571bd110ab830d9cc848f983"}
{"input": "", "context": "#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU General Public License as published by\n#    the Free Software Foundation, either version 3 of the License, or\n#    (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU General Public License for more details.\n#\n#    You should have received a copy of the GNU General Public License\n#    along with this program. If not, see <http://www.gnu.org/licenses/>.\n#\n#    This script is based on script.randomitems & script.watchlist\n#    Thanks to their original authors\nimport os\nimport re\nimport sys\nimport xbmc\nimport xbmcgui\nimport xbmcplugin\nimport xbmcaddon\nimport random\nimport urllib\nimport shutil\nimport glob, os\nimport time\n__addon__     = xbmcaddon.Addon('skin.qonfluence')\n__addonid__   = __addon__.getAddonInfo('id')\n__language__  = __addon__.getLocalizedString\naddonPath = xbmcaddon.Addon('skin.qonfluence').getAddonInfo(\"path\")\nimage    = os.path.join(addonPath,'notification.png')\ndialog = xbmcgui.Dialog()\nlocaltxt2 = __language__(32007)\nlocaltxt3 = __language__(32008)\nlocaltxt8 = __language__(32014)\nlocaltxt9 = __language__(32028)\nlocaltxt10 = __language__(32040)\nprnum=\"\"\ntry:\n    prnum= sys.argv[ 1 ]\nexcept:\n    pass\ndef cache():\n    localtxt1 = __language__(32006)+__language__(32000)\n    destpath=xbmc.translatePath(os.path.join('special://temp',''))\n    if dialog.yesno(localtxt1, localtxt3):\n        shutil.rmtree(destpath)\n        os.mkdir(destpath)\n        xbmc.executebuiltin(\"Notification(\"+localtxt9+\",\"+localtxt2+\", 5000, %s)\" % (image))\n#-------------------\ndef packages():\n    localtxt1 = __language__(32006)+__language__(32002)\n    path=xbmc.translatePath(os.path.join('special://home/addons/packages',''))\n    if dialog.yesno(localtxt1, localtxt3):\n        shutil.rmtree(path)\n        os.mkdir(path)\n        xbmc.executebuiltin(\"Notification(\"+localtxt9+\",\"+localtxt2+\", 5000, %s)\" % (image))\n#-------------------\ndef musicdb():\n    localtxt1 = __language__(32006)+__language__(32005)\n    path = xbmc.translatePath(os.path.join('special://profile/Database',''))\n    if dialog.yesno(localtxt1, localtxt3):\n        database = os.path.join(path, 'MyMusic*.db')\n        print database\n        filelist = glob.glob(database)\n        print filelist\n        if filelist != []:\n            for f in filelist:\n                print f\n                os.remove(f)\n                xbmc.executebuiltin(\"Notification(\"+localtxt2+\",\"+localtxt8+\")\")\n                time.sleep(3)\n                xbmc.executebuiltin(\"Reboot\")\n        else:\n            print 'merdaa'\n            xbmc.executebuiltin(\"Notification(\"+localtxt9+\",\"+localtxt10+\", 5000, %s)\" % (image))\n#-------------------\ndef videodb():\n    localtxt1 = __language__(32006)+__language__(32004)\n    path = xbmc.translatePath(os.path.join('special://profile/Database',''))\n    if dialog.yesno(localtxt1, localtxt3):\n        database = os.path.join(path, 'MyVideos*.db')\n        print database\n        filelist = glob.glob(database)\n        print filelist\n        if filelist != []:\n            for f in filelist:\n                print f\n                os.remove(f)\n                xbmc.executebuiltin(\"Notification(\"+localtxt2+\",\"+localtxt8+\")\")\n                time.sleep(3)\n                xbmc.executebuiltin(\"Reboot\")\n        else:\n            print 'merdaa'\n            xbmc.executebuiltin(\"Notification(\"+localtxt9+\",\"+localtxt10+\", 5000, %s)\" % (image))\n#-------------------\ndef thumbs():\n    localtxt1 = __language__(32006)+__language__(32001)\n    thumbnails=xbmc.translatePath(os.path.join('special://profile/Thumbnails',''))\n    path=xbmc.translatePath(os.path.join('special://profile/Database',''))\n    dialog = xbmcgui.Dialog()\n    if dialog.yesno(localtxt1, localtxt3):\n        shutil.rmtree(thumbnails)\n        os.mkdir(thumbnails)\n        database = os.path.join(path, 'Textures*.db')\n        print database\n        filelist = glob.glob(database)\n        print filelist\n        if filelist != []:\n            for f in filelist:\n                print f\n                os.remove(f)\n                xbmc.executebuiltin(\"Notification(\"+localtxt2+\",\"+localtxt8+\", 5000, %s)\" % (image))\n                time.sleep(3)\n                xbmc.executebuiltin(\"Reboot\")\n        else:\n            print 'merdaa'\n            xbmc.executebuiltin(\"Notification(\"+localtxt9+\",\"+localtxt10+\", 5000, %s)\" % (image))\n#-------------------\ndef advanced():\n    localtxt1 = __language__(32006)+__language__(32003)\n    dialog = xbmcgui.Dialog()\n    if dialog.yesno(localtxt1, localtxt3):\n        path = xbmc.translatePath(os.path.join('special://profile/userdata',''))\n        advance=os.path.join(path, 'advancedsettings.xml')\n        try:\n            os.remove(advance)\n            xbmc.executebuiltin(\"Notification(,\"+localtxt2+\")\")\n        except:\n            xbmc.executebuiltin(\"Notification(\"+localtxt9+\",\"+localtxt10+\", 5000, %s)\" % (image))\n#-------------------\ndef viewsdb():\n    localtxt1 = __language__(32006)+__language__(32011)\n    path = xbmc.translatePath(os.path.join('special://profile/Database',''))\n    if dialog.yesno(localtxt1, localtxt3):\n        database = os.path.join(path, 'ViewModes*.db')\n        print database\n        filelist = glob.glob(database)\n        print filelist\n        if filelist != []:\n            for f in filelist:\n                print f\n                os.remove(f)\n                xbmc.executebuiltin(\"Notification(\"+localtxt2+\",\"+localtxt8+\", 5000, %s)\" % (image))\n                time.sleep(3)\n                xbmc.executebuiltin(\"Reboot\")\n        else:\n            print 'merdaa'\n            xbmc.executebuiltin(\"Notification(\"+localtxt9+\",\"+localtxt10+\", 5000, %s)\" % (image))\n#-------------------\ndef date():\n    localtxt1 = __language__(32012)\n    localtxt4 = __language__(32013)\n    localtxt5 = __language__(32014)\n    destpath=xbmc.translatePath(os.path.join('/storage/.cache/connman',''))\n    if dialog.yesno(localtxt1, localtxt3):\n        shutil.rmtree(destpath)\n        os.mkdir(destpath)\n        xbmc.executebuiltin(\"Notification(\"+localtxt4+\",\"+localtxt5+\", 5000, %s)\" % (image))\n\txbmc.sleep(1000)\n\txbmc.restart()\n#-------------------\ndef notify(header=\"\", message=\"\", icon=image, time=5000, sound=True):\n    dialog = xbmcgui.Dialog()\n    dialog.notification(heading=\"Service Clean Up\", message=\"This Addon needs arguments to run\", icon=icon, time=time, sound=sound)\n#-------------------\ndef donate():\n    localtxt1 = __language__(32929)\n    localtxt2 = __language__(32930)\n    localtxt3 = __language__(32931)\n    localtxt4 = __language__(32932)\n    localtxt5 = __language__(32933)\n    localtxt6 = __language__(32934)\n\t\n    xbmc.executebuiltin(\"Notification(\"+localtxt1+\",\"+localtxt2+\",7000)\")\n    time.sleep(7)\n    xbmc.executebuiltin(\"Notification(\"+localtxt3+\",\"+localtxt4+\",7000)\")\n    time.sleep(7)\n    xbmc.executebuiltin(\"Notification(\"+localtxt5+\",\"+localtxt6+\",7000)\")\n    time.sleep(7)\n#-------------------\nif prnum == 'cache':\n    cache()\nelif prnum == 'packages':\n    packages()\nelif prnum == 'videodb':\n    videodb()\nelif prnum == 'musicdb':\n    musicdb()\nelif prnum == 'thumbs':\n    thumbs()\n", "outputs": ["elif prnum == 'advanced':"], "input_length": 1426, "output_length": 6, "length": 1432, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "925163551289322cb994a88b949fb53f5b8f69e1489ad9a4956137d18cc505c9"}
{"input": "", "context": "import cPickle\nimport wave\nimport gzip\nimport scipy\nimport scipy.io.wavfile\nfrom matplotlib import pylab\nimport scipy.io.wavfile\nimport os\nfrom numpy import *\nfrom pydub import AudioSegment\nfrom pyechonest import track, config\nimport numpy\nimport mfcc_diy\nclass Dataset:\n    \"\"\"Slices, shuffles and manages a small dataset for the HF optimizer.\"\"\"\n    def __init__(self, data, batch_size, number_batches=None, targets=None):\n        '''SequenceDataset __init__\n  data : list of lists of numpy arrays\n    Your dataset will be provided as a list (one list for each graph input) of\n    variable-length tensors that will be used as mini-batches. Typically, each\n    tensor is a sequence or a set of examples.\n  batch_size : int or None\n    If an int, the mini-batches will be further split in chunks of length\n    `batch_size`. This is useful for slicing subsequences or provide the full\n    dataset in a single tensor to be split here. All tensors in `data` must\n    then have the same leading dimension.\n  number_batches : int\n    Number of mini-batches over which you iterate to compute a gradient or\n    Gauss-Newton matrix product. If None, it will iterate over the entire dataset.\n  minimum_size : int\n    Reject all mini-batches that end up smaller than this length.'''\n        self.current_batch = 0\n        self.number_batches = number_batches\n        self.items = []\n        if targets is None:\n            if batch_size is None:\n                # self.items.append([data[i][i_sequence] for i in xrange(len(data))])\n                self.items = [[data[i]] for i in xrange(len(data))]\n            else:\n                # self.items = [sequence[i:i+batch_size] for sequence in data for i in xrange(0, len(sequence), batch_size)]\n                for sequence in data:\n                    num_batches = sequence.shape[0] / float(batch_size)\n                    num_batches = numpy.ceil(num_batches)\n                    for i in xrange(int(num_batches)):\n                        start = i * batch_size\n                        end = (i + 1) * batch_size\n                        if end > sequence.shape[0]:\n                            end = sequence.shape[0]\n                        self.items.append([sequence[start:end]])\n        else:\n            if batch_size is None:\n                self.items = [[data[i], targets[i]] for i in xrange(len(data))]\n            else:\n                for sequence, sequence_targets in zip(data, targets):\n                    num_batches = sequence.shape[0] / float(batch_size)\n                    num_batches = numpy.ceil(num_batches)\n                    for i in xrange(int(num_batches)):\n                        start = i * batch_size\n                        end = (i + 1) * batch_size\n                        if end > sequence.shape[0]:\n                            end = sequence.shape[0]\n                        self.items.append([sequence[start:end], sequence_targets[start:end]])\n        if not self.number_batches:\n            self.number_batches = len(self.items)\n        self.num_min_batches = len(self.items)\n        self.shuffle()\n    def shuffle(self):\n        numpy.random.shuffle(self.items)\n    def iterate(self, update=True):\n        for b in xrange(self.number_batches):\n            yield self.items[(self.current_batch + b) % len(self.items)]\n        if update: self.update()\n    def update(self):\n        if self.current_batch + self.number_batches >= len(self.items):\n            self.shuffle()\n            self.current_batch = 0\n        else:\n            self.current_batch += self.number_batches\ndef load_audio(song_dir):\n    file_format = song_dir.split('.')[1]\n    if 'wav' == file_format:\n        song = wave.open(song_dir, \"rb\")\n        params = song.getparams()\n        nchannels, samplewidth, framerate, nframes = params[:4]  # format info\n        song_data = song.readframes(nframes)\n        song.close()\n        wave_data = numpy.fromstring(song_data, dtype=numpy.short)\n        wave_data.shape = -1, 2\n        wave_data = wave_data.T\n    else:\n        raise NameError(\"now just support wav format audio files\")\n    return wave_data\ndef pickle_dataset(dataset, out_pkl='dataset.pkl'):\n    # pickle the file and for long time save\n    pkl_file = file(out_pkl, 'wb')\n    cPickle.dump(dataset, pkl_file, True)\n    pkl_file.close()\n    return 0\ndef build_song_set(songs_dir):\n    # save songs and singer lable to pickle file\n    songs_dataset = []\n    for parent, dirnames, filenames in os.walk(songs_dir):\n        for filename in filenames:\n            song_dir = os.path.join(parent, filename)\n            audio = load_audio(song_dir)\n            # change the value as your singer name level in the dir\n            # eg. short_wav/new_wav/dataset/singer_name so I set 3\n            singer = song_dir.split('/')[1]\n            # this value depends on the singer file level in the dir\n            songs_dataset.append((audio, singer))\n    pickle_dataset(songs_dataset, 'songs_audio_singer.pkl')\n    return 0\ndef load_data(pkl_dir='dataset.pkl'):\n    # load pickle data file\n    pkl_dataset = open(pkl_dir, 'rb')\n    dataset = cPickle.load(pkl_dataset)\n    pkl_dataset.close()\n    return dataset\ndef get_mono_left_right_audio(wavs_dir='mir1k-Wavfile'):\n    # split a audio to left and right channel\n    for parent, dirnames, filenames in os.walk(wavs_dir):\n        for filename in filenames:\n            audio_dir = os.path.join(parent, filename)\n            mono_sound_dir = 'mono/' + audio_dir\n            if not os.path.exists(os.path.split(mono_sound_dir)[0]):\n                os.makedirs(os.path.split(mono_sound_dir)[0])\n            left_audio_dir = 'left_right/' + os.path.splitext(mono_sound_dir)[0] + '_left.wav'\n            if not os.path.exists(os.path.split(left_audio_dir)[0]):\n                os.makedirs(os.path.split(left_audio_dir)[0])\n            right_audio_dir = 'left_right/' + os.path.splitext(mono_sound_dir)[0] + '_right.wav'\n            if not os.path.exists(os.path.split(right_audio_dir)[0]):\n                os.makedirs(os.path.split(right_audio_dir)[0])\n            sound = AudioSegment.from_wav(audio_dir)\n            mono = sound.set_channels(1)\n            left, right = sound.split_to_mono()\n            mono.export(mono_sound_dir, format='wav')\n            left.export(left_audio_dir, format='wav')\n            right.export(right_audio_dir, format='wav')\n    return 0\ndef get_right_voice_audio(wavs_dir='mir1k-Wavfile'):\n    # get singer voice from the right channel\n    for parent, dirnames, filenames in os.walk(wavs_dir):\n        for filename in filenames:\n            audio_dir = os.path.join(parent, filename)\n            right_audio_dir = 'right_voices/' + os.path.splitext(audio_dir)[0] + '_right.wav'\n            if not os.path.exists(os.path.split(right_audio_dir)[0]):\n                os.makedirs(os.path.split(right_audio_dir)[0])\n            sound = AudioSegment.from_wav(audio_dir)\n            left, right = sound.split_to_mono()\n            right.export(right_audio_dir, format='wav')\n    return 0\ndef draw_wav(wav_dir):\n    '''\n    draw the wav audio to show\n    '''\n    song = wave.open(wav_dir, \"rb\")\n    params = song.getparams()\n    nchannels, samplewidth, framerate, nframes = params[:4]  # format info\n    song_data = song.readframes(nframes)\n    song.close()\n    wave_data = numpy.fromstring(song_data, dtype=numpy.short)\n    wave_data.shape = -1, 1\n    wave_data = wave_data.T\n    time = numpy.arange(0, nframes) * (1.0 / framerate)\n    len_time = len(time)\n    time = time[0:len_time]\n    pylab.plot(time, wave_data[0])\n    pylab.xlabel(\"time\")\n    pylab.ylabel(\"wav_data\")\n    pylab.show()\n    return 0\ndef get_mfcc(wav_dir):\n    # mfccs\n    sample_rate, audio = scipy.io.wavfile.read(wav_dir)\n    # ceps, mspec, spec = mfcc(audio, nwin=256, fs=8000, nceps=13)\n    ceps, mspec, spec = mfcc_diy.mfcc(audio, nwin=8000, fs=8000, nceps=13)\n    mfccs = ceps\n    return mfccs\ndef get_raw(wav_dir):\n    # raw audio data\n    sample_rate, audio = scipy.io.wavfile.read(wav_dir)\n    return audio\ndef filter_nan_inf(mfccss):\n    # filter the nan and inf data point of mfcc\n    filter_nan_infs = []\n    for item in mfccss:\n        new_item = []\n        for ii in item:\n            if numpy.isinf(ii):\n                ii = 1000\n            elif numpy.isnan(ii):\n                ii = -11\n            else:\n                ii = ii\n            new_item.append(ii)\n        filter_nan_infs.append(new_item)\n    new_mfcc = numpy.array(filter_nan_infs)\n    return new_mfcc\ndef get_timbre_pitches_loudness(wav_dir):\n    # from echonest capture the timbre and pitches loudness et.al.\n    config.ECHO_NEST_API_KEY = \"BPQ7TEP9JXXDVIXA5\"  # daleloogn my api key\n    f = open(wav_dir)\n    print \"process:============ %s =============\" % wav_dir\n    t = track.track_from_file(f, 'wav', 256, force_upload=True)\n    t.get_analysis()\n    segments = t.segments  # list of dicts :timing,pitch,loudness and timbre for each segment\n    timbre_pitches_loudness = from_segments_get_timbre_pitch_etal(wav_dir, segments)\n    timbre_pitches_loudness_file_txt = open('timbre_pitches_loudness_file.txt', 'a')\n    timbre_pitches_loudness_file_txt.write(wav_dir + '\\r\\n')\n    timbre_pitches_loudness_file_txt.write(str(timbre_pitches_loudness))\n    timbre_pitches_loudness_file_txt.close()\n    return segments\ndef draw_segments_from_echonest(wav_dir, starts_point):\n    # just draw it and show the difference duration of segments\n    song = wave.open(wav_dir, \"rb\")\n    params = song.getparams()\n    nchannels, samplewidth, framerate, nframes = params[:4]  # format info\n    song_data = song.readframes(nframes)\n    song.close()\n    wave_data = numpy.fromstring(song_data, dtype=numpy.short)\n    wave_data.shape = -1, 1\n    wave_data = wave_data.T\n    time = numpy.arange(0, nframes) * (1.0 / framerate)\n    len_time = len(time)\n    time = time[0:len_time]\n    pylab.plot(time, wave_data[0])\n    num_len = len(starts_point)\n    pylab.plot(starts_point, [1] * num_len, 'ro')\n    pylab.xlabel(\"time\")\n    pylab.ylabel(\"wav_data\")\n    pylab.show()\n    return 0\ndef from_segments_get_timbre_pitch_etal(wav_dir, segments):\n    # from segments get the feature you want\n    timbre_pitches_loudness = []\n    starts_point = []\n    for segments_item in segments:\n        timbre = segments_item['timbre']\n        pitches = segments_item['pitches']\n        loudness_start = segments_item['loudness_start']\n        loudness_max_time = segments_item['loudness_max_time']\n        loudness_max = segments_item['loudness_max']\n        durarion = segments_item['duration']\n        start = segments_item['start']\n        starts_point.append(start)\n        segments_item_union = timbre + pitches + [loudness_start, loudness_max_time, loudness_max]\n        timbre_pitches_loudness.append(segments_item_union)\n        ##plot the segments seg\n    draw_segments_from_echonest(wav_dir, starts_point)\n    ####\n    return timbre_pitches_loudness\ndef generate_singer_label(wavs_dir):\n    # generate the singer to label dict\n    dict_singer_label = {}\n    singers = []\n    for parent, dirnames, filenames in os.walk(wavs_dir):\n        for filename in filenames:\n            singer_name = filename.split('_')[0]\n            singers.append(singer_name)\n    only_singers = sorted(list(set(singers)))\n    for item, singer in enumerate(only_singers):\n        dict_singer_label[singer] = item\n    # print dict_singer_label\n    return dict_singer_label\ndef build_dataset(wavs_dir):\n    print 'from %s build dataset==============' % wavs_dir\n    dataset = []\n    data = []\n    target = []\n    dict_singer_label = generate_singer_label(wavs_dir)\n    for parent, dirnames, filenames in os.walk(wavs_dir):\n        for filename in filenames:\n            song_dir = os.path.join(parent, filename)\n            print\"get mfcc of %s ====\" % filename\n            song_feature = get_mfcc(song_dir)\n            song_feature = filter_nan_inf(song_feature)  # feature=======================a song mfcc vector\n            singer = filename.split('_')[0]  # this value depends on the singer file level in the dir\n            singer_label = dict_singer_label[singer]  # target class====================\n            # song_mfcc_sum_vector = mfcc_sum_vector(song_feature)\n            #  feature=======================a song mfcc vector sum\n            songs_mfcc_vecto_link = []\n            for vector_item in song_feature:\n                vector_item = [x for x in vector_item]\n                # songs_mfcc_vecto_link.extend(vector_item)\n                # data.append(songs_mfcc_vecto_link)  # feature just a frame\n                data.append(vector_item)\n                target.append(singer_label)\n    dataset.append(data)\n    # print data[1:50]\n    dataset.append(target)\n    print 'pkl_to dataset.pkl'\n    pickle_dataset(dataset)\n    return 0\ndef slice_wav_beigin_one_end_one(wav_dir):\n    # it used for cut the wav file head and end\n    new_dir = 'sliced/' + wav_dir\n    if not os.path.exists(os.path.split(new_dir)[0]):\n        os.makedirs(os.path.split(new_dir)[0])\n    audio = AudioSegment.from_wav(wav_dir)\n    one_seconds = 1 * 1000\n    first_five_seconds = audio[one_seconds:-2000]\n    first_five_seconds.export(new_dir, format='wav')\n    return 0\ndef slice_wavs_dirs(dirs):\n    # in batach to slice\n    for parent, dirnames, filenames in os.walk(dirs):\n        for filename in filenames:\n            song_dir = os.path.join(parent, filename)\n            slice_wav_beigin_one_end_one(song_dir)\n    return 0\ndef save_echonest_data_to_txt(wav_dirs):\n    # cache the data from the internet\n    for parent, dirnames, filenames in os.walk(wav_dirs):\n        for filename in filenames:\n            song_dir = os.path.join(parent, filename)\n            if not os.path.exists('save_segments.txt'):\n                segments_file = open('save_segments.txt', 'w')\n                segments_file.close()\n            segments_file = open('save_segments.txt', 'r')\n            all_lines = segments_file.readlines()\n            segments_file.close()\n            dirs = []\n            for line_item in all_lines:\n                dir_song = line_item.split('@')[0]\n                dirs.append(dir_song)\n            if song_dir in dirs:\n                pass\n            else:\n                segments = get_timbre_pitches_loudness(song_dir)\n                lines = song_dir + '@' + str(segments) + '\\r\\n'\n                segments_file = open('save_segments.txt', 'a', )\n                segments_file.write(lines)\n                segments_file.close()\n    return 0\ndef print_color(color=\"red or yellow\"):\n    # consloe out color\n    if color == 'red':\n        print '\\033[1;31;40m'\n", "outputs": ["    elif color == 'yellow':"], "input_length": 2396, "output_length": 6, "length": 2402, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "db307be78984140735edc36bacc0fc2567c42c34fc72f80f73c557a2f0dc8d05"}
{"input": "", "context": "# -*- test-case-name: twisted.python.test.test_util\n# Copyright (c) Twisted Matrix Laboratories.\n# See LICENSE for details.\n\"\"\"\nTests for L{twisted.python.util}.\n\"\"\"\nfrom __future__ import division, absolute_import\nimport errno\nimport os.path\nimport shutil\nimport sys\nimport warnings\ntry:\n    import pwd, grp\nexcept ImportError:\n    pwd = grp = None\nfrom twisted.trial import unittest\nfrom twisted.trial.util import suppress as SUPPRESS\nfrom twisted.python import util\nfrom twisted.python.filepath import FilePath\nfrom twisted.internet import reactor\nfrom twisted.internet.interfaces import IReactorProcess\nfrom twisted.internet.protocol import ProcessProtocol\nfrom twisted.internet.defer import Deferred\nfrom twisted.internet.error import ProcessDone\nfrom twisted.test.test_process import MockOS\npyExe = FilePath(sys.executable)._asBytesPath()\nclass UtilTests(unittest.TestCase):\n    def testUniq(self):\n        l = [\"a\", 1, \"ab\", \"a\", 3, 4, 1, 2, 2, 4, 6]\n        self.assertEqual(util.uniquify(l), [\"a\", 1, \"ab\", 3, 4, 2, 6])\n    def testRaises(self):\n        self.assertTrue(util.raises(ZeroDivisionError, divmod, 1, 0))\n        self.assertFalse(util.raises(ZeroDivisionError, divmod, 0, 1))\n        try:\n            util.raises(TypeError, divmod, 1, 0)\n        except ZeroDivisionError:\n            pass\n        else:\n            raise unittest.FailTest(\"util.raises didn't raise when it should have\")\n    def test_uidFromNumericString(self):\n        \"\"\"\n        When L{uidFromString} is called with a base-ten string representation\n        of an integer, it returns the integer.\n        \"\"\"\n        self.assertEqual(util.uidFromString(\"100\"), 100)\n    def test_uidFromUsernameString(self):\n        \"\"\"\n        When L{uidFromString} is called with a base-ten string representation\n        of an integer, it returns the integer.\n        \"\"\"\n        pwent = pwd.getpwuid(os.getuid())\n        self.assertEqual(util.uidFromString(pwent.pw_name), pwent.pw_uid)\n    if pwd is None:\n        test_uidFromUsernameString.skip = (\n            \"Username/UID conversion requires the pwd module.\")\n    def test_gidFromNumericString(self):\n        \"\"\"\n        When L{gidFromString} is called with a base-ten string representation\n        of an integer, it returns the integer.\n        \"\"\"\n        self.assertEqual(util.gidFromString(\"100\"), 100)\n    def test_gidFromGroupnameString(self):\n        \"\"\"\n        When L{gidFromString} is called with a base-ten string representation\n        of an integer, it returns the integer.\n        \"\"\"\n        grent = grp.getgrgid(os.getgid())\n        self.assertEqual(util.gidFromString(grent.gr_name), grent.gr_gid)\n    if grp is None:\n        test_gidFromGroupnameString.skip = (\n            \"Group Name/GID conversion requires the grp module.\")\nclass NameToLabelTests(unittest.TestCase):\n    \"\"\"\n    Tests for L{nameToLabel}.\n    \"\"\"\n    def test_nameToLabel(self):\n        \"\"\"\n        Test the various kinds of inputs L{nameToLabel} supports.\n        \"\"\"\n        nameData = [\n            ('f', 'F'),\n            ('fo', 'Fo'),\n            ('foo', 'Foo'),\n            ('fooBar', 'Foo Bar'),\n            ('fooBarBaz', 'Foo Bar Baz'),\n            ]\n        for inp, out in nameData:\n            got = util.nameToLabel(inp)\n            self.assertEqual(\n                got, out,\n                \"nameToLabel(%r) == %r != %r\" % (inp, got, out))\nclass UntilConcludesTests(unittest.TestCase):\n    \"\"\"\n    Tests for L{untilConcludes}, an C{EINTR} helper.\n    \"\"\"\n    def test_uninterruptably(self):\n        \"\"\"\n        L{untilConcludes} calls the function passed to it until the function\n        does not raise either L{OSError} or L{IOError} with C{errno} of\n        C{EINTR}.  It otherwise completes with the same result as the function\n        passed to it.\n        \"\"\"\n        def f(a, b):\n            self.calls += 1\n            exc = self.exceptions.pop()\n            if exc is not None:\n                raise exc(errno.EINTR, \"Interrupted system call!\")\n            return a + b\n        self.exceptions = [None]\n        self.calls = 0\n        self.assertEqual(util.untilConcludes(f, 1, 2), 3)\n        self.assertEqual(self.calls, 1)\n        self.exceptions = [None, OSError, IOError]\n        self.calls = 0\n        self.assertEqual(util.untilConcludes(f, 2, 3), 5)\n        self.assertEqual(self.calls, 3)\nclass SwitchUIDTests(unittest.TestCase):\n    \"\"\"\n    Tests for L{util.switchUID}.\n    \"\"\"\n    if getattr(os, \"getuid\", None) is None:\n        skip = \"getuid/setuid not available\"\n    def setUp(self):\n        self.mockos = MockOS()\n        self.patch(util, \"os\", self.mockos)\n        self.patch(util, \"initgroups\", self.initgroups)\n        self.initgroupsCalls = []\n    def initgroups(self, uid, gid):\n        \"\"\"\n        Save L{util.initgroups} calls in C{self.initgroupsCalls}.\n        \"\"\"\n        self.initgroupsCalls.append((uid, gid))\n    def test_uid(self):\n        \"\"\"\n        L{util.switchUID} calls L{util.initgroups} and then C{os.setuid} with\n        the given uid.\n        \"\"\"\n        util.switchUID(12000, None)\n        self.assertEqual(self.initgroupsCalls, [(12000, None)])\n        self.assertEqual(self.mockos.actions, [(\"setuid\", 12000)])\n    def test_euid(self):\n        \"\"\"\n        L{util.switchUID} calls L{util.initgroups} and then C{os.seteuid} with\n        the given uid if the C{euid} parameter is set to C{True}.\n        \"\"\"\n        util.switchUID(12000, None, True)\n        self.assertEqual(self.initgroupsCalls, [(12000, None)])\n        self.assertEqual(self.mockos.seteuidCalls, [12000])\n    def test_currentUID(self):\n        \"\"\"\n        If the current uid is the same as the uid passed to L{util.switchUID},\n        then initgroups does not get called, but a warning is issued.\n        \"\"\"\n        uid = self.mockos.getuid()\n        util.switchUID(uid, None)\n        self.assertEqual(self.initgroupsCalls, [])\n        self.assertEqual(self.mockos.actions, [])\n        currentWarnings = self.flushWarnings([util.switchUID])\n        self.assertEqual(len(currentWarnings), 1)\n        self.assertIn('tried to drop privileges and setuid %i' % uid,\n                      currentWarnings[0]['message'])\n        self.assertIn(\n            'but uid is already %i' % uid, currentWarnings[0]['message'])\n    def test_currentEUID(self):\n        \"\"\"\n        If the current euid is the same as the euid passed to L{util.switchUID},\n        then initgroups does not get called, but a warning is issued.\n        \"\"\"\n        euid = self.mockos.geteuid()\n        util.switchUID(euid, None, True)\n        self.assertEqual(self.initgroupsCalls, [])\n        self.assertEqual(self.mockos.seteuidCalls, [])\n        currentWarnings = self.flushWarnings([util.switchUID])\n        self.assertEqual(len(currentWarnings), 1)\n        self.assertIn('tried to drop privileges and seteuid %i' % euid,\n                      currentWarnings[0]['message'])\n        self.assertIn(\n            'but euid is already %i' % euid, currentWarnings[0]['message'])\nclass MergeFunctionMetadataTests(unittest.TestCase):\n    \"\"\"\n    Tests for L{mergeFunctionMetadata}.\n    \"\"\"\n    def test_mergedFunctionBehavesLikeMergeTarget(self):\n        \"\"\"\n        After merging C{foo}'s data into C{bar}, the returned function behaves\n        as if it is C{bar}.\n        \"\"\"\n        foo_object = object()\n        bar_object = object()\n        def foo():\n            return foo_object\n        def bar(x, y, ab, c=10, *d, **e):\n            (a, b) = ab\n            return bar_object\n        baz = util.mergeFunctionMetadata(foo, bar)\n        self.assertIdentical(baz(1, 2, (3, 4), quux=10), bar_object)\n    def test_moduleIsMerged(self):\n        \"\"\"\n        Merging C{foo} into C{bar} returns a function with C{foo}'s\n        C{__module__}.\n        \"\"\"\n        def foo():\n            pass\n        def bar():\n            pass\n        bar.__module__ = 'somewhere.else'\n        baz = util.mergeFunctionMetadata(foo, bar)\n        self.assertEqual(baz.__module__, foo.__module__)\n    def test_docstringIsMerged(self):\n        \"\"\"\n        Merging C{foo} into C{bar} returns a function with C{foo}'s docstring.\n        \"\"\"\n        def foo():\n            \"\"\"\n            This is foo.\n            \"\"\"\n        def bar():\n            \"\"\"\n            This is bar.\n            \"\"\"\n        baz = util.mergeFunctionMetadata(foo, bar)\n        self.assertEqual(baz.__doc__, foo.__doc__)\n    def test_nameIsMerged(self):\n        \"\"\"\n        Merging C{foo} into C{bar} returns a function with C{foo}'s name.\n        \"\"\"\n        def foo():\n            pass\n        def bar():\n            pass\n        baz = util.mergeFunctionMetadata(foo, bar)\n        self.assertEqual(baz.__name__, foo.__name__)\n    def test_instanceDictionaryIsMerged(self):\n        \"\"\"\n        Merging C{foo} into C{bar} returns a function with C{bar}'s\n        dictionary, updated by C{foo}'s.\n        \"\"\"\n        def foo():\n            pass\n        foo.a = 1\n        foo.b = 2\n        def bar():\n            pass\n        bar.b = 3\n        bar.c = 4\n        baz = util.mergeFunctionMetadata(foo, bar)\n        self.assertEqual(foo.a, baz.a)\n        self.assertEqual(foo.b, baz.b)\n        self.assertEqual(bar.c, baz.c)\nclass OrderedDictTests(unittest.TestCase):\n    \"\"\"\n    Tests for L{util.OrderedDict}.\n    \"\"\"\n    def test_deprecated(self):\n        \"\"\"\n        L{util.OrderedDict} is deprecated.\n        \"\"\"\n        from twisted.python.util import OrderedDict\n        OrderedDict # Shh pyflakes\n        currentWarnings = self.flushWarnings(offendingFunctions=[\n            self.test_deprecated])\n        self.assertEqual(\n            currentWarnings[0]['message'],\n            \"twisted.python.util.OrderedDict was deprecated in Twisted \"\n            \"15.5.0: Use collections.OrderedDict instead.\")\n        self.assertEqual(currentWarnings[0]['category'], DeprecationWarning)\n        self.assertEqual(len(currentWarnings), 1)\nclass InsensitiveDictTests(unittest.TestCase):\n    \"\"\"\n    Tests for L{util.InsensitiveDict}.\n    \"\"\"\n    def test_preserve(self):\n        \"\"\"\n        L{util.InsensitiveDict} preserves the case of keys if constructed with\n        C{preserve=True}.\n        \"\"\"\n        dct = util.InsensitiveDict({'Foo':'bar', 1:2, 'fnz':{1:2}}, preserve=1)\n        self.assertEqual(dct['fnz'], {1:2})\n        self.assertEqual(dct['foo'], 'bar')\n        self.assertEqual(dct.copy(), dct)\n        self.assertEqual(dct['foo'], dct.get('Foo'))\n        self.assertIn(1, dct)\n        self.assertIn('foo', dct)\n        result = eval(repr(dct), {\n            'dct': dct,\n            'InsensitiveDict': util.InsensitiveDict,\n            })\n        self.assertEqual(result, dct)\n        keys=['Foo', 'fnz', 1]\n        for x in keys:\n            self.assertIn(x, dct.keys())\n            self.assertIn((x, dct[x]), dct.items())\n        self.assertEqual(len(keys), len(dct))\n        del dct[1]\n        del dct['foo']\n        self.assertEqual(dct.keys(), ['fnz'])\n    def test_noPreserve(self):\n        \"\"\"\n        L{util.InsensitiveDict} does not preserves the case of keys if\n        constructed with C{preserve=False}.\n        \"\"\"\n        dct = util.InsensitiveDict({'Foo':'bar', 1:2, 'fnz':{1:2}}, preserve=0)\n        keys=['foo', 'fnz', 1]\n        for x in keys:\n            self.assertIn(x, dct.keys())\n            self.assertIn((x, dct[x]), dct.items())\n        self.assertEqual(len(keys), len(dct))\n        del dct[1]\n        del dct['foo']\n        self.assertEqual(dct.keys(), ['fnz'])\n    def test_unicode(self):\n        \"\"\"\n        Unicode keys are case insensitive.\n        \"\"\"\n        d = util.InsensitiveDict(preserve=False)\n        d[u\"Foo\"] = 1\n        self.assertEqual(d[u\"FOO\"], 1)\n        self.assertEqual(d.keys(), [u\"foo\"])\n    def test_bytes(self):\n        \"\"\"\n        Bytes keys are case insensitive.\n        \"\"\"\n        d = util.InsensitiveDict(preserve=False)\n        d[b\"Foo\"] = 1\n        self.assertEqual(d[b\"FOO\"], 1)\n        self.assertEqual(d.keys(), [b\"foo\"])\nclass PasswordTestingProcessProtocol(ProcessProtocol):\n    \"\"\"\n    Write the string C{\"secret\\n\"} to a subprocess and then collect all of\n    its output and fire a Deferred with it when the process ends.\n    \"\"\"\n    def connectionMade(self):\n        self.output = []\n        self.transport.write(b'secret\\n')\n    def childDataReceived(self, fd, output):\n        self.output.append((fd, output))\n    def processEnded(self, reason):\n        self.finished.callback((reason, self.output))\nclass GetPasswordTests(unittest.TestCase):\n    if not IReactorProcess.providedBy(reactor):\n        skip = \"Process support required to test getPassword\"\n    def test_stdin(self):\n        \"\"\"\n        Making sure getPassword accepts a password from standard input by\n        running a child process which uses getPassword to read in a string\n        which it then writes it out again.  Write a string to the child\n        process and then read one and make sure it is the right string.\n        \"\"\"\n        p = PasswordTestingProcessProtocol()\n        p.finished = Deferred()\n        reactor.spawnProcess(\n            p, pyExe,\n            [pyExe,\n             b'-c',\n             (b'import sys\\n'\n              b'from twisted.python.util import getPassword\\n'\n              b'sys.stdout.write(getPassword())\\n'\n              b'sys.stdout.flush()\\n')],\n            env={b'PYTHONPATH': os.pathsep.join(sys.path).encode(\"utf8\")})\n        def processFinished(result):\n            (reason, output) = result\n            reason.trap(ProcessDone)\n            self.assertIn((1, b'secret'), output)\n        return p.finished.addCallback(processFinished)\nclass SearchUpwardsTests(unittest.TestCase):\n    def testSearchupwards(self):\n        os.makedirs('searchupwards/a/b/c')\n        open('searchupwards/foo.txt', 'w').close()\n        open('searchupwards/a/foo.txt', 'w').close()\n        open('searchupwards/a/b/c/foo.txt', 'w').close()\n        os.mkdir('searchupwards/bar')\n        os.mkdir('searchupwards/bam')\n        os.mkdir('searchupwards/a/bar')\n        os.mkdir('searchupwards/a/b/bam')\n        actual=util.searchupwards('searchupwards/a/b/c',\n                                  files=['foo.txt'],\n                                  dirs=['bar', 'bam'])\n        expected=os.path.abspath('searchupwards') + os.sep\n        self.assertEqual(actual, expected)\n        shutil.rmtree('searchupwards')\n        actual=util.searchupwards('searchupwards/a/b/c',\n                                  files=['foo.txt'],\n                                  dirs=['bar', 'bam'])\n        expected=None\n        self.assertEqual(actual, expected)\nclass IntervalDifferentialTests(unittest.TestCase):\n    def testDefault(self):\n        d = iter(util.IntervalDifferential([], 10))\n        for i in range(100):\n            self.assertEqual(next(d), (10, None))\n    def testSingle(self):\n        d = iter(util.IntervalDifferential([5], 10))\n        for i in range(100):\n            self.assertEqual(next(d), (5, 0))\n    def testPair(self):\n        d = iter(util.IntervalDifferential([5, 7], 10))\n        for i in range(100):\n            self.assertEqual(next(d), (5, 0))\n            self.assertEqual(next(d), (2, 1))\n            self.assertEqual(next(d), (3, 0))\n            self.assertEqual(next(d), (4, 1))\n            self.assertEqual(next(d), (1, 0))\n            self.assertEqual(next(d), (5, 0))\n            self.assertEqual(next(d), (1, 1))\n            self.assertEqual(next(d), (4, 0))\n            self.assertEqual(next(d), (3, 1))\n            self.assertEqual(next(d), (2, 0))\n            self.assertEqual(next(d), (5, 0))\n            self.assertEqual(next(d), (0, 1))\n    def testTriple(self):\n        d = iter(util.IntervalDifferential([2, 4, 5], 10))\n        for i in range(100):\n            self.assertEqual(next(d), (2, 0))\n            self.assertEqual(next(d), (2, 0))\n            self.assertEqual(next(d), (0, 1))\n            self.assertEqual(next(d), (1, 2))\n            self.assertEqual(next(d), (1, 0))\n            self.assertEqual(next(d), (2, 0))\n            self.assertEqual(next(d), (0, 1))\n            self.assertEqual(next(d), (2, 0))\n            self.assertEqual(next(d), (0, 2))\n            self.assertEqual(next(d), (2, 0))\n            self.assertEqual(next(d), (0, 1))\n            self.assertEqual(next(d), (2, 0))\n            self.assertEqual(next(d), (1, 2))\n            self.assertEqual(next(d), (1, 0))\n            self.assertEqual(next(d), (0, 1))\n            self.assertEqual(next(d), (2, 0))\n            self.assertEqual(next(d), (2, 0))\n            self.assertEqual(next(d), (0, 1))\n            self.assertEqual(next(d), (0, 2))\n    def testInsert(self):\n        d = iter(util.IntervalDifferential([], 10))\n        self.assertEqual(next(d), (10, None))\n        d.addInterval(3)\n        self.assertEqual(next(d), (3, 0))\n        self.assertEqual(next(d), (3, 0))\n        d.addInterval(6)\n        self.assertEqual(next(d), (3, 0))\n        self.assertEqual(next(d), (3, 0))\n        self.assertEqual(next(d), (0, 1))\n        self.assertEqual(next(d), (3, 0))\n        self.assertEqual(next(d), (3, 0))\n        self.assertEqual(next(d), (0, 1))\n    def testRemove(self):\n        d = iter(util.IntervalDifferential([3, 5], 10))\n        self.assertEqual(next(d), (3, 0))\n        self.assertEqual(next(d), (2, 1))\n        self.assertEqual(next(d), (1, 0))\n        d.removeInterval(3)\n        self.assertEqual(next(d), (4, 0))\n        self.assertEqual(next(d), (5, 0))\n        d.removeInterval(5)\n        self.assertEqual(next(d), (10, None))\n        self.assertRaises(ValueError, d.removeInterval, 10)\nclass Record(util.FancyEqMixin):\n    \"\"\"\n    Trivial user of L{FancyEqMixin} used by tests.\n    \"\"\"\n    compareAttributes = ('a', 'b')\n    def __init__(self, a, b):\n        self.a = a\n        self.b = b\nclass DifferentRecord(util.FancyEqMixin):\n    \"\"\"\n    Trivial user of L{FancyEqMixin} which is not related to L{Record}.\n    \"\"\"\n    compareAttributes = ('a', 'b')\n    def __init__(self, a, b):\n        self.a = a\n        self.b = b\nclass DerivedRecord(Record):\n    \"\"\"\n    A class with an inheritance relationship to L{Record}.\n    \"\"\"\nclass EqualToEverything(object):\n    \"\"\"\n    A class the instances of which consider themselves equal to everything.\n    \"\"\"\n    def __eq__(self, other):\n        return True\n    def __ne__(self, other):\n        return False\nclass EqualToNothing(object):\n    \"\"\"\n    A class the instances of which consider themselves equal to nothing.\n    \"\"\"\n    def __eq__(self, other):\n        return False\n    def __ne__(self, other):\n        return True\nclass EqualityTests(unittest.TestCase):\n    \"\"\"\n    Tests for L{FancyEqMixin}.\n    \"\"\"\n    def test_identity(self):\n        \"\"\"\n        Instances of a class which mixes in L{FancyEqMixin} but which\n        defines no comparison attributes compare by identity.\n        \"\"\"\n        class Empty(util.FancyEqMixin):\n            pass\n        self.assertFalse(Empty() == Empty())\n        self.assertTrue(Empty() != Empty())\n        empty = Empty()\n        self.assertTrue(empty == empty)\n        self.assertFalse(empty != empty)\n    def test_equality(self):\n        \"\"\"\n        Instances of a class which mixes in L{FancyEqMixin} should compare\n        equal if all of their attributes compare equal.  They should not\n        compare equal if any of their attributes do not compare equal.\n        \"\"\"\n        self.assertTrue(Record(1, 2) == Record(1, 2))\n        self.assertFalse(Record(1, 2) == Record(1, 3))\n        self.assertFalse(Record(1, 2) == Record(2, 2))\n        self.assertFalse(Record(1, 2) == Record(3, 4))\n    def test_unequality(self):\n        \"\"\"\n        Inequality between instances of a particular L{record} should be\n        defined as the negation of equality.\n        \"\"\"\n        self.assertFalse(Record(1, 2) != Record(1, 2))\n        self.assertTrue(Record(1, 2) != Record(1, 3))\n        self.assertTrue(Record(1, 2) != Record(2, 2))\n        self.assertTrue(Record(1, 2) != Record(3, 4))\n    def test_differentClassesEquality(self):\n        \"\"\"\n        Instances of different classes which mix in L{FancyEqMixin} should not\n        compare equal.\n        \"\"\"\n        self.assertFalse(Record(1, 2) == DifferentRecord(1, 2))\n    def test_differentClassesInequality(self):\n        \"\"\"\n        Instances of different classes which mix in L{FancyEqMixin} should\n        compare unequal.\n        \"\"\"\n        self.assertTrue(Record(1, 2) != DifferentRecord(1, 2))\n    def test_inheritedClassesEquality(self):\n        \"\"\"\n        An instance of a class which derives from a class which mixes in\n        L{FancyEqMixin} should compare equal to an instance of the base class\n        if and only if all of their attributes compare equal.\n        \"\"\"\n        self.assertTrue(Record(1, 2) == DerivedRecord(1, 2))\n        self.assertFalse(Record(1, 2) == DerivedRecord(1, 3))\n        self.assertFalse(Record(1, 2) == DerivedRecord(2, 2))\n        self.assertFalse(Record(1, 2) == DerivedRecord(3, 4))\n    def test_inheritedClassesInequality(self):\n        \"\"\"\n        An instance of a class which derives from a class which mixes in\n        L{FancyEqMixin} should compare unequal to an instance of the base\n        class if any of their attributes compare unequal.\n        \"\"\"\n        self.assertFalse(Record(1, 2) != DerivedRecord(1, 2))\n        self.assertTrue(Record(1, 2) != DerivedRecord(1, 3))\n        self.assertTrue(Record(1, 2) != DerivedRecord(2, 2))\n        self.assertTrue(Record(1, 2) != DerivedRecord(3, 4))\n    def test_rightHandArgumentImplementsEquality(self):\n        \"\"\"\n        The right-hand argument to the equality operator is given a chance\n        to determine the result of the operation if it is of a type\n        unrelated to the L{FancyEqMixin}-based instance on the left-hand\n        side.\n        \"\"\"\n        self.assertTrue(Record(1, 2) == EqualToEverything())\n        self.assertFalse(Record(1, 2) == EqualToNothing())\n    def test_rightHandArgumentImplementsUnequality(self):\n        \"\"\"\n        The right-hand argument to the non-equality operator is given a\n        chance to determine the result of the operation if it is of a type\n        unrelated to the L{FancyEqMixin}-based instance on the left-hand\n        side.\n        \"\"\"\n        self.assertFalse(Record(1, 2) != EqualToEverything())\n        self.assertTrue(Record(1, 2) != EqualToNothing())\nclass RunAsEffectiveUserTests(unittest.TestCase):\n    \"\"\"\n    Test for the L{util.runAsEffectiveUser} function.\n    \"\"\"\n    if getattr(os, \"geteuid\", None) is None:\n        skip = \"geteuid/seteuid not available\"\n    def setUp(self):\n        self.mockos = MockOS()\n        self.patch(os, \"geteuid\", self.mockos.geteuid)\n        self.patch(os, \"getegid\", self.mockos.getegid)\n        self.patch(os, \"seteuid\", self.mockos.seteuid)\n        self.patch(os, \"setegid\", self.mockos.setegid)\n    def _securedFunction(self, startUID, startGID, wantUID, wantGID):\n        \"\"\"\n        Check if wanted UID/GID matched start or saved ones.\n        \"\"\"\n        self.assertTrue(wantUID == startUID or\n                        wantUID == self.mockos.seteuidCalls[-1])\n        self.assertTrue(wantGID == startGID or\n                        wantGID == self.mockos.setegidCalls[-1])\n    def test_forwardResult(self):\n        \"\"\"\n        L{util.runAsEffectiveUser} forwards the result obtained by calling the\n        given function\n        \"\"\"\n        result = util.runAsEffectiveUser(0, 0, lambda: 1)\n        self.assertEqual(result, 1)\n    def test_takeParameters(self):\n        \"\"\"\n        L{util.runAsEffectiveUser} pass the given parameters to the given\n        function.\n        \"\"\"\n        result = util.runAsEffectiveUser(0, 0, lambda x: 2*x, 3)\n        self.assertEqual(result, 6)\n    def test_takesKeyworkArguments(self):\n        \"\"\"\n        L{util.runAsEffectiveUser} pass the keyword parameters to the given\n        function.\n        \"\"\"\n        result = util.runAsEffectiveUser(0, 0, lambda x, y=1, z=1: x*y*z, 2, z=3)\n        self.assertEqual(result, 6)\n    def _testUIDGIDSwitch(self, startUID, startGID, wantUID, wantGID,\n                          expectedUIDSwitches, expectedGIDSwitches):\n        \"\"\"\n        Helper method checking the calls to C{os.seteuid} and C{os.setegid}\n        made by L{util.runAsEffectiveUser}, when switching from startUID to\n        wantUID and from startGID to wantGID.\n        \"\"\"\n        self.mockos.euid = startUID\n        self.mockos.egid = startGID\n        util.runAsEffectiveUser(\n            wantUID, wantGID,\n            self._securedFunction, startUID, startGID, wantUID, wantGID)\n        self.assertEqual(self.mockos.seteuidCalls, expectedUIDSwitches)\n        self.assertEqual(self.mockos.setegidCalls, expectedGIDSwitches)\n        self.mockos.seteuidCalls = []\n        self.mockos.setegidCalls = []\n    def test_root(self):\n        \"\"\"\n        Check UID/GID switches when current effective UID is root.\n        \"\"\"\n        self._testUIDGIDSwitch(0, 0, 0, 0, [], [])\n        self._testUIDGIDSwitch(0, 0, 1, 0, [1, 0], [])\n        self._testUIDGIDSwitch(0, 0, 0, 1, [], [1, 0])\n        self._testUIDGIDSwitch(0, 0, 1, 1, [1, 0], [1, 0])\n    def test_UID(self):\n        \"\"\"\n        Check UID/GID switches when current effective UID is non-root.\n        \"\"\"\n        self._testUIDGIDSwitch(1, 0, 0, 0, [0, 1], [])\n        self._testUIDGIDSwitch(1, 0, 1, 0, [], [])\n        self._testUIDGIDSwitch(1, 0, 1, 1, [0, 1, 0, 1], [1, 0])\n", "outputs": ["        self._testUIDGIDSwitch(1, 0, 2, 1, [0, 2, 0, 1], [1, 0])"], "input_length": 5048, "output_length": 26, "length": 5074, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "1e3c73cc99c6c5f4c8b0a71258379e3ebf6b2496601b96f0c6345820d9debce0"}
{"input": "", "context": "using System;\nusing System.Collections.Generic;\nusing System.Drawing;\nusing System.Linq;\nusing System.Management;\nusing System.Text;\nusing System.Windows.Forms;\nusing GitCommands;\nusing GitCommands.Git;\nusing GitCommands.Patches;\nusing GitExtUtils.GitUI;\nusing GitUIPluginInterfaces;\nusing Microsoft.WindowsAPICodePack.Dialogs;\nusing ResourceManager;\nnamespace GitUI.CommandsDialogs\n{\n    public sealed partial class FormStash : GitModuleForm\n    {\n        private readonly TranslationString _currentWorkingDirChanges = new(\"Current working directory changes\");\n        private readonly TranslationString _noStashes = new(\"There are no stashes.\");\n        private readonly TranslationString _stashUntrackedFilesNotSupportedCaption = new(\"Stash untracked files\");\n        private readonly TranslationString _stashUntrackedFilesNotSupported = new(\"Stash untracked files is not supported in the version of msysgit you are using. Please update msysgit to at least version 1.7.7 to use this option.\");\n        private readonly TranslationString _stashDropConfirmTitle = new(\"Drop Stash Confirmation\");\n        private readonly TranslationString _cannotBeUndone = new(\"This action cannot be undone.\");\n        private readonly TranslationString _areYouSure = new(\"Are you sure you want to drop the stash? This action cannot be undone.\");\n        private readonly TranslationString _dontShowAgain = new(\"Don't show me this message again.\");\n        private readonly AsyncLoader _asyncLoader = new();\n        public bool ManageStashes { get; set; }\n        private GitStash _currentWorkingDirStashItem;\n        [Obsolete(\"For VS designer and translation test only. Do not remove.\")]\n        private FormStash()\n        {\n            InitializeComponent();\n            CompleteTheInitialization();\n        }\n        public FormStash(GitUICommands commands)\n            : base(commands)\n        {\n            InitializeComponent();\n            View.ExtraDiffArgumentsChanged += delegate { StashedSelectedIndexChanged(null, null); };\n            View.TopScrollReached += FileViewer_TopScrollReached;\n            View.BottomScrollReached += FileViewer_BottomScrollReached;\n            CompleteTheInitialization();\n        }\n        private void CompleteTheInitialization()\n        {\n            KeyPreview = true;\n            View.EscapePressed += () => DialogResult = DialogResult.Cancel;\n            splitContainer1.SplitterDistance = DpiUtil.Scale(280);\n            InitializeComplete();\n        }\n        protected override void OnKeyDown(KeyEventArgs e)\n        {\n            if (e.KeyCode == Keys.Escape && e.Modifiers == Keys.None)\n            {\n                var focusedControl = this.FindFocusedControl();\n                var comboBox = focusedControl as ComboBox;\n                if (comboBox is not null && comboBox.DroppedDown)\n                {\n                    comboBox.DroppedDown = false;\n                }\n                else\n                {\n                    var textBox = focusedControl as TextBoxBase;\n                    if (textBox is not null && textBox.SelectionLength > 0)\n                    {\n                        textBox.SelectionLength = 0;\n                    }\n                    else\n                    {\n                        DialogResult = DialogResult.Cancel;\n                    }\n                }\n                // do not let the modal form react itself on this preview of the Escape key press\n                e.SuppressKeyPress = true;\n                e.Handled = true;\n            }\n            base.OnKeyDown(e);\n        }\n        protected override void OnKeyUp(KeyEventArgs e)\n        {\n            if (e.KeyCode == Keys.Escape && e.Modifiers == Keys.None)\n            {\n                // do not let the modal form react itself on this preview of the Escape key press\n                e.SuppressKeyPress = true;\n                e.Handled = true;\n            }\n            base.OnKeyUp(e);\n        }\n        private void FormStashFormClosing(object sender, FormClosingEventArgs e)\n        {\n            AppSettings.StashKeepIndex = StashKeepIndex.Checked;\n            AppSettings.IncludeUntrackedFilesInManualStash = chkIncludeUntrackedFiles.Checked;\n        }\n        private void FormStashLoad(object sender, EventArgs e)\n        {\n            StashKeepIndex.Checked = AppSettings.StashKeepIndex;\n            chkIncludeUntrackedFiles.Checked = AppSettings.IncludeUntrackedFilesInManualStash;\n            ResizeStashesWidth();\n        }\n        private void Initialize()\n        {\n            var stashedItems = Module.GetStashes().ToList();\n            _currentWorkingDirStashItem = new GitStash(-1, _currentWorkingDirChanges.Text);\n            stashedItems.Insert(0, _currentWorkingDirStashItem);\n            Stashes.Text = \"\";\n            StashMessage.Text = \"\";\n            Stashes.SelectedItem = null;\n            Stashes.ComboBox.DisplayMember = nameof(GitStash.Message);\n            Stashes.Items.Clear();\n            foreach (GitStash stashedItem in stashedItems)\n            {\n                Stashes.Items.Add(stashedItem);\n            }\n            if (ManageStashes && Stashes.Items.Count > 1)\n            {\n                // more than just the default (\"Current working directory changes\")\n                Stashes.SelectedIndex = 1; // -> auto-select first non-default\n            }\n            else if (Stashes.Items.Count > 0)\n            {\n                // (no stashes) -> select default (\"Current working directory changes\")\n                Stashes.SelectedIndex = 0;\n            }\n        }\n        private void InitializeSoft()\n        {\n            GitStash gitStash = Stashes.SelectedItem as GitStash;\n            Stashed.GroupByRevision = false;\n            Stashed.ClearDiffs();\n            Loading.Visible = true;\n            Loading.IsAnimating = true;\n            Stashes.Enabled = false;\n            refreshToolStripButton.Enabled = false;\n            toolStripButton_customMessage.Enabled = false;\n            if (gitStash == _currentWorkingDirStashItem)\n            {\n                toolStripButton_customMessage.Enabled = true;\n                _asyncLoader.LoadAsync(() => Module.GetAllChangedFiles(), LoadGitItemStatuses);\n                Clear.Enabled = false; // disallow Drop  (of current working directory)\n                Apply.Enabled = false; // disallow Apply (of current working directory)\n            }\n            else if (gitStash is not null)\n            {\n                _asyncLoader.LoadAsync(() => Module.GetStashDiffFiles(gitStash.Name), LoadGitItemStatuses);\n                Clear.Enabled = true; // allow Drop\n                Apply.Enabled = true; // allow Apply\n            }\n        }\n        private void FileViewer_TopScrollReached(object sender, EventArgs e)\n        {\n            Stashed.SelectPreviousVisibleItem();\n            View.ScrollToBottom();\n        }\n        private void FileViewer_BottomScrollReached(object sender, EventArgs e)\n        {\n            Stashed.SelectNextVisibleItem();\n            View.ScrollToTop();\n        }\n        private void LoadGitItemStatuses(IReadOnlyList<GitItemStatus> gitItemStatuses)\n        {\n            GitStash gitStash = Stashes.SelectedItem as GitStash;\n            if (gitStash == _currentWorkingDirStashItem)\n            {\n                // FileStatusList has no interface for both worktree<-index, index<-HEAD at the same time\n                // Must be handled when displaying\n                var headId = Module.RevParse(\"HEAD\");\n                var headRev = new GitRevision(headId);\n                var indexRev = new GitRevision(ObjectId.IndexId)\n                {\n                    ParentIds = new[] { headId }\n                };\n                var workTreeRev = new GitRevision(ObjectId.WorkTreeId)\n                {\n                    ParentIds = new[] { ObjectId.IndexId }\n                };\n                var indexItems = gitItemStatuses.Where(item => item.Staged == StagedStatus.Index).ToList();\n                var workTreeItems = gitItemStatuses.Where(item => item.Staged != StagedStatus.Index).ToList();\n                Stashed.SetStashDiffs(headRev, indexRev, ResourceManager.Strings.Index, indexItems, workTreeRev, ResourceManager.Strings.Workspace, workTreeItems);\n            }\n            else\n            {\n", "outputs": ["                var firstId = Module.RevParse(gitStash.Name + \"^\");"], "input_length": 1028, "output_length": 12, "length": 1040, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "fb093786052b3e459acaef52c54a958f9ee45da000cb2a073a71a70ee5a4d416"}
{"input": "", "context": "# -*- coding: utf-8 -*-\nfrom django.db import models, migrations\nfrom django.conf import settings\nclass Migration(migrations.Migration):\n    dependencies = [\n        ('creation', '__first__'),\n        migrations.swappable_dependency(settings.AUTH_USER_MODEL),\n    ]\n    operations = [\n        migrations.CreateModel(\n            name='AcademicCenter',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('academic_code', models.CharField(unique=True, max_length=100)),\n                ('institution_name', models.CharField(max_length=200)),\n                ('address', models.TextField()),\n                ('pincode', models.PositiveIntegerField()),\n                ('resource_center', models.BooleanField()),\n                ('rating', models.PositiveSmallIntegerField()),\n                ('contact_person', models.TextField()),\n                ('remarks', models.TextField()),\n                ('status', models.BooleanField()),\n                ('created', models.DateTimeField(auto_now_add=True)),\n                ('updated', models.DateTimeField(auto_now=True)),\n            ],\n            options={\n                'verbose_name': 'Academic Center',\n            },\n        ),\n        migrations.CreateModel(\n            name='City',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('name', models.CharField(max_length=200)),\n                ('created', models.DateTimeField(auto_now_add=True, null=True)),\n                ('updated', models.DateTimeField(auto_now=True, null=True)),\n            ],\n        ),\n        migrations.CreateModel(\n            name='Course',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('name', models.CharField(max_length=200)),\n                ('created', models.DateTimeField(auto_now_add=True)),\n                ('updated', models.DateTimeField(auto_now=True)),\n            ],\n        ),\n        migrations.CreateModel(\n            name='CourseMap',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('test', models.BooleanField(default=False)),\n                ('category', models.PositiveIntegerField(default=0)),\n                ('created', models.DateTimeField(auto_now_add=True)),\n                ('updated', models.DateTimeField(auto_now=True)),\n            ],\n            options={\n                'ordering': ('foss',),\n            },\n        ),\n        migrations.CreateModel(\n            name='Department',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('name', models.CharField(max_length=200)),\n                ('created', models.DateTimeField(auto_now_add=True)),\n                ('updated', models.DateTimeField(auto_now=True)),\n            ],\n            options={\n                'ordering': ['name'],\n            },\n        ),\n        migrations.CreateModel(\n            name='District',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('code', models.CharField(max_length=3)),\n                ('name', models.CharField(max_length=200)),\n                ('created', models.DateTimeField(auto_now_add=True, null=True)),\n                ('updated', models.DateTimeField(auto_now=True, null=True)),\n            ],\n        ),\n        migrations.CreateModel(\n            name='EventsNotification',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('role', models.PositiveSmallIntegerField(default=0)),\n                ('category', models.PositiveSmallIntegerField(default=0)),\n                ('categoryid', models.PositiveIntegerField(default=0)),\n                ('status', models.PositiveSmallIntegerField(default=0)),\n                ('message', models.CharField(max_length=255)),\n                ('created', models.DateTimeField(auto_now_add=True)),\n                ('academic', models.ForeignKey(to='events.AcademicCenter')),\n                ('user', models.ForeignKey(to=settings.AUTH_USER_MODEL)),\n            ],\n        ),\n        migrations.CreateModel(\n            name='FossMdlCourses',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('mdlcourse_id', models.PositiveIntegerField()),\n                ('mdlquiz_id', models.PositiveIntegerField()),\n                ('foss', models.ForeignKey(to='creation.FossCategory')),\n            ],\n        ),\n        migrations.CreateModel(\n            name='InstituteCategory',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('name', models.CharField(max_length=200)),\n                ('created', models.DateTimeField(auto_now_add=True)),\n                ('updated', models.DateTimeField(auto_now=True)),\n            ],\n            options={\n                'verbose_name': 'Institute Categorie',\n            },\n        ),\n        migrations.CreateModel(\n            name='InstituteType',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('name', models.CharField(max_length=200)),\n                ('created', models.DateTimeField(auto_now_add=True)),\n                ('updated', models.DateTimeField(auto_now=True)),\n            ],\n        ),\n        migrations.CreateModel(\n            name='Invigilator',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('status', models.PositiveSmallIntegerField(default=0)),\n                ('created', models.DateTimeField(auto_now_add=True)),\n                ('updated', models.DateTimeField(auto_now=True)),\n                ('academic', models.ForeignKey(to='events.AcademicCenter')),\n                ('appoved_by', models.ForeignKey(related_name='invigilator_approved_by', blank=True, to=settings.AUTH_USER_MODEL, null=True)),\n                ('user', models.OneToOneField(to=settings.AUTH_USER_MODEL)),\n            ],\n        ),\n        migrations.CreateModel(\n            name='LabCourse',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('name', models.CharField(max_length=200)),\n                ('created', models.DateTimeField(auto_now_add=True)),\n                ('updated', models.DateTimeField(auto_now=True)),\n            ],\n        ),\n        migrations.CreateModel(\n            name='Location',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('name', models.CharField(max_length=200)),\n                ('pincode', models.PositiveIntegerField()),\n                ('created', models.DateTimeField(auto_now_add=True, null=True)),\n                ('updated', models.DateTimeField(auto_now=True)),\n                ('district', models.ForeignKey(to='events.District')),\n            ],\n        ),\n        migrations.CreateModel(\n            name='Organiser',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('status', models.PositiveSmallIntegerField(default=0)),\n                ('created', models.DateTimeField(auto_now_add=True)),\n                ('updated', models.DateTimeField(auto_now=True)),\n                ('academic', models.ForeignKey(blank=True, to='events.AcademicCenter', null=True)),\n                ('appoved_by', models.ForeignKey(related_name='organiser_approved_by', blank=True, to=settings.AUTH_USER_MODEL, null=True)),\n                ('user', models.OneToOneField(related_name='organiser', to=settings.AUTH_USER_MODEL)),\n            ],\n        ),\n        migrations.CreateModel(\n            name='OrganiserNotification',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('user', models.ForeignKey(to=settings.AUTH_USER_MODEL)),\n            ],\n        ),\n        migrations.CreateModel(\n            name='Permission',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('created', models.DateTimeField(auto_now_add=True)),\n                ('updated', models.DateTimeField(auto_now=True)),\n                ('assigned_by', models.ForeignKey(related_name='permission_assigned_by', to=settings.AUTH_USER_MODEL)),\n                ('district', models.ForeignKey(related_name='permission_district', to='events.District', null=True)),\n                ('institute', models.ForeignKey(related_name='permission_district', to='events.AcademicCenter', null=True)),\n                ('institute_type', models.ForeignKey(related_name='permission_institution_type', to='events.InstituteType', null=True)),\n            ],\n        ),\n        migrations.CreateModel(\n            name='PermissionType',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('name', models.CharField(max_length=200)),\n                ('created', models.DateTimeField(auto_now_add=True)),\n                ('updated', models.DateTimeField(auto_now=True)),\n            ],\n        ),\n        migrations.CreateModel(\n            name='ResourcePerson',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('assigned_by', models.PositiveIntegerField()),\n                ('status', models.BooleanField()),\n                ('created', models.DateTimeField(auto_now_add=True)),\n                ('updated', models.DateTimeField(auto_now=True)),\n            ],\n            options={\n                'verbose_name': 'Resource Person',\n            },\n        ),\n        migrations.CreateModel(\n            name='Semester',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('name', models.CharField(max_length=50)),\n                ('even', models.BooleanField(default=True)),\n            ],\n        ),\n        migrations.CreateModel(\n            name='SingleTraining',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('training_type', models.PositiveIntegerField(default=0)),\n                ('tdate', models.DateField()),\n                ('ttime', models.TimeField()),\n                ('status', models.PositiveSmallIntegerField(default=0)),\n                ('participant_count', models.PositiveIntegerField(default=0)),\n                ('created', models.DateTimeField()),\n                ('updated', models.DateTimeField()),\n                ('academic', models.ForeignKey(to='events.AcademicCenter')),\n                ('course', models.ForeignKey(to='events.CourseMap')),\n                ('language', models.ForeignKey(to='creation.Language')),\n                ('organiser', models.ForeignKey(to='events.Organiser')),\n            ],\n        ),\n        migrations.CreateModel(\n            name='SingleTrainingAttendance',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('firstname', models.CharField(max_length=100, null=True)),\n                ('lastname', models.CharField(max_length=100, null=True)),\n                ('gender', models.CharField(max_length=10, null=True)),\n                ('email', models.EmailField(max_length=254, null=True)),\n                ('password', models.CharField(max_length=100, null=True)),\n                ('count', models.PositiveSmallIntegerField(default=0)),\n                ('status', models.PositiveSmallIntegerField(default=0)),\n                ('created', models.DateTimeField()),\n                ('updated', models.DateTimeField()),\n                ('training', models.ForeignKey(to='events.SingleTraining')),\n            ],\n        ),\n        migrations.CreateModel(\n            name='State',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('code', models.CharField(max_length=3)),\n                ('name', models.CharField(max_length=50)),\n                ('slug', models.CharField(max_length=100)),\n                ('latitude', models.DecimalField(null=True, max_digits=10, decimal_places=4, blank=True)),\n                ('longtitude', models.DecimalField(null=True, max_digits=10, decimal_places=4, blank=True)),\n                ('img_map_area', models.TextField()),\n", "outputs": ["                ('created', models.DateTimeField(auto_now_add=True, null=True)),"], "input_length": 1863, "output_length": 12, "length": 1875, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "17b1ad22097b5551260b43f8540ae7aa8809b49b53911df9d7172e170bd20ab2"}
{"input": "", "context": "# Copy this file to app_server/settings.py and adjust to your specification (it should work fine out of the box)\n# Django settings for django_agfk project.\nimport os\nimport sys\nSETTINGS_PATH = os.path.realpath(os.path.dirname(__file__))\nCLIENT_SERVER_PATH = SETTINGS_PATH\nAGFK_PATH = os.path.realpath(os.path.join(SETTINGS_PATH, '../'))\nsys.path.append(AGFK_PATH)\nimport config\nADMINS = (\n    # ('Your Name', 'your_email@example.com'),\n)\nMANAGERS = ADMINS\nDATABASES = {\n    'default': {\n        'ENGINE': 'django.db.backends.sqlite3',  # Add 'postgresql_psycopg2', 'mysql', 'sqlite3' or 'oracle'.\n        'NAME': config.DJANGO_DB_FILE,                 # Or path to database file if using sqlite3.\n        'USER': '',                      # Not used with sqlite3.\n        'PASSWORD': '',                  # Not used with sqlite3.\n        'HOST': '',                      # Set to empty string for localhost. Not used with sqlite3.\n        'PORT': '',                      # Set to empty string for default. Not used with sqlite3.\n    }\n}\n# Local time zone for this installation. Choices can be found here:\n# http://en.wikipedia.org/wiki/List_of_tz_zones_by_name\n# although not all choices may be available on all operating systems.\n# On Unix systems, a value of None will cause Django to use the same\n# timezone as the operating system.\n# If running in a Windows environment this must be set to the same as your\n# system time zone.\nTIME_ZONE = 'America/Chicago'\n# Language code for this installation. All choices can be found here:\n# http://www.i18nguy.com/unicode/language-identifiers.html\nLANGUAGE_CODE = 'en-us'\nSITE_ID = 1\n# If you set this to False, Django will make some optimizations so as not\n# to load the internationalization machinery.\nUSE_I18N = True\n# If you set this to False, Django will not format dates, numbers and\n# calendars according to the current locale.\nUSE_L10N = True\n# If you set this to False, Django will not use timezone-aware datetimes.\nUSE_TZ = True\n# Absolute filesystem path to the directory that will hold user-uploaded files.\n# Example: \"/home/media/media.lawrence.com/media/\"\nMEDIA_ROOT = ''\n# URL that handles the media served from MEDIA_ROOT. Make sure to use a\n# trailing slash.\n# Examples: \"http://media.lawrence.com/media/\", \"http://example.com/media/\"\nMEDIA_URL = ''\n# Absolute path to the directory static files should be collected to.\n# Don't put anything in this directory yourself; store your static files\n# in apps' \"static/\" subdirectories and in STATICFILES_DIRS.\n# Example: \"/home/media/media.lawrence.com/static/\"\nSTATIC_ROOT = os.path.join(CLIENT_SERVER_PATH, 'static/media')\n# URL prefix for static files.\n# Example: \"http://media.lawrence.com/static/\"\nSTATIC_URL = '/static/'\n# Additional locations of static files\nSTATICFILES_DIRS = (\n    ('css',os.path.join(CLIENT_SERVER_PATH, 'static/css')),\n    ('images',os.path.join(CLIENT_SERVER_PATH, 'static/images')),\n    ('fonts',os.path.join(CLIENT_SERVER_PATH, 'static/fonts')),\n    ('javascript',os.path.join(CLIENT_SERVER_PATH, 'static/javascript')),\n    ('lib',os.path.join(CLIENT_SERVER_PATH, 'static/lib'))\n)\n# List of finder classes that know how to find static files in\n# various locations.\nSTATICFILES_FINDERS = (\n    'django.contrib.staticfiles.finders.FileSystemFinder',\n    'django.contrib.staticfiles.finders.AppDirectoriesFinder',\n    'compressor.finders.CompressorFinder'\n    #    'django.contrib.staticfiles.finders.DefaultStorageFinder',\n)\n# List of callables that know how to import templates from various sources.\nTEMPLATE_LOADERS = (\n    'django.template.loaders.filesystem.Loader',\n    'django.template.loaders.app_directories.Loader',\n    'django.template.loaders.eggs.Loader'\n)\nMIDDLEWARE_CLASSES = (\n    'django.middleware.common.CommonMiddleware',\n    'django.contrib.sessions.middleware.SessionMiddleware',\n    'django.middleware.csrf.CsrfViewMiddleware',\n    'django.contrib.auth.middleware.AuthenticationMiddleware',\n    'django.contrib.messages.middleware.MessageMiddleware',\n    # Uncomment the next line for simple clickjacking protection:\n    # 'django.middleware.clickjacking.XFrameOptionsMiddleware',\n)\nROOT_URLCONF = 'urls'\n# Python dotted path to the WSGI application used by Django's runserver.\nWSGI_APPLICATION = 'wsgi.application'\nTEMPLATE_DIRS = (\n    os.path.join(CLIENT_SERVER_PATH,'static/html/'),\n    os.path.join(CLIENT_SERVER_PATH,'static/html/underscore-templates/'),\n    os.path.join(CLIENT_SERVER_PATH,'static/html/content-editing/')\n)\nINSTALLED_APPS = (\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.sites',\n    'django.contrib.messages',\n    'django.contrib.staticfiles',\n    'django.contrib.admin',\n    'django.contrib.admindocs',\n    'apps.graph',\n    'apps.user_management',\n    'apps.roadmaps',\n    'apps.browser_tests',\n    'haystack',\n    'captcha',\n    'compressor',\n    'lazysignup',\n    'reversion',\n    'tastypie'\n)\n# apps settings\nCAPTCHA_NOISE_FUNCTIONS = ()\nCAPTCHA_LETTER_ROTATION = (-10,10)\nCAPTCHA_FONT_SIZE = 24\nCAPTCHA_CHALLENGE_FUNCT = 'captcha.helpers.math_challenge'\nHAYSTACK_CONNECTIONS = {\n    'default': {\n        'ENGINE': 'haystack.backends.whoosh_backend.WhooshEngine',\n        'PATH': os.path.join(config.APP_SERVER_SEARCH_INDEX_PATH, 'whoosh_index'),\n    },\n}\n# TODO we may want to eventually switch to queued processing\n# https://github.com/toastdriven/queued_search\nHAYSTACK_SIGNAL_PROCESSOR = 'haystack.signals.RealtimeSignalProcessor'\nHAYSTACK_DEFAULT_OPERATOR = 'AND'\nSESSION_SAVE_EVERY_REQUEST = True\n# context processors\nTEMPLATE_CONTEXT_PROCESSORS = (\"django.contrib.auth.context_processors.auth\",\n                               \"django.core.context_processors.debug\",\n                               \"django.core.context_processors.media\",\n                               \"django.core.context_processors.static\",\n                               \"django.core.context_processors.tz\",\n                               \"django.contrib.messages.context_processors.messages\",\n                               )\n# A sample logging configuration. The only tangible logging\n# performed by this configuration is to send an email to\n# the site admins on every HTTP 500 error when DEBUG=False.\n# See http://docs.djangoproject.com/en/dev/topics/logging for\n# more details on how to customize your logging configuration.\nLOGGING = {\n    'version': 1,\n    'disable_existing_loggers': False,\n    'filters': {\n        'require_debug_false': {\n            '()': 'django.utils.log.RequireDebugFalse'\n        }\n    },\n    'handlers': {\n        'mail_admins': {\n            'level': 'ERROR',\n            'filters': ['require_debug_false'],\n            'class': 'django.utils.log.AdminEmailHandler'\n        }\n    },\n    'loggers': {\n        'django.request': {\n            'handlers': ['mail_admins'],\n            'level': 'ERROR',\n            'propagate': True,\n        },\n    }\n}\nAUTHENTICATION_BACKENDS = (\n    'django.contrib.auth.backends.ModelBackend',\n    'lazysignup.backends.LazySignupBackend',\n)\n# default URL to redirect to after login\nLOGIN_REDIRECT_URL = '/user'\nINTERNAL_IPS = (\"127.0.0.1\",)\nAPP_SERVER = 'http://' + str(config.FRONTEND_SERVER_IP) + \":\" + str(config.FRONTEND_SERVER_PORT)\nfrom settings_local import *\n", "outputs": ["if DEBUG and len(sys.argv) > 1:"], "input_length": 1047, "output_length": 10, "length": 1057, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "bec2a27fbea89b131d42ff53304384146d6d8215d12a10c7451af832f061138c"}
{"input": "", "context": "\"\"\"\nACE parser\nFrom wotsit.org and the SDK header (bitflags)\nPartial study of a new block type (5) I've called \"new_recovery\", as its\nsyntax is very close to the former one (of type 2).\nStatus: can only read totally file and header blocks.\nAuthor: Christophe Gisquet <christophe.gisquet@free.fr>\nCreation date: 19 january 2006\n\"\"\"\nfrom hachoir_py2.parser import Parser\nfrom hachoir_py2.field import (StaticFieldSet, FieldSet,\n                               Bit, Bits, NullBits, RawBytes, Enum,\n                               UInt8, UInt16, UInt32,\n                               PascalString8, PascalString16, String,\n                               TimeDateMSDOS32)\nfrom hachoir_py2.core.text_handler import textHandler, filesizeHandler, hexadecimal\nfrom hachoir_py2.core.endian import LITTLE_ENDIAN\nfrom hachoir_py2.parser.common.msdos import MSDOSFileAttr32\nMAGIC = \"**ACE**\"\nOS_MSDOS = 0\nOS_WIN32 = 2\nHOST_OS = {\n    0: \"MS-DOS\",\n    1: \"OS/2\",\n    2: \"Win32\",\n    3: \"Unix\",\n    4: \"MAC-OS\",\n    5: \"Win NT\",\n    6: \"Primos\",\n    7: \"APPLE GS\",\n    8: \"ATARI\",\n    9: \"VAX VMS\",\n    10: \"AMIGA\",\n    11: \"NEXT\",\n}\nCOMPRESSION_TYPE = {\n    0: \"Store\",\n    1: \"Lempel-Ziv 77\",\n    2: \"ACE v2.0\",\n}\nCOMPRESSION_MODE = {\n    0: \"fastest\",\n    1: \"fast\",\n    2: \"normal\",\n    3: \"good\",\n    4: \"best\",\n}\n# TODO: Computing the CRC16 would also prove useful\n# def markerValidate(self):\n#    return not self[\"extend\"].value and self[\"signature\"].value == MAGIC and \\\n#           self[\"host_os\"].value<12\nclass MarkerFlags(StaticFieldSet):\n    format = (\n        (Bit, \"extend\", \"Whether the header is extended\"),\n        (Bit, \"has_comment\", \"Whether the archive has a comment\"),\n        (NullBits, \"unused\", 7, \"Reserved bits\"),\n        (Bit, \"sfx\", \"SFX\"),\n        (Bit, \"limited_dict\", \"Junior SFX with 256K dictionary\"),\n        (Bit, \"multi_volume\", \"Part of a set of ACE archives\"),\n        (Bit, \"has_av_string\", \"This header holds an AV-string\"),\n        (Bit, \"recovery_record\", \"Recovery record preset\"),\n        (Bit, \"locked\", \"Archive is locked\"),\n        (Bit, \"solid\", \"Archive uses solid compression\")\n    )\ndef markerFlags(self):\n    yield MarkerFlags(self, \"flags\", \"Marker flags\")\ndef markerHeader(self):\n    yield String(self, \"signature\", 7, \"Signature\")\n    yield UInt8(self, \"ver_extract\", \"Version needed to extract archive\")\n    yield UInt8(self, \"ver_created\", \"Version used to create archive\")\n    yield Enum(UInt8(self, \"host_os\", \"OS where the files were compressed\"), HOST_OS)\n    yield UInt8(self, \"vol_num\", \"Volume number\")\n    yield TimeDateMSDOS32(self, \"time\", \"Date and time (MS DOS format)\")\n    yield Bits(self, \"reserved\", 64, \"Reserved size for future extensions\")\n    flags = self[\"flags\"]\n    if flags[\"has_av_string\"].value:\n        yield PascalString8(self, \"av_string\", \"AV String\")\n    if flags[\"has_comment\"].value:\n        size = filesizeHandler(UInt16(self, \"comment_size\", \"Comment size\"))\n        yield size\n        if size.value > 0:\n            yield RawBytes(self, \"compressed_comment\", size.value, \\\n                           \"Compressed comment\")\nclass FileFlags(StaticFieldSet):\n    format = (\n        (Bit, \"extend\", \"Whether the header is extended\"),\n        (Bit, \"has_comment\", \"Presence of file comment\"),\n        (Bits, \"unused\", 10, \"Unused bit flags\"),\n        (Bit, \"encrypted\", \"File encrypted with password\"),\n        (Bit, \"previous\", \"File continued from previous volume\"),\n        (Bit, \"next\", \"File continues on the next volume\"),\n        (Bit, \"solid\", \"File compressed using previously archived files\")\n    )\ndef fileFlags(self):\n    yield FileFlags(self, \"flags\", \"File flags\")\ndef fileHeader(self):\n    yield filesizeHandler(UInt32(self, \"compressed_size\", \"Size of the compressed file\"))\n    yield filesizeHandler(UInt32(self, \"uncompressed_size\", \"Uncompressed file size\"))\n    yield TimeDateMSDOS32(self, \"ftime\", \"Date and time (MS DOS format)\")\n    if self[\"/header/host_os\"].value in (OS_MSDOS, OS_WIN32):\n        yield MSDOSFileAttr32(self, \"file_attr\", \"File attributes\")\n    else:\n        yield textHandler(UInt32(self, \"file_attr\", \"File attributes\"), hexadecimal)\n    yield textHandler(UInt32(self, \"file_crc32\", \"CRC32 checksum over the compressed file)\"), hexadecimal)\n    yield Enum(UInt8(self, \"compression_type\", \"Type of compression\"), COMPRESSION_TYPE)\n    yield Enum(UInt8(self, \"compression_mode\", \"Quality of compression\"), COMPRESSION_MODE)\n    yield textHandler(UInt16(self, \"parameters\", \"Compression parameters\"), hexadecimal)\n    yield textHandler(UInt16(self, \"reserved\", \"Reserved data\"), hexadecimal)\n    # Filename\n    yield PascalString16(self, \"filename\", \"Filename\")\n    # Comment\n    if self[\"flags/has_comment\"].value:\n        yield filesizeHandler(UInt16(self, \"comment_size\", \"Size of the compressed comment\"))\n        if self[\"comment_size\"].value > 0:\n            yield RawBytes(self, \"comment_data\", self[\"comment_size\"].value, \"Comment data\")\ndef fileBody(self):\n    size = self[\"compressed_size\"].value\n    if size > 0:\n        yield RawBytes(self, \"compressed_data\", size, \"Compressed data\")\ndef fileDesc(self):\n    return \"File entry: %s (%s)\" % (self[\"filename\"].value, self[\"compressed_size\"].display)\ndef recoveryHeader(self):\n    yield filesizeHandler(UInt32(self, \"rec_blk_size\", \"Size of recovery data\"))\n    self.body_size = self[\"rec_blk_size\"].size\n    yield String(self, \"signature\", 7, \"Signature, normally '**ACE**'\")\n    yield textHandler(UInt32(self, \"relative_start\",\n                             \"Relative start (to this block) of the data this block is mode of\"),\n                      hexadecimal)\n    yield UInt32(self, \"num_blocks\", \"Number of blocks the data is split into\")\n    yield UInt32(self, \"size_blocks\", \"Size of these blocks\")\n    yield UInt16(self, \"crc16_blocks\", \"CRC16 over recovery data\")\n    # size_blocks blocks of size size_blocks follow\n    # The ultimate data is the xor data of all those blocks\n    size = self[\"size_blocks\"].value\n    for index in xrange(self[\"num_blocks\"].value):\n        yield RawBytes(self, \"data[]\", size, \"Recovery block %i\" % index)\n    yield RawBytes(self, \"xor_data\", size, \"The XOR value of the above data blocks\")\ndef recoveryDesc(self):\n    return \"Recovery block, size=%u\" % self[\"body_size\"].display\ndef newRecoveryHeader(self):\n    \"\"\"\n    This header is described nowhere\n    \"\"\"\n    if self[\"flags/extend\"].value:\n        yield filesizeHandler(UInt32(self, \"body_size\", \"Size of the unknown body following\"))\n        self.body_size = self[\"body_size\"].value\n    yield textHandler(UInt32(self, \"unknown[]\", \"Unknown field, probably 0\"),\n                      hexadecimal)\n    yield String(self, \"signature\", 7, \"Signature, normally '**ACE**'\")\n    yield textHandler(UInt32(self, \"relative_start\",\n                             \"Offset (=crc16's) of this block in the file\"), hexadecimal)\n    yield textHandler(UInt32(self, \"unknown[]\",\n                             \"Unknown field, probably 0\"), hexadecimal)\nclass BaseFlags(StaticFieldSet):\n    format = (\n        (Bit, \"extend\", \"Whether the header is extended\"),\n        (NullBits, \"unused\", 15, \"Unused bit flags\")\n    )\ndef parseFlags(self):\n    yield BaseFlags(self, \"flags\", \"Unknown flags\")\ndef parseHeader(self):\n    if self[\"flags/extend\"].value:\n        yield filesizeHandler(UInt32(self, \"body_size\", \"Size of the unknown body following\"))\n        self.body_size = self[\"body_size\"].value\ndef parseBody(self):\n    if self.body_size > 0:\n        yield RawBytes(self, \"body_data\", self.body_size, \"Body data, unhandled\")\nclass Block(FieldSet):\n    TAG_INFO = {\n        0: (\"header\", \"Archiver header\", markerFlags, markerHeader, None),\n        1: (\"file[]\", fileDesc, fileFlags, fileHeader, fileBody),\n        2: (\"recovery[]\", recoveryDesc, recoveryHeader, None, None),\n        5: (\"new_recovery[]\", None, None, newRecoveryHeader, None)\n    }\n    def __init__(self, parent, name, description=None):\n        FieldSet.__init__(self, parent, name, description)\n        self.body_size = 0\n        self.desc_func = None\n        type = self[\"block_type\"].value\n        if type in self.TAG_INFO:\n            self._name, desc, self.parseFlags, self.parseHeader, self.parseBody = self.TAG_INFO[type]\n            if desc:\n                if isinstance(desc, str):\n                    self._description = desc\n                else:\n                    self.desc_func = desc\n        else:\n            self.warning(\"Processing as unknown block block of type %u\" % type)\n        if not self.parseFlags:\n            self.parseFlags = parseFlags\n        if not self.parseHeader:\n            self.parseHeader = parseHeader\n        if not self.parseBody:\n            self.parseBody = parseBody\n    def createFields(self):\n        yield textHandler(UInt16(self, \"crc16\", \"Archive CRC16 (from byte 4 on)\"), hexadecimal)\n        yield filesizeHandler(UInt16(self, \"head_size\", \"Block size (from byte 4 on)\"))\n        yield UInt8(self, \"block_type\", \"Block type\")\n        # Flags\n        for flag in self.parseFlags(self):\n            yield flag\n        # Rest of the header\n        for field in self.parseHeader(self):\n            yield field\n        size = self[\"head_size\"].value - (self.current_size // 8) + (2 + 2)\n        if size > 0:\n            yield RawBytes(self, \"extra_data\", size, \"Extra header data, unhandled\")\n        # Body in itself\n        for field in self.parseBody(self):\n            yield field\n    def createDescription(self):\n        if self.desc_func:\n            return self.desc_func(self)\n        else:\n", "outputs": ["            return \"Block: %s\" % self[\"type\"].display"], "input_length": 2140, "output_length": 15, "length": 2155, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "6f9710bc20a2fbd15e1c378a6ba1d2069248492e137a70bae64b2393702aee35"}
{"input": "", "context": "/*\n * To change this license header, choose License Headers in Project Properties.\n * To change this template file, choose Tools | Templates\n * and open the template in the editor.\n */\npackage ac.factory;\nimport elsu.events.*;\nimport ac.core.*;\nimport elsu.database.*;\nimport elsu.support.*;\nimport java.lang.reflect.*;\nimport java.util.*;\n/**\n *\n * @author ss.dhaliwal\n */\npublic class ActionFactory extends AbstractEventManager implements IEventPublisher, IEventSubscriber {\n    private ConfigLoader _config = null;\n    private Map<String, Object> _dbManager = new HashMap<>();\n    public ActionFactory(ConfigLoader config) throws Exception {\n        setConfig(config);\n        setDbManager();\n        initialize();\n        notifyListeners(new EventObject(this), EventStatusType.INFORMATION,\n                getClass().toString() + \", ActionFactory(), \"\n                + \"contructor completed.\", null);\n    }\n    public ActionFactory(ConfigLoader config, IEventSubscriber owner) throws Exception {\n    \taddEventListener(owner);\n    \t\n        setConfig(config);\n        setDbManager();\n        initialize();\n        notifyListeners(new EventObject(this), EventStatusType.INFORMATION,\n                getClass().toString() + \", ActionFactory(), \"\n                + \"contructor completed.\", null);\n    }\n    public ActionFactory(ConfigLoader config, Object dbManager) throws Exception {\n        setConfig(config);\n        setDbManager(\"default\", dbManager);\n        initialize();\n        notifyListeners(new EventObject(this), EventStatusType.INFORMATION,\n                getClass().toString() + \", ActionFactory(), \"\n                + \"contructor completed.\", null);\n    }\n    public ActionFactory(ConfigLoader config, Object dbManager, IEventSubscriber owner) throws Exception {\n    \taddEventListener(owner);\n    \t\n        setConfig(config);\n        setDbManager(\"default\", dbManager);\n        initialize();\n        notifyListeners(new EventObject(this), EventStatusType.INFORMATION,\n                getClass().toString() + \", ActionFactory(), \"\n                + \"contructor completed.\", null);\n    }\n    private void initialize() throws Exception {\n        /*\n         String syncProvider = getSyncProvider();\n         boolean installed = false;\n         if ((syncProvider != null) && (!syncProvider.isEmpty())) {\n         java.util.Enumeration e = SyncFactory.getRegisteredProviders();\n         while (e.hasMoreElements()) {\n         e.nextElement();\n         if (e.getClass().toString().replaceAll(\"class \", \"\").equals(syncProvider)) {\n         installed = true;\n         break;\n         }\n         }\n         if (!installed) {\n         SyncFactory.registerProvider(syncProvider);\n         // log error for tracking\n         getConfig().logInfo(getClass().toString() + \", initialize(), \"\n         + \"sync provider installed.\");\n         } else {\n         // log error for tracking\n         getConfig().logError(getClass().toString() + \", initialize(), \"\n         + \"sync provider already installed.\");\n         }\n         }\n         */\n        notifyListeners(new EventObject(this), EventStatusType.INFORMATION,\n                getClass().toString() + \", initialize(), \"\n                + \"initialization completed.\", null);\n    }\n    public ConfigLoader getConfig() {\n        return this._config;\n    }\n    private void setConfig() throws Exception {\n        this._config = new ConfigLoader(\"\", null);\n    }\n    private void setConfig(String config) throws Exception {\n        this._config = new ConfigLoader(config, null);\n    }\n    private void setConfig(ConfigLoader config) {\n        this._config = config;\n    }\n    private void setConfig(String config, String[] filterPath) {\n        try {\n            this._config = new ConfigLoader(config, filterPath);\n        } catch (Exception ex) {\n        }\n    }\n    public String getFrameworkProperty(String key) {\n        return getConfig().getProperty(\"application.framework.attributes.key.\" + key).toString();\n    }\n    public String getActionProperty(String key) {\n        return getConfig().getProperty(\"application.actions.action.\" + key).toString();\n    }\n    //public Object getDbManager() {\n    //    return getDbManager(\"default\");\n    //}\n    public Object getDbManager(String key) {\n        Object result = null;\n        // if key is null, then set it to default\n        if (key == null) {\n            key = \"default\";\n        }\n        \n        if (this._dbManager.containsKey(key)) {\n            result = this._dbManager.get(key);\n        }\n        return result;\n    }\n    private void setDbManager() throws Exception {\n        if (this._dbManager.size() == 0) {\n            String[] connectionList = getFrameworkProperty(\"dbmanager.activeList\").split(\",\");\n            String[] propsList;\n            \n            for (String connection : connectionList) {\n                String dbDriver\n                        = getFrameworkProperty(\"dbmanager.connection.\" + connection + \".driver\");\n                String dbConnectionString\n                        = getFrameworkProperty(\"dbmanager.connection.\" + connection + \".uri\");\n                int maxPool = 5;\n                try {\n                    maxPool = Integer.parseInt(\n                            getFrameworkProperty(\"dbmanager.connection.\" + connection + \".poolSize\"));\n                } catch (Exception ex) {\n                    maxPool = 5;\n                }\n                // check if properties are defined\n                HashMap properties = new HashMap<String, String>();                \n                propsList = getFrameworkProperty(\"dbmanager.connection.\" + connection + \".params.list\").split(\",\");\n                for (String prop : propsList) {\n                \tproperties.put(prop, getFrameworkProperty(\"dbmanager.connection.\" + connection + \".params.\" + prop));\n                }\n                // capture any exceptions to prevent resource leaks\n                // create the database manager\n                setDbManager(connection, new DatabaseManager(\n                        dbDriver,\n                        dbConnectionString, maxPool,\n                        properties));\n                // connect the event notifiers\n                ((DatabaseManager) getDbManager(connection)).addEventListener(this);\n                notifyListeners(new EventObject(this), EventStatusType.INFORMATION,\n                        getClass().toString() + \", setDbManager(), \"\n                        + \"dbManager initialized.\", null);\n            }\n        }\n    }\n    private void setDbManager(String key, Object dbManager) {\n        if (this._dbManager.containsKey(key)) {\n            this._dbManager.remove(key);\n        }\n        this._dbManager.put(key, dbManager);\n    }\n    public IAction getActionObject(String className) throws Exception {\n        IAction result = null;\n        String classPath = getActionProperty(className);\n        if (classPath != null) {\n            // using reflection, load the class for the service\n            Class<?> actionClass = Class.forName(classPath);\n            // create service constructor discovery type parameter array\n            // populate it with the required class types\n            Class<?>[] argTypes = {ConfigLoader.class, DatabaseManager.class};\n            // retrieve the matching constructor for the service using\n            // reflection\n            Constructor<?> cons = actionClass.getDeclaredConstructor(\n                    argTypes);\n            // retrieve database manager for the class (else try default)\n            String dbName = null;\n            try {\n                dbName = getConfig().getProperty(getConfig().getKeyByValue(classPath).replace(\".class\", \"\") + \".connection\").toString();\n            } catch (Exception exi) { }\n            \n            Object dbManager = this.getDbManager(dbName);\n            // create parameter array and populate it with values to \n            // pass to the service constructor\n            Object[] arguments\n                    = {getConfig(), dbManager};\n            // create new instance of the service using the discovered\n            // constructor and parameters\n            result = (IAction) cons.newInstance(arguments);\n            // check if the instance is typeof IEventPublisher\n            // - if yes, then subscribe to its events\n            if (result instanceof IEventPublisher) {\n                ((IEventPublisher) result).addEventListener(this);\n            }\n            notifyListeners(new EventObject(this), EventStatusType.INFORMATION,\n                    getClass().toString() + \", getClassByName(), \"\n                    + \"class (\" + className + \"/\" + classPath + \") instantiated.\", null);\n        } else {\n", "outputs": ["            notifyListeners(new EventObject(this), EventStatusType.ERROR,"], "input_length": 1429, "output_length": 10, "length": 1439, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "6691e2874fd558f6aca775ca288801c1f15e0aa04cf10f7a407080820cfd0227"}
{"input": "", "context": "#region License\n// Copyright (c) 2013, ClearCanvas Inc.\n// All rights reserved.\n// http://www.clearcanvas.ca\n//\n// This file is part of the ClearCanvas RIS/PACS open source project.\n//\n// The ClearCanvas RIS/PACS open source project is free software: you can\n// redistribute it and/or modify it under the terms of the GNU General Public\n// License as published by the Free Software Foundation, either version 3 of the\n// License, or (at your option) any later version.\n//\n// The ClearCanvas RIS/PACS open source project is distributed in the hope that it\n// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of\n// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General\n// Public License for more details.\n//\n// You should have received a copy of the GNU General Public License along with\n// the ClearCanvas RIS/PACS open source project.  If not, see\n// <http://www.gnu.org/licenses/>.\n#endregion\nusing System;\nusing ClearCanvas.Common;\nusing ClearCanvas.Common.Utilities;\nusing ClearCanvas.Desktop;\nusing ClearCanvas.Desktop.Trees;\nusing ClearCanvas.Desktop.Tables;\nusing ClearCanvas.Desktop.Actions;\nnamespace ClearCanvas.Ris.Client\n{\n    /// <summary>\n    /// Extension point for views onto <see cref=\"FolderExplorerComponent\"/>\n    /// </summary>\n    [ExtensionPoint]\n    public class FolderExplorerComponentViewExtensionPoint : ExtensionPoint<IApplicationComponentView>\n    {\n    }\n    /// <summary>\n    /// WorklistExplorerComponent class\n    /// </summary>\n    [AssociateView(typeof(FolderExplorerComponentViewExtensionPoint))]\n    public class FolderExplorerComponent : ApplicationComponent, IFolderExplorerComponent\n    {\n\t\tenum InitializationState\n\t\t{\n\t\t\tNotInitialized,\n\t\t\tInitializing,\n\t\t\tInitialized\n\t\t}\n\t\tprivate readonly FolderTreeRoot _folderTreeRoot;\n\t\tprivate FolderTreeNode _selectedTreeNode;\n        private event EventHandler _selectedFolderChanged;\n    \tprivate event EventHandler _intialized;\n\t\tprivate InitializationState _initializationState;\n        private readonly IFolderSystem _folderSystem;\n    \tprivate Timer _folderInvalidateTimer;\n    \tprivate readonly FolderExplorerGroupComponent _owner;\n        /// <summary>\n        /// Constructor\n        /// </summary>\n        public FolderExplorerComponent(IFolderSystem folderSystem, FolderExplorerGroupComponent owner)\n        {\n\t\t\t_folderTreeRoot = new FolderTreeRoot(this);\n            _folderSystem = folderSystem;\n        \t_owner = owner;\n        }\n\t\t#region IFolderExplorerComponent implementation\n    \t/// <summary>\n    \t/// Gets a value indicating whether this folder explorer has already been initialized.\n    \t/// </summary>\n    \tbool IFolderExplorerComponent.IsInitialized\n    \t{\n\t\t\tget { return IsInitialized; }\n    \t}\n    \t/// <summary>\n    \t/// Instructs the folder explorer to initialize (build the folder system).\n    \t/// </summary>\n    \tvoid IFolderExplorerComponent.Initialize()\n\t\t{\n\t\t\tInitialize();\n\t\t}\n\t\t/// <summary>\n\t\t/// Occurs when asynchronous initialization of this folder system has completed.\n\t\t/// </summary>\n\t\tevent EventHandler IFolderExplorerComponent.Initialized\n\t\t{\n\t\t\tadd { _intialized += value; }\n\t\t\tremove { _intialized -= value; }\n\t\t}\n\t\t/// <summary>\n\t\t/// Gets or sets the currently selected folder.\n\t\t/// </summary>\n\t\tIFolder IFolderExplorerComponent.SelectedFolder\n\t\t{\n\t\t\tget { return this.SelectedFolder; }\n\t\t\tset\n\t\t\t{\n\t\t\t\tthis.SelectedFolder = value;\n\t\t\t}\n\t\t}\n\t\t/// <summary>\n\t\t/// Invalidates all folders.\n\t\t/// </summary>\n    \tvoid IFolderExplorerComponent.InvalidateFolders()\n\t\t{\n\t\t\t// check initialized\n\t\t\tif (!IsInitialized)\n\t\t\t\treturn;\n\t\t\t// invalidate all folders, and update starting at the root\n\t\t\t_folderSystem.InvalidateFolders();\n\t\t}\n    \t/// <summary>\n    \t/// Gets the underlying folder system associated with this folder explorer.\n    \t/// </summary>\n    \tIFolderSystem IFolderExplorerComponent.FolderSystem\n\t\t{\n\t\t\tget { return _folderSystem; }\n\t\t}\n    \t/// <summary>\n    \t/// Occurs when the selected folder changes.\n    \t/// </summary>\n    \tevent EventHandler IFolderExplorerComponent.SelectedFolderChanged\n\t\t{\n\t\t\tadd { _selectedFolderChanged += value; }\n\t\t\tremove { _selectedFolderChanged -= value; }\n\t\t}\n\t\t/// <summary>\n\t\t/// Executes a search on this folder system.\n\t\t/// </summary>\n\t\t/// <param name=\"searchParams\"></param>\n\t\tvoid IFolderExplorerComponent.ExecuteSearch(SearchParams searchParams)\n\t\t{\n\t\t\t// check initialized\n\t\t\tif (!IsInitialized)\n\t\t\t\treturn;\n\t\t\tif (_folderSystem.SearchEnabled)\n\t\t\t\t_folderSystem.ExecuteSearch(searchParams);\n\t\t}\n\t\tvoid IFolderExplorerComponent.LaunchAdvancedSearchComponent()\n\t\t{\n\t\t\t_folderSystem.LaunchSearchComponent();\n\t\t}\n    \t/// <summary>\n    \t/// Gets the application component that displays the content of a folder for this folder system.\n    \t/// </summary>\n    \t/// <returns></returns>\n    \tIApplicationComponent IFolderExplorerComponent.GetContentComponent()\n    \t{\n    \t\treturn _folderSystem.GetContentComponent();\n    \t}\n    \t#endregion\n\t\t#region Application Component overrides\n\t\tpublic override void Start()\n        {\n\t\t\t// if the folder system needs immediate initialization, do that now\n\t\t\tif(!_folderSystem.LazyInitialize)\n\t\t\t{\n\t\t\t\tInitialize();\n\t\t\t}\n        \tbase.Start();\n        }\n    \tpublic override void Stop()\n\t\t{\n\t\t\tif (_folderInvalidateTimer != null)\n\t\t\t{\n\t\t\t\t_folderInvalidateTimer.Stop();\n\t\t\t\t_folderInvalidateTimer.Dispose();\n\t\t\t}\n\t\t\t// un-subscribe to events (important because the folderSystem object may be re-used by another explorer)\n\t\t\t_folderSystem.Folders.ItemAdded -= FolderAddedEventHandler;\n\t\t\t_folderSystem.Folders.ItemRemoved -= FolderRemovedEventHandler;\n\t\t\t_folderSystem.FoldersChanged -= FoldersChangedEventHandler;\n\t\t\t_folderSystem.FoldersInvalidated -= FoldersInvalidatedEventHandler;\n\t\t\t_folderSystem.FolderPropertiesChanged -= FolderPropertiesChangedEventHandler;\n\t\t\t_folderSystem.Dispose();\n\t\t\tbase.Stop();\n\t\t}\n        public override IActionSet ExportedActions\n        {\n            get \n            { \n                return _folderSystem.FolderTools == null\n                    ? new ActionSet()\n                    : _folderSystem.FolderTools.Actions; \n            }\n        }\n        #endregion\n        #region Presentation Model\n    \tpublic ITree FolderTree\n        {\n\t\t\tget { return _folderTreeRoot.GetSubTree(); }\n        }\n        public ISelection SelectedFolderTreeNode\n        {\n            get { return new Selection(_selectedTreeNode); }\n            set\n            {\n\t\t\t\tvar nodeToSelect = (FolderTreeNode)value.Item;\n                SelectFolder(nodeToSelect);\n            }\n        }\n        public ITable FolderContentsTable\n        {\n            get { return _selectedTreeNode == null ? null : _selectedTreeNode.Folder.ItemsTable; }\n        }\n        public event EventHandler SelectedFolderChanged\n        {\n", "outputs": ["            add { _selectedFolderChanged += value; }"], "input_length": 912, "output_length": 7, "length": 919, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "a40522fc2c7db1458a85ac50b18f762380fb45847a3d5c9adb497c679a672b04"}
{"input": "", "context": "package org.alfresco.web.awe.tag;\nimport java.io.IOException;\nimport java.io.UnsupportedEncodingException;\nimport java.io.Writer;\nimport java.net.URLEncoder;\nimport java.util.ArrayList;\nimport java.util.List;\nimport javax.servlet.ServletRequest;\nimport javax.servlet.http.HttpServletRequest;\n/**\n * Tag utilities for Alfresco Web Editor\n * \n * @author muzquiano\n */\npublic class AlfrescoTagUtil\n{\n    public static final String KEY_MARKER_ID_PREFIX = \"awe_marker_id_prefix\";\n    public static final String KEY_EDITABLE_CONTENT = \"awe_editable_content\";\n    /**\n     * Returns the list of marked content that has been discovered.\n     * <p>\n     * This list is built up as each markContent tag is encountered.\n     * </p>\n     * \n     * @return List of MarkedContent objects\n     */\n    @SuppressWarnings(\"unchecked\")\n    public static List<MarkedContent> getMarkedContent(ServletRequest request)\n    {\n        List<MarkedContent> markedContent = (List<MarkedContent>) request.getAttribute(KEY_EDITABLE_CONTENT);\n        if (markedContent == null)\n        {\n            markedContent = new ArrayList<MarkedContent>();\n            request.setAttribute(KEY_EDITABLE_CONTENT, markedContent);\n        }\n        return markedContent;\n    }\n    public static void writeMarkContentHtml(Writer out, String urlPrefix, String redirectUrl, MarkedContent content)\n            throws IOException, UnsupportedEncodingException\n    {\n        String contentId = content.getContentId();\n        String contentTitle = content.getContentTitle();\n        String formId = content.getFormId();\n        String editMarkerId = content.getMarkerId();\n        \n        // Hide initially, in case we need to log in or user does not want to\n        // log in\n        out.write(\"<span class=\\\"alfresco-content-marker\\\" style=\\\"display: none\\\" id=\\\"\");\n        out.write(editMarkerId);\n        out.write(\"\\\">\");\n        // render edit link for content\n        out.write(\"<a class=\\\"alfresco-content-edit\\\" href=\\\"\");\n        out.write(urlPrefix);\n        out.write(\"/page/metadata?nodeRef=\");\n        out.write(contentId);\n        out.write(\"&js=off\");\n        if (contentTitle != null)\n        {\n            out.write(\"&title=\");\n            out.write(URLEncoder.encode(contentTitle, \"UTF-8\"));\n        }\n        if (redirectUrl != null)\n        {\n            out.write(\"&redirect=\");\n            out.write(redirectUrl);\n        }\n        if (formId != null)\n        {\n            out.write(\"&formId=\");\n            out.write(formId);\n        }\n        out.write(\"\\\"><img src=\\\"\");\n        out.write(urlPrefix);\n        out.write(\"/res/awe/images/edit.png\\\" alt=\\\"\");\n        out.write(encode(contentTitle == null ? \"\" : contentTitle));\n        out.write(\"\\\" title=\\\"\");\n        out.write(encode(contentTitle == null ? \"\" : contentTitle));\n        out.write(\"\\\"border=\\\"0\\\" /></a>\");\n        // render create link for content\n        out.write(\"<a class=\\\"alfresco-content-new\\\" href=\\\"\");\n        out.write(urlPrefix);\n        out.write(\"/page/metadata?nodeRef=\");\n        out.write(contentId);\n        out.write(\"&js=off\");\n        if (contentTitle != null)\n        {\n            out.write(\"&title=\");\n            out.write(URLEncoder.encode(contentTitle, \"UTF-8\"));\n        }\n        if (redirectUrl != null)\n        {\n            out.write(\"&redirect=\");\n            out.write(redirectUrl);\n        }\n        if (formId != null)\n        {\n            out.write(\"&formId=\");\n            out.write(formId);\n        }\n        out.write(\"\\\"><img src=\\\"\");\n        out.write(urlPrefix);\n        out.write(\"/res/awe/images/new.png\\\" alt=\\\"\");\n        out.write(encode(contentTitle == null ? \"\" : contentTitle));\n        out.write(\"\\\" title=\\\"\");\n        out.write(encode(contentTitle == null ? \"\" : contentTitle));\n        out.write(\"\\\"border=\\\"0\\\" /></a>\");\n        // render delete link for content\n        out.write(\"<a class=\\\"alfresco-content-delete\\\" href=\\\"\");\n        out.write(urlPrefix);\n        // TODO\n        out.write(\"/page/metadata?nodeRef=\");\n        out.write(contentId);\n        out.write(\"&js=off\");\n        if (contentTitle != null)\n        {\n            out.write(\"&title=\");\n            out.write(URLEncoder.encode(contentTitle, \"UTF-8\"));\n        }\n        if (redirectUrl != null)\n        {\n            out.write(\"&redirect=\");\n            out.write(redirectUrl);\n        }\n        if (formId != null)\n        {\n            out.write(\"&formId=\");\n            out.write(formId);\n        }\n        out.write(\"\\\"><img src=\\\"\");\n        out.write(urlPrefix);\n        out.write(\"/res/awe/images/delete.png\\\" alt=\\\"\");\n        out.write(encode(contentTitle == null ? \"\" : contentTitle));\n        out.write(\"\\\" title=\\\"\");\n        out.write(encode(contentTitle == null ? \"\" : contentTitle));\n        out.write(\"\\\"border=\\\"0\\\" /></a>\");\n        out.write(\"</span>\\n\");\n    }\n    /**\n     * Calculates the redirect url for form submission, this will\n     * be the current request URL.\n     * \n     * @return The redirect URL\n     */\n    public static String calculateRedirectUrl(HttpServletRequest request)\n    {\n        // NOTE: This may become configurable in the future, for now\n        //       this just returns the current page's URI\n        String redirectUrl = null;\n        try\n        {\n            StringBuffer url = request.getRequestURL();\n            String queryString = request.getQueryString();\n            if (queryString != null)\n            {\n                url.append(\"?\").append(queryString);\n            }\n            redirectUrl = URLEncoder.encode(url.toString(), \"UTF-8\");\n        }\n        catch (UnsupportedEncodingException uee)\n        {\n            // just return null\n        }\n        return redirectUrl;\n    }\n    \n    /**\n     * Encodes the given string, so that it can be used within an HTML page.\n     * \n     * @param string     the String to convert\n     */\n    public static String encode(String string)\n    {\n        if (string == null)\n        {\n            return \"\";\n        }\n        StringBuilder sb = null;      // create on demand\n        String enc;\n        char c;\n        for (int i = 0; i < string.length(); i++)\n        {\n            enc = null;\n            c = string.charAt(i);\n            switch (c)\n            {\n                case '\"': enc = \"&quot;\"; break;    //\"\n                case '&': enc = \"&amp;\"; break;     //&\n                case '<': enc = \"&lt;\"; break;      //<\n                case '>': enc = \"&gt;\"; break;      //>\n                case '\\u20AC': enc = \"&euro;\";  break;\n                case '\\u00AB': enc = \"&laquo;\"; break;\n                case '\\u00BB': enc = \"&raquo;\"; break;\n                case '\\u00A0': enc = \"&nbsp;\"; break;\n                default:\n                    if (((int)c) >= 0x80)\n                    {\n                        //encode all non basic latin characters\n                        enc = \"&#\" + ((int)c) + \";\";\n                    }\n                    break;\n            }\n            if (enc != null)\n            {\n                if (sb == null)\n                {\n                    String soFar = string.substring(0, i);\n                    sb = new StringBuilder(i + 16);\n                    sb.append(soFar);\n                }\n                sb.append(enc);\n            }\n            else\n            {\n                if (sb != null)\n                {\n                    sb.append(c);\n                }\n            }\n        }\n", "outputs": ["        if (sb == null)"], "input_length": 1373, "output_length": 6, "length": 1379, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "11004c05f03cb24156f61e5ee092ca10b6713c355230343a0f5a6022306f878f"}
{"input": "", "context": "import os\nimport zmq\nimport warnings\nTIMEOUT = 1000  # milliseconds\nVERBOSE = False\nRETRY = True  # Should we try to get another server if we can't connect?\nSERVERFILE = \"serverlist.dat\" # Base name of the file containing  server names\nif __name__ == '__main__':\n    VERBOSE = True\ndef printV(*args):\n    if VERBOSE:\n        for arg in args:\n            print arg,\n        print ''\ndef getBasePath(): # Get the base directory of this script\n    return __file__[:__file__.rfind(\"clientBase.py\")]\ndef getServerFile(): # Return the full path the the server list file\n    return os.path.join(getBasePath(), SERVERFILE)\ndef generateConfig(): # generates the config and server files if not found\n    serverFile = getServerFile()\n    if os.path.isfile(serverFile):\n        printV(\"Server List Found at %s\" % serverFile)\n    else:\n        printV(\"No Server List Found\")\n        printV(\"Generating New Server List at %s\" % serverFile)\n        with open(serverFile,'wb') as f:\n            f.write(\"echidna tcp://108.52.218.107:5001\")\nclass SDSSError(Exception):  # custom SDSSError that relates to serverside issues\n    def __init__(self, message, errors=None):\n        super(SDSSError, self).__init__(message)\n        self.errors = errors\nclass ServerList(dict):  # dictionary like class that manages the possible servers\n    def __init__(self, *args, **kwargs):\n        super(ServerList, self).__init__(*args, **kwargs)\n        self.best = None\n        self.priority = {}\n    def addServer(self, name, address, priority):  # add a server to our list of servers\n        server = {\"address\": address, \"priority\": priority}\n        self[name] = server\n        self.priority[priority] = name\n    def addServersFromFile(self, filename):\n        servers = []\n        priority = 0\n        with open(filename, 'rb') as f:\n            for line in f:\n                name, address = line.strip().split()\n                self.addServer(name, address, priority)\n                priority += 1\n    def saveServersToFile(self, filename):\n        lines = []\n        for p in sorted(self.priority.keys()):\n            name = self.priority[p]\n            address = self[name]['address']\n            lines.append(' '.join((name, address)))\n        with open(filename, 'wb') as f:\n            f.write('\\n'.join(lines))\n    def testServer(self, server):\n        try:\n            context = zmq.Context()\n            socket = context.socket(zmq.REQ)\n            socket.LINGER = False\n            socket.connect(server['address'])\n            socket.send(b\"ping\\n\", flags=zmq.NOBLOCK)\n            if socket.poll(timeout=1000, flags=zmq.POLLIN):\n                return True\n            else:\n                return False\n        except zmq.ZMQError as e:\n            raise SDSSError(e.message, e.errno)\n    def getBestServer(self):  # determine the best server\n        for key, server in sorted(self.items(), key=lambda x: x[1]['priority']):\n            isGood = self.testServer(server)\n            if isGood:\n                printV(\"Best Server is %s\" % key)\n                self.best = server['address']\n                break\n        else:\n            self.best = None\n            raise SDSSError(\"No good servers available at the moment\", self.best)\n    def setBestServer(self, server):  # manually override the best server\n        printV(\"Testing Server %s\" % server)\n        isGood = self.testServer(self[server])\n        if isGood:\n            self.best = self[server]['address']\n            printV(\"%s is now connected\" % server)\n        else:\n            raise SDSSError(\"Bad Server: %s\" % server, server)\ngenerateConfig() # Setup the server list and config if needed\nservers = ServerList() # Instantiate a new server list\nservers.addServersFromFile(getServerFile()) # Add servers from our server list\nservers.getBestServer() # Find the best server based on priority and availability\ndef getSocket():\n    context = zmq.Context()\n    socket = context.socket(zmq.REQ)\n    socket.LINGER = False\n    socket.connect(servers.best)\n    return socket\ndef zmqSocketDecorator(func):  # a decorator that handles the zmq sockets and raises SDSS exceptions\n    def wrapper(*args, **kwargs):\n        try:\n            socket = getSocket()\n            return func(socket, *args, **kwargs)\n        except zmq.ZMQError as e:\n            raise SDSSError(e.message, e.errno)\n    return wrapper\n@zmqSocketDecorator\ndef getCommandResult(socket, cmd):  # send a command to the server and return the result\n    global RETRY\n    socket.send(cmd)\n    if socket.poll(timeout=TIMEOUT, flags=zmq.POLLIN):\n        result = socket.recv_pyobj(flags=zmq.NOBLOCK)\n    else:\n        if RETRY:\n            printV(\"Server Disconnected.  Attempting to Connect to Another Server\")\n            servers.getBestServer()\n            RETRY = False\n            result = getCommandResult(cmd)\n            RETRY = True\n            return result\n        else:\n            raise SDSSError(\"Socket timed out\", TIMEOUT)\n    if isinstance(result, Exception):\n        raise SDSSError(*result.args)\n    return result\ndef createCommand(server_func, *args):  # get the command string for a function and it's arguments\n    if len(args):\n        args = \" \".join(map(str, args))\n    else:\n        args = ''\n    cmd = b\"%s\\n%s\" % (server_func, args)\n    return cmd\ndef isValid(server_func):  # checks if a server_func is valid\n    cmd = createCommand('isValid', server_func)\n    result = getCommandResult(cmd)\n    return result\ndef commandArgCount(server_func):  # gets information about the server func\n    cmd = createCommand('argCount', server_func)\n    result = getCommandResult(cmd)\n    return result\ndef _createFunction(server_func, docstr=None):\n    # Create a function object that acts on a server side func with name 'server_func'\n    if isValid(server_func):\n        nargs = commandArgCount(server_func) - 1\n    else:\n        raise SDSSError(\"Invalid Function: %s\" % server_func, server_func)\n    def Func(*args):\n        if len(args) != nargs:\n            message = \"%s takes exactly %i arguments (%i given)\" % (server_func, nargs, len(args))\n            raise TypeError(message)\n        if docstr is not None:\n            Func.__doc__ = docstr\n        cmd = createCommand(server_func, *args)\n        result = getCommandResult(cmd)\n        return result\n    return Func\ndef createFunction(server_func, docstr=None):\n    def initialFunc(*args):\n        initalFunc = _createFunction(server_func, docstr)\n        return initalFunc(*args)\n    return initialFunc\n# define our client-side functions below\ngetRandLC = createFunction(\"randLC\",\n                           \"\"\"\nargs: None\nreturns:\n    filename, redshift, data (tuple):\n        filename (str): name of the file on disk\n        redshift (float): redshift of the object\n        data (numpy structure array): structured array of the data from the LC file\n\"\"\")\ngetLC = createFunction(\"getLC\",\n                       \"\"\"\nargs:\n    ID (str): SDSS J2000 name\nreturns:\n    filename, redshift, data (tuple):\n        filename (str): name of the file on disk\n        redshift (float): redshift of the object\n        data (numpy structure array): structured array of the data from the LC file\n\"\"\")\ngetIDList = createFunction(\"IDList\",\n                           \"\"\"\nargs: None\nreturns:\n    IDList (list): List of strings of SDSS Objects names on disk\n\"\"\")\ngetNearestLC = createFunction('getNearestLC',\n                              \"\"\"\nargs:\n    ID (str): SDSS J200 name\n    tol (float): matching tolerance in degrees\nreturns:\n    filename, reshift, data (tuple):\n        see above\n\"\"\")\nif __name__ == '__main__':\n    import sys\n    if len(sys.argv) == 1:\n        print \"Test\"\n    if sys.argv[1] == '--check':\n        for name in sys.argv[2:]:\n            try:\n                getNearestLC(name, 2/60.0/60.0)\n            except SDSSError as e:\n                if 'No objects in list' in e.message:\n                    print \"LC does not exist in data base\", 0, name\n            except IndexError as e:\n                print \"No File Specified\"\n            else:\n                print \"LC does exist in database     \", 1, name\n    elif sys.argv[1] == '--rand':\n        print getRandLC()\n", "outputs": ["    elif sys.argv[1] == '--list':"], "input_length": 1552, "output_length": 11, "length": 1563, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "78495eee3543caa9754bb6d16e309af315bf4a9366e4fff550dbe9328b4ac182"}
{"input": "", "context": "namespace HospitalityManagement.Dialogs\n {\n partial class rptParamsDiag\n  {\n  /// <summary>\n  /// Required designer variable.\n  /// </summary>\n  private System.ComponentModel.IContainer components = null;\n  /// <summary>\n  /// Clean up any resources being used.\n  /// </summary>\n  /// <param name=\"disposing\">true if managed resources should be disposed; otherwise, false.</param>\n  protected override void Dispose(bool disposing)\n   {\n   if (disposing && (components != null))\n    {\n    components.Dispose();\n    }\n   base.Dispose(disposing);\n   }\n  #region Windows Form Designer generated code\n  /// <summary>\n  /// Required method for Designer support - do not modify\n  /// the contents of this method with the code editor.\n  /// </summary>\n  private void InitializeComponent()\n   {\n            this.docTypComboBox = new System.Windows.Forms.ComboBox();\n            this.OKButton = new System.Windows.Forms.Button();\n            this.label6 = new System.Windows.Forms.Label();\n            this.endDteButton = new System.Windows.Forms.Button();\n            this.label8 = new System.Windows.Forms.Label();\n            this.cancelButton = new System.Windows.Forms.Button();\n            this.endDteTextBox = new System.Windows.Forms.TextBox();\n            this.startDteButton = new System.Windows.Forms.Button();\n            this.label1 = new System.Windows.Forms.Label();\n            this.startDteTextBox = new System.Windows.Forms.TextBox();\n            this.createdByTextBox = new System.Windows.Forms.TextBox();\n            this.label4 = new System.Windows.Forms.Label();\n            this.createdByIDTextBox = new System.Windows.Forms.TextBox();\n            this.createdByButton = new System.Windows.Forms.Button();\n            this.sortByComboBox = new System.Windows.Forms.ComboBox();\n            this.label2 = new System.Windows.Forms.Label();\n            this.rptComboBox = new System.Windows.Forms.ComboBox();\n            this.label3 = new System.Windows.Forms.Label();\n            this.useCreationDateCheckBox = new System.Windows.Forms.CheckBox();\n            this.SuspendLayout();\n            // \n            // docTypComboBox\n            // \n            this.docTypComboBox.BackColor = System.Drawing.Color.FromArgb(((int)(((byte)(255)))), ((int)(((byte)(255)))), ((int)(((byte)(128)))));\n            this.docTypComboBox.DropDownStyle = System.Windows.Forms.ComboBoxStyle.DropDownList;\n            this.docTypComboBox.FormattingEnabled = true;\n            this.docTypComboBox.Items.AddRange(new object[] {\n            \"Pro-Forma Invoice\",\n            \"Sales Order\",\n            \"Sales Invoice\",\n            \"Internal Item Request\",\n            \"Item Issue-Unbilled\",\n            \"Sales Return\"});\n            this.docTypComboBox.Location = new System.Drawing.Point(91, 83);\n            this.docTypComboBox.Name = \"docTypComboBox\";\n            this.docTypComboBox.Size = new System.Drawing.Size(264, 21);\n            this.docTypComboBox.TabIndex = 4;\n            // \n            // OKButton\n            // \n            this.OKButton.Location = new System.Drawing.Point(112, 185);\n            this.OKButton.Name = \"OKButton\";\n            this.OKButton.Size = new System.Drawing.Size(75, 23);\n            this.OKButton.TabIndex = 6;\n            this.OKButton.Text = \"OK\";\n            this.OKButton.UseVisualStyleBackColor = true;\n            this.OKButton.Click += new System.EventHandler(this.OKButton_Click);\n            // \n            // label6\n            // \n            this.label6.AutoSize = true;\n            this.label6.ForeColor = System.Drawing.Color.White;\n            this.label6.Location = new System.Drawing.Point(5, 86);\n            this.label6.Name = \"label6\";\n            this.label6.Size = new System.Drawing.Size(86, 13);\n            this.label6.TabIndex = 74;\n            this.label6.Text = \"Document Type:\";\n            // \n            // endDteButton\n            // \n            this.endDteButton.Font = new System.Drawing.Font(\"Tahoma\", 8.25F, System.Drawing.FontStyle.Regular, System.Drawing.GraphicsUnit.Point, ((byte)(0)));\n            this.endDteButton.ForeColor = System.Drawing.Color.Black;\n            this.endDteButton.Location = new System.Drawing.Point(328, 56);\n            this.endDteButton.Name = \"endDteButton\";\n            this.endDteButton.Size = new System.Drawing.Size(28, 23);\n            this.endDteButton.TabIndex = 3;\n            this.endDteButton.TabStop = false;\n            this.endDteButton.Text = \"...\";\n            this.endDteButton.UseVisualStyleBackColor = true;\n            this.endDteButton.Click += new System.EventHandler(this.endDteButton_Click);\n            // \n            // label8\n            // \n            this.label8.AutoSize = true;\n            this.label8.ForeColor = System.Drawing.Color.White;\n            this.label8.Location = new System.Drawing.Point(5, 61);\n            this.label8.Name = \"label8\";\n            this.label8.Size = new System.Drawing.Size(55, 13);\n            this.label8.TabIndex = 73;\n            this.label8.Text = \"End Date:\";\n            // \n            // cancelButton\n            // \n            this.cancelButton.Location = new System.Drawing.Point(187, 185);\n            this.cancelButton.Name = \"cancelButton\";\n            this.cancelButton.Size = new System.Drawing.Size(75, 23);\n            this.cancelButton.TabIndex = 7;\n            this.cancelButton.Text = \"Cancel\";\n            this.cancelButton.UseVisualStyleBackColor = true;\n            this.cancelButton.Click += new System.EventHandler(this.cancelButton_Click);\n            // \n            // endDteTextBox\n            // \n            this.endDteTextBox.BackColor = System.Drawing.Color.FromArgb(((int)(((byte)(255)))), ((int)(((byte)(255)))), ((int)(((byte)(128)))));\n            this.endDteTextBox.Location = new System.Drawing.Point(92, 57);\n            this.endDteTextBox.Name = \"endDteTextBox\";\n            this.endDteTextBox.Size = new System.Drawing.Size(233, 21);\n            this.endDteTextBox.TabIndex = 2;\n            this.endDteTextBox.TextChanged += new System.EventHandler(this.startDteTextBox_TextChanged);\n            this.endDteTextBox.Leave += new System.EventHandler(this.startDteTextBox_Leave);\n            // \n            // startDteButton\n            // \n            this.startDteButton.Font = new System.Drawing.Font(\"Tahoma\", 8.25F, System.Drawing.FontStyle.Regular, System.Drawing.GraphicsUnit.Point, ((byte)(0)));\n            this.startDteButton.ForeColor = System.Drawing.Color.Black;\n            this.startDteButton.Location = new System.Drawing.Point(328, 30);\n            this.startDteButton.Name = \"startDteButton\";\n            this.startDteButton.Size = new System.Drawing.Size(28, 23);\n            this.startDteButton.TabIndex = 1;\n            this.startDteButton.TabStop = false;\n            this.startDteButton.Text = \"...\";\n            this.startDteButton.UseVisualStyleBackColor = true;\n            this.startDteButton.Click += new System.EventHandler(this.startDteButton_Click);\n            // \n            // label1\n            // \n            this.label1.AutoSize = true;\n            this.label1.ForeColor = System.Drawing.Color.White;\n            this.label1.Location = new System.Drawing.Point(5, 35);\n            this.label1.Name = \"label1\";\n            this.label1.Size = new System.Drawing.Size(61, 13);\n            this.label1.TabIndex = 70;\n            this.label1.Text = \"Start Date:\";\n            // \n            // startDteTextBox\n            // \n            this.startDteTextBox.BackColor = System.Drawing.Color.FromArgb(((int)(((byte)(255)))), ((int)(((byte)(255)))), ((int)(((byte)(128)))));\n            this.startDteTextBox.Location = new System.Drawing.Point(92, 31);\n            this.startDteTextBox.Name = \"startDteTextBox\";\n            this.startDteTextBox.Size = new System.Drawing.Size(233, 21);\n            this.startDteTextBox.TabIndex = 0;\n            this.startDteTextBox.TextChanged += new System.EventHandler(this.startDteTextBox_TextChanged);\n            this.startDteTextBox.Leave += new System.EventHandler(this.startDteTextBox_Leave);\n            // \n            // createdByTextBox\n            // \n            this.createdByTextBox.Location = new System.Drawing.Point(92, 109);\n            this.createdByTextBox.MaxLength = 200;\n            this.createdByTextBox.Name = \"createdByTextBox\";\n            this.createdByTextBox.Size = new System.Drawing.Size(233, 21);\n            this.createdByTextBox.TabIndex = 193;\n            this.createdByTextBox.TextChanged += new System.EventHandler(this.startDteTextBox_TextChanged);\n            this.createdByTextBox.Leave += new System.EventHandler(this.startDteTextBox_Leave);\n            // \n            // label4\n            // \n            this.label4.AutoSize = true;\n            this.label4.ForeColor = System.Drawing.Color.White;\n            this.label4.Location = new System.Drawing.Point(5, 113);\n            this.label4.Name = \"label4\";\n            this.label4.Size = new System.Drawing.Size(65, 13);\n            this.label4.TabIndex = 192;\n            this.label4.Text = \"Created By:\";\n            // \n            // createdByIDTextBox\n            // \n            this.createdByIDTextBox.Location = new System.Drawing.Point(293, 109);\n            this.createdByIDTextBox.MaxLength = 200;\n            this.createdByIDTextBox.Name = \"createdByIDTextBox\";\n            this.createdByIDTextBox.ReadOnly = true;\n            this.createdByIDTextBox.Size = new System.Drawing.Size(32, 21);\n            this.createdByIDTextBox.TabIndex = 194;\n            this.createdByIDTextBox.TabStop = false;\n            this.createdByIDTextBox.Text = \"-1\";\n            // \n            // createdByButton\n            // \n            this.createdByButton.Font = new System.Drawing.Font(\"Tahoma\", 8.25F, System.Drawing.FontStyle.Regular, System.Drawing.GraphicsUnit.Point, ((byte)(0)));\n            this.createdByButton.ForeColor = System.Drawing.Color.Black;\n            this.createdByButton.Location = new System.Drawing.Point(328, 109);\n            this.createdByButton.Name = \"createdByButton\";\n            this.createdByButton.Size = new System.Drawing.Size(28, 23);\n            this.createdByButton.TabIndex = 195;\n            this.createdByButton.TabStop = false;\n            this.createdByButton.Text = \"...\";\n            this.createdByButton.UseVisualStyleBackColor = true;\n            this.createdByButton.Click += new System.EventHandler(this.createdByButton_Click);\n            // \n            // sortByComboBox\n            // \n            this.sortByComboBox.BackColor = System.Drawing.Color.FromArgb(((int)(((byte)(255)))), ((int)(((byte)(255)))), ((int)(((byte)(128)))));\n            this.sortByComboBox.DropDownStyle = System.Windows.Forms.ComboBoxStyle.DropDownList;\n            this.sortByComboBox.FormattingEnabled = true;\n            this.sortByComboBox.Items.AddRange(new object[] {\n            \"QTY\",\n            \"TOTAL AMOUNT\"});\n            this.sortByComboBox.Location = new System.Drawing.Point(91, 135);\n            this.sortByComboBox.Name = \"sortByComboBox\";\n            this.sortByComboBox.Size = new System.Drawing.Size(264, 21);\n            this.sortByComboBox.TabIndex = 5;\n            // \n            // label2\n            // \n            this.label2.AutoSize = true;\n            this.label2.ForeColor = System.Drawing.Color.White;\n            this.label2.Location = new System.Drawing.Point(5, 138);\n            this.label2.Name = \"label2\";\n            this.label2.Size = new System.Drawing.Size(46, 13);\n            this.label2.TabIndex = 197;\n            this.label2.Text = \"Sort By:\";\n            // \n            // rptComboBox\n            // \n            this.rptComboBox.BackColor = System.Drawing.Color.FromArgb(((int)(((byte)(255)))), ((int)(((byte)(255)))), ((int)(((byte)(128)))));\n            this.rptComboBox.DropDownStyle = System.Windows.Forms.ComboBoxStyle.DropDownList;\n            this.rptComboBox.FormattingEnabled = true;\n            this.rptComboBox.Items.AddRange(new object[] {\n            \"Money Received Report (Payments Received)\",\n            \"Money Received Report (Documents Created)\",\n            \"Items Sold/Issued Report\",\n            \"Rooms Needing Cleaning\"});\n", "outputs": ["            this.rptComboBox.Location = new System.Drawing.Point(92, 5);"], "input_length": 1551, "output_length": 10, "length": 1561, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "9b4ebc4bb87f04a8a25df3e958596d826cf7f7d8572feb2d85e688ed98d37298"}
{"input": "", "context": "using System;\nusing System.Collections;\nusing System.Collections.Generic;\nusing System.Data;\nusing System.Data.Common;\nusing System.Text;\nusing NHibernate.AdoNet;\nusing NHibernate.Cache;\nusing NHibernate.Cache.Entry;\nusing NHibernate.Dialect.Lock;\nusing NHibernate.Engine;\nusing NHibernate.Exceptions;\nusing NHibernate.Id;\nusing NHibernate.Id.Insert;\nusing NHibernate.Impl;\nusing NHibernate.Intercept;\nusing NHibernate.Loader.Entity;\nusing NHibernate.Mapping;\nusing NHibernate.Metadata;\nusing NHibernate.Properties;\nusing NHibernate.SqlCommand;\nusing NHibernate.Tuple;\nusing NHibernate.Tuple.Entity;\nusing NHibernate.Type;\nusing NHibernate.Util;\nusing Array=System.Array;\nusing Property=NHibernate.Mapping.Property;\nusing NHibernate.SqlTypes;\nusing System.Linq;\nnamespace NHibernate.Persister.Entity\n{\n\t/// <summary>\n\t/// Superclass for built-in mapping strategies. Implements functionalty common to both mapping\n\t/// strategies\n\t/// </summary>\n\t/// <remarks>\n\t/// May be considered an immutable view of the mapping object\n\t/// </remarks>\n\tpublic abstract class AbstractEntityPersister : IOuterJoinLoadable, IQueryable, IClassMetadata, IUniqueKeyLoadable, ISqlLoadable, ILazyPropertyInitializer, IPostInsertIdentityPersister, ILockable\n\t{\n\t\t#region InclusionChecker\n\t\tprotected internal interface IInclusionChecker\n\t\t{\n\t\t\tbool IncludeProperty(int propertyNumber);\n\t\t}\n\t\tprivate class NoneInclusionChecker : IInclusionChecker\n\t\t{\n\t\t\tprivate readonly ValueInclusion[] inclusions;\n\t\t\tpublic NoneInclusionChecker(ValueInclusion[] inclusions)\n\t\t\t{\n\t\t\t\tthis.inclusions = inclusions;\n\t\t\t}\n\t\t\t// TODO : currently we really do not handle ValueInclusion.PARTIAL...\n\t\t\t// ValueInclusion.PARTIAL would indicate parts of a component need to\n\t\t\t// be included in the select; currently we then just render the entire\n\t\t\t// component into the select clause in that case.\n\t\t\tpublic bool IncludeProperty(int propertyNumber)\n\t\t\t{\n\t\t\t\treturn inclusions[propertyNumber] != ValueInclusion.None;\n\t\t\t}\n\t\t}\n\t\tprivate class FullInclusionChecker : IInclusionChecker\n\t\t{\n\t\t\tprivate readonly bool[] includeProperty;\n\t\t\tpublic FullInclusionChecker(bool[] includeProperty)\n\t\t\t{\n\t\t\t\tthis.includeProperty = includeProperty;\n\t\t\t}\n\t\t\tpublic bool IncludeProperty(int propertyNumber)\n\t\t\t{\n\t\t\t\treturn includeProperty[propertyNumber];\n\t\t\t}\n\t\t}\n\t\t#endregion\n\t\tprivate class GeneratedIdentifierBinder : IBinder\n\t\t{\n\t\t\tprivate readonly object[] fields;\n\t\t\tprivate readonly bool[] notNull;\n\t\t\tprivate readonly ISessionImplementor session;\n\t\t\tprivate readonly object entity;\n\t\t\tprivate readonly AbstractEntityPersister entityPersister;\n\t\t\tpublic GeneratedIdentifierBinder(object[] fields, bool[] notNull, ISessionImplementor session, object entity, AbstractEntityPersister entityPersister)\n\t\t\t{\n\t\t\t\tthis.fields = fields;\n\t\t\t\tthis.notNull = notNull;\n\t\t\t\tthis.session = session;\n\t\t\t\tthis.entity = entity;\n\t\t\t\tthis.entityPersister = entityPersister;\n\t\t\t}\n\t\t\tpublic object Entity\n\t\t\t{\n\t\t\t\tget { return entity; }\n\t\t\t}\n\t\t\tpublic virtual void BindValues(DbCommand ps)\n\t\t\t{\n\t\t\t\tentityPersister.Dehydrate(null, fields, notNull, entityPersister.propertyColumnInsertable, 0, ps, session);\n\t\t\t}\n\t\t}\n\t\tprivate static readonly IInternalLogger log = LoggerProvider.LoggerFor(typeof(AbstractEntityPersister));\n\t\tpublic const string EntityClass = \"class\";\n\t\tprotected const string Discriminator_Alias = \"clazz_\";\n\t\tprivate readonly ISessionFactoryImplementor factory;\n\t\tprivate readonly ICacheConcurrencyStrategy cache;\n\t\tprivate readonly bool isLazyPropertiesCacheable;\n\t\tprivate readonly ICacheEntryStructure cacheEntryStructure;\n\t\tprivate readonly EntityMetamodel entityMetamodel;\n\t\tprivate readonly Dictionary<System.Type, string> entityNameBySubclass = new Dictionary<System.Type, string>();\n\t\tprivate readonly string[] rootTableKeyColumnNames;\n\t\tprivate readonly string[] identifierAliases;\n\t\tprivate readonly int identifierColumnSpan;\n\t\tprivate readonly string versionColumnName;\n\t\tprivate readonly bool hasFormulaProperties;\n\t\tprivate readonly int batchSize;\n\t\tprivate readonly bool hasSubselectLoadableCollections;\n\t\tprotected internal string rowIdName;\n\t\tprivate readonly ISet<string> lazyProperties;\n\t\tprivate readonly string sqlWhereString;\n\t\tprivate readonly string sqlWhereStringTemplate;\n\t\t#region Information about properties of this class\n\t\t//including inherited properties\n\t\t//(only really needed for updatable/insertable properties)\n\t\tprivate readonly int[] propertyColumnSpans;\n\t\t// the names of the columns for the property\n\t\t// the array is indexed as propertyColumnNames[propertyIndex][columnIndex] = \"columnName\"\n\t\tprivate readonly string[] propertySubclassNames;\n\t\tprivate readonly string[][] propertyColumnAliases;\n\t\tprivate readonly string[][] propertyColumnNames;\n\t\t// the alias names for the columns of the property.  This is used in the AS portion for \n\t\t// selecting a column.  It is indexed the same as propertyColumnNames\n\t\t// private readonly string[ ] propertyFormulaTemplates;\n\t\tprivate readonly string[][] propertyColumnFormulaTemplates;\n\t\tprivate readonly bool[][] propertyColumnUpdateable;\n\t\tprivate readonly bool[][] propertyColumnInsertable;\n\t\tprivate readonly bool[] propertyUniqueness;\n\t\tprivate readonly bool[] propertySelectable;\n\t\t#endregion\n\t\t#region Information about lazy properties of this class\n\t\tprivate readonly string[] lazyPropertyNames;\n\t\tprivate readonly int[] lazyPropertyNumbers;\n\t\tprivate readonly IType[] lazyPropertyTypes;\n\t\tprivate readonly string[][] lazyPropertyColumnAliases;\n\t\t#endregion\n\t\t#region Information about all properties in class hierarchy\n\t\tprivate readonly string[] subclassPropertyNameClosure;\n\t\tprivate readonly string[] subclassPropertySubclassNameClosure;\n\t\tprivate readonly IType[] subclassPropertyTypeClosure;\n\t\tprivate readonly string[][] subclassPropertyFormulaTemplateClosure;\n\t\tprivate readonly string[][] subclassPropertyColumnNameClosure;\n\t\tprivate readonly FetchMode[] subclassPropertyFetchModeClosure;\n\t\tprivate readonly bool[] subclassPropertyNullabilityClosure;\n\t\tprotected bool[] propertyDefinedOnSubclass;\n\t\tprivate readonly int[][] subclassPropertyColumnNumberClosure;\n\t\tprivate readonly int[][] subclassPropertyFormulaNumberClosure;\n\t\tprivate readonly CascadeStyle[] subclassPropertyCascadeStyleClosure;\n\t\t#endregion\n\t\t#region Information about all columns/formulas in class hierarchy\n\t\tprivate readonly string[] subclassColumnClosure;\n\t\tprivate readonly bool[] subclassColumnLazyClosure;\n\t\tprivate readonly string[] subclassColumnAliasClosure;\n\t\tprivate readonly bool[] subclassColumnSelectableClosure;\n\t\tprivate readonly string[] subclassFormulaClosure;\n\t\tprivate readonly string[] subclassFormulaTemplateClosure;\n\t\tprivate readonly string[] subclassFormulaAliasClosure;\n\t\tprivate readonly bool[] subclassFormulaLazyClosure;\n\t\t#endregion\n\t\t#region Dynamic filters attached to the class-level\n\t\tprivate readonly FilterHelper filterHelper;\n\t\t#endregion\n\t\tprivate readonly Dictionary<string, EntityLoader> uniqueKeyLoaders = new Dictionary<string, EntityLoader>();\n\t\tprivate readonly Dictionary<LockMode, ILockingStrategy> lockers = new Dictionary<LockMode, ILockingStrategy>();\n\t\tprivate readonly Dictionary<string, IUniqueEntityLoader> loaders = new Dictionary<string, IUniqueEntityLoader>();\n\t\t#region SQL strings\n\t\tprivate SqlString sqlVersionSelectString;\n\t\tprivate SqlString sqlSnapshotSelectString;\n\t\tprivate SqlString sqlLazySelectString;\n\t\tprivate SqlCommandInfo sqlIdentityInsertString;\n\t\tprivate SqlCommandInfo sqlUpdateByRowIdString;\n\t\tprivate SqlCommandInfo sqlLazyUpdateByRowIdString;\n\t\tprivate SqlCommandInfo[] sqlDeleteStrings;\n\t\tprivate SqlCommandInfo[] sqlInsertStrings;\n\t\tprivate SqlCommandInfo[] sqlUpdateStrings;\n\t\tprivate SqlCommandInfo[] sqlLazyUpdateStrings;\n\t\tprivate SqlString sqlInsertGeneratedValuesSelectString;\n\t\tprivate SqlString sqlUpdateGeneratedValuesSelectString;\n\t\tprivate string identitySelectString;\n\t\t#endregion\n\t\t#region Custom SQL\n\t\tprotected internal bool[] insertCallable;\n\t\tprotected internal bool[] updateCallable;\n\t\tprotected internal bool[] deleteCallable;\n\t\tprotected internal SqlString[] customSQLInsert;\n\t\tprotected internal SqlString[] customSQLUpdate;\n\t\tprotected internal SqlString[] customSQLDelete;\n\t\tprotected internal ExecuteUpdateResultCheckStyle[] insertResultCheckStyles;\n\t\tprotected internal ExecuteUpdateResultCheckStyle[] updateResultCheckStyles;\n\t\tprotected internal ExecuteUpdateResultCheckStyle[] deleteResultCheckStyles;\n\t\t#endregion\n\t\tprivate IInsertGeneratedIdentifierDelegate identityDelegate;\n\t\tprivate bool[] tableHasColumns;\n\t\tprivate readonly string loaderName;\n\t\tprivate IUniqueEntityLoader queryLoader;\n\t\tprivate readonly string temporaryIdTableName;\n\t\tprivate readonly string temporaryIdTableDDL;\n\t\tprivate readonly Dictionary<string, string[]> subclassPropertyAliases = new Dictionary<string, string[]>();\n\t\tprivate readonly Dictionary<string, string[]> subclassPropertyColumnNames = new Dictionary<string, string[]>();\n\t\tprotected readonly BasicEntityPropertyMapping propertyMapping;\n\t\tprotected AbstractEntityPersister(PersistentClass persistentClass, ICacheConcurrencyStrategy cache,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tISessionFactoryImplementor factory)\n\t\t{\n\t\t\tthis.factory = factory;\n\t\t\tthis.cache = cache;\n\t\t\tisLazyPropertiesCacheable = persistentClass.IsLazyPropertiesCacheable;\n\t\t\tcacheEntryStructure = factory.Settings.IsStructuredCacheEntriesEnabled\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t? (ICacheEntryStructure)new StructuredCacheEntry(this)\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t: (ICacheEntryStructure)new UnstructuredCacheEntry();\n\t\t\tentityMetamodel = new EntityMetamodel(persistentClass, factory);\n\t\t\tif (persistentClass.HasPocoRepresentation)\n\t\t\t{\n\t\t\t\t//TODO: this is currently specific to pojos, but need to be available for all entity-modes\n\t\t\t\tforeach (Subclass subclass in persistentClass.SubclassIterator)\n\t\t\t\t{\n\t\t\t\t\tentityNameBySubclass[subclass.MappedClass] = subclass.EntityName;\n\t\t\t\t}\n\t\t\t}\n\t\t\tbatchSize = persistentClass.BatchSize ?? factory.Settings.DefaultBatchFetchSize;\n\t\t\thasSubselectLoadableCollections = persistentClass.HasSubselectLoadableCollections;\n\t\t\tpropertyMapping = new BasicEntityPropertyMapping(this);\n\t\t\t#region IDENTIFIER\n\t\t\tidentifierColumnSpan = persistentClass.Identifier.ColumnSpan;\n\t\t\trootTableKeyColumnNames = new string[identifierColumnSpan];\n\t\t\tidentifierAliases = new string[identifierColumnSpan];\n\t\t\trowIdName = persistentClass.RootTable.RowId;\n\t\t\tloaderName = persistentClass.LoaderName;\n\t\t\t// TODO NH: Not safe cast to Column\n\t\t\tint i = 0;\n\t\t\tforeach (Column col in persistentClass.Identifier.ColumnIterator)\n\t\t\t{\n\t\t\t\trootTableKeyColumnNames[i] = col.GetQuotedName(factory.Dialect);\n\t\t\t\tidentifierAliases[i] = col.GetAlias(factory.Dialect, persistentClass.RootTable);\n\t\t\t\ti++;\n\t\t\t}\n\t\t\t#endregion\n\t\t\t#region VERSION\n\t\t\tif (persistentClass.IsVersioned)\n\t\t\t{\n\t\t\t\tforeach (Column col in persistentClass.Version.ColumnIterator)\n\t\t\t\t{\n\t\t\t\t\tversionColumnName = col.GetQuotedName(factory.Dialect);\n\t\t\t\t\tbreak; //only happens once\n\t\t\t\t}\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tversionColumnName = null;\n\t\t\t}\n\t\t\t#endregion\n\t\t\t#region WHERE STRING\n\t\t\tsqlWhereString = !string.IsNullOrEmpty(persistentClass.Where) ? \"( \" + persistentClass.Where + \") \" : null;\n\t\t\tsqlWhereStringTemplate = sqlWhereString == null\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t? null\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t: Template.RenderWhereStringTemplate(sqlWhereString, factory.Dialect,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t factory.SQLFunctionRegistry);\n\t\t\t#endregion\n\t\t\t#region PROPERTIES\n\t\t\t// NH: see consistence with the implementation on EntityMetamodel where we are disabling lazy-properties for no lazy entities\n\t\t\tbool lazyAvailable = IsInstrumented && entityMetamodel.IsLazy;\n\t\t\tint hydrateSpan = entityMetamodel.PropertySpan;\n\t\t\tpropertyColumnSpans = new int[hydrateSpan];\n\t\t\tpropertySubclassNames = new string[hydrateSpan];\n\t\t\tpropertyColumnAliases = new string[hydrateSpan][];\n\t\t\tpropertyColumnNames = new string[hydrateSpan][];\n\t\t\tpropertyColumnFormulaTemplates = new string[hydrateSpan][];\n\t\t\tpropertyUniqueness = new bool[hydrateSpan];\n\t\t\tpropertySelectable = new bool[hydrateSpan];\n\t\t\tpropertyColumnUpdateable = new bool[hydrateSpan][];\n\t\t\tpropertyColumnInsertable = new bool[hydrateSpan][];\n\t\t\tvar thisClassProperties = new HashSet<Property>();\n\t\t\tlazyProperties = new HashSet<string>();\n\t\t\tList<string> lazyNames = new List<string>();\n\t\t\tList<int> lazyNumbers = new List<int>();\n\t\t\tList<IType> lazyTypes = new List<IType>();\n\t\t\tList<string[]> lazyColAliases = new List<string[]>();\n\t\t\ti = 0;\n\t\t\tbool foundFormula = false;\n\t\t\tforeach (Property prop in persistentClass.PropertyClosureIterator)\n\t\t\t{\n\t\t\t\tthisClassProperties.Add(prop);\n\t\t\t\tint span = prop.ColumnSpan;\n\t\t\t\tpropertyColumnSpans[i] = span;\n\t\t\t\tpropertySubclassNames[i] = prop.PersistentClass.EntityName;\n\t\t\t\tstring[] colNames = new string[span];\n\t\t\t\tstring[] colAliases = new string[span];\n\t\t\t\tstring[] templates = new string[span];\n\t\t\t\tint k = 0;\n\t\t\t\tforeach (ISelectable thing in prop.ColumnIterator)\n\t\t\t\t{\n\t\t\t\t\tcolAliases[k] = thing.GetAlias(factory.Dialect, prop.Value.Table);\n\t\t\t\t\tif (thing.IsFormula)\n\t\t\t\t\t{\n\t\t\t\t\t\tfoundFormula = true;\n\t\t\t\t\t\ttemplates[k] = thing.GetTemplate(factory.Dialect, factory.SQLFunctionRegistry);\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\tcolNames[k] = thing.GetTemplate(factory.Dialect, factory.SQLFunctionRegistry);\n\t\t\t\t\t}\n\t\t\t\t\tk++;\n\t\t\t\t}\n\t\t\t\tpropertyColumnNames[i] = colNames;\n\t\t\t\tpropertyColumnFormulaTemplates[i] = templates;\n\t\t\t\tpropertyColumnAliases[i] = colAliases;\n\t\t\t\tif (lazyAvailable && prop.IsLazy)\n\t\t\t\t{\n\t\t\t\t\tlazyProperties.Add(prop.Name);\n\t\t\t\t\tlazyNames.Add(prop.Name);\n\t\t\t\t\tlazyNumbers.Add(i);\n\t\t\t\t\tlazyTypes.Add(prop.Value.Type);\n\t\t\t\t\tlazyColAliases.Add(colAliases);\n\t\t\t\t}\n\t\t\t\tpropertyColumnUpdateable[i] = prop.Value.ColumnUpdateability;\n\t\t\t\tpropertyColumnInsertable[i] = prop.Value.ColumnInsertability;\n\t\t\t\tpropertySelectable[i] = prop.IsSelectable;\n\t\t\t\tpropertyUniqueness[i] = prop.Value.IsAlternateUniqueKey;\n\t\t\t\ti++;\n\t\t\t}\n\t\t\thasFormulaProperties = foundFormula;\n\t\t\tlazyPropertyColumnAliases = lazyColAliases.ToArray();\n\t\t\tlazyPropertyNames = lazyNames.ToArray();\n\t\t\tlazyPropertyNumbers = lazyNumbers.ToArray();\n\t\t\tlazyPropertyTypes = lazyTypes.ToArray();\n\t\t\t#endregion\n\t\t\t#region SUBCLASS PROPERTY CLOSURE\n\t\t\tList<string> columns = new List<string>();\n\t\t\tList<bool> columnsLazy = new List<bool>();\n\t\t\tList<string> aliases = new List<string>();\n\t\t\tList<string> formulas = new List<string>();\n\t\t\tList<string> formulaAliases = new List<string>();\n\t\t\tList<string> formulaTemplates = new List<string>();\n\t\t\tList<bool> formulasLazy = new List<bool>();\n\t\t\tList<IType> types = new List<IType>();\n\t\t\tList<string> names = new List<string>();\n\t\t\tList<string> classes = new List<string>();\n\t\t\tList<string[]> templates2 = new List<string[]>();\n\t\t\tList<string[]> propColumns = new List<string[]>();\n\t\t\tList<FetchMode> joinedFetchesList = new List<FetchMode>();\n\t\t\tList<CascadeStyle> cascades = new List<CascadeStyle>();\n\t\t\tList<bool> definedBySubclass = new List<bool>();\n\t\t\tList<int[]> propColumnNumbers = new List<int[]>();\n\t\t\tList<int[]> propFormulaNumbers = new List<int[]>();\n\t\t\tList<bool> columnSelectables = new List<bool>();\n\t\t\tList<bool> propNullables = new List<bool>();\n\t\t\tforeach (Property prop in persistentClass.SubclassPropertyClosureIterator)\n\t\t\t{\n\t\t\t\tnames.Add(prop.Name);\n\t\t\t\tclasses.Add(prop.PersistentClass.EntityName);\n\t\t\t\tbool isDefinedBySubclass = !thisClassProperties.Contains(prop);\n\t\t\t\tdefinedBySubclass.Add(isDefinedBySubclass);\n\t\t\t\tpropNullables.Add(prop.IsOptional || isDefinedBySubclass); //TODO: is this completely correct?\n\t\t\t\ttypes.Add(prop.Type);\n\t\t\t\tstring[] cols = new string[prop.ColumnSpan];\n\t\t\t\tstring[] forms = new string[prop.ColumnSpan];\n\t\t\t\tint[] colnos = new int[prop.ColumnSpan];\n\t\t\t\tint[] formnos = new int[prop.ColumnSpan];\n\t\t\t\tint l = 0;\n\t\t\t\tbool lazy = prop.IsLazy && lazyAvailable;\n\t\t\t\tforeach (ISelectable thing in prop.ColumnIterator)\n\t\t\t\t{\n\t\t\t\t\tif (thing.IsFormula)\n\t\t\t\t\t{\n\t\t\t\t\t\tstring template = thing.GetTemplate(factory.Dialect, factory.SQLFunctionRegistry);\n\t\t\t\t\t\tformnos[l] = formulaTemplates.Count;\n\t\t\t\t\t\tcolnos[l] = -1;\n\t\t\t\t\t\tformulaTemplates.Add(template);\n\t\t\t\t\t\tforms[l] = template;\n\t\t\t\t\t\tformulas.Add(thing.GetText(factory.Dialect));\n\t\t\t\t\t\tformulaAliases.Add(thing.GetAlias(factory.Dialect));\n\t\t\t\t\t\tformulasLazy.Add(lazy);\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\tstring colName = thing.GetTemplate(factory.Dialect, factory.SQLFunctionRegistry);\n\t\t\t\t\t\tcolnos[l] = columns.Count; //before add :-)\n\t\t\t\t\t\tformnos[l] = -1;\n\t\t\t\t\t\tcolumns.Add(colName);\n\t\t\t\t\t\tcols[l] = colName;\n\t\t\t\t\t\taliases.Add(thing.GetAlias(factory.Dialect, prop.Value.Table));\n\t\t\t\t\t\tcolumnsLazy.Add(lazy);\n\t\t\t\t\t\tcolumnSelectables.Add(prop.IsSelectable);\n\t\t\t\t\t}\n\t\t\t\t\tl++;\n\t\t\t\t}\n\t\t\t\tpropColumns.Add(cols);\n\t\t\t\ttemplates2.Add(forms);\n\t\t\t\tpropColumnNumbers.Add(colnos);\n\t\t\t\tpropFormulaNumbers.Add(formnos);\n\t\t\t\tjoinedFetchesList.Add(prop.Value.FetchMode);\n\t\t\t\tcascades.Add(prop.CascadeStyle);\n\t\t\t}\n\t\t\tsubclassColumnClosure = columns.ToArray();\n\t\t\tsubclassColumnAliasClosure = aliases.ToArray();\n\t\t\tsubclassColumnLazyClosure = columnsLazy.ToArray();\n\t\t\tsubclassColumnSelectableClosure = columnSelectables.ToArray();\n\t\t\tsubclassFormulaClosure = formulas.ToArray();\n\t\t\tsubclassFormulaTemplateClosure = formulaTemplates.ToArray();\n\t\t\tsubclassFormulaAliasClosure = formulaAliases.ToArray();\n\t\t\tsubclassFormulaLazyClosure = formulasLazy.ToArray();\n\t\t\tsubclassPropertyNameClosure = names.ToArray();\n\t\t\tsubclassPropertySubclassNameClosure = classes.ToArray();\n\t\t\tsubclassPropertyTypeClosure = types.ToArray();\n\t\t\tsubclassPropertyNullabilityClosure = propNullables.ToArray();\n\t\t\tsubclassPropertyFormulaTemplateClosure = templates2.ToArray();\n\t\t\tsubclassPropertyColumnNameClosure = propColumns.ToArray();\n\t\t\tsubclassPropertyColumnNumberClosure = propColumnNumbers.ToArray();\n\t\t\tsubclassPropertyFormulaNumberClosure = propFormulaNumbers.ToArray();\n\t\t\tsubclassPropertyCascadeStyleClosure = cascades.ToArray();\n\t\t\tsubclassPropertyFetchModeClosure = joinedFetchesList.ToArray();\n\t\t\tpropertyDefinedOnSubclass = definedBySubclass.ToArray();\n\t\t\t#endregion\n\t\t\t// Handle any filters applied to the class level\n\t\t\tfilterHelper = new FilterHelper(persistentClass.FilterMap, factory.Dialect, factory.SQLFunctionRegistry);\n\t\t\ttemporaryIdTableName = persistentClass.TemporaryIdTableName;\n\t\t\ttemporaryIdTableDDL = persistentClass.TemporaryIdTableDDL;\n\t\t}\n\t\tprotected abstract int[] SubclassColumnTableNumberClosure { get; }\n\t\tprotected abstract int[] SubclassFormulaTableNumberClosure { get; }\n\t\tprotected internal abstract int[] PropertyTableNumbersInSelect { get;}\n\t\tprotected internal abstract int[] PropertyTableNumbers { get;}\n\t\tpublic virtual string DiscriminatorColumnName\n\t\t{\n\t\t\tget { return Discriminator_Alias; }\n\t\t}\n\t\tprotected virtual string DiscriminatorFormulaTemplate\n\t\t{\n\t\t\tget { return null; }\n\t\t}\n\t\tpublic string[] RootTableKeyColumnNames\n\t\t{\n\t\t\tget { return rootTableKeyColumnNames; }\n\t\t}\n\t\tprotected internal SqlCommandInfo[] SQLUpdateByRowIdStrings\n\t\t{\n\t\t\tget\n\t\t\t{\n\t\t\t\tif (sqlUpdateByRowIdString == null)\n\t\t\t\t\tthrow new AssertionFailure(\"no update by row id\");\n\t\t\t\tSqlCommandInfo[] result = new SqlCommandInfo[TableSpan + 1];\n\t\t\t\tresult[0] = sqlUpdateByRowIdString;\n\t\t\t\tArray.Copy(sqlUpdateStrings, 0, result, 1, TableSpan);\n\t\t\t\treturn result;\n\t\t\t}\n\t\t}\n\t\tprotected internal SqlCommandInfo[] SQLLazyUpdateByRowIdStrings\n\t\t{\n\t\t\tget\n\t\t\t{\n\t\t\t\tif (sqlLazyUpdateByRowIdString == null)\n\t\t\t\t\tthrow new AssertionFailure(\"no update by row id\");\n\t\t\t\tSqlCommandInfo[] result = new SqlCommandInfo[TableSpan];\n\t\t\t\tresult[0] = sqlLazyUpdateByRowIdString;\n\t\t\t\tfor (int i = 1; i < TableSpan; i++)\n\t\t\t\t\tresult[i] = sqlLazyUpdateStrings[i];\n\t\t\t\treturn result;\n\t\t\t}\n\t\t}\n\t\tprotected SqlString SQLSnapshotSelectString\n\t\t{\n\t\t\tget { return sqlSnapshotSelectString; }\n\t\t}\n\t\tprotected SqlString SQLLazySelectString\n\t\t{\n\t\t\tget { return sqlLazySelectString; }\n\t\t}\n\t\t/// <summary>\n\t\t/// The queries that delete rows by id (and version)\n\t\t/// </summary>\n\t\tprotected SqlCommandInfo[] SqlDeleteStrings\n\t\t{\n\t\t\tget { return sqlDeleteStrings; }\n\t\t}\n\t\t/// <summary>\n\t\t/// The queries that insert rows with a given id\n\t\t/// </summary>\n\t\tprotected SqlCommandInfo[] SqlInsertStrings\n\t\t{\n\t\t\tget { return sqlInsertStrings; }\n\t\t}\n\t\t/// <summary>\n\t\t/// The queries that update rows by id (and version)\n\t\t/// </summary>\n\t\tprotected SqlCommandInfo[] SqlUpdateStrings\n\t\t{\n\t\t\tget { return sqlUpdateStrings; }\n\t\t}\n\t\tprotected internal SqlCommandInfo[] SQLLazyUpdateStrings\n\t\t{\n\t\t\tget { return sqlLazyUpdateStrings; }\n\t\t}\n\t\t/// <summary> \n\t\t/// The query that inserts a row, letting the database generate an id \n\t\t/// </summary>\n\t\t/// <returns> The IDENTITY-based insertion query. </returns>\n\t\tprotected internal SqlCommandInfo SQLIdentityInsertString\n\t\t{\n\t\t\tget { return sqlIdentityInsertString; }\n\t\t}\n\t\tprotected SqlString VersionSelectString\n\t\t{\n\t\t\tget { return sqlVersionSelectString; }\n\t\t}\n\t\tpublic bool IsBatchable => OptimisticLockMode == Versioning.OptimisticLock.None ||\n\t\t                           (!IsVersioned && OptimisticLockMode == Versioning.OptimisticLock.Version) ||\n\t\t                           Factory.Settings.IsBatchVersionedDataEnabled;\n\t\tpublic virtual string[] QuerySpaces\n\t\t{\n\t\t\tget { return PropertySpaces; }\n\t\t}\n\t\tprotected internal ISet<string> LazyProperties\n\t\t{\n\t\t\tget { return lazyProperties; }\n\t\t}\n\t\tpublic bool IsBatchLoadable\n\t\t{\n\t\t\tget { return batchSize > 1; }\n\t\t}\n\t\tpublic virtual string[] IdentifierColumnNames\n\t\t{\n\t\t\tget { return rootTableKeyColumnNames; }\n\t\t}\n\t\tprotected int IdentifierColumnSpan\n\t\t{\n\t\t\tget { return identifierColumnSpan; }\n\t\t}\n\t\tpublic virtual string VersionColumnName\n\t\t{\n\t\t\tget { return versionColumnName; }\n\t\t}\n\t\tprotected internal string VersionedTableName\n\t\t{\n\t\t\tget { return GetTableName(0); }\n\t\t}\n\t\tprotected internal bool[] SubclassColumnLaziness\n\t\t{\n\t\t\tget { return subclassColumnLazyClosure; }\n\t\t}\n\t\tprotected internal bool[] SubclassFormulaLaziness\n\t\t{\n\t\t\tget { return subclassFormulaLazyClosure; }\n\t\t}\n\t\t/// <summary> \n\t\t/// We can't immediately add to the cache if we have formulas\n\t\t/// which must be evaluated, or if we have the possibility of\n\t\t/// two concurrent updates to the same item being merged on\n\t\t/// the database. This can happen if (a) the item is not\n\t\t/// versioned and either (b) we have dynamic update enabled\n\t\t/// or (c) we have multiple tables holding the state of the\n\t\t/// item.\n\t\t/// </summary>\n\t\tpublic bool IsCacheInvalidationRequired\n\t\t{\n\t\t\tget { return HasFormulaProperties || (!IsVersioned && (entityMetamodel.IsDynamicUpdate || TableSpan > 1)); }\n\t\t}\n\t\tpublic bool IsLazyPropertiesCacheable\n\t\t{\n\t\t\tget { return isLazyPropertiesCacheable; }\n\t\t}\n\t\tpublic virtual string RootTableName\n\t\t{\n\t\t\tget { return GetSubclassTableName(0); }\n\t\t}\n\t\tpublic virtual string[] RootTableIdentifierColumnNames\n\t\t{\n\t\t\tget { return RootTableKeyColumnNames; }\n\t\t}\n\t\tprotected internal string[] PropertySubclassNames\n\t\t{\n\t\t\tget { return propertySubclassNames; }\n\t\t}\n\t\tprotected string[][] SubclassPropertyFormulaTemplateClosure\n\t\t{\n\t\t\tget { return subclassPropertyFormulaTemplateClosure; }\n\t\t}\n\t\tprotected IType[] SubclassPropertyTypeClosure\n\t\t{\n\t\t\tget { return subclassPropertyTypeClosure; }\n\t\t}\n\t\tprotected string[][] SubclassPropertyColumnNameClosure\n\t\t{\n\t\t\tget { return subclassPropertyColumnNameClosure; }\n\t\t}\n\t\tprotected string[] SubclassPropertyNameClosure\n\t\t{\n\t\t\tget { return subclassPropertyNameClosure; }\n\t\t}\n\t\tprotected string[] SubclassPropertySubclassNameClosure\n\t\t{\n\t\t\tget { return subclassPropertySubclassNameClosure; }\n\t\t}\n\t\tprotected string[] SubclassColumnClosure\n\t\t{\n\t\t\tget { return subclassColumnClosure; }\n\t\t}\n\t\tprotected string[] SubclassColumnAliasClosure\n\t\t{\n\t\t\tget { return subclassColumnAliasClosure; }\n\t\t}\n\t\tprotected string[] SubclassFormulaClosure\n\t\t{\n\t\t\tget { return subclassFormulaClosure; }\n\t\t}\n\t\tprotected string[] SubclassFormulaTemplateClosure\n\t\t{\n\t\t\tget { return subclassFormulaTemplateClosure; }\n\t\t}\n\t\tprotected string[] SubclassFormulaAliasClosure\n\t\t{\n\t\t\tget { return subclassFormulaAliasClosure; }\n\t\t}\n\t\tpublic string IdentitySelectString\n\t\t{\n\t\t\tget\n\t\t\t{\n\t\t\t\tif (identitySelectString == null)\n\t\t\t\t\tidentitySelectString =\n\t\t\t\t\t\tFactory.Dialect.GetIdentitySelectString(GetTableName(0), GetKeyColumns(0)[0],\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tIdentifierType.SqlTypes(Factory)[0].DbType);\n\t\t\t\treturn identitySelectString;\n\t\t\t}\n\t\t}\n\t\tprivate string RootAlias\n\t\t{\n\t\t\tget { return StringHelper.GenerateAlias(EntityName); }\n\t\t}\n\t\tpublic ISessionFactoryImplementor Factory\n\t\t{\n\t\t\tget { return factory; }\n\t\t}\n\t\tpublic EntityMetamodel EntityMetamodel\n\t\t{\n\t\t\tget { return entityMetamodel; }\n\t\t}\n\t\tpublic ICacheConcurrencyStrategy Cache\n\t\t{\n\t\t\tget { return cache; }\n\t\t}\n\t\tpublic ICacheEntryStructure CacheEntryStructure\n\t\t{\n\t\t\tget { return cacheEntryStructure; }\n\t\t}\n\t\tpublic IComparer VersionComparator\n\t\t{\n\t\t\tget { return IsVersioned ? VersionType.Comparator : null; }\n\t\t}\n\t\tpublic string EntityName\n\t\t{\n\t\t\tget { return entityMetamodel.Name; }\n\t\t}\n\t\tpublic EntityType EntityType\n\t\t{\n\t\t\tget { return entityMetamodel.EntityType; }\n\t\t}\n\t\tpublic virtual bool IsPolymorphic\n\t\t{\n\t\t\tget { return entityMetamodel.IsPolymorphic; }\n\t\t}\n\t\tpublic virtual bool IsInherited\n\t\t{\n\t\t\tget { return entityMetamodel.IsInherited; }\n\t\t}\n\t\tpublic virtual IVersionType VersionType\n\t\t{\n\t\t\tget { return LocateVersionType(); }\n\t\t}\n\t\tpublic virtual int VersionProperty\n\t\t{\n\t\t\tget { return entityMetamodel.VersionPropertyIndex; }\n\t\t}\n\t\tpublic virtual bool IsVersioned\n\t\t{\n\t\t\tget { return entityMetamodel.IsVersioned; }\n\t\t}\n\t\tpublic virtual bool IsIdentifierAssignedByInsert\n\t\t{\n\t\t\tget { return entityMetamodel.IdentifierProperty.IsIdentifierAssignedByInsert; }\n\t\t}\n\t\tpublic virtual bool IsMutable\n\t\t{\n\t\t\tget { return entityMetamodel.IsMutable; }\n\t\t}\n\t\tpublic virtual bool IsAbstract\n\t\t{\n\t\t\tget { return entityMetamodel.IsAbstract; }\n\t\t}\n\t\tpublic virtual IIdentifierGenerator IdentifierGenerator\n\t\t{\n\t\t\tget { return entityMetamodel.IdentifierProperty.IdentifierGenerator; }\n\t\t}\n\t\tpublic virtual string RootEntityName\n\t\t{\n\t\t\tget { return entityMetamodel.RootName; }\n\t\t}\n\t\tpublic virtual IClassMetadata ClassMetadata\n\t\t{\n\t\t\tget { return this; }\n\t\t}\n\t\tpublic virtual string MappedSuperclass\n\t\t{\n\t\t\tget { return entityMetamodel.Superclass; }\n\t\t}\n\t\tpublic virtual bool IsExplicitPolymorphism\n\t\t{\n\t\t\tget { return entityMetamodel.IsExplicitPolymorphism; }\n\t\t}\n\t\tpublic string[] KeyColumnNames\n\t\t{\n\t\t\tget { return IdentifierColumnNames; }\n\t\t}\n\t\tpublic string[] JoinColumnNames\n\t\t{\n\t\t\tget { return KeyColumnNames; }\n\t\t}\n\t\tpublic string Name\n\t\t{\n\t\t\tget { return EntityName; }\n\t\t}\n\t\tpublic bool IsCollection\n\t\t{\n\t\t\tget { return false; }\n\t\t}\n\t\tpublic IType Type\n\t\t{\n\t\t\tget { return entityMetamodel.EntityType; }\n\t\t}\n\t\tpublic bool IsSelectBeforeUpdateRequired\n\t\t{\n\t\t\tget { return entityMetamodel.IsSelectBeforeUpdate; }\n\t\t}\n\t\tpublic bool IsVersionPropertyGenerated\n\t\t{\n\t\t\tget { return IsVersioned && PropertyUpdateGenerationInclusions[VersionProperty] != ValueInclusion.None; }\n\t\t}\n\t\tpublic bool VersionPropertyInsertable\n\t\t{\n\t\t\tget { return IsVersioned && PropertyInsertability[VersionProperty]; }\n\t\t}\n\t\tpublic virtual string[] PropertyNames\n\t\t{\n\t\t\tget { return entityMetamodel.PropertyNames; }\n\t\t}\n\t\tpublic virtual IType[] PropertyTypes\n\t\t{\n\t\t\tget { return entityMetamodel.PropertyTypes; }\n\t\t}\n\t\tpublic bool[] PropertyLaziness\n\t\t{\n\t\t\tget { return entityMetamodel.PropertyLaziness; }\n\t\t}\n\t\tpublic virtual bool[] PropertyCheckability\n\t\t{\n\t\t\tget { return entityMetamodel.PropertyCheckability; }\n\t\t}\n\t\tpublic bool[] NonLazyPropertyUpdateability\n\t\t{\n\t\t\tget { return entityMetamodel.NonlazyPropertyUpdateability; }\n\t\t}\n\t\tpublic virtual bool[] PropertyInsertability\n\t\t{\n\t\t\tget { return entityMetamodel.PropertyInsertability; }\n\t\t}\n\t\tpublic ValueInclusion[] PropertyInsertGenerationInclusions\n\t\t{\n\t\t\tget { return entityMetamodel.PropertyInsertGenerationInclusions; }\n\t\t}\n\t\tpublic ValueInclusion[] PropertyUpdateGenerationInclusions\n\t\t{\n\t\t\tget { return entityMetamodel.PropertyUpdateGenerationInclusions; }\n\t\t}\n\t\tpublic virtual bool[] PropertyNullability\n\t\t{\n\t\t\tget { return entityMetamodel.PropertyNullability; }\n\t\t}\n\t\tpublic virtual bool[] PropertyVersionability\n\t\t{\n\t\t\tget { return entityMetamodel.PropertyVersionability; }\n\t\t}\n\t\tpublic virtual CascadeStyle[] PropertyCascadeStyles\n\t\t{\n\t\t\tget { return entityMetamodel.CascadeStyles; }\n\t\t}\n\t\tpublic virtual bool IsMultiTable\n\t\t{\n\t\t\tget { return false; }\n\t\t}\n\t\tpublic string TemporaryIdTableName\n\t\t{\n\t\t\tget { return temporaryIdTableName; }\n\t\t}\n\t\tpublic string TemporaryIdTableDDL\n\t\t{\n\t\t\tget { return temporaryIdTableDDL; }\n\t\t}\n\t\tprotected int PropertySpan\n\t\t{\n\t\t\tget { return entityMetamodel.PropertySpan; }\n\t\t}\n\t\tpublic virtual string IdentifierPropertyName\n\t\t{\n\t\t\tget { return entityMetamodel.IdentifierProperty.Name; }\n\t\t}\n\t\tpublic virtual IType GetIdentifierType(int j)\n\t\t{\n\t\t\treturn IdentifierType;\n\t\t}\n\t\tpublic virtual IType IdentifierType\n\t\t{\n\t\t\tget { return entityMetamodel.IdentifierProperty.Type; }\n\t\t}\n\t\tpublic int[] NaturalIdentifierProperties\n\t\t{\n\t\t\tget { return entityMetamodel.NaturalIdentifierProperties; }\n\t\t}\n\t\tpublic abstract string[][] ConstraintOrderedTableKeyColumnClosure { get;}\n\t\tpublic abstract IType DiscriminatorType { get;}\n\t\tpublic abstract string[] ConstraintOrderedTableNameClosure { get;}\n\t\tpublic abstract string DiscriminatorSQLValue { get;}\n\t\tpublic abstract object DiscriminatorValue { get;}\n\t\tpublic abstract string[] SubclassClosure { get; }\n\t\tpublic abstract string[] PropertySpaces { get;}\n\t\tprotected virtual void AddDiscriminatorToInsert(SqlInsertBuilder insert) { }\n\t\tprotected virtual void AddDiscriminatorToSelect(SelectFragment select, string name, string suffix) { }\n\t\tpublic abstract string GetSubclassTableName(int j);\n\t\t//gets the identifier for a join table if other than pk\n\t\tprotected virtual object GetJoinTableId(int j, object[] fields)\n\t\t{\n\t\t\treturn null;\n\t\t}\n\t\tprotected virtual object GetJoinTableId(int table, object obj)\n\t\t{\n\t\t\treturn null;\n\t\t}\n\t\t//for joining to other keys than pk\n\t\tprotected virtual string[] GetJoinIdKeyColumns(int j)\n\t\t{\n\t\t\treturn IdentifierColumnNames;\n\t\t}\n\t\tprotected abstract string[] GetSubclassTableKeyColumns(int j);\n\t\tprotected abstract bool IsClassOrSuperclassTable(int j);\n\t\tprotected abstract int SubclassTableSpan { get; }\n\t\tprotected abstract int TableSpan { get; }\n\t\tprotected abstract bool IsTableCascadeDeleteEnabled(int j);\n\t\tprotected abstract string GetTableName(int table);\n\t\tprotected abstract string[] GetKeyColumns(int table);\n\t\tprotected abstract bool IsPropertyOfTable(int property, int table);\n\t\tprotected virtual int? GetRefIdColumnOfTable(int table)\n\t\t{\n\t\t\treturn null;\n\t\t}\n\t\tprotected virtual Tuple.Property GetIdentiferProperty(int table)\n\t\t{\n\t\t\tvar refId = GetRefIdColumnOfTable(table);\n\t\t\tif (refId == null)\n\t\t\t\treturn entityMetamodel.IdentifierProperty;\n\t\t\treturn entityMetamodel.Properties[refId.Value];\n\t\t}\n\t\tprotected virtual bool IsIdOfTable(int property, int table)\n\t\t{\n\t\t\treturn false;\n\t\t}\n\t\tprotected abstract int GetSubclassPropertyTableNumber(int i);\n\t\tpublic abstract string FilterFragment(string alias);\n\t\tprotected internal virtual string DiscriminatorAlias\n\t\t{\n\t\t\tget { return Discriminator_Alias; }\n\t\t}\n\t\tprotected virtual bool IsInverseTable(int j)\n\t\t{\n\t\t\treturn false;\n\t\t}\n\t\tprotected virtual bool IsNullableTable(int j)\n\t\t{\n\t\t\treturn false;\n\t\t}\n\t\tprotected virtual bool IsNullableSubclassTable(int j)\n\t\t{\n\t\t\treturn false;\n\t\t}\n\t\tprotected virtual bool IsInverseSubclassTable(int j)\n\t\t{\n\t\t\treturn false;\n\t\t}\n\t\tpublic virtual bool IsSubclassEntityName(string entityName)\n\t\t{\n\t\t\treturn entityMetamodel.SubclassEntityNames.Contains(entityName);\n\t\t}\n\t\tprotected bool[] TableHasColumns\n\t\t{\n\t\t\tget { return tableHasColumns; }\n\t\t}\n\t\tprotected bool IsInsertCallable(int j)\n\t\t{\n\t\t\treturn insertCallable[j];\n\t\t}\n\t\tprotected bool IsUpdateCallable(int j)\n\t\t{\n\t\t\treturn updateCallable[j];\n\t\t}\n\t\tprotected bool IsDeleteCallable(int j)\n\t\t{\n\t\t\treturn deleteCallable[j];\n\t\t}\n\t\tprotected virtual bool IsSubclassPropertyDeferred(string propertyName, string entityName)\n\t\t{\n\t\t\treturn false;\n\t\t}\n\t\tprotected virtual bool IsSubclassTableSequentialSelect(int table)\n\t\t{\n\t\t\treturn false;\n\t\t}\n\t\tpublic virtual bool HasSequentialSelect\n\t\t{\n\t\t\tget { return false; }\n\t\t}\n\t\t/// <summary>\n\t\t/// Decide which tables need to be updated\n\t\t/// </summary>\n\t\t/// <param name=\"dirtyProperties\">The indices of all the entity properties considered dirty.</param>\n\t\t/// <param name=\"hasDirtyCollection\">Whether any collections owned by the entity which were considered dirty. </param>\n\t\t/// <returns> Array of booleans indicating which table require updating. </returns>\n\t\t/// <remarks>\n\t\t/// The return here is an array of boolean values with each index corresponding\n\t\t/// to a given table in the scope of this persister.\n\t\t/// </remarks>\n\t\tprotected virtual bool[] GetTableUpdateNeeded(int[] dirtyProperties, bool hasDirtyCollection)\n\t\t{\n\t\t\tif (dirtyProperties == null)\n\t\t\t{\n\t\t\t\treturn TableHasColumns; //for object that came in via update()\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tbool[] updateability = PropertyUpdateability;\n\t\t\t\tint[] propertyTableNumbers = PropertyTableNumbers;\n\t\t\t\tbool[] tableUpdateNeeded = new bool[TableSpan];\n\t\t\t\tfor (int i = 0; i < dirtyProperties.Length; i++)\n\t\t\t\t{\n\t\t\t\t\tint property = dirtyProperties[i];\n\t\t\t\t\tint table = propertyTableNumbers[property];\n\t\t\t\t\ttableUpdateNeeded[table] = tableUpdateNeeded[table] ||\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t (GetPropertyColumnSpan(property) > 0 && updateability[property]);\n\t\t\t\t}\n\t\t\t\tif (IsVersioned)\n\t\t\t\t{\n\t\t\t\t\t// NH-2386 when there isn't dirty-properties and the version is generated even in UPDATE\n\t\t\t\t\t// we can't execute an UPDATE because there isn't something to UPDATE\n\t\t\t\t\tif(!entityMetamodel.VersionProperty.IsUpdateGenerated)\n\t\t\t\t\t{\n\t\t\t\t\t\ttableUpdateNeeded[0] = tableUpdateNeeded[0] ||\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t Versioning.IsVersionIncrementRequired(dirtyProperties, hasDirtyCollection,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t PropertyVersionability);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treturn tableUpdateNeeded;\n\t\t\t}\n\t\t}\n\t\tpublic virtual bool HasRowId\n\t\t{\n\t\t\tget { return rowIdName != null; }\n\t\t}\n\t\tprotected internal virtual SqlString GenerateLazySelectString()\n\t\t{\n\t\t\tif (!entityMetamodel.HasLazyProperties)\n\t\t\t\treturn null;\n\t\t\tHashSet<int> tableNumbers = new HashSet<int>();\n\t\t\tList<int> columnNumbers = new List<int>();\n\t\t\tList<int> formulaNumbers = new List<int>();\n\t\t\tfor (int i = 0; i < lazyPropertyNames.Length; i++)\n\t\t\t{\n\t\t\t\t// all this only really needs to consider properties\n\t\t\t\t// of this class, not its subclasses, but since we\n\t\t\t\t// are reusing code used for sequential selects, we\n\t\t\t\t// use the subclass closure\n\t\t\t\tint propertyNumber = GetSubclassPropertyIndex(lazyPropertyNames[i]);\n\t\t\t\tint tableNumber = GetSubclassPropertyTableNumber(propertyNumber);\n\t\t\t\ttableNumbers.Add(tableNumber);\n\t\t\t\tint[] colNumbers = subclassPropertyColumnNumberClosure[propertyNumber];\n\t\t\t\tfor (int j = 0; j < colNumbers.Length; j++)\n\t\t\t\t{\n\t\t\t\t\tif (colNumbers[j] != -1)\n\t\t\t\t\t{\n\t\t\t\t\t\tcolumnNumbers.Add(colNumbers[j]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tint[] formNumbers = subclassPropertyFormulaNumberClosure[propertyNumber];\n\t\t\t\tfor (int j = 0; j < formNumbers.Length; j++)\n\t\t\t\t{\n\t\t\t\t\tif (formNumbers[j] != -1)\n\t\t\t\t\t{\n\t\t\t\t\t\tformulaNumbers.Add(formNumbers[j]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (columnNumbers.Count == 0 && formulaNumbers.Count == 0)\n\t\t\t{\n\t\t\t\t// only one-to-one is lazy fetched\n\t\t\t\treturn null;\n\t\t\t}\n\t\t\treturn RenderSelect(tableNumbers.ToArray(), columnNumbers.ToArray(), formulaNumbers.ToArray());\n\t\t}\n\t\tpublic virtual object InitializeLazyProperty(string fieldName, object entity, ISessionImplementor session)\n\t\t{\n\t\t\tobject id = session.GetContextEntityIdentifier(entity);\n\t\t\tEntityEntry entry = session.PersistenceContext.GetEntry(entity);\n\t\t\tif (entry == null)\n\t\t\t\tthrow new HibernateException(\"entity is not associated with the session: \" + id);\n\t\t\tif (log.IsDebugEnabled)\n\t\t\t{\n\t\t\t\tlog.Debug(\n\t\t\t\t\tstring.Format(\"initializing lazy properties of: {0}, field access: {1}\",\n\t\t\t\t\t\t\t\t\t\t\t\tMessageHelper.InfoString(this, id, Factory), fieldName));\n\t\t\t}\n\t\t\tif (HasCache && session.CacheMode.HasFlag(CacheMode.Get))\n\t\t\t{\n\t\t\t\tCacheKey cacheKey = session.GenerateCacheKey(id, IdentifierType, EntityName);\n\t\t\t\tobject ce = Cache.Get(cacheKey, session.Timestamp);\n\t\t\t\tif (ce != null)\n\t\t\t\t{\n\t\t\t\t\tCacheEntry cacheEntry = (CacheEntry)CacheEntryStructure.Destructure(ce, factory);\n\t\t\t\t\tif (!cacheEntry.AreLazyPropertiesUnfetched)\n\t\t\t\t\t{\n\t\t\t\t\t\t//note early exit here:\n\t\t\t\t\t\treturn InitializeLazyPropertiesFromCache(fieldName, entity, session, entry, cacheEntry);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn InitializeLazyPropertiesFromDatastore(fieldName, entity, session, id, entry);\n\t\t}\n\t\tprivate object InitializeLazyPropertiesFromDatastore(string fieldName, object entity, ISessionImplementor session, object id, EntityEntry entry)\n\t\t{\n\t\t\tif (!HasLazyProperties)\n\t\t\t\tthrow new AssertionFailure(\"no lazy properties\");\n\t\t\tlog.Debug(\"initializing lazy properties from datastore\");\n\t\t\tusing (new SessionIdLoggingContext(session.SessionId)) \n\t\t\ttry\n\t\t\t{\n\t\t\t\tobject result = null;\n\t\t\t\tDbCommand ps = null;\n\t\t\t\tDbDataReader rs = null;\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\tSqlString lazySelect = SQLLazySelectString;\n\t\t\t\t\tif (lazySelect != null)\n\t\t\t\t\t{\n\t\t\t\t\t\t// null sql means that the only lazy properties\n\t\t\t\t\t\t// are shared PK one-to-one associations which are\n\t\t\t\t\t\t// handled differently in the Type#nullSafeGet code...\n\t\t\t\t\t\tps = session.Batcher.PrepareCommand(CommandType.Text, lazySelect, IdentifierType.SqlTypes(Factory));\n\t\t\t\t\t\tIdentifierType.NullSafeSet(ps, id, 0, session);\n\t\t\t\t\t\trs = session.Batcher.ExecuteReader(ps);\n\t\t\t\t\t\trs.Read();\n\t\t\t\t\t}\n\t\t\t\t\tobject[] snapshot = entry.LoadedState;\n\t\t\t\t\tfor (int j = 0; j < lazyPropertyNames.Length; j++)\n\t\t\t\t\t{\n\t\t\t\t\t\tobject propValue = lazyPropertyTypes[j].NullSafeGet(rs, lazyPropertyColumnAliases[j], session, entity);\n\t\t\t\t\t\tif (InitializeLazyProperty(fieldName, entity, session, snapshot, j, propValue))\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tresult = propValue;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfinally\n\t\t\t\t{\n\t\t\t\t\tsession.Batcher.CloseCommand(ps, rs);\n\t\t\t\t}\n\t\t\t\tlog.Debug(\"done initializing lazy properties\");\n\t\t\t\treturn result;\n\t\t\t}\n\t\t\tcatch (DbException sqle)\n\t\t\t{\n\t\t\t\tvar exceptionContext = new AdoExceptionContextInfo\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\tSqlException = sqle,\n\t\t\t\t\t\t\t\t\t\t\tMessage =\n\t\t\t\t\t\t\t\t\t\t\t\t\"could not initialize lazy properties: \" + MessageHelper.InfoString(this, id, Factory),\n\t\t\t\t\t\t\t\t\t\t\tSql = SQLLazySelectString.ToString(),\n\t\t\t\t\t\t\t\t\t\t\tEntityName = EntityName,\n\t\t\t\t\t\t\t\t\t\t\tEntityId = id\n\t\t\t\t\t\t\t\t\t\t};\n\t\t\t\tthrow ADOExceptionHelper.Convert(Factory.SQLExceptionConverter, exceptionContext);\n\t\t\t}\n\t\t}\n\t\tprivate object InitializeLazyPropertiesFromCache(string fieldName, object entity, ISessionImplementor session, EntityEntry entry, CacheEntry cacheEntry)\n\t\t{\n\t\t\tlog.Debug(\"initializing lazy properties from second-level cache\");\n\t\t\tobject result = null;\n\t\t\tobject[] disassembledValues = cacheEntry.DisassembledState;\n\t\t\tobject[] snapshot = entry.LoadedState;\n", "outputs": ["\t\t\tfor (int j = 0; j < lazyPropertyNames.Length; j++)"], "input_length": 5783, "output_length": 13, "length": 5796, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "c8f18948789575fec8ba5e8a6a1f28d8df3a170151bb60fc81007a48dd91058f"}
{"input": "", "context": "import argparse\nimport numpy as np\nimport scipy.linalg\nimport scipy.spatial as spatial\nimport scipy.sparse.linalg as spla\nimport subprocess\ntry:\n  import pickle as cpickle\nexcept:\n  try:\n    import cpickle\n  except:\n    import _pickle as cpickle\nfrom functools import partial\nimport sys\nimport time\nimport copy\nimport scipy.sparse as sp\nfrom sksparse.cholmod import cholesky\n#import matplotlib.pyplot as plt\n# Find project functions\nfound_functions = False\npath_to_append = ''\nsys.path.append('../../')\nwhile found_functions is False:\n    try:\n        from Lub_Solver import Lub_Solver as LS\n        from stochastic_forcing import stochastic_forcing as stochastic\n        from mobility import mobility as mb\n        from body import body\n        from read_input import read_input\n        from read_input import read_vertex_file\n        from read_input import read_clones_file\n        from read_input import read_slip_file\n        import general_application_utils\n        import multi_bodies_functions\n        found_functions = True\n    except ImportError:\n        path_to_append += '../'\n        print('searching functions in path ', path_to_append)\n        sys.path.append(path_to_append)\n        if len(path_to_append) > 21:\n            print('\\nProjected functions not found. Edit path in multi_bodies.py')\n            sys.exit()\nif __name__ == '__main__':\n    # Get command line arguments\n    parser = argparse.ArgumentParser(description='Run a multi-body simulation and save trajectory.')\n    parser.add_argument('--input-file', dest='input_file', type=str, default='data.main', help='name of the input file')\n    parser.add_argument('--print-residual', action='store_true', help='print gmres and lanczos residuals')\n    args = parser.parse_args()\n    input_file = args.input_file\n    # Read input file\n    read = read_input.ReadInput(input_file)\n    # Set some variables for the simulation\n    eta = read.eta\n    a = read.blob_radius\n    output_name = read.output_name\n    structures = read.structures\n    print(structures)\n    structures_ID = read.structures_ID\n    \n    # Copy input file to output\n    subprocess.call([\"cp\", input_file, output_name + '.inputfile'])\n    # Set random generator state\n    if read.random_state is not None:\n      with open(read.random_state, 'rb') as f:\n\tnp.random.set_state(cpickle.load(f))\n    elif read.seed is not None:\n      np.random.seed(int(read.seed))\n    \n    # Save random generator state\n    with open(output_name + '.random_state', 'wb') as f:\n      cpickle.dump(np.random.get_state(), f)\n    # Create rigid bodies\n    bodies = []\n    body_types = []\n    body_names = []\n    for ID, structure in enumerate(structures):\n      print('Creating structures = ', structure[1])\n      # Read vertex and clones files\n      struct_ref_config = read_vertex_file.read_vertex_file(structure[0])\n      num_bodies_struct, struct_locations, struct_orientations = read_clones_file.read_clones_file(structure[1])\n      # Read slip file if it exists\n      slip = None\n      if(len(structure) > 2):\n\tslip = read_slip_file.read_slip_file(structure[2])\n      body_types.append(num_bodies_struct)\n      body_names.append(structures_ID[ID])\n      # Create each body of type structure\n      for i in range(num_bodies_struct):\n\tb = body.Body(struct_locations[i], struct_orientations[i], struct_ref_config, a)\n\tb.ID = structures_ID[ID]\n\t# Calculate body length for the RFD\n\tif i == 0:\n\t  b.calc_body_length()\n\telse:\n\t  b.body_length = bodies[-1].body_length\n\t# Append bodies to total bodies list\n\tbodies.append(b)\n    bodies = np.array(bodies)\n    # Set some more variables\n    num_of_body_types = len(body_types)\n    num_bodies = bodies.size\n    num_particles = len(bodies)\n    Nblobs = sum([x.Nblobs for x in bodies])\n    \n    cutoff = read.Lub_Cut\n    \n    #L = read.periodic_length\n    phi=0.4\n    Lphi = np.sqrt(np.pi*(a**2)*num_particles/phi)\n    L = np.array([Lphi, Lphi, 0])\n    \n    n_steps = read.n_steps \n    n_save = read.n_save\n    dt = read.dt \n    \n    print(L)\n    \n    for b in bodies:\n      for i in range(3):\n\tif L[i] > 0:\n\t  while b.location[i] < 0:\n\t    b.location[i] += L[i]\n\t  while b.location[i] > L[i]:\n\t    b.location[i] -= L[i]\n\t  \n    \n    \n    firm_delta = read.firm_delta\n    debye_length_delta = 2.0*a*firm_delta/np.log(1.0e1) \n    repulsion_strength_delta = read.repulsion_strength_firm\n    \n    LSolv = LS(bodies,a,eta,cutoff,L,debye_length=firm_delta)\n    LSolv.dt = dt\n    LSolv.kT = read.kT\n    LSolv.tolerance = read.solver_tolerance\n    \n    multi_bodies_functions.calc_blob_blob_forces = multi_bodies_functions.set_blob_blob_forces(read.blob_blob_force_implementation)\n    multi_bodies_functions.calc_body_body_forces_torques = multi_bodies_functions.set_body_body_forces_torques(read.body_body_force_torque_implementation)\n    \n    \n    import time\n    t0 = time.time()\n    LSolv.Set_R_Mats()\n    dt1 = time.time() - t0\n    print((\"Make R mats time : %s\" %dt1))\n    \n    Omega = 9.0*2.0*np.pi\n    \n    total_rej = 0\n    for n in range(n_steps):\n      print(n)\n      \n      FT_calc = partial(multi_bodies_functions.force_torque_calculator_sort_by_bodies, \n                                               g = read.g, \n                                               repulsion_strength_firm = repulsion_strength_delta,\n                                               debye_length_firm = debye_length_delta, \n                                               firm_delta = firm_delta,\n                                               repulsion_strength_wall = read.repulsion_strength_wall,\n                                               debye_length_wall = read.debye_length_wall,\n                                               repulsion_strength = read.repulsion_strength, \n                                               debye_length = read.debye_length, \n                                               periodic_length = L,\n                                               omega = 0, #Omega ############## CHANGE ME TO ZERO FOR CONST OMEGA AND TO 'Omega' FOR CONST TORQUE\n                                               eta = eta,\n                                               a = a)\n      \n      \n      Torque_Lim = 1.9904\n      Output_Vel = True\n      t0 = time.time()\n      reject_wall, reject_jump, Trap_vel_t = LSolv.Update_Bodies_Trap(FT_calc,Omega=Omega,Out_Torque=Output_Vel, Cut_Torque=Torque_Lim)\n      dt1 = time.time() - t0\n     \n      ### Update rollers with const. omega and no torque limitaion \n      #Output_Vel = False\n      #t0 = time.time()\n      #reject_wall, reject_jump = LSolv.Update_Bodies_Trap(FT_calc,Omega=Omega)\n      #dt1 = time.time() - t0\n      ### Update rollers with const. torque (ALSO MAKE CHANGE ON LINE 169 in FT_calc)\n      #Output_Vel = False\n      #t0 = time.time()\n      #reject_wall, reject_jump = LSolv.Update_Bodies_Trap(FT_calc)\n      #dt1 = time.time() - t0\n      \n      print((\"walltime for time step : %s\" %dt1))\n      print((\"Number of rejected timesteps wall: %s\" %LSolv.num_rejections_wall))\n      print((\"Number of rejected timesteps jump: %s\" %LSolv.num_rejections_jump))\n      \n      if n % n_save == 0:\n\tprint((\"SAVING CONFIGURATION : %s\" %n))\n\tif (reject_wall+reject_jump) == 0:\n\t  body_offset = 0\n\t  for i, ID in enumerate(structures_ID):\n\t    name = output_name + '.' + ID + '.config'\n\t    if n == 0:\n\t      status = 'w'\n\t    else:\n\t      status = 'a'\n\t    with open(name, status) as f_ID:\n\t      f_ID.write(str(body_types[i]) + '\\n')\n\t      for j in range(body_types[i]):\n\t\torientation = bodies[body_offset + j].orientation.entries\n\t\tf_ID.write('%s %s %s %s %s %s %s\\n' % (bodies[body_offset + j].location[0], \n\t\t\t\t\t\t\tbodies[body_offset + j].location[1], \n\t\t\t\t\t\t\tbodies[body_offset + j].location[2], \n\t\t\t\t\t\t\torientation[0], \n\t\t\t\t\t\t\torientation[1], \n\t\t\t\t\t\t\torientation[2], \n\t\t\t\t\t\t\torientation[3]))\n\t      body_offset += body_types[i]\n\t      \n\t  ##########################\n\t  if Output_Vel:\n\t    body_offset = 0\n\t    for i, ID in enumerate(structures_ID):\n\t      name = output_name + '.' + ID + '.Torque'\n\t      if n == 0:\n\t\tstatus = 'w'\n\t      else:\n\t\tstatus = 'a'\n\t      with open(name, status) as f_ID:\n\t\tf_ID.write(str(body_types[i]) + '\\n')\n\t\tfor j in range(body_types[i]):\n\t\t  t = Trap_vel_t[3*(body_offset+j):3*(body_offset+j)+3]\n\t\t  f_ID.write('%s %s %s\\n' % (t[0], \n\t\t\t\t\t\t      t[1], \n\t\t\t\t\t\t      t[2]))\n\t\tbody_offset += body_types[i]\n\t      \n\telse:\n\t  total_rej += 1\n\t  body_offset = 0\n\t  for i, ID in enumerate(structures_ID):\n\t    name = output_name + '.' + ID + '.rejected_config'\n", "outputs": ["\t    if total_rej == 1:"], "input_length": 1434, "output_length": 5, "length": 1439, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "9b60b7534f5a0cb5c9c20579cd07e2237579150c428b807066425e5c4e089de5"}
{"input": "", "context": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n#\n# Copyright (C) 2019-2021 Pyresample developers\n#\n# This program is free software: you can redistribute it and/or modify it under\n# the terms of the GNU Lesser General Public License as published by the Free\n# Software Foundation, either version 3 of the License, or (at your option) any\n# later version.\n#\n# This program is distributed in the hope that it will be useful, but WITHOUT\n# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n# FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more\n# details.\n#\n# You should have received a copy of the GNU Lesser General Public License along\n# with this program.  If not, see <http://www.gnu.org/licenses/>.\n\"\"\"Area config handling and creation utilities.\"\"\"\nimport io\nimport logging\nimport math\nimport os\nimport pathlib\nimport warnings\nfrom typing import Any, Union\nimport numpy as np\nimport yaml\nfrom pyproj import Proj, Transformer\nfrom pyproj.crs import CRS, CRSError\nfrom pyresample.utils import proj4_str_to_dict\ntry:\n    from xarray import DataArray\nexcept ImportError:\n    class DataArray(object):\n        \"\"\"Stand-in for DataArray for holding units information.\"\"\"\n        def __init__(self, data, attrs=None):\n            \"\"\"Initialize 'attrs' and 'data' properties.\"\"\"\n            self.attrs = attrs or {}\n            self.data = np.array(data)\n        def __getitem__(self, item):\n            \"\"\"Get a subset of the data contained in a DataArray.\"\"\"\n            return DataArray(self.data[item], attrs=self.attrs)\n        def __getattr__(self, item):\n            \"\"\"Get metadata property from 'attrs'.\"\"\"\n            return self.attrs[item]\n        def __len__(self):\n            \"\"\"Get size of the data.\"\"\"\n            return len(self.data)\nclass AreaNotFound(KeyError):\n    \"\"\"Exception raised when specified are is no found in file.\"\"\"\ndef load_area(area_file_name, *regions):\n    \"\"\"Load area(s) from area file.\n    Parameters\n    ----------\n    area_file_name : str, pathlib.Path, stream, or list thereof\n        List of paths or streams.  Any str or pathlib.Path will be\n        interpreted as a path to a file.  Any stream will be interpreted\n        as containing a yaml definition file.  To read directly from a string,\n        use :func:`load_area_from_string`.\n    regions : str argument list\n        Regions to parse. If no regions are specified all\n        regions in the file are returned\n    Returns\n    -------\n    area_defs : AreaDefinition or list\n        If one area name is specified a single AreaDefinition object is returned.\n        If several area names are specified a list of AreaDefinition objects is returned\n    Raises\n    ------\n    AreaNotFound:\n        If a specified area name is not found\n    \"\"\"\n    area_list = parse_area_file(area_file_name, *regions)\n    if len(area_list) == 1:\n        return area_list[0]\n    return area_list\ndef load_area_from_string(area_strs, *regions):\n    \"\"\"Load area(s) from area strings.\n    Like :func:`~pyresample.area_config.load_area`, but load from string\n    directly.\n    Parameters\n    ----------\n    area_strs : str or List[str]\n        Strings containing yaml definitions.\n    regions : str\n        Regions to parse.\n    Returns\n    -------\n    area_defs : AreaDefinition or list\n        If one area name is specified a single AreaDefinition object is returned.\n        If several area names are specified a list of AreaDefinition objects is returned\n    \"\"\"\n    if isinstance(area_strs, str):\n        area_strs = [area_strs]\n    return load_area([io.StringIO(area_str) for area_str in area_strs],\n                     *regions)\ndef parse_area_file(area_file_name, *regions):\n    \"\"\"Parse area information from area file.\n    Parameters\n    -----------\n    area_file_name : str or list\n        One or more paths to area definition files\n    regions : str argument list\n        Regions to parse. If no regions are specified all\n        regions in the file are returned\n    Returns\n    -------\n    area_defs : list\n        List of AreaDefinition objects\n    Raises\n    ------\n    AreaNotFound:\n        If a specified area is not found\n    \"\"\"\n    try:\n        return _parse_yaml_area_file(area_file_name, *regions)\n    except (yaml.scanner.ScannerError, yaml.parser.ParserError):\n        return _parse_legacy_area_file(area_file_name, *regions)\ndef _read_yaml_area_file_content(area_file_name):\n    \"\"\"Read one or more area files in to a single dict object.\"\"\"\n    from pyresample.utils import recursive_dict_update\n    if isinstance(area_file_name, (str, pathlib.Path)):\n        area_file_name = [area_file_name]\n    area_dict = {}\n    for area_file_obj in area_file_name:\n        if isinstance(area_file_obj, io.IOBase):\n            # already a stream\n            tmp_dict = yaml.safe_load(area_file_obj)\n        else:\n            # hopefully a path to a file, but in the past a yaml string could\n            # be passed directly, assume any string with a newline must be\n            # a yaml file and not a path\n            if isinstance(area_file_obj, str) and \"\\n\" in area_file_obj:\n                warnings.warn(\"It looks like you passed a YAML string \"\n                              \"directly.  This is deprecated since pyresample \"\n                              \"1.14.1, please use load_area_from_string or \"\n                              \"pass a stream or a path to a file instead\",\n                              DeprecationWarning)\n                tmp_dict = yaml.safe_load(area_file_obj)\n            else:\n                with open(area_file_obj) as area_file_obj:\n                    tmp_dict = yaml.safe_load(area_file_obj)\n        area_dict = recursive_dict_update(area_dict, tmp_dict)\n    return area_dict\ndef _parse_yaml_area_file(area_file_name, *regions):\n    \"\"\"Parse area information from a yaml area file.\n    Args:\n        area_file_name: filename, file-like object, yaml string, or list of\n                        these.\n    The result of loading multiple area files is the combination of all\n    the files, using the first file as the \"base\", replacing things after\n    that.\n    \"\"\"\n    area_dict = _read_yaml_area_file_content(area_file_name)\n    area_list = regions or area_dict.keys()\n    res = []\n    for area_name in area_list:\n        params = area_dict.get(area_name)\n        if params is None:\n            raise AreaNotFound('Area \"{0}\" not found in file \"{1}\"'.format(area_name, area_file_name))\n        params.setdefault('area_id', area_name)\n        # Optional arguments.\n        params['shape'] = _capture_subarguments(params, 'shape', ['height', 'width'])\n        params['upper_left_extent'] = _capture_subarguments(params, 'upper_left_extent', ['upper_left_extent', 'x', 'y',\n                                                                                          'units'])\n        params['center'] = _capture_subarguments(params, 'center', ['center', 'x', 'y', 'units'])\n        params['area_extent'] = _capture_subarguments(params, 'area_extent', ['area_extent', 'lower_left_xy',\n                                                                              'upper_right_xy', 'units'])\n        params['resolution'] = _capture_subarguments(params, 'resolution', ['resolution', 'dx', 'dy', 'units'])\n        params['radius'] = _capture_subarguments(params, 'radius', ['radius', 'dx', 'dy', 'units'])\n        params['rotation'] = _capture_subarguments(params, 'rotation', ['rotation', 'units'])\n        res.append(create_area_def(**params))\n    return res\ndef _capture_subarguments(params, arg_name, sub_arg_list):\n    \"\"\"Capture :func:`~pyresample.utils.create_area_def` sub-arguments (i.e. units, height, dx, etc) from a yaml file.\n    Example:\n        resolution:\n          dx: 11\n          dy: 22\n          units: meters\n        # returns DataArray((11, 22), attrs={'units': 'meters})\n    \"\"\"\n    # Check if argument is in yaml.\n    argument = params.get(arg_name)\n    if not isinstance(argument, dict):\n        return argument\n    argument_keys = argument.keys()\n    for sub_arg in argument_keys:\n        # Verify that provided sub-arguments are valid.\n        if sub_arg not in sub_arg_list:\n            raise ValueError('Invalid area definition: {0} is not a valid sub-argument for {1}'.format(sub_arg,\n                                                                                                       arg_name))\n        elif arg_name in argument_keys:\n            # If the arg_name is provided as a sub_arg, then it contains all the data and does not need other sub_args.\n            if sub_arg != arg_name and sub_arg != 'units':\n                raise ValueError('Invalid area definition: {0} has too many sub-arguments: Both {0} and {1} were '\n                                 'specified.'.\n                                 format(arg_name, sub_arg))\n            # If the arg_name is provided, it's expected that units is also provided.\n            elif 'units' not in argument_keys:\n                raise ValueError('Invalid area definition: {0} has the sub-argument {0} without units'.format(arg_name))\n    units = argument.pop('units', None)\n    list_of_values = argument.pop(arg_name, [])\n    for sub_arg in sub_arg_list:\n        sub_arg_value = argument.get(sub_arg)\n        # Don't append units to the argument.\n        if sub_arg_value is not None:\n            if sub_arg in ('lower_left_xy', 'upper_right_xy') and isinstance(sub_arg_value, list):\n                list_of_values.extend(sub_arg_value)\n            else:\n                list_of_values.append(sub_arg_value)\n    # If units are provided, convert to xarray.\n    if units is not None:\n        return DataArray(list_of_values, attrs={'units': units})\n    return list_of_values\ndef _read_legacy_area_file_lines(area_file_name):\n    if isinstance(area_file_name, str):\n        area_file_name = [area_file_name]\n    for area_file_obj in area_file_name:\n        if (isinstance(area_file_obj, str) and\n           not os.path.isfile(area_file_obj)):\n            # file content string\n            for line in area_file_obj.splitlines():\n                yield line\n            continue\n        elif isinstance(area_file_obj, str):\n            # filename\n            with open(area_file_obj, 'r') as area_file:\n                for line in area_file.readlines():\n                    yield line\ndef _parse_legacy_area_file(area_file_name, *regions):\n    \"\"\"Parse area information from a legacy area file.\"\"\"\n    area_file = _read_legacy_area_file_lines(area_file_name)\n    area_list = list(regions)\n    if not area_list:\n        select_all_areas = True\n        area_defs = []\n    else:\n        select_all_areas = False\n        area_defs = [None for i in area_list]\n    # Extract area from file\n    in_area = False\n    for line in area_file:\n        if not in_area:\n            if 'REGION' in line and not line.strip().startswith('#'):\n                area_id = line.replace('REGION:', ''). \\\n                    replace('{', '').strip()\n                if area_id in area_list or select_all_areas:\n                    in_area = True\n                    area_content = ''\n        elif '};' in line:\n            in_area = False\n            try:\n                if select_all_areas:\n                    area_defs.append(_create_area(area_id, area_content))\n                else:\n                    area_defs[area_list.index(area_id)] = _create_area(area_id,\n                                                                       area_content)\n            except KeyError:\n                raise ValueError('Invalid area definition: %s, %s' % (area_id, area_content))\n        else:\n            area_content += line\n    # Check if all specified areas were found\n    if not select_all_areas:\n        for i, area in enumerate(area_defs):\n            if area is None:\n                raise AreaNotFound('Area \"%s\" not found in file \"%s\"' %\n                                   (area_list[i], area_file_name))\n    return area_defs\ndef _create_area(area_id, area_content):\n    \"\"\"Parse area configuration.\"\"\"\n    from configobj import ConfigObj\n    config_obj = area_content.replace('{', '').replace('};', '')\n    config_obj = ConfigObj([line.replace(':', '=', 1)\n                            for line in config_obj.splitlines()])\n    config = config_obj.dict()\n    config['REGION'] = area_id\n    try:\n        string_types = basestring\n    except NameError:\n        string_types = str\n    if not isinstance(config['NAME'], string_types):\n        config['NAME'] = ', '.join(config['NAME'])\n    config['XSIZE'] = int(config['XSIZE'])\n    config['YSIZE'] = int(config['YSIZE'])\n    if 'ROTATION' in config.keys():\n        config['ROTATION'] = float(config['ROTATION'])\n    else:\n        config['ROTATION'] = 0\n    config['AREA_EXTENT'][0] = config['AREA_EXTENT'][0].replace('(', '')\n    config['AREA_EXTENT'][3] = config['AREA_EXTENT'][3].replace(')', '')\n    for i, val in enumerate(config['AREA_EXTENT']):\n        config['AREA_EXTENT'][i] = float(val)\n    config['PCS_DEF'] = _get_proj4_args(config['PCS_DEF'])\n    return create_area_def(config['REGION'], config['PCS_DEF'], description=config['NAME'], proj_id=config['PCS_ID'],\n                           shape=(config['YSIZE'], config['XSIZE']), area_extent=config['AREA_EXTENT'],\n                           rotation=config['ROTATION'])\ndef get_area_def(area_id, area_name, proj_id, proj4_args, width, height, area_extent, rotation=0):\n    \"\"\"Construct AreaDefinition object from arguments.\n    Parameters\n    -----------\n    area_id : str\n        ID of area\n    area_name :str\n        Description of area\n    proj_id : str\n        ID of projection\n    proj4_args : list, dict, or str\n        Proj4 arguments as list of arguments or string\n    width : int\n        Number of pixel in x dimension\n    height : int\n        Number of pixel in y dimension\n    rotation: float\n        Rotation in degrees (negative is cw)\n    area_extent : list\n        Area extent as a list of ints (LL_x, LL_y, UR_x, UR_y)\n    Returns\n    -------\n    area_def : object\n        AreaDefinition object\n    \"\"\"\n    proj_dict = _get_proj4_args(proj4_args)\n    return create_area_def(area_id, proj_dict, description=area_name, proj_id=proj_id,\n                           shape=(height, width), area_extent=area_extent)\ndef _get_proj4_args(proj4_args):\n    \"\"\"Create dict from proj4 args.\"\"\"\n    from pyresample.utils.proj4 import convert_proj_floats\n    if isinstance(proj4_args, str):\n        # float conversion is done in `proj4_str_to_dict` already\n        return proj4_str_to_dict(str(proj4_args))\n    from configobj import ConfigObj\n    proj_config = ConfigObj(proj4_args)\n    return convert_proj_floats(proj_config.items())\ndef create_area_def(area_id, projection, width=None, height=None, area_extent=None, shape=None, upper_left_extent=None,\n                    center=None, resolution=None, radius=None, units=None, **kwargs):\n    \"\"\"Create AreaDefinition from whatever information is known.\n    Parameters\n    ----------\n    area_id : str\n        ID of area\n    projection : pyproj CRS object, dict, str, int, tuple, object\n        Projection parameters.  This can be in any format understood by\n        :func:`pyproj.crs.CRS.from_user_input`, such as a pyproj CRS object,\n        proj4 dict, proj4 string, EPSG integer code, or others.\n    description : str, optional\n        Description/name of area. Defaults to area_id\n    proj_id : str, optional\n        ID of projection (deprecated)\n    units : str, optional\n        Units that provided arguments should be interpreted as. This can be\n        one of 'deg', 'degrees', 'meters', 'metres', and any\n        parameter supported by the\n        `cs2cs -lu <https://proj4.org/apps/cs2cs.html#cmdoption-cs2cs-lu>`_\n        command. Units are determined in the following priority:\n        1. units expressed with each variable through a DataArray's attrs attribute.\n        2. units passed to ``units``\n        3. units used in ``projection``\n        4. meters\n    width : str, optional\n        Number of pixels in the x direction\n    height : str, optional\n        Number of pixels in the y direction\n    area_extent : list, optional\n        Area extent as a list (lower_left_x, lower_left_y, upper_right_x, upper_right_y)\n    shape : list, optional\n        Number of pixels in the y and x direction (height, width)\n    upper_left_extent : list, optional\n        Upper left corner of upper left pixel (x, y)\n    center : list, optional\n        Center of projection (x, y)\n    resolution : list or float, optional\n        Size of pixels: (dx, dy)\n    radius : list or float, optional\n        Length from the center to the edges of the projection (dx, dy)\n    rotation: float, optional\n        rotation in degrees(negative is cw)\n    nprocs : int, optional\n        Number of processor cores to be used\n    lons : numpy array, optional\n        Grid lons\n    lats : numpy array, optional\n        Grid lats\n    optimize_projection:\n        Whether the projection parameters have to be optimized for a DynamicAreaDefinition.\n    Returns\n    -------\n    AreaDefinition or DynamicAreaDefinition : AreaDefinition or DynamicAreaDefinition\n        If shape and area_extent are found, an AreaDefinition object is returned.\n        If only shape or area_extent can be found, a DynamicAreaDefinition object is returned\n    Raises\n    ------\n    ValueError:\n        If neither shape nor area_extent could be found\n    Notes\n    -----\n    * ``resolution`` and ``radius`` can be specified with one value if dx == dy\n    * If ``resolution`` and ``radius`` are provided as angles, center must be given or findable. In such a case,\n      they represent [projection x distance from center[0] to center[0]+dx, projection y distance from center[1] to\n      center[1]+dy]\n    \"\"\"\n    description = kwargs.pop('description', area_id)\n    proj_id = kwargs.pop('proj_id', None)\n    # convert EPSG dictionaries to projection string\n    # (hold on to EPSG code as much as possible)\n    if isinstance(projection, dict) and 'EPSG' in projection:\n        projection = \"EPSG:{}\".format(projection['EPSG'])\n    try:\n        crs = _get_proj_data(projection)\n        p = Proj(crs, preserve_units=True)\n    except (RuntimeError, CRSError):\n        # Assume that an invalid projection will be \"fixed\" by a dynamic area definition later\n        return _make_area(area_id, description, proj_id, projection, shape, area_extent, **kwargs)\n    # If no units are provided, try to get units used in proj_dict. If still none are provided, use meters.\n    if units is None:\n        units = _get_proj_units(crs)\n    # Allow height and width to be provided for more consistency across functions in pyresample.\n    if height is not None or width is not None:\n        shape = _validate_variable(shape, (height, width), 'shape', ['height', 'width'])\n    # Makes sure list-like objects are list-like, have the right shape, and contain only numbers.\n    center = _verify_list('center', center, 2)\n    radius = _verify_list('radius', radius, 2)\n    upper_left_extent = _verify_list('upper_left_extent', upper_left_extent, 2)\n    resolution = _verify_list('resolution', resolution, 2)\n    shape = _verify_list('shape', shape, 2)\n    area_extent = _verify_list('area_extent', area_extent, 4)\n    # Converts from lat/lon to projection coordinates (x,y) if not in projection coordinates. Returns tuples.\n    center = _convert_units(center, 'center', units, p, crs)\n    upper_left_extent = _convert_units(upper_left_extent, 'upper_left_extent', units, p, crs)\n    if area_extent is not None:\n        # convert area extent, pass as (X, Y)\n        area_extent_ll = area_extent[:2]\n        area_extent_ur = area_extent[2:]\n        area_extent_ll = _convert_units(area_extent_ll, 'area_extent', units, p, crs)\n        area_extent_ur = _convert_units(area_extent_ur, 'area_extent', units, p, crs)\n        area_extent = area_extent_ll + area_extent_ur\n    # Fills in missing information to attempt to create an area definition.\n    if area_extent is None or shape is None:\n        area_extent, shape, resolution = \\\n            _extrapolate_information(area_extent, shape, center, radius,\n                                     resolution, upper_left_extent, units,\n                                     p, crs)\n    return _make_area(area_id, description, proj_id, projection, shape,\n                      area_extent, resolution=resolution, **kwargs)\ndef _make_area(\n        area_id: str,\n        description: str,\n        proj_id: str,\n        projection: Union[dict, CRS],\n        shape: tuple,\n        area_extent: tuple,\n        **kwargs):\n    \"\"\"Handle the creation of an area definition for create_area_def.\"\"\"\n    from pyresample.geometry import AreaDefinition, DynamicAreaDefinition\n    # Remove arguments that are only for DynamicAreaDefinition.\n    optimize_projection = kwargs.pop('optimize_projection', False)\n    resolution = kwargs.pop('resolution', None)\n    # If enough data is provided, create an AreaDefinition. If only shape or area_extent are found, make a\n    # DynamicAreaDefinition. If not enough information was provided, raise a ValueError.\n    height, width = (None, None)\n    if shape is not None:\n        height, width = shape\n    if None not in (area_extent, shape):\n        return AreaDefinition(area_id, description, proj_id, projection, width, height, area_extent, **kwargs)\n    return DynamicAreaDefinition(area_id=area_id, description=description, projection=projection, width=width,\n                                 height=height, area_extent=area_extent, rotation=kwargs.get('rotation'),\n                                 resolution=resolution, optimize_projection=optimize_projection)\ndef _get_proj_data(projection: Any) -> CRS:\n    \"\"\"Take projection information and returns a proj CRS.\n    Takes projection information in any format understood by\n    :func:`pyproj.crs.CRS.from_user_input`.  There is special\n    handling for the \"EPSG:XXXX\" case where \"XXXX\" is an EPSG\n    number code. It can be provided as a string `\"EPSG:XXXX\"` or\n    as a dictionary (when provided via YAML) as `{'EPSG': XXXX}`.\n    If it is passed as a string (\"EPSG:XXXX\") then the rules of\n    :func:`~pyresample.utils._proj.proj4_str_to_dict` are followed.  If a\n    dictionary and pyproj 2.0+ is installed then the string `\"EPSG:XXXX\"`\n    is passed to ``proj4_str_to_dict``. If pyproj<2.0 is installed then\n    the string ``+init=EPSG:XXXX`` is passed to ``proj4_str_to_dict``\n    which provides limited information to area config operations.\n    \"\"\"\n    if isinstance(projection, dict) and 'EPSG' in projection:\n        projection = \"EPSG:{}\".format(projection['EPSG'])\n    return CRS.from_user_input(projection)\ndef _get_proj_units(crs):\n    if crs.is_geographic:\n        unit_name = 'degrees'\n    else:\n        unit_name = crs.axis_info[0].unit_name\n    return {\n        'metre': 'm',\n        'meter': 'm',\n        'kilometre': 'km',\n        'kilometer': 'km',\n    }.get(unit_name, unit_name)\ndef _sign(num):\n    \"\"\"Return the sign of the number provided.\n    Returns:\n        1 if number is greater than 0, -1 otherwise\n    \"\"\"\n    return -1 if num < 0 else 1\ndef _round_poles(center, units, p):\n    \"\"\"Round center to the nearest pole if it is extremely close to said pole.\n    Used to work around floating point precision issues .\n    \"\"\"\n    # For a laea projection, this allows for an error of 11 meters around the pole.\n    error = .0001\n    if 'deg' in units:\n        if abs(abs(center[1]) - 90) < error:\n            center = (center[0], _sign(center[1]) * 90)\n    else:\n        center = p(*center, inverse=True, errcheck=True)\n        if abs(abs(center[1]) - 90) < error:\n            center = (center[0], _sign(center[1]) * 90)\n        center = p(*center, errcheck=True)\n    return center\ndef _distance_from_center_forward(\n        var: tuple,\n        center: tuple,\n        p: Proj):\n    \"\"\"Convert distances in degrees to projection units.\"\"\"\n    # Interprets radius and resolution as distances between latitudes/longitudes.\n    # Since the distance between longitudes and latitudes is not constant in\n    # most projections, there must be reference point to start from.\n    if center is None:\n        center = (0, 0)\n    center_as_angle = p(*center, inverse=True, errcheck=True)\n    pole = 90\n    # If on a pole, use northern/southern latitude for both height and width.\n    if abs(abs(center_as_angle[1]) - pole) < 1e-3:\n        direction_of_poles = _sign(center_as_angle[1])\n        var = (center[1] - p(0, center_as_angle[1] - direction_of_poles * abs(var[0]),\n                             errcheck=True)[1],\n               center[1] - p(0, center_as_angle[1] - direction_of_poles * abs(var[1]),\n                             errcheck=True)[1])\n    # Uses southern latitude and western longitude if radius is positive. Uses northern latitude and\n    # eastern longitude if radius is negative.\n    else:\n        var = (center[0] - p(center_as_angle[0] - var[0], center_as_angle[1], errcheck=True)[0],\n               center[1] - p(center_as_angle[0], center_as_angle[1] - var[1], errcheck=True)[1])\n    return var\ndef _convert_units(\n        var,\n        name: str,\n        units: str,\n        p: Proj,\n        crs: CRS,\n        inverse: bool = False,\n        center=None):\n    \"\"\"Convert units from lon/lat to projection coordinates (meters).\n    If `inverse` it True then the inverse calculation is done.\n    \"\"\"\n    if var is None:\n        return None\n    if isinstance(var, DataArray):\n        units = var.units\n        var = tuple(var.data.tolist())\n    if crs.is_geographic and not ('deg' == units or 'degrees' == units):\n        raise ValueError('latlon/latlong projection cannot take {0} as units: {1}'.format(units, name))\n    # Check if units are an angle.\n    is_angle = ('deg' == units or 'degrees' == units)\n    if ('deg' in units) and not is_angle:\n        logging.warning('units provided to {0} are incorrect: {1}'.format(name, units))\n    # Convert from var projection units to projection units given by projection from user.\n    if not is_angle:\n        if units == 'meters' or units == 'metres':\n            units = 'm'\n        if _get_proj_units(crs) != units:\n            tmp_proj_dict = crs.to_dict()\n            tmp_proj_dict['units'] = units\n            transformer = Transformer.from_crs(tmp_proj_dict, p.crs)\n            var = transformer.transform(*var)\n    if name == 'center':\n        var = _round_poles(var, units, p)\n    # Return either degrees or meters depending on if the inverse is true or not.\n    # Don't convert if inverse is True: Want degrees.\n    # Converts list-like from degrees to meters.\n    if is_angle and not inverse:\n        if name in ('radius', 'resolution'):\n            var = _distance_from_center_forward(var, center, p)\n        elif not crs.is_geographic:\n            # only convert to meters\n            # this allows geographic projections to use coordinates outside\n            # normal lon/lat ranges (ex. -90/90)\n            var = p(*var, errcheck=True)\n    # Don't convert if inverse is False: Want meters.\n    elif not is_angle and inverse:\n        # Converts list-like from meters to degrees.\n        var = p(*var, inverse=True, errcheck=True)\n    if name in ['radius', 'resolution']:\n        var = (abs(var[0]), abs(var[1]))\n    return var\ndef _round_shape(shape, radius=None, resolution=None):\n    \"\"\"Make sure shape is an integer.\n    Rounds down if shape is less than .01 above nearest whole number to\n    handle floating point precision issues. Otherwise the number is\n    round up.\n    \"\"\"\n    # Used for area definition to prevent indexing None.\n    if shape is None:\n        return None\n    incorrect_shape = False\n    height, width = shape\n    if abs(width - round(width)) > 1e-8:\n        incorrect_shape = True\n        if width - math.floor(width) >= .01:\n            width = math.ceil(width)\n    width = int(round(width))\n    if abs(height - round(height)) > 1e-8:\n        incorrect_shape = True\n        if height - math.floor(height) >= .01:\n            height = math.ceil(height)\n    height = int(round(height))\n    if incorrect_shape:\n        if radius is not None and resolution is not None:\n            new_resolution = (2 * radius[0] / width, 2 * radius[1] / height)\n            logging.warning('shape found from radius and resolution does not contain only '\n                            'integers: {0}\\nRounding shape to {1} and resolution from {2} meters to '\n                            '{3} meters'.format(shape, (height, width), resolution, new_resolution))\n        else:\n            logging.warning('shape provided does not contain only integers: {0}\\n'\n                            'Rounding shape to {1}'.format(shape, (height, width)))\n    return height, width\ndef _validate_variable(var, new_var, var_name, input_list):\n    \"\"\"Make sure data given by the user does not conflict with itself.\n    If a variable that was given by the user contradicts other data provided, an exception is raised.\n    Example: upper_left_extent is (-10, 10), but area_extent is (-20, -20, 20, 20).\n    \"\"\"\n    if var is not None and not np.allclose(np.array(var, dtype=float), np.array(new_var, dtype=float), equal_nan=True):\n        raise ValueError('CONFLICTING DATA: {0} given does not match {0} found from {1}'.format(\n            var_name, ', '.join(input_list)) + ':\\ngiven: {0}\\nvs\\nfound: {1}'.format(var, new_var))\n    return new_var\ndef _extrapolate_information(area_extent, shape, center, radius, resolution, upper_left_extent, units, p, crs):\n    \"\"\"Attempt to find shape and area_extent based on data provided.\n    Parameters are used in a specific order to determine area_extent and shape.\n    The area_extent and shape are later used to create an `AreaDefinition`.\n    Providing some parameters may have no effect if other parameters could be\n    used to determine area_extent and shape. The order of the parameters used\n    is:\n    1. area_extent\n    2. upper_left_extent and center\n    3. radius and resolution\n    4. resolution and shape\n    5. radius and center\n    6. upper_left_extent and radius\n    \"\"\"\n    # Input unaffected by data below: When area extent is calculated, it's either with\n    # shape (giving you an area definition) or with center/radius/upper_left_extent (which this produces).\n    # Yet output (center/radius/upper_left_extent) is essential for data below.\n    if area_extent is not None:\n        # Function 1-A\n        new_center = ((area_extent[2] + area_extent[0]) / 2, (area_extent[3] + area_extent[1]) / 2)\n        center = _validate_variable(center, new_center, 'center', ['area_extent'])\n        # If radius is given in an angle without center it will raise an exception, and to verify, it must be in meters.\n        radius = _convert_units(radius, 'radius', units, p, crs, center=center)\n        new_radius = ((area_extent[2] - area_extent[0]) / 2, (area_extent[3] - area_extent[1]) / 2)\n        radius = _validate_variable(radius, new_radius, 'radius', ['area_extent'])\n        new_upper_left_extent = (area_extent[0], area_extent[3])\n        upper_left_extent = _validate_variable(\n            upper_left_extent, new_upper_left_extent, 'upper_left_extent', ['area_extent'])\n    # Output used below, but nowhere else is upper_left_extent made. Thus it should go as early as possible.\n    elif None not in (upper_left_extent, center):\n        # Function 1-B\n        radius = _convert_units(radius, 'radius', units, p, crs, center=center)\n        new_radius = (center[0] - upper_left_extent[0], upper_left_extent[1] - center[1])\n        radius = _validate_variable(radius, new_radius, 'radius', ['upper_left_extent', 'center'])\n    else:\n        radius = _convert_units(radius, 'radius', units, p, crs, center=center)\n    # Convert resolution to meters if given as an angle. If center is not found, an exception is raised.\n    resolution = _convert_units(resolution, 'resolution', units, p, crs, center=center)\n    # Inputs unaffected by data below: area_extent is not an input. However, output is used below.\n    if radius is not None and resolution is not None:\n        # Function 2-A\n        new_shape = _round_shape((2 * radius[1] / resolution[1], 2 * radius[0] / resolution[0]), radius=radius,\n                                 resolution=resolution)\n        shape = _validate_variable(shape, new_shape, 'shape', ['radius', 'resolution'])\n    elif resolution is not None and shape is not None:\n        # Function 2-B\n        new_radius = (resolution[0] * shape[1] / 2, resolution[1] * shape[0] / 2)\n        radius = _validate_variable(radius, new_radius, 'radius', ['shape', 'resolution'])\n    # Input determined from above functions, but output does not affect above functions: area_extent can be\n    # used to find center/upper_left_extent which are used to find each other, which is redundant.\n    if center is not None and radius is not None:\n        # Function 1-C\n        new_area_extent = (center[0] - radius[0], center[1] - radius[1], center[0] + radius[0], center[1] + radius[1])\n        area_extent = _validate_variable(area_extent, new_area_extent, 'area_extent', ['center', 'radius'])\n    elif upper_left_extent is not None and radius is not None:\n        # Function 1-D\n        new_area_extent = (\n            upper_left_extent[0], upper_left_extent[1] - 2 * radius[1], upper_left_extent[0] + 2 * radius[0],\n            upper_left_extent[1])\n        area_extent = _validate_variable(area_extent, new_area_extent, 'area_extent', ['upper_left_extent', 'radius'])\n    return area_extent, shape, resolution\ndef _format_list(var, name):\n    \"\"\"Ensure that parameter is list-like of numbers.\n    Used to let resolution and radius be single numbers if their elements are equal.\n    \"\"\"\n    # Single-number format.\n    if not isinstance(var, (list, tuple)) and name in ('resolution', 'radius'):\n", "outputs": ["        var = (float(var), float(var))"], "input_length": 6304, "output_length": 13, "length": 6317, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "dfc7f05ab126423a07aa6783582f1d89043514abaedc7a42599c24342b48d1f2"}
{"input": "", "context": "# (C) British Crown Copyright 2013 - 2015, Met Office\n#\n# This file is part of Iris.\n#\n# Iris is free software: you can redistribute it and/or modify it under\n# the terms of the GNU Lesser General Public License as published by the\n# Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# Iris is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU Lesser General Public License for more details.\n#\n# You should have received a copy of the GNU Lesser General Public License\n# along with Iris.  If not, see <http://www.gnu.org/licenses/>.\n\"\"\"NAME file format loading functions.\"\"\"\nfrom __future__ import (absolute_import, division, print_function)\nfrom six.moves import range, zip\nimport collections\nimport datetime\nimport re\nimport warnings\nimport numpy as np\nfrom iris.coords import AuxCoord, DimCoord, CellMethod\nimport iris.coord_systems\nimport iris.cube\nfrom iris.exceptions import TranslationError\nimport iris.util\nimport iris.unit\nEARTH_RADIUS = 6371229.0\nNAMEIII_DATETIME_FORMAT = '%d/%m/%Y  %H:%M %Z'\nNAMEII_FIELD_DATETIME_FORMAT = '%H%M%Z %d/%m/%Y'\nNAMEII_TIMESERIES_DATETIME_FORMAT = '%d/%m/%Y  %H:%M:%S'\nNAMECoord = collections.namedtuple('NAMECoord', ['name',\n                                                 'dimension',\n                                                 'values'])\ndef _split_name_and_units(name):\n    units = None\n    if \"(\" in name and \")\" in name:\n        split = name.rsplit(\"(\", 1)\n        try_units = split[1].replace(\")\", \"\").strip()\n        try:\n            try_units = iris.unit.Unit(try_units)\n        except ValueError:\n            pass\n        else:\n            name = split[0].strip()\n            units = try_units\n    return name, units\ndef read_header(file_handle):\n    \"\"\"\n    Return a dictionary containing the header information extracted\n    from the the provided NAME file object.\n    Args:\n    * file_handle (file-like object):\n        A file-like object from which to read the header information.\n    Returns:\n        A dictionary containing the extracted header information.\n    \"\"\"\n    header = {}\n    header['NAME Version'] = file_handle.next().strip()\n    for line in file_handle:\n        words = line.split(':', 1)\n        if len(words) != 2:\n            break\n        key, value = [word.strip() for word in words]\n        header[key] = value\n    # Cast some values into floats or integers if they match a\n    # given name. Set any empty string values to None.\n    for key, value in header.items():\n        if value:\n            if key in ['X grid origin', 'Y grid origin',\n                       'X grid resolution', 'Y grid resolution']:\n                header[key] = float(value)\n            elif key in ['X grid size', 'Y grid size',\n                         'Number of preliminary cols',\n                         'Number of field cols',\n                         'Number of fields',\n                         'Number of series']:\n                header[key] = int(value)\n        else:\n            header[key] = None\n    return header\ndef _read_data_arrays(file_handle, n_arrays, shape):\n    \"\"\"\n    Return a list of NumPy arrays containing the data extracted from\n    the provided file object. The number and shape of the arrays\n    must be specified.\n    \"\"\"\n    data_arrays = [np.zeros(shape, dtype=np.float32) for\n                   i in range(n_arrays)]\n    # Iterate over the remaining lines which represent the data in\n    # a column form.\n    for line in file_handle:\n        # Split the line by comma, removing the last empty column\n        # caused by the trailing comma\n        vals = line.split(',')[:-1]\n        # Cast the x and y grid positions to integers and convert\n        # them to zero based indices\n        x = int(float(vals[0])) - 1\n        y = int(float(vals[1])) - 1\n        # Populate the data arrays (i.e. all columns but the leading 4).\n        for i, data_array in enumerate(data_arrays):\n            data_array[y, x] = float(vals[i + 4])\n    return data_arrays\ndef _build_lat_lon_for_NAME_field(header):\n    \"\"\"\n    Return regular latitude and longitude coordinates extracted from\n    the provided header dictionary.\n    \"\"\"\n    start = header['X grid origin']\n    step = header['X grid resolution']\n    count = header['X grid size']\n    pts = start + np.arange(count, dtype=np.float64) * step\n    lon = NAMECoord(name='longitude', dimension=1, values=pts)\n    start = header['Y grid origin']\n    step = header['Y grid resolution']\n    count = header['Y grid size']\n    pts = start + np.arange(count, dtype=np.float64) * step\n    lat = NAMECoord(name='latitude', dimension=0, values=pts)\n    return lat, lon\ndef _build_lat_lon_for_NAME_timeseries(column_headings):\n    \"\"\"\n    Return regular latitude and longitude coordinates extracted from\n    the provided column_headings dictionary.\n    \"\"\"\n    pattern = re.compile(r'\\-?[0-9]*\\.[0-9]*')\n    new_Xlocation_column_header = []\n    for t in column_headings['X']:\n        if 'Lat-Long' in t:\n            matches = pattern.search(t)\n            new_Xlocation_column_header.append(float(matches.group(0)))\n        else:\n            new_Xlocation_column_header.append(t)\n    column_headings['X'] = new_Xlocation_column_header\n    lon = NAMECoord(name='longitude', dimension=None,\n                    values=column_headings['X'])\n    new_Ylocation_column_header = []\n    for t in column_headings['Y']:\n        if 'Lat-Long' in t:\n            matches = pattern.search(t)\n            new_Ylocation_column_header.append(float(matches.group(0)))\n        else:\n            new_Ylocation_column_header.append(t)\n    column_headings['Y'] = new_Ylocation_column_header\n    lat = NAMECoord(name='latitude', dimension=None,\n                    values=column_headings['Y'])\n    return lat, lon\ndef _calc_integration_period(time_avgs):\n    \"\"\"\n    Return a list of datetime.timedelta objects determined from the provided\n    list of averaging/integration period column headings.\n    \"\"\"\n    integration_periods = []\n    pattern = re.compile(\n        r'(\\d{0,2})(day)?\\s*(\\d{1,2})(hr)?\\s*(\\d{1,2})(min)?\\s*(\\w*)')\n    for time_str in time_avgs:\n        days = 0\n        hours = 0\n        minutes = 0\n        matches = pattern.search(time_str)\n        if matches:\n            if len(matches.group(1)) > 0:\n                days = float(matches.group(1))\n            if len(matches.group(3)) > 0:\n                hours = float(matches.group(3))\n            if len(matches.group(1)) > 0:\n                minutes = float(matches.group(5))\n        total_hours = days * 24.0 + hours + minutes / 60.0\n        integration_periods.append(datetime.timedelta(hours=total_hours))\n    return integration_periods\ndef _parse_units(units):\n    \"\"\"\n    Return a known :class:`iris.unit.Unit` given a NAME unit\n    .. note::\n        * Some NAME units are not currently handled.\n        * Units which are in the wrong case (case is ignored in NAME)\n        * Units where the space between SI units is missing\n        * Units where the characters used are non-standard (i.e. 'mc' for\n          micro instead of 'u')\n    Args:\n    * units (string):\n        NAME units.\n    Returns:\n        An instance of :class:`iris.unit.Unit`.\n    \"\"\"\n    unit_mapper = {'Risks/m3': '1',    # Used for Bluetongue\n                   'TCID50s/m3': '1',  # Used for Foot and Mouth\n                   'TCID50/m3': '1',   # Used for Foot and Mouth\n                   'N/A': '1',         # Used for CHEMET area at risk\n                   'lb': 'pounds',     # pounds\n                   'oz': '1',          # ounces\n                   'deg': 'degree',    # angular degree\n                   'oktas': '1',       # oktas\n                   'deg C': 'deg_C',   # degrees Celsius\n                   'FL': 'unknown'     # flight level\n                   }\n    units = unit_mapper.get(units, units)\n    units = units.replace('Kg', 'kg')\n    units = units.replace('gs', 'g s')\n    units = units.replace('Bqs', 'Bq s')\n    units = units.replace('mcBq', 'uBq')\n    units = units.replace('mcg', 'ug')\n    try:\n        units = iris.unit.Unit(units)\n    except ValueError:\n        warnings.warn('Unknown units: {!r}'.format(units))\n        units = iris.unit.Unit(None)\n    return units\ndef _cf_height_from_name(z_coord):\n    \"\"\"\n    Parser for the z component of field headings.\n    This parse is specifically for handling the z component of NAME field\n    headings, which include height above ground level, height above sea level\n    and flight level etc.  This function returns an iris coordinate\n    representing this field heading.\n    Args:\n    * z_coord (list):\n        A field heading, specifically the z component.\n    Returns:\n        An instance of :class:`iris.coords.AuxCoord` representing the\n        interpretation of the supplied field heading.\n    \"\"\"\n    # NAMEII - integer/float support.\n    # Match against height agl, asl and Pa.\n    pattern = re.compile(r'^From\\s*'\n                         '(?P<lower_bound>[0-9]+(\\.[0-9]+)?)'\n                         '\\s*-\\s*'\n                         '(?P<upper_bound>[0-9]+(\\.[0-9]+)?)'\n                         '\\s*(?P<type>m\\s*asl|m\\s*agl|Pa)'\n                         '(?P<extra>.*)')\n    # Match against flight level.\n    pattern_fl = re.compile(r'^From\\s*'\n                            '(?P<type>FL)'\n                            '(?P<lower_bound>[0-9]+(\\.[0-9]+)?)'\n                            '\\s*-\\s*FL'\n                            '(?P<upper_bound>[0-9]+(\\.[0-9]+)?)'\n                            '(?P<extra>.*)')\n    # NAMEIII - integer/float support.\n    # Match scalar against height agl, asl, Pa, FL\n    pattern_scalar = re.compile(r'Z\\s*=\\s*'\n                                '(?P<point>[0-9]+(\\.[0-9]+)?)'\n                                '\\s*(?P<type>m\\s*agl|m\\s*asl|FL|Pa)'\n                                '(?P<extra>.*)')\n    type_name = {'magl': 'height', 'masl': 'altitude', 'FL': 'flight_level',\n                 'Pa': 'air_pressure'}\n    patterns = [pattern, pattern_fl, pattern_scalar]\n    units = 'no-unit'\n    points = z_coord\n    bounds = None\n    standard_name = None\n    long_name = 'z'\n    for pattern in patterns:\n        match = pattern.match(z_coord)\n        if match:\n            match = match.groupdict()\n            # Do not interpret if there is additional information to the match\n            if match['extra']:\n                break\n            units = match['type'].replace(' ', '')\n            name = type_name[units]\n            # Interpret points if present.\n            if 'point' in match:\n                points = float(match['point'])\n            # Interpret points from bounds.\n            else:\n                bounds = np.array([float(match['lower_bound']),\n                                   float(match['upper_bound'])])\n                points = bounds.sum() / 2.\n            long_name = None\n            if name == 'altitude':\n                units = units[0]\n                standard_name = name\n                long_name = 'altitude above sea level'\n            elif name == 'height':\n                units = units[0]\n                standard_name = name\n                long_name = 'height above ground level'\n            elif name == 'air_pressure':\n                standard_name = name\n            elif name == 'flight_level':\n                long_name = name\n            units = _parse_units(units)\n            break\n    coord = AuxCoord(points, units=units, standard_name=standard_name,\n                     long_name=long_name, bounds=bounds)\n    return coord\ndef _generate_cubes(header, column_headings, coords, data_arrays,\n                    cell_methods=None):\n    \"\"\"\n    Yield :class:`iris.cube.Cube` instances given\n    the headers, column headings, coords and data_arrays extracted\n    from a NAME file.\n    \"\"\"\n    for i, data_array in enumerate(data_arrays):\n        # Turn the dictionary of column headings with a list of header\n        # information for each field into a dictionary of headings for\n        # just this field.\n        field_headings = {k: v[i] for k, v in\n                          column_headings.iteritems()}\n        # Make a cube.\n        cube = iris.cube.Cube(data_array)\n        # Determine the name and units.\n        name = '{} {}'.format(field_headings['Species'],\n                              field_headings['Quantity'])\n        name = name.upper().replace(' ', '_')\n        cube.rename(name)\n        # Some units are not in SI units, are missing spaces or typed\n        # in the wrong case. _parse_units returns units that are\n        # recognised by Iris.\n        cube.units = _parse_units(field_headings['Unit'])\n        # Define and add the singular coordinates of the field (flight\n        # level, time etc.)\n        z_coord = _cf_height_from_name(field_headings['Z'])\n        cube.add_aux_coord(z_coord)\n        # Define the time unit and use it to serialise the datetime for\n        # the time coordinate.\n        time_unit = iris.unit.Unit(\n            'hours since epoch', calendar=iris.unit.CALENDAR_GREGORIAN)\n        # Build time, latitude and longitude coordinates.\n        for coord in coords:\n            pts = coord.values\n            coord_sys = None\n            if coord.name == 'latitude' or coord.name == 'longitude':\n                coord_units = 'degrees'\n                coord_sys = iris.coord_systems.GeogCS(EARTH_RADIUS)\n            if coord.name == 'time':\n                coord_units = time_unit\n                pts = time_unit.date2num(coord.values)\n            if coord.dimension is not None:\n                if coord.name == 'longitude':\n                    circular = iris.util._is_circular(pts, 360.0)\n                else:\n                    circular = False\n                icoord = DimCoord(points=pts,\n                                  standard_name=coord.name,\n                                  units=coord_units,\n                                  coord_system=coord_sys,\n                                  circular=circular)\n                if coord.name == 'time' and 'Av or Int period' in \\\n                        field_headings:\n                    dt = coord.values - \\\n                        field_headings['Av or Int period']\n                    bnds = time_unit.date2num(\n                        np.vstack((dt, coord.values)).T)\n                    icoord.bounds = bnds\n                else:\n                    icoord.guess_bounds()\n                cube.add_dim_coord(icoord, coord.dimension)\n            else:\n                icoord = AuxCoord(points=pts[i],\n                                  standard_name=coord.name,\n                                  coord_system=coord_sys,\n                                  units=coord_units)\n                if coord.name == 'time' and 'Av or Int period' in \\\n                        field_headings:\n                    dt = coord.values - \\\n                        field_headings['Av or Int period']\n                    bnds = time_unit.date2num(\n                        np.vstack((dt, coord.values)).T)\n                    icoord.bounds = bnds[i, :]\n                cube.add_aux_coord(icoord)\n        # Headings/column headings which are encoded elsewhere.\n        headings = ['X', 'Y', 'Z', 'Time', 'Unit', 'Av or Int period',\n                    'X grid origin', 'Y grid origin',\n                    'X grid size', 'Y grid size',\n                    'X grid resolution', 'Y grid resolution', ]\n        # Add the Main Headings as attributes.\n        for key, value in header.iteritems():\n            if value is not None and value != '' and \\\n                    key not in headings:\n                cube.attributes[key] = value\n        # Add the Column Headings as attributes\n        for key, value in field_headings.iteritems():\n            if value is not None and value != '' and \\\n                    key not in headings:\n                cube.attributes[key] = value\n        if cell_methods is not None:\n            cube.add_cell_method(cell_methods[i])\n        yield cube\ndef _build_cell_methods(av_or_ints, coord):\n    \"\"\"\n    Return a list of :class:`iris.coords.CellMethod` instances\n    based on the provided list of column heading entries and the\n    associated coordinate. If a given entry does not correspond to a cell\n    method (e.g. \"No time averaging\"), a value of None is inserted.\n    Args:\n    * av_or_ints (iterable of strings):\n        An iterable of strings containing the colummn heading entries\n        to be parsed.\n    * coord (string or :class:`iris.coords.Coord`):\n        The coordinate name (or :class:`iris.coords.Coord` instance)\n        to which the column heading entries refer.\n    Returns:\n        A list that is the same length as `av_or_ints` containing\n        :class:`iris.coords.CellMethod` instances or values of None.\n    \"\"\"\n    cell_methods = []\n    no_avg_pattern = re.compile(r'^(no( (.* )?averaging)?)?$', re.IGNORECASE)\n    for av_or_int in av_or_ints:\n        if no_avg_pattern.search(av_or_int) is not None:\n            cell_method = None\n        elif 'average' in av_or_int or 'averaged' in av_or_int:\n            cell_method = CellMethod('mean', coord)\n        elif 'integral' in av_or_int or 'integrated' in av_or_int:\n            cell_method = CellMethod('sum', coord)\n        else:\n            cell_method = None\n            msg = 'Unknown {} statistic: {!r}. Unable to create cell method.'\n            warnings.warn(msg.format(coord, av_or_int))\n        cell_methods.append(cell_method)\n    return cell_methods\ndef load_NAMEIII_field(filename):\n    \"\"\"\n    Load a NAME III grid output file returning a\n    generator of :class:`iris.cube.Cube` instances.\n    Args:\n    * filename (string):\n        Name of file to load.\n    Returns:\n        A generator :class:`iris.cube.Cube` instances.\n    \"\"\"\n    # Loading a file gives a generator of lines which can be progressed using\n    # the next() method. This will come in handy as we wish to progress\n    # through the file line by line.\n    with open(filename, 'r') as file_handle:\n        # Create a dictionary which can hold the header metadata about this\n        # file.\n        header = read_header(file_handle)\n        # Skip the next line (contains the word Fields:) in the file.\n        next(file_handle)\n        # Read the lines of column definitions.\n        # In this version a fixed order of column headings is assumed (and\n        # first 4 columns are ignored).\n        column_headings = {}\n        for column_header_name in ['Species Category', 'Name', 'Quantity',\n                                   'Species', 'Unit', 'Sources', 'Ensemble Av',\n                                   'Time Av or Int', 'Horizontal Av or Int',\n                                   'Vertical Av or Int', 'Prob Perc',\n                                   'Prob Perc Ens', 'Prob Perc Time',\n                                   'Time', 'Z', 'D']:\n            cols = [col.strip() for col in file_handle.next().split(',')]\n            column_headings[column_header_name] = cols[4:-1]\n        # Convert the time to python datetimes.\n        new_time_column_header = []\n        for i, t in enumerate(column_headings['Time']):\n            dt = datetime.datetime.strptime(t, NAMEIII_DATETIME_FORMAT)\n            new_time_column_header.append(dt)\n        column_headings['Time'] = new_time_column_header\n        # Convert averaging/integrating period to timedeltas.\n        column_headings['Av or Int period'] = _calc_integration_period(\n            column_headings['Time Av or Int'])\n        # Build a time coordinate.\n        tdim = NAMECoord(name='time', dimension=None,\n                         values=np.array(column_headings['Time']))\n        cell_methods = _build_cell_methods(column_headings['Time Av or Int'],\n                                           tdim.name)\n        # Build regular latitude and longitude coordinates.\n        lat, lon = _build_lat_lon_for_NAME_field(header)\n        coords = [lon, lat, tdim]\n        # Skip the line after the column headings.\n        next(file_handle)\n        # Create data arrays to hold the data for each column.\n        n_arrays = header['Number of field cols']\n        shape = (header['Y grid size'], header['X grid size'])\n        data_arrays = _read_data_arrays(file_handle, n_arrays, shape)\n    return _generate_cubes(header, column_headings, coords, data_arrays,\n                           cell_methods)\ndef load_NAMEII_field(filename):\n    \"\"\"\n    Load a NAME II grid output file returning a\n    generator of :class:`iris.cube.Cube` instances.\n    Args:\n    * filename (string):\n        Name of file to load.\n    Returns:\n        A generator :class:`iris.cube.Cube` instances.\n    \"\"\"\n    with open(filename, 'r') as file_handle:\n        # Create a dictionary which can hold the header metadata about this\n        # file.\n        header = read_header(file_handle)\n        # Origin in namever=2 format is bottom-left hand corner so alter this\n        # to centre of a grid box\n        header['X grid origin'] = header['X grid origin'] + \\\n            header['X grid resolution'] / 2\n        header['Y grid origin'] = header['Y grid origin'] + \\\n            header['Y grid resolution'] / 2\n        # Read the lines of column definitions.\n        # In this version a fixed order of column headings is assumed (and\n        # first 4 columns are ignored).\n        column_headings = {}\n        for column_header_name in ['Species Category', 'Species',\n                                   'Time Av or Int', 'Quantity',\n                                   'Unit', 'Z', 'Time']:\n            cols = [col.strip() for col in file_handle.next().split(',')]\n            column_headings[column_header_name] = cols[4:-1]\n        # Convert the time to python datetimes\n        new_time_column_header = []\n        for i, t in enumerate(column_headings['Time']):\n            dt = datetime.datetime.strptime(t, NAMEII_FIELD_DATETIME_FORMAT)\n            new_time_column_header.append(dt)\n        column_headings['Time'] = new_time_column_header\n        # Convert averaging/integrating period to timedeltas.\n        pattern = re.compile(r'\\s*(\\d{3})\\s*(hr)?\\s*(time)\\s*(\\w*)')\n        column_headings['Av or Int period'] = []\n        for i, t in enumerate(column_headings['Time Av or Int']):\n            matches = pattern.search(t)\n            hours = 0\n            if matches:\n                if len(matches.group(1)) > 0:\n                    hours = float(matches.group(1))\n            column_headings['Av or Int period'].append(\n                datetime.timedelta(hours=hours))\n        # Build a time coordinate.\n        tdim = NAMECoord(name='time', dimension=None,\n                         values=np.array(column_headings['Time']))\n        cell_methods = _build_cell_methods(column_headings['Time Av or Int'],\n                                           tdim.name)\n        # Build regular latitude and longitude coordinates.\n        lat, lon = _build_lat_lon_for_NAME_field(header)\n        coords = [lon, lat, tdim]\n        # Skip the blank line after the column headings.\n        next(file_handle)\n        # Create data arrays to hold the data for each column.\n        n_arrays = header['Number of fields']\n        shape = (header['Y grid size'], header['X grid size'])\n        data_arrays = _read_data_arrays(file_handle, n_arrays, shape)\n    return _generate_cubes(header, column_headings, coords, data_arrays,\n                           cell_methods)\ndef load_NAMEIII_timeseries(filename):\n    \"\"\"\n    Load a NAME III time series file returning a\n    generator of :class:`iris.cube.Cube` instances.\n    Args:\n    * filename (string):\n        Name of file to load.\n    Returns:\n        A generator :class:`iris.cube.Cube` instances.\n    \"\"\"\n    with open(filename, 'r') as file_handle:\n        # Create a dictionary which can hold the header metadata about this\n        # file.\n        header = read_header(file_handle)\n        # skip the next line (contains the word Fields:) in the file.\n        next(file_handle)\n        # Read the lines of column definitions - currently hardwired\n        column_headings = {}\n        for column_header_name in ['Species Category', 'Name', 'Quantity',\n                                   'Species', 'Unit', 'Sources', 'Ens Av',\n                                   'Time Av or Int', 'Horizontal Av or Int',\n                                   'Vertical Av or Int', 'Prob Perc',\n                                   'Prob Perc Ens', 'Prob Perc Time',\n                                   'Location', 'X', 'Y', 'Z', 'D']:\n            cols = [col.strip() for col in file_handle.next().split(',')]\n            column_headings[column_header_name] = cols[1:-1]\n        # Determine the coordinates of the data and store in namedtuples.\n        # Extract latitude and longitude information from X, Y location\n        # headings.\n        lat, lon = _build_lat_lon_for_NAME_timeseries(column_headings)\n        # Convert averaging/integrating period to timedeltas.\n        column_headings['Av or Int period'] = _calc_integration_period(\n            column_headings['Time Av or Int'])\n        # Skip the line after the column headings.\n        next(file_handle)\n        # Make a list of data lists to hold the data for each column.\n        data_lists = [[] for i in range(header['Number of field cols'])]\n        time_list = []\n        # Iterate over the remaining lines which represent the data in a\n        # column form.\n        for line in file_handle:\n            # Split the line by comma, removing the last empty column caused\n            # by the trailing comma.\n            vals = line.split(',')[:-1]\n            # Time is stored in the first column.\n            t = vals[0].strip()\n            dt = datetime.datetime.strptime(t, NAMEIII_DATETIME_FORMAT)\n            time_list.append(dt)\n            # Populate the data arrays.\n            for i, data_list in enumerate(data_lists):\n                data_list.append(float(vals[i + 1]))\n        data_arrays = [np.array(l) for l in data_lists]\n        time_array = np.array(time_list)\n        tdim = NAMECoord(name='time', dimension=0, values=time_array)\n        coords = [lon, lat, tdim]\n    return _generate_cubes(header, column_headings, coords, data_arrays)\ndef load_NAMEII_timeseries(filename):\n    \"\"\"\n    Load a NAME II Time Series file returning a\n    generator of :class:`iris.cube.Cube` instances.\n    Args:\n    * filename (string):\n        Name of file to load.\n    Returns:\n        A generator :class:`iris.cube.Cube` instances.\n    \"\"\"\n    with open(filename, 'r') as file_handle:\n        # Create a dictionary which can hold the header metadata about this\n        # file.\n        header = read_header(file_handle)\n        # Read the lines of column definitions.\n        column_headings = {}\n        for column_header_name in ['Y', 'X', 'Location',\n                                   'Species Category', 'Species',\n                                   'Quantity', 'Z', 'Unit']:\n            cols = [col.strip() for col in file_handle.next().split(',')]\n            column_headings[column_header_name] = cols[1:-1]\n        # Determine the coordinates of the data and store in namedtuples.\n        # Extract latitude and longitude information from X, Y location\n        # headings.\n", "outputs": ["        lat, lon = _build_lat_lon_for_NAME_timeseries(column_headings)"], "input_length": 4894, "output_length": 8, "length": 4902, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "60dc132a7e81ce7e6128eb2a15bcae9e437cff5f21b51c7746cd3d086de60925"}
{"input": "", "context": "//    CANAPE Network Testing Tool\n//    Copyright (C) 2014 Context Information Security\n//\n//    This program is free software: you can redistribute it and/or modify\n//    it under the terms of the GNU General Public License as published by\n//    the Free Software Foundation, either version 3 of the License, or\n//    (at your option) any later version.\n//\n//    This program is distributed in the hope that it will be useful,\n//    but WITHOUT ANY WARRANTY; without even the implied warranty of\n//    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n//    GNU General Public License for more details.\n//\n//    You should have received a copy of the GNU General Public License\n//    along with this program.  If not, see <http://www.gnu.org/licenses/>.\nusing System;\nusing CANAPE.DataAdapters;\nusing CANAPE.DataFrames;\nusing CANAPE.Utils;\nnamespace CANAPE.Net.Layers\n{\n    /// <summary>\n    /// Simpler dynamic base network layer class, makes it easier to implement in a class and for python\n    /// </summary>\n    /// <typeparam name=\"T\">Type of configuration</typeparam>\n    /// <typeparam name=\"R\">Type to reference configuration</typeparam>\n    public abstract class WrappedNetworkLayer<T, R> : BaseNetworkLayer<T, R>\n        where R : class\n        where T : class, R, new()\n    {        \n        private class WrapperServerDataAdapter : IDataAdapter\n        {\n            WrappedNetworkLayer<T,R> _networkLayer;\n            string _description;\n            public WrapperServerDataAdapter(WrappedNetworkLayer<T, R> networkLayer, string description)\n            {\n                _networkLayer = networkLayer;\n                _description = description;\n            }\n            public DataFrame Read()\n            {\n                return _networkLayer.ServerRead();\n            }\n            public void Write(DataFrame frame)\n            {\n                _networkLayer.ServerWrite(frame);\n            }\n            public void Close()\n            {\n                _networkLayer.ServerClose();\n            }\n            public string Description\n            {\n                get { return _description; }\n            }\n            public int ReadTimeout\n            {\n                get\n                {\n                    return _networkLayer.ServerGetTimeout();\n                }\n                set\n                {\n                    _networkLayer.ServerSetTimeout(value);\n                }\n            }\n            public bool CanTimeout\n            {\n                get { return _networkLayer.ServerCanTimeout(); }\n            }\n            public void Dispose()\n            {\n                Close();\n            }\n            public void Reconnect()\n            {\n                throw new NotImplementedException();\n            }\n        }\n        private class WrapperClientDataAdapter : IDataAdapter\n        {\n            WrappedNetworkLayer<T, R> _networkLayer;\n            string _description;\n            public WrapperClientDataAdapter(WrappedNetworkLayer<T, R> networkLayer, string description)\n            {\n                _networkLayer = networkLayer;\n                _description = description;\n            }\n            public DataFrame Read()\n            {\n                return _networkLayer.ClientRead();\n            }\n            public void Write(DataFrame frame)\n            {\n                _networkLayer.ClientWrite(frame);\n            }\n            public void Close()\n            {\n                _networkLayer.ClientClose();\n            }\n            public string Description\n            {\n                get { return _description; }\n            }\n            public int ReadTimeout\n            {\n                get\n                {\n                    return _networkLayer.ClientGetTimeout();\n                }\n                set\n                {\n                    _networkLayer.ClientSetTimeout(value);\n                }\n            }\n            public bool CanTimeout\n            {\n                get { return _networkLayer.ClientCanTimeout(); }\n            }\n            public void Dispose()\n            {\n                Close();\n            }\n            public void Reconnect()\n            {\n                throw new NotImplementedException();\n            }\n        }\n        /// <summary>\n        /// Method to override writing for a wrapped client adapter\n        /// </summary>\n        /// <param name=\"frame\">The wraper to write</param>\n        protected abstract void ClientWrite(DataFrame frame);\n        /// <summary>\n        /// Method to override reading for a wrapped client adapter\n        /// </summary>\n        /// <returns>A data frame read from the adapter, null on end of stream</returns>\n        protected abstract DataFrame ClientRead();\n        /// <summary>\n        /// Method to override closing for a wrapped client adapter\n        /// </summary>\n        protected abstract void ClientClose();\n        /// <summary>\n        /// Method to override setting a timeout for a wrapped client adapter\n        /// </summary>\n        /// <param name=\"timeout\">The timeout in milliseconds</param>\n        protected virtual void ClientSetTimeout(int timeout)\n        {\n            throw new NotSupportedException();\n        }\n        /// <summary>\n        /// Method to override getting a timeout for a wrapped client adapter\n        /// </summary>\n        /// <returns>The timeout in milliseconds</returns>\n        protected virtual int ClientGetTimeout()\n        {\n            throw new NotSupportedException();\n        }\n        /// <summary>\n        /// Method to override indicating whether we can timeout or not\n        /// </summary>\n        /// <returns>True indicates a timeout can be set</returns>\n        protected virtual bool ClientCanTimeout()\n        {\n            throw new NotSupportedException();\n        }\n        /// <summary>\n        /// Method to override writing for a wrapped server adapter\n        /// </summary>\n        /// <param name=\"frame\">The frame to write</param>\n        protected abstract void ServerWrite(DataFrame frame);\n        /// <summary>\n        /// Method to override reading for a wrapped server adapter\n        /// </summary>\n        /// <returns>A data frame read from the adapter, null on end of stream</returns>\n        protected abstract DataFrame ServerRead();\n        /// <summary>\n        /// Method to override setting a timeout for a wrapped server adapter\n        /// </summary>\n        /// <param name=\"timeout\">The timeout in milliseconds</param>\n        protected virtual void ServerSetTimeout(int timeout)\n        {\n            throw new NotSupportedException();\n        }\n        /// <summary>\n        /// Method to override getting a timeout for a wrapped client adapter\n        /// </summary>\n        /// <returns>The timeout in milliseconds</returns>\n        protected virtual int ServerGetTimeout()\n        {\n", "outputs": ["            throw new NotSupportedException();"], "input_length": 972, "output_length": 6, "length": 978, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "9bf8c9e2c432a66154d1230d86de0b6727bc831c74d0938b5eefbe29a55d7c4f"}
{"input": "", "context": "# -*- coding: utf-8 -*-\n# This code is part of Amoco\n# Copyright (C) 2021 Axel Tillequin (bdcht3@gmail.com)\n# published under GPLv2 license\nfrom amoco.arch.tricore import env\nfrom amoco.arch.core import *\n# -------------------------------------------------------\n# from TriCore TC1.6.2 core architecture manual V1.2.2\n# (32-bit Unified Processor Core), 2020-01-15\n# define all except FPU instructions\n# -------------------------------------------------------\nISPECS = []\n@ispec(\"32<[ disp1(16) disp2(8) {6d} ]\", mnemonic=\"CALL\")\n@ispec(\"32<[ disp1(16) disp2(8) {61} ]\", mnemonic=\"FCALL\")\n@ispec(\"32<[ disp1(16) disp2(8) {1d} ]\", mnemonic=\"J\")\n@ispec(\"32<[ disp1(16) disp2(8) {5d} ]\", mnemonic=\"JL\")\ndef tricore_branch(obj, disp1, disp2):\n    v = env.cst(((disp2<<16)+disp1)<<1,24)\n    obj.operands = [disp.signextend(32)]\n    obj.type = type_control_flow\n@ispec(\"32<[ disp1(16) disp2(8) {ed} ]\", mnemonic=\"CALLA\")\n@ispec(\"32<[ disp1(16) disp2(8) {e1} ]\", mnemonic=\"FCALLA\")\n@ispec(\"32<[ disp1(16) disp2(8) {9d} ]\", mnemonic=\"JA\")\n@ispec(\"32<[ disp1(16) disp2(8) {dd} ]\", mnemonic=\"JLA\")\ndef tricore_branch(obj, disp1, disp2):\n    v = env.cst((disp2<<16)+disp1,24)\n    addr = composer([env.bit0,v[0:20],env.cst(0,7),v[20:24]])\n    obj.operands = [addr]\n    obj.type = type_control_flow\n@ispec(\"32<[ ---- {00} ---- ---- a(4) {2d} ]\", mnemonic=\"CALLI\")\n@ispec(\"32<[ ---- {01} ---- ---- a(4) {2d} ]\", mnemonic=\"FCALLI\")\n@ispec(\"32<[ ---- {03} ---- ---- a(4) {2d} ]\", mnemonic=\"JI\")\n@ispec(\"32<[ ---- {02} ---- ---- a(4) {2d} ]\", mnemonic=\"JLI\")\ndef tricore_branchI(obj, a):\n    src = env.A[a]\n    obj.operands = [src]\n    obj.type = type_control_flow\n@ispec(\"16<[ disp(8) {5c} ]\", mnemonic=\"CALL\")\n@ispec(\"16<[ disp(8) {3c} ]\", mnemonic=\"J\")\n@ispec(\"16<[ disp(8) {ee} ]\", mnemonic=\"JNZ\")\n@ispec(\"16<[ disp(8) {6e} ]\", mnemonic=\"JZ\")\ndef tricore_branch(obj, disp):\n    disp = env.cst(disp<<1,8)\n    obj.operands = [disp.signextend(32)]\n    obj.type = type_control_flow\n@ispec(\"32<[ ---- 0000000 const9(9) ---- {ad} ]\", mnemonic=\"BISR\")\n@ispec(\"32<[ ---- 0000100 const9(9) ---- {ad} ]\", mnemonic=\"SYSCALL\")\ndef tricore_system(obj, const9):\n    obj.operands = [env.cst(const9,9)]\n    obj.type = type_system\n@ispec(\"32<[ c(4) {1c} ---- b(4) ---- {0b} ]\", mnemonic=\"ABS\")\n@ispec(\"32<[ c(4) {5c} ---- b(4) ---- {0b} ]\", mnemonic=\"ABS_B\")\n@ispec(\"32<[ c(4) {7c} ---- b(4) ---- {0b} ]\", mnemonic=\"ABS_H\")\n@ispec(\"32<[ c(4) {1d} ---- b(4) ---- {0b} ]\", mnemonic=\"ABSS\")\n@ispec(\"32<[ c(4) {7d} ---- b(4) ---- {0b} ]\", mnemonic=\"ABSS_H\")\n@ispec(\"32<[ c(4) {1f} ---- b(4) ---- {0b} ]\", mnemonic=\"MOV\")\ndef tricore_dd_arithmetic(obj, c, b):\n    src = env.D[b]\n    dst = env.D[c]\n    obj.operands = [dst, src]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) {80} ---- b(4) ---- {0b} ]\", mnemonic=\"MOV\")\ndef tricore_dd_arithmetic(obj, c, b):\n    src = env.D[b]\n    dst = env.E[c]\n    obj.operands = [dst, src.signextend(64)]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) {81} ---- b(4) a(4) {0b} ]\", mnemonic=\"MOV\")\ndef tricore_dd_arithmetic(obj, c, b, a):\n    src2 = env.D[b]\n    dst = env.E[c]\n    obj.operands = [dst, composer([src2,src1])]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) {0e} ---- b(4) a(4) {0b} ]\", mnemonic=\"ABSDIF\")\n@ispec(\"32<[ c(4) {4e} ---- b(4) a(4) {0b} ]\", mnemonic=\"ABSDIF_B\")\n@ispec(\"32<[ c(4) {6e} ---- b(4) a(4) {0b} ]\", mnemonic=\"ABSDIF_H\")\n@ispec(\"32<[ c(4) {0f} ---- b(4) a(4) {0b} ]\", mnemonic=\"ABSDIFS\")\n@ispec(\"32<[ c(4) {6f} ---- b(4) a(4) {0b} ]\", mnemonic=\"ABSDIFS_H\")\n@ispec(\"32<[ c(4) {00} ---- b(4) a(4) {0b} ]\", mnemonic=\"ADD\")\n@ispec(\"32<[ c(4) {40} ---- b(4) a(4) {0b} ]\", mnemonic=\"ADD_B\")\n@ispec(\"32<[ c(4) {60} ---- b(4) a(4) {0b} ]\", mnemonic=\"ADD_H\")\n@ispec(\"32<[ c(4) {05} ---- b(4) a(4) {0b} ]\", mnemonic=\"ADDC\")\n@ispec(\"32<[ c(4) {02} ---- b(4) a(4) {0b} ]\", mnemonic=\"ADDS\")\n@ispec(\"32<[ c(4) {62} ---- b(4) a(4) {0b} ]\", mnemonic=\"ADDS_H\")\n@ispec(\"32<[ c(4) {63} ---- b(4) a(4) {0b} ]\", mnemonic=\"ADDS_HU\")\n@ispec(\"32<[ c(4) {03} ---- b(4) a(4) {0b} ]\", mnemonic=\"ADDS_U\")\n@ispec(\"32<[ c(4) {04} ---- b(4) a(4) {0b} ]\", mnemonic=\"ADDX\")\n@ispec(\"32<[ c(4) {08} ---- b(4) a(4) {0f} ]\", mnemonic=\"AND\")\n@ispec(\"32<[ c(4) {20} ---- b(4) a(4) {0b} ]\", mnemonic=\"AND_EQ\")\n@ispec(\"32<[ c(4) {24} ---- b(4) a(4) {0b} ]\", mnemonic=\"AND_GE\")\n@ispec(\"32<[ c(4) {25} ---- b(4) a(4) {0b} ]\", mnemonic=\"AND_GE_U\")\n@ispec(\"32<[ c(4) {22} ---- b(4) a(4) {0b} ]\", mnemonic=\"AND_LT\")\n@ispec(\"32<[ c(4) {23} ---- b(4) a(4) {0b} ]\", mnemonic=\"AND_LT_U\")\n@ispec(\"32<[ c(4) {21} ---- b(4) a(4) {0b} ]\", mnemonic=\"AND_NE\")\n@ispec(\"32<[ c(4) {0e} ---- b(4) a(4) {0f} ]\", mnemonic=\"ANDN\")\n@ispec(\"32<[ c(4) {10} ---- b(4) a(4) {0b} ]\", mnemonic=\"EQ\")\n@ispec(\"32<[ c(4) {50} ---- b(4) a(4) {0b} ]\", mnemonic=\"EQ_B\")\n@ispec(\"32<[ c(4) {70} ---- b(4) a(4) {0b} ]\", mnemonic=\"EQ_H\")\n@ispec(\"32<[ c(4) {90} ---- b(4) a(4) {0b} ]\", mnemonic=\"EQ_W\")\n@ispec(\"32<[ c(4) {56} ---- b(4) a(4) {0b} ]\", mnemonic=\"EQANY_B\")\n@ispec(\"32<[ c(4) {76} ---- b(4) a(4) {0b} ]\", mnemonic=\"EQANY_H\")\n@ispec(\"32<[ c(4) {14} ---- b(4) a(4) {0b} ]\", mnemonic=\"GE\")\n@ispec(\"32<[ c(4) {15} ---- b(4) a(4) {0b} ]\", mnemonic=\"GE_U\")\n@ispec(\"32<[ c(4) {12} ---- b(4) a(4) {0b} ]\", mnemonic=\"LT\")\n@ispec(\"32<[ c(4) {13} ---- b(4) a(4) {0b} ]\", mnemonic=\"LT_U\")\n@ispec(\"32<[ c(4) {52} ---- b(4) a(4) {0b} ]\", mnemonic=\"LT_B\")\n@ispec(\"32<[ c(4) {53} ---- b(4) a(4) {0b} ]\", mnemonic=\"LT_BU\")\n@ispec(\"32<[ c(4) {72} ---- b(4) a(4) {0b} ]\", mnemonic=\"LT_H\")\n@ispec(\"32<[ c(4) {73} ---- b(4) a(4) {0b} ]\", mnemonic=\"LT_HU\")\n@ispec(\"32<[ c(4) {92} ---- b(4) a(4) {0b} ]\", mnemonic=\"LT_W\")\n@ispec(\"32<[ c(4) {93} ---- b(4) a(4) {0b} ]\", mnemonic=\"LT_WU\")\n@ispec(\"32<[ c(4) {1a} ---- b(4) a(4) {0b} ]\", mnemonic=\"MAX\")\n@ispec(\"32<[ c(4) {1b} ---- b(4) a(4) {0b} ]\", mnemonic=\"MAX_U\")\n@ispec(\"32<[ c(4) {5a} ---- b(4) a(4) {0b} ]\", mnemonic=\"MAX_B\")\n@ispec(\"32<[ c(4) {5b} ---- b(4) a(4) {0b} ]\", mnemonic=\"MAX_BU\")\n@ispec(\"32<[ c(4) {7a} ---- b(4) a(4) {0b} ]\", mnemonic=\"MAX_H\")\n@ispec(\"32<[ c(4) {7b} ---- b(4) a(4) {0b} ]\", mnemonic=\"MAX_HU\")\n@ispec(\"32<[ c(4) {18} ---- b(4) a(4) {0b} ]\", mnemonic=\"MIN\")\n@ispec(\"32<[ c(4) {19} ---- b(4) a(4) {0b} ]\", mnemonic=\"MIN_U\")\n@ispec(\"32<[ c(4) {58} ---- b(4) a(4) {0b} ]\", mnemonic=\"MIN_B\")\n@ispec(\"32<[ c(4) {59} ---- b(4) a(4) {0b} ]\", mnemonic=\"MIN_BU\")\n@ispec(\"32<[ c(4) {78} ---- b(4) a(4) {0b} ]\", mnemonic=\"MIN_H\")\n@ispec(\"32<[ c(4) {79} ---- b(4) a(4) {0b} ]\", mnemonic=\"MIN_HU\")\n@ispec(\"32<[ c(4) {09} ---- b(4) a(4) {0f} ]\", mnemonic=\"NAND\")\n@ispec(\"32<[ c(4) {11} ---- b(4) a(4) {0b} ]\", mnemonic=\"NE\")\n@ispec(\"32<[ c(4) {0b} ---- b(4) a(4) {0f} ]\", mnemonic=\"NOR\")\n@ispec(\"32<[ c(4) {0a} ---- b(4) a(4) {0f} ]\", mnemonic=\"OR\")\n@ispec(\"32<[ c(4) {27} ---- b(4) a(4) {0b} ]\", mnemonic=\"OR_EQ\")\n@ispec(\"32<[ c(4) {2b} ---- b(4) a(4) {0b} ]\", mnemonic=\"OR_GE\")\n@ispec(\"32<[ c(4) {2c} ---- b(4) a(4) {0b} ]\", mnemonic=\"OR_GE_U\")\n@ispec(\"32<[ c(4) {29} ---- b(4) a(4) {0b} ]\", mnemonic=\"OR_LT\")\n@ispec(\"32<[ c(4) {2a} ---- b(4) a(4) {0b} ]\", mnemonic=\"OR_LT_U\")\n@ispec(\"32<[ c(4) {28} ---- b(4) a(4) {0b} ]\", mnemonic=\"OR_NE\")\n@ispec(\"32<[ c(4) {0f} ---- b(4) a(4) {0f} ]\", mnemonic=\"ORN\")\n@ispec(\"32<[ c(4) {00} ---- b(4) a(4) {0f} ]\", mnemonic=\"SH\")\n@ispec(\"32<[ c(4) {37} ---- b(4) a(4) {0b} ]\", mnemonic=\"SH_EQ\")\n@ispec(\"32<[ c(4) {3b} ---- b(4) a(4) {0b} ]\", mnemonic=\"SH_GE\")\n@ispec(\"32<[ c(4) {3c} ---- b(4) a(4) {0b} ]\", mnemonic=\"SH_GE_U\")\n@ispec(\"32<[ c(4) {40} ---- b(4) a(4) {0f} ]\", mnemonic=\"SH_H\")\n@ispec(\"32<[ c(4) {39} ---- b(4) a(4) {0b} ]\", mnemonic=\"SH_LT\")\n@ispec(\"32<[ c(4) {3a} ---- b(4) a(4) {0b} ]\", mnemonic=\"SH_LT_U\")\n@ispec(\"32<[ c(4) {38} ---- b(4) a(4) {0b} ]\", mnemonic=\"SH_NE\")\n@ispec(\"32<[ c(4) {01} ---- b(4) a(4) {0f} ]\", mnemonic=\"SHA\")\n@ispec(\"32<[ c(4) {41} ---- b(4) a(4) {0f} ]\", mnemonic=\"SHA_H\")\n@ispec(\"32<[ c(4) {02} ---- b(4) a(4) {0f} ]\", mnemonic=\"SHAS\")\n@ispec(\"32<[ c(4) {08} ---- b(4) a(4) {0b} ]\", mnemonic=\"SUB\")\n@ispec(\"32<[ c(4) {48} ---- b(4) a(4) {0b} ]\", mnemonic=\"SUB_B\")\n@ispec(\"32<[ c(4) {68} ---- b(4) a(4) {0b} ]\", mnemonic=\"SUB_H\")\n@ispec(\"32<[ c(4) {0d} ---- b(4) a(4) {0b} ]\", mnemonic=\"SUBC\")\n@ispec(\"32<[ c(4) {0a} ---- b(4) a(4) {0b} ]\", mnemonic=\"SUBS\")\n@ispec(\"32<[ c(4) {0b} ---- b(4) a(4) {0b} ]\", mnemonic=\"SUBS_U\")\n@ispec(\"32<[ c(4) {6a} ---- b(4) a(4) {0b} ]\", mnemonic=\"SUBS_H\")\n@ispec(\"32<[ c(4) {6b} ---- b(4) a(4) {0b} ]\", mnemonic=\"SUBS_HU\")\n@ispec(\"32<[ c(4) {0c} ---- b(4) a(4) {0b} ]\", mnemonic=\"SUBX\")\n@ispec(\"32<[ c(4) {0d} ---- b(4) a(4) {0f} ]\", mnemonic=\"XNOR\")\n@ispec(\"32<[ c(4) {0c} ---- b(4) a(4) {0f} ]\", mnemonic=\"XOR\")\n@ispec(\"32<[ c(4) {2f} ---- b(4) a(4) {0b} ]\", mnemonic=\"XOR_EQ\")\n@ispec(\"32<[ c(4) {30} ---- b(4) a(4) {0b} ]\", mnemonic=\"XOR_NE\")\ndef tricore_ddd_arithmetic(obj, c, b, a):\n    src1 = env.D[a]\n    src2 = env.D[b]\n    dst = env.D[c]\n    obj.operands = [dst, src1, src2]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) {40} ---- b(4) a(4) {01} ]\", mnemonic=\"EQ_A\")\n@ispec(\"32<[ c(4) {43} ---- b(4) a(4) {01} ]\", mnemonic=\"GE_A\")\n@ispec(\"32<[ c(4) {42} ---- b(4) a(4) {01} ]\", mnemonic=\"LT_A\")\n@ispec(\"32<[ c(4) {41} ---- b(4) a(4) {01} ]\", mnemonic=\"NE_A\")\ndef tricore_daa_arithmetic(obj, c, b, a):\n    src1 = env.A[a]\n    src2 = env.A[b]\n    dst = env.D[c]\n    obj.operands = [dst, src1, src2]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) {63} ---- b(4) ---- {01} ]\", mnemonic=\"MOV_A\",  _dst=env.A, _src=env.D)\n@ispec(\"32<[ c(4) {00} ---- b(4) ---- {01} ]\", mnemonic=\"MOV_AA\", _dst=env.A, _src=env.A)\n@ispec(\"32<[ c(4) {4c} ---- b(4) ---- {01} ]\", mnemonic=\"MOV_D\",  _dst=env.D, _src=env.A)\ndef tricore_daa_arithmetic(obj, c, b, _dst, _src):\n    dst = _dst[c]\n    src = _src[b]\n    obj.operands = [dst, src]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) {48} ---- ---- a(4) {01} ]\", mnemonic=\"EQZ_A\")\n@ispec(\"32<[ c(4) {49} ---- ---- a(4) {01} ]\", mnemonic=\"NEZ_A\")\ndef tricore_da_arithmetic(obj, c, a):\n    src1 = env.A[a]\n    dst = env.D[c]\n    obj.operands = [dst, src1]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) {01} --00 b(4) a(4) {4b} ]\", mnemonic=\"BMERGE\")\ndef tricore_ddd_arithmetic(obj, c, b, a):\n    src1 = env.D[a]\n    src2 = env.D[b]\n    dst = env.D[c]\n    obj.operands = [dst, src1, src2]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) {06} --00 b(4) a(4) {4b} ]\", mnemonic=\"CRC32_B\")\n@ispec(\"32<[ c(4) {03} --00 b(4) a(4) {4b} ]\", mnemonic=\"CRC32B_W\")\n@ispec(\"32<[ c(4) {03} --00 b(4) a(4) {4b} ]\", mnemonic=\"CRC32L_W\")\ndef tricore_crc32(obj, c, b, a):\n    src1 = env.D[a]\n    src2 = env.D[b]\n    dst = env.D[c]\n    obj.operands = [dst, src2, src1]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) {20} --01 b(4) a(4) {4b} ]\", mnemonic=\"DIV\")\n@ispec(\"32<[ c(4) {21} --01 b(4) a(4) {4b} ]\", mnemonic=\"DIV_U\")\n@ispec(\"32<[ c(4) {5a} --00 b(4) a(4) {4b} ]\", mnemonic=\"DVINIT_B\")\n@ispec(\"32<[ c(4) {4a} --00 b(4) a(4) {4b} ]\", mnemonic=\"DVINIT_BU\")\n@ispec(\"32<[ c(4) {3a} --00 b(4) a(4) {4b} ]\", mnemonic=\"DVINIT_H\")\n@ispec(\"32<[ c(4) {2a} --00 b(4) a(4) {4b} ]\", mnemonic=\"DVINIT_HU\")\n@ispec(\"32<[ c(4) {1a} --00 b(4) a(4) {4b} ]\", mnemonic=\"DVINIT\")\n@ispec(\"32<[ c(4) {0a} --00 b(4) a(4) {4b} ]\", mnemonic=\"DVINIT_U\")\ndef tricore_edd_arithmetic(obj, c, b, a):\n    src1 = env.D[a]\n    src2 = env.D[b]\n    if c%2:\n        raise InstructionError(obj)\n    dst = env.E[c]\n    obj.operands = [dst, src1, src2]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) d(4) 100 ----- b(4) a(4) {17} ]\", mnemonic=\"DEXTR\")\ndef tricore_dddc(obj, c, d, b, a):\n    shift = env.D[d]\n    src1 = env.D[a]\n    src2 = env.D[b]\n    dst = env.D[c]\n    obj.operands = [dst, src1, src2, shift]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) d(4) 010 ----- ---- a(4) {17} ]\", mnemonic=\"EXTR\")\n@ispec(\"32<[ c(4) d(4) 011 ----- ---- a(4) {17} ]\", mnemonic=\"EXTR_U\")\ndef tricore_extr(obj, c, d, a):\n    if d%2:\n        raise InstructionError(obj)\n    width = env.E[d][32:37]\n    src1 = env.D[a]\n    dst = env.D[c]\n    obj.operands = [dst, src1, width]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) d(4) 000 0--00 ---- a(4) {6b} ]\", mnemonic=\"PACK\")\ndef tricore_extr(obj, c, d, a):\n    if d%2:\n        raise InstructionError(obj)\n    src1 = env.E[d]\n    src2 = env.D[a]\n    dst = env.D[c]\n    obj.operands = [dst, src1, src2]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) {08} -- 00 ---- a(4) {4b} ]\", mnemonic=\"UNPACK\")\ndef tricore_extr(obj, c, d, a):\n    src = env.D[a]\n    dst = env.E[c]\n    obj.operands = [dst, src]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) {02} -- 00 ---- a(4) {4b} ]\", mnemonic=\"PARITY\")\n@ispec(\"32<[ c(4) {22} -- 00 ---- a(4) {4b} ]\", mnemonic=\"POPCNT_W\")\ndef tricore_extr(obj, c, d, a):\n    src = env.D[a]\n    dst = env.D[c]\n    obj.operands = [dst, src]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) pos(5) 00 ----- b(4) a(4) {77} ]\", mnemonic=\"DEXTR\")\ndef tricore_dextr(obj, c, pos, b, a):\n    src1 = env.D[a]\n    src2 = env.D[b]\n    dst = env.D[c]\n    obj.operands = [dst, src1, src2, env.cst(pos,5)]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) pos(5) 10 width(5) ---- a(4) {37} ]\", mnemonic=\"EXTR\")\n@ispec(\"32<[ c(4) pos(5) 11 width(5) ---- a(4) {37} ]\", mnemonic=\"EXTR_U\")\ndef tricore_extr(obj, c, pos, width, a):\n    src1 = env.D[a]\n    dst = env.D[c]\n    obj.operands = [dst, src1, env.cst(pos,5), env.cst(width,5)]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) pos(5) 01 width(5) const(4) ---- {b7} ]\", mnemonic=\"IMASK\")\ndef tricore_imask(obj, c, pos, width, const):\n    if c%2:\n        raise InstructionError(obj)\n    dst = env.E[c]\n    obj.operands = [dst, env.cst(const,4), env.cst(pos,5), env.cst(width,5)]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) d(4) 001 width(5) const(4) ---- {d7} ]\", mnemonic=\"IMASK\")\ndef tricore_imask(obj, c, d, width, const):\n    src2 = env.D[d]\n    if c%2:\n        raise InstructionError(obj)\n    dst = env.E[c]\n    obj.operands = [dst, env.cst(const,4), src2, env.cst(width,5)]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) pos(5) 01 width(5) b(4) ---- {37} ]\", mnemonic=\"IMASK\")\ndef tricore_imask(obj, c, pos, width, b):\n    src1 = env.D[b]\n    if c%2:\n        raise InstructionError(obj)\n    dst = env.E[c]\n    obj.operands = [dst, src1, env.cst(pos,5), env.cst(width,5)]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) d(4) 001 width(5) b(4) ---- {57} ]\", mnemonic=\"IMASK\")\ndef tricore_imask(obj, c, d, width, b):\n    src1 = env.D[b]\n    src2 = env.D[d]\n    if c%2:\n        raise InstructionError(obj)\n    dst = env.E[c]\n    obj.operands = [dst, src1, src2, env.cst(width,5)]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) pos(5) 00 width(5) const(4) a(4) {b7} ]\", mnemonic=\"INSERT\")\ndef tricore_imask(obj, c, pos, width, const, a):\n    dst = env.D[c]\n    src1 = env.D[a]\n    obj.operands = [dst, src1, env.cst(const,4), env.cst(pos,5), env.cst(width,5)]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) d(4) 000 ----- const(4) a(4) {97} ]\", mnemonic=\"INSERT\")\ndef tricore_imask(obj, c, d, const, a):\n    src1 = env.D[a]\n    if d%2:\n        raise InstructionError(obj)\n    src3 = env.E[d]\n    dst = env.D[c]\n    obj.operands = [dst, src1, env.cst(const,4), src3]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) d(4) 000 width(5) const(4) a(4) {d7} ]\", mnemonic=\"INSERT\")\ndef tricore_imask(obj, c, d, width, const, a):\n    src1 = env.D[a]\n    src3 = env.D[d]\n    dst = env.D[c]\n    obj.operands = [dst, src1, env.cst(const,4), src3]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) pos(5) 00 width(5) b(4) a(4) {37} ]\", mnemonic=\"INSERT\")\ndef tricore_imask(obj, c, pos, width, b, a):\n    dst = env.D[c]\n    src1 = env.D[a]\n    src2 = env.D[b]\n    obj.operands = [dst, src1, src2, env.cst(pos,5), env.cst(width,5)]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) d(4) 000 ----- b(4) a(4) {17} ]\", mnemonic=\"INSERT\")\ndef tricore_imask(obj, c, d, b, a):\n    src1 = env.D[a]\n    src2 = env.D[b]\n    if d%2:\n        raise InstructionError(obj)\n    src3 = env.E[d]\n    dst = env.D[c]\n    obj.operands = [dst, src1, src2, src3]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) d(4) 000 width(5) b(4) a(4) {57} ]\", mnemonic=\"INSERT\")\ndef tricore_imask(obj, c, d, width, b, a):\n    src1 = env.D[a]\n    src2 = env.D[b]\n    src3 = env.D[d]\n    dst = env.D[c]\n    obj.operands = [dst, src1, src2, src3, env.cst(width,5)]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) d(4) 010 width(5) ---- a(4) {57} ]\", mnemonic=\"EXTR\")\n@ispec(\"32<[ c(4) d(4) 011 width(5) ---- a(4) {57} ]\", mnemonic=\"EXTR_U\")\ndef tricore_extr(obj, c, d, width, a):\n    src2 = env.D[d]\n    src1 = env.D[a]\n    dst = env.D[c]\n    obj.operands = [dst, src1, src2, env.cst(width,5)]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) {09} --00 ---- a(4) {4b} ]\", mnemonic=\"BSPLIT\")\ndef tricore_edd_arithmetic(obj, c, a):\n    src1 = env.D[a]\n    dst = env.E[c]\n    obj.operands = [dst, src1]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) 0001110 ~const9(9) a(4) {8b} ]\", mnemonic=\"ABSDIF\")\n@ispec(\"32<[ c(4) 0001111 ~const9(9) a(4) {8b} ]\", mnemonic=\"ABSDIFS\")\n@ispec(\"32<[ c(4) 0000000 ~const9(9) a(4) {8b} ]\", mnemonic=\"ADD\")\n@ispec(\"32<[ c(4) 0000101 ~const9(9) a(4) {8b} ]\", mnemonic=\"ADDC\")\n@ispec(\"32<[ c(4) 0000010 ~const9(9) a(4) {8b} ]\", mnemonic=\"ADDS\")\n@ispec(\"32<[ c(4) 0000011 ~const9(9) a(4) {8b} ]\", mnemonic=\"ADDS_U\")  #const9 is signed\n@ispec(\"32<[ c(4) 0000100 ~const9(9) a(4) {8b} ]\", mnemonic=\"ADDX\")\n@ispec(\"32<[ c(4) 0100000 ~const9(9) a(4) {8b} ]\", mnemonic=\"AND_EQ\")\n@ispec(\"32<[ c(4) 0100100 ~const9(9) a(4) {8b} ]\", mnemonic=\"AND_GE\")\n@ispec(\"32<[ c(4) 0100010 ~const9(9) a(4) {8b} ]\", mnemonic=\"AND_LT\")\n@ispec(\"32<[ c(4) 0100001 ~const9(9) a(4) {8b} ]\", mnemonic=\"AND_NE\")\n@ispec(\"32<[ c(4) 0010000 ~const9(9) a(4) {8b} ]\", mnemonic=\"EQ\")\n@ispec(\"32<[ c(4) 1010110 ~const9(9) a(4) {8b} ]\", mnemonic=\"EQANY_B\")\n@ispec(\"32<[ c(4) 1110110 ~const9(9) a(4) {8b} ]\", mnemonic=\"EQANY_H\")\n@ispec(\"32<[ c(4) 0010100 ~const9(9) a(4) {8b} ]\", mnemonic=\"GE\")\n@ispec(\"32<[ c(4) 0010010 ~const9(9) a(4) {8b} ]\", mnemonic=\"LT\")\n@ispec(\"32<[ c(4) 0011010 ~const9(9) a(4) {8b} ]\", mnemonic=\"MAX\")\n@ispec(\"32<[ c(4) 0010001 ~const9(9) a(4) {8b} ]\", mnemonic=\"NE\")\n@ispec(\"32<[ c(4) 0100111 ~const9(9) a(4) {8b} ]\", mnemonic=\"OR_EQ\")\n@ispec(\"32<[ c(4) 0101011 ~const9(9) a(4) {8b} ]\", mnemonic=\"OR_GE\")\n@ispec(\"32<[ c(4) 0101001 ~const9(9) a(4) {8b} ]\", mnemonic=\"OR_LT\")\n@ispec(\"32<[ c(4) 0001000 ~const9(9) a(4) {8b} ]\", mnemonic=\"RSUB\")\n@ispec(\"32<[ c(4) 0001001 ~const9(9) a(4) {8b} ]\", mnemonic=\"RSUBS\")\n@ispec(\"32<[ c(4) 0001011 ~const9(9) a(4) {8b} ]\", mnemonic=\"RSUBS_U\") #const9 is signed\n@ispec(\"32<[ c(4) 0000000 ~const9(9) a(4) {8f} ]\", mnemonic=\"SH\")\n@ispec(\"32<[ c(4) 1000000 ~const9(9) a(4) {8f} ]\", mnemonic=\"SH_H\")\n@ispec(\"32<[ c(4) 0110111 ~const9(9) a(4) {8b} ]\", mnemonic=\"SH_EQ\")\n@ispec(\"32<[ c(4) 0111011 ~const9(9) a(4) {8b} ]\", mnemonic=\"SH_GE\")\n@ispec(\"32<[ c(4) 0111001 ~const9(9) a(4) {8b} ]\", mnemonic=\"SH_LT\")\n@ispec(\"32<[ c(4) 0111000 ~const9(9) a(4) {8b} ]\", mnemonic=\"SH_NE\")\n@ispec(\"32<[ c(4) 0000001 ~const9(9) a(4) {8f} ]\", mnemonic=\"SHA\")\n@ispec(\"32<[ c(4) 1000001 ~const9(9) a(4) {8f} ]\", mnemonic=\"SHA_H\")\n@ispec(\"32<[ c(4) 0000010 ~const9(9) a(4) {8f} ]\", mnemonic=\"SHAS\")\n@ispec(\"32<[ c(4) 0101111 ~const9(9) a(4) {8b} ]\", mnemonic=\"XOR_EQ\")\n@ispec(\"32<[ c(4) 0110011 ~const9(9) a(4) {8b} ]\", mnemonic=\"XOR_GE\")\n@ispec(\"32<[ c(4) 0110001 ~const9(9) a(4) {8b} ]\", mnemonic=\"XOR_LT\")\n@ispec(\"32<[ c(4) 0110000 ~const9(9) a(4) {8b} ]\", mnemonic=\"XOR_NE\")\ndef tricore_ddc_arithmetic(obj, c, const9, a):\n    src1 = env.D[a]\n    if obj.mnemonic in (\"SH\",\"SHA\",\"SHAS\"):\n        const9 = const9[0:6]\n    elif obj.mnemonic in (\"SH_H\",\"SHA_H\"):\n        const9 = const9[0:5]\n    src2 = env.cst(const9.int(-1),32)\n    dst = env.D[c]\n    obj.operands = [dst, src1, src2]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) pos2(5) 00 pos1(5) b(4) a(4) {47} ]\", mnemonic=\"AND_AND_T\")\n@ispec(\"32<[ c(4) pos2(5) 11 pos1(5) b(4) a(4) {47} ]\", mnemonic=\"AND_ANDN_T\")\n@ispec(\"32<[ c(4) pos2(5) 10 pos1(5) b(4) a(4) {47} ]\", mnemonic=\"AND_NOR_T\")\n@ispec(\"32<[ c(4) pos2(5) 01 pos1(5) b(4) a(4) {47} ]\", mnemonic=\"AND_OR_T\")\n@ispec(\"32<[ c(4) pos2(5) 00 pos1(5) b(4) a(4) {87} ]\", mnemonic=\"AND_T\")\n@ispec(\"32<[ c(4) pos2(5) 11 pos1(5) b(4) a(4) {87} ]\", mnemonic=\"ANDN_T\")\n@ispec(\"32<[ c(4) pos2(5) 00 pos1(5) b(4) a(4) {67} ]\", mnemonic=\"INS_T\")\n@ispec(\"32<[ c(4) pos2(5) 01 pos1(5) b(4) a(4) {67} ]\", mnemonic=\"INSN_T\")\n@ispec(\"32<[ c(4) pos2(5) 00 pos1(5) b(4) a(4) {07} ]\", mnemonic=\"NAND_T\")\n@ispec(\"32<[ c(4) pos2(5) 10 pos1(5) b(4) a(4) {87} ]\", mnemonic=\"NOR_T\")\n@ispec(\"32<[ c(4) pos2(5) 00 pos1(5) b(4) a(4) {c7} ]\", mnemonic=\"OR_AND_T\")\n@ispec(\"32<[ c(4) pos2(5) 11 pos1(5) b(4) a(4) {c7} ]\", mnemonic=\"OR_ANDN_T\")\n@ispec(\"32<[ c(4) pos2(5) 10 pos1(5) b(4) a(4) {c7} ]\", mnemonic=\"OR_NOR_T\")\n@ispec(\"32<[ c(4) pos2(5) 01 pos1(5) b(4) a(4) {c7} ]\", mnemonic=\"OR_OR_T\")\n@ispec(\"32<[ c(4) pos2(5) 01 pos1(5) b(4) a(4) {87} ]\", mnemonic=\"OR_T\")\n@ispec(\"32<[ c(4) pos2(5) 01 pos1(5) b(4) a(4) {07} ]\", mnemonic=\"ORN_T\")\n@ispec(\"32<[ c(4) pos2(5) 00 pos1(5) b(4) a(4) {27} ]\", mnemonic=\"SH_AND_T\")\n@ispec(\"32<[ c(4) pos2(5) 11 pos1(5) b(4) a(4) {27} ]\", mnemonic=\"SH_ANDN_T\")\n@ispec(\"32<[ c(4) pos2(5) 00 pos1(5) b(4) a(4) {a7} ]\", mnemonic=\"SH_NAND_T\")\n@ispec(\"32<[ c(4) pos2(5) 10 pos1(5) b(4) a(4) {27} ]\", mnemonic=\"SH_NOR_T\")\n@ispec(\"32<[ c(4) pos2(5) 01 pos1(5) b(4) a(4) {27} ]\", mnemonic=\"SH_OR_T\")\n@ispec(\"32<[ c(4) pos2(5) 01 pos1(5) b(4) a(4) {a7} ]\", mnemonic=\"SH_ORN_T\")\n@ispec(\"32<[ c(4) pos2(5) 10 pos1(5) b(4) a(4) {a7} ]\", mnemonic=\"SH_XNOR_T\")\n@ispec(\"32<[ c(4) pos2(5) 11 pos1(5) b(4) a(4) {a7} ]\", mnemonic=\"SH_XOR_T\")\n@ispec(\"32<[ c(4) pos2(5) 10 pos1(5) b(4) a(4) {07} ]\", mnemonic=\"XNOR_T\")\n@ispec(\"32<[ c(4) pos2(5) 11 pos1(5) b(4) a(4) {07} ]\", mnemonic=\"XOR_T\")\ndef tricore_ddd_arithmetic(obj, c, pos2, pos1, b, a):\n    src1 = env.D[a]\n    src2 = env.D[b]\n    dst = env.D[c]\n    obj.operands = [dst, src1[pos1:pos1+1], src2[pos2:pos2+1]]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) 0001000 const9(9) a(4) {8f} ]\", mnemonic=\"AND\")\n@ispec(\"32<[ c(4) 0100101 const9(9) a(4) {8b} ]\", mnemonic=\"AND_GE_U\")\n@ispec(\"32<[ c(4) 0100011 const9(9) a(4) {8b} ]\", mnemonic=\"AND_LT_U\")\n@ispec(\"32<[ c(4) 0001110 const9(9) a(4) {8f} ]\", mnemonic=\"ANDN\")\n@ispec(\"32<[ c(4) 0001001 const9(9) a(4) {8f} ]\", mnemonic=\"NAND\")\n@ispec(\"32<[ c(4) 0001011 const9(9) a(4) {8f} ]\", mnemonic=\"NOR\")\n@ispec(\"32<[ c(4) 0010101 const9(9) a(4) {8b} ]\", mnemonic=\"GE_U\")\n@ispec(\"32<[ c(4) 0001010 const9(9) a(4) {8f} ]\", mnemonic=\"OR\")\n@ispec(\"32<[ c(4) 0101100 const9(9) a(4) {8b} ]\", mnemonic=\"OR_GE_U\")\n@ispec(\"32<[ c(4) 0101010 const9(9) a(4) {8b} ]\", mnemonic=\"OR_LT_U\")\n@ispec(\"32<[ c(4) 0101000 const9(9) a(4) {8b} ]\", mnemonic=\"OR_NE\")\n@ispec(\"32<[ c(4) 0001111 const9(9) a(4) {8f} ]\", mnemonic=\"ORN\")\n@ispec(\"32<[ c(4) 0000111 const9(9) a(4) {8f} ]\", mnemonic=\"SHUFFLE\")\n@ispec(\"32<[ c(4) 0001101 const9(9) a(4) {8f} ]\", mnemonic=\"XNOR\")\n@ispec(\"32<[ c(4) 0001100 const9(9) a(4) {8f} ]\", mnemonic=\"XOR\")\n@ispec(\"32<[ c(4) 0111100 const9(9) a(4) {8b} ]\", mnemonic=\"SH_GE_U\")\n@ispec(\"32<[ c(4) 0111010 const9(9) a(4) {8b} ]\", mnemonic=\"SH_LT_U\")\n@ispec(\"32<[ c(4) 0110100 const9(9) a(4) {8b} ]\", mnemonic=\"XOR_GE_U\")\n@ispec(\"32<[ c(4) 0110011 const9(9) a(4) {8b} ]\", mnemonic=\"XOR_LT_U\")\n@ispec(\"32<[ c(4) 0011011 const9(9) a(4) {8b} ]\", mnemonic=\"MAX_U\")\n@ispec(\"32<[ c(4) 0010011 const9(9) a(4) {8b} ]\", mnemonic=\"LT_U\")\ndef tricore_ddc_arithmetic(obj, c, const9, a):\n    src1 = env.D[a]\n    src2 = env.cst(const9,32)\n    dst = env.D[c]\n    obj.operands = [dst, src1, src2]\n    obj.type = type_data_processing\n@ispec(\"16<[ ~const4(4) a(4) {c2} ]\", mnemonic=\"ADD\")\n@ispec(\"16<[ ~const4(4) a(4) {06} ]\", mnemonic=\"SH\")\n@ispec(\"16<[ ~const4(4) a(4) {86} ]\", mnemonic=\"SHA\")\ndef tricore_ddc_arithmetic(obj, const4, a):\n    dst = env.D[a]\n    src2 = env.cst(const4.int(-1),32)\n    src1 = env.D[a]\n    obj.operands = [dst, src1, src2]\n    obj.type = type_data_processing\n@ispec(\"16<[ ~const4(4) a(4) {92} ]\", mnemonic=\"ADD\")\n@ispec(\"16<[ ~const4(4) a(4) {8a} ]\", mnemonic=\"CADD\")\n@ispec(\"16<[ ~const4(4) a(4) {ca} ]\", mnemonic=\"CADDN\")\n@ispec(\"16<[ ~const4(4) a(4) {aa} ]\", mnemonic=\"CMOV\")\n@ispec(\"16<[ ~const4(4) a(4) {ea} ]\", mnemonic=\"CMOVN\")\ndef tricore_ddc_arithmetic(obj, const4, a):\n    dst = env.D[a]\n    src2 = env.cst(const4.int(-1),32)\n    src1 = env.D[15]\n    obj.operands = [dst, src1, src2]\n    if \"CADD\" in obj.mnemonic:\n        obj.operands = [dst, src1, dst, src2]\n    obj.type = type_data_processing\n@ispec(\"16<[ ~const4(4) a(4) {9a} ]\", mnemonic=\"ADD\")\n@ispec(\"16<[ ~const4(4) a(4) {ba} ]\", mnemonic=\"EQ\")\n@ispec(\"16<[ ~const4(4) a(4) {fa} ]\", mnemonic=\"LT\")\n@ispec(\"16<[ ~const4(4) a(4) {82} ]\", mnemonic=\"MOV\")\ndef tricore_ddc_arithmetic(obj, const4, a):\n    dst = env.D[15]\n    src2 = env.cst(const4.int(-1),32)\n    src1 = env.D[a]\n    obj.operands = [dst, src1, src2]\n    if obj.mnemonic==\"MOV\":\n        obj.operands = [src1,src2]\n    obj.type = type_data_processing\n@ispec(\"16<[ ~const4(4) a(4) {d2} ]\", mnemonic=\"MOV\")\ndef tricore_ec_arithmetic(obj, const4, a):\n    dst = env.E[a]\n    src = env.cst(const4.int(-1),64)\n    obj.operands = [dst, src]\n    obj.type = type_data_processing\n@ispec(\"16<[ const4(4) a(4) {a0} ]\", mnemonic=\"MOV_A\")\ndef tricore_ec_arithmetic(obj, const4, a):\n    dst = env.A[a]\n    src = env.cst(const4,32)\n    obj.operands = [dst, src]\n    obj.type = type_data_processing\n@ispec(\"16<[ const8(8) {16} ]\", mnemonic=\"AND\")\n@ispec(\"16<[ const8(8) {da} ]\", mnemonic=\"MOV\")\n@ispec(\"16<[ const8(8) {96} ]\", mnemonic=\"OR\")\ndef tricore_ddc_arithmetic(obj, const8):\n    dst = env.D[15]\n    src2 = env.cst(const8,32)\n    src1 = env.D[15]\n    obj.operands = [dst, src1, src2]\n    if obj.mnemonic==\"MOV\":\n        obj.operands = [src1,src2]\n    obj.type = type_data_processing\n@ispec(\"16<[ b(4) a(4) {42} ]\", mnemonic=\"ADD\")\n@ispec(\"16<[ b(4) a(4) {26} ]\", mnemonic=\"AND\")\n@ispec(\"16<[ b(4) a(4) {a6} ]\", mnemonic=\"OR\")\n@ispec(\"16<[ b(4) a(4) {a2} ]\", mnemonic=\"SUB\")\n@ispec(\"16<[ b(4) a(4) {62} ]\", mnemonic=\"SUBS\")\n@ispec(\"16<[ b(4) a(4) {c6} ]\", mnemonic=\"XOR\")\ndef tricore_dd_arithmetic(obj, b, a):\n    dst = env.D[a]\n    src1 = env.D[a]\n    src2 = env.D[b]\n    obj.operands = [dst, src1, src2]\n    obj.type = type_data_processing\n@ispec(\"16<[ b(4) a(4) {02} ]\", mnemonic=\"MOV\"    , _dst=env.D, _src=env.D)\n@ispec(\"16<[ b(4) a(4) {60} ]\", mnemonic=\"MOV_A\"  , _dst=env.A, _src=env.D)\n@ispec(\"16<[ b(4) a(4) {40} ]\", mnemonic=\"MOV_AA\" , _dst=env.A, _src=env.A)\n@ispec(\"16<[ b(4) a(4) {80} ]\", mnemonic=\"MOV_D\"  , _dst=env.D, _src=env.A)\ndef tricore_mov(obj, b, a, _dst, _src):\n    dst = _dst[a]\n    src = _src[b]\n    obj.operands = [dst, src]\n    obj.type = type_data_processing\n@ispec(\"16<[ b(4) a(4) {12} ]\", mnemonic=\"ADD\")\n@ispec(\"16<[ b(4) a(4) {2a} ]\", mnemonic=\"CMOV\")\n@ispec(\"16<[ b(4) a(4) {6a} ]\", mnemonic=\"CMOVN\")\n@ispec(\"16<[ b(4) a(4) {52} ]\", mnemonic=\"SUB\")\ndef tricore_dd_arithmetic(obj, b, a):\n    dst = env.D[a]\n    src1 = env.D[15]\n    src2 = env.D[b]\n    obj.operands = [dst, src1, src2]\n    obj.type = type_data_processing\n@ispec(\"16<[ b(4) a(4) {1a} ]\", mnemonic=\"ADD\")\n@ispec(\"16<[ b(4) a(4) {22} ]\", mnemonic=\"ADDS\")\n@ispec(\"16<[ b(4) a(4) {3a} ]\", mnemonic=\"EQ\")\n@ispec(\"16<[ b(4) a(4) {7a} ]\", mnemonic=\"LT\")\n@ispec(\"16<[ b(4) a(4) {5a} ]\", mnemonic=\"SUB\")\ndef tricore_dd_arithmetic(obj, b, a):\n    dst = env.D[15]\n    src1 = env.D[a]\n    src2 = env.D[b]\n    obj.operands = [dst, src1, src2]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) {01} ---- b(4) a(4) {01} ]\", mnemonic=\"ADD_A\")\n@ispec(\"32<[ c(4) {02} ---- b(4) a(4) {01} ]\", mnemonic=\"SUB_A\")\ndef tricore_aaa_arithmetic(obj, c, b, a):\n    src1 = env.A[a]\n    src2 = env.A[b]\n    dst = env.A[c]\n    obj.operands = [dst, src1, src2]\n    obj.type = type_data_processing\n@ispec(\"16<[ ~const4(4) a(4) {b0} ]\", mnemonic=\"ADD_A\")\ndef tricore_aac_arithmetic(obj, const4, a):\n    dst = env.A[a]\n    src2 = env.cst(const4.int(-1),32)\n    src1 = env.A[a]\n    obj.operands = [dst, src1, src2]\n    obj.type = type_data_processing\n@ispec(\"16<[ const8(8) {20} ]\", mnemonic=\"SUB_A\")\ndef tricore_aac_arithmetic(obj, const8, a):\n    dst = env.A[10]\n    src2 = env.cst(const8,32)\n    src1 = env.A[10]\n    obj.operands = [dst, src1, src2]\n    obj.type = type_data_processing\n@ispec(\"16<[ b(4) a(4) {30} ]\", mnemonic=\"ADD_A\")\ndef tricore_aa_arithmetic(obj, b, a):\n    dst = env.A[a]\n    src1 = env.A[a]\n    src2 = env.A[b]\n    obj.operands = [dst, src1, src2]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) ~const16(16) a(4) {1b} ]\", mnemonic=\"ADDI\")\n@ispec(\"32<[ c(4) ~const16(16) a(4) {9b} ]\", mnemonic=\"ADDIH\")\ndef tricore_di_arithmetic(obj, c, const16, a):\n    src1 = env.D[a]\n    src2 = env.cst(const16.int(-1),32)\n    if self.mnemonic==\"ADDIH\": src2=src2<<16\n    dst = env.D[c]\n    obj.operands = [dst, src1, src2]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) ~const16(16) a(4) {11} ]\", mnemonic=\"ADDIH_A\")\ndef tricore_ai_arithmetic(obj, c, const16, a):\n    src1 = env.A[a]\n    src2 = env.cst(const16.int(-1),32)<<16\n    dst = env.A[c]\n    obj.operands = [dst, src1, src2]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) {60} -- n(2) b(4) a(4) {01} ]\", mnemonic=\"ADDSC_A\")\ndef tricore_aaa_arithmetic(obj, c, n, b, a):\n    src1 = env.D[a]\n    src2 = env.A[b]\n    dst = env.A[c]\n    obj.operands = [dst, src2, src1, env.cst(n,2)]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) {62} ---- b(4) a(4) {01} ]\", mnemonic=\"ADDSC_AT\")\ndef tricore_aaa_arithmetic(obj, c, b, a):\n    src1 = env.D[a]\n    src2 = env.A[b]\n    dst = env.A[c]\n    obj.operands = [dst, src2, src1]\n    obj.type = type_data_processing\n@ispec(\"16<[ b(4) a(4) n(2) 010000 ]\", mnemonic=\"ADDSC_A\")\ndef tricore_aa_arithmetic(obj, b, a, n):\n    dst = env.A[a]\n    src1 = env.D[15]\n    src2 = env.A[b]\n    obj.operands = [dst, src2, src1, env.cst(n,2)]\n    obj.type = type_data_processing\n@ispec(\"32<[ off2(4) 10 1110 off1(6) b(4) ---- {89} ]\", mnemonic=\"CACHEA_I\",  mode=\"Short-offset\")\n@ispec(\"32<[ off2(4) 00 1110 off1(6) b(4) ---- {a9} ]\", mnemonic=\"CACHEA_I\",  mode=\"Bit-reverse\")\n@ispec(\"32<[ off2(4) 01 1110 off1(6) b(4) ---- {a9} ]\", mnemonic=\"CACHEA_I\",  mode=\"Circular\")\n@ispec(\"32<[ off2(4) 00 1110 off1(6) b(4) ---- {89} ]\", mnemonic=\"CACHEA_I\",  mode=\"Post-increment\")\n@ispec(\"32<[ off2(4) 01 1110 off1(6) b(4) ---- {89} ]\", mnemonic=\"CACHEA_I\",  mode=\"Pre-increment\")\n@ispec(\"32<[ off2(4) 10 1100 off1(6) b(4) ---- {89} ]\", mnemonic=\"CACHEA_W\",  mode=\"Short-offset\")\n@ispec(\"32<[ off2(4) 00 1100 off1(6) b(4) ---- {a9} ]\", mnemonic=\"CACHEA_W\",  mode=\"Bit-reverse\")\n@ispec(\"32<[ off2(4) 01 1100 off1(6) b(4) ---- {a9} ]\", mnemonic=\"CACHEA_W\",  mode=\"Circular\")\n@ispec(\"32<[ off2(4) 00 1100 off1(6) b(4) ---- {89} ]\", mnemonic=\"CACHEA_W\",  mode=\"Post-increment\")\n@ispec(\"32<[ off2(4) 01 1100 off1(6) b(4) ---- {89} ]\", mnemonic=\"CACHEA_W\",  mode=\"Pre-increment\")\n@ispec(\"32<[ off2(4) 10 1101 off1(6) b(4) ---- {89} ]\", mnemonic=\"CACHEA_WI\", mode=\"Short-offset\")\n@ispec(\"32<[ off2(4) 00 1101 off1(6) b(4) ---- {a9} ]\", mnemonic=\"CACHEA_WI\", mode=\"Bit-reverse\")\n@ispec(\"32<[ off2(4) 01 1101 off1(6) b(4) ---- {a9} ]\", mnemonic=\"CACHEA_WI\", mode=\"Circular\")\n@ispec(\"32<[ off2(4) 00 1101 off1(6) b(4) ---- {89} ]\", mnemonic=\"CACHEA_WI\", mode=\"Post-increment\")\n@ispec(\"32<[ off2(4) 01 1101 off1(6) b(4) ---- {89} ]\", mnemonic=\"CACHEA_WI\", mode=\"Pre-increment\")\n@ispec(\"32<[ off2(4) 10 1011 off1(6) b(4) ---- {89} ]\", mnemonic=\"CACHEI_W\",  mode=\"Short-offset\")\n@ispec(\"32<[ off2(4) 00 1011 off1(6) b(4) ---- {89} ]\", mnemonic=\"CACHEI_W\",  mode=\"Post-increment\")\n@ispec(\"32<[ off2(4) 01 1011 off1(6) b(4) ---- {89} ]\", mnemonic=\"CACHEI_W\",  mode=\"Pre-increment\")\n@ispec(\"32<[ off2(4) 10 1010 off1(6) b(4) ---- {89} ]\", mnemonic=\"CACHEI_I\",  mode=\"Short-offset\")\n@ispec(\"32<[ off2(4) 00 1010 off1(6) b(4) ---- {89} ]\", mnemonic=\"CACHEI_I\",  mode=\"Post-increment\")\n@ispec(\"32<[ off2(4) 01 1010 off1(6) b(4) ---- {89} ]\", mnemonic=\"CACHEI_I\",  mode=\"Pre-increment\")\n@ispec(\"32<[ off2(4) 10 1111 off1(6) b(4) ---- {89} ]\", mnemonic=\"CACHEI_WI\", mode=\"Short-offset\")\n@ispec(\"32<[ off2(4) 00 1111 off1(6) b(4) ---- {89} ]\", mnemonic=\"CACHEI_WI\", mode=\"Post-increment\")\n@ispec(\"32<[ off2(4) 01 1111 off1(6) b(4) ---- {89} ]\", mnemonic=\"CACHEI_WI\", mode=\"Pre-increment\")\ndef tricore_cache(obj, off2, off1, b):\n    src2 = env.A[b]\n    src1 = env.cst((off2<<6)+off1,10)\n    obj.operands = [src2, src1]\n    obj.type = type_system\n@ispec(\"32<[ off2(4) 10 0011 off1(6) b(4) a(4) {49} ]\", mnemonic=\"CMPSWAP_W\", mode=\"Short-offset\")\n@ispec(\"32<[ off2(4) 00 0011 off1(6) b(4) a(4) {69} ]\", mnemonic=\"CMPSWAP_W\", mode=\"Bit-reverse\")\n@ispec(\"32<[ off2(4) 01 0011 off1(6) b(4) a(4) {69} ]\", mnemonic=\"CMPSWAP_W\", mode=\"Circular\")\n@ispec(\"32<[ off2(4) 00 0011 off1(6) b(4) a(4) {49} ]\", mnemonic=\"CMPSWAP_W\", mode=\"Post-increment\")\n@ispec(\"32<[ off2(4) 01 0011 off1(6) b(4) a(4) {49} ]\", mnemonic=\"CMPSWAP_W\", mode=\"Pre-increment\")\n@ispec(\"32<[ off2(4) 10 0010 off1(6) b(4) a(4) {49} ]\", mnemonic=\"SWAPMSK_W\", mode=\"Short-offset\")\n@ispec(\"32<[ off2(4) 00 0010 off1(6) b(4) a(4) {69} ]\", mnemonic=\"SWAPMSK_W\", mode=\"Bit-reverse\")\n@ispec(\"32<[ off2(4) 01 0010 off1(6) b(4) a(4) {69} ]\", mnemonic=\"SWAPMSK_W\", mode=\"Circular\")\n@ispec(\"32<[ off2(4) 00 0010 off1(6) b(4) a(4) {49} ]\", mnemonic=\"SWAPMSK_W\", mode=\"Post-increment\")\n@ispec(\"32<[ off2(4) 01 0010 off1(6) b(4) a(4) {49} ]\", mnemonic=\"SWAPMSK_W\", mode=\"Pre-increment\")\ndef tricore_swap(obj, off2, off1, b, a):\n    if a%2:\n        raise InstructionError(obj)\n    dst = env.D[a]\n    src1 = env.A[b]\n    src2 = env.cst((off2<<6)+off1,10)\n    src3 = env.E[a]\n    obj.operands = [dst, src1, src2, src3]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) d(4) 000 ~const9(9) a(4) {ab} ]\", mnemonic=\"CADD\")\n@ispec(\"32<[ c(4) d(4) 001 ~const9(9) a(4) {ab} ]\", mnemonic=\"CADDN\")\n@ispec(\"32<[ c(4) d(4) 001 ~const9(9) a(4) {13} ]\", mnemonic=\"MADD\", opt4=\"32+(32+K9)->32\")\n@ispec(\"32<[ c(4) d(4) 101 ~const9(9) a(4) {13} ]\", mnemonic=\"MADDS\",  opt4=\"32+(32+K9)->32\")\n@ispec(\"32<[ c(4) d(4) 100 ~const9(9) a(4) {13} ]\", mnemonic=\"MADDS_U\", opt4=\"32+(32+K9)->32\")\n@ispec(\"32<[ c(4) d(4) 001 ~const9(9) a(4) {33} ]\", mnemonic=\"MSUB\", opt4=\"32+(32+K9)->32\")\n@ispec(\"32<[ c(4) d(4) 101 ~const9(9) a(4) {33} ]\", mnemonic=\"MSUBS\",  opt4=\"32+(32+K9)->32\")\n@ispec(\"32<[ c(4) d(4) 100 ~const9(9) a(4) {33} ]\", mnemonic=\"MSUBS_U\", opt4=\"32+(32+K9)->32\")\n@ispec(\"32<[ c(4) d(4) 100 ~const9(9) a(4) {ab} ]\", mnemonic=\"SEL\")\n@ispec(\"32<[ c(4) d(4) 101 ~const9(9) a(4) {ab} ]\", mnemonic=\"SELN\")\ndef tricore_cond_ddc(obj, c, d, const9, a):\n    cond = env.D[d]\n    src1 = env.D[a]\n    src2 = env.cst(const9.int(-1),32)\n    dst = env.D[c]\n    obj.operands = [dst, cond, src1, src2]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) d(4) 011 ~const9(9) a(4) {13} ]\", mnemonic=\"MADD\", opt4=\"64+(32+K9)->64\")\n@ispec(\"32<[ c(4) d(4) 111 ~const9(9) a(4) {13} ]\", mnemonic=\"MADDS\", opt4=\"64+(32+K9)->64\")\n@ispec(\"32<[ c(4) d(4) 010 ~const9(9) a(4) {13} ]\", mnemonic=\"MADD_U\", opt4=\"64+(32+K9)->64\")\n@ispec(\"32<[ c(4) d(4) 111 ~const9(9) a(4) {13} ]\", mnemonic=\"MADDS_U\", opt4=\"64+(32+K9)->64\")\n@ispec(\"32<[ c(4) d(4) 011 ~const9(9) a(4) {33} ]\", mnemonic=\"MSUB\", opt4=\"64+(32+K9)->64\")\n@ispec(\"32<[ c(4) d(4) 111 ~const9(9) a(4) {33} ]\", mnemonic=\"MSUBS\", opt4=\"64+(32+K9)->64\")\n@ispec(\"32<[ c(4) d(4) 010 ~const9(9) a(4) {33} ]\", mnemonic=\"MSUB_U\", opt4=\"64+(32+K9)->64\")\n@ispec(\"32<[ c(4) d(4) 111 ~const9(9) a(4) {33} ]\", mnemonic=\"MSUBS_U\", opt4=\"64+(32+K9)->64\")\ndef tricore_cond_eec(obj, c, d, const9, a):\n    cond = env.E[d]\n    src1 = env.D[a]\n    src2 = env.cst(const9.int(-1),32)\n    dst = env.E[c]\n    obj.operands = [dst, cond, src1, src2]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) d(4) 011010 n(2) b(4) a(4) {83} ]\", mnemonic=\"MADD_H\", op4=\"LL\")\n@ispec(\"32<[ c(4) d(4) 011001 n(2) b(4) a(4) {83} ]\", mnemonic=\"MADD_H\", op4=\"LU\")\n@ispec(\"32<[ c(4) d(4) 011000 n(2) b(4) a(4) {83} ]\", mnemonic=\"MADD_H\", op4=\"UL\")\n@ispec(\"32<[ c(4) d(4) 011011 n(2) b(4) a(4) {83} ]\", mnemonic=\"MADD_H\", op4=\"UU\")\n@ispec(\"32<[ c(4) d(4) 111010 n(2) b(4) a(4) {83} ]\", mnemonic=\"MADDS_H\", op4=\"LL\")\n@ispec(\"32<[ c(4) d(4) 111001 n(2) b(4) a(4) {83} ]\", mnemonic=\"MADDS_H\", op4=\"LU\")\n@ispec(\"32<[ c(4) d(4) 111000 n(2) b(4) a(4) {83} ]\", mnemonic=\"MADDS_H\", op4=\"UL\")\n@ispec(\"32<[ c(4) d(4) 111011 n(2) b(4) a(4) {83} ]\", mnemonic=\"MADDS_H\", op4=\"UU\")\n@ispec(\"32<[ c(4) d(4) 000010 n(2) b(4) a(4) {43} ]\", mnemonic=\"MADD_Q\", op4=\"32+(32*32)Up->32\")\n@ispec(\"32<[ c(4) d(4) 011011 n(2) b(4) a(4) {43} ]\", mnemonic=\"MADD_Q\", op4=\"64+(32*32)->64\")\n@ispec(\"32<[ c(4) d(4) 000001 n(2) b(4) a(4) {43} ]\", mnemonic=\"MADD_Q\", op4=\"32+(16L*32)Up->32\")\n@ispec(\"32<[ c(4) d(4) 011001 n(2) b(4) a(4) {43} ]\", mnemonic=\"MADD_Q\", op4=\"64+(16L*32)->64\")\n@ispec(\"32<[ c(4) d(4) 000000 n(2) b(4) a(4) {43} ]\", mnemonic=\"MADD_Q\", op4=\"32+(16U*32)Up->32\")\n@ispec(\"32<[ c(4) d(4) 011000 n(2) b(4) a(4) {43} ]\", mnemonic=\"MADD_Q\", op4=\"64+(16U*32)->64\")\n@ispec(\"32<[ c(4) d(4) 000101 n(2) b(4) a(4) {43} ]\", mnemonic=\"MADD_Q\", op4=\"32+(16L*16L)->32\")\n@ispec(\"32<[ c(4) d(4) 011101 n(2) b(4) a(4) {43} ]\", mnemonic=\"MADD_Q\", op4=\"64+(16L*16L)->64\")\n@ispec(\"32<[ c(4) d(4) 000100 n(2) b(4) a(4) {43} ]\", mnemonic=\"MADD_Q\", op4=\"32+(16U*16U)->32\")\n@ispec(\"32<[ c(4) d(4) 011100 n(2) b(4) a(4) {43} ]\", mnemonic=\"MADD_Q\", op4=\"64+(16U*16U)->64\")\n@ispec(\"32<[ c(4) d(4) 100010 n(2) b(4) a(4) {43} ]\", mnemonic=\"MADDS_Q\", op4=\"32+(32*32)Up->32\")\n@ispec(\"32<[ c(4) d(4) 111011 n(2) b(4) a(4) {43} ]\", mnemonic=\"MADDS_Q\", op4=\"64+(32*32)->64\")\n@ispec(\"32<[ c(4) d(4) 100001 n(2) b(4) a(4) {43} ]\", mnemonic=\"MADDS_Q\", op4=\"32+(16L*32)Up->32\")\n@ispec(\"32<[ c(4) d(4) 111001 n(2) b(4) a(4) {43} ]\", mnemonic=\"MADDS_Q\", op4=\"64+(16L*32)->64\")\n@ispec(\"32<[ c(4) d(4) 100000 n(2) b(4) a(4) {43} ]\", mnemonic=\"MADDS_Q\", op4=\"32+(16U*32)Up->32\")\n@ispec(\"32<[ c(4) d(4) 111000 n(2) b(4) a(4) {43} ]\", mnemonic=\"MADDS_Q\", op4=\"64+(16U*32)->64\")\n@ispec(\"32<[ c(4) d(4) 100101 n(2) b(4) a(4) {43} ]\", mnemonic=\"MADDS_Q\", op4=\"32+(16L*16L)->32\")\n@ispec(\"32<[ c(4) d(4) 111101 n(2) b(4) a(4) {43} ]\", mnemonic=\"MADDS_Q\", op4=\"64+(16L*16L)->64\")\n@ispec(\"32<[ c(4) d(4) 100100 n(2) b(4) a(4) {43} ]\", mnemonic=\"MADDS_Q\", op4=\"32+(16U*16U)->32\")\n@ispec(\"32<[ c(4) d(4) 111100 n(2) b(4) a(4) {43} ]\", mnemonic=\"MADDS_Q\", op4=\"64+(16U*16U)->64\")\n@ispec(\"32<[ c(4) d(4) 011010 n(2) b(4) a(4) {a3} ]\", mnemonic=\"MSUB_H\", op4=\"LL\")\n@ispec(\"32<[ c(4) d(4) 011001 n(2) b(4) a(4) {a3} ]\", mnemonic=\"MSUB_H\", op4=\"LU\")\n@ispec(\"32<[ c(4) d(4) 011000 n(2) b(4) a(4) {a3} ]\", mnemonic=\"MSUB_H\", op4=\"UL\")\n@ispec(\"32<[ c(4) d(4) 011011 n(2) b(4) a(4) {a3} ]\", mnemonic=\"MSUB_H\", op4=\"UU\")\n@ispec(\"32<[ c(4) d(4) 111010 n(2) b(4) a(4) {a3} ]\", mnemonic=\"MSUBS_H\", op4=\"LL\")\n@ispec(\"32<[ c(4) d(4) 111001 n(2) b(4) a(4) {a3} ]\", mnemonic=\"MSUBS_H\", op4=\"LU\")\n@ispec(\"32<[ c(4) d(4) 111000 n(2) b(4) a(4) {a3} ]\", mnemonic=\"MSUBS_H\", op4=\"UL\")\n@ispec(\"32<[ c(4) d(4) 111011 n(2) b(4) a(4) {a3} ]\", mnemonic=\"MSUBS_H\", op4=\"UU\")\n@ispec(\"32<[ c(4) d(4) 000010 n(2) b(4) a(4) {63} ]\", mnemonic=\"MSUB_Q\", op4=\"32+(32*32)Up->32\")\n@ispec(\"32<[ c(4) d(4) 011011 n(2) b(4) a(4) {63} ]\", mnemonic=\"MSUB_Q\", op4=\"64+(32*32)->64\")\n@ispec(\"32<[ c(4) d(4) 000001 n(2) b(4) a(4) {63} ]\", mnemonic=\"MSUB_Q\", op4=\"32+(16L*32)Up->32\")\n@ispec(\"32<[ c(4) d(4) 011001 n(2) b(4) a(4) {63} ]\", mnemonic=\"MSUB_Q\", op4=\"64+(16L*32)->64\")\n@ispec(\"32<[ c(4) d(4) 000000 n(2) b(4) a(4) {63} ]\", mnemonic=\"MSUB_Q\", op4=\"32+(16U*32)Up->32\")\n@ispec(\"32<[ c(4) d(4) 011000 n(2) b(4) a(4) {63} ]\", mnemonic=\"MSUB_Q\", op4=\"64+(16U*32)->64\")\n@ispec(\"32<[ c(4) d(4) 000101 n(2) b(4) a(4) {63} ]\", mnemonic=\"MSUB_Q\", op4=\"32+(16L*16L)->32\")\n@ispec(\"32<[ c(4) d(4) 011101 n(2) b(4) a(4) {63} ]\", mnemonic=\"MSUB_Q\", op4=\"64+(16L*16L)->64\")\n@ispec(\"32<[ c(4) d(4) 000100 n(2) b(4) a(4) {63} ]\", mnemonic=\"MSUB_Q\", op4=\"32+(16U*16U)->32\")\n@ispec(\"32<[ c(4) d(4) 011100 n(2) b(4) a(4) {63} ]\", mnemonic=\"MSUB_Q\", op4=\"64+(16U*16U)->64\")\n@ispec(\"32<[ c(4) d(4) 100010 n(2) b(4) a(4) {63} ]\", mnemonic=\"MSUBS_Q\", op4=\"32+(32*32)Up->32\")\n@ispec(\"32<[ c(4) d(4) 111011 n(2) b(4) a(4) {63} ]\", mnemonic=\"MSUBS_Q\", op4=\"64+(32*32)->64\")\n@ispec(\"32<[ c(4) d(4) 100001 n(2) b(4) a(4) {63} ]\", mnemonic=\"MSUBS_Q\", op4=\"32+(16L*32)Up->32\")\n@ispec(\"32<[ c(4) d(4) 111001 n(2) b(4) a(4) {63} ]\", mnemonic=\"MSUBS_Q\", op4=\"64+(16L*32)->64\")\n@ispec(\"32<[ c(4) d(4) 100000 n(2) b(4) a(4) {63} ]\", mnemonic=\"MSUBS_Q\", op4=\"32+(16U*32)Up->32\")\n@ispec(\"32<[ c(4) d(4) 111000 n(2) b(4) a(4) {63} ]\", mnemonic=\"MSUBS_Q\", op4=\"64+(16U*32)->64\")\n@ispec(\"32<[ c(4) d(4) 100101 n(2) b(4) a(4) {63} ]\", mnemonic=\"MSUBS_Q\", op4=\"32+(16L*16L)->32\")\n@ispec(\"32<[ c(4) d(4) 111101 n(2) b(4) a(4) {63} ]\", mnemonic=\"MSUBS_Q\", op4=\"64+(16L*16L)->64\")\n@ispec(\"32<[ c(4) d(4) 100100 n(2) b(4) a(4) {63} ]\", mnemonic=\"MSUBS_Q\", op4=\"32+(16U*16U)->32\")\n@ispec(\"32<[ c(4) d(4) 111100 n(2) b(4) a(4) {63} ]\", mnemonic=\"MSUBS_Q\", op4=\"64+(16U*16U)->64\")\ndef tricore_cond_eec(obj, c, d, n, b, a):\n    cond = env.E[d]\n    src1 = env.D[a]\n    src2 = env.D[b]\n    dst = env.E[c]\n    obj.operands = [dst, cond, src1, src2, env.cst(n,2)]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) d(4) 0000 ---- b(4) a(4) {2b} ]\", mnemonic=\"CADD\")\n@ispec(\"32<[ c(4) d(4) 0001 ---- b(4) a(4) {2b} ]\", mnemonic=\"CADDN\")\n@ispec(\"32<[ c(4) d(4) 0010 ---- b(4) a(4) {2b} ]\", mnemonic=\"CSUB\")\n@ispec(\"32<[ c(4) d(4) 0011 ---- b(4) a(4) {2b} ]\", mnemonic=\"CSUBN\")\n@ispec(\"32<[ c(4) d(4)      {0a} b(4) a(4) {03} ]\", mnemonic=\"MADD\", opt4=\"32+(32*32)->32\")\n@ispec(\"32<[ c(4) d(4)      {8a} b(4) a(4) {03} ]\", mnemonic=\"MADDS\", opt4=\"32+(32*32)->32\")\n@ispec(\"32<[ c(4) d(4)      {88} b(4) a(4) {03} ]\", mnemonic=\"MADDS_U\", opt4=\"32+(32*32)->32\")\n@ispec(\"32<[ c(4) d(4) 0100 ---- b(4) a(4) {2b} ]\", mnemonic=\"SEL\")\n@ispec(\"32<[ c(4) d(4) 0101 ---- b(4) a(4) {2b} ]\", mnemonic=\"SELN\")\ndef tricore_cond_ddd(obj, c, d, b, a):\n    cond = env.D[d]\n    src1 = env.D[a]\n    src2 = env.D[b]\n    dst = env.D[c]\n    obj.operands = [dst, cond, src1, src2]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) d(4) {6a}      b(4) a(4) {03} ]\", mnemonic=\"MADD\", opt4=\"64+(32*32)->64\")\n@ispec(\"32<[ c(4) d(4) {ea}      b(4) a(4) {03} ]\", mnemonic=\"MADDS\", opt4=\"64+(32*32)->64\")\n@ispec(\"32<[ c(4) d(4) {68}      b(4) a(4) {03} ]\", mnemonic=\"MADD_U\", opt4=\"64+(32*32)->64\")\n@ispec(\"32<[ c(4) d(4) {e8}      b(4) a(4) {03} ]\", mnemonic=\"MADDS_U\", opt4=\"64+(32*32)->64\")\ndef tricore_cond_ddd(obj, c, d, b, a):\n    cond = env.E[d]\n    src1 = env.D[a]\n    src2 = env.D[b]\n    dst = env.E[c]\n    obj.operands = [dst, cond, src1, src2]\n    obj.type = type_data_processing\n@ispec(\"32<[ c(4) {1c} ---- ---- a(4) {0f} ]\", mnemonic=\"CLO\")\n@ispec(\"32<[ c(4) {7d} ---- ---- a(4) {0f} ]\", mnemonic=\"CLO_H\")\n@ispec(\"32<[ c(4) {1d} ---- ---- a(4) {0f} ]\", mnemonic=\"CLS\")\n@ispec(\"32<[ c(4) {7e} ---- ---- a(4) {0f} ]\", mnemonic=\"CLS_H\")\n@ispec(\"32<[ c(4) {1b} ---- ---- a(4) {0f} ]\", mnemonic=\"CLZ\")\n@ispec(\"32<[ c(4) {7c} ---- ---- a(4) {0f} ]\", mnemonic=\"CLZ_H\")\n@ispec(\"32<[ c(4) {5e} ---- ---- a(4) {0b} ]\", mnemonic=\"SAT_B\")\n@ispec(\"32<[ c(4) {5f} ---- ---- a(4) {0b} ]\", mnemonic=\"SAT_BU\")\n@ispec(\"32<[ c(4) {7e} ---- ---- a(4) {0b} ]\", mnemonic=\"SAT_H\")\n@ispec(\"32<[ c(4) {7f} ---- ---- a(4) {0b} ]\", mnemonic=\"SAT_HU\")\ndef tricore_dd_arithmetic(obj, c, a):\n    src = env.D[a]\n    dst = env.D[c]\n    obj.operands = [dst, src]\n    obj.type = type_data_processing\n@ispec(\"16<[ 1010 ---- {00} ]\", mnemonic=\"DEBUG\")\n@ispec(\"16<[ 0000 ---- {00} ]\", mnemonic=\"NOP\")\ndef tricore_system(obj):\n    obj.operands = []\n    obj.type = type_system\n@ispec(\"16<[ 0111 ---- {00} ]\", mnemonic=\"FRET\")\n@ispec(\"16<[ 1001 ---- {00} ]\", mnemonic=\"RET\")\n@ispec(\"16<[ 1000 ---- {00} ]\", mnemonic=\"RFE\")\ndef tricore_ret(obj):\n    obj.operands = []\n    obj.type = type_control_flow\n@ispec(\"32<[ ---- 000100 ---------- ---- {0d} ]\", mnemonic=\"DEBUG\")\n@ispec(\"32<[ ---- 001101 ---------- ---- {0d} ]\", mnemonic=\"DISABLE\")\n@ispec(\"32<[ ---- 010010 ---------- ---- {0d} ]\", mnemonic=\"DSYNC\")\n@ispec(\"32<[ ---- 001100 ---------- ---- {0d} ]\", mnemonic=\"ENABLE\")\n@ispec(\"32<[ ---- 010011 ---------- ---- {0d} ]\", mnemonic=\"ISYNC\")\n@ispec(\"32<[ ---- 010101 ---------- ---- {0d} ]\", mnemonic=\"TRAPSV\")\n@ispec(\"32<[ ---- 010100 ---------- ---- {0d} ]\", mnemonic=\"TRAPV\")\n@ispec(\"32<[ ---- 000000 ---------- ---- {0d} ]\", mnemonic=\"NOP\")\n@ispec(\"32<[ ---- 001001 ---------- ---- {0d} ]\", mnemonic=\"RSLCX\")\n@ispec(\"32<[ ---- 000000 ---------- ---- {2f} ]\", mnemonic=\"RSTV\")\n@ispec(\"32<[ ---- 001000 ---------- ---- {0d} ]\", mnemonic=\"SVLCX\")\n@ispec(\"32<[ ---- 010110 ---------- ---- {0d} ]\", mnemonic=\"WAIT\")\ndef tricore_system(obj):\n    obj.operands = []\n    obj.type = type_system\n@ispec(\"32<[ ---- 000011 ---------- ---- {0d} ]\", mnemonic=\"FRET\")\n@ispec(\"32<[ ---- 000110 ---------- ---- {0d} ]\", mnemonic=\"RET\")\n@ispec(\"32<[ ---- 000111 ---------- ---- {0d} ]\", mnemonic=\"RFE\")\n@ispec(\"32<[ ---- 000101 ---------- ---- {0d} ]\", mnemonic=\"RFM\")\ndef tricore_ret(obj):\n    obj.operands = []\n    obj.type = type_control_flow\n@ispec(\"32<[ ---- 001111 ---------- a(4) {0d} ]\", mnemonic=\"DISABLE\")\n@ispec(\"32<[ ---- 001110 ---------- a(4) {0d} ]\", mnemonic=\"RESTORE\")\ndef tricore_system(obj, a):\n    obj.operands = [env.D[a]]\n    obj.type = type_system\n@ispec(\"32<[ c(4) d(4) 1101 -- 00 b(4) ---- {6b} ]\", mnemonic=\"DVADJ\")\n@ispec(\"32<[ c(4) d(4) 1111 -- 00 b(4) ---- {6b} ]\", mnemonic=\"DVSTEP\")\n@ispec(\"32<[ c(4) d(4) 1110 -- 00 b(4) ---- {6b} ]\", mnemonic=\"DVSTEP_U\")\n@ispec(\"32<[ c(4) d(4) 1010 -- 00 b(4) ---- {6b} ]\", mnemonic=\"IXMAX\")\n@ispec(\"32<[ c(4) d(4) 1011 -- 00 b(4) ---- {6b} ]\", mnemonic=\"IXMAX_U\")\n@ispec(\"32<[ c(4) d(4) 1000 -- 00 b(4) ---- {6b} ]\", mnemonic=\"IXMIN\")\n@ispec(\"32<[ c(4) d(4) 1001 -- 00 b(4) ---- {6b} ]\", mnemonic=\"IXMIN_U\")\ndef tricore_eee(obj, c, d, b):\n    if d%2 or b%2 or c%2:\n        raise InstructionError(obj)\n    src1 = env.E[d]\n    src2 = env.E[b]\n    dst = env.E[c]\n    obj.operands = [dst, src1, src2]\n    obj.type = type_data_processing\n@ispec(\"16<[ ~const4(4) disp(4) {1e} ]\", mnemonic=\"JEQ\", _off=0)\n@ispec(\"16<[ ~const4(4) disp(4) {9e} ]\", mnemonic=\"JEQ\", _off=16)\n@ispec(\"16<[ ~const4(4) disp(4) {5e} ]\", mnemonic=\"JNE\", _off=0)\n@ispec(\"16<[ ~const4(4) disp(4) {de} ]\", mnemonic=\"JNE\", _off=16)\ndef tricore_jcc(obj, const4, disp, _off):\n    dst = env.D[15]\n    src1 = env.cst(const4.int(-1),32)\n    src2 = env.cst(disp,32)+_off\n    obj.operands = [dst, src1, src2]\n    obj.type = type_control_flow\n@ispec(\"16<[ b(4) disp(4) {3e} ]\", mnemonic=\"JEQ\", _off=0)\n@ispec(\"16<[ b(4) disp(4) {be} ]\", mnemonic=\"JEQ\", _off=16)\n@ispec(\"16<[ b(4) disp(4) {7e} ]\", mnemonic=\"JNE\", _off=0)\n@ispec(\"16<[ b(4) disp(4) {fe} ]\", mnemonic=\"JNE\", _off=16)\ndef tricore_jcc(obj, b, disp, _off):\n    dst = env.D[15]\n    src1 = env.D[b]\n    src2 = env.cst(disp,32)+_off\n    obj.operands = [dst, src1, src2]\n    obj.type = type_control_flow\n@ispec(\"16<[ b(4) disp(4) {ce} ]\", mnemonic=\"JGEZ\")\n@ispec(\"16<[ b(4) disp(4) {4e} ]\", mnemonic=\"JGTZ\")\n@ispec(\"16<[ b(4) disp(4) {8e} ]\", mnemonic=\"JLEZ\")\n@ispec(\"16<[ b(4) disp(4) {0e} ]\", mnemonic=\"JLTZ\")\n@ispec(\"16<[ b(4) disp(4) {f6} ]\", mnemonic=\"JNZ\")\n@ispec(\"16<[ b(4) disp(4) {76} ]\", mnemonic=\"JZ\")\ndef tricore_jcc(obj, b, disp):\n    src1 = env.D[b]\n    src2 = env.cst(disp,32)\n    obj.operands = [src1, src2]\n    obj.type = type_control_flow\n@ispec(\"32<[ 0 ~disp(15) const(4) a(4) {df} ]\", mnemonic=\"JEQ\")\n@ispec(\"32<[ 1 ~disp(15) const(4) a(4) {df} ]\", mnemonic=\"JNE\")\n@ispec(\"32<[ 0 ~disp(15) const(4) a(4) {ff} ]\", mnemonic=\"JGE\")\n@ispec(\"32<[ 1 ~disp(15) const(4) a(4) {ff} ]\", mnemonic=\"JGE_U\")\n@ispec(\"32<[ 0 ~disp(15) const(4) a(4) {bf} ]\", mnemonic=\"JLT\")\n@ispec(\"32<[ 1 ~disp(15) const(4) a(4) {bf} ]\", mnemonic=\"JLT_U\")\n@ispec(\"32<[ 1 ~disp(15) const(4) a(4) {9f} ]\", mnemonic=\"JNED\")\n@ispec(\"32<[ 0 ~disp(15) const(4) a(4) {9f} ]\", mnemonic=\"JNEI\")\ndef tricore_jcc(obj, disp, const, a):\n    src1 = env.D[a]\n    src2 = env.cst(const,4)\n    obj.operands = [src1, src2, env.cst(disp.int(-1),32)]\n    obj.type = type_control_flow\n@ispec(\"32<[ 0 ~disp(15) b(4) a(4) {5f} ]\", mnemonic=\"JEQ\")\n@ispec(\"32<[ 1 ~disp(15) b(4) a(4) {5f} ]\", mnemonic=\"JNE\")\n@ispec(\"32<[ 0 ~disp(15) b(4) a(4) {7f} ]\", mnemonic=\"JGE\")\n@ispec(\"32<[ 1 ~disp(15) b(4) a(4) {7f} ]\", mnemonic=\"JGE_U\")\n@ispec(\"32<[ 0 ~disp(15) b(4) a(4) {3f} ]\", mnemonic=\"JLT\")\n@ispec(\"32<[ 1 ~disp(15) b(4) a(4) {3f} ]\", mnemonic=\"JLT_U\")\n@ispec(\"32<[ 1 ~disp(15) b(4) a(4) {1f} ]\", mnemonic=\"JNED\")\n@ispec(\"32<[ 0 ~disp(15) b(4) a(4) {1f} ]\", mnemonic=\"JNEI\")\ndef tricore_jcc(obj, disp, b, a):\n    src1 = env.D[a]\n    src2 = env.D[b]\n    obj.operands = [src1, src2, env.cst(disp.int(-1),32)]\n    obj.type = type_control_flow\n@ispec(\"32<[ 0 ~disp(15) b(4) a(4) {7d} ]\", mnemonic=\"JEQ_A\")\n@ispec(\"32<[ 1 ~disp(15) b(4) a(4) {7d} ]\", mnemonic=\"JNE_A\")\ndef tricore_jcc(obj, disp, b, a):\n    src1 = env.A[a]\n    src2 = env.A[b]\n    obj.operands = [src1, src2, env.cst(disp.int(-1),32)]\n    obj.type = type_control_flow\n@ispec(\"32<[ 1 ~disp(15) ---- a(4) {bd} ]\", mnemonic=\"JNZ_A\")\n@ispec(\"32<[ 0 ~disp(15) ---- a(4) {bd} ]\", mnemonic=\"JZ_A\")\ndef tricore_jcc(obj, disp, a):\n    src1 = env.A[a]\n    src2 = env.A[b]\n    obj.operands = [src1, src2, env.cst(disp.int(-1),32)]\n    obj.type = type_control_flow\n@ispec(\"32<[ 0 ~disp(15) b(4) ---- {fd} ]\", mnemonic=\"LOOP\")\n@ispec(\"32<[ 1 ~disp(15) b(4) ---- {fd} ]\", mnemonic=\"LOOPU\")\ndef tricore_jcc(obj, disp, b):\n    src1 = env.A[b]\n    src2 =  env.cst(disp.int(-1)*2,32)\n    obj.operands = [src1, src2]\n    if obj.mnemonic==\"LOOPU\":\n        obj.operands = [src2]\n    obj.type = type_control_flow\n@ispec(\"16<[ b(4) disp(4) {7c} ]\", mnemonic=\"JNZ_A\")\n@ispec(\"16<[ b(4) disp(4) {bc} ]\", mnemonic=\"JZ_A\")\ndef tricore_jcc(obj, b, disp):\n    src1 = env.A[b]\n    src2 = env.cst(disp,32)\n    obj.operands = [src1, src2]\n    obj.type = type_control_flow\n@ispec(\"16<[ b(4) #disp(4) {fc} ]\", mnemonic=\"LOOP\")\ndef tricore_jcc(obj, b, disp):\n    src1 = env.A[b]\n    src2 = env.cst(int((\"1\"*27)+disp+\"0\",2),32)\n    obj.operands = [src1, src2]\n    obj.type = type_control_flow\n@ispec(\"16<[ 0000 a(4) {dc} ]\", mnemonic=\"JI\")\ndef tricore_ji(obj, a):\n    src = env.A[a]\n    obj.operands = [src]\n    obj.type = type_control_flow\n@ispec(\"16<[ 0000 a(4) {46} ]\", mnemonic=\"NOT\")\n@ispec(\"16<[ 0101 a(4) {32} ]\", mnemonic=\"RSUB\")\n@ispec(\"16<[ 0000 a(4) {32} ]\", mnemonic=\"SAT_B\")\n@ispec(\"16<[ 0001 a(4) {32} ]\", mnemonic=\"SAT_BU\")\n@ispec(\"16<[ 0010 a(4) {32} ]\", mnemonic=\"SAT_H\")\n@ispec(\"16<[ 0011 a(4) {32} ]\", mnemonic=\"SAT_HU\")\ndef tricore_a(obj, a):\n    src = env.D[a]\n    obj.operands = [src]\n    obj.type = type_data_processing\n@ispec(\"16<[ n(4) disp(4) {ae} ]\", mnemonic=\"JNZ_T\")\n@ispec(\"16<[ n(4) disp(4) {2e} ]\", mnemonic=\"JZ_T\")\ndef tricore_ji(obj, n, disp):\n    obj.operands = [env.D[15][n:n+1], env.cst(disp,32)]\n    obj.type = type_control_flow\n@ispec(\"32<[ 1 ~disp(15) n(4) a(4) h 1101111 ]\", mnemonic=\"JNZ_T\")\n@ispec(\"32<[ 0 ~disp(15) n(4) a(4) h 1101111 ]\", mnemonic=\"JZ_T\")\ndef tricore_jcc(obj, disp, n, a, h):\n    i = n+(h<<4)\n    src = env.D[a][i:i+1]\n    obj.operands = [src, env.cst(disp.int(-1),32)]\n    obj.type = type_control_flow\n@ispec(\"32<[ ~off2(4) 10 ~off3(4) ~off1(6) ~off4(4) a(4) {85} ]\", mnemonic=\"LD_A\", mode=\"Absolute\")\n@ispec(\"32<[ ~off2(4) 00 ~off3(4) ~off1(6) ~off4(4) a(4) {05} ]\", mnemonic=\"LD_B\", mode=\"Absolute\")\n@ispec(\"32<[ ~off2(4) 01 ~off3(4) ~off1(6) ~off4(4) a(4) {05} ]\", mnemonic=\"LD_BU\", mode=\"Absolute\")\n@ispec(\"32<[ ~off2(4) 01 ~off3(4) ~off1(6) ~off4(4) a(4) {85} ]\", mnemonic=\"LD_D\", mode=\"Absolute\")\n@ispec(\"32<[ ~off2(4) 11 ~off3(4) ~off1(6) ~off4(4) a(4) {85} ]\", mnemonic=\"LD_DA\", mode=\"Absolute\")\n@ispec(\"32<[ ~off2(4) 10 ~off3(4) ~off1(6) ~off4(4) a(4) {05} ]\", mnemonic=\"LD_H\", mode=\"Absolute\")\n@ispec(\"32<[ ~off2(4) 11 ~off3(4) ~off1(6) ~off4(4) a(4) {05} ]\", mnemonic=\"LD_HU\", mode=\"Absolute\")\n@ispec(\"32<[ ~off2(4) 00 ~off3(4) ~off1(6) ~off4(4) a(4) {45} ]\", mnemonic=\"LD_Q\", mode=\"Absolute\")\n@ispec(\"32<[ ~off2(4) 00 ~off3(4) ~off1(6) ~off4(4) a(4) {85} ]\", mnemonic=\"LD_W\", mode=\"Absolute\")\n@ispec(\"32<[ ~off2(4) 00 ~off3(4) ~off1(6) ~off4(4) a(4) {c5} ]\", mnemonic=\"LEA\", mode=\"Absolute\")\ndef tricore_ld(obj, off2, off3, off1, off4, a):\n    dst = env.D[a]\n    if obj.mnemonic in (\"LD_A\", \"LEA\")  : dst = env.A[a]\n    if obj.mnemonic in (\"LD_D\",\"LDMST\") : dst = env.E[a]\n    if obj.mnemonic==\"LD_DA\": dst = env.P[a]\n    src = off1//off2//off3\n    obj.operands = [dst, composer([env.cst(src.int(),28),env.cst(off4,4)])]\n    obj.type = type_data_processing\n@ispec(\"32<[ ~off2(4) 01 ~off3(4) ~off1(6) ~off4(4) a(4) {c5} ]\", mnemonic=\"LHA\", mode=\"Absolute\")\ndef tricore_ld(obj, off2, off3, off1, off4, a):\n    dst = env.A[a]\n    src = off1//off2//off3//off4\n    obj.operands = [dst, composer([env.cst(0,14),env.cst(src.int(),18)])]\n    obj.type = type_data_processing\n@ispec(\"32<[ ~off2(4) 10 ~off3(4) ~off1(6) ~off4(4) a(4) {a5} ]\", mnemonic=\"ST_A\", mode=\"Absolute\")\n@ispec(\"32<[ ~off2(4) 00 ~off3(4) ~off1(6) ~off4(4) a(4) {25} ]\", mnemonic=\"ST_B\", mode=\"Absolute\")\n@ispec(\"32<[ ~off2(4) 01 ~off3(4) ~off1(6) ~off4(4) a(4) {a5} ]\", mnemonic=\"ST_D\", mode=\"Absolute\")\n@ispec(\"32<[ ~off2(4) 11 ~off3(4) ~off1(6) ~off4(4) a(4) {a5} ]\", mnemonic=\"ST_DA\", mode=\"Absolute\")\n@ispec(\"32<[ ~off2(4) 10 ~off3(4) ~off1(6) ~off4(4) a(4) {25} ]\", mnemonic=\"ST_H\", mode=\"Absolute\")\n@ispec(\"32<[ ~off2(4) 00 ~off3(4) ~off1(6) ~off4(4) a(4) {65} ]\", mnemonic=\"ST_Q\", mode=\"Absolute\")\n@ispec(\"32<[ ~off2(4) 00 ~off3(4) ~off1(6) ~off4(4) a(4) {a5} ]\", mnemonic=\"ST_W\", mode=\"Absolute\")\n@ispec(\"32<[ ~off2(4) 00 ~off3(4) ~off1(6) ~off4(4) a(4) {e5} ]\", mnemonic=\"SWAP_W\", mode=\"Absolute\")\n@ispec(\"32<[ ~off2(4) 01 ~off3(4) ~off1(6) ~off4(4) a(4) {e5} ]\", mnemonic=\"LDMST\", mode=\"Absolute\")\ndef tricore_st(obj, off2, off3, off1, off4, a):\n    src = env.D[a]\n    if obj.mnemonic in (\"ST_A\",)  : src = env.A[a]\n    if obj.mnemonic in (\"ST_D\",\"LDMST\") : src = env.E[a]\n    if obj.mnemonic==\"ST_DA\": src = env.P[a]\n    addr = off1//off2//off3\n    obj.operands = [composer([env.cst(addr.int(),28),env.cst(off4,4)]), src]\n    obj.type = type_data_processing\n@ispec(\"32<[ ~off2(4) 00 ~off3(4) ~off1(6) ~off4(4) b bpos(3) {d5} ]\", mnemonic=\"ST_T\", mode=\"Absolute\")\ndef tricore_st(obj, off2, off3, off1, off4, b, bpos):\n    obj.operands = [composer([env.cst(src.int(),28),env.cst(off4,4)]), env.cst(bpos,3), env.cst(b,1)]\n    obj.type = type_data_processing\n@ispec(\"32<[ ~off2(4) 00 ~off3(4) ~off1(6) ~off4(4) ---- {15} ]\", mnemonic=\"STLCX\", mode=\"Absolute\")\ndef tricore_st(obj, off2, off3, off1, off4):\n    obj.operands = [composer([env.cst(src.int(),28),env.cst(off4,4)])]\n    obj.type = type_data_processing\n@ispec(\"32<[ ~off2(4) 10 ~off3(4) ~off1(6) ~off4(4) a(4) {15} ]\", mnemonic=\"LDLCX\", mode=\"Absolute\")\n@ispec(\"32<[ ~off2(4) 11 ~off3(4) ~off1(6) ~off4(4) a(4) {15} ]\", mnemonic=\"LDUCX\", mode=\"Absolute\")\ndef tricore_ld(obj, off2, off3, off1, off4, a):\n    src = off1//off2//off3\n    obj.operands = [composer([env.cst(src.int(),28),env.cst(off4,4)])]\n    obj.type = type_data_processing\n@ispec(\"32<[ ~off2(4) 10 0110 ~off1(6) b(4) a(4) {09} ]\", mnemonic=\"LD_A\", mode=\"Short-offset\")\n@ispec(\"32<[ ~off2(4) 00 0110 ~off1(6) b(4) a(4) {29} ]\", mnemonic=\"LD_A\", mode=\"Bit-reverse\")\n@ispec(\"32<[ ~off2(4) 01 0110 ~off1(6) b(4) a(4) {29} ]\", mnemonic=\"LD_A\", mode=\"Circular\")\n@ispec(\"32<[ ~off2(4) 00 0110 ~off1(6) b(4) a(4) {09} ]\", mnemonic=\"LD_A\", mode=\"Post-increment\")\n@ispec(\"32<[ ~off2(4) 01 0110 ~off1(6) b(4) a(4) {09} ]\", mnemonic=\"LD_A\", mode=\"Pre-increment\")\n@ispec(\"32<[ ~off2(4) 10 0000 ~off1(6) b(4) a(4) {09} ]\", mnemonic=\"LD_B\", mode=\"Short-offset\")\n@ispec(\"32<[ ~off2(4) 00 0000 ~off1(6) b(4) a(4) {29} ]\", mnemonic=\"LD_B\", mode=\"Bit-reverse\")\n@ispec(\"32<[ ~off2(4) 01 0000 ~off1(6) b(4) a(4) {29} ]\", mnemonic=\"LD_B\", mode=\"Circular\")\n@ispec(\"32<[ ~off2(4) 00 0000 ~off1(6) b(4) a(4) {09} ]\", mnemonic=\"LD_B\", mode=\"Post-increment\")\n@ispec(\"32<[ ~off2(4) 01 0000 ~off1(6) b(4) a(4) {09} ]\", mnemonic=\"LD_B\", mode=\"Pre-increment\")\n@ispec(\"32<[ ~off2(4) 10 0001 ~off1(6) b(4) a(4) {09} ]\", mnemonic=\"LD_BU\", mode=\"Short-offset\")\n@ispec(\"32<[ ~off2(4) 00 0001 ~off1(6) b(4) a(4) {29} ]\", mnemonic=\"LD_BU\", mode=\"Bit-reverse\")\n@ispec(\"32<[ ~off2(4) 01 0001 ~off1(6) b(4) a(4) {29} ]\", mnemonic=\"LD_BU\", mode=\"Circular\")\n@ispec(\"32<[ ~off2(4) 00 0001 ~off1(6) b(4) a(4) {09} ]\", mnemonic=\"LD_BU\", mode=\"Post-increment\")\n@ispec(\"32<[ ~off2(4) 01 0001 ~off1(6) b(4) a(4) {09} ]\", mnemonic=\"LD_BU\", mode=\"Pre-increment\")\n@ispec(\"32<[ ~off2(4) 10 0101 ~off1(6) b(4) a(4) {09} ]\", mnemonic=\"LD_D\", mode=\"Short-offset\")\n@ispec(\"32<[ ~off2(4) 00 0101 ~off1(6) b(4) a(4) {29} ]\", mnemonic=\"LD_D\", mode=\"Bit-reverse\")\n@ispec(\"32<[ ~off2(4) 01 0101 ~off1(6) b(4) a(4) {29} ]\", mnemonic=\"LD_D\", mode=\"Circular\")\n@ispec(\"32<[ ~off2(4) 00 0101 ~off1(6) b(4) a(4) {09} ]\", mnemonic=\"LD_D\", mode=\"Post-increment\")\n@ispec(\"32<[ ~off2(4) 01 0101 ~off1(6) b(4) a(4) {09} ]\", mnemonic=\"LD_D\", mode=\"Pre-increment\")\n@ispec(\"32<[ ~off2(4) 10 0111 ~off1(6) b(4) a(4) {09} ]\", mnemonic=\"LD_DA\", mode=\"Short-offset\")\n@ispec(\"32<[ ~off2(4) 00 0111 ~off1(6) b(4) a(4) {29} ]\", mnemonic=\"LD_DA\", mode=\"Bit-reverse\")\n@ispec(\"32<[ ~off2(4) 01 0111 ~off1(6) b(4) a(4) {29} ]\", mnemonic=\"LD_DA\", mode=\"Circular\")\n@ispec(\"32<[ ~off2(4) 00 0111 ~off1(6) b(4) a(4) {09} ]\", mnemonic=\"LD_DA\", mode=\"Post-increment\")\n@ispec(\"32<[ ~off2(4) 01 0111 ~off1(6) b(4) a(4) {09} ]\", mnemonic=\"LD_DA\", mode=\"Pre-increment\")\n@ispec(\"32<[ ~off2(4) 10 0010 ~off1(6) b(4) a(4) {09} ]\", mnemonic=\"LD_H\", mode=\"Short-offset\")\n@ispec(\"32<[ ~off2(4) 00 0010 ~off1(6) b(4) a(4) {29} ]\", mnemonic=\"LD_H\", mode=\"Bit-reverse\")\n@ispec(\"32<[ ~off2(4) 01 0010 ~off1(6) b(4) a(4) {29} ]\", mnemonic=\"LD_H\", mode=\"Circular\")\n@ispec(\"32<[ ~off2(4) 00 0010 ~off1(6) b(4) a(4) {09} ]\", mnemonic=\"LD_H\", mode=\"Post-increment\")\n@ispec(\"32<[ ~off2(4) 01 0010 ~off1(6) b(4) a(4) {09} ]\", mnemonic=\"LD_H\", mode=\"Pre-increment\")\n@ispec(\"32<[ ~off2(4) 10 0011 ~off1(6) b(4) a(4) {09} ]\", mnemonic=\"LD_HU\", mode=\"Short-offset\")\n@ispec(\"32<[ ~off2(4) 00 0011 ~off1(6) b(4) a(4) {29} ]\", mnemonic=\"LD_HU\", mode=\"Bit-reverse\")\n@ispec(\"32<[ ~off2(4) 01 0011 ~off1(6) b(4) a(4) {29} ]\", mnemonic=\"LD_HU\", mode=\"Circular\")\n@ispec(\"32<[ ~off2(4) 00 0011 ~off1(6) b(4) a(4) {09} ]\", mnemonic=\"LD_HU\", mode=\"Post-increment\")\n@ispec(\"32<[ ~off2(4) 01 0011 ~off1(6) b(4) a(4) {09} ]\", mnemonic=\"LD_HU\", mode=\"Pre-increment\")\n@ispec(\"32<[ ~off2(4) 10 1000 ~off1(6) b(4) a(4) {09} ]\", mnemonic=\"LD_Q\", mode=\"Short-offset\")\n@ispec(\"32<[ ~off2(4) 00 1000 ~off1(6) b(4) a(4) {29} ]\", mnemonic=\"LD_Q\", mode=\"Bit-reverse\")\n@ispec(\"32<[ ~off2(4) 01 1000 ~off1(6) b(4) a(4) {29} ]\", mnemonic=\"LD_Q\", mode=\"Circular\")\n@ispec(\"32<[ ~off2(4) 00 1000 ~off1(6) b(4) a(4) {09} ]\", mnemonic=\"LD_Q\", mode=\"Post-increment\")\n@ispec(\"32<[ ~off2(4) 01 1000 ~off1(6) b(4) a(4) {09} ]\", mnemonic=\"LD_Q\", mode=\"Pre-increment\")\n@ispec(\"32<[ ~off2(4) 10 0100 ~off1(6) b(4) a(4) {09} ]\", mnemonic=\"LD_W\", mode=\"Short-offset\")\n@ispec(\"32<[ ~off2(4) 00 0100 ~off1(6) b(4) a(4) {29} ]\", mnemonic=\"LD_W\", mode=\"Bit-reverse\")\n@ispec(\"32<[ ~off2(4) 01 0100 ~off1(6) b(4) a(4) {29} ]\", mnemonic=\"LD_W\", mode=\"Circular\")\n@ispec(\"32<[ ~off2(4) 00 0100 ~off1(6) b(4) a(4) {09} ]\", mnemonic=\"LD_W\", mode=\"Post-increment\")\n@ispec(\"32<[ ~off2(4) 01 0100 ~off1(6) b(4) a(4) {09} ]\", mnemonic=\"LD_W\", mode=\"Pre-increment\")\n@ispec(\"32<[ ~off2(4) 10 1000 ~off1(6) b(4) a(4) {49} ]\", mnemonic=\"LEA\", mode=\"Short-offset\")\ndef tricore_ld(obj, off2, off1, b, a):\n    dst = env.D[a]\n    if   obj.mnemonic==\"LD_A\"  : dst = env.A[a]\n    elif obj.mnemonic==\"LEA\"   : dst = env.A[a]\n    elif obj.mnemonic==\"LD_D\"  : dst = env.E[a]\n    elif obj.mnemonic==\"LDMST\" : dst = env.E[a]\n    elif obj.mnemonic==\"LD_DA\" : dst = env.P[a]\n    obj.b = b\n    src1 = env.A[b]\n    off10 = off1//off2\n    src2 = env.cst(off10.int(-1),10)\n    obj.operands = [dst, src1, src2]\n    if obj.mode == \"Bit-Reverse\":\n        obj.operands.pop()\n    obj.type = type_data_processing\n@ispec(\"32<[ ~off2(4) 10 0110 ~off1(6) b(4) a(4) {89} ]\", mnemonic=\"ST_A\", mode=\"Short-offset\")\n@ispec(\"32<[ ~off2(4) 00 0110 ~off1(6) b(4) a(4) {a9} ]\", mnemonic=\"ST_A\", mode=\"Bit-reverse\")\n@ispec(\"32<[ ~off2(4) 01 0110 ~off1(6) b(4) a(4) {a9} ]\", mnemonic=\"ST_A\", mode=\"Circular\")\n@ispec(\"32<[ ~off2(4) 00 0110 ~off1(6) b(4) a(4) {89} ]\", mnemonic=\"ST_A\", mode=\"Post-increment\")\n@ispec(\"32<[ ~off2(4) 01 0110 ~off1(6) b(4) a(4) {89} ]\", mnemonic=\"ST_A\", mode=\"Pre-increment\")\n@ispec(\"32<[ ~off2(4) 10 0000 ~off1(6) b(4) a(4) {89} ]\", mnemonic=\"ST_B\", mode=\"Short-offset\")\n@ispec(\"32<[ ~off2(4) 00 0000 ~off1(6) b(4) a(4) {a9} ]\", mnemonic=\"ST_B\", mode=\"Bit-reverse\")\n@ispec(\"32<[ ~off2(4) 01 0000 ~off1(6) b(4) a(4) {a9} ]\", mnemonic=\"ST_B\", mode=\"Circular\")\n@ispec(\"32<[ ~off2(4) 00 0000 ~off1(6) b(4) a(4) {89} ]\", mnemonic=\"ST_B\", mode=\"Post-increment\")\n@ispec(\"32<[ ~off2(4) 01 0000 ~off1(6) b(4) a(4) {89} ]\", mnemonic=\"ST_B\", mode=\"Pre-increment\")\n@ispec(\"32<[ ~off2(4) 10 0101 ~off1(6) b(4) a(4) {89} ]\", mnemonic=\"ST_D\", mode=\"Short-offset\")\n@ispec(\"32<[ ~off2(4) 00 0101 ~off1(6) b(4) a(4) {a9} ]\", mnemonic=\"ST_D\", mode=\"Bit-reverse\")\n@ispec(\"32<[ ~off2(4) 01 0101 ~off1(6) b(4) a(4) {a9} ]\", mnemonic=\"ST_D\", mode=\"Circular\")\n@ispec(\"32<[ ~off2(4) 00 0101 ~off1(6) b(4) a(4) {89} ]\", mnemonic=\"ST_D\", mode=\"Post-increment\")\n@ispec(\"32<[ ~off2(4) 01 0101 ~off1(6) b(4) a(4) {89} ]\", mnemonic=\"ST_D\", mode=\"Pre-increment\")\n@ispec(\"32<[ ~off2(4) 10 0111 ~off1(6) b(4) a(4) {89} ]\", mnemonic=\"ST_DA\", mode=\"Short-offset\")\n@ispec(\"32<[ ~off2(4) 00 0111 ~off1(6) b(4) a(4) {a9} ]\", mnemonic=\"ST_DA\", mode=\"Bit-reverse\")\n@ispec(\"32<[ ~off2(4) 01 0111 ~off1(6) b(4) a(4) {a9} ]\", mnemonic=\"ST_DA\", mode=\"Circular\")\n@ispec(\"32<[ ~off2(4) 00 0111 ~off1(6) b(4) a(4) {89} ]\", mnemonic=\"ST_DA\", mode=\"Post-increment\")\n@ispec(\"32<[ ~off2(4) 01 0111 ~off1(6) b(4) a(4) {89} ]\", mnemonic=\"ST_DA\", mode=\"Pre-increment\")\n@ispec(\"32<[ ~off2(4) 10 0010 ~off1(6) b(4) a(4) {89} ]\", mnemonic=\"ST_H\", mode=\"Short-offset\")\n@ispec(\"32<[ ~off2(4) 00 0010 ~off1(6) b(4) a(4) {a9} ]\", mnemonic=\"ST_H\", mode=\"Bit-reverse\")\n@ispec(\"32<[ ~off2(4) 01 0010 ~off1(6) b(4) a(4) {a9} ]\", mnemonic=\"ST_H\", mode=\"Circular\")\n@ispec(\"32<[ ~off2(4) 00 0010 ~off1(6) b(4) a(4) {89} ]\", mnemonic=\"ST_H\", mode=\"Post-increment\")\n@ispec(\"32<[ ~off2(4) 01 0010 ~off1(6) b(4) a(4) {89} ]\", mnemonic=\"ST_H\", mode=\"Pre-increment\")\n@ispec(\"32<[ ~off2(4) 10 1000 ~off1(6) b(4) a(4) {89} ]\", mnemonic=\"ST_Q\", mode=\"Short-offset\")\n@ispec(\"32<[ ~off2(4) 00 1000 ~off1(6) b(4) a(4) {a9} ]\", mnemonic=\"ST_Q\", mode=\"Bit-reverse\")\n@ispec(\"32<[ ~off2(4) 01 1000 ~off1(6) b(4) a(4) {a9} ]\", mnemonic=\"ST_Q\", mode=\"Circular\")\n@ispec(\"32<[ ~off2(4) 00 1000 ~off1(6) b(4) a(4) {89} ]\", mnemonic=\"ST_Q\", mode=\"Post-increment\")\n@ispec(\"32<[ ~off2(4) 01 1000 ~off1(6) b(4) a(4) {89} ]\", mnemonic=\"ST_Q\", mode=\"Pre-increment\")\n@ispec(\"32<[ ~off2(4) 10 0100 ~off1(6) b(4) a(4) {89} ]\", mnemonic=\"ST_W\", mode=\"Short-offset\")\n@ispec(\"32<[ ~off2(4) 00 0100 ~off1(6) b(4) a(4) {a9} ]\", mnemonic=\"ST_W\", mode=\"Bit-reverse\")\n@ispec(\"32<[ ~off2(4) 01 0100 ~off1(6) b(4) a(4) {a9} ]\", mnemonic=\"ST_W\", mode=\"Circular\")\n@ispec(\"32<[ ~off2(4) 00 0100 ~off1(6) b(4) a(4) {89} ]\", mnemonic=\"ST_W\", mode=\"Post-increment\")\n@ispec(\"32<[ ~off2(4) 01 0100 ~off1(6) b(4) a(4) {89} ]\", mnemonic=\"ST_W\", mode=\"Pre-increment\")\n@ispec(\"32<[ ~off2(4) 10 0001 ~off1(6) b(4) a(4) {49} ]\", mnemonic=\"LDMST\", mode=\"Short-offset\")\n@ispec(\"32<[ ~off2(4) 00 0001 ~off1(6) b(4) a(4) {69} ]\", mnemonic=\"LDMST\", mode=\"Bit-reverse\")\n@ispec(\"32<[ ~off2(4) 01 0001 ~off1(6) b(4) a(4) {69} ]\", mnemonic=\"LDMST\", mode=\"Circular\")\n@ispec(\"32<[ ~off2(4) 00 0001 ~off1(6) b(4) a(4) {49} ]\", mnemonic=\"LDMST\", mode=\"Post-increment\")\n@ispec(\"32<[ ~off2(4) 01 0001 ~off1(6) b(4) a(4) {49} ]\", mnemonic=\"LDMST\", mode=\"Pre-increment\")\ndef tricore_st(obj, off2, off1, b, a):\n    dst = env.D[a]\n    if   obj.mnemonic==\"ST_A\"  : dst = env.A[a]\n    elif obj.mnemonic==\"ST_D\"  : dst = env.E[a]\n    elif obj.mnemonic==\"ST_DA\" : dst = env.P[a]\n    elif obj.mnemonic==\"LDMST\" : dst = env.E[a]\n    obj.b = b\n    src1 = env.A[b]\n    off10 = off1//off2\n    src2 = env.cst(off10.int(-1),10)\n    obj.operands = [src1, src2, dst]\n    if obj.mode == \"Bit-Reverse\":\n        obj.operands.pop()\n    obj.type = type_data_processing\n@ispec(\"32<[ ~off2(4) 10 1000 ~off1(6) b(4) a(4) {49} ]\", mnemonic=\"SWAP_W\", mode=\"Short-offset\")\n@ispec(\"32<[ ~off2(4) 00 1000 ~off1(6) b(4) a(4) {69} ]\", mnemonic=\"SWAP_W\", mode=\"Bit-reverse\")\n@ispec(\"32<[ ~off2(4) 01 1000 ~off1(6) b(4) a(4) {69} ]\", mnemonic=\"SWAP_W\", mode=\"Circular\")\n@ispec(\"32<[ ~off2(4) 00 1000 ~off1(6) b(4) a(4) {49} ]\", mnemonic=\"SWAP_W\", mode=\"Post-increment\")\n@ispec(\"32<[ ~off2(4) 01 1000 ~off1(6) b(4) a(4) {49} ]\", mnemonic=\"SWAP_W\", mode=\"Pre-increment\")\ndef tricore_ld(obj, off2, off1, b, a):\n    dst = env.D[a]\n    src1 = env.P[b]\n    off10 = off1//off2\n    src2 = env.cst(off10.int(-1),10)\n    obj.operands = [src1, src2, dst]\n    obj.type = type_data_processing\n@ispec(\"32<[ ~off2(4) 10 0100 ~off1(6) b(4) ---- {49} ]\", mnemonic=\"LDLCX\", mode=\"Short-offset\")\n@ispec(\"32<[ ~off2(4) 10 0101 ~off1(6) b(4) ---- {49} ]\", mnemonic=\"LDUCX\", mode=\"Short-offset\")\n@ispec(\"32<[ ~off2(4) 10 0110 ~off1(6) b(4) ---- {49} ]\", mnemonic=\"STLCX\", mode=\"Short-offset\")\n@ispec(\"32<[ ~off2(4) 10 0111 ~off1(6) b(4) ---- {49} ]\", mnemonic=\"STUCX\", mode=\"Short-offset\")\ndef tricore_ld(obj, off2, off1, b):\n    src1 = env.A[b]\n    off10 = off1//off2\n    src2 = env.cst(off10.int(-1),10)\n    obj.operands = [src1, src2]\n    obj.type = type_data_processing\n@ispec(\"32<[ ~off2(4) ~off3(6) ~off1(6) b(4) a(4) {99} ]\", mnemonic=\"LD_A\", mode=\"Long-offset\")\n@ispec(\"32<[ ~off2(4) ~off3(6) ~off1(6) b(4) a(4) {79} ]\", mnemonic=\"LD_B\", mode=\"Long-offset\")\n@ispec(\"32<[ ~off2(4) ~off3(6) ~off1(6) b(4) a(4) {39} ]\", mnemonic=\"LD_BU\", mode=\"Long-offset\")\n@ispec(\"32<[ ~off2(4) ~off3(6) ~off1(6) b(4) a(4) {09} ]\", mnemonic=\"LD_H\", mode=\"Long-offset\")\n@ispec(\"32<[ ~off2(4) ~off3(6) ~off1(6) b(4) a(4) {b9} ]\", mnemonic=\"LD_HU\", mode=\"Long-offset\")\n@ispec(\"32<[ ~off2(4) ~off3(6) ~off1(6) b(4) a(4) {19} ]\", mnemonic=\"LD_W\", mode=\"Long-offset\")\n@ispec(\"32<[ ~off2(4) ~off3(6) ~off1(6) b(4) a(4) {d9} ]\", mnemonic=\"LEA\", mode=\"Long-offset\")\ndef tricore_ld(obj, off2, off3, off1, b, a):\n    dst = env.D[a]\n", "outputs": ["    if obj.mnemonic in (\"LD_A\", \"LEA\"): dst = env.A[a]"], "input_length": 27222, "output_length": 19, "length": 27241, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "4733cab403278ba799305434e56f6c2885e1da57f8afc5e18514c01dbd833923"}
{"input": "", "context": "# Copyright 2013 The Servo Project Developers. See the COPYRIGHT\n# file at the top-level directory of this distribution.\n#\n# Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n# http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n# <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n# option. This file may not be copied, modified, or distributed\n# except according to those terms.\nfrom __future__ import print_function, unicode_literals\nimport os\nimport os.path as path\nimport subprocess\nimport sys\nfrom time import time\nfrom mach.decorators import (\n    CommandArgument,\n    CommandProvider,\n    Command,\n)\nfrom servo.command_base import CommandBase, cd\ndef is_headless_build():\n    return int(os.getenv('SERVO_HEADLESS', 0)) == 1\ndef notify_linux(title, text):\n    try:\n        import dbus\n        bus = dbus.SessionBus()\n        notify_obj = bus.get_object(\"org.freedesktop.Notifications\", \"/org/freedesktop/Notifications\")\n        method = notify_obj.get_dbus_method(\"Notify\", \"org.freedesktop.Notifications\")\n        method(title, 0, \"\", text, \"\", [], [], -1)\n    except:\n        raise Exception(\"Please make sure that the Python dbus module is installed!\")\ndef notify_win(title, text):\n    from ctypes import Structure, windll, POINTER, sizeof\n    from ctypes.wintypes import DWORD, HANDLE, WINFUNCTYPE, BOOL, UINT\n    class FLASHWINDOW(Structure):\n        _fields_ = [(\"cbSize\", UINT),\n                    (\"hwnd\", HANDLE),\n                    (\"dwFlags\", DWORD),\n                    (\"uCount\", UINT),\n                    (\"dwTimeout\", DWORD)]\n    FlashWindowExProto = WINFUNCTYPE(BOOL, POINTER(FLASHWINDOW))\n    FlashWindowEx = FlashWindowExProto((\"FlashWindowEx\", windll.user32))\n    FLASHW_CAPTION = 0x01\n    FLASHW_TRAY = 0x02\n    FLASHW_TIMERNOFG = 0x0C\n    params = FLASHWINDOW(sizeof(FLASHWINDOW),\n                         windll.kernel32.GetConsoleWindow(),\n                         FLASHW_CAPTION | FLASHW_TRAY | FLASHW_TIMERNOFG, 3, 0)\n    FlashWindowEx(params)\ndef notify_darwin(title, text):\n    try:\n        import Foundation\n        bundleDict = Foundation.NSBundle.mainBundle().infoDictionary()\n        bundleIdentifier = 'CFBundleIdentifier'\n        if bundleIdentifier not in bundleDict:\n            bundleDict[bundleIdentifier] = 'mach'\n        note = Foundation.NSUserNotification.alloc().init()\n        note.setTitle_(title)\n        note.setInformativeText_(text)\n        now = Foundation.NSDate.dateWithTimeInterval_sinceDate_(0, Foundation.NSDate.date())\n        note.setDeliveryDate_(now)\n        centre = Foundation.NSUserNotificationCenter.defaultUserNotificationCenter()\n        centre.scheduleNotification_(note)\n    except ImportError:\n        raise Exception(\"Please make sure that the Python pyobjc module is installed!\")\ndef notify_build_done(elapsed):\n    \"\"\"Generate desktop notification when build is complete and the\n    elapsed build time was longer than 30 seconds.\"\"\"\n    if elapsed > 30:\n        notify(\"Servo build\", \"Completed in %0.2fs\" % elapsed)\ndef notify(title, text):\n    \"\"\"Generate a desktop notification using appropriate means on\n    supported platforms Linux, Windows, and Mac OS.  On unsupported\n    platforms, this function acts as a no-op.\"\"\"\n    platforms = {\n        \"linux\": notify_linux,\n        \"win\": notify_win,\n        \"darwin\": notify_darwin\n    }\n    func = platforms.get(sys.platform)\n    if func is not None:\n        try:\n            func(title, text)\n        except Exception as e:\n            extra = getattr(e, \"message\", \"\")\n            print(\"[Warning] Could not generate notification! %s\" % extra, file=sys.stderr)\ndef call(*args, **kwargs):\n    \"\"\"Wrap `subprocess.call`, printing the command if verbose=True.\"\"\"\n    verbose = kwargs.pop('verbose', False)\n    if verbose:\n        print(' '.join(args[0]))\n    return subprocess.call(*args, **kwargs)\n@CommandProvider\nclass MachCommands(CommandBase):\n    @Command('build',\n             description='Build Servo',\n             category='build')\n    @CommandArgument('--target', '-t',\n                     default=None,\n                     help='Cross compile for given target platform')\n    @CommandArgument('--release', '-r',\n                     action='store_true',\n                     help='Build in release mode')\n    @CommandArgument('--dev', '-d',\n                     action='store_true',\n                     help='Build in development mode')\n    @CommandArgument('--jobs', '-j',\n                     default=None,\n                     help='Number of jobs to run in parallel')\n    @CommandArgument('--android',\n                     default=None,\n                     action='store_true',\n                     help='Build for Android')\n    @CommandArgument('--debug-mozjs',\n                     default=None,\n                     action='store_true',\n                     help='Enable debug assertions in mozjs')\n    @CommandArgument('--verbose', '-v',\n                     action='store_true',\n                     help='Print verbose output')\n    @CommandArgument('params', nargs='...',\n                     help=\"Command-line arguments to be passed through to Cargo\")\n    def build(self, target=None, release=False, dev=False, jobs=None,\n              android=None, verbose=False, debug_mozjs=False, params=None):\n        if android is None:\n            android = self.config[\"build\"][\"android\"]\n        opts = params or []\n        features = []\n        base_path = self.get_target_dir()\n        release_path = path.join(base_path, \"release\", \"servo\")\n        dev_path = path.join(base_path, \"debug\", \"servo\")\n        release_exists = path.exists(release_path)\n        dev_exists = path.exists(dev_path)\n        if not (release or dev):\n            if self.config[\"build\"][\"mode\"] == \"dev\":\n                dev = True\n            elif self.config[\"build\"][\"mode\"] == \"release\":\n                release = True\n            elif release_exists and not dev_exists:\n                release = True\n            elif dev_exists and not release_exists:\n                dev = True\n            else:\n                print(\"Please specify either --dev (-d) for a development\")\n                print(\"  build, or --release (-r) for an optimized build.\")\n                sys.exit(1)\n        if release and dev:\n            print(\"Please specify either --dev or --release.\")\n            sys.exit(1)\n        self.ensure_bootstrapped()\n        if release:\n            opts += [\"--release\"]\n        if target:\n            opts += [\"--target\", target]\n        if jobs is not None:\n            opts += [\"-j\", jobs]\n        if verbose:\n            opts += [\"-v\"]\n        if android:\n            # Ensure the APK builder submodule has been built first\n            apk_builder_dir = \"support/android-rs-glue\"\n            with cd(path.join(apk_builder_dir, \"apk-builder\")):\n                status = call([\"cargo\", \"build\"], env=self.build_env(), verbose=verbose)\n                if status:\n                    return status\n            opts += [\"--target\", \"arm-linux-androideabi\"]\n        if debug_mozjs or self.config[\"build\"][\"debug-mozjs\"]:\n            features += [\"script/debugmozjs\"]\n        if is_headless_build():\n            opts += [\"--no-default-features\"]\n            features += [\"headless\"]\n        if android:\n            features += [\"android_glue\"]\n        if features:\n            opts += [\"--features\", \"%s\" % ' '.join(features)]\n        build_start = time()\n        env = self.build_env()\n        if android:\n            # Build OpenSSL for android\n            make_cmd = [\"make\"]\n            if jobs is not None:\n                make_cmd += [\"-j\" + jobs]\n            with cd(self.android_support_dir()):\n                status = call(\n                    make_cmd + [\"-f\", \"openssl.makefile\"],\n                    env=self.build_env(),\n                    verbose=verbose)\n                if status:\n                    return status\n            openssl_dir = path.join(self.android_support_dir(), \"openssl-1.0.1k\")\n            env['OPENSSL_LIB_DIR'] = openssl_dir\n            env['OPENSSL_INCLUDE_DIR'] = path.join(openssl_dir, \"include\")\n            env['OPENSSL_STATIC'] = 'TRUE'\n        status = call(\n", "outputs": ["            [\"cargo\", \"build\"] + opts,"], "input_length": 1398, "output_length": 12, "length": 1410, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "ced8bc7d6d61224dd4ca87e84914e95c6231c506dbaad3d5b89057933e05f238"}
{"input": "", "context": "//\n// ActivatorTest.cs - NUnit Test Cases for System.Activator\n//\n// Authors:\n//\tNick Drochak <ndrochak@gol.com>\n//\tGert Driesen <drieseng@users.sourceforge.net>\n//\tSebastien Pouliot  <sebastien@ximian.com>\n//\n// Copyright (C) 2005 Novell, Inc (http://www.novell.com)\n//\nusing System;\nusing System.Globalization;\nusing System.IO;\nusing System.Reflection;\n#if !TARGET_JVM && !MONOTOUCH // Reflection.Emit not supported for TARGET_JVM\nusing System.Reflection.Emit;\n#endif\nusing System.Runtime.InteropServices;\nusing System.Runtime.Remoting;\nusing System.Runtime.Remoting.Channels;\nusing System.Security;\nusing System.Security.Permissions;\nusing NUnit.Framework;\n// The class in this namespace is used by the main test class\nnamespace MonoTests.System.ActivatorTestInternal {\n\t// We need a COM class to test the Activator class\n\t[ComVisible (true)]\n\tpublic class COMTest : MarshalByRefObject {\n\t\tprivate int id;\n\t\tpublic bool constructorFlag = false;\n\t\tpublic COMTest ()\n\t\t{\n\t\t\tid = 0;\n\t\t}\n\t\tpublic COMTest (int id)\n\t\t{\n\t\t\tthis.id = id;\n\t\t}\n\t\t// This property is visible\n\t\t[ComVisible (true)]\n\t\tpublic int Id {\n\t\t\tget { return id; }\n\t\t\tset { id = value; }\n\t\t}\n\t}\n\t[ComVisible (false)]\n\tpublic class NonCOMTest : COMTest {\n\t}\n}\nnamespace MonoTests.System {\n\tusing MonoTests.System.ActivatorTestInternal;\n\tclass CustomUserType : Type\n\t{\n\t\tpublic override Assembly Assembly\n\t\t{\n\t\t\tget { throw new NotImplementedException (); }\n\t\t}\n\t\tpublic override string AssemblyQualifiedName\n\t\t{\n\t\t\tget { throw new NotImplementedException (); }\n\t\t}\n\t\tpublic override Type BaseType\n\t\t{\n\t\t\tget { throw new NotImplementedException (); }\n\t\t}\n\t\tpublic override string FullName\n\t\t{\n\t\t\tget { throw new NotImplementedException (); }\n\t\t}\n\t\tpublic override Guid GUID\n\t\t{\n\t\t\tget { throw new NotImplementedException (); }\n\t\t}\n\t\tprotected override TypeAttributes GetAttributeFlagsImpl ()\n\t\t{\n\t\t\tthrow new NotImplementedException ();\n\t\t}\n\t\tprotected override ConstructorInfo GetConstructorImpl (BindingFlags bindingAttr, Binder binder, CallingConventions callConvention, Type[] types, ParameterModifier[] modifiers)\n\t\t{\n\t\t\tthrow new NotImplementedException ();\n\t\t}\n\t\tpublic override ConstructorInfo[] GetConstructors (BindingFlags bindingAttr)\n\t\t{\n\t\t\tthrow new NotImplementedException ();\n\t\t}\n\t\tpublic override Type GetElementType ()\n\t\t{\n\t\t\tthrow new NotImplementedException ();\n\t\t}\n\t\tpublic override EventInfo GetEvent (string name, BindingFlags bindingAttr)\n\t\t{\n\t\t\tthrow new NotImplementedException ();\n\t\t}\n\t\tpublic override EventInfo[] GetEvents (BindingFlags bindingAttr)\n\t\t{\n\t\t\tthrow new NotImplementedException ();\n\t\t}\n\t\tpublic override FieldInfo GetField (string name, BindingFlags bindingAttr)\n\t\t{\n\t\t\tthrow new NotImplementedException ();\n\t\t}\n\t\tpublic override FieldInfo[] GetFields (BindingFlags bindingAttr)\n\t\t{\n\t\t\tthrow new NotImplementedException ();\n\t\t}\n\t\tpublic override Type GetInterface (string name, bool ignoreCase)\n\t\t{\n\t\t\tthrow new NotImplementedException ();\n\t\t}\n\t\tpublic override Type[] GetInterfaces ()\n\t\t{\n\t\t\tthrow new NotImplementedException ();\n\t\t}\n\t\tpublic override MemberInfo[] GetMembers (BindingFlags bindingAttr)\n\t\t{\n\t\t\tthrow new NotImplementedException ();\n\t\t}\n\t\tprotected override MethodInfo GetMethodImpl (string name, BindingFlags bindingAttr, Binder binder, CallingConventions callConvention, Type[] types, ParameterModifier[] modifiers)\n\t\t{\n\t\t\tthrow new NotImplementedException ();\n\t\t}\n\t\tpublic override MethodInfo[] GetMethods (BindingFlags bindingAttr)\n\t\t{\n\t\t\tthrow new NotImplementedException ();\n\t\t}\n\t\tpublic override Type GetNestedType (string name, BindingFlags bindingAttr)\n\t\t{\n\t\t\tthrow new NotImplementedException ();\n\t\t}\n\t\tpublic override Type[] GetNestedTypes (BindingFlags bindingAttr)\n\t\t{\n\t\t\tthrow new NotImplementedException ();\n\t\t}\n\t\tpublic override PropertyInfo[] GetProperties (BindingFlags bindingAttr)\n\t\t{\n\t\t\tthrow new NotImplementedException ();\n\t\t}\n\t\tprotected override PropertyInfo GetPropertyImpl (string name, BindingFlags bindingAttr, Binder binder, Type returnType, Type[] types, ParameterModifier[] modifiers)\n\t\t{\n\t\t\tthrow new NotImplementedException ();\n\t\t}\n\t\tprotected override bool HasElementTypeImpl ()\n\t\t{\n\t\t\tthrow new NotImplementedException ();\n\t\t}\n\t\tpublic override object InvokeMember (string name, BindingFlags invokeAttr, Binder binder, object target, object[] args, ParameterModifier[] modifiers, CultureInfo culture, string[] namedParameters)\n\t\t{\n\t\t\tthrow new NotImplementedException ();\n\t\t}\n\t\tprotected override bool IsArrayImpl ()\n\t\t{\n\t\t\tthrow new NotImplementedException ();\n\t\t}\n\t\tprotected override bool IsByRefImpl ()\n\t\t{\n\t\t\tthrow new NotImplementedException ();\n\t\t}\n\t\tprotected override bool IsCOMObjectImpl ()\n\t\t{\n\t\t\tthrow new NotImplementedException ();\n\t\t}\n\t\tprotected override bool IsPointerImpl ()\n\t\t{\n\t\t\tthrow new NotImplementedException ();\n\t\t}\n\t\tprotected override bool IsPrimitiveImpl ()\n\t\t{\n\t\t\tthrow new NotImplementedException ();\n\t\t}\n\t\tpublic override Module Module\n\t\t{\n\t\t\tget { throw new NotImplementedException (); }\n\t\t}\n\t\tpublic override string Namespace\n\t\t{\n\t\t\tget { throw new NotImplementedException (); }\n\t\t}\n\t\tpublic override Type UnderlyingSystemType\n\t\t{\n\t\t\tget {\n\t\t\t\treturn this;\n\t\t\t}\n\t\t}\n\t\tpublic override object[] GetCustomAttributes (Type attributeType, bool inherit)\n\t\t{\n\t\t\tthrow new NotImplementedException ();\n\t\t}\n\t\tpublic override object[] GetCustomAttributes (bool inherit)\n\t\t{\n\t\t\tthrow new NotImplementedException ();\n\t\t}\n\t\tpublic override bool IsDefined (Type attributeType, bool inherit)\n\t\t{\n\t\t\tthrow new NotImplementedException ();\n\t\t}\n\t\tpublic override string Name\n\t\t{\n\t\t\tget { throw new NotImplementedException (); }\n\t\t}\n\t}\n\t[TestFixture]\n\tpublic class ActivatorTest {\n\t\tprivate string testLocation = typeof (ActivatorTest).Assembly.Location;\n\t\t[Test]\n\t\tpublic void CreateInstance_Type()\n\t\t{\n\t\t\tCOMTest objCOMTest = (COMTest) Activator.CreateInstance (typeof (COMTest));\n\t\t\tAssert.AreEqual (\"MonoTests.System.ActivatorTestInternal.COMTest\", (objCOMTest.GetType ()).ToString (), \"#A02\");\n\t\t}\n\t\t[Test]\n\t\t[ExpectedException (typeof (ArgumentNullException))]\n\t\tpublic void CreateInstance_TypeNull ()\n\t\t{\n\t\t\tActivator.CreateInstance ((Type)null);\n\t\t}\n\t\t[Test]\n\t\t[ExpectedException (typeof (ArgumentException))]\n\t\tpublic void CreateInstance_CustomType ()\n\t\t{\n\t\t\tActivator.CreateInstance (new CustomUserType ());\n\t\t}\n\t\t[Test]\n\t\tpublic void CreateInstance_StringString ()\n\t\t{\n\t\t\tObjectHandle objHandle = Activator.CreateInstance (null, \"MonoTests.System.ActivatorTestInternal.COMTest\");\n\t\t\tCOMTest objCOMTest = (COMTest)objHandle.Unwrap ();\n\t\t\tobjCOMTest.Id = 2;\n\t\t\tAssert.AreEqual (2, objCOMTest.Id, \"#A03\");\n\t\t}\n\t\t[Test]\n", "outputs": ["\t\t[ExpectedException (typeof (ArgumentNullException))]"], "input_length": 1061, "output_length": 9, "length": 1070, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "6d29b29b7c992447921cab1e473fe13f5eb84e58bf5bdb76dd2464043dbe9277"}
{"input": "", "context": "from typing import Optional, List, Iterable, Dict, Any, Type, Union\nimport re\nfrom collections import OrderedDict\nfrom xml.dom import minidom\nfrom systemrdl import RDLCompiler, RDLImporter\nfrom systemrdl import rdltypes\nfrom systemrdl.messages import SourceRefBase\nfrom systemrdl import component as comp\nfrom . import typemaps\nclass IPXACTImporter(RDLImporter):\n    def __init__(self, compiler: RDLCompiler):\n        super().__init__(compiler)\n        self.ns = None # type: str\n        self._current_regwidth = 32\n        self._addressUnitBits = 8\n        self._current_addressBlock_access = rdltypes.AccessType.rw\n    @property\n    def src_ref(self) -> SourceRefBase:\n        return self.default_src_ref\n    #---------------------------------------------------------------------------\n    def import_file(self, path: str) -> None:\n        super().import_file(path)\n        # minidom does not provide file position data. Using a bare SourceRef\n        # for everything created during this import\n        self._current_regwidth = 32\n        self._addressUnitBits = 8\n        dom = minidom.parse(path)\n        addressBlock_s = self.seek_to_top_addressBlocks(dom)\n        # Parse all the addressBlock elements found\n        addrmap_or_mems = []\n        for addressBlock in addressBlock_s:\n            addrmap_or_mem = self.parse_addressBlock(addressBlock)\n            if addrmap_or_mem is not None:\n                addrmap_or_mems.append(addrmap_or_mem)\n        if not addrmap_or_mems:\n            self.msg.fatal(\n                \"'memoryMap' must contain at least one 'addressBlock' element\",\n                self.src_ref\n            )\n        if (len(addrmap_or_mems) == 1) and (addrmap_or_mems[0].addr_offset == 0):\n            # OK to drop the hierarchy implied by the enclosing memoryMap\n            # since it is only a wrapper around a single addressBlock at base\n            # offset 0\n            # This addressBlock will be the top component that is registered\n            # in $root\n            top_component = addrmap_or_mems[0]\n            #  de-instantiate the addrmap\n            top_component.type_name = top_component.inst_name\n            top_component.is_instance = False\n            top_component.inst_name = None\n            top_component.original_def = None\n            top_component.external = None\n            top_component.inst_src_ref = None\n            top_component.addr_offset = None\n        else:\n            # memoryMap encloses multiple addressBlock components, or the single\n            # one uses a meaningful address offset.\n            # In order to preserve this information, encapsulate them in a\n            # top-level parent that is named after the memoryMap\n            # Get the top-level memoryMap's element values\n            d = self.flatten_element_values(addressBlock_s[0].parentNode)\n            # Check for required name\n            if 'name' not in d:\n                self.msg.fatal(\"memoryMap is missing required tag 'name'\", self.src_ref)\n            # Create component instance to represent the memoryMap\n            C = comp.Addrmap()\n            C.def_src_ref = self.src_ref\n            # Collect properties and other values\n            C.type_name = d['name']\n            if 'displayName' in d:\n                self.assign_property(C, \"name\", d['displayName'])\n            if 'description' in d:\n                self.assign_property(C, \"desc\", d['description'])\n            # Insert all the addrmap_or_mems as children\n            C.children = addrmap_or_mems\n            top_component = C\n        # register it with the root namespace\n        self.register_root_component(top_component)\n    #---------------------------------------------------------------------------\n    def seek_to_top_addressBlocks(self, dom: minidom.Element) -> List[minidom.Element]:\n        \"\"\"\n        IP-XACT files can be a little ambiguous depending on who they come from\n        This function returns the most reasonable starting point to use\n        as the top-level node for import.\n        Returns a list of addressBlock elements\n        If:\n            - There is exactly one memoryMap\n            - Inside it, a single addressBlock\n        Then the addressBlock is the top-level node\n        (will actually return a list with only one addressBlock)\n        If:\n            - There is exactly one memoryMap\n            - Inside it, more than one addressBlock that has meaningful contents\n                \"meaningful\" is having a name, base address, and at least one\n                child\n        Then the memoryMap is the top-level node\n        (will actually return a list of remaining meaningful addressBlocks)\n        If there is more than one memoryMap, use the first one that contains\n        an addressBlock child\n        \"\"\"\n        # Find <component> and determine namespace prefix\n        c_ipxact = self.get_first_child_by_tag(dom, \"ipxact:component\")\n        c_spirit = self.get_first_child_by_tag(dom, \"spirit:component\")\n        if c_ipxact is not None:\n            component = c_ipxact\n        elif c_spirit is not None:\n            component = c_spirit\n        else:\n            self.msg.fatal(\n                \"Could not find a 'component' element\",\n                self.src_ref\n            )\n        self.ns = component.prefix\n        # Find <memoryMaps>\n        memoryMaps_s = self.get_children_by_tag(component, self.ns+\":memoryMaps\")\n        if len(memoryMaps_s) != 1:\n            self.msg.fatal(\n                \"'component' must contain exactly one 'memoryMaps' element\",\n                self.src_ref\n            )\n        memoryMaps = memoryMaps_s[0]\n        # Find all <memoryMap>\n        memoryMap_s = self.get_children_by_tag(memoryMaps, self.ns+\":memoryMap\")\n        # Find the first <memoryMap> that has at least one <addressBlock>\n        for mm in memoryMap_s:\n            addressBlock_s = self.get_children_by_tag(mm, self.ns+\":addressBlock\")\n            if addressBlock_s:\n                aub = self.get_first_child_by_tag(mm, self.ns+\":addressUnitBits\")\n                if aub:\n                    self._addressUnitBits = self.parse_integer(get_text(aub))\n                    if (self._addressUnitBits < 8) or (self._addressUnitBits % 8 != 0):\n                        self.msg.fatal(\n                            \"Importer only supports <addressUnitBits> that is a multiple of 8\",\n                            self.src_ref\n                        )\n                break\n        else:\n            self.msg.fatal(\n                \"No valid 'memoryMap' found\",\n                self.src_ref\n            )\n        return addressBlock_s\n    #---------------------------------------------------------------------------\n    def parse_addressBlock(self, addressBlock: minidom.Element) -> Union[comp.Addrmap, comp.Mem]:\n        \"\"\"\n        Parses an addressBlock and returns an instantiated addrmap or mem\n        component.\n        If addressBlock is empty or usage specifies 'reserved' then returns\n        None\n        \"\"\"\n        # Schema:\n        #   {nameGroup}\n        #       name (required) --> inst_name\n        #       displayName --> prop:name\n        #       description --> prop:desc\n        #   accessHandles\n        #   isPresent --> prop:ispresent\n        #   baseAddress (required) --> addr_offset\n        #   {addressBlockDefinitionGroup}\n        #       typeIdentifier\n        #       range (required) --> divide by width and set prop:mementries if Mem\n        #       width (required) --> prop:memwidth if Mem\n        #       {memoryBlockData}\n        #           usage --> Mem vs Addrmap instance\n        #           volatile\n        #           access --> prop:sw if Mem\n        #           parameters\n        #       {registerData}\n        #           register --> children\n        #           registerFile --> children\n        #   vendorExtensions\n        d = self.flatten_element_values(addressBlock)\n        if d.get('usage', None) == \"reserved\":\n            # 1685-2014 6.9.4.2-a.1.iii: defines the entire range of the\n            # addressBlock as reserved or for unknown usage to IP-XACT. This\n            # type shall not contain registers.\n            return None\n        # Check for required values\n        required = {'name', 'baseAddress', 'range', 'width'}\n        missing = required - set(d.keys())\n        for m in missing:\n            self.msg.fatal(\"addressBlock is missing required tag '%s'\" % m, self.src_ref)\n        # Create component instance\n        is_memory = (d.get('usage', None) == \"memory\")\n        if is_memory:\n            C = self.instantiate_mem(\n                self.create_mem_definition(),\n                d['name'], self.AU_to_bytes(d['baseAddress'])\n            )\n        else:\n            C = self.instantiate_addrmap(\n                self.create_addrmap_definition(),\n                d['name'], self.AU_to_bytes(d['baseAddress'])\n            )\n        # Collect properties and other values\n        if 'displayName' in d:\n            self.assign_property(C, \"name\", d['displayName'])\n        if 'description' in d:\n            self.assign_property(C, \"desc\", d['description'])\n        if 'isPresent' in d:\n            self.assign_property(C, \"ispresent\", d['isPresent'])\n        self._current_regwidth = d['width']\n        if is_memory:\n            self.assign_property(C, \"memwidth\", d['width'])\n            self.assign_property(\n                C, \"mementries\",\n                (d['range'] * self._addressUnitBits) // (d['width'])\n            )\n            if 'access' in d:\n                self.assign_property(C, \"sw\", d['access'])\n        if 'access' in d:\n            self._current_addressBlock_access = d['access']\n        else:\n            self._current_addressBlock_access = rdltypes.AccessType.rw\n        # collect children\n        for child_el in d['child_els']:\n            if child_el.localName == \"register\":\n                R = self.parse_register(child_el)\n                if R:\n                    self.add_child(C, R)\n            elif child_el.localName == \"registerFile\" and not is_memory:\n                R = self.parse_registerFile(child_el)\n                if R:\n                    self.add_child(C, R)\n            else:\n                self.msg.error(\n                    \"Invalid child element <%s> found in <%s:addressBlock>\"\n                    % (child_el.tagName, self.ns),\n                    self.src_ref\n                )\n        if 'vendorExtensions' in d:\n            C = self.addressBlock_vendorExtensions(d['vendorExtensions'], C)\n        if not is_memory and not C.children:\n            # If a register addressBlock has no children, skip it\n            return None\n        return C\n    #---------------------------------------------------------------------------\n    def parse_registerFile(self, registerFile: minidom.Element) -> comp.Regfile:\n        \"\"\"\n        Parses an registerFile and returns an instantiated regfile component\n        \"\"\"\n        # Schema:\n        #   {nameGroup}\n        #       name (required) --> inst_name\n        #       displayName --> prop:name\n        #       description --> prop:desc\n        #   accessHandles\n        #   isPresent --> prop:ispresent\n        #   dim --> dimensions\n        #   addressOffset (required)\n        #   {registerFileDefinitionGroup}\n        #       typeIdentifier\n        #       range (required)\n        #       {registerData}\n        #           register --> children\n        #           registerFile --> children\n        #   parameters\n        #   vendorExtensions\n        d = self.flatten_element_values(registerFile)\n        # Check for required values\n        required = {'name', 'addressOffset', 'range'}\n        missing = required - set(d.keys())\n        for m in missing:\n            self.msg.fatal(\"registerFile is missing required tag '%s'\" % m, self.src_ref)\n        # Create component instance\n        if 'dim' in d:\n            # is array\n            C = self.instantiate_regfile(\n                self.create_regfile_definition(),\n                d['name'], self.AU_to_bytes(d['addressOffset']),\n                d['dim'], self.AU_to_bytes(d['range'])\n            )\n        else:\n            C = self.instantiate_regfile(\n                self.create_regfile_definition(),\n                d['name'], self.AU_to_bytes(d['addressOffset'])\n            )\n        # Collect properties and other values\n        if 'displayName' in d:\n            self.assign_property(C, \"name\", d['displayName'])\n        if 'description' in d:\n            self.assign_property(C, \"desc\", d['description'])\n        if 'isPresent' in d:\n            self.assign_property(C, \"ispresent\", d['isPresent'])\n        # collect children\n        for child_el in d['child_els']:\n            if child_el.localName == \"register\":\n                R = self.parse_register(child_el)\n                if R:\n                    self.add_child(C, R)\n            elif child_el.localName == \"registerFile\":\n                R = self.parse_registerFile(child_el)\n                if R:\n                    self.add_child(C, R)\n            else:\n                self.msg.error(\n                    \"Invalid child element <%s> found in <%s:registerFile>\"\n                    % (child_el.tagName, self.ns),\n                    self.src_ref\n                )\n        if 'vendorExtensions' in d:\n            C = self.registerFile_vendorExtensions(d['vendorExtensions'], C)\n        if not C.children:\n            # Register File contains no fields! RDL does not allow this. Discard\n            self.msg.warning(\n                \"Discarding registerFile '%s' because it does not contain any children\"\n                % (C.inst_name),\n                self.src_ref\n            )\n            return None\n        return C\n    #---------------------------------------------------------------------------\n    def parse_register(self, register: minidom.Element) -> comp.Reg:\n        \"\"\"\n        Parses a register and returns an instantiated reg component\n        \"\"\"\n        # Schema:\n        #   {nameGroup}\n        #       name (required) --> inst_name\n        #       displayName --> prop:name\n        #       description --> prop:desc\n        #   accessHandles\n        #   isPresent --> prop:ispresent\n        #   dim --> dimensions\n        #   addressOffset (required)\n        #   {registerDefinitionGroup}\n        #       typeIdentifier\n        #       size (required)\n        #       volatile\n        #       access\n        #       reset { <<1685-2009>>\n        #           value\n        #           mask\n        #       }\n        #       field...\n        #   alternateRegisters\n        #   parameters\n        #   vendorExtensions\n        d = self.flatten_element_values(register)\n        # Check for required values\n        required = {'name', 'addressOffset', 'size'}\n        missing = required - set(d.keys())\n        for m in missing:\n            self.msg.fatal(\"register is missing required tag '%s'\" % m, self.src_ref)\n        # Create component instance\n        if 'dim' in d:\n            # is array\n            C = self.instantiate_reg(\n                self.create_reg_definition(),\n                d['name'], self.AU_to_bytes(d['addressOffset']),\n                d['dim'], d['size'] // 8\n            )\n        else:\n            C = self.instantiate_reg(\n                self.create_reg_definition(),\n                d['name'], self.AU_to_bytes(d['addressOffset'])\n            )\n        # Collect properties and other values\n        if 'displayName' in d:\n            self.assign_property(C, \"name\", d['displayName'])\n        if 'description' in d:\n            self.assign_property(C, \"desc\", d['description'])\n        if 'isPresent' in d:\n            self.assign_property(C, \"ispresent\", d['isPresent'])\n        self.assign_property(C, \"regwidth\", d['size'])\n        reg_access = d.get('access', self._current_addressBlock_access)\n        reg_reset_value = d.get('reset.value', None)\n        reg_reset_mask = d.get('reset.mask', None)\n        # collect children\n        for child_el in d['child_els']:\n            if child_el.localName == \"field\":\n                field = self.parse_field(child_el, reg_access, reg_reset_value, reg_reset_mask)\n                if field is not None:\n                    self.add_child(C, field)\n            else:\n                self.msg.error(\n                    \"Invalid child element <%s> found in <%s:register>\"\n                    % (child_el.tagName, self.ns),\n                    self.src_ref\n                )\n        if 'vendorExtensions' in d:\n            C = self.register_vendorExtensions(d['vendorExtensions'], C)\n        if not C.children:\n            # Register contains no fields! RDL does not allow this. Discard\n            self.msg.warning(\n                \"Discarding register '%s' because it does not contain any fields\"\n                % (C.inst_name),\n                self.src_ref\n            )\n            return None\n        return C\n    #---------------------------------------------------------------------------\n    def parse_field(self, field: minidom.Element, reg_access: rdltypes.AccessType, reg_reset_value: Optional[int], reg_reset_mask: Optional[int]) -> comp.Field:\n        \"\"\"\n        Parses an field and returns an instantiated field component\n        \"\"\"\n        # Schema:\n        #   {nameGroup}\n        #       name (required) --> inst_name\n        #       displayName --> prop:name\n        #       description --> prop:desc\n        #   accessHandles\n        #   isPresent --> prop:ispresent\n        #   bitOffset (required)\n        #   resets { <<1685-2014>>\n        #       reset {\n        #           value\n        #           mask\n        #       }\n        #   }\n        #   {fieldDefinitionGroup}\n        #       typeIdentifier\n        #       bitWidth (required)\n        #       {fieldData}\n        #           volatile\n        #           access\n        #           enumeratedValues...\n        #           modifiedWriteValue\n        #           writeValueConstraint\n        #           readAction\n        #           testable\n        #           reserved\n        #   parameters\n        #   vendorExtensions\n        d = self.flatten_element_values(field)\n        # Check for required values\n        required = {'name', 'bitOffset', 'bitWidth'}\n        missing = required - set(d.keys())\n        for m in missing:\n            self.msg.fatal(\"field is missing required tag '%s'\" % m, self.src_ref)\n        # Discard field if it is reserved\n        if d.get('reserved', False):\n            return None\n        # Create component instance\n        C = self.instantiate_field(\n            self.create_field_definition(),\n            d['name'], d['bitOffset'], d['bitWidth']\n        )\n        # Collect properties and other values\n        if 'displayName' in d:\n            self.assign_property(C, \"name\", d['displayName'])\n        if 'description' in d:\n            self.assign_property(C, \"desc\", d['description'])\n        if 'isPresent' in d:\n            self.assign_property(C, \"ispresent\", d['isPresent'])\n        if 'access' in d:\n            self.assign_property(C, \"sw\", d['access'])\n        else:\n            self.assign_property(C, \"sw\", reg_access)\n        if 'testable' in d:\n            self.assign_property(C, \"donttest\", not d['testable'])\n        if 'reset.value' in d:\n            self.assign_property(C, \"reset\", d['reset.value'])\n        elif reg_reset_value is not None:\n            mask = (1 << C.width) - 1\n            rst = (reg_reset_value >> C.lsb) & mask\n            if reg_reset_mask is None:\n                rmask = mask\n            else:\n                rmask = (reg_reset_mask >> C.lsb) & mask\n            if rmask:\n                self.assign_property(C, \"reset\", rst)\n        if 'readAction' in d:\n            self.assign_property(C, \"onread\", d['readAction'])\n        if 'modifiedWriteValue' in d:\n            self.assign_property(C, \"onwrite\", d['modifiedWriteValue'])\n        if 'enum_el' in d:\n            enum_type = self.parse_enumeratedValues(d['enum_el'], C.inst_name + \"_enum_t\")\n            self.assign_property(C, \"encode\", enum_type)\n        if 'vendorExtensions' in d:\n            C = self.field_vendorExtensions(d['vendorExtensions'], C)\n        return C\n    #---------------------------------------------------------------------------\n    def parse_integer(self, s: str) -> int:\n        \"\"\"\n        Converts an IP-XACT number string into an int\n        IP-XACT technically supports integer expressions in these fields.\n        For now, I don't have a compelling reason to support them.\n        Handles the following formats:\n            - Normal decimal: 123, -456\n            - Verilog-style: 'b10, 'o77, d123, 'hff, 8'hff\n            - scaledInteger:\n                - May have # or 0x prefix for hex\n                - May have K, M, G, or T multiplier suffix\n        \"\"\"\n        s = s.strip()\n        multiplier = {\n            \"K\": 1024,\n            \"M\": 1024*1024,\n            \"G\": 1024*1024*1024,\n            \"T\": 1024*1024*1024*1024\n        }\n        m = re.fullmatch(r'(-?\\d+)(K|M|G|T)?', s, re.I)\n        if m:\n            v = int(m.group(1))\n            if m.group(2):\n                v *= multiplier[m.group(2).upper()]\n            return v\n        m = re.fullmatch(r\"\\d*'h([0-9a-f]+)\", s, re.I)\n        if m:\n            return int(m.group(1), 16)\n        m = re.fullmatch(r\"(-)?(0x|#)([0-9a-f]+)(K|M|G|T)?\", s, re.I)\n        if m:\n            v = int(m.group(3), 16)\n            if m.group(1):\n                v = -v\n            if m.group(4):\n                v *= multiplier[m.group(4).upper()]\n            return v\n        m = re.fullmatch(r\"\\d*'d([0-9]+)\", s, re.I)\n        if m:\n            return int(m.group(1), 10)\n        m = re.fullmatch(r\"\\d*'b([0-1]+)\", s, re.I)\n        if m:\n            return int(m.group(1), 2)\n        m = re.fullmatch(r\"\\d*'o([0-7]+)\", s, re.I)\n        if m:\n            return int(m.group(1), 8)\n        raise ValueError\n    #---------------------------------------------------------------------------\n    def parse_boolean(self, s: str) -> bool:\n        \"\"\"\n        Converts several boolean-ish representations to a true bool.\n        \"\"\"\n        s = s.lower().strip()\n        if s in (\"true\", \"1\"):\n            return True\n        elif s in (\"false\", \"0\"):\n            return False\n        else:\n            raise ValueError(\"Unable to parse boolean value '%s'\" % s)\n    #---------------------------------------------------------------------------\n    def flatten_element_values(self, el: minidom.Element) -> Dict[str, Any]:\n        \"\"\"\n        Given any of the IP-XACT RAL component elements, flatten the\n        key/value tags into a dictionary.\n        Handles values contained in:\n            addressBlock, register, registerFile, field\n        Ignores several tags that are not interesting to the RAL importer\n        \"\"\"\n        d = {\n            'child_els' : []\n        } # type: Dict[str, Any]\n        for child in self.iterelements(el):\n            if child.localName == \"name\":\n                # Sanitize name\n                d[child.localName] = re.sub(\n                    r'[:\\-.]',\n                    \"_\",\n                    get_text(child).strip()\n                )\n            elif child.localName in (\"displayName\", \"usage\"):\n                # Copy string types directly, but stripped\n                d[child.localName] = get_text(child).strip()\n            elif child.localName == \"description\":\n                # Copy description string types unmodified\n                d[child.localName] = get_text(child)\n            elif child.localName in (\"baseAddress\", \"addressOffset\", \"range\", \"width\", \"size\", \"bitOffset\", \"bitWidth\"):\n                # Parse integer types\n                d[child.localName] = self.parse_integer(get_text(child))\n            elif child.localName in (\"isPresent\", \"volatile\", \"testable\", \"reserved\"):\n                # Parse boolean types\n                d[child.localName] = self.parse_boolean(get_text(child))\n            elif child.localName in (\"register\", \"registerFile\", \"field\"):\n                # Child elements that need to be parsed elsewhere\n                d['child_els'].append(child)\n            elif child.localName in (\"reset\", \"resets\"):\n                if child.localName == \"resets\":\n                    # pick the first reset\n                    reset = self.get_first_child_by_tag(child, self.ns + \":reset\")\n                    if reset is None:\n                        continue\n                else:\n                    reset = child\n                value_el = self.get_first_child_by_tag(reset, self.ns + \":value\")\n                if value_el:\n                    d['reset.value'] = self.parse_integer(get_text(value_el))\n                mask_el = self.get_first_child_by_tag(reset, self.ns + \":mask\")\n                if mask_el:\n                    d['reset.mask'] = self.parse_integer(get_text(mask_el))\n            elif child.localName == \"access\":\n                s = get_text(child).strip()\n                sw = typemaps.sw_from_access(s)\n                if sw is None:\n                    self.msg.error(\n                        \"Invalid value '%s' found in <%s>\" % (s, child.tagName),\n                        self.src_ref\n                    )\n                else:\n                    d['access'] = sw\n            elif child.localName == \"dim\":\n                # Accumulate array dimensions\n                dim = self.parse_integer(get_text(child))\n                if 'dim' in d:\n                    d['dim'].append(dim)\n                else:\n                    d['dim'] = [dim]\n            elif child.localName == \"readAction\":\n                s = get_text(child).strip()\n                onread = typemaps.onread_from_readaction(s)\n                if onread is None:\n                    self.msg.error(\n                        \"Invalid value '%s' found in <%s>\" % (s, child.tagName),\n                        self.src_ref\n                    )\n                else:\n                    d['readAction'] = onread\n            elif child.localName == \"modifiedWriteValue\":\n                s = get_text(child).strip()\n                onwrite = typemaps.onwrite_from_mwv(s)\n                if onwrite is None:\n                    self.msg.error(\n                        \"Invalid value '%s' found in <%s>\" % (s, child.tagName),\n                        self.src_ref\n                    )\n                else:\n                    d['modifiedWriteValue'] = onwrite\n            elif child.localName == \"enumeratedValues\":\n                # Deal with this later\n                d['enum_el'] = child\n            elif child.localName == \"vendorExtensions\":\n                # Deal with this later\n                d['vendorExtensions'] = child\n        return d\n    #---------------------------------------------------------------------------\n    def parse_enumeratedValues(self, enumeratedValues: minidom.Element, type_name: str) -> Type[rdltypes.UserEnum]:\n        \"\"\"\n        Parses an enumeration listing and returns the user-defined enum type\n        \"\"\"\n        entries = OrderedDict()\n        for enumeratedValue in self.iterelements(enumeratedValues):\n            if enumeratedValue.localName != \"enumeratedValue\":\n                continue\n            # Flatten element values\n            d = {} # type: Dict[str, Any]\n            for child in self.iterelements(enumeratedValue):\n                if child.localName in (\"name\", \"displayName\"):\n                    d[child.localName] = get_text(child).strip()\n                elif child.localName == \"description\":\n                    d[child.localName] = get_text(child)\n                elif child.localName == \"value\":\n                    d[child.localName] = self.parse_integer(get_text(child))\n            # Check for required values\n            required = {'name', 'value'}\n            missing = required - set(d.keys())\n            for m in missing:\n                self.msg.fatal(\"enumeratedValue is missing required tag '%s'\" % m, self.src_ref)\n            entry_name = d['name']\n            entry_value = d['value']\n            displayname = d.get('displayName', None)\n            desc = d.get('description', None)\n", "outputs": ["            entries[entry_name] = (entry_value, displayname, desc)"], "input_length": 4786, "output_length": 12, "length": 4798, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "357c5c98df1e3d4f4209087982221db06429711afefaf66ef24f2dfb52d8e660"}
{"input": "", "context": "/* Copyright Statement:\n *\n * This software/firmware and related documentation (\"MediaTek Software\") are\n * protected under relevant copyright laws. The information contained herein is\n * confidential and proprietary to MediaTek Inc. and/or its licensors. Without\n * the prior written permission of MediaTek inc. and/or its licensors, any\n * reproduction, modification, use or disclosure of MediaTek Software, and\n * information contained herein, in whole or in part, shall be strictly\n * prohibited.\n * \n * MediaTek Inc. (C) 2010. All rights reserved.\n * \n * BY OPENING THIS FILE, RECEIVER HEREBY UNEQUIVOCALLY ACKNOWLEDGES AND AGREES\n * THAT THE SOFTWARE/FIRMWARE AND ITS DOCUMENTATIONS (\"MEDIATEK SOFTWARE\")\n * RECEIVED FROM MEDIATEK AND/OR ITS REPRESENTATIVES ARE PROVIDED TO RECEIVER\n * ON AN \"AS-IS\" BASIS ONLY. MEDIATEK EXPRESSLY DISCLAIMS ANY AND ALL\n * WARRANTIES, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE IMPLIED\n * WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE OR\n * NONINFRINGEMENT. NEITHER DOES MEDIATEK PROVIDE ANY WARRANTY WHATSOEVER WITH\n * RESPECT TO THE SOFTWARE OF ANY THIRD PARTY WHICH MAY BE USED BY,\n * INCORPORATED IN, OR SUPPLIED WITH THE MEDIATEK SOFTWARE, AND RECEIVER AGREES\n * TO LOOK ONLY TO SUCH THIRD PARTY FOR ANY WARRANTY CLAIM RELATING THERETO.\n * RECEIVER EXPRESSLY ACKNOWLEDGES THAT IT IS RECEIVER'S SOLE RESPONSIBILITY TO\n * OBTAIN FROM ANY THIRD PARTY ALL PROPER LICENSES CONTAINED IN MEDIATEK\n * SOFTWARE. MEDIATEK SHALL ALSO NOT BE RESPONSIBLE FOR ANY MEDIATEK SOFTWARE\n * RELEASES MADE TO RECEIVER'S SPECIFICATION OR TO CONFORM TO A PARTICULAR\n * STANDARD OR OPEN FORUM. RECEIVER'S SOLE AND EXCLUSIVE REMEDY AND MEDIATEK'S\n * ENTIRE AND CUMULATIVE LIABILITY WITH RESPECT TO THE MEDIATEK SOFTWARE\n * RELEASED HEREUNDER WILL BE, AT MEDIATEK'S OPTION, TO REVISE OR REPLACE THE\n * MEDIATEK SOFTWARE AT ISSUE, OR REFUND ANY SOFTWARE LICENSE FEES OR SERVICE\n * CHARGE PAID BY RECEIVER TO MEDIATEK FOR SUCH MEDIATEK SOFTWARE AT ISSUE.\n *\n * The following software/firmware and/or related documentation (\"MediaTek\n * Software\") have been modified by MediaTek Inc. All revisions are subject to\n * any receiver's applicable license agreements with MediaTek Inc.\n */\npackage org.bouncycastle.crypto.modes;\nimport org.bouncycastle.crypto.BlockCipher;\nimport org.bouncycastle.crypto.CipherParameters;\nimport org.bouncycastle.crypto.DataLengthException;\nimport org.bouncycastle.crypto.params.ParametersWithIV;\n/**\n * implements the GOST 28147 OFB counter mode (GCTR).\n */\npublic class GOFBBlockCipher\n    implements BlockCipher\n{\n    private byte[]          IV;\n    private byte[]          ofbV;\n    private byte[]          ofbOutV;\n    private final int             blockSize;\n    private final BlockCipher     cipher;\n    boolean firstStep = true;\n    int N3;\n    int N4;\n    static final int C1 = 16843012; //00000001000000010000000100000100\n    static final int C2 = 16843009; //00000001000000010000000100000001\n    /**\n     * Basic constructor.\n     *\n     * @param cipher the block cipher to be used as the basis of the\n     * counter mode (must have a 64 bit block size).\n     */\n    public GOFBBlockCipher(\n        BlockCipher cipher)\n    {\n        this.cipher = cipher;\n        this.blockSize = cipher.getBlockSize();\n        \n        if (blockSize != 8)\n        {\n            throw new IllegalArgumentException(\"GCTR only for 64 bit block ciphers\");\n        }\n        this.IV = new byte[cipher.getBlockSize()];\n        this.ofbV = new byte[cipher.getBlockSize()];\n        this.ofbOutV = new byte[cipher.getBlockSize()];\n    }\n    /**\n     * return the underlying block cipher that we are wrapping.\n     *\n     * @return the underlying block cipher that we are wrapping.\n     */\n    public BlockCipher getUnderlyingCipher()\n    {\n        return cipher;\n    }\n    /**\n     * Initialise the cipher and, possibly, the initialisation vector (IV).\n     * If an IV isn't passed as part of the parameter, the IV will be all zeros.\n     * An IV which is too short is handled in FIPS compliant fashion.\n     *\n     * @param encrypting if true the cipher is initialised for\n     *  encryption, if false for decryption.\n     * @param params the key and other data required by the cipher.\n     * @exception IllegalArgumentException if the params argument is\n     * inappropriate.\n     */\n    public void init(\n        boolean             encrypting, //ignored by this CTR mode\n        CipherParameters    params)\n        throws IllegalArgumentException\n    {\n        firstStep = true;\n        N3 = 0;\n        N4 = 0;\n        if (params instanceof ParametersWithIV)\n        {\n                ParametersWithIV ivParam = (ParametersWithIV)params;\n                byte[]      iv = ivParam.getIV();\n                if (iv.length < IV.length)\n                {\n                    // prepend the supplied IV with zeros (per FIPS PUB 81)\n                    System.arraycopy(iv, 0, IV, IV.length - iv.length, iv.length); \n                    for (int i = 0; i < IV.length - iv.length; i++)\n                    {\n                        IV[i] = 0;\n                    }\n                }\n                else\n                {\n                    System.arraycopy(iv, 0, IV, 0, IV.length);\n                }\n                reset();\n                cipher.init(true, ivParam.getParameters());\n        }\n        else\n        {\n                reset();\n                cipher.init(true, params);\n        }\n    }\n    /**\n     * return the algorithm name and mode.\n     *\n     * @return the name of the underlying algorithm followed by \"/GCTR\"\n     * and the block size in bits\n     */\n    public String getAlgorithmName()\n    {\n        return cipher.getAlgorithmName() + \"/GCTR\";\n    }\n    \n    /**\n     * return the block size we are operating at (in bytes).\n     *\n     * @return the block size we are operating at (in bytes).\n     */\n    public int getBlockSize()\n    {\n        return blockSize;\n    }\n    /**\n     * Process one block of input from the array in and write it to\n     * the out array.\n     *\n     * @param in the array containing the input data.\n     * @param inOff offset into the in array the data starts at.\n     * @param out the array the output data will be copied into.\n     * @param outOff the offset into the out array the output will start at.\n     * @exception DataLengthException if there isn't enough data in in, or\n     * space in out.\n     * @exception IllegalStateException if the cipher isn't initialised.\n     * @return the number of bytes processed and produced.\n     */\n    public int processBlock(\n        byte[]      in,\n        int         inOff,\n        byte[]      out,\n        int         outOff)\n        throws DataLengthException, IllegalStateException\n    {\n        if ((inOff + blockSize) > in.length)\n        {\n            throw new DataLengthException(\"input buffer too short\");\n        }\n        if ((outOff + blockSize) > out.length)\n        {\n            throw new DataLengthException(\"output buffer too short\");\n        }\n        if (firstStep)\n        {\n            firstStep = false;\n            cipher.processBlock(ofbV, 0, ofbOutV, 0);\n            N3 = bytesToint(ofbOutV, 0);\n            N4 = bytesToint(ofbOutV, 4);\n        }\n        N3 += C2;\n        N4 += C1;\n        intTobytes(N3, ofbV, 0);\n        intTobytes(N4, ofbV, 4);\n        cipher.processBlock(ofbV, 0, ofbOutV, 0);\n        //\n        // XOR the ofbV with the plaintext producing the cipher text (and\n        // the next input block).\n        //\n        for (int i = 0; i < blockSize; i++)\n        {\n            out[outOff + i] = (byte)(ofbOutV[i] ^ in[inOff + i]);\n        }\n        //\n        // change over the input block.\n        //\n        System.arraycopy(ofbV, blockSize, ofbV, 0, ofbV.length - blockSize);\n        System.arraycopy(ofbOutV, 0, ofbV, ofbV.length - blockSize, blockSize);\n        return blockSize;\n    }\n    /**\n     * reset the feedback vector back to the IV and reset the underlying\n     * cipher.\n     */\n    public void reset()\n    {\n        System.arraycopy(IV, 0, ofbV, 0, IV.length);\n        cipher.reset();\n    }\n    //array of bytes to type int\n    private int bytesToint(\n        byte[]  in,\n        int     inOff)\n    {\n        return  ((in[inOff + 3] << 24) & 0xff000000) + ((in[inOff + 2] << 16) & 0xff0000) +\n                ((in[inOff + 1] << 8) & 0xff00) + (in[inOff] & 0xff);\n    }\n    //int to array of bytes\n    private void intTobytes(\n            int     num,\n            byte[]  out,\n            int     outOff)\n    {\n", "outputs": ["            out[outOff + 3] = (byte)(num >>> 24);"], "input_length": 1503, "output_length": 18, "length": 1521, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "388b0d6f39fc9c710963c776778c0b63f9904370e5921cd4e486aa10dce00526"}
{"input": "", "context": "#!/usr/bin/env python\n'''\nCreated on Jan 28, 2016\n@author: cme\n'''\n#****************************************************************\n# \\file\n#\n# \\note\n# Copyright (c) 2016 \\n\n# Fraunhofer Institute for Manufacturing Engineering\n# and Automation (IPA) \\n\\n\n#\n#*****************************************************************\n#\n# \\note\n# Project name: Care-O-bot\n# \\note\n# ROS stack name: ipa_pars\n# \\note\n# ROS package name: ipa_pars_main\n#\n# \\author\n# Author: Christian Ehrmann\n# \\author\n# Supervised by: Richard Bormann\n#\n# \\date Date of creation: 01.2016\n#\n# \\brief\n#\n#\n#*****************************************************************\n#\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n#\n# - Redistributions of source code must retain the above copyright\n# notice, this list of conditions and the following disclaimer. \\n\n# - Redistributions in binary form must reproduce the above copyright\n# notice, this list of conditions and the following disclaimer in the\n# documentation and/or other materials provided with the distribution. \\n\n# - Neither the name of the Fraunhofer Institute for Manufacturing\n# Engineering and Automation (IPA) nor the names of its\n# contributors may be used to endorse or promote products derived from\n# this software without specific prior written permission. \\n\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU Lesser General Public License LGPL as\n# published by the Free Software Foundation, either version 3 of the\n# License, or (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n# GNU Lesser General Public License LGPL for more details.\n#\n# You should have received a copy of the GNU Lesser General Public\n# License LGPL along with this program.\n# If not, see <http://www.gnu.org/licenses/>.\n#\n#****************************************************************/\nimport actionlib\nimport rospy\nimport sys\nimport cv2\nimport yaml\nimport os\nfrom yaml import load\n# from cv_bridge import CvBridge, CvBridgeError\nfrom ipa_pars_main.msg._LogicPlanAction import *\nfrom ipa_pars_main.msg._PlanSolverAction import *\nfrom ipa_pars_main.msg._KnowledgeParserAction import *\nfrom ipa_pars_main.msg._PlanExecutorAction import *\nfrom std_msgs.msg import String\n#from std_msgs import String[]\n# import numpy as np\n# from sensor_msgs.msg._Image import Image\n# import sensor_msgs.msg\n# from map_analyzer.srv import MapAnalyzer\n# from cob_srvs.srv._SetString import SetString\n# from map_analyzer.srv._MapAnalyzer import MapAnalyzerResponse\n# from ipa_pars_main.srv._PlanData import PlanData, PlanDataRequest\nclass PlanningServer(object):\n    _feedback = ipa_pars_main.msg.LogicPlanFeedback()\n    _result = ipa_pars_main.msg.LogicPlanResult()\n    def __init__(self):\n        rospy.loginfo(\"Initialize PlanningServer ...\")\n        self._planningSolverClient = actionlib.SimpleActionClient('planning_solver_server', PlanSolverAction)\n        rospy.logwarn(\"Waiting for PlanSolverServer to come available ...\")\n        self._planningSolverClient.wait_for_server()\n        rospy.logwarn(\"PlanningSolverServer is online!\")\n        self._knowledgeParserClient = actionlib.SimpleActionClient('knowledge_parser_server', KnowledgeParserAction)\n        rospy.logwarn(\"Waiting for KnowledgeParserServer to come available ...\")\n        self._knowledgeParserClient.wait_for_server()\n        rospy.loginfo(\"Read static and dynamic knowledge from file\")\n        self._static_knowledge = yaml.dump(self.readKnowledgeBase(\"static-knowledge-base.yaml\"))\n        self._dynamic_knowledge = yaml.dump(self.readKnowledgeBase(\"dynamic-knowledge-base.yaml\"))\n        rospy.logwarn(\"KnowledgeParserServer is online!\")\n        self._planningExecutorClient = actionlib.SimpleActionClient('planning_executor_server', PlanExecutorAction)\n        rospy.logwarn(\"Waiting for PlanExecutorServer to come available ...\")\n        self._planningExecutorClient.wait_for_server()\n        rospy.logwarn(\"PlanExecutorServer is online!\")\n        self._as = actionlib.SimpleActionServer('planning_server', ipa_pars_main.msg.LogicPlanAction, execute_cb=self.execute_cb, auto_start=False)\n        self._as.start()\n        rospy.loginfo(\"PlanningServer running! Waiting for a new goal.\")\n    def execute_cb(self, goal):\n        rospy.loginfo(\"Executing a new goal!\")\n        rospy.loginfo(\"GOAL: %s , %s, %s \" % (str(goal.goal_type), str(goal.what), str(goal.where)))\n        rospy.loginfo(\"in progress ...\")\n        success = False\n        \n        while not (success):\n            knowledge_parser_result = self.workOnKnowledge()\n            print knowledge_parser_result\n            planning_solver_result = self.workOnPlan(knowledge_parser_result.problem_pddl.data, knowledge_parser_result.domain_pddl.data)\n            print planning_solver_result\n            planning_executor_result = self.executeActionPlan(planning_solver_result.action_list)\n            print \"This came back from PlanningExecutor:\"\n            print planning_executor_result\n            self._dynamic_knowledge = planning_executor_result.dynamic_knowledge.data\n            if planning_executor_result.success:\n                success = True\n                break\n        print \"i am sleeping now\"\n        success = True\n        rospy.sleep(5)\n        #===========================\n        if self._as.is_preempt_requested():\n            rospy.loginfo('%s: Preempted' % 'pars_server')\n            success = False\n        if success:\n            self._result.success = True\n            rospy.loginfo(\"Succeeded the Logic Plan\")\n            self._as.set_succeeded(self._result, \"good job\")\n    def workOnKnowledge(self):\n        knowledge_goal = ipa_pars_main.msg.KnowledgeParserGoal()\n        knowledge_goal.static_knowledge.data = self._static_knowledge\n        print knowledge_goal.static_knowledge.data\n        knowledge_goal.dynamic_knowledge.data = self._dynamic_knowledge\n        rospy.loginfo(\"Sending goal to KnowledgeParserServer ...\")\n        self._knowledgeParserClient.send_goal(knowledge_goal)\n        rospy.loginfo(\"Waiting for result ...\")\n        self._knowledgeParserClient.wait_for_result()\n        result = self._knowledgeParserClient.get_result()\n        rospy.loginfo(\"Received the result from KnowledgeParserServer!\")\n        return result\n    def readKnowledgeBase(self, knowledge_yaml):\n        listOfInput = []\n        try:\n            if os.path.isdir(\"ipa_pars/knowledge/\"):\n                fileObject = open(\"ipa_pars/knowledge/\"+knowledge_yaml, \"r\")\n                yamlfile = load(fileObject)\n                fileObject.close()\n                return yamlfile\n        except IOError:\n            rospy.loginfo(\"Reading %s base failed!\" % knowledge_yaml)\n        return None\n    def workOnPlan(self, domain, problem):\n        goal = ipa_pars_main.msg.PlanSolverGoal()\n        goal.problem.data = problem\n        goal.domain.data = domain\n        rospy.loginfo(\"Sending goal to solver ...\")\n        self._planningSolverClient.send_goal(goal)\n        rospy.loginfo(\"Waiting for result ...\")\n        self._planningSolverClient.wait_for_result()\n        result = self._planningSolverClient.get_result()\n        rospy.loginfo(\"Received the result from Solver:\")\n        return result\n    def executeActionPlan(self, actionplan):\n        goal = ipa_pars_main.msg.PlanExecutorGoal()\n        #read goals for debug from file\n        listOfInput = []\n        for itm in actionplan:\n            listOfInput.append(itm.data)\n        print \"this is the action list to send\"\n        #delete last element\n        #del listOfInput[-1:]\n        print listOfInput\n        listOfOutput = []\n        for action_exe in listOfInput:\n            new_action = String()\n            new_action.data = action_exe.replace(\"(\",\"\").replace(\")\",\"\")\n            listOfOutput.append(new_action)\n        print listOfOutput\n        goal.action_list = listOfOutput\n        rospy.loginfo(\"Send action list to PlanExecutorServer ...\")\n        self._planningExecutorClient.send_goal(goal)\n        rospy.loginfo(\"Waiting for result of PlanExecutorServer ...\")\n        self._planningExecutorClient.wait_for_result()\n", "outputs": ["        result = self._planningExecutorClient.get_result()"], "input_length": 1398, "output_length": 5, "length": 1403, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "d6c81be82b8586e9aa4b7d0fc326557e3dd651490ccb463a1a2465b93f65b1b3"}
{"input": "", "context": "//#############################################################################\n//#                                                                           #\n//#  Copyright (C) <2015>  <IMS MAXIMS>                                       #\n//#                                                                           #\n//#  This program is free software: you can redistribute it and/or modify     #\n//#  it under the terms of the GNU Affero General Public License as           #\n//#  published by the Free Software Foundation, either version 3 of the       #\n//#  License, or (at your option) any later version.                          # \n//#                                                                           #\n//#  This program is distributed in the hope that it will be useful,          #\n//#  but WITHOUT ANY WARRANTY; without even the implied warranty of           #\n//#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the            #\n//#  GNU Affero General Public License for more details.                      #\n//#                                                                           #\n//#  You should have received a copy of the GNU Affero General Public License #\n//#  along with this program.  If not, see <http://www.gnu.org/licenses/>.    #\n//#                                                                           #\n//#  IMS MAXIMS provides absolutely NO GUARANTEE OF THE CLINICAL SAFTEY of    #\n//#  this program.  Users of this software do so entirely at their own risk.  #\n//#  IMS MAXIMS only ensures the Clinical Safety of unaltered run-time        #\n//#  software that it builds, deploys and maintains.                          #\n//#                                                                           #\n//#############################################################################\n//#EOH\n// This code was generated by Barbara Worwood using IMS Development Environment (version 1.80 build 5589.25814)\n// Copyright (C) 1995-2015 IMS MAXIMS. All rights reserved.\n// WARNING: DO NOT MODIFY the content of this file\npackage ims.clinical.forms.edischargeallergiesetccomponent;\nimport ims.framework.*;\nimport ims.framework.controls.*;\nimport ims.framework.enumerations.*;\nimport ims.framework.utils.RuntimeAnchoring;\npublic class GenForm extends FormBridge\n{\n\tprivate static final long serialVersionUID = 1L;\n\tprotected void fireCustomControlValueChanged()\n\t{\n\t\tsuper.fireValueChanged();\n\t}\n\tpublic boolean canProvideData(IReportSeed[] reportSeeds)\n\t{\n\t\treturn new ReportDataProvider(reportSeeds, this.getFormReportFields()).canProvideData();\n\t}\n\tpublic boolean hasData(IReportSeed[] reportSeeds)\n\t{\n\t\treturn new ReportDataProvider(reportSeeds, this.getFormReportFields()).hasData();\n\t}\n\tpublic IReportField[] getData(IReportSeed[] reportSeeds)\n\t{\n\t\treturn getData(reportSeeds, false);\n\t}\n\tpublic IReportField[] getData(IReportSeed[] reportSeeds, boolean excludeNulls)\n\t{\n\t\treturn new ReportDataProvider(reportSeeds, this.getFormReportFields(), excludeNulls).getData();\n\t}\n\tpublic static class ctnAlertContainer extends ContainerBridge\n\t{\n\t\tprivate static final long serialVersionUID = 1L;\n\t\tpublic static class cmbAlertCategoryComboBox extends ComboBoxBridge\n\t\t{\n\t\t\tprivate static final long serialVersionUID = 1L;\n\t\t\t\n\t\t\tpublic void newRow(ims.core.vo.lookups.AlertType value, String text)\n\t\t\t{\n\t\t\t\tsuper.control.newRow(value, text);\n\t\t\t}\n\t\t\tpublic void newRow(ims.core.vo.lookups.AlertType value, String text, ims.framework.utils.Image image)\n\t\t\t{\n\t\t\t\tsuper.control.newRow(value, text, image);\n\t\t\t}\n\t\t\tpublic void newRow(ims.core.vo.lookups.AlertType value, String text, ims.framework.utils.Color textColor)\n\t\t\t{\n\t\t\t\tsuper.control.newRow(value, text, textColor);\n\t\t\t}\n\t\t\tpublic void newRow(ims.core.vo.lookups.AlertType value, String text, ims.framework.utils.Image image, ims.framework.utils.Color textColor)\n\t\t\t{\n\t\t\t\tsuper.control.newRow(value, text, image, textColor);\n\t\t\t}\n\t\t\tpublic boolean removeRow(ims.core.vo.lookups.AlertType value)\n\t\t\t{\n\t\t\t\treturn super.control.removeRow(value);\n\t\t\t}\n\t\t\tpublic ims.core.vo.lookups.AlertType getValue()\n\t\t\t{\n\t\t\t\treturn (ims.core.vo.lookups.AlertType)super.control.getValue();\n\t\t\t}\n\t\t\tpublic void setValue(ims.core.vo.lookups.AlertType value)\n\t\t\t{\n\t\t\t\tsuper.control.setValue(value);\n\t\t\t}\n\t\t}\n\t\tpublic static class cmbAlertAlertComboBox extends ComboBoxBridge\n\t\t{\n\t\t\tprivate static final long serialVersionUID = 1L;\n\t\t\t\n\t\t\tpublic void newRow(ims.core.vo.lookups.AlertType value, String text)\n\t\t\t{\n\t\t\t\tsuper.control.newRow(value, text);\n\t\t\t}\n\t\t\tpublic void newRow(ims.core.vo.lookups.AlertType value, String text, ims.framework.utils.Image image)\n\t\t\t{\n\t\t\t\tsuper.control.newRow(value, text, image);\n\t\t\t}\n\t\t\tpublic void newRow(ims.core.vo.lookups.AlertType value, String text, ims.framework.utils.Color textColor)\n\t\t\t{\n\t\t\t\tsuper.control.newRow(value, text, textColor);\n\t\t\t}\n\t\t\tpublic void newRow(ims.core.vo.lookups.AlertType value, String text, ims.framework.utils.Image image, ims.framework.utils.Color textColor)\n\t\t\t{\n\t\t\t\tsuper.control.newRow(value, text, image, textColor);\n\t\t\t}\n\t\t\tpublic boolean removeRow(ims.core.vo.lookups.AlertType value)\n\t\t\t{\n\t\t\t\treturn super.control.removeRow(value);\n\t\t\t}\n\t\t\tpublic ims.core.vo.lookups.AlertType getValue()\n\t\t\t{\n\t\t\t\treturn (ims.core.vo.lookups.AlertType)super.control.getValue();\n\t\t\t}\n\t\t\tpublic void setValue(ims.core.vo.lookups.AlertType value)\n\t\t\t{\n\t\t\t\tsuper.control.setValue(value);\n\t\t\t}\n\t\t}\n\t\tpublic static class cmbAlertSourceComboBox extends ComboBoxBridge\n\t\t{\n\t\t\tprivate static final long serialVersionUID = 1L;\n\t\t\t\n\t\t\tpublic void newRow(ims.core.vo.lookups.SourceofInformation value, String text)\n\t\t\t{\n\t\t\t\tsuper.control.newRow(value, text);\n\t\t\t}\n\t\t\tpublic void newRow(ims.core.vo.lookups.SourceofInformation value, String text, ims.framework.utils.Image image)\n\t\t\t{\n\t\t\t\tsuper.control.newRow(value, text, image);\n\t\t\t}\n\t\t\tpublic void newRow(ims.core.vo.lookups.SourceofInformation value, String text, ims.framework.utils.Color textColor)\n\t\t\t{\n\t\t\t\tsuper.control.newRow(value, text, textColor);\n\t\t\t}\n\t\t\tpublic void newRow(ims.core.vo.lookups.SourceofInformation value, String text, ims.framework.utils.Image image, ims.framework.utils.Color textColor)\n\t\t\t{\n\t\t\t\tsuper.control.newRow(value, text, image, textColor);\n\t\t\t}\n\t\t\tpublic boolean removeRow(ims.core.vo.lookups.SourceofInformation value)\n\t\t\t{\n\t\t\t\treturn super.control.removeRow(value);\n\t\t\t}\n\t\t\tpublic ims.core.vo.lookups.SourceofInformation getValue()\n\t\t\t{\n\t\t\t\treturn (ims.core.vo.lookups.SourceofInformation)super.control.getValue();\n\t\t\t}\n\t\t\tpublic void setValue(ims.core.vo.lookups.SourceofInformation value)\n\t\t\t{\n\t\t\t\tsuper.control.setValue(value);\n\t\t\t}\n\t\t}\n\t\tprotected void setContext(Form form, ims.framework.interfaces.IAppForm appForm, Control control, FormLoader loader, Images form_images_local, ContextMenus contextMenus, Integer startControlID, ims.framework.utils.SizeInfo designSize, ims.framework.utils.SizeInfo runtimeSize, Integer startTabIndex, boolean skipContextValidation) throws Exception\n\t\t{\n\t\t\tif(form == null)\n\t\t\t\tthrow new RuntimeException(\"Invalid form\");\n\t\t\tif(appForm == null)\n\t\t\t\tthrow new RuntimeException(\"Invalid application form\");\n\t\t\tif(control == null); // this is to avoid eclipse warning only.\n\t\t\tif(loader == null); // this is to avoid eclipse warning only.\n\t\t\tif(form_images_local == null); // this is to avoid eclipse warning only.\n\t\t\tif(contextMenus == null); // this is to avoid eclipse warning only.\n\t\t\tif(startControlID == null)\n\t\t\t\tthrow new RuntimeException(\"Invalid startControlID\");\n\t\t\tif(designSize == null); // this is to avoid eclipse warning only.\n\t\t\tif(runtimeSize == null); // this is to avoid eclipse warning only.\n\t\t\tif(startTabIndex == null)\n\t\t\t\tthrow new RuntimeException(\"Invalid startTabIndex\");\n\t\n\t\n\t\t\t// Custom Controls\n\t\t\tims.framework.CustomComponent instance1 = factory.getEmptyCustomComponent();\n\t\t\tRuntimeAnchoring anchoringHelper1 = new RuntimeAnchoring(designSize, runtimeSize, 448, 56, 344, 56, ims.framework.enumerations.ControlAnchoring.TOPLEFTRIGHT);\n\t\t\tims.framework.FormUiLogic m_ccAlertAuthorForm = loader.loadComponent(102228, appForm, startControlID * 10 + 1000, anchoringHelper1.getSize(), instance1, startTabIndex.intValue() + 22, skipContextValidation);\n\t\t\t//ims.framework.Control m_ccAlertAuthorControl = factory.getControl(CustomComponent.class, new Object[] { control, new Integer(startControlID.intValue() + 1000), new Integer(448), new Integer(56), new Integer(344), new Integer(56), ControlState.DISABLED, ControlState.UNKNOWN, ims.framework.enumerations.ControlAnchoring.TOPLEFTRIGHT, new Integer(startTabIndex.intValue() + 22), m_ccAlertAuthorForm, instance1 } );\n\t\t\tims.framework.Control m_ccAlertAuthorControl = factory.getControl(CustomComponent.class, new Object[] { control, new Integer(startControlID.intValue() + 1001),  new Integer(anchoringHelper1.getX()), new Integer(anchoringHelper1.getY()), new Integer(anchoringHelper1.getWidth()), new Integer(anchoringHelper1.getHeight()), ControlState.DISABLED, ControlState.UNKNOWN, ims.framework.enumerations.ControlAnchoring.TOPLEFTRIGHT, new Integer(startTabIndex.intValue() + 22), m_ccAlertAuthorForm, instance1, Boolean.FALSE } );\n\t\t\tsuper.addControl(m_ccAlertAuthorControl);\n\t\t\tMenu[] menus1 = m_ccAlertAuthorForm.getForm().getRegisteredMenus();\n\t\t\tfor(int x = 0; x < menus1.length; x++)\n\t\t\t{\n\t\t\t\tform.registerMenu(menus1[x]);\n\t\t\t}\n\t\n\t\t\t// Label Controls\n\t\t\tRuntimeAnchoring anchoringHelper2 = new RuntimeAnchoring(designSize, runtimeSize, 8, 8, 60, 17, ims.framework.enumerations.ControlAnchoring.TOPLEFT);\n\t\t\tsuper.addControl(factory.getControl(Label.class, new Object[] { control, new Integer(startControlID.intValue() + 1002), new Integer(anchoringHelper2.getX()), new Integer(anchoringHelper2.getY()), new Integer(anchoringHelper2.getWidth()), new Integer(anchoringHelper2.getHeight()), ControlState.UNKNOWN, ControlState.UNKNOWN, ims.framework.enumerations.ControlAnchoring.TOPLEFT, \"Category:\", new Integer(1), null, new Integer(0)}));\n\t\t\tRuntimeAnchoring anchoringHelper3 = new RuntimeAnchoring(designSize, runtimeSize, 8, 32, 36, 17, ims.framework.enumerations.ControlAnchoring.TOPLEFT);\n\t\t\tsuper.addControl(factory.getControl(Label.class, new Object[] { control, new Integer(startControlID.intValue() + 1003), new Integer(anchoringHelper3.getX()), new Integer(anchoringHelper3.getY()), new Integer(anchoringHelper3.getWidth()), new Integer(anchoringHelper3.getHeight()), ControlState.UNKNOWN, ControlState.UNKNOWN, ims.framework.enumerations.ControlAnchoring.TOPLEFT, \"Alert:\", new Integer(1), null, new Integer(0)}));\n\t\t\tRuntimeAnchoring anchoringHelper4 = new RuntimeAnchoring(designSize, runtimeSize, 8, 56, 63, 17, ims.framework.enumerations.ControlAnchoring.TOPLEFT);\n\t\t\tsuper.addControl(factory.getControl(Label.class, new Object[] { control, new Integer(startControlID.intValue() + 1004), new Integer(anchoringHelper4.getX()), new Integer(anchoringHelper4.getY()), new Integer(anchoringHelper4.getWidth()), new Integer(anchoringHelper4.getHeight()), ControlState.UNKNOWN, ControlState.UNKNOWN, ims.framework.enumerations.ControlAnchoring.TOPLEFT, \"Comment:\", new Integer(1), null, new Integer(0)}));\n\t\t\tRuntimeAnchoring anchoringHelper5 = new RuntimeAnchoring(designSize, runtimeSize, 456, 8, 47, 17, ims.framework.enumerations.ControlAnchoring.TOPLEFT);\n\t\t\tsuper.addControl(factory.getControl(Label.class, new Object[] { control, new Integer(startControlID.intValue() + 1005), new Integer(anchoringHelper5.getX()), new Integer(anchoringHelper5.getY()), new Integer(anchoringHelper5.getWidth()), new Integer(anchoringHelper5.getHeight()), ControlState.UNKNOWN, ControlState.UNKNOWN, ims.framework.enumerations.ControlAnchoring.TOPLEFT, \"Source:\", new Integer(1), null, new Integer(0)}));\n\t\t\tRuntimeAnchoring anchoringHelper6 = new RuntimeAnchoring(designSize, runtimeSize, 456, 32, 95, 17, ims.framework.enumerations.ControlAnchoring.TOPLEFT);\n\t\t\tsuper.addControl(factory.getControl(Label.class, new Object[] { control, new Integer(startControlID.intValue() + 1006), new Integer(anchoringHelper6.getX()), new Integer(anchoringHelper6.getY()), new Integer(anchoringHelper6.getWidth()), new Integer(anchoringHelper6.getHeight()), ControlState.UNKNOWN, ControlState.UNKNOWN, ims.framework.enumerations.ControlAnchoring.TOPLEFT, \"Date Identified:\", new Integer(1), null, new Integer(0)}));\n\t\n\t\t\t// TextBox Controls\n\t\t\tRuntimeAnchoring anchoringHelper7 = new RuntimeAnchoring(designSize, runtimeSize, 120, 56, 304, 56, ims.framework.enumerations.ControlAnchoring.TOPLEFT);\n\t\t\tsuper.addControl(factory.getControl(TextBox.class, new Object[] { control, new Integer(startControlID.intValue() + 1007), new Integer(anchoringHelper7.getX()), new Integer(anchoringHelper7.getY()), new Integer(anchoringHelper7.getWidth()), new Integer(anchoringHelper7.getHeight()), new Integer(startTabIndex.intValue() + 19), ControlState.DISABLED, ControlState.UNKNOWN, ims.framework.enumerations.ControlAnchoring.TOPLEFT,Boolean.TRUE, new Integer(255), Boolean.TRUE, Boolean.FALSE, null, null, Boolean.FALSE, ims.framework.enumerations.CharacterCasing.NORMAL, ims.framework.enumerations.TextTrimming.NONE, \"\", \"\"}));\n\t\n\t\t\t// PartialDateBox Controls\n\t\t\tRuntimeAnchoring anchoringHelper8 = new RuntimeAnchoring(designSize, runtimeSize, 586, 32, 142, 20, ims.framework.enumerations.ControlAnchoring.TOPLEFT);\n\t\t\tsuper.addControl(factory.getControl(PartialDateBox.class, new Object[] { control, new Integer(startControlID.intValue() + 1008), new Integer(anchoringHelper8.getX()), new Integer(anchoringHelper8.getY()), new Integer(anchoringHelper8.getWidth()), new Integer(anchoringHelper8.getHeight()), new Integer(startTabIndex.intValue() + 21), ControlState.DISABLED, ControlState.UNKNOWN, ims.framework.enumerations.ControlAnchoring.TOPLEFT, \"Invalid date entered\", Boolean.FALSE, Boolean.FALSE}));\n\t\n\t\t\t// ComboBox Controls\n\t\t\tRuntimeAnchoring anchoringHelper9 = new RuntimeAnchoring(designSize, runtimeSize, 120, 8, 304, 21, ims.framework.enumerations.ControlAnchoring.TOPLEFT);\n\t\t\tComboBox m_cmbAlertCategoryTemp = (ComboBox)factory.getControl(ComboBox.class, new Object[] { control, new Integer(startControlID.intValue() + 1009), new Integer(anchoringHelper9.getX()), new Integer(anchoringHelper9.getY()), new Integer(anchoringHelper9.getWidth()), new Integer(anchoringHelper9.getHeight()), new Integer(startTabIndex.intValue() + 16), ControlState.DISABLED, ControlState.UNKNOWN,ims.framework.enumerations.ControlAnchoring.TOPLEFT ,Boolean.TRUE, Boolean.TRUE, SortOrder.NONE, Boolean.FALSE, new Integer(1), null, Boolean.TRUE, new Integer(-1)});\n\t\t\taddControl(m_cmbAlertCategoryTemp);\n\t\t\tcmbAlertCategoryComboBox cmbAlertCategory = (cmbAlertCategoryComboBox)ComboBoxFlyweightFactory.getInstance().createComboBoxBridge(cmbAlertCategoryComboBox.class, m_cmbAlertCategoryTemp);\n\t\t\tsuper.addComboBox(cmbAlertCategory);\n\t\t\tRuntimeAnchoring anchoringHelper10 = new RuntimeAnchoring(designSize, runtimeSize, 120, 32, 304, 21, ims.framework.enumerations.ControlAnchoring.TOPLEFT);\n\t\t\tComboBox m_cmbAlertAlertTemp = (ComboBox)factory.getControl(ComboBox.class, new Object[] { control, new Integer(startControlID.intValue() + 1010), new Integer(anchoringHelper10.getX()), new Integer(anchoringHelper10.getY()), new Integer(anchoringHelper10.getWidth()), new Integer(anchoringHelper10.getHeight()), new Integer(startTabIndex.intValue() + 18), ControlState.DISABLED, ControlState.UNKNOWN,ims.framework.enumerations.ControlAnchoring.TOPLEFT ,Boolean.TRUE, Boolean.FALSE, SortOrder.NONE, Boolean.FALSE, new Integer(1), null, Boolean.TRUE, new Integer(-1)});\n\t\t\taddControl(m_cmbAlertAlertTemp);\n\t\t\tcmbAlertAlertComboBox cmbAlertAlert = (cmbAlertAlertComboBox)ComboBoxFlyweightFactory.getInstance().createComboBoxBridge(cmbAlertAlertComboBox.class, m_cmbAlertAlertTemp);\n\t\t\tsuper.addComboBox(cmbAlertAlert);\n\t\t\tRuntimeAnchoring anchoringHelper11 = new RuntimeAnchoring(designSize, runtimeSize, 586, 8, 191, 21, ims.framework.enumerations.ControlAnchoring.TOPLEFTRIGHT);\n\t\t\tComboBox m_cmbAlertSourceTemp = (ComboBox)factory.getControl(ComboBox.class, new Object[] { control, new Integer(startControlID.intValue() + 1011), new Integer(anchoringHelper11.getX()), new Integer(anchoringHelper11.getY()), new Integer(anchoringHelper11.getWidth()), new Integer(anchoringHelper11.getHeight()), new Integer(startTabIndex.intValue() + 20), ControlState.DISABLED, ControlState.UNKNOWN,ims.framework.enumerations.ControlAnchoring.TOPLEFTRIGHT ,Boolean.TRUE, Boolean.FALSE, SortOrder.NONE, Boolean.FALSE, new Integer(1), null, Boolean.FALSE, new Integer(-1)});\n\t\t\taddControl(m_cmbAlertSourceTemp);\n\t\t\tcmbAlertSourceComboBox cmbAlertSource = (cmbAlertSourceComboBox)ComboBoxFlyweightFactory.getInstance().createComboBoxBridge(cmbAlertSourceComboBox.class, m_cmbAlertSourceTemp);\n\t\t\tsuper.addComboBox(cmbAlertSource);\n\t\t}\n\t\tpublic ims.core.forms.authoringinfo.IComponent ccAlertAuthor()\n\t\t{\n\t\t\treturn (ims.core.forms.authoringinfo.IComponent)((ims.framework.cn.controls.CustomComponent)super.getControl(0)).getLogic();\n\t\t}\n\t\tpublic void setccAlertAuthorValueChangedEvent(ims.framework.delegates.ValueChanged delegate)\n\t\t{\n\t\t\t((CustomComponent)super.getControl(0)).setValueChangedEvent(delegate);\n\t\t}\n\t\tpublic void setccAlertAuthorVisible(boolean value)\n\t\t{\n\t\t\t((ims.framework.Control)super.getControl(0)).setVisible(value);\n\t\t}\n\t\tpublic boolean isccAlertAuthorVisible()\n\t\t{\n\t\t\treturn ((ims.framework.Control)super.getControl(0)).isVisible();\n\t\t}\n\t\tpublic void setccAlertAuthorEnabled(boolean value)\n\t\t{\n\t\t\t((ims.framework.Control)super.getControl(0)).setEnabled(value);\n\t\t}\n\t\tpublic boolean isccAlertAuthorEnabled()\n\t\t{\n\t\t\treturn ((ims.framework.Control)super.getControl(0)).isEnabled();\n\t\t}\n\t\tpublic TextBox txtAlertComment()\n\t\t{\n\t\t\treturn (TextBox)super.getControl(6);\n\t\t}\n\t\tpublic PartialDateBox pdtAlertDateIdentified()\n\t\t{\n\t\t\treturn (PartialDateBox)super.getControl(7);\n\t\t}\n\t\tpublic cmbAlertCategoryComboBox cmbAlertCategory()\n\t\t{\n\t\t\treturn (cmbAlertCategoryComboBox)super.getComboBox(0);\n\t\t}\n\t\tpublic cmbAlertAlertComboBox cmbAlertAlert()\n\t\t{\n\t\t\treturn (cmbAlertAlertComboBox)super.getComboBox(1);\n\t\t}\n\t\tpublic cmbAlertSourceComboBox cmbAlertSource()\n\t\t{\n\t\t\treturn (cmbAlertSourceComboBox)super.getComboBox(2);\n\t\t}\n\t}\n\tpublic static class ctnAllergyContainer extends ContainerBridge\n\t{\n\t\tprivate static final long serialVersionUID = 1L;\n\t\tpublic static class cmbAllergyTypeComboBox extends ComboBoxBridge\n\t\t{\n\t\t\tprivate static final long serialVersionUID = 1L;\n\t\t\t\n\t\t\tpublic void newRow(ims.core.vo.lookups.AllergenType value, String text)\n\t\t\t{\n\t\t\t\tsuper.control.newRow(value, text);\n\t\t\t}\n\t\t\tpublic void newRow(ims.core.vo.lookups.AllergenType value, String text, ims.framework.utils.Image image)\n\t\t\t{\n\t\t\t\tsuper.control.newRow(value, text, image);\n\t\t\t}\n\t\t\tpublic void newRow(ims.core.vo.lookups.AllergenType value, String text, ims.framework.utils.Color textColor)\n\t\t\t{\n\t\t\t\tsuper.control.newRow(value, text, textColor);\n\t\t\t}\n\t\t\tpublic void newRow(ims.core.vo.lookups.AllergenType value, String text, ims.framework.utils.Image image, ims.framework.utils.Color textColor)\n\t\t\t{\n\t\t\t\tsuper.control.newRow(value, text, image, textColor);\n\t\t\t}\n\t\t\tpublic boolean removeRow(ims.core.vo.lookups.AllergenType value)\n\t\t\t{\n\t\t\t\treturn super.control.removeRow(value);\n\t\t\t}\n\t\t\tpublic ims.core.vo.lookups.AllergenType getValue()\n\t\t\t{\n\t\t\t\treturn (ims.core.vo.lookups.AllergenType)super.control.getValue();\n\t\t\t}\n\t\t\tpublic void setValue(ims.core.vo.lookups.AllergenType value)\n\t\t\t{\n\t\t\t\tsuper.control.setValue(value);\n\t\t\t}\n\t\t}\n\t\tpublic static class cmbAllergyReactionComboBox extends ComboBoxBridge\n\t\t{\n\t\t\tprivate static final long serialVersionUID = 1L;\n\t\t\t\n\t\t\tpublic void newRow(ims.core.vo.lookups.AllergyReaction value, String text)\n\t\t\t{\n\t\t\t\tsuper.control.newRow(value, text);\n\t\t\t}\n\t\t\tpublic void newRow(ims.core.vo.lookups.AllergyReaction value, String text, ims.framework.utils.Image image)\n\t\t\t{\n\t\t\t\tsuper.control.newRow(value, text, image);\n\t\t\t}\n\t\t\tpublic void newRow(ims.core.vo.lookups.AllergyReaction value, String text, ims.framework.utils.Color textColor)\n\t\t\t{\n\t\t\t\tsuper.control.newRow(value, text, textColor);\n\t\t\t}\n\t\t\tpublic void newRow(ims.core.vo.lookups.AllergyReaction value, String text, ims.framework.utils.Image image, ims.framework.utils.Color textColor)\n\t\t\t{\n\t\t\t\tsuper.control.newRow(value, text, image, textColor);\n\t\t\t}\n\t\t\tpublic boolean removeRow(ims.core.vo.lookups.AllergyReaction value)\n\t\t\t{\n\t\t\t\treturn super.control.removeRow(value);\n\t\t\t}\n\t\t\tpublic ims.core.vo.lookups.AllergyReaction getValue()\n\t\t\t{\n\t\t\t\treturn (ims.core.vo.lookups.AllergyReaction)super.control.getValue();\n\t\t\t}\n\t\t\tpublic void setValue(ims.core.vo.lookups.AllergyReaction value)\n\t\t\t{\n\t\t\t\tsuper.control.setValue(value);\n\t\t\t}\n\t\t}\n\t\tpublic static class cmbAllergySourceComboBox extends ComboBoxBridge\n\t\t{\n\t\t\tprivate static final long serialVersionUID = 1L;\n\t\t\t\n\t\t\tpublic void newRow(ims.core.vo.lookups.SourceofInformation value, String text)\n\t\t\t{\n\t\t\t\tsuper.control.newRow(value, text);\n\t\t\t}\n\t\t\tpublic void newRow(ims.core.vo.lookups.SourceofInformation value, String text, ims.framework.utils.Image image)\n\t\t\t{\n\t\t\t\tsuper.control.newRow(value, text, image);\n\t\t\t}\n\t\t\tpublic void newRow(ims.core.vo.lookups.SourceofInformation value, String text, ims.framework.utils.Color textColor)\n\t\t\t{\n\t\t\t\tsuper.control.newRow(value, text, textColor);\n\t\t\t}\n\t\t\tpublic void newRow(ims.core.vo.lookups.SourceofInformation value, String text, ims.framework.utils.Image image, ims.framework.utils.Color textColor)\n\t\t\t{\n\t\t\t\tsuper.control.newRow(value, text, image, textColor);\n\t\t\t}\n\t\t\tpublic boolean removeRow(ims.core.vo.lookups.SourceofInformation value)\n\t\t\t{\n\t\t\t\treturn super.control.removeRow(value);\n\t\t\t}\n\t\t\tpublic ims.core.vo.lookups.SourceofInformation getValue()\n\t\t\t{\n\t\t\t\treturn (ims.core.vo.lookups.SourceofInformation)super.control.getValue();\n\t\t\t}\n\t\t\tpublic void setValue(ims.core.vo.lookups.SourceofInformation value)\n\t\t\t{\n\t\t\t\tsuper.control.setValue(value);\n\t\t\t}\n\t\t}\n\t\tprotected void setContext(Form form, ims.framework.interfaces.IAppForm appForm, Control control, FormLoader loader, Images form_images_local, ContextMenus contextMenus, Integer startControlID, ims.framework.utils.SizeInfo designSize, ims.framework.utils.SizeInfo runtimeSize, Integer startTabIndex, boolean skipContextValidation) throws Exception\n\t\t{\n\t\t\tif(form == null)\n\t\t\t\tthrow new RuntimeException(\"Invalid form\");\n\t\t\tif(appForm == null)\n\t\t\t\tthrow new RuntimeException(\"Invalid application form\");\n\t\t\tif(control == null); // this is to avoid eclipse warning only.\n\t\t\tif(loader == null); // this is to avoid eclipse warning only.\n\t\t\tif(form_images_local == null); // this is to avoid eclipse warning only.\n\t\t\tif(contextMenus == null); // this is to avoid eclipse warning only.\n\t\t\tif(startControlID == null)\n\t\t\t\tthrow new RuntimeException(\"Invalid startControlID\");\n\t\t\tif(designSize == null); // this is to avoid eclipse warning only.\n\t\t\tif(runtimeSize == null); // this is to avoid eclipse warning only.\n\t\t\tif(startTabIndex == null)\n\t\t\t\tthrow new RuntimeException(\"Invalid startTabIndex\");\n\t\n\t\n\t\t\t// Custom Controls\n\t\t\tims.framework.CustomComponent instance1 = factory.getEmptyCustomComponent();\n\t\t\tRuntimeAnchoring anchoringHelper12 = new RuntimeAnchoring(designSize, runtimeSize, 448, 112, 344, 56, ims.framework.enumerations.ControlAnchoring.TOPLEFTRIGHT);\n\t\t\tims.framework.FormUiLogic m_ccAllergyAuthorForm = loader.loadComponent(102228, appForm, startControlID * 10 + 2000, anchoringHelper12.getSize(), instance1, startTabIndex.intValue() + 11, skipContextValidation);\n\t\t\t//ims.framework.Control m_ccAllergyAuthorControl = factory.getControl(CustomComponent.class, new Object[] { control, new Integer(startControlID.intValue() + 1012), new Integer(448), new Integer(112), new Integer(344), new Integer(56), ControlState.DISABLED, ControlState.UNKNOWN, ims.framework.enumerations.ControlAnchoring.TOPLEFTRIGHT, new Integer(startTabIndex.intValue() + 11), m_ccAllergyAuthorForm, instance1 } );\n\t\t\tims.framework.Control m_ccAllergyAuthorControl = factory.getControl(CustomComponent.class, new Object[] { control, new Integer(startControlID.intValue() + 1013),  new Integer(anchoringHelper12.getX()), new Integer(anchoringHelper12.getY()), new Integer(anchoringHelper12.getWidth()), new Integer(anchoringHelper12.getHeight()), ControlState.DISABLED, ControlState.UNKNOWN, ims.framework.enumerations.ControlAnchoring.TOPLEFTRIGHT, new Integer(startTabIndex.intValue() + 11), m_ccAllergyAuthorForm, instance1, Boolean.FALSE } );\n\t\t\tsuper.addControl(m_ccAllergyAuthorControl);\n\t\t\tMenu[] menus1 = m_ccAllergyAuthorForm.getForm().getRegisteredMenus();\n\t\t\tfor(int x = 0; x < menus1.length; x++)\n\t\t\t{\n\t\t\t\tform.registerMenu(menus1[x]);\n\t\t\t}\n\t\t\tims.framework.CustomComponent instance2 = factory.getEmptyCustomComponent();\n\t\t\tRuntimeAnchoring anchoringHelper13 = new RuntimeAnchoring(designSize, runtimeSize, 8, 8, 784, 64, ims.framework.enumerations.ControlAnchoring.TOPLEFTRIGHT);\n\t\t\tims.framework.FormUiLogic m_ccAllergyTermForm = loader.loadComponent(123133, appForm, startControlID * 10 + 3000, anchoringHelper13.getSize(), instance2, startTabIndex.intValue() + 2, skipContextValidation);\n\t\t\t//ims.framework.Control m_ccAllergyTermControl = factory.getControl(CustomComponent.class, new Object[] { control, new Integer(startControlID.intValue() + 1014), new Integer(8), new Integer(8), new Integer(784), new Integer(64), ControlState.DISABLED, ControlState.UNKNOWN, ims.framework.enumerations.ControlAnchoring.TOPLEFTRIGHT, new Integer(startTabIndex.intValue() + 2), m_ccAllergyTermForm, instance2 } );\n\t\t\tims.framework.Control m_ccAllergyTermControl = factory.getControl(CustomComponent.class, new Object[] { control, new Integer(startControlID.intValue() + 1015),  new Integer(anchoringHelper13.getX()), new Integer(anchoringHelper13.getY()), new Integer(anchoringHelper13.getWidth()), new Integer(anchoringHelper13.getHeight()), ControlState.DISABLED, ControlState.UNKNOWN, ims.framework.enumerations.ControlAnchoring.TOPLEFTRIGHT, new Integer(startTabIndex.intValue() + 2), m_ccAllergyTermForm, instance2, Boolean.FALSE } );\n\t\t\tsuper.addControl(m_ccAllergyTermControl);\n\t\t\tMenu[] menus2 = m_ccAllergyTermForm.getForm().getRegisteredMenus();\n\t\t\tfor(int x = 0; x < menus2.length; x++)\n\t\t\t{\n\t\t\t\tform.registerMenu(menus2[x]);\n\t\t\t}\n\t\n\t\t\t// Label Controls\n\t\t\tRuntimeAnchoring anchoringHelper14 = new RuntimeAnchoring(designSize, runtimeSize, 16, 72, 36, 17, ims.framework.enumerations.ControlAnchoring.TOPLEFT);\n\t\t\tsuper.addControl(factory.getControl(Label.class, new Object[] { control, new Integer(startControlID.intValue() + 1016), new Integer(anchoringHelper14.getX()), new Integer(anchoringHelper14.getY()), new Integer(anchoringHelper14.getWidth()), new Integer(anchoringHelper14.getHeight()), ControlState.UNKNOWN, ControlState.UNKNOWN, ims.framework.enumerations.ControlAnchoring.TOPLEFT, \"Type:\", new Integer(1), null, new Integer(0)}));\n\t\t\tRuntimeAnchoring anchoringHelper15 = new RuntimeAnchoring(designSize, runtimeSize, 16, 96, 58, 17, ims.framework.enumerations.ControlAnchoring.TOPLEFT);\n\t\t\tsuper.addControl(factory.getControl(Label.class, new Object[] { control, new Integer(startControlID.intValue() + 1017), new Integer(anchoringHelper15.getX()), new Integer(anchoringHelper15.getY()), new Integer(anchoringHelper15.getWidth()), new Integer(anchoringHelper15.getHeight()), ControlState.UNKNOWN, ControlState.UNKNOWN, ims.framework.enumerations.ControlAnchoring.TOPLEFT, \"Reaction:\", new Integer(1), null, new Integer(0)}));\n\t\t\tRuntimeAnchoring anchoringHelper16 = new RuntimeAnchoring(designSize, runtimeSize, 456, 72, 47, 17, ims.framework.enumerations.ControlAnchoring.TOPLEFT);\n\t\t\tsuper.addControl(factory.getControl(Label.class, new Object[] { control, new Integer(startControlID.intValue() + 1018), new Integer(anchoringHelper16.getX()), new Integer(anchoringHelper16.getY()), new Integer(anchoringHelper16.getWidth()), new Integer(anchoringHelper16.getHeight()), ControlState.UNKNOWN, ControlState.UNKNOWN, ims.framework.enumerations.ControlAnchoring.TOPLEFT, \"Source:\", new Integer(1), null, new Integer(0)}));\n\t\t\tRuntimeAnchoring anchoringHelper17 = new RuntimeAnchoring(designSize, runtimeSize, 16, 120, 41, 17, ims.framework.enumerations.ControlAnchoring.TOPLEFT);\n\t\t\tsuper.addControl(factory.getControl(Label.class, new Object[] { control, new Integer(startControlID.intValue() + 1019), new Integer(anchoringHelper17.getX()), new Integer(anchoringHelper17.getY()), new Integer(anchoringHelper17.getWidth()), new Integer(anchoringHelper17.getHeight()), ControlState.UNKNOWN, ControlState.UNKNOWN, ims.framework.enumerations.ControlAnchoring.TOPLEFT, \"Effect:\", new Integer(1), null, new Integer(0)}));\n\t\t\tRuntimeAnchoring anchoringHelper18 = new RuntimeAnchoring(designSize, runtimeSize, 456, 96, 95, 17, ims.framework.enumerations.ControlAnchoring.TOPLEFT);\n\t\t\tsuper.addControl(factory.getControl(Label.class, new Object[] { control, new Integer(startControlID.intValue() + 1020), new Integer(anchoringHelper18.getX()), new Integer(anchoringHelper18.getY()), new Integer(anchoringHelper18.getWidth()), new Integer(anchoringHelper18.getHeight()), ControlState.UNKNOWN, ControlState.UNKNOWN, ims.framework.enumerations.ControlAnchoring.TOPLEFT, \"Date Identified:\", new Integer(1), null, new Integer(0)}));\n\t\n\t\t\t// TextBox Controls\n\t\t\tRuntimeAnchoring anchoringHelper19 = new RuntimeAnchoring(designSize, runtimeSize, 120, 120, 304, 40, ims.framework.enumerations.ControlAnchoring.TOPLEFT);\n\t\t\tsuper.addControl(factory.getControl(TextBox.class, new Object[] { control, new Integer(startControlID.intValue() + 1021), new Integer(anchoringHelper19.getX()), new Integer(anchoringHelper19.getY()), new Integer(anchoringHelper19.getWidth()), new Integer(anchoringHelper19.getHeight()), new Integer(startTabIndex.intValue() + 8), ControlState.DISABLED, ControlState.UNKNOWN, ims.framework.enumerations.ControlAnchoring.TOPLEFT,Boolean.TRUE, new Integer(250), Boolean.TRUE, Boolean.FALSE, null, null, Boolean.FALSE, ims.framework.enumerations.CharacterCasing.NORMAL, ims.framework.enumerations.TextTrimming.NONE, \"\", \"\"}));\n\t\n\t\t\t// PartialDateBox Controls\n\t\t\tRuntimeAnchoring anchoringHelper20 = new RuntimeAnchoring(designSize, runtimeSize, 586, 96, 142, 20, ims.framework.enumerations.ControlAnchoring.TOPLEFT);\n\t\t\tsuper.addControl(factory.getControl(PartialDateBox.class, new Object[] { control, new Integer(startControlID.intValue() + 1022), new Integer(anchoringHelper20.getX()), new Integer(anchoringHelper20.getY()), new Integer(anchoringHelper20.getWidth()), new Integer(anchoringHelper20.getHeight()), new Integer(startTabIndex.intValue() + 10), ControlState.DISABLED, ControlState.UNKNOWN, ims.framework.enumerations.ControlAnchoring.TOPLEFT, \"Invalid date entered\", Boolean.FALSE, Boolean.FALSE}));\n\t\n\t\t\t// ComboBox Controls\n\t\t\tRuntimeAnchoring anchoringHelper21 = new RuntimeAnchoring(designSize, runtimeSize, 120, 72, 304, 21, ims.framework.enumerations.ControlAnchoring.TOPLEFT);\n\t\t\tComboBox m_cmbAllergyTypeTemp = (ComboBox)factory.getControl(ComboBox.class, new Object[] { control, new Integer(startControlID.intValue() + 1023), new Integer(anchoringHelper21.getX()), new Integer(anchoringHelper21.getY()), new Integer(anchoringHelper21.getWidth()), new Integer(anchoringHelper21.getHeight()), new Integer(startTabIndex.intValue() + 6), ControlState.DISABLED, ControlState.UNKNOWN,ims.framework.enumerations.ControlAnchoring.TOPLEFT ,Boolean.TRUE, Boolean.TRUE, SortOrder.NONE, Boolean.FALSE, new Integer(1), null, Boolean.FALSE, new Integer(-1)});\n\t\t\taddControl(m_cmbAllergyTypeTemp);\n\t\t\tcmbAllergyTypeComboBox cmbAllergyType = (cmbAllergyTypeComboBox)ComboBoxFlyweightFactory.getInstance().createComboBoxBridge(cmbAllergyTypeComboBox.class, m_cmbAllergyTypeTemp);\n\t\t\tsuper.addComboBox(cmbAllergyType);\n\t\t\tRuntimeAnchoring anchoringHelper22 = new RuntimeAnchoring(designSize, runtimeSize, 120, 96, 304, 21, ims.framework.enumerations.ControlAnchoring.TOPLEFT);\n\t\t\tComboBox m_cmbAllergyReactionTemp = (ComboBox)factory.getControl(ComboBox.class, new Object[] { control, new Integer(startControlID.intValue() + 1024), new Integer(anchoringHelper22.getX()), new Integer(anchoringHelper22.getY()), new Integer(anchoringHelper22.getWidth()), new Integer(anchoringHelper22.getHeight()), new Integer(startTabIndex.intValue() + 7), ControlState.DISABLED, ControlState.UNKNOWN,ims.framework.enumerations.ControlAnchoring.TOPLEFT ,Boolean.TRUE, Boolean.FALSE, SortOrder.NONE, Boolean.FALSE, new Integer(1), null, Boolean.FALSE, new Integer(-1)});\n\t\t\taddControl(m_cmbAllergyReactionTemp);\n\t\t\tcmbAllergyReactionComboBox cmbAllergyReaction = (cmbAllergyReactionComboBox)ComboBoxFlyweightFactory.getInstance().createComboBoxBridge(cmbAllergyReactionComboBox.class, m_cmbAllergyReactionTemp);\n\t\t\tsuper.addComboBox(cmbAllergyReaction);\n\t\t\tRuntimeAnchoring anchoringHelper23 = new RuntimeAnchoring(designSize, runtimeSize, 586, 72, 191, 21, ims.framework.enumerations.ControlAnchoring.TOPLEFTRIGHT);\n\t\t\tComboBox m_cmbAllergySourceTemp = (ComboBox)factory.getControl(ComboBox.class, new Object[] { control, new Integer(startControlID.intValue() + 1025), new Integer(anchoringHelper23.getX()), new Integer(anchoringHelper23.getY()), new Integer(anchoringHelper23.getWidth()), new Integer(anchoringHelper23.getHeight()), new Integer(startTabIndex.intValue() + 9), ControlState.DISABLED, ControlState.UNKNOWN,ims.framework.enumerations.ControlAnchoring.TOPLEFTRIGHT ,Boolean.TRUE, Boolean.FALSE, SortOrder.NONE, Boolean.FALSE, new Integer(1), null, Boolean.TRUE, new Integer(-1)});\n\t\t\taddControl(m_cmbAllergySourceTemp);\n\t\t\tcmbAllergySourceComboBox cmbAllergySource = (cmbAllergySourceComboBox)ComboBoxFlyweightFactory.getInstance().createComboBoxBridge(cmbAllergySourceComboBox.class, m_cmbAllergySourceTemp);\n\t\t\tsuper.addComboBox(cmbAllergySource);\n\t\t}\n\t\tpublic ims.core.forms.authoringinfo.IComponent ccAllergyAuthor()\n\t\t{\n\t\t\treturn (ims.core.forms.authoringinfo.IComponent)((ims.framework.cn.controls.CustomComponent)super.getControl(0)).getLogic();\n\t\t}\n\t\tpublic void setccAllergyAuthorValueChangedEvent(ims.framework.delegates.ValueChanged delegate)\n\t\t{\n\t\t\t((CustomComponent)super.getControl(0)).setValueChangedEvent(delegate);\n\t\t}\n\t\tpublic void setccAllergyAuthorVisible(boolean value)\n\t\t{\n\t\t\t((ims.framework.Control)super.getControl(0)).setVisible(value);\n\t\t}\n\t\tpublic boolean isccAllergyAuthorVisible()\n\t\t{\n\t\t\treturn ((ims.framework.Control)super.getControl(0)).isVisible();\n\t\t}\n\t\tpublic void setccAllergyAuthorEnabled(boolean value)\n\t\t{\n\t\t\t((ims.framework.Control)super.getControl(0)).setEnabled(value);\n\t\t}\n\t\tpublic boolean isccAllergyAuthorEnabled()\n\t\t{\n\t\t\treturn ((ims.framework.Control)super.getControl(0)).isEnabled();\n\t\t}\n\t\tpublic ims.clinical.forms.clinicalcoding.IComponent ccAllergyTerm()\n\t\t{\n\t\t\treturn (ims.clinical.forms.clinicalcoding.IComponent)((ims.framework.cn.controls.CustomComponent)super.getControl(1)).getLogic();\n\t\t}\n\t\tpublic void setccAllergyTermValueChangedEvent(ims.framework.delegates.ValueChanged delegate)\n\t\t{\n\t\t\t((CustomComponent)super.getControl(1)).setValueChangedEvent(delegate);\n\t\t}\n\t\tpublic void setccAllergyTermVisible(boolean value)\n\t\t{\n\t\t\t((ims.framework.Control)super.getControl(1)).setVisible(value);\n\t\t}\n\t\tpublic boolean isccAllergyTermVisible()\n\t\t{\n\t\t\treturn ((ims.framework.Control)super.getControl(1)).isVisible();\n\t\t}\n\t\tpublic void setccAllergyTermEnabled(boolean value)\n\t\t{\n\t\t\t((ims.framework.Control)super.getControl(1)).setEnabled(value);\n\t\t}\n\t\tpublic boolean isccAllergyTermEnabled()\n\t\t{\n\t\t\treturn ((ims.framework.Control)super.getControl(1)).isEnabled();\n\t\t}\n\t\tpublic TextBox txtAllergyEffect()\n\t\t{\n\t\t\treturn (TextBox)super.getControl(7);\n\t\t}\n\t\tpublic PartialDateBox pdtAllergyDateIdentified()\n\t\t{\n\t\t\treturn (PartialDateBox)super.getControl(8);\n\t\t}\n\t\tpublic cmbAllergyTypeComboBox cmbAllergyType()\n\t\t{\n\t\t\treturn (cmbAllergyTypeComboBox)super.getComboBox(0);\n\t\t}\n\t\tpublic cmbAllergyReactionComboBox cmbAllergyReaction()\n\t\t{\n\t\t\treturn (cmbAllergyReactionComboBox)super.getComboBox(1);\n\t\t}\n\t\tpublic cmbAllergySourceComboBox cmbAllergySource()\n\t\t{\n\t\t\treturn (cmbAllergySourceComboBox)super.getComboBox(2);\n\t\t}\n\t}\n\tpublic static class grdAlertsRow extends GridRowBridge\n\t{\n\t\tprivate static final long serialVersionUID = 1L;\n\t\t\n\t\tprotected grdAlertsRow(GridRow row)\n\t\t{\n\t\t\tsuper(row);\n\t\t}\n\t\tpublic void showOpened(int column)\n\t\t{\n\t\t\tsuper.row.showOpened(column);\n\t\t}\n\t\tpublic void setColDateReadOnly(boolean value)\n\t\t{\n\t\t\tsuper.row.setReadOnly(0, value);\n\t\t}\n\t\tpublic boolean isColDateReadOnly()\n\t\t{\n\t\t\treturn super.row.isReadOnly(0);\n\t\t}\n\t\tpublic void showColDateOpened()\n\t\t{\n\t\t\tsuper.row.showOpened(0);\n\t\t}\n\t\tpublic void setTooltipForColDate(String value)\n\t\t{\n\t\t\tsuper.row.setTooltip(0, value);\n\t\t}\n\t\tpublic String getColDate()\n\t\t{\n\t\t\treturn (String)super.row.get(0);\n\t\t}\n\t\tpublic void setColDate(String value)\n\t\t{\n\t\t\tsuper.row.set(0, value);\n\t\t}\n\t\tpublic void setCellColDateTooltip(String value)\n\t\t{\n\t\t\tsuper.row.setTooltip(0, value);\n\t\t}\n\t\tpublic void setColCategoryReadOnly(boolean value)\n\t\t{\n\t\t\tsuper.row.setReadOnly(1, value);\n\t\t}\n\t\tpublic boolean isColCategoryReadOnly()\n\t\t{\n\t\t\treturn super.row.isReadOnly(1);\n\t\t}\n\t\tpublic void showColCategoryOpened()\n\t\t{\n\t\t\tsuper.row.showOpened(1);\n\t\t}\n\t\tpublic void setTooltipForColCategory(String value)\n\t\t{\n\t\t\tsuper.row.setTooltip(1, value);\n\t\t}\n\t\tpublic String getColCategory()\n\t\t{\n\t\t\treturn (String)super.row.get(1);\n\t\t}\n\t\tpublic void setColCategory(String value)\n\t\t{\n\t\t\tsuper.row.set(1, value);\n\t\t}\n\t\tpublic void setCellColCategoryTooltip(String value)\n\t\t{\n\t\t\tsuper.row.setTooltip(1, value);\n\t\t}\n\t\tpublic void setColAlertReadOnly(boolean value)\n\t\t{\n\t\t\tsuper.row.setReadOnly(2, value);\n\t\t}\n\t\tpublic boolean isColAlertReadOnly()\n\t\t{\n\t\t\treturn super.row.isReadOnly(2);\n\t\t}\n\t\tpublic void showColAlertOpened()\n\t\t{\n\t\t\tsuper.row.showOpened(2);\n\t\t}\n\t\tpublic void setTooltipForColAlert(String value)\n\t\t{\n\t\t\tsuper.row.setTooltip(2, value);\n\t\t}\n\t\tpublic String getColAlert()\n\t\t{\n\t\t\treturn (String)super.row.get(2);\n\t\t}\n\t\tpublic void setColAlert(String value)\n\t\t{\n\t\t\tsuper.row.set(2, value);\n\t\t}\n\t\tpublic void setCellColAlertTooltip(String value)\n\t\t{\n\t\t\tsuper.row.setTooltip(2, value);\n\t\t}\n\t\tpublic void setColSourceReadOnly(boolean value)\n\t\t{\n\t\t\tsuper.row.setReadOnly(3, value);\n\t\t}\n\t\tpublic boolean isColSourceReadOnly()\n\t\t{\n\t\t\treturn super.row.isReadOnly(3);\n\t\t}\n\t\tpublic void showColSourceOpened()\n\t\t{\n\t\t\tsuper.row.showOpened(3);\n\t\t}\n\t\tpublic void setTooltipForColSource(String value)\n\t\t{\n\t\t\tsuper.row.setTooltip(3, value);\n\t\t}\n\t\tpublic String getColSource()\n\t\t{\n\t\t\treturn (String)super.row.get(3);\n\t\t}\n\t\tpublic void setColSource(String value)\n\t\t{\n\t\t\tsuper.row.set(3, value);\n\t\t}\n\t\tpublic void setCellColSourceTooltip(String value)\n\t\t{\n\t\t\tsuper.row.setTooltip(3, value);\n\t\t}\n\t\tpublic void setColActiveReadOnly(boolean value)\n\t\t{\n\t\t\tsuper.row.setReadOnly(4, value);\n\t\t}\n\t\tpublic boolean isColActiveReadOnly()\n\t\t{\n\t\t\treturn super.row.isReadOnly(4);\n\t\t}\n\t\tpublic void showColActiveOpened()\n\t\t{\n\t\t\tsuper.row.showOpened(4);\n\t\t}\n\t\tpublic void setTooltipForColActive(String value)\n\t\t{\n\t\t\tsuper.row.setTooltip(4, value);\n\t\t}\n\t\tpublic ims.framework.utils.Image getColActive()\n\t\t{\n\t\t\treturn (ims.framework.utils.Image)super.row.get(4);\n\t\t}\n\t\tpublic void setColActive(ims.framework.utils.Image value)\n\t\t{\n\t\t\tsuper.row.set(4, value);\n\t\t}\n\t\tpublic void setCellColActiveTooltip(String value)\n\t\t{\n\t\t\tsuper.row.setTooltip(4, value);\n\t\t}\n\t\tpublic void setColAuditReadOnly(boolean value)\n\t\t{\n\t\t\tsuper.row.setReadOnly(5, value);\n\t\t}\n\t\tpublic boolean isColAuditReadOnly()\n\t\t{\n\t\t\treturn super.row.isReadOnly(5);\n\t\t}\n\t\tpublic void showColAuditOpened()\n\t\t{\n\t\t\tsuper.row.showOpened(5);\n\t\t}\n\t\tpublic void setTooltipForColAudit(String value)\n\t\t{\n\t\t\tsuper.row.setTooltip(5, value);\n\t\t}\n\t\tpublic ims.framework.utils.Image getColAudit()\n\t\t{\n\t\t\treturn (ims.framework.utils.Image)super.row.get(5);\n\t\t}\n\t\tpublic void setColAudit(ims.framework.utils.Image value)\n\t\t{\n\t\t\tsuper.row.set(5, value);\n\t\t}\n\t\tpublic void setCellColAuditTooltip(String value)\n\t\t{\n\t\t\tsuper.row.setTooltip(5, value);\n\t\t}\n\t\tpublic void setColIncludeReadOnly(boolean value)\n\t\t{\n\t\t\tsuper.row.setReadOnly(6, value);\n\t\t}\n\t\tpublic boolean isColIncludeReadOnly()\n\t\t{\n\t\t\treturn super.row.isReadOnly(6);\n\t\t}\n\t\tpublic void showColIncludeOpened()\n\t\t{\n\t\t\tsuper.row.showOpened(6);\n\t\t}\n\t\tpublic void setTooltipForColInclude(String value)\n\t\t{\n\t\t\tsuper.row.setTooltip(6, value);\n\t\t}\n\t\tpublic boolean getColInclude()\n\t\t{\n\t\t\treturn ((Boolean)super.row.get(6)).booleanValue();\n\t\t}\n\t\tpublic void setColInclude(boolean value)\n\t\t{\n\t\t\tsuper.row.set(6, new Boolean(value));\n\t\t}\n\t\tpublic void setCellColIncludeTooltip(String value)\n\t\t{\n\t\t\tsuper.row.setTooltip(6, value);\n\t\t}\n\t\tpublic ims.core.vo.PatientAlertEDischargeVo getValue()\n\t\t{\n\t\t\treturn (ims.core.vo.PatientAlertEDischargeVo)super.row.getValue();\n\t\t}\n\t\tpublic void setValue(ims.core.vo.PatientAlertEDischargeVo value)\n\t\t{\n\t\t\tsuper.row.setValue(value);\n\t\t}\n\t}\n\tpublic static class grdAlertsRowCollection extends GridRowCollectionBridge\n\t{\n\t\tprivate static final long serialVersionUID = 1L;\n\t\t\n\t\tprivate grdAlertsRowCollection(GridRowCollection collection)\n\t\t{\n\t\t\tsuper(collection);\n\t\t}\n\t\tpublic grdAlertsRow get(int index)\n\t\t{\n\t\t\treturn new grdAlertsRow(super.collection.get(index));\n\t\t}\n\t\tpublic grdAlertsRow newRow()\n\t\t{\n\t\t\treturn new grdAlertsRow(super.collection.newRow());\n\t\t}\n\t\tpublic grdAlertsRow newRow(boolean autoSelect)\n\t\t{\n\t\t\treturn new grdAlertsRow(super.collection.newRow(autoSelect));\n\t\t}\n\t\tpublic grdAlertsRow newRowAt(int index)\n\t\t{\n\t\t\treturn new grdAlertsRow(super.collection.newRowAt(index));\n\t\t}\n\t\tpublic grdAlertsRow newRowAt(int index, boolean autoSelect)\n\t\t{\n\t\t\treturn new grdAlertsRow(super.collection.newRowAt(index, autoSelect));\n\t\t}\n\t}\n\tpublic static class grdAlertsGrid extends GridBridge\n\t{\n\t\tprivate static final long serialVersionUID = 1L;\n\t\t\n\t\tprivate void addStringColumn(String caption, int captionAlignment, int alignment, int width, boolean readOnly, boolean bold, int sortOrder, int maxLength, boolean canGrow, ims.framework.enumerations.CharacterCasing casing)\n\t\t{\n\t\t\tsuper.grid.addStringColumn(caption, captionAlignment, alignment, width, readOnly, bold, sortOrder, maxLength, canGrow, casing);\n\t\t}\n\t\tprivate void addImageColumn(String caption, int captionAlignment, int alignment, int width, boolean canGrow, int sortOrder)\n\t\t{\n\t\t\tsuper.grid.addImageColumn(caption, captionAlignment, alignment, width, canGrow, sortOrder);\n\t\t}\n\t\tprivate void addBoolColumn(String caption, int captionAlignment, int alignment, int width, boolean readOnly, boolean autoPostBack, int sortOrder, boolean canGrow)\n\t\t{\n\t\t\tsuper.grid.addBoolColumn(caption, captionAlignment, alignment, width, readOnly, autoPostBack, sortOrder, canGrow);\n\t\t}\n\t\tpublic ims.core.vo.PatientAlertEDischargeVoCollection getValues()\n\t\t{\n\t\t\tims.core.vo.PatientAlertEDischargeVoCollection listOfValues = new ims.core.vo.PatientAlertEDischargeVoCollection();\n\t\t\tfor(int x = 0; x < this.getRows().size(); x++)\n\t\t\t{\n\t\t\t\tlistOfValues.add(this.getRows().get(x).getValue());\n\t\t\t}\n\t\t\treturn listOfValues;\n\t\t}\n\t\tpublic ims.core.vo.PatientAlertEDischargeVo getValue()\n\t\t{\n\t\t\treturn (ims.core.vo.PatientAlertEDischargeVo)super.grid.getValue();\n\t\t}\n\t\tpublic void setValue(ims.core.vo.PatientAlertEDischargeVo value)\n\t\t{\n\t\t\tsuper.grid.setValue(value);\n\t\t}\n\t\tpublic grdAlertsRow getSelectedRow()\n\t\t{\n\t\t\treturn super.grid.getSelectedRow() == null ? null : new grdAlertsRow(super.grid.getSelectedRow());\n\t\t}\n\t\tpublic int getSelectedRowIndex()\n\t\t{\n\t\t\treturn super.grid.getSelectedRowIndex();\n\t\t}\n\t\tpublic grdAlertsRowCollection getRows()\n\t\t{\n\t\t\treturn new grdAlertsRowCollection(super.grid.getRows());\n\t\t}\n\t\tpublic grdAlertsRow getRowByValue(ims.core.vo.PatientAlertEDischargeVo value)\n\t\t{\n\t\t\tGridRow row = super.grid.getRowByValue(value);\n\t\t\treturn row == null?null:new grdAlertsRow(row);\n\t\t}\n\t\tpublic void setColDateHeaderTooltip(String value)\n\t\t{\n\t\t\tsuper.grid.setColumnHeaderTooltip(0, value);\n\t\t}\n\t\tpublic String getColDateHeaderTooltip()\n\t\t{\n\t\t\treturn super.grid.getColumnHeaderTooltip(0);\n\t\t}\n\t\tpublic void setColCategoryHeaderTooltip(String value)\n\t\t{\n\t\t\tsuper.grid.setColumnHeaderTooltip(1, value);\n\t\t}\n\t\tpublic String getColCategoryHeaderTooltip()\n\t\t{\n\t\t\treturn super.grid.getColumnHeaderTooltip(1);\n\t\t}\n\t\tpublic void setColAlertHeaderTooltip(String value)\n\t\t{\n\t\t\tsuper.grid.setColumnHeaderTooltip(2, value);\n\t\t}\n\t\tpublic String getColAlertHeaderTooltip()\n\t\t{\n\t\t\treturn super.grid.getColumnHeaderTooltip(2);\n\t\t}\n\t\tpublic void setColSourceHeaderTooltip(String value)\n\t\t{\n\t\t\tsuper.grid.setColumnHeaderTooltip(3, value);\n\t\t}\n\t\tpublic String getColSourceHeaderTooltip()\n\t\t{\n\t\t\treturn super.grid.getColumnHeaderTooltip(3);\n\t\t}\n\t\tpublic void setColActiveHeaderTooltip(String value)\n\t\t{\n\t\t\tsuper.grid.setColumnHeaderTooltip(4, value);\n\t\t}\n\t\tpublic String getColActiveHeaderTooltip()\n\t\t{\n\t\t\treturn super.grid.getColumnHeaderTooltip(4);\n\t\t}\n\t\tpublic void setColAuditHeaderTooltip(String value)\n\t\t{\n\t\t\tsuper.grid.setColumnHeaderTooltip(5, value);\n\t\t}\n\t\tpublic String getColAuditHeaderTooltip()\n\t\t{\n\t\t\treturn super.grid.getColumnHeaderTooltip(5);\n\t\t}\n\t\tpublic void setColIncludeHeaderTooltip(String value)\n\t\t{\n\t\t\tsuper.grid.setColumnHeaderTooltip(6, value);\n\t\t}\n\t\tpublic String getColIncludeHeaderTooltip()\n\t\t{\n\t\t\treturn super.grid.getColumnHeaderTooltip(6);\n\t\t}\n\t}\n\tpublic static class grdAllergiesRow extends GridRowBridge\n\t{\n\t\tprivate static final long serialVersionUID = 1L;\n\t\t\n\t\tprotected grdAllergiesRow(GridRow row)\n\t\t{\n\t\t\tsuper(row);\n\t\t}\n\t\tpublic void showOpened(int column)\n\t\t{\n\t\t\tsuper.row.showOpened(column);\n\t\t}\n\t\tpublic void setColDateReadOnly(boolean value)\n\t\t{\n\t\t\tsuper.row.setReadOnly(0, value);\n\t\t}\n\t\tpublic boolean isColDateReadOnly()\n\t\t{\n\t\t\treturn super.row.isReadOnly(0);\n\t\t}\n\t\tpublic void showColDateOpened()\n\t\t{\n\t\t\tsuper.row.showOpened(0);\n\t\t}\n\t\tpublic void setTooltipForColDate(String value)\n\t\t{\n\t\t\tsuper.row.setTooltip(0, value);\n\t\t}\n\t\tpublic String getColDate()\n\t\t{\n\t\t\treturn (String)super.row.get(0);\n\t\t}\n\t\tpublic void setColDate(String value)\n\t\t{\n\t\t\tsuper.row.set(0, value);\n\t\t}\n\t\tpublic void setCellColDateTooltip(String value)\n\t\t{\n\t\t\tsuper.row.setTooltip(0, value);\n\t\t}\n\t\tpublic void setColAllergenDesReadOnly(boolean value)\n\t\t{\n\t\t\tsuper.row.setReadOnly(1, value);\n\t\t}\n\t\tpublic boolean isColAllergenDesReadOnly()\n\t\t{\n\t\t\treturn super.row.isReadOnly(1);\n\t\t}\n\t\tpublic void showColAllergenDesOpened()\n\t\t{\n\t\t\tsuper.row.showOpened(1);\n\t\t}\n\t\tpublic void setTooltipForColAllergenDes(String value)\n\t\t{\n\t\t\tsuper.row.setTooltip(1, value);\n\t\t}\n\t\tpublic String getColAllergenDes()\n\t\t{\n\t\t\treturn (String)super.row.get(1);\n\t\t}\n\t\tpublic void setColAllergenDes(String value)\n\t\t{\n\t\t\tsuper.row.set(1, value);\n\t\t}\n\t\tpublic void setCellColAllergenDesTooltip(String value)\n\t\t{\n\t\t\tsuper.row.setTooltip(1, value);\n\t\t}\n\t\tpublic void setColReactionReadOnly(boolean value)\n\t\t{\n\t\t\tsuper.row.setReadOnly(2, value);\n\t\t}\n\t\tpublic boolean isColReactionReadOnly()\n\t\t{\n\t\t\treturn super.row.isReadOnly(2);\n\t\t}\n\t\tpublic void showColReactionOpened()\n\t\t{\n\t\t\tsuper.row.showOpened(2);\n\t\t}\n\t\tpublic void setTooltipForColReaction(String value)\n\t\t{\n\t\t\tsuper.row.setTooltip(2, value);\n\t\t}\n\t\tpublic String getColReaction()\n\t\t{\n\t\t\treturn (String)super.row.get(2);\n\t\t}\n\t\tpublic void setColReaction(String value)\n\t\t{\n\t\t\tsuper.row.set(2, value);\n\t\t}\n\t\tpublic void setCellColReactionTooltip(String value)\n\t\t{\n\t\t\tsuper.row.setTooltip(2, value);\n\t\t}\n\t\tpublic void setColSourceReadOnly(boolean value)\n\t\t{\n\t\t\tsuper.row.setReadOnly(3, value);\n\t\t}\n\t\tpublic boolean isColSourceReadOnly()\n\t\t{\n\t\t\treturn super.row.isReadOnly(3);\n\t\t}\n\t\tpublic void showColSourceOpened()\n\t\t{\n\t\t\tsuper.row.showOpened(3);\n\t\t}\n\t\tpublic void setTooltipForColSource(String value)\n\t\t{\n\t\t\tsuper.row.setTooltip(3, value);\n\t\t}\n\t\tpublic String getColSource()\n\t\t{\n\t\t\treturn (String)super.row.get(3);\n\t\t}\n\t\tpublic void setColSource(String value)\n\t\t{\n\t\t\tsuper.row.set(3, value);\n\t\t}\n\t\tpublic void setCellColSourceTooltip(String value)\n\t\t{\n\t\t\tsuper.row.setTooltip(3, value);\n\t\t}\n\t\tpublic void setColIsActiveReadOnly(boolean value)\n\t\t{\n\t\t\tsuper.row.setReadOnly(4, value);\n\t\t}\n\t\tpublic boolean isColIsActiveReadOnly()\n\t\t{\n\t\t\treturn super.row.isReadOnly(4);\n\t\t}\n\t\tpublic void showColIsActiveOpened()\n\t\t{\n\t\t\tsuper.row.showOpened(4);\n\t\t}\n\t\tpublic void setTooltipForColIsActive(String value)\n\t\t{\n\t\t\tsuper.row.setTooltip(4, value);\n\t\t}\n\t\tpublic ims.framework.utils.Image getColIsActive()\n\t\t{\n\t\t\treturn (ims.framework.utils.Image)super.row.get(4);\n\t\t}\n\t\tpublic void setColIsActive(ims.framework.utils.Image value)\n\t\t{\n\t\t\tsuper.row.set(4, value);\n\t\t}\n\t\tpublic void setCellColIsActiveTooltip(String value)\n\t\t{\n\t\t\tsuper.row.setTooltip(4, value);\n\t\t}\n\t\tpublic void setColAuditReadOnly(boolean value)\n\t\t{\n\t\t\tsuper.row.setReadOnly(5, value);\n\t\t}\n\t\tpublic boolean isColAuditReadOnly()\n\t\t{\n\t\t\treturn super.row.isReadOnly(5);\n\t\t}\n\t\tpublic void showColAuditOpened()\n\t\t{\n\t\t\tsuper.row.showOpened(5);\n\t\t}\n\t\tpublic void setTooltipForColAudit(String value)\n\t\t{\n\t\t\tsuper.row.setTooltip(5, value);\n\t\t}\n\t\tpublic ims.framework.utils.Image getColAudit()\n\t\t{\n\t\t\treturn (ims.framework.utils.Image)super.row.get(5);\n\t\t}\n\t\tpublic void setColAudit(ims.framework.utils.Image value)\n\t\t{\n\t\t\tsuper.row.set(5, value);\n\t\t}\n\t\tpublic void setCellColAuditTooltip(String value)\n\t\t{\n\t\t\tsuper.row.setTooltip(5, value);\n\t\t}\n\t\tpublic void setColIncludeReadOnly(boolean value)\n\t\t{\n\t\t\tsuper.row.setReadOnly(6, value);\n\t\t}\n\t\tpublic boolean isColIncludeReadOnly()\n\t\t{\n\t\t\treturn super.row.isReadOnly(6);\n\t\t}\n\t\tpublic void showColIncludeOpened()\n\t\t{\n\t\t\tsuper.row.showOpened(6);\n\t\t}\n\t\tpublic void setTooltipForColInclude(String value)\n\t\t{\n\t\t\tsuper.row.setTooltip(6, value);\n\t\t}\n\t\tpublic boolean getColInclude()\n\t\t{\n\t\t\treturn ((Boolean)super.row.get(6)).booleanValue();\n\t\t}\n\t\tpublic void setColInclude(boolean value)\n\t\t{\n\t\t\tsuper.row.set(6, new Boolean(value));\n\t\t}\n\t\tpublic void setCellColIncludeTooltip(String value)\n\t\t{\n\t\t\tsuper.row.setTooltip(6, value);\n\t\t}\n\t\tpublic ims.core.vo.PatientAllergyEDischargeVo getValue()\n\t\t{\n\t\t\treturn (ims.core.vo.PatientAllergyEDischargeVo)super.row.getValue();\n\t\t}\n\t\tpublic void setValue(ims.core.vo.PatientAllergyEDischargeVo value)\n\t\t{\n\t\t\tsuper.row.setValue(value);\n\t\t}\n\t}\n\tpublic static class grdAllergiesRowCollection extends GridRowCollectionBridge\n\t{\n\t\tprivate static final long serialVersionUID = 1L;\n\t\t\n\t\tprivate grdAllergiesRowCollection(GridRowCollection collection)\n\t\t{\n\t\t\tsuper(collection);\n\t\t}\n\t\tpublic grdAllergiesRow get(int index)\n\t\t{\n\t\t\treturn new grdAllergiesRow(super.collection.get(index));\n\t\t}\n\t\tpublic grdAllergiesRow newRow()\n\t\t{\n\t\t\treturn new grdAllergiesRow(super.collection.newRow());\n\t\t}\n\t\tpublic grdAllergiesRow newRow(boolean autoSelect)\n\t\t{\n\t\t\treturn new grdAllergiesRow(super.collection.newRow(autoSelect));\n\t\t}\n\t\tpublic grdAllergiesRow newRowAt(int index)\n\t\t{\n\t\t\treturn new grdAllergiesRow(super.collection.newRowAt(index));\n\t\t}\n\t\tpublic grdAllergiesRow newRowAt(int index, boolean autoSelect)\n\t\t{\n\t\t\treturn new grdAllergiesRow(super.collection.newRowAt(index, autoSelect));\n\t\t}\n\t}\n\tpublic static class grdAllergiesGrid extends GridBridge\n\t{\n\t\tprivate static final long serialVersionUID = 1L;\n\t\t\n\t\tprivate void addStringColumn(String caption, int captionAlignment, int alignment, int width, boolean readOnly, boolean bold, int sortOrder, int maxLength, boolean canGrow, ims.framework.enumerations.CharacterCasing casing)\n\t\t{\n\t\t\tsuper.grid.addStringColumn(caption, captionAlignment, alignment, width, readOnly, bold, sortOrder, maxLength, canGrow, casing);\n\t\t}\n\t\tprivate void addImageColumn(String caption, int captionAlignment, int alignment, int width, boolean canGrow, int sortOrder)\n\t\t{\n\t\t\tsuper.grid.addImageColumn(caption, captionAlignment, alignment, width, canGrow, sortOrder);\n\t\t}\n\t\tprivate void addBoolColumn(String caption, int captionAlignment, int alignment, int width, boolean readOnly, boolean autoPostBack, int sortOrder, boolean canGrow)\n\t\t{\n\t\t\tsuper.grid.addBoolColumn(caption, captionAlignment, alignment, width, readOnly, autoPostBack, sortOrder, canGrow);\n\t\t}\n\t\tpublic ims.core.vo.PatientAllergyEDischargeVoCollection getValues()\n\t\t{\n\t\t\tims.core.vo.PatientAllergyEDischargeVoCollection listOfValues = new ims.core.vo.PatientAllergyEDischargeVoCollection();\n\t\t\tfor(int x = 0; x < this.getRows().size(); x++)\n\t\t\t{\n\t\t\t\tlistOfValues.add(this.getRows().get(x).getValue());\n\t\t\t}\n\t\t\treturn listOfValues;\n\t\t}\n\t\tpublic ims.core.vo.PatientAllergyEDischargeVo getValue()\n\t\t{\n\t\t\treturn (ims.core.vo.PatientAllergyEDischargeVo)super.grid.getValue();\n\t\t}\n\t\tpublic void setValue(ims.core.vo.PatientAllergyEDischargeVo value)\n\t\t{\n\t\t\tsuper.grid.setValue(value);\n\t\t}\n\t\tpublic grdAllergiesRow getSelectedRow()\n\t\t{\n\t\t\treturn super.grid.getSelectedRow() == null ? null : new grdAllergiesRow(super.grid.getSelectedRow());\n\t\t}\n\t\tpublic int getSelectedRowIndex()\n\t\t{\n\t\t\treturn super.grid.getSelectedRowIndex();\n\t\t}\n\t\tpublic grdAllergiesRowCollection getRows()\n\t\t{\n\t\t\treturn new grdAllergiesRowCollection(super.grid.getRows());\n\t\t}\n\t\tpublic grdAllergiesRow getRowByValue(ims.core.vo.PatientAllergyEDischargeVo value)\n\t\t{\n\t\t\tGridRow row = super.grid.getRowByValue(value);\n\t\t\treturn row == null?null:new grdAllergiesRow(row);\n\t\t}\n\t\tpublic void setColDateHeaderTooltip(String value)\n\t\t{\n\t\t\tsuper.grid.setColumnHeaderTooltip(0, value);\n\t\t}\n\t\tpublic String getColDateHeaderTooltip()\n\t\t{\n\t\t\treturn super.grid.getColumnHeaderTooltip(0);\n\t\t}\n\t\tpublic void setColAllergenDesHeaderTooltip(String value)\n\t\t{\n\t\t\tsuper.grid.setColumnHeaderTooltip(1, value);\n\t\t}\n\t\tpublic String getColAllergenDesHeaderTooltip()\n\t\t{\n\t\t\treturn super.grid.getColumnHeaderTooltip(1);\n\t\t}\n\t\tpublic void setColReactionHeaderTooltip(String value)\n\t\t{\n\t\t\tsuper.grid.setColumnHeaderTooltip(2, value);\n\t\t}\n\t\tpublic String getColReactionHeaderTooltip()\n\t\t{\n\t\t\treturn super.grid.getColumnHeaderTooltip(2);\n\t\t}\n\t\tpublic void setColSourceHeaderTooltip(String value)\n\t\t{\n\t\t\tsuper.grid.setColumnHeaderTooltip(3, value);\n\t\t}\n\t\tpublic String getColSourceHeaderTooltip()\n\t\t{\n\t\t\treturn super.grid.getColumnHeaderTooltip(3);\n\t\t}\n\t\tpublic void setColIsActiveHeaderTooltip(String value)\n\t\t{\n\t\t\tsuper.grid.setColumnHeaderTooltip(4, value);\n\t\t}\n\t\tpublic String getColIsActiveHeaderTooltip()\n\t\t{\n\t\t\treturn super.grid.getColumnHeaderTooltip(4);\n\t\t}\n\t\tpublic void setColAuditHeaderTooltip(String value)\n\t\t{\n\t\t\tsuper.grid.setColumnHeaderTooltip(5, value);\n\t\t}\n\t\tpublic String getColAuditHeaderTooltip()\n\t\t{\n\t\t\treturn super.grid.getColumnHeaderTooltip(5);\n\t\t}\n\t\tpublic void setColIncludeHeaderTooltip(String value)\n\t\t{\n\t\t\tsuper.grid.setColumnHeaderTooltip(6, value);\n\t\t}\n\t\tpublic String getColIncludeHeaderTooltip()\n\t\t{\n\t\t\treturn super.grid.getColumnHeaderTooltip(6);\n\t\t}\n\t}\n\tprivate void validateContext(ims.framework.Context context)\n\t{\n\t\tif(context == null)\n\t\t\treturn;\n\t\tif(!context.isValidContextType(ims.core.vo.CareContextShortVo.class))\n\t\t\tthrow new ims.framework.exceptions.CodingRuntimeException(\"The type 'ims.core.vo.CareContextShortVo' of the global context variable 'Core.CurrentCareContext' is not supported.\");\n\t\tif(!context.isValidContextType(ims.core.vo.PatientShort.class))\n\t\t\tthrow new ims.framework.exceptions.CodingRuntimeException(\"The type 'ims.core.vo.PatientShort' of the global context variable 'Core.PatientShort' is not supported.\");\n\t\tif(!context.isValidContextType(ims.core.vo.EpisodeofCareShortVo.class))\n\t\t\tthrow new ims.framework.exceptions.CodingRuntimeException(\"The type 'ims.core.vo.EpisodeofCareShortVo' of the global context variable 'Core.EpisodeofCareShort' is not supported.\");\n\t}\n\tprivate void validateMandatoryContext(Context context)\n\t{\n\t\tif(new ims.framework.ContextVariable(\"Core.CurrentCareContext\", \"_cvp_Core.CurrentCareContext\").getValueIsNull(context))\n\t\t\tthrow new ims.framework.exceptions.FormMandatoryContextMissingException(\"The required context data 'Core.CurrentCareContext' is not available.\");\n\t\tif(new ims.framework.ContextVariable(\"Core.PatientShort\", \"_cvp_Core.PatientShort\").getValueIsNull(context))\n\t\t\tthrow new ims.framework.exceptions.FormMandatoryContextMissingException(\"The required context data 'Core.PatientShort' is not available.\");\n\t\tif(new ims.framework.ContextVariable(\"Core.EpisodeofCareShort\", \"_cvp_Core.EpisodeofCareShort\").getValueIsNull(context))\n\t\t\tthrow new ims.framework.exceptions.FormMandatoryContextMissingException(\"The required context data 'Core.EpisodeofCareShort' is not available.\");\n\t}\n\tpublic boolean supportsRecordedInError()\n\t{\n\t\treturn false;\n\t}\n\tpublic ims.vo.ValueObject getRecordedInErrorVo()\n\t{\n\t\treturn null;\n\t}\n\tprotected void setContext(FormLoader loader, Form form, ims.framework.interfaces.IAppForm appForm, UIFactory factory, Context context) throws Exception\n\t{\n\t\tsetContext(loader, form, appForm, factory, context, Boolean.FALSE, new Integer(0), null, null, new Integer(0));\n\t}\n\tprotected void setContext(FormLoader loader, Form form, ims.framework.interfaces.IAppForm appForm, UIFactory factory, Context context, Boolean skipContextValidation) throws Exception\n\t{\n\t\tsetContext(loader, form, appForm, factory, context, skipContextValidation, new Integer(0), null, null, new Integer(0));\n\t}\n\tprotected void setContext(FormLoader loader, Form form, ims.framework.interfaces.IAppForm appForm, UIFactory factory, ims.framework.Context context, Boolean skipContextValidation, Integer startControlID, ims.framework.utils.SizeInfo runtimeSize, ims.framework.Control control, Integer startTabIndex) throws Exception\n\t{\n\t\tif(loader == null); // this is to avoid eclipse warning only.\n\t\tif(factory == null); // this is to avoid eclipse warning only.\n\t\tif(runtimeSize == null); // this is to avoid eclipse warning only.\n\t\tif(appForm == null)\n\t\t\tthrow new RuntimeException(\"Invalid application form\");\n\t\tif(startControlID == null)\n\t\t\tthrow new RuntimeException(\"Invalid startControlID\");\n\t\tif(control == null); // this is to avoid eclipse warning only.\n\t\tif(startTabIndex == null)\n\t\t\tthrow new RuntimeException(\"Invalid startTabIndex\");\n\t\tthis.context = context;\n\t\tthis.componentIdentifier = startControlID.toString();\n\t\tthis.formInfo = form.getFormInfo();\n\t\tthis.globalContext = new GlobalContext(context);\n\t\n\t\tif(skipContextValidation == null || !skipContextValidation.booleanValue())\n\t\t{\n\t\t\tvalidateContext(context);\n\t\t\tvalidateMandatoryContext(context);\n\t\t}\n\t\n\t\tsuper.setContext(form);\n\t\tims.framework.utils.SizeInfo designSize = new ims.framework.utils.SizeInfo(848, 632);\n\t\tif(runtimeSize == null)\n\t\t\truntimeSize = designSize;\n\t\tform.setWidth(runtimeSize.getWidth());\n\t\tform.setHeight(runtimeSize.getHeight());\n\t\tsuper.setFormReferences(FormReferencesFlyweightFactory.getInstance().create(Forms.class));\n\t\tsuper.setImageReferences(ImageReferencesFlyweightFactory.getInstance().create(Images.class));\n\t\tsuper.setGlobalContext(ContextBridgeFlyweightFactory.getInstance().create(GlobalContextBridge.class, context, false));\n\t\tsuper.setLocalContext(new LocalContext(context, form.getFormInfo(), componentIdentifier));\n\t\t// Context Menus\n\t\tcontextMenus = new ContextMenus();\n\t\tcontextMenus.Clinical.contextMenuEdischargeAlertsEtc = factory.createMenu(startControlID.intValue() + 1);\n\t\tcontextMenus.Clinical.contextMenuEdischargeAlertsEtcNewItem = factory.createMenuItem(startControlID.intValue() + 1, \"New Alert\", true, false, new Integer(102179), true, false);\n\t\tif(factory.getUIEngine().getLoggedInRole().hasMenuActionRight(appForm, new ims.framework.MenuAction(4400001)))\n\t\t\tcontextMenus.Clinical.contextMenuEdischargeAlertsEtc.add(contextMenus.Clinical.contextMenuEdischargeAlertsEtcNewItem);\n\t\tcontextMenus.Clinical.contextMenuEdischargeAlertsEtcEditItem = factory.createMenuItem(startControlID.intValue() + 2, \"Edit Alert\", true, false, new Integer(102150), true, false);\n\t\tif(factory.getUIEngine().getLoggedInRole().hasMenuActionRight(appForm, new ims.framework.MenuAction(4400002)))\n\t\t\tcontextMenus.Clinical.contextMenuEdischargeAlertsEtc.add(contextMenus.Clinical.contextMenuEdischargeAlertsEtcEditItem);\n\t\tform.registerMenu(contextMenus.Clinical.contextMenuEdischargeAlertsEtc);\n\t\tcontextMenus.Clinical.contextMenuEdischargeAllergiesEtc = factory.createMenu(startControlID.intValue() + 2);\n\t\tcontextMenus.Clinical.contextMenuEdischargeAllergiesEtcNewItem = factory.createMenuItem(startControlID.intValue() + 3, \"New Allergy\", true, false, new Integer(102179), true, false);\n\t\tif(factory.getUIEngine().getLoggedInRole().hasMenuActionRight(appForm, new ims.framework.MenuAction(4390001)))\n\t\t\tcontextMenus.Clinical.contextMenuEdischargeAllergiesEtc.add(contextMenus.Clinical.contextMenuEdischargeAllergiesEtcNewItem);\n\t\tcontextMenus.Clinical.contextMenuEdischargeAllergiesEtcEditItem = factory.createMenuItem(startControlID.intValue() + 4, \"Edit Allergy\", true, false, new Integer(102150), true, false);\n\t\tif(factory.getUIEngine().getLoggedInRole().hasMenuActionRight(appForm, new ims.framework.MenuAction(4390002)))\n\t\t\tcontextMenus.Clinical.contextMenuEdischargeAllergiesEtc.add(contextMenus.Clinical.contextMenuEdischargeAllergiesEtcEditItem);\n\t\tform.registerMenu(contextMenus.Clinical.contextMenuEdischargeAllergiesEtc);\n\t\t// Panel Controls\n\t\tRuntimeAnchoring anchoringHelper24 = new RuntimeAnchoring(designSize, runtimeSize, 8, 328, 832, 24, ims.framework.enumerations.ControlAnchoring.TOPLEFTRIGHT);\n\t\tsuper.addControl(factory.getControl(Panel.class, new Object[] { control, new Integer(startControlID.intValue() + 1026), new Integer(anchoringHelper24.getX()), new Integer(anchoringHelper24.getY()), new Integer(anchoringHelper24.getWidth()), new Integer(anchoringHelper24.getHeight()), ControlState.UNKNOWN, ControlState.UNKNOWN, ims.framework.enumerations.ControlAnchoring.TOPLEFTRIGHT,\"Alerts\", new Integer(1), \"\"}));\n\t\tRuntimeAnchoring anchoringHelper25 = new RuntimeAnchoring(designSize, runtimeSize, 8, 0, 832, 24, ims.framework.enumerations.ControlAnchoring.TOPLEFTRIGHT);\n\t\tsuper.addControl(factory.getControl(Panel.class, new Object[] { control, new Integer(startControlID.intValue() + 1027), new Integer(anchoringHelper25.getX()), new Integer(anchoringHelper25.getY()), new Integer(anchoringHelper25.getWidth()), new Integer(anchoringHelper25.getHeight()), ControlState.UNKNOWN, ControlState.UNKNOWN, ims.framework.enumerations.ControlAnchoring.TOPLEFTRIGHT,\"Allergies\", new Integer(1), \"\"}));\n\t\t// Container Clasess\n\t\tRuntimeAnchoring anchoringHelper26 = new RuntimeAnchoring(designSize, runtimeSize, 24, 440, 808, 152, ims.framework.enumerations.ControlAnchoring.ALL);\n\t\tContainer m_ctnAlert = (Container)factory.getControl(Container.class, new Object[] { control, new Integer(startControlID.intValue() + 1028), new Integer(anchoringHelper26.getX()), new Integer(anchoringHelper26.getY()), new Integer(anchoringHelper26.getWidth()), new Integer(anchoringHelper26.getHeight()), ControlState.UNKNOWN, ControlState.UNKNOWN, ims.framework.enumerations.ControlAnchoring.ALL, null, new Boolean(false)});\n\t\taddControl(m_ctnAlert);\n\t\tctnAlertContainer ctnAlert = (ctnAlertContainer)ContainerBridgeFlyweightFactory.getInstance().createContainerBridge(ctnAlertContainer.class, m_ctnAlert, factory);\n\t\tims.framework.utils.SizeInfo m_ctnAlertDesignSize = new ims.framework.utils.SizeInfo(808, 152);\n\t\tims.framework.utils.SizeInfo m_ctnAlertRuntimeSize = new ims.framework.utils.SizeInfo(anchoringHelper26.getWidth(), anchoringHelper26.getHeight());\n\t\tctnAlert.setContext(form, appForm, m_ctnAlert, loader, this.getImages(), contextMenus, startControlID, m_ctnAlertDesignSize, m_ctnAlertRuntimeSize, startTabIndex, skipContextValidation);\n\t\tsuper.addContainer(ctnAlert);\n\t\tRuntimeAnchoring anchoringHelper27 = new RuntimeAnchoring(designSize, runtimeSize, 24, 144, 816, 176, ims.framework.enumerations.ControlAnchoring.TOPLEFTRIGHT);\n\t\tContainer m_ctnAllergy = (Container)factory.getControl(Container.class, new Object[] { control, new Integer(startControlID.intValue() + 1029), new Integer(anchoringHelper27.getX()), new Integer(anchoringHelper27.getY()), new Integer(anchoringHelper27.getWidth()), new Integer(anchoringHelper27.getHeight()), ControlState.UNKNOWN, ControlState.UNKNOWN, ims.framework.enumerations.ControlAnchoring.TOPLEFTRIGHT, null, new Boolean(false)});\n\t\taddControl(m_ctnAllergy);\n\t\tctnAllergyContainer ctnAllergy = (ctnAllergyContainer)ContainerBridgeFlyweightFactory.getInstance().createContainerBridge(ctnAllergyContainer.class, m_ctnAllergy, factory);\n\t\tims.framework.utils.SizeInfo m_ctnAllergyDesignSize = new ims.framework.utils.SizeInfo(816, 176);\n\t\tims.framework.utils.SizeInfo m_ctnAllergyRuntimeSize = new ims.framework.utils.SizeInfo(anchoringHelper27.getWidth(), anchoringHelper27.getHeight());\n\t\tctnAllergy.setContext(form, appForm, m_ctnAllergy, loader, this.getImages(), contextMenus, startControlID, m_ctnAllergyDesignSize, m_ctnAllergyRuntimeSize, startTabIndex, skipContextValidation);\n\t\tsuper.addContainer(ctnAllergy);\n\t\t// Button Controls\n\t\tRuntimeAnchoring anchoringHelper28 = new RuntimeAnchoring(designSize, runtimeSize, 674, 600, 75, 23, ims.framework.enumerations.ControlAnchoring.BOTTOMRIGHT);\n\t\tsuper.addControl(factory.getControl(Button.class, new Object[] { control, new Integer(startControlID.intValue() + 1030), new Integer(anchoringHelper28.getX()), new Integer(anchoringHelper28.getY()), new Integer(anchoringHelper28.getWidth()), new Integer(anchoringHelper28.getHeight()), new Integer(startTabIndex.intValue() + 25), ControlState.HIDDEN, ControlState.ENABLED, ims.framework.enumerations.ControlAnchoring.BOTTOMRIGHT, \"Save\", Boolean.FALSE, null, Boolean.FALSE, Boolean.TRUE, Boolean.FALSE, null, ims.framework.utils.Color.Default, ims.framework.utils.Color.Default }));\n\t\tRuntimeAnchoring anchoringHelper29 = new RuntimeAnchoring(designSize, runtimeSize, 754, 600, 75, 23, ims.framework.enumerations.ControlAnchoring.BOTTOMRIGHT);\n\t\tsuper.addControl(factory.getControl(Button.class, new Object[] { control, new Integer(startControlID.intValue() + 1031), new Integer(anchoringHelper29.getX()), new Integer(anchoringHelper29.getY()), new Integer(anchoringHelper29.getWidth()), new Integer(anchoringHelper29.getHeight()), new Integer(startTabIndex.intValue() + 26), ControlState.HIDDEN, ControlState.ENABLED, ims.framework.enumerations.ControlAnchoring.BOTTOMRIGHT, \"Cancel\", Boolean.FALSE, null, Boolean.FALSE, Boolean.FALSE, Boolean.FALSE, null, ims.framework.utils.Color.Default, ims.framework.utils.Color.Default }));\n\t\t// Grid Controls\n\t\tRuntimeAnchoring anchoringHelper30 = new RuntimeAnchoring(designSize, runtimeSize, 24, 360, 808, 76, ims.framework.enumerations.ControlAnchoring.TOPLEFTRIGHT);\n\t\tGrid m_grdAlertsTemp = (Grid)factory.getControl(Grid.class, new Object[] { control, new Integer(startControlID.intValue() + 1032), new Integer(anchoringHelper30.getX()), new Integer(anchoringHelper30.getY()), new Integer(anchoringHelper30.getWidth()), new Integer(anchoringHelper30.getHeight()), new Integer(startTabIndex.intValue() + 14), ControlState.UNKNOWN, ControlState.UNKNOWN, ims.framework.enumerations.ControlAnchoring.TOPLEFTRIGHT,Boolean.TRUE, Boolean.FALSE, new Integer(24), Boolean.TRUE, contextMenus.Clinical.contextMenuEdischargeAlertsEtc, Boolean.FALSE, Boolean.FALSE, new Integer(0), null, Boolean.FALSE, Boolean.TRUE});\n\t\taddControl(m_grdAlertsTemp);\n\t\tgrdAlertsGrid grdAlerts = (grdAlertsGrid)GridFlyweightFactory.getInstance().createGridBridge(grdAlertsGrid.class, m_grdAlertsTemp);\n\t\tgrdAlerts.addStringColumn(\"Date\", 0, 0, 85, true, false, 0, 0, true, ims.framework.enumerations.CharacterCasing.NORMAL);\n\t\tgrdAlerts.addStringColumn(\"Category\", 0, 0, 200, true, false, 0, 0, true, ims.framework.enumerations.CharacterCasing.NORMAL);\n\t\tgrdAlerts.addStringColumn(\"Alert\", 0, 0, 200, true, false, 0, 0, true, ims.framework.enumerations.CharacterCasing.NORMAL);\n\t\tgrdAlerts.addStringColumn(\"Source\", 0, 0, 170, true, false, 0, 0, true, ims.framework.enumerations.CharacterCasing.NORMAL);\n\t\tgrdAlerts.addImageColumn(\" \", 1, 1, 40, false, 0);\n\t\tgrdAlerts.addImageColumn(\" \", 0, 0, 40, true, 0);\n\t\tgrdAlerts.addBoolColumn(\"Include\", 0, 0, -1, false, true, 0, true);\n\t\tsuper.addGrid(grdAlerts);\n\t\tRuntimeAnchoring anchoringHelper31 = new RuntimeAnchoring(designSize, runtimeSize, 24, 32, 808, 112, ims.framework.enumerations.ControlAnchoring.TOPLEFTRIGHT);\n\t\tGrid m_grdAllergiesTemp = (Grid)factory.getControl(Grid.class, new Object[] { control, new Integer(startControlID.intValue() + 1033), new Integer(anchoringHelper31.getX()), new Integer(anchoringHelper31.getY()), new Integer(anchoringHelper31.getWidth()), new Integer(anchoringHelper31.getHeight()), new Integer(startTabIndex.intValue() + 1), ControlState.UNKNOWN, ControlState.UNKNOWN, ims.framework.enumerations.ControlAnchoring.TOPLEFTRIGHT,Boolean.TRUE, Boolean.FALSE, new Integer(24), Boolean.TRUE, contextMenus.Clinical.contextMenuEdischargeAllergiesEtc, Boolean.FALSE, Boolean.FALSE, new Integer(0), null, Boolean.FALSE, Boolean.TRUE});\n\t\taddControl(m_grdAllergiesTemp);\n\t\tgrdAllergiesGrid grdAllergies = (grdAllergiesGrid)GridFlyweightFactory.getInstance().createGridBridge(grdAllergiesGrid.class, m_grdAllergiesTemp);\n\t\tgrdAllergies.addStringColumn(\"Date\", 0, 0, 85, true, false, 0, 0, true, ims.framework.enumerations.CharacterCasing.NORMAL);\n\t\tgrdAllergies.addStringColumn(\"Allergen Description\", 0, 0, 200, true, false, 0, 0, true, ims.framework.enumerations.CharacterCasing.NORMAL);\n\t\tgrdAllergies.addStringColumn(\"Reaction\", 0, 0, 200, true, false, 0, 0, true, ims.framework.enumerations.CharacterCasing.NORMAL);\n\t\tgrdAllergies.addStringColumn(\"Source\", 0, 0, 170, true, false, 0, 0, true, ims.framework.enumerations.CharacterCasing.NORMAL);\n\t\tgrdAllergies.addImageColumn(\"  \", 1, 1, 40, true, 0);\n\t\tgrdAllergies.addImageColumn(\" \", 0, 0, 40, true, 0);\n\t\tgrdAllergies.addBoolColumn(\"Include\", 0, 0, -1, false, true, 0, true);\n\t\tsuper.addGrid(grdAllergies);\n\t}\n\tpublic Forms getForms()\n\t{\n\t\treturn (Forms)super.getFormReferences();\n\t}\n\tpublic Images getImages()\n\t{\n\t\treturn (Images)super.getImageReferences();\n\t}\n\tpublic ctnAlertContainer ctnAlert()\n\t{\n\t\treturn (ctnAlertContainer)super.getContainer(0);\n\t}\n\tpublic ctnAllergyContainer ctnAllergy()\n\t{\n\t\treturn (ctnAllergyContainer)super.getContainer(1);\n\t}\n\tpublic Button btnSave()\n\t{\n\t\treturn (Button)super.getControl(4);\n\t}\n\tpublic Button btnCancel()\n\t{\n\t\treturn (Button)super.getControl(5);\n\t}\n\tpublic grdAlertsGrid grdAlerts()\n\t{\n\t\treturn (grdAlertsGrid)super.getGrid(0);\n\t}\n\tpublic grdAllergiesGrid grdAllergies()\n\t{\n\t\treturn (grdAllergiesGrid)super.getGrid(1);\n\t}\n\tpublic static class Forms implements java.io.Serializable\n\t{\n\t\tprivate static final long serialVersionUID = 1L;\n\t\tprotected final class LocalFormName extends FormName\n\t\t{\n\t\t\tprivate static final long serialVersionUID = 1L;\n\t\t\n\t\t\tprivate LocalFormName(int name)\n\t\t\t{\n\t\t\t\tsuper(name);\n\t\t\t}\n\t\t}\n\t\tprivate Forms()\n\t\t{\n\t\t\tCore = new CoreForms();\n\t\t}\n\t\tpublic final class CoreForms implements java.io.Serializable\n\t\t{\n\t\t\tprivate static final long serialVersionUID = 1L;\n\t\t\tprivate CoreForms()\n\t\t\t{\n\t\t\t\tYesNoDialog = new LocalFormName(102107);\n\t\t\t}\n\t\t\tpublic final FormName YesNoDialog;\n\t\t}\n\t\tpublic CoreForms Core;\n\t}\n\tpublic static class Images implements java.io.Serializable\n\t{\n\t\tprivate static final long serialVersionUID = 1L;\n\t\tprivate final class ImageHelper extends ims.framework.utils.ImagePath\n\t\t{\n\t\t\tprivate static final long serialVersionUID = 1L;\n\t\t\t\n\t\t\tprivate ImageHelper(int id, String path, Integer width, Integer height)\n\t\t\t{\n", "outputs": ["\t\t\t\tsuper(id, path, width, height);"], "input_length": 11209, "output_length": 11, "length": 11220, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "1b1838ae06940fdfb72cd1ced2495a4280244ff3a4bb68b635f2398e51795637"}
{"input": "", "context": "using System;\nusing System.Collections.Generic;\nusing System.Text;\nusing Axiom.Core;\nusing Axiom.Media;\nusing Axiom.Graphics;\nusing Axiom.Overlays;\nusing Axiom.Animating;\nusing Axiom.Math;\nusing System.Runtime.InteropServices;\nnamespace Axiom.Demos\n{\n\tpublic class DynamicTextures : TechDemo\n\t{\n\t\tTexture ptex;\n\t\tHardwarePixelBuffer buffer;\n\t\tOverlay overlay;\n\t\tstatic readonly int reactorExtent = 130; // must be 2^N + 2\n\t\tuint[] clut = new uint[ 1024 ];\n\t\tAnimationState swim;\n\t\tstatic float fDefDim;\n\t\tstatic float fDefVel;\n\t\tfloat tim;\n\t\tList<int[]> chemical = new List<int[]>();\n\t\tList<int[]> delta = new List<int[]>();\n\t\tint mSize;\n\t\tint dt, hdiv0, hdiv1; // diffusion parameters\n\t\tint F, k; // reaction parameters\n\t\tbool rpressed;\n\t\tRandom rand = new Random();\n\t\tpublic DynamicTextures()\n\t\t{\n\t\t\tchemical.Add( null );\n\t\t\tchemical.Add( null );\n\t\t\tdelta.Add( null );\n\t\t\tdelta.Add( null );\n\t\t}\n\t\tpublic override bool Setup()\n\t\t{\n\t\t\tif ( base.Setup() )\n\t\t\t{\n\t\t\t\ttim = 0;\n\t\t\t\trpressed = false;\n\t\t\t\t// Create  colour lookup\n\t\t\t\tfor ( int col = 0; col < 1024; col++ )\n\t\t\t\t{\n\t\t\t\t\tColorEx c;\n\t\t\t\t\tc = HSVtoRGB( ( 1.0f - col / 1024.0f ) * 90.0f + 225.0f, 0.9f, 0.75f + 0.25f * ( 1.0f - col / 1024.0f ) );\n\t\t\t\t\tc.a = 1.0f - col / 1024.0f;\n\t\t\t\t\tunsafe\n\t\t\t\t\t{\n\t\t\t\t\t\tfixed ( uint* dest = clut )\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tPixelConverter.PackColor( c, PixelFormat.A8R8G8B8, (IntPtr)( &dest[ col ] ) );\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t// Setup\n\t\t\t\tLogManager.Instance.Write( \"Creating chemical containment\" );\n\t\t\t\tmSize = reactorExtent * reactorExtent;\n\t\t\t\tchemical[ 0 ] = new int[ mSize ];\n\t\t\t\tchemical[ 1 ] = new int[ mSize ];\n\t\t\t\tdelta[ 0 ] = new int[ mSize ];\n\t\t\t\tdelta[ 1 ] = new int[ mSize ];\n\t\t\t\tdt = FROMFLOAT( 2.0f );\n\t\t\t\thdiv0 = FROMFLOAT( 2.0E-5f / ( 2.0f * 0.01f * 0.01f ) ); // a / (2.0f*h*h); -- really diffusion rate\n\t\t\t\thdiv1 = FROMFLOAT( 1.0E-5f / ( 2.0f * 0.01f * 0.01f ) ); // a / (2.0f*h*h); -- really diffusion rate\n\t\t\t\t//k = FROMFLOAT(0.056f);\n\t\t\t\t//F = FROMFLOAT(0.020f);\n\t\t\t\tk = FROMFLOAT( 0.0619f );\n\t\t\t\tF = FROMFLOAT( 0.0316f );\n\t\t\t\tresetReactor();\n\t\t\t\tfireUpReactor();\n\t\t\t\tupdateInfoParamF();\n\t\t\t\tupdateInfoParamK();\n\t\t\t\tupdateInfoParamA0();\n\t\t\t\tupdateInfoParamA1();\n\t\t\t\tLogManager.Instance.Write( \"Cthulhu dawn\" );\n\t\t\t\treturn true;\n\t\t\t}\n\t\t\treturn false;\n\t\t}\n\t\tpublic override void CreateScene()\n\t\t{\n\t\t\t// Create dynamic texture\n\t\t\tptex = TextureManager.Instance.CreateManual( \"DynaTex\", ResourceGroupManager.DefaultResourceGroupName, TextureType.TwoD, reactorExtent - 2, reactorExtent - 2, 0, PixelFormat.A8R8G8B8, TextureUsage.DynamicWriteOnly );\n\t\t\tbuffer = ptex.GetBuffer( 0, 0 );\n\t\t\t// Set ambient light\n\t\t\tscene.AmbientLight = new ColorEx( 0.6F, 0.6F, 0.6F );\n\t\t\tscene.SetSkyBox( true, \"SkyBox/Space\", 50 );\n\t\t\t//mRoot->getRenderSystem()->clearFrameBuffer(FBT_COLOUR, ColourValue(255,255,255,0));\n\t\t\t// Create a light\n\t\t\tLight l = scene.CreateLight( \"MainLight\" );\n\t\t\tl.Diffuse = new ColorEx( 0.75F, 0.75F, 0.80F );\n\t\t\tl.Specular = new ColorEx( 0.9F, 0.9F, 1F );\n\t\t\tl.Position = new Vector3( -100, 80, 50 );\n\t\t\tscene.RootSceneNode.AttachObject( l );\n\t\t\tEntity planeEnt = scene.CreateEntity( \"TexPlane1\", PrefabEntity.Plane );\n\t\t\t// Give the plane a texture\n\t\t\tplaneEnt.MaterialName = \"Examples/DynaTest\";\n\t\t\tSceneNode node = scene.RootSceneNode.CreateChildSceneNode( new Vector3( -100, -40, -100 ) );\n\t\t\tnode.AttachObject( planeEnt );\n\t\t\tnode.Scale = new Vector3( 3.0f, 3.0f, 3.0f );\n\t\t\t// Create objects\n\t\t\tSceneNode blaNode = scene.RootSceneNode.CreateChildSceneNode( new Vector3( -200, 0, 50 ) );\n\t\t\tEntity ent2 = scene.CreateEntity( \"knot\", \"knot.mesh\" );\n\t\t\tent2.MaterialName = \"Examples/DynaTest4\";\n\t\t\tblaNode.AttachObject( ent2 );\n\t\t\tblaNode = scene.RootSceneNode.CreateChildSceneNode( new Vector3( 200, -90, 50 ) );\n\t\t\tent2 = scene.CreateEntity( \"knot2\", \"knot.mesh\" );\n\t\t\tent2.MaterialName = \"Examples/DynaTest2\";\n\t\t\tblaNode.AttachObject( ent2 );\n\t\t\tblaNode = scene.RootSceneNode.CreateChildSceneNode( new Vector3( -110, 200, 50 ) );\n\t\t\t// Cloaked fish\n\t\t\tent2 = scene.CreateEntity( \"knot3\", \"fish.mesh\" );\n\t\t\tent2.MaterialName = \"Examples/DynaTest3\";\n\t\t\tswim = ent2.GetAnimationState( \"swim\" );\n\t\t\tswim.IsEnabled = true;\n\t\t\tblaNode.AttachObject( ent2 );\n\t\t\tblaNode.Scale = new Vector3( 50.0f, 50.0f, 50.0f );\n\t\t\tLogManager.Instance.Write( \"HardwarePixelBuffer {0} {1} {2} \", buffer.Width, buffer.Height, buffer.Depth );\n\t\t\tbuffer.Lock( BufferLocking.Normal );\n\t\t\tPixelBox pb = buffer.CurrentLock;\n\t\t\tLogManager.Instance.Write( \"PixelBox {0} {1} {2} {3} {4} {5} {6}\", pb.Width, pb.Height, pb.Depth, pb.RowPitch, pb.SlicePitch, pb.Data, pb.Format );\n\t\t\tbuffer.Unlock();\n\t\t\t// show GUI\n\t\t\toverlay = OverlayManager.Instance.GetByName( \"Example/DynTexOverlay\" );\n\t\t\toverlay.Show();\n\t\t}\n\t\tprotected override void OnFrameStarted( object source, FrameEventArgs evt )\n\t\t{\n\t\t\tfor ( int x = 0; x < 10; x++ )\n\t\t\t\trunStep();\n\t\t\tbuildTexture();\n\t\t\tswim.AddTime( evt.TimeSinceLastFrame );\n\t\t\tbase.OnFrameStarted( source, evt );\n\t\t}\n\t\tvoid resetReactor()\n\t\t{\n\t\t\tLogManager.Instance.Write( \"Facilitating neutral start up conditions\" );\n\t\t\tfor ( int x = 0; x < mSize; x++ )\n\t\t\t{\n\t\t\t\tchemical[ 0 ][ x ] = FROMFLOAT( 1.0f );\n\t\t\t\tchemical[ 1 ][ x ] = FROMFLOAT( 0.0f );\n\t\t\t}\n\t\t}\n\t\tvoid fireUpReactor()\n\t\t{\n\t\t\tLogManager.Instance.Write( \"Warning: reactor is being fired up\" );\n\t\t\tint center = reactorExtent / 2;\n\t\t\tfor ( int x = center - 10; x < center + 10; x++ )\n\t\t\t{\n\t\t\t\tfor ( int y = center - 10; y < center + 10; y++ )\n\t\t\t\t{\n\t\t\t\t\tchemical[ 0 ][ y * reactorExtent + x ] = FROMFLOAT( 0.5f ) + rand.Next() % FROMFLOAT( 0.1f );\n\t\t\t\t\tchemical[ 1 ][ y * reactorExtent + x ] = FROMFLOAT( 0.25f ) + rand.Next() % FROMFLOAT( 0.1f );\n\t\t\t\t}\n\t\t\t}\n\t\t\tLogManager.Instance.Write( \"Warning: reaction has begun\" );\n\t\t}\n\t\tvoid runStep()\n\t\t{\n\t\t\tint x, y;\n\t\t\tfor ( x = 0; x < mSize; x++ )\n\t\t\t{\n\t\t\t\tdelta[ 0 ][ x ] = 0;\n\t\t\t\tdelta[ 1 ][ x ] = 0;\n\t\t\t}\n\t\t\t// Boundary conditions\n\t\t\tint idx;\n\t\t\tidx = 0;\n\t\t\tfor ( y = 0; y < reactorExtent; y++ )\n\t\t\t{\n\t\t\t\tchemical[ 0 ][ idx ] = chemical[ 0 ][ idx + reactorExtent - 2 ];\n\t\t\t\tchemical[ 0 ][ idx + reactorExtent - 1 ] = chemical[ 0 ][ idx + 1 ];\n\t\t\t\tchemical[ 1 ][ idx ] = chemical[ 1 ][ idx + reactorExtent - 2 ];\n\t\t\t\tchemical[ 1 ][ idx + reactorExtent - 1 ] = chemical[ 1 ][ idx + 1 ];\n\t\t\t\tidx += reactorExtent;\n\t\t\t}\n\t\t\tint skip = reactorExtent * ( reactorExtent - 1 );\n\t\t\tfor ( y = 0; y < reactorExtent; y++ )\n\t\t\t{\n\t\t\t\tchemical[ 0 ][ y ] = chemical[ 0 ][ y + skip - reactorExtent ];\n\t\t\t\tchemical[ 0 ][ y + skip ] = chemical[ 0 ][ y + reactorExtent ];\n\t\t\t\tchemical[ 1 ][ y ] = chemical[ 1 ][ y + skip - reactorExtent ];\n\t\t\t\tchemical[ 1 ][ y + skip ] = chemical[ 1 ][ y + reactorExtent ];\n\t\t\t}\n\t\t\t// Diffusion\n\t\t\tidx = reactorExtent + 1;\n\t\t\tfor ( y = 0; y < reactorExtent - 2; y++ )\n\t\t\t{\n\t\t\t\tfor ( x = 0; x < reactorExtent - 2; x++ )\n\t\t\t\t{\n\t\t\t\t\tdelta[ 0 ][ idx ] += MULT( chemical[ 0 ][ idx - reactorExtent ] + chemical[ 0 ][ idx - 1 ]\n\t\t\t\t\t\t\t\t\t- 4 * chemical[ 0 ][ idx ] + chemical[ 0 ][ idx + 1 ]\n", "outputs": ["\t\t\t\t\t\t\t\t\t+ chemical[ 0 ][ idx + reactorExtent ], hdiv0 );"], "input_length": 1517, "output_length": 14, "length": 1531, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "1355abae35e2af415d4e38d8e752438dee64c653a04bce74b0b6d0b1c2a115b6"}
{"input": "", "context": "#!/usr/bin/env python3\nfrom argparse import ArgumentParser\nfrom encrypted_archive_index import EncryptedArchiveIndex\nimport sys\nfrom getpass import getpass\nfrom key_deriver import KeyDeriver\nimport log\nfrom archive_encryptor import ArchiveEncryptor, EncryptedArchiveCorruptException\nimport consts\nimport os\ndef new_password(prompt, confirm_prompt='Confirm Password: '):\n    while True:\n        password = getpass(prompt)\n        confirm_password = getpass(confirm_prompt)\n        if password == confirm_password:\n            break\n        log.msg('Passwords do not match - please try again')\n        log.msg()\n    return password\ndef load_archive_index(path):\n    eai = EncryptedArchiveIndex(path)\n    if not eai.exists():\n        log.info('cryptostasis', 'Archive Index does not exist - going through first time setup')\n        log.msg('===== First Time Setup =====')\n        log.msg('You\\'ll need to set a password used to encrypt the archive index')\n        password = new_password('New Index Password: ')\n        eai.init_new()\n        master_key = eai.derive_master_key(password)\n        eai.update_master_key(master_key)\n        archive_index = eai.create_new_index()\n        archive_index.save()\n        return archive_index\n    else:\n        log.info('cryptostasis', 'Attempting to load archive index')\n        try:\n            eai.load()\n            log.info('cryptostasis', 'Successfully loaded archive index')\n        except Exception as e:\n            log.msg('Failed to load archive index')\n            log.debug('cryptostasis', str(e))\n            sys.exit(1)\n        password = getpass('Index Password: ')\n        master_key = eai.derive_master_key(password)\n        if not eai.verify_master_key(master_key):\n            log.msg('Incorrect password')\n            sys.exit(1)\n        if not eai.verify_index_integrity(master_key):\n            log.msg('Index corrupt')\n            sys.exit(1)\n        return eai.decrypt_index(master_key)\ndef get_input_strm(args):\n    if args.input_file is not None:\n        return open(args.input_file, 'rb')\n    return sys.stdin.buffer\ndef get_output_strm(args):\n    if args.output_file is not None:\n        return open(args.output_file, 'wb')\n    return sys.stdout.buffer\n# Actions\ndef encrypt_archive(archive_index, args):\n    input_strm = get_input_strm(args)\n    output_strm = get_output_strm(args)\n    archive_name = args.archive_name\n    if archive_index.name_exists(archive_name):\n        log.msg('\\'{}\\' archive exists - quitting'.format(archive_name))\n        sys.exit(1)\n    arch_enc = ArchiveEncryptor(archive_index)\n    arch_enc.encrypt_archive(input_strm, output_strm, archive_name)\n    input_strm.close()\n    output_strm.flush()\n    output_strm.close()\ndef decrypt_archive(archive_index, args):\n    input_strm = get_input_strm(args)\n    output_strm = get_output_strm(args)\n    arch_enc = ArchiveEncryptor(archive_index)\n    success = True\n    try:\n        archive_entry = arch_enc.decrypt_archive(input_strm, output_strm)\n        if archive_entry is not None:\n            log.msg('Successfully decrypted \\'{}\\' archive'.format(archive_entry.name))\n        else:\n            log.msg('Could not find th decryption key for this archive - are you sure that it is an encrypted archive?')\n            success = False\n    except Exception as e:\n        log.msg('Something went wrong trying to decrypt the archive')\n        log.debug('cryptostasis', 'Decryption failed - stack trace:\\n{}'.format(str(e)))\n        success = False\n    except EncryptedArchiveCorruptException as e:\n        log.msg('Failed to decrypt archive: {}'.format(e.message))\n        if e is EncryptedArchiveCorruptException:\n            log.info('cryptostasis', 'Corrupt archive - {}'.format(e.reason))\n        log.debug('cryptostasis', 'Full exception:\\n{}'.format(str(e)))\n        success = False\n    input_strm.close()\n    output_strm.flush()\n    output_strm.close()\n    if not success:\n        if args.output_file is not None:\n            os.remove(args.output_file)\n        return 1\ndef list_index(archive_index, args):\n    log.msg(str(archive_index))\ndef change_password(archive_index, args):\n    new_pass = new_password('Enter the new index password: ')\n    eai = archive_index.encrypted_archive_index\n    eai.password_salt = KeyDeriver.new_salt()\n    if args.time_cost is not None:\n        eai.time_cost = args.time_cost\n    if args.memory_cost is not None:\n        eai.memory_cost = args.memory_cost\n    if args.parallelism is not None:\n        eai.parallelism = args.parallelism\n    master_key = archive_index.encrypted_archive_index.derive_master_key(new_pass)\n    archive_index.encrypted_archive_index.update_master_key(master_key)\n    archive_index.save()\n    log.msg('Successfully changed index password')\ndef main():\n    parser = ArgumentParser()\n    parser.add_argument('-v', '--verbose', action='count', default=0, dest='verbosity')\n    parser.add_argument('-V', '--version', dest='version', help='Show version and exit', action='store_true')\n    parser.add_argument('--log-file', type=str, dest='log_file', help='Path to log file (use with --verbose)')\n    parser.add_argument(\n        '-I',\n        '--index',\n        type=str,\n        dest='index_file',\n        default=consts.INDEX_DEFAULT_LOCATION,\n        help='Archive Index File (defaults to {})'.format(consts.INDEX_DEFAULT_LOCATION)\n    )\n    actions = parser.add_subparsers()\n    encrypt_subparser = actions.add_parser('encrypt', help='Encrypt an archive')\n    encrypt_subparser.set_defaults(func=encrypt_archive)\n    encrypt_subparser.add_argument('archive_name')\n    encrypt_subparser.add_argument('-f', '--input-file', type=str, dest='input_file', help='Input archive file (defaults to STDIN)')\n    encrypt_subparser.add_argument('-o', '--output-file', type=str, dest='output_file', help='Encrypted output archive file (defaults to STDOUT)')\n    decrypt_subparser = actions.add_parser('decrypt', help='Decrypt an archive')\n    decrypt_subparser.set_defaults(func=decrypt_archive)\n    decrypt_subparser.add_argument('-f', '--input-file', type=str, dest='input_file', help='Input encrypted archive file (defaults to STDIN)')\n    decrypt_subparser.add_argument('-o', '--output-file', type=str, dest='output_file', help='Output archive file (defaults to STDOUT)')\n    list_subparser = actions.add_parser('list', help='List entries in the index')\n    list_subparser.set_defaults(func=list_index)\n    change_password_subparser = actions.add_parser(\n        'passwd',\n        description = (\n            'When changing the encryption password, you can also configure the Key Derivation Function (KDF) parameters. ' +\n            'If they are not set, they default to the current parameters as loaded from the index. ' +\n            'When creating a new index, the parameters are time_cost = {}, memory_cost = {}, and parallelism = {}'\n                .format(consts.DEFAULT_TIME_COST, consts.DEFAULT_MEMORY_COST, consts.DEFAULT_PARALLELISM)\n        ),\n        help = 'Change index password'\n    )\n    change_password_subparser.set_defaults(func=change_password)\n    change_password_subparser.add_argument('-t', '--time-cost', type=int, dest='time_cost', help='The time cost parameter passed to the KDF')\n    change_password_subparser.add_argument('-m', '--memory-cost', type=int, dest='memory_cost', help='The memory cost parameter passed to the KDF')\n    change_password_subparser.add_argument('-p', '--parallelism', type=int, dest='parallelism', help='The parallelism parameter passed to the KDF')\n    args = parser.parse_args()\n    if args.version:\n        log.msg('Cryptostasis v{}'.format(consts.VERSION))\n        sys.exit(0)\n    log.level = args.verbosity\n    log.info('cryptostasis', 'Verbosity level: {}'.format(args.verbosity))\n    if args.log_file is not None:\n        log.msg('Writing logs to: {}'.format(args.log_file))\n", "outputs": ["        log.log_strm = open(args.log_file, 'w')"], "input_length": 1213, "output_length": 10, "length": 1223, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "e495c9008ff2c7a0ce448e91827336006fa47a65970cbcd52c293e8c101f7e22"}
{"input": "", "context": "/*\n * ManagedWinapi - A collection of .NET components that wrap PInvoke calls to \n * access native API by managed code. http://mwinapi.sourceforge.net/\n * Copyright (C) 2006 Michael Schierl\n * \n * This library is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n * This library is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n * \n * You should have received a copy of the GNU Lesser General Public\n * License along with this library; see the file COPYING. if not, visit\n * http://www.gnu.org/licenses/lgpl.html or write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA\n */\nusing System;\nusing System.Collections.Generic;\nusing System.Text;\nusing System.Windows.Forms;\nusing System.Runtime.InteropServices;\nusing System.Drawing;\nnamespace ManagedWinapi.Windows\n{\n    /// <summary>\n    /// Any list view, including those from other applications.\n    /// </summary>\n    public class SystemListView\n    {\n        /// <summary>\n        /// Get a SystemListView reference from a SystemWindow (which is a list view)\n        /// </summary>\n        public static SystemListView FromSystemWindow(SystemWindow sw)\n        {\n            if (sw.SendGetMessage(LVM_GETITEMCOUNT) == 0) return null;\n            return new SystemListView(sw);\n        }\n        readonly SystemWindow sw;\n        private SystemListView(SystemWindow sw)\n        {\n            this.sw = sw;\n        }\n        /// <summary>\n        /// The number of items (icons) in this list view.\n        /// </summary>\n        public int Count\n        {\n            get\n            {\n                return sw.SendGetMessage(LVM_GETITEMCOUNT);\n            }\n        }\n        /// <summary>\n        /// An item of this list view.\n        /// </summary>\n        public SystemListViewItem this[int index]\n        {\n            get\n            {\n                return this[index, 0];\n            }\n        }\n        /// <summary>\n        /// A subitem (a column value) of an item of this list view.\n        /// </summary>\n        public SystemListViewItem this[int index, int subIndex]\n        {\n            get\n            {\n                LVITEM lvi = new LVITEM();\n                lvi.cchTextMax = 300;\n                lvi.iItem = index;\n                lvi.iSubItem = subIndex;\n                lvi.stateMask = 0xffffffff;\n                lvi.mask = LVIF_IMAGE | LVIF_STATE | LVIF_TEXT;\n                ProcessMemoryChunk tc = ProcessMemoryChunk.Alloc(sw.Process, 301);\n                lvi.pszText = tc.Location;\n                ProcessMemoryChunk lc = ProcessMemoryChunk.AllocStruct(sw.Process, lvi);\n                ApiHelper.FailIfZero(SystemWindow.SendMessage(new HandleRef(sw, sw.HWnd), SystemListView.LVM_GETITEM, IntPtr.Zero, lc.Location));\n                lvi = (LVITEM)lc.ReadToStructure(0, typeof(LVITEM));\n                lc.Dispose();\n                if (lvi.pszText != tc.Location)\n                {\n                    tc.Dispose();\n                    tc = new ProcessMemoryChunk(sw.Process, lvi.pszText, lvi.cchTextMax);\n                }\n                byte[] tmp = tc.Read();\n                string title = Encoding.Default.GetString(tmp);\n                if (title.IndexOf('\\0') != -1) title = title.Substring(0, title.IndexOf('\\0'));\n                int image = lvi.iImage;\n                uint state = lvi.state;\n                tc.Dispose();\n                return new SystemListViewItem(sw, index, title, state, image);\n            }\n        }\n        /// <summary>\n        /// All columns of this list view, if it is in report view.\n        /// </summary>\n        public SystemListViewColumn[] Columns\n        {\n            get\n            {\n                List<SystemListViewColumn> result = new List<SystemListViewColumn>();\n                LVCOLUMN lvc = new LVCOLUMN();\n                lvc.cchTextMax = 300;\n                lvc.mask = LVCF_FMT | LVCF_SUBITEM | LVCF_TEXT | LVCF_WIDTH;\n                ProcessMemoryChunk tc = ProcessMemoryChunk.Alloc(sw.Process, 301);\n                lvc.pszText = tc.Location;\n                ProcessMemoryChunk lc = ProcessMemoryChunk.AllocStruct(sw.Process, lvc);\n                for (int i = 0; ; i++)\n                {\n                    IntPtr ok = SystemWindow.SendMessage(new HandleRef(sw, sw.HWnd), LVM_GETCOLUMN, new IntPtr(i), lc.Location);\n                    if (ok == IntPtr.Zero) break;\n                    lvc = (LVCOLUMN)lc.ReadToStructure(0, typeof(LVCOLUMN));\n                    byte[] tmp = tc.Read();\n                    string title = Encoding.Default.GetString(tmp);\n                    if (title.IndexOf('\\0') != -1) title = title.Substring(0, title.IndexOf('\\0'));\n                    result.Add(new SystemListViewColumn(lvc.fmt, lvc.cx, lvc.iSubItem, title));\n                }\n                tc.Dispose();\n                lc.Dispose();\n                return result.ToArray();\n            }\n        }\n        #region PInvoke Declarations\n        internal static readonly uint LVM_GETITEMRECT = (0x1000 + 14),\n            LVM_SETITEMPOSITION = (0x1000 + 15),\n            LVM_GETITEMPOSITION = (0x1000 + 16),\n            LVM_GETITEMCOUNT = (0x1000 + 4),\n            LVM_GETITEM = 0x1005,\n            LVM_GETCOLUMN = (0x1000 + 25);\n        private static readonly uint LVIF_TEXT = 0x1,\n            LVIF_IMAGE = 0x2,\n            LVIF_STATE = 0x8,\n            LVCF_FMT = 0x1,\n            LVCF_WIDTH = 0x2,\n            LVCF_TEXT = 0x4,\n            LVCF_SUBITEM = 0x8;\n        [StructLayout(LayoutKind.Sequential)]\n        private struct LVCOLUMN\n        {\n            public UInt32 mask;\n            public Int32 fmt;\n            public Int32 cx;\n            public IntPtr pszText;\n            public Int32 cchTextMax;\n            public Int32 iSubItem;\n        }\n        [StructLayout(LayoutKind.Sequential)]\n        private struct LVITEM\n        {\n            public UInt32 mask;\n            public Int32 iItem;\n            public Int32 iSubItem;\n            public UInt32 state;\n            public UInt32 stateMask;\n            public IntPtr pszText;\n            public Int32 cchTextMax;\n            public Int32 iImage;\n            public IntPtr lParam;\n        }\n        #endregion\n    }\n    /// <summary>\n    /// An item of a list view.\n    /// </summary>\n    public class SystemListViewItem\n    {\n        readonly string title;\n        readonly uint state;\n        readonly int image, index;\n        readonly SystemWindow sw;\n        internal SystemListViewItem(SystemWindow sw, int index, string title, uint state, int image)\n        {\n            this.sw = sw;\n            this.index = index;\n            this.title = title;\n            this.state = state;\n            this.image = image;\n        }\n        /// <summary>\n        /// The title of this item\n        /// </summary>\n        public string Title { get { return title; } }\n        /// <summary>\n        /// The index of this item's image in the image list of this list view.\n        /// </summary>\n        public int Image { get { return image; } }\n        /// <summary>\n        /// State bits of this item.\n        /// </summary>\n        public uint State { get { return state; } }\n        /// <summary>\n        /// Position of the upper left corner of this item.\n        /// </summary>\n        public Point Position\n        {\n            get\n            {\n                POINT pt = new POINT();\n                ProcessMemoryChunk c = ProcessMemoryChunk.AllocStruct(sw.Process, pt);\n                ApiHelper.FailIfZero(SystemWindow.SendMessage(new HandleRef(sw, sw.HWnd), SystemListView.LVM_GETITEMPOSITION, new IntPtr(index), c.Location));\n", "outputs": ["                pt = (POINT)c.ReadToStructure(0, typeof(POINT));"], "input_length": 1227, "output_length": 15, "length": 1242, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "132a61ae65eb3e7b41508c5f87d3ba4ca4eb33143cf3f08aaf0a03ea6f30319c"}
{"input": "", "context": "/*\n * Copyright 2002-2010 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.springframework.orm.jpa.persistenceunit;\nimport java.net.URL;\nimport java.util.LinkedList;\nimport java.util.List;\nimport java.util.Properties;\nimport javax.persistence.spi.ClassTransformer;\nimport javax.persistence.spi.PersistenceUnitTransactionType;\nimport javax.sql.DataSource;\nimport org.springframework.util.ClassUtils;\n/**\n * Spring's base implementation of the JPA\n * {@link javax.persistence.spi.PersistenceUnitInfo} interface,\n * used to bootstrap an EntityManagerFactory in a container.\n *\n * <p>This implementation is largely a JavaBean, offering mutators\n * for all standard PersistenceUnitInfo properties.\n *\n * @author Rod Johnson\n * @author Juergen Hoeller\n * @author Costin Leau\n * @since 2.0\n */\npublic class MutablePersistenceUnitInfo implements SmartPersistenceUnitInfo {\n\tprivate String persistenceUnitName;\n\tprivate String persistenceProviderClassName;\n\tprivate PersistenceUnitTransactionType transactionType;\n\tprivate DataSource nonJtaDataSource;\n\tprivate DataSource jtaDataSource;\n\tprivate List<String> mappingFileNames = new LinkedList<String>();\n\tprivate List<URL> jarFileUrls = new LinkedList<URL>();\n\tprivate URL persistenceUnitRootUrl;\n\tprivate List<String> managedClassNames = new LinkedList<String>();\n\tprivate boolean excludeUnlistedClasses = false;\n\tprivate Properties properties = new Properties();\n\tprivate String persistenceXMLSchemaVersion = \"1.0\";\n\tprivate String persistenceProviderPackageName;\n\tpublic void setPersistenceUnitName(String persistenceUnitName) {\n\t\tthis.persistenceUnitName = persistenceUnitName;\n\t}\n\tpublic String getPersistenceUnitName() {\n\t\treturn this.persistenceUnitName;\n\t}\n\tpublic void setPersistenceProviderClassName(String persistenceProviderClassName) {\n\t\tthis.persistenceProviderClassName = persistenceProviderClassName;\n\t}\n\tpublic String getPersistenceProviderClassName() {\n\t\treturn this.persistenceProviderClassName;\n\t}\n\tpublic void setTransactionType(PersistenceUnitTransactionType transactionType) {\n\t\tthis.transactionType = transactionType;\n\t}\n\tpublic PersistenceUnitTransactionType getTransactionType() {\n\t\tif (this.transactionType != null) {\n\t\t\treturn this.transactionType;\n\t\t}\n\t\telse {\n\t\t\treturn (this.jtaDataSource != null ?\n\t\t\t\t\tPersistenceUnitTransactionType.JTA : PersistenceUnitTransactionType.RESOURCE_LOCAL);\n\t\t}\n\t}\n\tpublic void setJtaDataSource(DataSource jtaDataSource) {\n\t\tthis.jtaDataSource = jtaDataSource;\n\t}\n\tpublic DataSource getJtaDataSource() {\n\t\treturn this.jtaDataSource;\n\t}\n\tpublic void setNonJtaDataSource(DataSource nonJtaDataSource) {\n\t\tthis.nonJtaDataSource = nonJtaDataSource;\n\t}\n\tpublic DataSource getNonJtaDataSource() {\n\t\treturn this.nonJtaDataSource;\n\t}\n\tpublic void addMappingFileName(String mappingFileName) {\n\t\tthis.mappingFileNames.add(mappingFileName);\n\t}\n\tpublic List<String> getMappingFileNames() {\n\t\treturn this.mappingFileNames;\n\t}\n\tpublic void addJarFileUrl(URL jarFileUrl) {\n\t\tthis.jarFileUrls.add(jarFileUrl);\n\t}\n\tpublic List<URL> getJarFileUrls() {\n\t\treturn this.jarFileUrls;\n\t}\n\tpublic void setPersistenceUnitRootUrl(URL persistenceUnitRootUrl) {\n\t\tthis.persistenceUnitRootUrl = persistenceUnitRootUrl;\n\t}\n\tpublic URL getPersistenceUnitRootUrl() {\n\t\treturn this.persistenceUnitRootUrl;\n\t}\n\tpublic void addManagedClassName(String managedClassName) {\n\t\tthis.managedClassNames.add(managedClassName);\n\t}\n\tpublic List<String> getManagedClassNames() {\n\t\treturn this.managedClassNames;\n\t}\n\tpublic void setExcludeUnlistedClasses(boolean excludeUnlistedClasses) {\n\t\tthis.excludeUnlistedClasses = excludeUnlistedClasses;\n\t}\n\tpublic boolean excludeUnlistedClasses() {\n\t\treturn this.excludeUnlistedClasses;\n\t}\n\tpublic void addProperty(String name, String value) {\n\t\tif (this.properties == null) {\n\t\t\tthis.properties = new Properties();\n\t\t}\n\t\tthis.properties.setProperty(name, value);\n\t}\n\tpublic void setProperties(Properties properties) {\n\t\tthis.properties = properties;\n\t}\n\tpublic Properties getProperties() {\n\t\treturn this.properties;\n\t}\n\tpublic void setPersistenceXMLSchemaVersion(String persistenceXMLSchemaVersion) {\n\t\tthis.persistenceXMLSchemaVersion = persistenceXMLSchemaVersion;\n\t}\n\tpublic String getPersistenceXMLSchemaVersion() {\n\t\treturn this.persistenceXMLSchemaVersion;\n\t}\n\tpublic void setPersistenceProviderPackageName(String persistenceProviderPackageName) {\n\t\tthis.persistenceProviderPackageName = persistenceProviderPackageName;\n\t}\n\tpublic String getPersistenceProviderPackageName() {\n\t\treturn this.persistenceProviderPackageName;\n\t}\n\t/**\n\t * This implementation returns the default ClassLoader.\n\t * @see org.springframework.util.ClassUtils#getDefaultClassLoader()\n\t */\n\tpublic ClassLoader getClassLoader() {\n\t\treturn ClassUtils.getDefaultClassLoader();\n\t}\n\t/**\n\t * This implementation throws an UnsupportedOperationException.\n\t */\n\tpublic void addTransformer(ClassTransformer classTransformer) {\n\t\tthrow new UnsupportedOperationException(\"addTransformer not supported\");\n\t}\n\t/**\n\t * This implementation throws an UnsupportedOperationException.\n\t */\n\tpublic ClassLoader getNewTempClassLoader() {\n\t\tthrow new UnsupportedOperationException(\"getNewTempClassLoader not supported\");\n\t}\n\t@Override\n\tpublic String toString() {\n", "outputs": ["\t\tStringBuilder builder = new StringBuilder();"], "input_length": 792, "output_length": 8, "length": 800, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "0dc10ee4d4b141edb2ffcfe14ccf46db7f721e1b13ec6a12b26ec9f0abf7ac36"}
{"input": "", "context": "package org.openswing.swing.mdi.client;\nimport java.beans.*;\nimport java.util.*;\nimport java.awt.*;\nimport java.awt.event.*;\nimport java.awt.image.BufferedImage;\nimport java.util.logging.Level;\nimport java.util.logging.Logger;\nimport javax.swing.*;\nimport javax.swing.event.*;\nimport org.openswing.swing.util.client.*;\nimport java.util.List;\nimport java.util.Collections;\n/**\n * <p>Title: OpenSwing Framework</p>\n * <p>Description: Panel used to show the last opened windows and to switch between them.\n * It can contains a toggle button for each added internal frame.\n * User can click on the button to set to front the related internal frame or\n * can reduce to icon or close internal frame by means of the popup menu opened by clicking with the right mouse button on the toggle button or\n * can set to front the internal frame by entering the toggle button with the left mouse button clicked.\n * <p>Copyright: Copyright (C) 2006 Mauro Carniel</p>\n *\n * <p> This file is part of OpenSwing Framework.\n * This library is free software; you can redistribute it and/or\n * modify it under the terms of the (LGPL) Lesser General Public\n * License as published by the Free Software Foundation;\n *\n *                GNU LESSER GENERAL PUBLIC LICENSE\n *                 Version 2.1, February 1999\n *\n * This library is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Library General Public License for more details.\n *\n * You should have received a copy of the GNU Library General Public\n * License along with this library; if not, write to the Free\n * Software Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.\n *\n *       The author may be contacted at:\n *           maurocarniel@tin.it</p>\n *\n * @author Mauro Carniel\n * @version 1.0\n */\npublic class WinIconsPanel extends JPanel {\n  FlowLayout flowLayout1 = new FlowLayout();\n  /** collection of button, linked frame */\n  private Hashtable buttons = new Hashtable();\n  /** collection of pairs <frame title, SortedSet of associated Integer number> */\n  private Hashtable buttonsNr = new Hashtable();\n  /* toggle button width */\n  private static final int len = 120;\n  /** current horizontal position when locating a new toggle button */\n  private int x = 0;\n  /** used to show a popup menu containing a \"close frame\" menu item */\n  private JPopupMenu menu = new JPopupMenu();\n  /** menu item inserted into the popup menu */\n  private JMenuItem closeMenu = new JMenuItem(ClientSettings.getInstance().getResources().getResource(\"close window\"));\n  /** menu item inserted into the popup menu */\n  private JMenuItem iconMenu = new JMenuItem(ClientSettings.getInstance().getResources().getResource(\"reduce to icon\"));\n  /** internal frame to close */\n  private InternalFrame frameToClose = null;\n  public WinIconsPanel() {\n    try {\n      jbInit();\n    }\n    catch(Exception e) {\n      e.printStackTrace();\n    }\n  }\n  public final void init() {\n    this.removeAll();\n    buttons.clear();\n    buttonsNr.clear();\n    this.setMinimumSize(new Dimension(2000,26));\n    this.setPreferredSize(new Dimension(2000,26));\n  }\n  private void jbInit() throws Exception {\n    this.setBorder(BorderFactory.createLoweredBevelBorder());\n    flowLayout1.setAlignment(FlowLayout.LEFT);\n    flowLayout1.setHgap(0);\n    flowLayout1.setVgap(0);\n    this.setLayout(flowLayout1);\n    menu.add(closeMenu);\n    closeMenu.addActionListener(new ActionListener() {\n      public void actionPerformed(ActionEvent e) {\n        try {\n          x = x-len;\n          frameToClose.closeFrame();\n          frameToClose = null;\n        }\n        catch (PropertyVetoException ex) {\n        }\n      }\n    });\n    closeMenu.setVisible(ClientSettings.SHOW_POPUP_MENU_CLOSE);\n    if(ClientSettings.ICON_MENU_WINDOW_CLOSE!=null)\n      closeMenu.setIcon(new ImageIcon(ClientUtils.getImage(ClientSettings.ICON_MENU_WINDOW_CLOSE)));\n    menu.add(iconMenu);\n    iconMenu.addActionListener(new ActionListener() {\n      public void actionPerformed(ActionEvent e) {\n        try {\n          frameToClose.setIcon(true);\n        }\n        catch (PropertyVetoException ex) {\n          ex.printStackTrace();\n        }\n        frameToClose = null;\n      }\n    });\n    iconMenu.setVisible(ClientSettings.SHOW_ICON_POPUP_MENU_REDUCE_ICON);\n    if(ClientSettings.ICON_POPUP_MENU_REDUCE_ICON!=null)\n      iconMenu.setIcon(new ImageIcon(ClientUtils.getImage(ClientSettings.ICON_POPUP_MENU_REDUCE_ICON)));\n  }\n  /**\n   * Add an internal frame icon to the panel.\n   * Add an internal frame listener.\n   * @param frame internal frame to add\n   */\n  public final void add(final InternalFrame frame) {\n    try {\n      Integer n = null;\n      SortedSet list = (SortedSet)buttonsNr.get(frame.getTitle());\n      if (list==null) {\n        list = new TreeSet();\n        n = new Integer(1);\n        list.add(n);\n        buttonsNr.put(frame.getTitle(),list);\n      }\n      else {\n        n = new Integer( ((Integer)list.last()).intValue()+1 );\n        for(int i=1;i<n.intValue();i++)\n          if (!list.contains(new Integer(i))) {\n            n = new Integer(i);\n            break;\n          }\n        list.add(n);\n      }\n      final JToggleButton btn = new JToggleButton((n.intValue()>1?\" [\"+n.intValue()+\"] \":\"\")+frame.getTitle());\n      if (ClientSettings.ICON_ENABLE_FRAME!=null)\n          btn.setIcon(new ImageIcon(ClientUtils.getImage(ClientSettings.ICON_ENABLE_FRAME)));\n      btn.setHorizontalAlignment(SwingConstants.LEFT);\n      btn.setToolTipText(frame.getTitle());\n//      int len = btn.getFontMetrics(btn.getFont()).stringWidth(btn.getText());\n//      btn.setMinimumSize(new Dimension(len+20,24));\n      btn.setMinimumSize(new Dimension(len,24));\n      btn.setMaximumSize(new Dimension(len,24));\n      btn.setPreferredSize(new Dimension(len,24));\n      btn.setSize(new Dimension(len,24));\n//      while (x+len+20>this.getWidth()-200) {\n//        x = x-this.getComponent(0).getWidth();\n//        this.remove(0);\n//\n//        this.revalidate();\n//        this.repaint();\n//      }\n      while (x+len+20>this.getWidth()-200) {\n        if (this.getComponentCount()>0)\n          x = x-this.getComponent(0).getWidth();\n        if (this.getComponentCount()>0)\n          this.remove(0);\n        this.revalidate();\n        this.repaint();\n      }\n      this.add(btn,null);\n      //x = x+len+20;\n      x = x+len;\n      buttons.put(btn,frame);\n      btn.setSelected(true);\n      this.revalidate();\n      this.repaint();\n      btn.addMouseMotionListener(new MouseMotionAdapter() {\n      public void mouseMoved(MouseEvent e) {\n          if (e.getX()<25) {\n            if (ClientSettings.ICON_CLOSE_FRAME_SELECTED!=null)\n              btn.setIcon(new ImageIcon(ClientUtils.getImage(ClientSettings.ICON_CLOSE_FRAME_SELECTED)));\n          } else {\n            if (ClientSettings.ICON_CLOSE_FRAME!=null)\n              btn.setIcon(new ImageIcon(ClientUtils.getImage(ClientSettings.ICON_CLOSE_FRAME)));\n          }\n        }\n      });\n      btn.addMouseListener(new MouseAdapter() {\n        public void mouseExited(MouseEvent e) {\n          if (frame.isSelected()) {\n            if (ClientSettings.ICON_ENABLE_FRAME!=null)\n              btn.setIcon(new ImageIcon(ClientUtils.getImage(ClientSettings.ICON_ENABLE_FRAME)));\n          } else {\n            if(!btn.isSelected())\n              if(ClientSettings.ICON_DISABLE_FRAME!=null)\n                btn.setIcon(new ImageIcon(ClientUtils.getImage(ClientSettings.ICON_DISABLE_FRAME)));\n          }\n        }\n        public void mouseClicked(MouseEvent e) {\n          if (SwingUtilities.isRightMouseButton(e)) {\n            frameToClose = (InternalFrame)buttons.get(btn);\n            if (frameToClose!=null &&\n                frameToClose.getDesktopPane()!=null &&\n                ((DesktopPane)frameToClose.getDesktopPane()).isModal() &&\n                !frameToClose.isModal()) {\n              e.consume();\n              return;\n            }\n            iconMenu.setVisible( frameToClose.isIconifiable() );\n            menu.show(btn,e.getX(),e.getY());\n          }else{\n            if(e.getX() < 25){\n              frameToClose = (InternalFrame)buttons.get(btn);\n              try {\n                frameToClose.closeFrame();\n              } catch (PropertyVetoException ex) {\n            } }\n          }\n        }\n        public void mouseEntered(MouseEvent e) {\n           if (SwingUtilities.isLeftMouseButton(e)) {\n            btn.setSelected(true);\n", "outputs": ["            InternalFrame f = (InternalFrame)buttons.get(btn);"], "input_length": 1503, "output_length": 11, "length": 1514, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "ccfb6b37ba1b0c73d2fa46c8eb0b57d91d94c6314be2df46a6124e702a4bd9e8"}
{"input": "", "context": "# pylint: disable=no-member\n\"\"\"\nUnit tests for the Mixed Modulestore, with DDT for the various stores (Split, Draft, XML)\n\"\"\"\nfrom collections import namedtuple\nimport datetime\nimport logging\nimport ddt\nimport itertools\nimport mimetypes\nfrom unittest import skip\nfrom uuid import uuid4\nfrom contextlib import contextmanager\nfrom mock import patch\n# Mixed modulestore depends on django, so we'll manually configure some django settings\n# before importing the module\n# TODO remove this import and the configuration -- xmodule should not depend on django!\nfrom django.conf import settings\n# This import breaks this test file when run separately. Needs to be fixed! (PLAT-449)\nfrom mock_django import mock_signal_receiver\nfrom nose.plugins.attrib import attr\nimport pymongo\nfrom pytz import UTC\nfrom shutil import rmtree\nfrom tempfile import mkdtemp\nfrom xmodule.x_module import XModuleMixin\nfrom xmodule.modulestore.edit_info import EditInfoMixin\nfrom xmodule.modulestore.inheritance import InheritanceMixin\nfrom xmodule.modulestore.tests.test_cross_modulestore_import_export import MongoContentstoreBuilder\nfrom xmodule.contentstore.content import StaticContent\nfrom opaque_keys.edx.keys import CourseKey\nfrom xmodule.modulestore.xml_importer import import_course_from_xml\nfrom xmodule.modulestore.xml_exporter import export_course_to_xml\nfrom xmodule.modulestore.django import SignalHandler\nif not settings.configured:\n    settings.configure()\nfrom opaque_keys.edx.locations import SlashSeparatedCourseKey\nfrom opaque_keys.edx.locator import BlockUsageLocator, CourseLocator, LibraryLocator\nfrom xmodule.exceptions import InvalidVersionError\nfrom xmodule.modulestore import ModuleStoreEnum\nfrom xmodule.modulestore.draft_and_published import UnsupportedRevisionError, DIRECT_ONLY_CATEGORIES\nfrom xmodule.modulestore.exceptions import ItemNotFoundError, DuplicateCourseError, ReferentialIntegrityError, NoPathToItem\nfrom xmodule.modulestore.mixed import MixedModuleStore\nfrom xmodule.modulestore.search import path_to_location, navigation_index\nfrom xmodule.modulestore.tests.factories import check_mongo_calls, check_exact_number_of_calls, \\\n    mongo_uses_error_check\nfrom xmodule.modulestore.tests.utils import create_modulestore_instance, LocationMixin, mock_tab_from_json\nfrom xmodule.modulestore.tests.mongo_connection import MONGO_PORT_NUM, MONGO_HOST\nfrom xmodule.tests import DATA_DIR, CourseComparisonTest\nlog = logging.getLogger(__name__)\nclass CommonMixedModuleStoreSetup(CourseComparisonTest):\n    \"\"\"\n    Quasi-superclass which tests Location based apps against both split and mongo dbs (Locator and\n    Location-based dbs)\n    \"\"\"\n    HOST = MONGO_HOST\n    PORT = MONGO_PORT_NUM\n    DB = 'test_mongo_%s' % uuid4().hex[:5]\n    COLLECTION = 'modulestore'\n    ASSET_COLLECTION = 'assetstore'\n    FS_ROOT = DATA_DIR\n    DEFAULT_CLASS = 'xmodule.raw_module.RawDescriptor'\n    RENDER_TEMPLATE = lambda t_n, d, ctx=None, nsp='main': ''\n    MONGO_COURSEID = 'MITx/999/2013_Spring'\n    XML_COURSEID1 = 'edX/toy/2012_Fall'\n    XML_COURSEID2 = 'edX/simple/2012_Fall'\n    BAD_COURSE_ID = 'edX/simple'\n    modulestore_options = {\n        'default_class': DEFAULT_CLASS,\n        'fs_root': DATA_DIR,\n        'render_template': RENDER_TEMPLATE,\n        'xblock_mixins': (EditInfoMixin, InheritanceMixin, LocationMixin, XModuleMixin),\n    }\n    DOC_STORE_CONFIG = {\n        'host': HOST,\n        'port': PORT,\n        'db': DB,\n        'collection': COLLECTION,\n        'asset_collection': ASSET_COLLECTION,\n    }\n    MAPPINGS = {\n        XML_COURSEID1: 'xml',\n        XML_COURSEID2: 'xml',\n        BAD_COURSE_ID: 'xml',\n    }\n    OPTIONS = {\n        'stores': [\n            {\n                'NAME': 'draft',\n                'ENGINE': 'xmodule.modulestore.mongo.draft.DraftModuleStore',\n                'DOC_STORE_CONFIG': DOC_STORE_CONFIG,\n                'OPTIONS': modulestore_options\n            },\n            {\n                'NAME': 'split',\n                'ENGINE': 'xmodule.modulestore.split_mongo.split_draft.DraftVersioningModuleStore',\n                'DOC_STORE_CONFIG': DOC_STORE_CONFIG,\n                'OPTIONS': modulestore_options\n            },\n            {\n                'NAME': 'xml',\n                'ENGINE': 'xmodule.modulestore.xml.XMLModuleStore',\n                'OPTIONS': {\n                    'data_dir': DATA_DIR,\n                    'default_class': 'xmodule.hidden_module.HiddenDescriptor',\n                    'xblock_mixins': modulestore_options['xblock_mixins'],\n                }\n            },\n        ],\n        'xblock_mixins': modulestore_options['xblock_mixins'],\n    }\n    def _compare_ignore_version(self, loc1, loc2, msg=None):\n        \"\"\"\n        AssertEqual replacement for CourseLocator\n        \"\"\"\n        if loc1.for_branch(None) != loc2.for_branch(None):\n            self.fail(self._formatMessage(msg, u\"{} != {}\".format(unicode(loc1), unicode(loc2))))\n    def setUp(self):\n        \"\"\"\n        Set up the database for testing\n        \"\"\"\n        super(CommonMixedModuleStoreSetup, self).setUp()\n        self.exclude_field(None, 'wiki_slug')\n        self.exclude_field(None, 'xml_attributes')\n        self.exclude_field(None, 'parent')\n        self.ignore_asset_key('_id')\n        self.ignore_asset_key('uploadDate')\n        self.ignore_asset_key('content_son')\n        self.ignore_asset_key('thumbnail_location')\n        self.options = getattr(self, 'options', self.OPTIONS)\n        self.connection = pymongo.MongoClient(\n            host=self.HOST,\n            port=self.PORT,\n            tz_aware=True,\n        )\n        self.connection.drop_database(self.DB)\n        self.addCleanup(self.connection.drop_database, self.DB)\n        self.addCleanup(self.connection.close)\n        self.addTypeEqualityFunc(BlockUsageLocator, '_compare_ignore_version')\n        self.addTypeEqualityFunc(CourseLocator, '_compare_ignore_version')\n        # define attrs which get set in initdb to quell pylint\n        self.writable_chapter_location = self.store = self.fake_location = self.xml_chapter_location = None\n        self.course_locations = {}\n        self.user_id = ModuleStoreEnum.UserID.test\n    # pylint: disable=invalid-name\n    def _create_course(self, course_key):\n        \"\"\"\n        Create a course w/ one item in the persistence store using the given course & item location.\n        \"\"\"\n        # create course\n        with self.store.bulk_operations(course_key):\n            self.course = self.store.create_course(course_key.org, course_key.course, course_key.run, self.user_id)\n            if isinstance(self.course.id, CourseLocator):\n                self.course_locations[self.MONGO_COURSEID] = self.course.location\n            else:\n                self.assertEqual(self.course.id, course_key)\n            # create chapter\n            chapter = self.store.create_child(self.user_id, self.course.location, 'chapter', block_id='Overview')\n            self.writable_chapter_location = chapter.location\n    def _create_block_hierarchy(self):\n        \"\"\"\n        Creates a hierarchy of blocks for testing\n        Each block's (version_agnostic) location is assigned as a field of the class and can be easily accessed\n        \"\"\"\n        BlockInfo = namedtuple('BlockInfo', 'field_name, category, display_name, sub_tree')\n        trees = [\n            BlockInfo(\n                'chapter_x', 'chapter', 'Chapter_x', [\n                    BlockInfo(\n                        'sequential_x1', 'sequential', 'Sequential_x1', [\n                            BlockInfo(\n                                'vertical_x1a', 'vertical', 'Vertical_x1a', [\n                                    BlockInfo('problem_x1a_1', 'problem', 'Problem_x1a_1', []),\n                                    BlockInfo('problem_x1a_2', 'problem', 'Problem_x1a_2', []),\n                                    BlockInfo('problem_x1a_3', 'problem', 'Problem_x1a_3', []),\n                                    BlockInfo('html_x1a_1', 'html', 'HTML_x1a_1', []),\n                                ]\n                            ),\n                            BlockInfo(\n                                'vertical_x1b', 'vertical', 'Vertical_x1b', []\n                            )\n                        ]\n                    ),\n                    BlockInfo(\n                        'sequential_x2', 'sequential', 'Sequential_x2', []\n                    )\n                ]\n            ),\n            BlockInfo(\n                'chapter_y', 'chapter', 'Chapter_y', [\n                    BlockInfo(\n                        'sequential_y1', 'sequential', 'Sequential_y1', [\n                            BlockInfo(\n                                'vertical_y1a', 'vertical', 'Vertical_y1a', [\n                                    BlockInfo('problem_y1a_1', 'problem', 'Problem_y1a_1', []),\n                                    BlockInfo('problem_y1a_2', 'problem', 'Problem_y1a_2', []),\n                                    BlockInfo('problem_y1a_3', 'problem', 'Problem_y1a_3', []),\n                                ]\n                            )\n                        ]\n                    )\n                ]\n            )\n        ]\n        def create_sub_tree(parent, block_info):\n            \"\"\"\n            recursive function that creates the given block and its descendants\n            \"\"\"\n            block = self.store.create_child(\n                self.user_id, parent.location,\n                block_info.category, block_id=block_info.display_name,\n                fields={'display_name': block_info.display_name},\n            )\n            for tree in block_info.sub_tree:\n                create_sub_tree(block, tree)\n            setattr(self, block_info.field_name, block.location)\n        with self.store.bulk_operations(self.course.id):\n            for tree in trees:\n                create_sub_tree(self.course, tree)\n    def _course_key_from_string(self, string):\n        \"\"\"\n        Get the course key for the given course string\n        \"\"\"\n        return self.course_locations[string].course_key\n    def _has_changes(self, location):\n        \"\"\"\n        Helper function that loads the item before calling has_changes\n        \"\"\"\n        return self.store.has_changes(self.store.get_item(location))\n    # pylint: disable=dangerous-default-value\n    def _initialize_mixed(self, mappings=MAPPINGS, contentstore=None):\n        \"\"\"\n        initializes the mixed modulestore.\n        \"\"\"\n        self.store = MixedModuleStore(\n            contentstore, create_modulestore_instance=create_modulestore_instance,\n            mappings=mappings,\n            **self.options\n        )\n        self.addCleanup(self.store.close_all_connections)\n    def initdb(self, default):\n        \"\"\"\n        Initialize the database and create one test course in it\n        \"\"\"\n        # set the default modulestore\n        store_configs = self.options['stores']\n        for index in range(len(store_configs)):\n            if store_configs[index]['NAME'] == default:\n                if index > 0:\n                    store_configs[index], store_configs[0] = store_configs[0], store_configs[index]\n                break\n        self._initialize_mixed()\n        # convert to CourseKeys\n        self.course_locations = {\n            course_id: CourseLocator.from_string(course_id)\n            for course_id in [self.MONGO_COURSEID, self.XML_COURSEID1, self.XML_COURSEID2]\n        }\n        # and then to the root UsageKey\n        self.course_locations = {\n            course_id: course_key.make_usage_key('course', course_key.run)\n            for course_id, course_key in self.course_locations.iteritems()  # pylint: disable=maybe-no-member\n        }\n        mongo_course_key = self.course_locations[self.MONGO_COURSEID].course_key\n        self.fake_location = self.store.make_course_key(mongo_course_key.org, mongo_course_key.course, mongo_course_key.run).make_usage_key('vertical', 'fake')\n        self.xml_chapter_location = self.course_locations[self.XML_COURSEID1].replace(\n            category='chapter', name='Overview'\n        )\n        self._create_course(self.course_locations[self.MONGO_COURSEID].course_key)\n@ddt.ddt\n@attr('mongo')\nclass TestMixedModuleStore(CommonMixedModuleStoreSetup):\n    \"\"\"\n    Tests of the MixedModulestore interface methods.\n    \"\"\"\n    @ddt.data('draft', 'split')\n    def test_get_modulestore_type(self, default_ms):\n        \"\"\"\n        Make sure we get back the store type we expect for given mappings\n        \"\"\"\n        self.initdb(default_ms)\n        self.assertEqual(self.store.get_modulestore_type(\n            self._course_key_from_string(self.XML_COURSEID1)), ModuleStoreEnum.Type.xml\n        )\n        self.assertEqual(self.store.get_modulestore_type(\n            self._course_key_from_string(self.XML_COURSEID2)), ModuleStoreEnum.Type.xml\n        )\n        mongo_ms_type = ModuleStoreEnum.Type.mongo if default_ms == 'draft' else ModuleStoreEnum.Type.split\n        self.assertEqual(self.store.get_modulestore_type(\n            self._course_key_from_string(self.MONGO_COURSEID)), mongo_ms_type\n        )\n        # try an unknown mapping, it should be the 'default' store\n        self.assertEqual(self.store.get_modulestore_type(\n            SlashSeparatedCourseKey('foo', 'bar', '2012_Fall')), mongo_ms_type\n        )\n    @ddt.data('draft', 'split')\n    def test_get_modulestore_cache(self, default_ms):\n        \"\"\"\n        Make sure we cache discovered course mappings\n        \"\"\"\n        self.initdb(default_ms)\n        # unset mappings\n        self.store.mappings = {}\n        course_key = self.course_locations[self.MONGO_COURSEID].course_key\n        with check_exact_number_of_calls(self.store.default_modulestore, 'has_course', 1):\n            self.assertEqual(self.store.default_modulestore, self.store._get_modulestore_for_courselike(course_key))  # pylint: disable=protected-access\n            self.assertIn(course_key, self.store.mappings)\n            self.assertEqual(self.store.default_modulestore, self.store._get_modulestore_for_courselike(course_key))  # pylint: disable=protected-access\n    @ddt.data(*itertools.product(\n        (ModuleStoreEnum.Type.mongo, ModuleStoreEnum.Type.split),\n        (True, False)\n    ))\n    @ddt.unpack\n    def test_duplicate_course_error(self, default_ms, reset_mixed_mappings):\n        \"\"\"\n        Make sure we get back the store type we expect for given mappings\n        \"\"\"\n        self._initialize_mixed(mappings={})\n        with self.store.default_store(default_ms):\n            self.store.create_course('org_x', 'course_y', 'run_z', self.user_id)\n            if reset_mixed_mappings:\n                self.store.mappings = {}\n            with self.assertRaises(DuplicateCourseError):\n                self.store.create_course('org_x', 'course_y', 'run_z', self.user_id)\n    # Draft:\n    #    problem: One lookup to locate an item that exists\n    #    fake: one w/ wildcard version\n    # split has one lookup for the course and then one for the course items\n    @ddt.data(('draft', [1, 1], 0), ('split', [2, 2], 0))\n    @ddt.unpack\n    def test_has_item(self, default_ms, max_find, max_send):\n        self.initdb(default_ms)\n        self._create_block_hierarchy()\n        self.assertTrue(self.store.has_item(self.course_locations[self.XML_COURSEID1]))\n        with check_mongo_calls(max_find.pop(0), max_send):\n            self.assertTrue(self.store.has_item(self.problem_x1a_1))\n        # try negative cases\n        self.assertFalse(self.store.has_item(\n            self.course_locations[self.XML_COURSEID1].replace(name='not_findable', category='problem')\n        ))\n        with check_mongo_calls(max_find.pop(0), max_send):\n            self.assertFalse(self.store.has_item(self.fake_location))\n        # verify that an error is raised when the revision is not valid\n        with self.assertRaises(UnsupportedRevisionError):\n            self.store.has_item(self.fake_location, revision=ModuleStoreEnum.RevisionOption.draft_preferred)\n    # draft queries:\n    #   problem: find draft item, find all items pertinent to inheritance computation, find parent\n    #   non-existent problem: find draft, find published\n    # split:\n    #   problem: active_versions, structure\n    #   non-existent problem: ditto\n    @ddt.data(('draft', [3, 2], 0), ('split', [2, 2], 0))\n    @ddt.unpack\n    def test_get_item(self, default_ms, max_find, max_send):\n        self.initdb(default_ms)\n        self._create_block_hierarchy()\n        self.assertIsNotNone(self.store.get_item(self.course_locations[self.XML_COURSEID1]))\n        with check_mongo_calls(max_find.pop(0), max_send):\n            self.assertIsNotNone(self.store.get_item(self.problem_x1a_1))\n        # try negative cases\n        with self.assertRaises(ItemNotFoundError):\n            self.store.get_item(\n                self.course_locations[self.XML_COURSEID1].replace(name='not_findable', category='problem')\n            )\n        with check_mongo_calls(max_find.pop(0), max_send):\n            with self.assertRaises(ItemNotFoundError):\n                self.store.get_item(self.fake_location)\n        # verify that an error is raised when the revision is not valid\n        with self.assertRaises(UnsupportedRevisionError):\n            self.store.get_item(self.fake_location, revision=ModuleStoreEnum.RevisionOption.draft_preferred)\n    # Draft:\n    #    wildcard query, 6! load pertinent items for inheritance calls, load parents, course root fetch (why)\n    # Split:\n    #    active_versions (with regex), structure, and spurious active_versions refetch\n    @ddt.data(('draft', 14, 0), ('split', 3, 0))\n    @ddt.unpack\n    def test_get_items(self, default_ms, max_find, max_send):\n        self.initdb(default_ms)\n        self._create_block_hierarchy()\n        course_locn = self.course_locations[self.XML_COURSEID1]\n        # NOTE: use get_course if you just want the course. get_items is expensive\n        modules = self.store.get_items(course_locn.course_key, qualifiers={'category': 'course'})\n        self.assertEqual(len(modules), 1)\n        self.assertEqual(modules[0].location, course_locn)\n        course_locn = self.course_locations[self.MONGO_COURSEID]\n        with check_mongo_calls(max_find, max_send):\n            modules = self.store.get_items(course_locn.course_key, qualifiers={'category': 'problem'})\n        self.assertEqual(len(modules), 6)\n        # verify that an error is raised when the revision is not valid\n        with self.assertRaises(UnsupportedRevisionError):\n            self.store.get_items(\n                self.course_locations[self.MONGO_COURSEID].course_key,\n                revision=ModuleStoreEnum.RevisionOption.draft_preferred\n            )\n    # draft: get draft, get ancestors up to course (2-6), compute inheritance\n    #    sends: update problem and then each ancestor up to course (edit info)\n    # split: active_versions, definitions (calculator field), structures\n    #  2 sends to update index & structure (note, it would also be definition if a content field changed)\n    @ddt.data(('draft', 7, 5), ('split', 3, 2))\n    @ddt.unpack\n    def test_update_item(self, default_ms, max_find, max_send):\n        \"\"\"\n        Update should fail for r/o dbs and succeed for r/w ones\n        \"\"\"\n        self.initdb(default_ms)\n        self._create_block_hierarchy()\n        course = self.store.get_course(self.course_locations[self.XML_COURSEID1].course_key)\n        # if following raised, then the test is really a noop, change it\n        self.assertFalse(course.show_calculator, \"Default changed making test meaningless\")\n        course.show_calculator = True\n        with self.assertRaises(NotImplementedError):  # ensure it doesn't allow writing\n            self.store.update_item(course, self.user_id)\n        # now do it for a r/w db\n        problem = self.store.get_item(self.problem_x1a_1)\n        # if following raised, then the test is really a noop, change it\n        self.assertNotEqual(problem.max_attempts, 2, \"Default changed making test meaningless\")\n        problem.max_attempts = 2\n        with check_mongo_calls(max_find, max_send):\n            problem = self.store.update_item(problem, self.user_id)\n        self.assertEqual(problem.max_attempts, 2, \"Update didn't persist\")\n    @ddt.data('draft', 'split')\n    def test_has_changes_direct_only(self, default_ms):\n        \"\"\"\n        Tests that has_changes() returns false when a new xblock in a direct only category is checked\n        \"\"\"\n        self.initdb(default_ms)\n        test_course = self.store.create_course('testx', 'GreekHero', 'test_run', self.user_id)\n        # Create dummy direct only xblocks\n        chapter = self.store.create_item(\n            self.user_id,\n            test_course.id,\n            'chapter',\n            block_id='vertical_container'\n        )\n        # Check that neither xblock has changes\n        self.assertFalse(self.store.has_changes(test_course))\n        self.assertFalse(self.store.has_changes(chapter))\n    @ddt.data('draft', 'split')\n    def test_has_changes(self, default_ms):\n        \"\"\"\n        Tests that has_changes() only returns true when changes are present\n        \"\"\"\n        self.initdb(default_ms)\n        test_course = self.store.create_course('testx', 'GreekHero', 'test_run', self.user_id)\n        # Create a dummy component to test against\n        xblock = self.store.create_item(\n            self.user_id,\n            test_course.id,\n            'vertical',\n            block_id='test_vertical'\n        )\n        # Not yet published, so changes are present\n        self.assertTrue(self.store.has_changes(xblock))\n        # Publish and verify that there are no unpublished changes\n        newXBlock = self.store.publish(xblock.location, self.user_id)\n        self.assertFalse(self.store.has_changes(newXBlock))\n        # Change the component, then check that there now are changes\n        component = self.store.get_item(xblock.location)\n        component.display_name = 'Changed Display Name'\n        component = self.store.update_item(component, self.user_id)\n        self.assertTrue(self.store.has_changes(component))\n        # Publish and verify again\n        component = self.store.publish(component.location, self.user_id)\n        self.assertFalse(self.store.has_changes(component))\n    @ddt.data('draft', 'split')\n    def test_unit_stuck_in_draft_mode(self, default_ms):\n        \"\"\"\n        After revert_to_published() the has_changes() should return false if draft has no changes\n        \"\"\"\n        self.initdb(default_ms)\n        test_course = self.store.create_course('testx', 'GreekHero', 'test_run', self.user_id)\n        # Create a dummy component to test against\n        xblock = self.store.create_item(\n            self.user_id,\n            test_course.id,\n            'vertical',\n            block_id='test_vertical'\n        )\n        # Not yet published, so changes are present\n        self.assertTrue(self.store.has_changes(xblock))\n        # Publish and verify that there are no unpublished changes\n        component = self.store.publish(xblock.location, self.user_id)\n        self.assertFalse(self.store.has_changes(component))\n        self.store.revert_to_published(component.location, self.user_id)\n        component = self.store.get_item(component.location)\n        self.assertFalse(self.store.has_changes(component))\n        # Publish and verify again\n        component = self.store.publish(component.location, self.user_id)\n        self.assertFalse(self.store.has_changes(component))\n    @ddt.data('draft', 'split')\n    def test_unit_stuck_in_published_mode(self, default_ms):\n        \"\"\"\n        After revert_to_published() the has_changes() should return true if draft has changes\n        \"\"\"\n        self.initdb(default_ms)\n        test_course = self.store.create_course('testx', 'GreekHero', 'test_run', self.user_id)\n        # Create a dummy component to test against\n        xblock = self.store.create_item(\n            self.user_id,\n            test_course.id,\n            'vertical',\n            block_id='test_vertical'\n        )\n        # Not yet published, so changes are present\n        self.assertTrue(self.store.has_changes(xblock))\n        # Publish and verify that there are no unpublished changes\n        component = self.store.publish(xblock.location, self.user_id)\n        self.assertFalse(self.store.has_changes(component))\n        # Discard changes and verify that there are no changes\n        self.store.revert_to_published(component.location, self.user_id)\n        component = self.store.get_item(component.location)\n        self.assertFalse(self.store.has_changes(component))\n        # Change the component, then check that there now are changes\n        component = self.store.get_item(component.location)\n        component.display_name = 'Changed Display Name'\n        self.store.update_item(component, self.user_id)\n        # Verify that changes are present\n        self.assertTrue(self.store.has_changes(component))\n    def setup_has_changes(self, default_ms):\n        \"\"\"\n        Common set up for has_changes tests below.\n        Returns a dictionary of useful location maps for testing.\n        \"\"\"\n        self.initdb(default_ms)\n        self._create_block_hierarchy()\n        locations = {\n            'grandparent': self.chapter_x,\n            'parent_sibling': self.sequential_x2,\n            'parent': self.sequential_x1,\n            'child_sibling': self.vertical_x1b,\n            'child': self.vertical_x1a,\n        }\n        # Publish the vertical units\n        self.store.publish(locations['parent_sibling'], self.user_id)\n        self.store.publish(locations['parent'], self.user_id)\n        return locations\n    @ddt.data('draft', 'split')\n    def test_has_changes_ancestors(self, default_ms):\n        \"\"\"\n        Tests that has_changes() returns true on ancestors when a child is changed\n        \"\"\"\n        locations = self.setup_has_changes(default_ms)\n        # Verify that there are no unpublished changes\n        for key in locations:\n            self.assertFalse(self._has_changes(locations[key]))\n        # Change the child\n        child = self.store.get_item(locations['child'])\n        child.display_name = 'Changed Display Name'\n        self.store.update_item(child, self.user_id)\n        # All ancestors should have changes, but not siblings\n        self.assertTrue(self._has_changes(locations['grandparent']))\n        self.assertTrue(self._has_changes(locations['parent']))\n        self.assertTrue(self._has_changes(locations['child']))\n        self.assertFalse(self._has_changes(locations['parent_sibling']))\n        self.assertFalse(self._has_changes(locations['child_sibling']))\n        # Publish the unit with changes\n        self.store.publish(locations['parent'], self.user_id)\n        # Verify that there are no unpublished changes\n        for key in locations:\n            self.assertFalse(self._has_changes(locations[key]))\n    @ddt.data('draft', 'split')\n    def test_has_changes_publish_ancestors(self, default_ms):\n        \"\"\"\n        Tests that has_changes() returns false after a child is published only if all children are unchanged\n        \"\"\"\n        locations = self.setup_has_changes(default_ms)\n        # Verify that there are no unpublished changes\n        for key in locations:\n            self.assertFalse(self._has_changes(locations[key]))\n        # Change both children\n        child = self.store.get_item(locations['child'])\n        child_sibling = self.store.get_item(locations['child_sibling'])\n        child.display_name = 'Changed Display Name'\n        child_sibling.display_name = 'Changed Display Name'\n        self.store.update_item(child, user_id=self.user_id)\n        self.store.update_item(child_sibling, user_id=self.user_id)\n        # Verify that ancestors have changes\n        self.assertTrue(self._has_changes(locations['grandparent']))\n        self.assertTrue(self._has_changes(locations['parent']))\n        # Publish one child\n        self.store.publish(locations['child_sibling'], self.user_id)\n        # Verify that ancestors still have changes\n        self.assertTrue(self._has_changes(locations['grandparent']))\n        self.assertTrue(self._has_changes(locations['parent']))\n        # Publish the other child\n        self.store.publish(locations['child'], self.user_id)\n        # Verify that ancestors now have no changes\n        self.assertFalse(self._has_changes(locations['grandparent']))\n        self.assertFalse(self._has_changes(locations['parent']))\n    @ddt.data('draft', 'split')\n    def test_has_changes_add_remove_child(self, default_ms):\n        \"\"\"\n        Tests that has_changes() returns true for the parent when a child with changes is added\n        and false when that child is removed.\n        \"\"\"\n        locations = self.setup_has_changes(default_ms)\n        # Test that the ancestors don't have changes\n        self.assertFalse(self._has_changes(locations['grandparent']))\n        self.assertFalse(self._has_changes(locations['parent']))\n        # Create a new child and attach it to parent\n        self.store.create_child(\n            self.user_id,\n            locations['parent'],\n            'vertical',\n            block_id='new_child',\n        )\n        # Verify that the ancestors now have changes\n        self.assertTrue(self._has_changes(locations['grandparent']))\n        self.assertTrue(self._has_changes(locations['parent']))\n        # Remove the child from the parent\n        parent = self.store.get_item(locations['parent'])\n        parent.children = [locations['child'], locations['child_sibling']]\n        self.store.update_item(parent, user_id=self.user_id)\n        # Verify that ancestors now have no changes\n        self.assertFalse(self._has_changes(locations['grandparent']))\n        self.assertFalse(self._has_changes(locations['parent']))\n    @ddt.data('draft', 'split')\n    def test_has_changes_non_direct_only_children(self, default_ms):\n        \"\"\"\n        Tests that has_changes() returns true after editing the child of a vertical (both not direct only categories).\n        \"\"\"\n        self.initdb(default_ms)\n        parent = self.store.create_item(\n            self.user_id,\n            self.course.id,\n            'vertical',\n            block_id='parent',\n        )\n        child = self.store.create_child(\n            self.user_id,\n            parent.location,\n            'html',\n            block_id='child',\n        )\n        self.store.publish(parent.location, self.user_id)\n        # Verify that there are no changes\n        self.assertFalse(self._has_changes(parent.location))\n        self.assertFalse(self._has_changes(child.location))\n        # Change the child\n        child.display_name = 'Changed Display Name'\n        self.store.update_item(child, user_id=self.user_id)\n        # Verify that both parent and child have changes\n        self.assertTrue(self._has_changes(parent.location))\n        self.assertTrue(self._has_changes(child.location))\n    @ddt.data(*itertools.product(\n        ('draft', 'split'),\n        (ModuleStoreEnum.Branch.draft_preferred, ModuleStoreEnum.Branch.published_only)\n    ))\n    @ddt.unpack\n    def test_has_changes_missing_child(self, default_ms, default_branch):\n        \"\"\"\n        Tests that has_changes() does not throw an exception when a child doesn't exist.\n        \"\"\"\n        self.initdb(default_ms)\n        with self.store.branch_setting(default_branch, self.course.id):\n            # Create the parent and point it to a fake child\n            parent = self.store.create_item(\n                self.user_id,\n                self.course.id,\n                'vertical',\n                block_id='parent',\n            )\n            parent.children += [self.course.id.make_usage_key('vertical', 'does_not_exist')]\n            parent = self.store.update_item(parent, self.user_id)\n            # Check the parent for changes should return True and not throw an exception\n            self.assertTrue(self.store.has_changes(parent))\n    # Draft\n    #   Find: find parents (definition.children query), get parent, get course (fill in run?),\n    #         find parents of the parent (course), get inheritance items,\n    #         get item (to delete subtree), get inheritance again.\n    #   Sends: delete item, update parent\n    # Split\n    #   Find: active_versions, 2 structures (published & draft), definition (unnecessary)\n    #   Sends: updated draft and published structures and active_versions\n    @ddt.data(('draft', 7, 2), ('split', 4, 3))\n    @ddt.unpack\n    def test_delete_item(self, default_ms, max_find, max_send):\n        \"\"\"\n        Delete should reject on r/o db and work on r/w one\n        \"\"\"\n        self.initdb(default_ms)\n        if default_ms == 'draft' and mongo_uses_error_check(self.store):\n            max_find += 1\n        # r/o try deleting the chapter (is here to ensure it can't be deleted)\n        with self.assertRaises(NotImplementedError):\n            self.store.delete_item(self.xml_chapter_location, self.user_id)\n        with self.store.branch_setting(ModuleStoreEnum.Branch.draft_preferred, self.writable_chapter_location.course_key):\n            with check_mongo_calls(max_find, max_send):\n                self.store.delete_item(self.writable_chapter_location, self.user_id)\n            # verify it's gone\n            with self.assertRaises(ItemNotFoundError):\n                self.store.get_item(self.writable_chapter_location)\n        # verify it's gone from published too\n        with self.assertRaises(ItemNotFoundError):\n            self.store.get_item(self.writable_chapter_location, revision=ModuleStoreEnum.RevisionOption.published_only)\n    # Draft:\n    #    queries: find parent (definition.children), count versions of item, get parent, count grandparents,\n    #             inheritance items, draft item, draft child, inheritance\n    #    sends: delete draft vertical and update parent\n    # Split:\n    #    queries: active_versions, draft and published structures, definition (unnecessary)\n    #    sends: update published (why?), draft, and active_versions\n    @ddt.data(('draft', 9, 2), ('split', 2, 2))\n    @ddt.unpack\n    def test_delete_private_vertical(self, default_ms, max_find, max_send):\n        \"\"\"\n        Because old mongo treated verticals as the first layer which could be draft, it has some interesting\n        behavioral properties which this deletion test gets at.\n        \"\"\"\n        self.initdb(default_ms)\n        if default_ms == 'draft' and mongo_uses_error_check(self.store):\n            max_find += 1\n        # create and delete a private vertical with private children\n        private_vert = self.store.create_child(\n            # don't use course_location as it may not be the repr\n            self.user_id, self.course_locations[self.MONGO_COURSEID],\n            'vertical', block_id='private'\n        )\n        private_leaf = self.store.create_child(\n            # don't use course_location as it may not be the repr\n            self.user_id, private_vert.location, 'html', block_id='private_leaf'\n        )\n        # verify pre delete state (just to verify that the test is valid)\n        if hasattr(private_vert.location, 'version_guid'):\n            # change to the HEAD version\n            vert_loc = private_vert.location.for_version(private_leaf.location.version_guid)\n        else:\n            vert_loc = private_vert.location\n        self.assertTrue(self.store.has_item(vert_loc))\n        self.assertTrue(self.store.has_item(private_leaf.location))\n        course = self.store.get_course(self.course_locations[self.MONGO_COURSEID].course_key, 0)\n        self.assertIn(vert_loc, course.children)\n        # delete the vertical and ensure the course no longer points to it\n        with check_mongo_calls(max_find, max_send):\n            self.store.delete_item(vert_loc, self.user_id)\n        course = self.store.get_course(self.course_locations[self.MONGO_COURSEID].course_key, 0)\n        if hasattr(private_vert.location, 'version_guid'):\n            # change to the HEAD version\n            vert_loc = private_vert.location.for_version(course.location.version_guid)\n            leaf_loc = private_leaf.location.for_version(course.location.version_guid)\n        else:\n            vert_loc = private_vert.location\n            leaf_loc = private_leaf.location\n        self.assertFalse(self.store.has_item(vert_loc))\n        self.assertFalse(self.store.has_item(leaf_loc))\n        self.assertNotIn(vert_loc, course.children)\n    # Draft:\n    #   find: find parent (definition.children) 2x, find draft item, get inheritance items\n    #   send: one delete query for specific item\n    # Split:\n    #   find: active_version & structure (cached)\n    #   send: update structure and active_versions\n    @ddt.data(('draft', 4, 1), ('split', 2, 2))\n    @ddt.unpack\n    def test_delete_draft_vertical(self, default_ms, max_find, max_send):\n        \"\"\"\n        Test deleting a draft vertical which has a published version.\n        \"\"\"\n        self.initdb(default_ms)\n        # reproduce bug STUD-1965\n        # create and delete a private vertical with private children\n        private_vert = self.store.create_child(\n            # don't use course_location as it may not be the repr\n            self.user_id, self.course_locations[self.MONGO_COURSEID], 'vertical', block_id='publish'\n        )\n        private_leaf = self.store.create_child(\n            self.user_id, private_vert.location, 'html', block_id='bug_leaf'\n        )\n        # verify that an error is raised when the revision is not valid\n        with self.assertRaises(UnsupportedRevisionError):\n            self.store.delete_item(\n                private_leaf.location,\n                self.user_id,\n                revision=ModuleStoreEnum.RevisionOption.draft_preferred\n            )\n        self.store.publish(private_vert.location, self.user_id)\n        private_leaf.display_name = 'change me'\n        private_leaf = self.store.update_item(private_leaf, self.user_id)\n        # test succeeds if delete succeeds w/o error\n        if default_ms == 'draft' and mongo_uses_error_check(self.store):\n            max_find += 1\n        with check_mongo_calls(max_find, max_send):\n            self.store.delete_item(private_leaf.location, self.user_id)\n    # Draft:\n    #   1) find all courses (wildcard),\n    #   2) get each course 1 at a time (1 course),\n    #   3) wildcard split if it has any (1) but it doesn't\n    # Split:\n    #   1) wildcard split search,\n    #   2-4) active_versions, structure, definition (s/b lazy; so, unnecessary)\n    #   5) wildcard draft mongo which has none\n    @ddt.data(('draft', 3, 0), ('split', 5, 0))\n    @ddt.unpack\n    def test_get_courses(self, default_ms, max_find, max_send):\n        self.initdb(default_ms)\n        # we should have 3 total courses across all stores\n        with check_mongo_calls(max_find, max_send):\n            courses = self.store.get_courses()\n            course_ids = [course.location for course in courses]\n            self.assertEqual(len(courses), 3, \"Not 3 courses: {}\".format(course_ids))\n            self.assertIn(self.course_locations[self.MONGO_COURSEID], course_ids)\n            self.assertIn(self.course_locations[self.XML_COURSEID1], course_ids)\n            self.assertIn(self.course_locations[self.XML_COURSEID2], course_ids)\n        with self.store.branch_setting(ModuleStoreEnum.Branch.draft_preferred):\n            draft_courses = self.store.get_courses(remove_branch=True)\n        with self.store.branch_setting(ModuleStoreEnum.Branch.published_only):\n            published_courses = self.store.get_courses(remove_branch=True)\n        self.assertEquals([c.id for c in draft_courses], [c.id for c in published_courses])\n    @ddt.data('draft', 'split')\n    def test_create_child_detached_tabs(self, default_ms):\n        \"\"\"\n        test 'create_child' method with a detached category ('static_tab')\n        to check that new static tab is not a direct child of the course\n        \"\"\"\n        self.initdb(default_ms)\n        mongo_course = self.store.get_course(self.course_locations[self.MONGO_COURSEID].course_key)\n        self.assertEqual(len(mongo_course.children), 1)\n        # create a static tab of the course\n        self.store.create_child(\n            self.user_id,\n            self.course.location,\n            'static_tab'\n        )\n        # now check that the course has same number of children\n        mongo_course = self.store.get_course(self.course_locations[self.MONGO_COURSEID].course_key)\n        self.assertEqual(len(mongo_course.children), 1)\n    def test_xml_get_courses(self):\n        \"\"\"\n        Test that the xml modulestore only loaded the courses from the maps.\n        \"\"\"\n        self.initdb('draft')\n        xml_store = self.store._get_modulestore_by_type(ModuleStoreEnum.Type.xml)  # pylint: disable=protected-access\n        courses = xml_store.get_courses()\n        self.assertEqual(len(courses), 2)\n        course_ids = [course.id for course in courses]\n        self.assertIn(self.course_locations[self.XML_COURSEID1].course_key, course_ids)\n        self.assertIn(self.course_locations[self.XML_COURSEID2].course_key, course_ids)\n        # this course is in the directory from which we loaded courses but not in the map\n        self.assertNotIn(\"edX/toy/TT_2012_Fall\", course_ids)\n    def test_xml_no_write(self):\n        \"\"\"\n        Test that the xml modulestore doesn't allow write ops.\n        \"\"\"\n        self.initdb('draft')\n        xml_store = self.store._get_modulestore_by_type(ModuleStoreEnum.Type.xml)  # pylint: disable=protected-access\n        # the important thing is not which exception it raises but that it raises an exception\n        with self.assertRaises(AttributeError):\n            xml_store.create_course(\"org\", \"course\", \"run\", self.user_id)\n    # draft is 2: find out which ms owns course, get item\n    # split: active_versions, structure, definition (to load course wiki string)\n    @ddt.data(('draft', 2, 0), ('split', 3, 0))\n    @ddt.unpack\n    def test_get_course(self, default_ms, max_find, max_send):\n        \"\"\"\n        This test is here for the performance comparison not functionality. It tests the performance\n        of getting an item whose scope.content fields are looked at.\n        \"\"\"\n        self.initdb(default_ms)\n        with check_mongo_calls(max_find, max_send):\n            course = self.store.get_item(self.course_locations[self.MONGO_COURSEID])\n            self.assertEqual(course.id, self.course_locations[self.MONGO_COURSEID].course_key)\n        course = self.store.get_item(self.course_locations[self.XML_COURSEID1])\n        self.assertEqual(course.id, self.course_locations[self.XML_COURSEID1].course_key)\n    @ddt.data('draft', 'split')\n    def test_get_library(self, default_ms):\n        \"\"\"\n        Test that create_library and get_library work regardless of the default modulestore.\n        Other tests of MixedModulestore support are in test_libraries.py but this one must\n        be done here so we can test the configuration where Draft/old is the first modulestore.\n        \"\"\"\n        self.initdb(default_ms)\n        with self.store.default_store(ModuleStoreEnum.Type.split):  # The CMS also wraps create_library like this\n            library = self.store.create_library(\"org\", \"lib\", self.user_id, {\"display_name\": \"Test Library\"})\n        library_key = library.location.library_key\n        self.assertIsInstance(library_key, LibraryLocator)\n        # Now load with get_library and make sure it works:\n        library = self.store.get_library(library_key)\n        self.assertEqual(library.location.library_key, library_key)\n        # Clear the mappings so we can test get_library code path without mapping set:\n        self.store.mappings.clear()\n        library = self.store.get_library(library_key)\n        self.assertEqual(library.location.library_key, library_key)\n    # notice this doesn't test getting a public item via draft_preferred which draft would have 2 hits (split\n    # still only 2)\n    # Draft: get_parent\n    # Split: active_versions, structure\n    @ddt.data(('draft', 1, 0), ('split', 2, 0))\n    @ddt.unpack\n    def test_get_parent_locations(self, default_ms, max_find, max_send):\n        \"\"\"\n        Test a simple get parent for a direct only category (i.e, always published)\n        \"\"\"\n        self.initdb(default_ms)\n        self._create_block_hierarchy()\n        with check_mongo_calls(max_find, max_send):\n            parent = self.store.get_parent_location(self.problem_x1a_1)\n            self.assertEqual(parent, self.vertical_x1a)\n        parent = self.store.get_parent_location(self.xml_chapter_location)\n        self.assertEqual(parent, self.course_locations[self.XML_COURSEID1])\n    def verify_get_parent_locations_results(self, expected_results):\n        \"\"\"\n        Verifies the results of calling get_parent_locations matches expected_results.\n        \"\"\"\n        for child_location, parent_location, revision in expected_results:\n            self.assertEqual(\n                parent_location,\n                self.store.get_parent_location(child_location, revision=revision)\n            )\n    @ddt.data('draft', 'split')\n    def test_get_parent_locations_moved_child(self, default_ms):\n        self.initdb(default_ms)\n        self._create_block_hierarchy()\n        # publish the course\n        self.course = self.store.publish(self.course.location, self.user_id)\n        with self.store.bulk_operations(self.course.id):\n            # make drafts of verticals\n            self.store.convert_to_draft(self.vertical_x1a, self.user_id)\n            self.store.convert_to_draft(self.vertical_y1a, self.user_id)\n            # move child problem_x1a_1 to vertical_y1a\n            child_to_move_location = self.problem_x1a_1\n            new_parent_location = self.vertical_y1a\n            old_parent_location = self.vertical_x1a\n            with self.store.branch_setting(ModuleStoreEnum.Branch.draft_preferred):\n                old_parent = self.store.get_item(child_to_move_location).get_parent()\n            self.assertEqual(old_parent_location, old_parent.location)\n            child_to_move_contextualized = child_to_move_location.map_into_course(old_parent.location.course_key)\n            old_parent.children.remove(child_to_move_contextualized)\n            self.store.update_item(old_parent, self.user_id)\n            new_parent = self.store.get_item(new_parent_location)\n            new_parent.children.append(child_to_move_location)\n            self.store.update_item(new_parent, self.user_id)\n            with self.store.branch_setting(ModuleStoreEnum.Branch.draft_preferred):\n                self.assertEqual(new_parent_location, self.store.get_item(child_to_move_location).get_parent().location)\n            with self.store.branch_setting(ModuleStoreEnum.Branch.published_only):\n                self.assertEqual(old_parent_location, self.store.get_item(child_to_move_location).get_parent().location)\n            old_parent_published_location = old_parent_location.for_branch(ModuleStoreEnum.BranchName.published)\n            self.verify_get_parent_locations_results([\n                (child_to_move_location, new_parent_location, None),\n                (child_to_move_location, new_parent_location, ModuleStoreEnum.RevisionOption.draft_preferred),\n                (child_to_move_location, old_parent_published_location, ModuleStoreEnum.RevisionOption.published_only),\n            ])\n        # publish the course again\n        self.store.publish(self.course.location, self.user_id)\n        new_parent_published_location = new_parent_location.for_branch(ModuleStoreEnum.BranchName.published)\n        self.verify_get_parent_locations_results([\n            (child_to_move_location, new_parent_location, None),\n            (child_to_move_location, new_parent_location, ModuleStoreEnum.RevisionOption.draft_preferred),\n            (child_to_move_location, new_parent_published_location, ModuleStoreEnum.RevisionOption.published_only),\n        ])\n    @ddt.data('draft')\n    def test_get_parent_locations_deleted_child(self, default_ms):\n        self.initdb(default_ms)\n        self._create_block_hierarchy()\n        # publish the course\n        self.store.publish(self.course.location, self.user_id)\n        # make draft of vertical\n        self.store.convert_to_draft(self.vertical_y1a, self.user_id)\n        # delete child problem_y1a_1\n        child_to_delete_location = self.problem_y1a_1\n        old_parent_location = self.vertical_y1a\n        self.store.delete_item(child_to_delete_location, self.user_id)\n        self.verify_get_parent_locations_results([\n            (child_to_delete_location, old_parent_location, None),\n            # Note: The following could be an unexpected result, but we want to avoid an extra database call\n            (child_to_delete_location, old_parent_location, ModuleStoreEnum.RevisionOption.draft_preferred),\n            (child_to_delete_location, old_parent_location, ModuleStoreEnum.RevisionOption.published_only),\n        ])\n        # publish the course again\n        self.store.publish(self.course.location, self.user_id)\n        self.verify_get_parent_locations_results([\n            (child_to_delete_location, None, None),\n            (child_to_delete_location, None, ModuleStoreEnum.RevisionOption.draft_preferred),\n            (child_to_delete_location, None, ModuleStoreEnum.RevisionOption.published_only),\n        ])\n    @ddt.data('draft')\n    def test_get_parent_location_draft(self, default_ms):\n        \"\"\"\n        Test that \"get_parent_location\" method returns first published parent\n        for a draft component, if it has many possible parents (including\n        draft parents).\n        \"\"\"\n        self.initdb(default_ms)\n        course_id = self.course_locations[self.MONGO_COURSEID].course_key\n        # create parented children\n        self._create_block_hierarchy()\n        self.store.publish(self.course.location, self.user_id)\n        mongo_store = self.store._get_modulestore_for_courselike(course_id)  # pylint: disable=protected-access\n        # add another parent (unit) \"vertical_x1b\" for problem \"problem_x1a_1\"\n        mongo_store.collection.update(\n            self.vertical_x1b.to_deprecated_son('_id.'),\n            {'$push': {'definition.children': unicode(self.problem_x1a_1)}}\n        )\n        # convert first parent (unit) \"vertical_x1a\" of problem \"problem_x1a_1\" to draft\n        self.store.convert_to_draft(self.vertical_x1a, self.user_id)\n        item = self.store.get_item(self.vertical_x1a)\n        self.assertTrue(self.store.has_published_version(item))\n        # now problem \"problem_x1a_1\" has 3 parents [vertical_x1a (draft),\n        # vertical_x1a (published), vertical_x1b (published)]\n        # check that \"get_parent_location\" method of draft branch returns first\n        # published parent \"vertical_x1a\" without raising \"AssertionError\" for\n        # problem location revision\n        with self.store.branch_setting(ModuleStoreEnum.Branch.draft_preferred, course_id):\n            parent = mongo_store.get_parent_location(self.problem_x1a_1)\n            self.assertEqual(parent, self.vertical_x1a)\n    # Draft:\n    #   Problem path:\n    #    1. Get problem\n    #    2-6. get parent and rest of ancestors up to course\n    #    7-8. get sequential, compute inheritance\n    #    8-9. get vertical, compute inheritance\n    #    10-11. get other vertical_x1b (why?) and compute inheritance\n    # Split: active_versions & structure\n    @ddt.data(('draft', [12, 3], 0), ('split', [2, 2], 0))\n    @ddt.unpack\n    def test_path_to_location(self, default_ms, num_finds, num_sends):\n        \"\"\"\n        Make sure that path_to_location works\n        \"\"\"\n        self.initdb(default_ms)\n        course_key = self.course_locations[self.MONGO_COURSEID].course_key\n        with self.store.branch_setting(ModuleStoreEnum.Branch.published_only, course_key):\n            self._create_block_hierarchy()\n            should_work = (\n                (self.problem_x1a_2,\n                 (course_key, u\"Chapter_x\", u\"Sequential_x1\", '1')),\n                (self.chapter_x,\n                 (course_key, \"Chapter_x\", None, None)),\n            )\n            for location, expected in should_work:\n                # each iteration has different find count, pop this iter's find count\n                with check_mongo_calls(num_finds.pop(0), num_sends):\n                    self.assertEqual(path_to_location(self.store, location), expected)\n        not_found = (\n            course_key.make_usage_key('video', 'WelcomeX'),\n            course_key.make_usage_key('course', 'NotHome'),\n        )\n        for location in not_found:\n            with self.assertRaises(ItemNotFoundError):\n                path_to_location(self.store, location)\n        # Orphaned items should not be found.\n        orphan = course_key.make_usage_key('chapter', 'OrphanChapter')\n        self.store.create_item(\n            self.user_id,\n            orphan.course_key,\n            orphan.block_type,\n            block_id=orphan.block_id\n        )\n        with self.assertRaises(NoPathToItem):\n            path_to_location(self.store, orphan)\n    def test_xml_path_to_location(self):\n        \"\"\"\n        Make sure that path_to_location works: should be passed a modulestore\n        with the toy and simple courses loaded.\n        \"\"\"\n        # only needs course_locations set\n        self.initdb('draft')\n        course_key = self.course_locations[self.XML_COURSEID1].course_key\n        should_work = (\n            (course_key.make_usage_key('video', 'Welcome'),\n             (course_key, \"Overview\", \"Welcome\", None)),\n            (course_key.make_usage_key('chapter', 'Overview'),\n             (course_key, \"Overview\", None, None)),\n        )\n        for location, expected in should_work:\n            self.assertEqual(path_to_location(self.store, location), expected)\n        not_found = (\n            course_key.make_usage_key('video', 'WelcomeX'),\n            course_key.make_usage_key('course', 'NotHome'),\n        )\n        for location in not_found:\n            with self.assertRaises(ItemNotFoundError):\n                path_to_location(self.store, location)\n    def test_navigation_index(self):\n        \"\"\"\n        Make sure that navigation_index correctly parses the various position values that we might get from calls to\n        path_to_location\n        \"\"\"\n        self.assertEqual(1, navigation_index(\"1\"))\n        self.assertEqual(10, navigation_index(\"10\"))\n        self.assertEqual(None, navigation_index(None))\n        self.assertEqual(1, navigation_index(\"1_2\"))\n        self.assertEqual(5, navigation_index(\"5_2\"))\n        self.assertEqual(7, navigation_index(\"7_3_5_6_\"))\n    @ddt.data('draft', 'split')\n    def test_revert_to_published_root_draft(self, default_ms):\n        \"\"\"\n        Test calling revert_to_published on draft vertical.\n        \"\"\"\n        self.initdb(default_ms)\n        self._create_block_hierarchy()\n        vertical = self.store.get_item(self.vertical_x1a)\n        vertical_children_num = len(vertical.children)\n        self.store.publish(self.course.location, self.user_id)\n        self.assertFalse(self._has_changes(self.vertical_x1a))\n        # delete leaf problem (will make parent vertical a draft)\n        self.store.delete_item(self.problem_x1a_1, self.user_id)\n        self.assertTrue(self._has_changes(self.vertical_x1a))\n        draft_parent = self.store.get_item(self.vertical_x1a)\n        self.assertEqual(vertical_children_num - 1, len(draft_parent.children))\n        published_parent = self.store.get_item(\n            self.vertical_x1a,\n            revision=ModuleStoreEnum.RevisionOption.published_only\n        )\n        self.assertEqual(vertical_children_num, len(published_parent.children))\n        self.store.revert_to_published(self.vertical_x1a, self.user_id)\n        reverted_parent = self.store.get_item(self.vertical_x1a)\n        self.assertEqual(vertical_children_num, len(published_parent.children))\n        self.assertBlocksEqualByFields(reverted_parent, published_parent)\n        self.assertFalse(self._has_changes(self.vertical_x1a))\n    @ddt.data('draft', 'split')\n    def test_revert_to_published_root_published(self, default_ms):\n        \"\"\"\n        Test calling revert_to_published on a published vertical with a draft child.\n        \"\"\"\n        self.initdb(default_ms)\n        self._create_block_hierarchy()\n        self.store.publish(self.course.location, self.user_id)\n        problem = self.store.get_item(self.problem_x1a_1)\n        orig_display_name = problem.display_name\n        # Change display name of problem and update just it (so parent remains published)\n        problem.display_name = \"updated before calling revert\"\n        self.store.update_item(problem, self.user_id)\n        self.store.revert_to_published(self.vertical_x1a, self.user_id)\n        reverted_problem = self.store.get_item(self.problem_x1a_1)\n        self.assertEqual(orig_display_name, reverted_problem.display_name)\n    @ddt.data('draft', 'split')\n    def test_revert_to_published_no_draft(self, default_ms):\n        \"\"\"\n        Test calling revert_to_published on vertical with no draft content does nothing.\n        \"\"\"\n        self.initdb(default_ms)\n        self._create_block_hierarchy()\n        self.store.publish(self.course.location, self.user_id)\n        orig_vertical = self.store.get_item(self.vertical_x1a)\n        self.store.revert_to_published(self.vertical_x1a, self.user_id)\n        reverted_vertical = self.store.get_item(self.vertical_x1a)\n        self.assertBlocksEqualByFields(orig_vertical, reverted_vertical)\n    @ddt.data('draft', 'split')\n    def test_revert_to_published_no_published(self, default_ms):\n        \"\"\"\n        Test calling revert_to_published on vertical with no published version errors.\n        \"\"\"\n        self.initdb(default_ms)\n        self._create_block_hierarchy()\n        with self.assertRaises(InvalidVersionError):\n            self.store.revert_to_published(self.vertical_x1a, self.user_id)\n    @ddt.data('draft', 'split')\n    def test_revert_to_published_direct_only(self, default_ms):\n        \"\"\"\n        Test calling revert_to_published on a direct-only item is a no-op.\n        \"\"\"\n        self.initdb(default_ms)\n        self._create_block_hierarchy()\n        num_children = len(self.store.get_item(self.sequential_x1).children)\n        self.store.revert_to_published(self.sequential_x1, self.user_id)\n        reverted_parent = self.store.get_item(self.sequential_x1)\n        # It does not discard the child vertical, even though that child is a draft (with no published version)\n        self.assertEqual(num_children, len(reverted_parent.children))\n    # Draft: get all items which can be or should have parents\n    # Split: active_versions, structure\n    @ddt.data(('draft', 1, 0), ('split', 2, 0))\n    @ddt.unpack\n    def test_get_orphans(self, default_ms, max_find, max_send):\n        \"\"\"\n        Test finding orphans.\n        \"\"\"\n        self.initdb(default_ms)\n        course_id = self.course_locations[self.MONGO_COURSEID].course_key\n        # create parented children\n        self._create_block_hierarchy()\n        # orphans\n        orphan_locations = [\n            course_id.make_usage_key('chapter', 'OrphanChapter'),\n            course_id.make_usage_key('vertical', 'OrphanVertical'),\n            course_id.make_usage_key('problem', 'OrphanProblem'),\n            course_id.make_usage_key('html', 'OrphanHTML'),\n        ]\n        # detached items (not considered as orphans)\n        detached_locations = [\n            course_id.make_usage_key('static_tab', 'StaticTab'),\n            course_id.make_usage_key('course_info', 'updates'),\n        ]\n        for location in (orphan_locations + detached_locations):\n            self.store.create_item(\n                self.user_id,\n                location.course_key,\n                location.block_type,\n                block_id=location.block_id\n            )\n        with check_mongo_calls(max_find, max_send):\n            found_orphans = self.store.get_orphans(self.course_locations[self.MONGO_COURSEID].course_key)\n        self.assertItemsEqual(found_orphans, orphan_locations)\n    @ddt.data('draft')\n    def test_get_non_orphan_parents(self, default_ms):\n        \"\"\"\n        Test finding non orphan parents from many possible parents.\n        \"\"\"\n        self.initdb(default_ms)\n        course_id = self.course_locations[self.MONGO_COURSEID].course_key\n        # create parented children\n        self._create_block_hierarchy()\n        self.store.publish(self.course.location, self.user_id)\n        # test that problem \"problem_x1a_1\" has only one published parent\n        mongo_store = self.store._get_modulestore_for_courselike(course_id)  # pylint: disable=protected-access\n        with self.store.branch_setting(ModuleStoreEnum.Branch.published_only, course_id):\n            parent = mongo_store.get_parent_location(self.problem_x1a_1)\n            self.assertEqual(parent, self.vertical_x1a)\n        # add some published orphans\n        orphan_sequential = course_id.make_usage_key('sequential', 'OrphanSequential')\n        orphan_vertical = course_id.make_usage_key('vertical', 'OrphanVertical')\n        orphan_locations = [orphan_sequential, orphan_vertical]\n        for location in orphan_locations:\n            self.store.create_item(\n                self.user_id,\n                location.course_key,\n                location.block_type,\n                block_id=location.block_id\n            )\n            self.store.publish(location, self.user_id)\n        found_orphans = mongo_store.get_orphans(course_id)\n        self.assertEqual(set(found_orphans), set(orphan_locations))\n        self.assertEqual(len(set(found_orphans)), 2)\n        # add orphan vertical and sequential as another parents of problem \"problem_x1a_1\"\n        mongo_store.collection.update(\n            orphan_sequential.to_deprecated_son('_id.'),\n            {'$push': {'definition.children': unicode(self.problem_x1a_1)}}\n        )\n        mongo_store.collection.update(\n            orphan_vertical.to_deprecated_son('_id.'),\n            {'$push': {'definition.children': unicode(self.problem_x1a_1)}}\n        )\n        # test that \"get_parent_location\" method of published branch still returns the correct non-orphan parent for\n        # problem \"problem_x1a_1\" since the two other parents are orphans\n        with self.store.branch_setting(ModuleStoreEnum.Branch.published_only, course_id):\n            parent = mongo_store.get_parent_location(self.problem_x1a_1)\n            self.assertEqual(parent, self.vertical_x1a)\n        # now add valid published vertical as another parent of problem\n        mongo_store.collection.update(\n            self.sequential_x1.to_deprecated_son('_id.'),\n            {'$push': {'definition.children': unicode(self.problem_x1a_1)}}\n        )\n        # now check that \"get_parent_location\" method of published branch raises \"ReferentialIntegrityError\" for\n        # problem \"problem_x1a_1\" since it has now 2 valid published parents\n        with self.store.branch_setting(ModuleStoreEnum.Branch.published_only, course_id):\n            self.assertTrue(self.store.has_item(self.problem_x1a_1))\n            with self.assertRaises(ReferentialIntegrityError):\n                self.store.get_parent_location(self.problem_x1a_1)\n    @ddt.data('draft')\n    def test_create_item_from_parent_location(self, default_ms):\n        \"\"\"\n        Test a code path missed by the above: passing an old-style location as parent but no\n        new location for the child\n        \"\"\"\n        self.initdb(default_ms)\n        self.store.create_child(\n            self.user_id,\n            self.course_locations[self.MONGO_COURSEID],\n            'problem',\n            block_id='orphan'\n        )\n        orphans = self.store.get_orphans(self.course_locations[self.MONGO_COURSEID].course_key)\n        self.assertEqual(len(orphans), 0, \"unexpected orphans: {}\".format(orphans))\n    @ddt.data('draft', 'split')\n    def test_create_item_populates_edited_info(self, default_ms):\n        self.initdb(default_ms)\n        block = self.store.create_item(\n            self.user_id,\n            self.course.location.course_key,\n            'problem'\n        )\n        self.assertEqual(self.user_id, block.edited_by)\n        self.assertGreater(datetime.datetime.now(UTC), block.edited_on)\n    @ddt.data('draft', 'split')\n    def test_create_item_populates_subtree_edited_info(self, default_ms):\n        self.initdb(default_ms)\n        block = self.store.create_item(\n            self.user_id,\n            self.course.location.course_key,\n            'problem'\n        )\n        self.assertEqual(self.user_id, block.subtree_edited_by)\n        self.assertGreater(datetime.datetime.now(UTC), block.subtree_edited_on)\n    # Draft: wildcard search of draft and split\n    # Split: wildcard search of draft and split\n    @ddt.data(('draft', 2, 0), ('split', 2, 0))\n    @ddt.unpack\n    def test_get_courses_for_wiki(self, default_ms, max_find, max_send):\n        \"\"\"\n        Test the get_courses_for_wiki method\n        \"\"\"\n        self.initdb(default_ms)\n        # Test XML wikis\n        wiki_courses = self.store.get_courses_for_wiki('toy')\n        self.assertEqual(len(wiki_courses), 1)\n        self.assertIn(self.course_locations[self.XML_COURSEID1].course_key, wiki_courses)\n        wiki_courses = self.store.get_courses_for_wiki('simple')\n        self.assertEqual(len(wiki_courses), 1)\n        self.assertIn(self.course_locations[self.XML_COURSEID2].course_key, wiki_courses)\n        # Test Mongo wiki\n        with check_mongo_calls(max_find, max_send):\n            wiki_courses = self.store.get_courses_for_wiki('999')\n        self.assertEqual(len(wiki_courses), 1)\n        self.assertIn(\n            self.course_locations[self.MONGO_COURSEID].course_key.replace(branch=None),  # Branch agnostic\n            wiki_courses\n        )\n        self.assertEqual(len(self.store.get_courses_for_wiki('edX.simple.2012_Fall')), 0)\n        self.assertEqual(len(self.store.get_courses_for_wiki('no_such_wiki')), 0)\n    # Draft:\n    #    Find: find vertical, find children\n    #    Sends:\n    #      1. delete all of the published nodes in subtree\n    #      2. insert vertical as published (deleted in step 1) w/ the deleted problems as children\n    #      3-6. insert the 3 problems and 1 html as published\n    # Split: active_versions, 2 structures (pre & post published?)\n    # Sends:\n    #    - insert structure\n    #    - write index entry\n    @ddt.data(('draft', 2, 6), ('split', 3, 2))\n    @ddt.unpack\n    def test_unpublish(self, default_ms, max_find, max_send):\n        \"\"\"\n        Test calling unpublish\n        \"\"\"\n        self.initdb(default_ms)\n        if default_ms == 'draft' and mongo_uses_error_check(self.store):\n            max_find += 1\n        self._create_block_hierarchy()\n        # publish\n        self.store.publish(self.course.location, self.user_id)\n        published_xblock = self.store.get_item(\n            self.vertical_x1a,\n            revision=ModuleStoreEnum.RevisionOption.published_only\n        )\n        self.assertIsNotNone(published_xblock)\n        # unpublish\n        with check_mongo_calls(max_find, max_send):\n            self.store.unpublish(self.vertical_x1a, self.user_id)\n        with self.assertRaises(ItemNotFoundError):\n            self.store.get_item(\n                self.vertical_x1a,\n                revision=ModuleStoreEnum.RevisionOption.published_only\n            )\n        # make sure draft version still exists\n        draft_xblock = self.store.get_item(\n            self.vertical_x1a,\n            revision=ModuleStoreEnum.RevisionOption.draft_only\n        )\n        self.assertIsNotNone(draft_xblock)\n    # Draft: specific query for revision None\n    # Split: active_versions, structure\n    @ddt.data(('draft', 1, 0), ('split', 2, 0))\n    @ddt.unpack\n    def test_has_published_version(self, default_ms, max_find, max_send):\n        \"\"\"\n        Test the has_published_version method\n        \"\"\"\n        self.initdb(default_ms)\n        self._create_block_hierarchy()\n        # start off as Private\n        item = self.store.create_child(self.user_id, self.writable_chapter_location, 'problem', 'test_compute_publish_state')\n        item_location = item.location\n        with check_mongo_calls(max_find, max_send):\n            self.assertFalse(self.store.has_published_version(item))\n        # Private -> Public\n        self.store.publish(item_location, self.user_id)\n        item = self.store.get_item(item_location)\n        self.assertTrue(self.store.has_published_version(item))\n        # Public -> Private\n        self.store.unpublish(item_location, self.user_id)\n        item = self.store.get_item(item_location)\n        self.assertFalse(self.store.has_published_version(item))\n        # Private -> Public\n        self.store.publish(item_location, self.user_id)\n        item = self.store.get_item(item_location)\n        self.assertTrue(self.store.has_published_version(item))\n        # Public -> Draft with NO changes\n        self.store.convert_to_draft(item_location, self.user_id)\n        item = self.store.get_item(item_location)\n        self.assertTrue(self.store.has_published_version(item))\n        # Draft WITH changes\n        item.display_name = 'new name'\n        item = self.store.update_item(item, self.user_id)\n        self.assertTrue(self.store.has_changes(item))\n        self.assertTrue(self.store.has_published_version(item))\n    @ddt.data('draft', 'split')\n    def test_update_edit_info_ancestors(self, default_ms):\n        \"\"\"\n        Tests that edited_on, edited_by, subtree_edited_on, and subtree_edited_by are set correctly during update\n        \"\"\"\n        self.initdb(default_ms)\n        test_course = self.store.create_course('testx', 'GreekHero', 'test_run', self.user_id)\n        def check_node(location_key, after, before, edited_by, subtree_after, subtree_before, subtree_by):\n            \"\"\"\n            Checks that the node given by location_key matches the given edit_info constraints.\n            \"\"\"\n            node = self.store.get_item(location_key)\n            if after:\n                self.assertLess(after, node.edited_on)\n            self.assertLess(node.edited_on, before)\n            self.assertEqual(node.edited_by, edited_by)\n            if subtree_after:\n                self.assertLess(subtree_after, node.subtree_edited_on)\n            self.assertLess(node.subtree_edited_on, subtree_before)\n            self.assertEqual(node.subtree_edited_by, subtree_by)\n        with self.store.bulk_operations(test_course.id):\n            # Create a dummy vertical & html to test against\n            component = self.store.create_child(\n                self.user_id,\n                test_course.location,\n                'vertical',\n                block_id='test_vertical'\n            )\n            child = self.store.create_child(\n                self.user_id,\n                component.location,\n                'html',\n                block_id='test_html'\n            )\n            sibling = self.store.create_child(\n                self.user_id,\n                component.location,\n                'html',\n                block_id='test_html_no_change'\n            )\n        after_create = datetime.datetime.now(UTC)\n        # Verify that all nodes were last edited in the past by create_user\n        for block in [component, child, sibling]:\n            check_node(block.location, None, after_create, self.user_id, None, after_create, self.user_id)\n        # Change the component, then check that there now are changes\n        component.display_name = 'Changed Display Name'\n        editing_user = self.user_id - 2\n        with self.store.bulk_operations(test_course.id):  # TNL-764 bulk ops disabled ancestor updates\n", "outputs": ["            component = self.store.update_item(component, editing_user)"], "input_length": 9521, "output_length": 8, "length": 9529, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "37d78372635a182faf8d15828501f0b0f7ba6361622943bad514903bd6df6a9d"}
{"input": "", "context": "#!/usr/bin/env python\n#\n# Copyright 2011 Stef Walter\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU Lesser General Public License as published\n# by the Free Software Foundation; either version 2 of the licence or (at\n# your option) any later version.\n#\n# See the included COPYING file for more information.\n#\nimport getopt\nimport os\nimport sys\nimport time\nimport unittest\nimport aes\nimport dh\nimport hkdf\nimport dbus\nimport dbus.service\nimport dbus.glib\nimport gobject\nCOLLECTION_PREFIX = \"/org/freedesktop/secrets/collection/\"\nbus_name = 'org.freedesktop.Secret.MockService'\nready_pipe = -1\nobjects = { }\nclass NotSupported(dbus.exceptions.DBusException):\n\tdef __init__(self, msg):\n\t\tdbus.exceptions.DBusException.__init__(self, msg, name=\"org.freedesktop.DBus.Error.NotSupported\")\nclass InvalidArgs(dbus.exceptions.DBusException):\n\tdef __init__(self, msg):\n\t\tdbus.exceptions.DBusException.__init__(self, msg, name=\"org.freedesktop.DBus.Error.InvalidArgs\")\nclass IsLocked(dbus.exceptions.DBusException):\n\tdef __init__(self, msg):\n\t\tdbus.exceptions.DBusException.__init__(self, msg, name=\"org.freedesktop.Secret.Error.IsLocked\")\nclass NoSuchObject(dbus.exceptions.DBusException):\n\tdef __init__(self, msg):\n\t\tdbus.exceptions.DBusException.__init__(self, msg, name=\"org.freedesktop.Secret.Error.NoSuchObject\")\nunique_identifier = 111\ndef next_identifier(prefix=''):\n\tglobal unique_identifier\n\tunique_identifier += 1\n\treturn \"%s%d\" % (prefix, unique_identifier)\ndef encode_identifier(value):\n\treturn \"\".join([(c.isalpha() or c.isdigit()) and c or \"_%02x\" % ord(c) \\\n\t                       for c in value.encode('utf-8')])\ndef hex_encode(string):\n\treturn \"\".join([hex(ord(c))[2:].zfill(2) for c in string])\ndef alias_path(name):\n\treturn \"/org/freedesktop/secrets/aliases/%s\" % name\nclass PlainAlgorithm():\n\tdef negotiate(self, service, sender, param):\n\t\tif type (param) != dbus.String:\n\t\t\traise InvalidArgs(\"invalid argument passed to OpenSession\")\n\t\tsession = SecretSession(service, sender, self, None)\n\t\treturn (dbus.String(\"\", variant_level=1), session)\n\tdef encrypt(self, key, data):\n\t\treturn (\"\", data)\n\tdef decrypt(self, param, data):\n\t\tif params == \"\":\n\t\t\traise InvalidArgs(\"invalid secret plain parameter\")\n\t\treturn data\nclass AesAlgorithm():\n\tdef negotiate(self, service, sender, param):\n\t\tif type (param) != dbus.ByteArray:\n\t\t\traise InvalidArgs(\"invalid argument passed to OpenSession\")\n\t\tprivat, publi = dh.generate_pair()\n\t\tpeer = dh.bytes_to_number(param)\n\t\t# print \"mock publi: \", hex(publi)\n\t\t# print \" mock peer: \", hex(peer)\n\t\tikm = dh.derive_key(privat, peer)\n\t\t# print \"  mock ikm: \", hex_encode(ikm)\n\t\tkey = hkdf.hkdf(ikm, 16)\n\t\t# print \"  mock key: \", hex_encode(key)\n\t\tsession = SecretSession(service, sender, self, key)\n\t\treturn (dbus.ByteArray(dh.number_to_bytes(publi), variant_level=1), session)\n\tdef encrypt(self, key, data):\n\t\tkey = map(ord, key)\n\t\tdata = aes.append_PKCS7_padding(data)\n\t\tkeysize = len(key)\n\t\tiv = [ord(i) for i in os.urandom(16)]\n\t\tmode = aes.AESModeOfOperation.modeOfOperation[\"CBC\"]\n\t\tmoo = aes.AESModeOfOperation()\n\t\t(mode, length, ciph) = moo.encrypt(data, mode, key, keysize, iv)\n\t\treturn (\"\".join([chr(i) for i in iv]),\n\t\t        \"\".join([chr(i) for i in ciph]))\n\tdef decrypt(self, key, param, data):\n\t\tkey = map(ord, key)\n\t\tkeysize = len(key)\n\t\tiv = map(ord, param[:16])\n\t\tdata = map(ord, data)\n\t\tmoo = aes.AESModeOfOperation()\n\t\tmode = aes.AESModeOfOperation.modeOfOperation[\"CBC\"]\n\t\tdecr = moo.decrypt(data, None, mode, key, keysize, iv)\n\t\treturn aes.strip_PKCS7_padding(decr)\nclass SecretPrompt(dbus.service.Object):\n\tdef __init__(self, service, sender, prompt_name=None, delay=0,\n\t             dismiss=False, action=None):\n\t\tself.sender = sender\n\t\tself.service = service\n\t\tself.delay = 0\n\t\tself.dismiss = False\n\t\tself.result = dbus.String(\"\", variant_level=1)\n\t\tself.action = action\n\t\tself.completed = False\n\t\tif prompt_name:\n\t\t\tself.path = \"/org/freedesktop/secrets/prompts/%s\" % prompt_name\n\t\telse:\n\t\t\tself.path = \"/org/freedesktop/secrets/prompts/%s\" % next_identifier('p')\n\t\tdbus.service.Object.__init__(self, service.bus_name, self.path)\n\t\tservice.add_prompt(self)\n\t\tassert self.path not in objects\n\t\tobjects[self.path] = self\n\tdef _complete(self):\n\t\tif self.completed:\n\t\t\treturn\n\t\tself.completed = True\n\t\tself.Completed(self.dismiss, self.result)\n\t\tself.remove_from_connection()\n\t@dbus.service.method('org.freedesktop.Secret.Prompt')\n\tdef Prompt(self, window_id):\n\t\tif self.action:\n\t\t\tself.result = self.action()\n\t\tgobject.timeout_add(self.delay * 1000, self._complete)\n\t@dbus.service.method('org.freedesktop.Secret.Prompt')\n\tdef Dismiss(self):\n\t\tself._complete()\n\t@dbus.service.signal(dbus_interface='org.freedesktop.Secret.Prompt', signature='bv')\n\tdef Completed(self, dismiss, result):\n\t\tpass\nclass SecretSession(dbus.service.Object):\n\tdef __init__(self, service, sender, algorithm, key):\n\t\tself.sender = sender\n\t\tself.service = service\n\t\tself.algorithm = algorithm\n\t\tself.key = key\n\t\tself.path = \"/org/freedesktop/secrets/sessions/%s\" % next_identifier('s')\n\t\tdbus.service.Object.__init__(self, service.bus_name, self.path)\n\t\tservice.add_session(self)\n\t\tobjects[self.path] = self\n\tdef encode_secret(self, secret, content_type):\n\t\t(params, data) = self.algorithm.encrypt(self.key, secret)\n\t\t# print \"   mock iv: \", hex_encode(params)\n\t\t# print \" mock ciph: \", hex_encode(data)\n\t\treturn dbus.Struct((dbus.ObjectPath(self.path), dbus.ByteArray(params),\n\t\t                    dbus.ByteArray(data), dbus.String(content_type)),\n\t\t                   signature=\"oayays\")\n\tdef decode_secret(self, value):\n\t\tplain = self.algorithm.decrypt(self.key, value[1], value[2])\n\t\treturn (plain, value[3])\n\t@dbus.service.method('org.freedesktop.Secret.Session')\n\tdef Close(self):\n\t\tself.remove_from_connection()\n\t\tself.service.remove_session(self)\nclass SecretItem(dbus.service.Object):\n\tSUPPORTS_MULTIPLE_OBJECT_PATHS = True\n\tdef __init__(self, collection, identifier=None, label=\"Item\", attributes={ },\n\t             secret=\"\", confirm=False, content_type=\"text/plain\", type=None):\n\t\tif identifier is None:\n\t\t\tidentifier = next_identifier()\n\t\tidentifier = encode_identifier(identifier)\n\t\tself.collection = collection\n\t\tself.identifier = identifier\n\t\tself.label = label or \"Unnamed item\"\n\t\tself.secret = secret\n\t\tself.type = type or \"org.freedesktop.Secret.Generic\"\n\t\tself.attributes = attributes\n\t\tself.content_type = content_type\n\t\tself.path = \"%s/%s\" % (collection.path, identifier)\n\t\tself.confirm = confirm\n\t\tself.created = self.modified = time.time()\n\t\tdbus.service.Object.__init__(self, collection.service.bus_name, self.path)\n\t\tself.collection.add_item(self)\n\t\tobjects[self.path] = self\n\tdef add_alias(self, name):\n\t\tpath = \"%s/%s\" % (alias_path(name), self.identifier)\n\t\tobjects[path] = self\n\t\tself.add_to_connection(self.connection, path)\n\tdef remove_alias(self, name):\n\t\tpath = \"%s/%s\" % (alias_path(name), self.identifier)\n\t\tdel objects[path]\n\t\tself.remove_from_connection(self.connection, path)\n\tdef match_attributes(self, attributes):\n\t\tfor (key, value) in attributes.items():\n\t\t\tif not self.attributes.get(key) == value:\n\t\t\t\treturn False\n\t\treturn True\n\tdef get_locked(self):\n\t\treturn self.collection.locked\n\tdef perform_xlock(self, lock):\n\t\treturn self.collection.perform_xlock(lock)\n\tdef perform_delete(self):\n\t\tself.collection.remove_item(self)\n\t\tdel objects[self.path]\n\t\tself.remove_from_connection()\n\t@dbus.service.method('org.freedesktop.Secret.Item', sender_keyword='sender')\n\tdef GetSecret(self, session_path, sender=None):\n\t\tsession = objects.get(session_path, None)\n\t\tif not session or session.sender != sender:\n\t\t\traise InvalidArgs(\"session invalid: %s\" % session_path)\n\t\tif self.get_locked():\n\t\t\traise IsLocked(\"secret is locked: %s\" % self.path)\n\t\treturn session.encode_secret(self.secret, self.content_type)\n\t@dbus.service.method('org.freedesktop.Secret.Item', sender_keyword='sender', byte_arrays=True)\n\tdef SetSecret(self, secret, sender=None):\n\t\tsession = objects.get(secret[0], None)\n\t\tif not session or session.sender != sender:\n\t\t\traise InvalidArgs(\"session invalid: %s\" % secret[0])\n\t\tif self.get_locked():\n\t\t\traise IsLocked(\"secret is locked: %s\" % self.path)\n\t\t(self.secret, self.content_type) = session.decode_secret(secret)\n\t@dbus.service.method('org.freedesktop.Secret.Item', sender_keyword='sender')\n\tdef Delete(self, sender=None):\n\t\titem = self\n\t\tdef prompt_callback():\n\t\t\titem.perform_delete()\n\t\t\treturn dbus.String(\"\", variant_level=1)\n\t\tif self.confirm:\n\t\t\tprompt = SecretPrompt(self.collection.service, sender,\n\t\t\t                      dismiss=False, action=prompt_callback)\n\t\t\treturn dbus.ObjectPath(prompt.path)\n\t\telse:\n\t\t\tself.perform_delete()\n\t\t\treturn dbus.ObjectPath(\"/\")\n\t@dbus.service.method(dbus.PROPERTIES_IFACE, in_signature='ss', out_signature='v')\n\tdef Get(self, interface_name, property_name):\n\t\treturn self.GetAll(interface_name)[property_name]\n\t@dbus.service.method(dbus.PROPERTIES_IFACE, in_signature='s', out_signature='a{sv}')\n\tdef GetAll(self, interface_name):\n\t\tif interface_name == 'org.freedesktop.Secret.Item':\n\t\t\treturn {\n\t\t\t\t'Locked': self.get_locked(),\n\t\t\t\t'Attributes': dbus.Dictionary(self.attributes, signature='ss', variant_level=1),\n\t\t\t\t'Label': self.label,\n\t\t\t\t'Created': dbus.UInt64(self.created),\n\t\t\t\t'Modified': dbus.UInt64(self.modified),\n\t\t\t\t# For compatibility with libgnome-keyring, not part of spec\n\t\t\t\t'Type': self.type\n\t\t\t}\n\t\telse:\n\t\t\traise InvalidArgs('Unknown %s interface' % interface_name)\n\t@dbus.service.method(dbus.PROPERTIES_IFACE, in_signature='ssv')\n\tdef Set(self, interface_name, property_name, new_value):\n\t\tif interface_name != 'org.freedesktop.Secret.Item':\n\t\t\traise InvalidArgs('Unknown %s interface' % interface_name)\n\t\tif property_name == \"Label\":\n\t\t\tself.label = str(new_value)\n\t\telif property_name == \"Attributes\":\n\t\t\tself.attributes = dict(new_value)\n\t\t# For compatibility with libgnome-keyring, not part of spec\n\t\telif property_name == \"Type\":\n\t\t\tself.type = str(new_value)\n\t\telse:\n\t\t\traise InvalidArgs('Not writable %s property' % property_name)\n\t\tself.PropertiesChanged(interface_name, { property_name: new_value }, [])\n\t@dbus.service.signal(dbus.PROPERTIES_IFACE, signature='sa{sv}as')\n\tdef PropertiesChanged(self, interface_name, changed_properties, invalidated_properties):\n\t\tself.modified = time.time()\nclass SecretCollection(dbus.service.Object):\n\tSUPPORTS_MULTIPLE_OBJECT_PATHS = True\n\tdef __init__(self, service, identifier=None, label=\"Collection\", locked=False,\n\t             confirm=False, master=None):\n\t\tif identifier is None:\n\t\t\tidentifier = next_identifier(label)\n\t\tidentifier = encode_identifier(identifier)\n\t\tself.service = service\n\t\tself.identifier = identifier\n\t\tself.label = label or \"Unnamed collection\"\n\t\tself.locked = locked\n\t\tself.items = { }\n\t\tself.confirm = confirm\n\t\tself.master = None\n\t\tself.created = self.modified = time.time()\n\t\tself.aliased = set()\n\t\tself.path = \"%s%s\" % (COLLECTION_PREFIX, identifier)\n\t\tdbus.service.Object.__init__(self, service.bus_name, self.path)\n\t\tself.service.add_collection(self)\n\t\tobjects[self.path] = self\n\tdef add_item(self, item):\n\t\tself.items[item.path] = item\n\t\tfor alias in self.aliased:\n\t\t\titem.add_alias(alias)\n\tdef remove_item(self, item):\n\t\tfor alias in self.aliased:\n\t\t\titem.remove_alias(alias)\n\t\tdel self.items[item.path]\n\tdef add_alias(self, name):\n\t\tif name in self.aliased:\n\t\t\treturn\n\t\tself.aliased.add(name)\n\t\tfor item in self.items.values():\n\t\t\titem.add_alias(name)\n\t\tpath = alias_path(name)\n\t\tobjects[path] = self\n\t\tself.add_to_connection(self.connection, path)\n\tdef remove_alias(self, name):\n\t\tif name not in self.aliased:\n\t\t\treturn\n\t\tpath = alias_path(name)\n\t\tself.aliased.remove(name)\n\t\tdel objects[path]\n\t\tself.remove_from_connection(self.connection, path)\n\t\tfor item in self.items.values():\n\t\t\titem.remove_alias(name)\n\tdef search_items(self, attributes):\n\t\tresults = []\n\t\tfor item in self.items.values():\n\t\t\tif item.match_attributes(attributes):\n\t\t\t\tresults.append(item)\n\t\treturn results\n\tdef get_locked(self):\n\t\treturn self.locked\n\tdef perform_xlock(self, lock):\n\t\tself.locked = lock\n\t\tfor item in self.items.values():\n\t\t\tself.PropertiesChanged('org.freedesktop.Secret.Item', { \"Locked\" : lock }, [])\n\t\tself.PropertiesChanged('org.freedesktop.Secret.Collection', { \"Locked\" : lock }, [])\n\tdef perform_delete(self):\n\t\tfor item in self.items.values():\n\t\t\titem.perform_delete()\n\t\tdel objects[self.path]\n\t\tself.service.remove_collection(self)\n\t\tfor alias in list(self.aliased):\n\t\t\tself.remove_alias(alias)\n\t\tself.remove_from_connection()\n\t@dbus.service.method('org.freedesktop.Secret.Collection', byte_arrays=True, sender_keyword='sender')\n\tdef CreateItem(self, properties, value, replace, sender=None):\n\t\tsession_path = value[0]\n\t\tsession = objects.get(session_path, None)\n\t\tif not session or session.sender != sender:\n\t\t\traise InvalidArgs(\"session invalid: %s\" % session_path)\n\t\tif self.locked:\n\t\t\traise IsLocked(\"collection is locked: %s\" % self.path)\n\t\tattributes = properties.get(\"org.freedesktop.Secret.Item.Attributes\", { })\n\t\tlabel = properties.get(\"org.freedesktop.Secret.Item.Label\", None)\n\t\t(secret, content_type) = session.decode_secret(value)\n\t\titem = None\n\t\t# This is done for compatibility with libgnome-keyring, not part of spec\n\t\ttype = properties.get(\"org.freedesktop.Secret.Item.Type\", None)\n\t\tif replace:\n\t\t\titems = self.search_items(attributes)\n\t\t\tif items:\n\t\t\t\titem = items[0]\n\t\tif item is None:\n\t\t\titem = SecretItem(self, next_identifier(), label, attributes, type=type,\n\t\t\t                  secret=secret, confirm=False, content_type=content_type)\n\t\telse:\n\t\t\titem.label = label\n\t\t\titem.type = type\n\t\t\titem.secret = secret\n\t\t\titem.attributes = attributes\n\t\t\titem.content_type = content_type\n\t\treturn (dbus.ObjectPath(item.path), dbus.ObjectPath(\"/\"))\n\t@dbus.service.method('org.freedesktop.Secret.Collection')\n\tdef SearchItems(self, attributes):\n\t\titems = self.search_items(attributes)\n\t\treturn (dbus.Array([item.path for item in items], \"o\"))\n\t@dbus.service.method('org.freedesktop.Secret.Collection', sender_keyword='sender')\n\tdef Delete(self, sender=None):\n\t\tcollection = self\n\t\tdef prompt_callback():\n\t\t\tcollection.perform_delete()\n\t\t\treturn dbus.String(\"\", variant_level=1)\n\t\tif self.confirm:\n\t\t\tprompt = SecretPrompt(self.service, sender, dismiss=False,\n\t\t\t                      action=prompt_callback)\n\t\t\treturn dbus.ObjectPath(prompt.path)\n\t\telse:\n\t\t\tself.perform_delete()\n\t\t\treturn dbus.ObjectPath(\"/\")\n\t@dbus.service.method(dbus.PROPERTIES_IFACE, in_signature='ss', out_signature='v')\n\tdef Get(self, interface_name, property_name):\n\t\treturn self.GetAll(interface_name)[property_name]\n\t@dbus.service.method(dbus.PROPERTIES_IFACE, in_signature='s', out_signature='a{sv}')\n\tdef GetAll(self, interface_name):\n\t\tif interface_name == 'org.freedesktop.Secret.Collection':\n\t\t\treturn {\n\t\t\t\t'Locked': self.get_locked(),\n\t\t\t\t'Label': self.label,\n\t\t\t\t'Created': dbus.UInt64(self.created),\n\t\t\t\t'Modified': dbus.UInt64(self.modified),\n\t\t\t\t'Items': dbus.Array([dbus.ObjectPath(i.path) for i in self.items.values()], signature='o', variant_level=1)\n\t\t\t}\n\t\telse:\n\t\t\traise InvalidArgs('Unknown %s interface' % interface_name)\n\t@dbus.service.method(dbus.PROPERTIES_IFACE, in_signature='ssv')\n\tdef Set(self, interface_name, property_name, new_value):\n\t\tif interface_name != 'org.freedesktop.Secret.Collection':\n\t\t\traise InvalidArgs('Unknown %s interface' % interface_name)\n\t\tif property_name == \"Label\":\n\t\t\tself.label = str(new_value)\n\t\telse:\n\t\t\traise InvalidArgs('Not a writable property %s' % property_name)\n\t\tself.PropertiesChanged(interface_name, { property_name: new_value }, [])\n\t@dbus.service.signal(dbus.PROPERTIES_IFACE, signature='sa{sv}as')\n\tdef PropertiesChanged(self, interface_name, changed_properties, invalidated_properties):\n\t\tself.modified = time.time()\nclass SecretService(dbus.service.Object):\n\talgorithms = {\n\t\t'plain': PlainAlgorithm(),\n\t\t\"dh-ietf1024-sha256-aes128-cbc-pkcs7\": AesAlgorithm(),\n\t}\n\tdef __init__(self, name=None):\n\t\tif name == None:\n\t\t\tname = bus_name\n\t\tbus = dbus.SessionBus()\n\t\tself.bus_name = dbus.service.BusName(name, allow_replacement=True, replace_existing=True)\n\t\tdbus.service.Object.__init__(self, self.bus_name, '/org/freedesktop/secrets')\n\t\tself.sessions = { }\n\t\tself.prompts = { }\n\t\tself.collections = { }\n\t\tself.aliases = { }\n\t\tself.aliased = { }\n\t\tdef on_name_owner_changed(owned, old_owner, new_owner):\n\t\t\tif not new_owner:\n\t\t\t\tfor session in list(self.sessions.get(old_owner, [])):\n\t\t\t\t\tsession.Close()\n\t\tbus.add_signal_receiver(on_name_owner_changed,\n\t\t                        'NameOwnerChanged',\n\t\t                        'org.freedesktop.DBus')\n\tdef add_standard_objects(self):\n\t\tcollection = SecretCollection(self, \"english\", label=\"Collection One\", locked=False)\n\t\tSecretItem(collection, \"1\", label=\"Item One\", secret=\"111\",\n\t\t           attributes={ \"number\": \"1\", \"string\": \"one\", \"even\": \"false\", \"xdg:schema\": \"org.mock.Schema\" })\n\t\tSecretItem(collection, \"2\", label=\"Item Two\", secret=\"222\",\n\t\t           attributes={ \"number\": \"2\", \"string\": \"two\", \"even\": \"true\", \"xdg:schema\": \"org.mock.Schema\" })\n\t\tSecretItem(collection, \"3\", label=\"Item Three\", secret=\"333\",\n\t\t           attributes={ \"number\": \"3\", \"string\": \"three\", \"even\": \"false\", \"xdg:schema\": \"org.mock.Schema\" })\n\t\tself.set_alias('default', collection)\n\t\tcollection = SecretCollection(self, \"spanish\", locked=True)\n\t\tSecretItem(collection, \"10\", secret=\"111\",\n\t\t           attributes={ \"number\": \"1\", \"string\": \"uno\", \"even\": \"false\", \"xdg:schema\": \"org.mock.Schema\" })\n\t\tSecretItem(collection, \"20\", secret=\"222\",\n\t\t           attributes={ \"number\": \"2\", \"string\": \"dos\", \"even\": \"true\", \"xdg:schema\": \"org.mock.Schema\" })\n\t\tSecretItem(collection, \"30\", secret=\"3333\",\n\t\t           attributes={ \"number\": \"3\", \"string\": \"tres\", \"even\": \"false\", \"xdg:schema\": \"org.mock.Schema\" })\n\t\tcollection = SecretCollection(self, \"german\", locked=True)\n\t\tSecretItem(collection, \"300\", secret=\"333\",\n\t\t           attributes={ \"number\": \"3\", \"string\": \"drei\", \"prime\": \"true\", \"xdg:schema\": \"org.mock.Primes\" })\n\t\tSecretItem(collection, \"400\", secret=\"444\",\n\t\t           attributes={ \"number\": \"4\", \"string\": \"vier\", \"prime\": \"false\", \"xdg:schema\": \"org.mock.Primes\" })\n\t\tSecretItem(collection, \"500\", secret=\"555\",\n\t\t           attributes={ \"number\": \"5\", \"string\": \"fuenf\", \"prime\": \"true\", \"xdg:schema\": \"org.mock.Primes\" })\n\t\tSecretItem(collection, \"600\", secret=\"666\",\n\t\t           attributes={ \"number\": \"6\", \"string\": \"sechs\", \"prime\": \"false\", \"xdg:schema\": \"org.mock.Primes\" })\n\t\tcollection = SecretCollection(self, \"empty\", locked=False)\n\t\tcollection = SecretCollection(self, \"session\", label=\"Session Keyring\", locked=False)\n\t\tself.set_alias('session', collection)\n\tdef listen(self):\n\t\tglobal ready_pipe\n", "outputs": ["\t\tloop = gobject.MainLoop()"], "input_length": 3613, "output_length": 5, "length": 3618, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "1b3d6641b899705657dd79342f62520fe5f24193fadaa30f9335892e958428b3"}
{"input": "", "context": "package com.servinglynk.hmis.warehouse.model.v2016;\nimport java.io.Serializable;\nimport java.time.LocalDateTime;\nimport java.util.Collections;\nimport java.util.Map;\nimport java.util.WeakHashMap;\nimport javax.persistence.Basic;\nimport javax.persistence.CascadeType;\nimport javax.persistence.Column;\nimport javax.persistence.Entity;\nimport javax.persistence.FetchType;\nimport javax.persistence.Id;\nimport javax.persistence.JoinColumn;\nimport javax.persistence.ManyToOne;\nimport javax.persistence.Table;\nimport javax.persistence.Transient;\nimport org.hibernate.annotations.Type;\nimport org.hibernate.proxy.HibernateProxy;\nimport com.servinglynk.hmis.warehouse.enums.ContactLocationEnum;\nimport com.servinglynk.hmis.warehouse.model.EnrollmentSharingModel;\n/**\n * Object mapping for hibernate-handled table: contact.\n *\n *\n * @author autogenerated\n */\n@Entity(name = \"contact_v2016\")\n@Table(name = \"contact\", catalog = \"hmis\", schema = \"v2016\")\npublic class Contact extends HmisBaseModel implements Cloneable, Serializable,EnrollmentSharingModel {\n\t/** Serial Version UID. */\n\tprivate static final long serialVersionUID = -4922450713586410718L;\n\t/** Use a WeakHashMap so entries will be garbage collected once all entities\n\t\treferring to a saved hash are garbage collected themselves. */\n\tprivate static final Map<Serializable, java.util.UUID> SAVED_HASHES =\n\t\tCollections.synchronizedMap(new WeakHashMap<Serializable, java.util.UUID>());\n\t/** hashCode temporary storage. */\n\tprivate volatile java.util.UUID hashCode;\n\t/** Field mapping. */\n\tprivate LocalDateTime contactDate;\n\t/** Field mapping. */\n\tprivate ContactLocationEnum contactLocation;\n\t/** Field mapping. */\n\tprivate Enrollment enrollmentid;\n\t/** Field mapping. */\n\tprivate java.util.UUID id;\n\t/**\n\t * Default constructor, mainly for hibernate use.\n\t */\n\tpublic Contact() {\n\t\t// Default constructor\n\t}\n\t/** Constructor taking a given ID.\n\t * @param id to set\n\t */\n\tpublic Contact(java.util.UUID id) {\n\t\tthis.id = id;\n\t}\n\t/** Return the type of this class. Useful for when dealing with proxies.\n\t* @return Defining class.\n\t*/\n\t@Transient\n\tpublic Class<?> getClassType() {\n\t\treturn Contact.class;\n\t}\n\t /**\n\t * Return the value associated with the column: contactDate.\n\t * @return A LocalDateTime object (this.contactDate)\n\t */\n\t@Type(type=\"org.jadira.usertype.dateandtime.threeten.PersistentLocalDateTime\")\n\t@Basic( optional = true )\n\t@Column( name = \"contact_date\"  )\n\tpublic LocalDateTime getContactDate() {\n\t\treturn this.contactDate;\n\t}\n\t /**\n\t * Set the value related to the column: contactDate.\n\t * @param contactDate the contactDate value you wish to set\n\t */\n\tpublic void setContactDate(final LocalDateTime contactDate) {\n\t\tthis.contactDate = contactDate;\n\t}\n\t /**\n\t * Return the value associated with the column: contactLocation.\n\t * @return A Integer object (this.contactLocation)\n\t */\n\t@Type(type = \"com.servinglynk.hmis.warehouse.enums.ContactLocationEnumType\")\n\t@Basic( optional = true )\n\t@Column( name = \"contact_location\"  )\n\tpublic ContactLocationEnum getContactLocation() {\n\t\treturn this.contactLocation;\n\t}\n\t /**\n\t * Set the value related to the column: contactLocation.\n\t * @param contactLocation the contactLocation value you wish to set\n\t */\n\tpublic void setContactLocation(final ContactLocationEnum contactLocation) {\n\t\tthis.contactLocation = contactLocation;\n\t}\n\t /**\n\t * Return the value associated with the column: enrollmentid.\n\t * @return A Enrollment object (this.enrollmentid)\n\t */\n\t@ManyToOne( cascade = { CascadeType.PERSIST, CascadeType.MERGE }, fetch = FetchType.LAZY )\n\t@org.hibernate.annotations.Cascade({org.hibernate.annotations.CascadeType.SAVE_UPDATE})\n\t@Basic( optional = true )\n\t@JoinColumn(name = \"enrollmentid\", nullable = true )\n\tpublic Enrollment getEnrollmentid() {\n\t\treturn this.enrollmentid;\n\t}\n\t /**\n\t * Set the value related to the column: enrollmentid.\n\t * @param enrollmentid the enrollmentid value you wish to set\n\t */\n\tpublic void setEnrollmentid(final Enrollment enrollmentid) {\n\t\tthis.enrollmentid = enrollmentid;\n\t}\n\t /**\n\t * Return the value associated with the column: id.\n\t * @return A java.util.UUID object (this.id)\n\t */\n\t@Id\n\t @Basic( optional = false )\n    @Column( name = \"id\", nullable = false  ) @org.hibernate.annotations.Type(type=\"org.hibernate.type.PostgresUUIDType\")\n\tpublic java.util.UUID getId() {\n\t\treturn this.id;\n\t}\n\t /**\n\t * Set the value related to the column: id.\n\t * @param id the id value you wish to set\n\t */\n\tpublic void setId(final java.util.UUID id) {\n\t\t// If we've just been persisted and hashCode has been\n\t\t// returned then make sure other entities with this\n\t\t// ID return the already returned hash code\n\t\tif ( (this.id == null ) &&\n\t\t\t\t(id != null) &&\n\t\t\t\t(this.hashCode != null) ) {\n\t\tSAVED_HASHES.put( id, this.hashCode );\n\t\t}\n\t\tthis.id = id;\n\t}\n\t/** Field mapping. */\n\tprotected Export export;\n\t /**\n\t * Return the value associated with the column: export.\n\t * @return A Export object (this.export)\n\t */\n\t@ManyToOne( cascade = { CascadeType.PERSIST, CascadeType.MERGE }, fetch = FetchType.LAZY )\n\t@org.hibernate.annotations.Cascade({org.hibernate.annotations.CascadeType.SAVE_UPDATE})\n\t@Basic( optional = true )\n\t@JoinColumn(name = \"export_id\", nullable = true )\n\tpublic Export getExport() {\n\t\treturn this.export;\n\t}\n\t /**\n\t * Set the value related to the column: export.\n\t * @param export the export value you wish to set\n\t */\n\tpublic void setExport(final Export export) {\n\t\tthis.export = export;\n\t}\n   /**\n    * Deep copy.\n\t* @return cloned object\n\t* @throws CloneNotSupportedException on error\n    */\n    @Override\n    public Contact clone() throws CloneNotSupportedException {\n        final Contact copy = (Contact)super.clone();\n\t\tcopy.setContactDate(this.getContactDate());\n\t\tcopy.setContactLocation(this.getContactLocation());\n\t\tcopy.setDateCreated(this.getDateCreated());\n\t\tcopy.setDateCreatedFromSource(this.getDateCreatedFromSource());\n\t\tcopy.setDateUpdated(this.getDateUpdated());\n\t\tcopy.setDateUpdatedFromSource(this.getDateUpdatedFromSource());\n\t\tcopy.setDeleted(this.isDeleted());\n\t\tcopy.setEnrollmentid(this.getEnrollmentid());\n\t\tcopy.setExport(this.getExport());\n\t\tcopy.setId(this.getId());\n\t\tcopy.setParentId(this.getParentId());\n\t\tcopy.setProjectGroupCode(this.getProjectGroupCode());\n\t\tcopy.setSync(this.isSync());\n\t\tcopy.setUserId(this.getUserId());\n\t\tcopy.setVersion(this.getVersion());\n\t\treturn copy;\n\t}\n\t/** Provides toString implementation.\n\t * @see java.lang.Object#toString()\n\t * @return String representation of this class.\n\t */\n\t@Override\n\tpublic String toString() {\n\t\tStringBuffer sb = new StringBuffer();\n\t\tsb.append(\"contactDate: \" + this.getContactDate() + \", \");\n\t\tsb.append(\"contactLocation: \" + this.getContactLocation() + \", \");\n\t\tsb.append(\"dateCreated: \" + this.getDateCreated() + \", \");\n\t\tsb.append(\"dateCreatedFromSource: \" + this.getDateCreatedFromSource() + \", \");\n\t\tsb.append(\"dateUpdated: \" + this.getDateUpdated() + \", \");\n\t\tsb.append(\"dateUpdatedFromSource: \" + this.getDateUpdatedFromSource() + \", \");\n\t\tsb.append(\"deleted: \" + this.isDeleted() + \", \");\n\t\tsb.append(\"id: \" + this.getId() + \", \");\n\t\tsb.append(\"parentId: \" + this.getParentId() + \", \");\n\t\tsb.append(\"projectGroupCode: \" + this.getProjectGroupCode() + \", \");\n\t\tsb.append(\"sync: \" + this.isSync() + \", \");\n\t\tsb.append(\"userId: \" + this.getUserId() + \", \");\n\t\tsb.append(\"version: \" + this.getVersion());\n\t\treturn sb.toString();\n\t}\n\t/** Equals implementation.\n\t * @see java.lang.Object#equals(java.lang.Object)\n\t * @param aThat Object to compare with\n\t * @return true/false\n\t */\n\t@Override\n\tpublic boolean equals(final Object aThat) {\n\t\tObject proxyThat = aThat;\n\t\tif ( this == aThat ) {\n\t\t\t return true;\n\t\t}\n", "outputs": ["\t\tif (aThat instanceof HibernateProxy) {"], "input_length": 1418, "output_length": 7, "length": 1425, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "3834acfad1eb830e3858f58ddaf78093ba5f5c40d2c5fe52f1238a897e168aae"}
{"input": "", "context": "#region Copyright & License Information\n/*\n * Copyright 2007-2019 The OpenRA Developers (see AUTHORS)\n * This file is part of OpenRA, which is free software. It is made\n * available to you under the terms of the GNU General Public License\n * as published by the Free Software Foundation, either version 3 of\n * the License, or (at your option) any later version. For more\n * information, see COPYING.\n */\n#endregion\nusing System.Collections.Generic;\nusing OpenRA.Activities;\nusing OpenRA.Mods.Common.Pathfinder;\nusing OpenRA.Mods.Common.Traits;\nusing OpenRA.Primitives;\nusing OpenRA.Traits;\nnamespace OpenRA.Mods.Common.Activities\n{\n\tpublic class FindAndDeliverResources : Activity\n\t{\n\t\treadonly Harvester harv;\n\t\treadonly HarvesterInfo harvInfo;\n\t\treadonly Mobile mobile;\n\t\treadonly LocomotorInfo locomotorInfo;\n\t\treadonly ResourceClaimLayer claimLayer;\n\t\treadonly IPathFinder pathFinder;\n\t\treadonly DomainIndex domainIndex;\n\t\treadonly Actor deliverActor;\n\t\tCPos? orderLocation;\n\t\tbool hasDeliveredLoad;\n\t\tbool hasHarvestedCell;\n\t\tbool hasWaited;\n\t\tpublic FindAndDeliverResources(Actor self, Actor deliverActor = null)\n\t\t{\n\t\t\tharv = self.Trait<Harvester>();\n\t\t\tharvInfo = self.Info.TraitInfo<HarvesterInfo>();\n\t\t\tmobile = self.Trait<Mobile>();\n\t\t\tlocomotorInfo = mobile.Info.LocomotorInfo;\n\t\t\tclaimLayer = self.World.WorldActor.Trait<ResourceClaimLayer>();\n\t\t\tpathFinder = self.World.WorldActor.Trait<IPathFinder>();\n\t\t\tdomainIndex = self.World.WorldActor.Trait<DomainIndex>();\n\t\t\tthis.deliverActor = deliverActor;\n\t\t}\n\t\tpublic FindAndDeliverResources(Actor self, CPos orderLocation)\n\t\t\t: this(self, null)\n\t\t{\n\t\t\tthis.orderLocation = orderLocation;\n\t\t}\n\t\tprotected override void OnFirstRun(Actor self)\n\t\t{\n\t\t\t// If an explicit \"harvest\" order is given, direct the harvester to the ordered location instead of\n\t\t\t// the previous harvested cell for the initial search.\n\t\t\tif (orderLocation != null)\n\t\t\t{\n\t\t\t\tharv.LastHarvestedCell = orderLocation;\n\t\t\t\t// If two \"harvest\" orders are issued consecutively, we deliver the load first if needed.\n\t\t\t\t// We have to make sure the actual \"harvest\" order is not skipped if a third order is queued,\n\t\t\t\t// so we keep deliveredLoad false.\n\t\t\t\tif (harv.IsFull)\n\t\t\t\t\tQueueChild(self, new DeliverResources(self), true);\n\t\t\t}\n\t\t\t// If an explicit \"deliver\" order is given, the harvester goes immediately to the refinery.\n\t\t\tif (deliverActor != null)\n\t\t\t{\n\t\t\t\tQueueChild(self, new DeliverResources(self, deliverActor), true);\n\t\t\t\thasDeliveredLoad = true;\n\t\t\t}\n\t\t}\n\t\tpublic override Activity Tick(Actor self)\n\t\t{\n\t\t\tif (ChildActivity != null)\n\t\t\t{\n\t\t\t\tChildActivity = ActivityUtils.RunActivity(self, ChildActivity);\n\t\t\t\tif (ChildActivity != null)\n\t\t\t\t\treturn this;\n\t\t\t}\n\t\t\tif (IsCanceling)\n\t\t\t\treturn NextActivity;\n\t\t\tif (NextActivity != null)\n\t\t\t{\n\t\t\t\t// Interrupt automated harvesting after clearing the first cell.\n\t\t\t\tif (!harvInfo.QueueFullLoad && (hasHarvestedCell || harv.LastSearchFailed))\n\t\t\t\t\treturn NextActivity;\n\t\t\t\t// Interrupt automated harvesting after first complete harvest cycle.\n\t\t\t\tif (hasDeliveredLoad || harv.IsFull)\n\t\t\t\t\treturn NextActivity;\n\t\t\t}\n\t\t\t// Are we full or have nothing more to gather? Deliver resources.\n\t\t\tif (harv.IsFull || (!harv.IsEmpty && harv.LastSearchFailed))\n\t\t\t{\n\t\t\t\tQueueChild(self, new DeliverResources(self), true);\n\t\t\t\thasDeliveredLoad = true;\n\t\t\t\treturn this;\n\t\t\t}\n\t\t\t// After a failed search, wait and sit still for a bit before searching again.\n\t\t\tif (harv.LastSearchFailed && !hasWaited)\n\t\t\t{\n\t\t\t\tQueueChild(self, new Wait(harv.Info.WaitDuration), true);\n\t\t\t\thasWaited = true;\n\t\t\t\treturn this;\n\t\t\t}\n\t\t\tvar closestHarvestableCell = ClosestHarvestablePos(self);\n\t\t\t// If no resources are found near the current field, search near the refinery instead.\n\t\t\t// If that doesn't help, give up for now.\n\t\t\tif (!closestHarvestableCell.HasValue)\n\t\t\t{\n\t\t\t\tif (harv.LastHarvestedCell != null)\n\t\t\t\t{\n\t\t\t\t\tharv.LastHarvestedCell = null; // Forces search from backup position.\n\t\t\t\t\tclosestHarvestableCell = ClosestHarvestablePos(self);\n\t\t\t\t\tharv.LastSearchFailed = !closestHarvestableCell.HasValue;\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t\tharv.LastSearchFailed = true;\n\t\t\t}\n\t\t\tif (harv.LastSearchFailed)\n\t\t\t{\n\t\t\t\t// If no harvestable position could be found and we are at the refinery, get out of the way\n\t\t\t\t// of the refinery entrance.\n\t\t\t\tvar lastproc = harv.LastLinkedProc ?? harv.LinkedProc;\n\t\t\t\tif (lastproc != null && !lastproc.Disposed)\n\t\t\t\t{\n\t\t\t\t\tvar deliveryLoc = lastproc.Location + lastproc.Trait<IAcceptResources>().DeliveryOffset;\n\t\t\t\t\tif (self.Location == deliveryLoc && harv.IsEmpty)\n\t\t\t\t\t{\n\t\t\t\t\t\t// Get out of the way:\n\t\t\t\t\t\tvar unblockCell = deliveryLoc + harv.Info.UnblockCell;\n\t\t\t\t\t\tvar moveTo = mobile.NearestMoveableCell(unblockCell, 1, 5);\n\t\t\t\t\t\tself.SetTargetLine(Target.FromCell(self.World, moveTo), Color.Green, false);\n\t\t\t\t\t\tQueueChild(self, mobile.MoveTo(moveTo, 1), true);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treturn this;\n\t\t\t}\n\t\t\t// Attempt to claim the target cell\n\t\t\tif (!claimLayer.TryClaimCell(self, closestHarvestableCell.Value))\n\t\t\t{\n\t\t\t\tQueueChild(self, new Wait(25), true);\n\t\t\t\treturn this;\n\t\t\t}\n\t\t\tharv.LastSearchFailed = false;\n\t\t\tforeach (var n in self.TraitsImplementing<INotifyHarvesterAction>())\n\t\t\t\tn.MovingToResources(self, closestHarvestableCell.Value, new FindAndDeliverResources(self));\n\t\t\tself.SetTargetLine(Target.FromCell(self.World, closestHarvestableCell.Value), Color.Red, false);\n\t\t\tQueueChild(self, mobile.MoveTo(closestHarvestableCell.Value, 1), true);\n\t\t\tQueueChild(self, new HarvestResource(self));\n\t\t\thasHarvestedCell = true;\n\t\t\treturn this;\n\t\t}\n\t\t/// <summary>\n\t\t/// Finds the closest harvestable pos between the current position of the harvester\n\t\t/// and the last order location\n\t\t/// </summary>\n\t\tCPos? ClosestHarvestablePos(Actor self)\n\t\t{\n\t\t\t// Harvesters should respect an explicit harvest order instead of harvesting the current cell.\n\t\t\tif (orderLocation == null)\n\t\t\t{\n\t\t\t\tif (harv.CanHarvestCell(self, self.Location) && claimLayer.CanClaimCell(self, self.Location))\n\t\t\t\t\treturn self.Location;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tif (harv.CanHarvestCell(self, orderLocation.Value) && claimLayer.CanClaimCell(self, orderLocation.Value))\n\t\t\t\t\treturn orderLocation;\n\t\t\t\torderLocation = null;\n\t\t\t}\n\t\t\t// Determine where to search from and how far to search:\n\t\t\tvar searchFromLoc = harv.LastHarvestedCell ?? GetSearchFromLocation(self);\n\t\t\tvar searchRadius = harv.LastHarvestedCell.HasValue ? harvInfo.SearchFromOrderRadius : harvInfo.SearchFromProcRadius;\n\t\t\tvar searchRadiusSquared = searchRadius * searchRadius;\n\t\t\t// Find any harvestable resources:\n\t\t\tList<CPos> path;\n\t\t\tusing (var search = PathSearch.Search(self.World, locomotorInfo, self, true, loc =>\n\t\t\t\t\tdomainIndex.IsPassable(self.Location, loc, locomotorInfo) && harv.CanHarvestCell(self, loc) && claimLayer.CanClaimCell(self, loc))\n\t\t\t\t.WithCustomCost(loc =>\n\t\t\t\t{\n\t\t\t\t\tif ((loc - searchFromLoc).LengthSquared > searchRadiusSquared)\n\t\t\t\t\t\treturn int.MaxValue;\n\t\t\t\t\treturn 0;\n\t\t\t\t})\n\t\t\t\t.FromPoint(searchFromLoc)\n\t\t\t\t.FromPoint(self.Location))\n\t\t\t\tpath = pathFinder.FindPath(search);\n", "outputs": ["\t\t\tif (path.Count > 0)"], "input_length": 1178, "output_length": 6, "length": 1184, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "25f0724d14b7276d5990289b567fa4eec5167a8f195e0b0d83ec97b3ce82da32"}
{"input": "", "context": "/* NFC Reader is free software; you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation; either version 3 of the License, or\n(at your option) any later version.\nNFC Reader is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\nYou should have received a copy of the GNU General Public License\nalong with Wget.  If not, see <http://www.gnu.org/licenses/>.\nAdditional permission under GNU GPL version 3 section 7 */\npackage cache.wind.nfc.nfc.reader.pboc;\nimport android.nfc.tech.IsoDep;\nimport java.io.IOException;\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport cache.wind.nfc.SPEC;\nimport cache.wind.nfc.nfc.Util;\nimport cache.wind.nfc.nfc.bean.Application;\nimport cache.wind.nfc.nfc.bean.Card;\nimport cache.wind.nfc.nfc.tech.Iso7816;\n@SuppressWarnings(\"unchecked\")\npublic abstract class StandardPboc {\n\tprivate static Class<?>[][] readers = {\n\t\t\t{ BeijingMunicipal.class, WuhanTong.class, CityUnion.class, TUnion.class,\n\t\t\t\t\tShenzhenTong.class, }, { StandardECash.class, } };\n\tpublic static void readCard(IsoDep tech, Card card) throws InstantiationException,\n\t\t\tIllegalAccessException, IOException {\n\t\tfinal Iso7816.StdTag tag = new Iso7816.StdTag(tech);\n\t\ttag.connect();\n\t\tfor (final Class<?> g[] : readers) {\n\t\t\tHINT hint = HINT.RESETANDGONEXT;\n\t\t\tfor (final Class<?> r : g) {\n\t\t\t\tfinal StandardPboc reader = (StandardPboc) r.newInstance();\n\t\t\t\tswitch (hint) {\n\t\t\t\tcase RESETANDGONEXT:\n\t\t\t\t\tif (!reader.resetTag(tag))\n\t\t\t\t\t\tcontinue;\n\t\t\t\tcase GONEXT:\n\t\t\t\t\thint = reader.readCard(tag, card);\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif (hint == HINT.STOP)\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\ttag.close();\n\t}\n\tprotected boolean resetTag(Iso7816.StdTag tag) throws IOException {\n\t\treturn tag.selectByID(DFI_MF).isOkey() || tag.selectByName(DFN_PSE).isOkey();\n\t}\n\tprotected enum HINT {\n\t\tSTOP, GONEXT, RESETANDGONEXT,\n\t}\n\tprotected final static byte[] DFI_MF = { (byte) 0x3F, (byte) 0x00 };\n\tprotected final static byte[] DFI_EP = { (byte) 0x10, (byte) 0x01 };\n\tprotected final static byte[] DFN_PSE = { (byte) '1', (byte) 'P', (byte) 'A', (byte) 'Y',\n\t\t\t(byte) '.', (byte) 'S', (byte) 'Y', (byte) 'S', (byte) '.', (byte) 'D', (byte) 'D',\n\t\t\t(byte) 'F', (byte) '0', (byte) '1', };\n\tprotected final static byte[] DFN_PXX = { (byte) 'P' };\n\tprotected final static int SFI_EXTRA = 21;\n\tprotected static int MAX_LOG = 10;\n\tprotected static int SFI_LOG = 24;\n\tprotected final static byte TRANS_CSU = 6;\n\tprotected final static byte TRANS_CSU_CPX = 9;\n\tprotected abstract Object getApplicationId();\n\tprotected byte[] getMainApplicationId() {\n\t\treturn DFI_EP;\n\t}\n\tprotected SPEC.CUR getCurrency() {\n\t\treturn SPEC.CUR.CNY;\n\t}\n\tprotected boolean selectMainApplication(Iso7816.StdTag tag) throws IOException {\n\t\tfinal byte[] aid = getMainApplicationId();\n\t\treturn ((aid.length == 2) ? tag.selectByID(aid) : tag.selectByName(aid)).isOkey();\n\t}\n\tprotected HINT readCard(Iso7816.StdTag tag, Card card) throws IOException {\n\t\t/*--------------------------------------------------------------*/\n\t\t// select Main Application\n\t\t/*--------------------------------------------------------------*/\n\t\tif (!selectMainApplication(tag))\n\t\t\treturn HINT.GONEXT;\n\t\tIso7816.Response INFO, BALANCE;\n\t\t/*--------------------------------------------------------------*/\n\t\t// read card info file, binary (21)\n\t\t/*--------------------------------------------------------------*/\n\t\tINFO = tag.readBinary(SFI_EXTRA);\n\t\t/*--------------------------------------------------------------*/\n\t\t// read balance\n\t\t/*--------------------------------------------------------------*/\n\t\tBALANCE = tag.getBalance(0, true);\n\t\t/*--------------------------------------------------------------*/\n\t\t// read log file, record (24)\n\t\t/*--------------------------------------------------------------*/\n\t\tArrayList<byte[]> LOG = readLog24(tag, SFI_LOG);\n\t\t/*--------------------------------------------------------------*/\n\t\t// build result\n\t\t/*--------------------------------------------------------------*/\n\t\tfinal Application app = createApplication();\n\t\tparseBalance(app, BALANCE);\n\t\tparseInfo21(app, INFO, 4, true);\n\t\tparseLog24(app, LOG);\n\t\tconfigApplication(app);\n\t\tcard.addApplication(app);\n\t\treturn HINT.STOP;\n\t}\n\tprotected float parseBalance(Iso7816.Response data) {\n\t\tfloat ret = 0f;\n\t\tif (data.isOkey() && data.size() >= 4) {\n\t\t\tint n = Util.toInt(data.getBytes(), 0, 4);\n\t\t\tif (n > 1000000 || n < -1000000)\n\t\t\t\tn -= 0x80000000;\n\t\t\tret = n / 100.0f;\n\t\t}\n\t\treturn ret;\n\t}\n\tprotected void parseBalance(Application app, Iso7816.Response... data) {\n\t\tfloat amount = 0f;\n\t\tfor (Iso7816.Response rsp : data)\n\t\t\tamount += parseBalance(rsp);\n\t\tapp.setProperty(SPEC.PROP.BALANCE, amount);\n\t}\n\tprotected void parseInfo21(Application app, Iso7816.Response data, int dec, boolean bigEndian) {\n\t\tif (!data.isOkey() || data.size() < 30) {\n\t\t\treturn;\n\t\t}\n\t\tfinal byte[] d = data.getBytes();\n\t\tif (dec < 1 || dec > 10) {\n\t\t\tapp.setProperty(SPEC.PROP.SERIAL, Util.toHexString(d, 10, 10));\n\t\t} else {\n\t\t\tfinal int sn = bigEndian ? Util.toIntR(d, 19, dec) : Util.toInt(d, 20 - dec, dec);\n\t\t\tapp.setProperty(SPEC.PROP.SERIAL, String.format(\"%d\", 0xFFFFFFFFL & sn));\n\t\t}\n\t\tif (d[9] != 0)\n\t\t\tapp.setProperty(SPEC.PROP.VERSION, String.valueOf(d[9]));\n\t\tapp.setProperty(SPEC.PROP.DATE, String.format(\"%02X%02X.%02X.%02X - %02X%02X.%02X.%02X\",\n\t\t\t\td[20], d[21], d[22], d[23], d[24], d[25], d[26], d[27]));\n\t}\n\tprotected boolean addLog24(final Iso7816.Response r, ArrayList<byte[]> l) {\n\t\tif (!r.isOkey())\n\t\t\treturn false;\n\t\tfinal byte[] raw = r.getBytes();\n\t\tfinal int N = raw.length - 23;\n\t\tif (N < 0)\n\t\t\treturn false;\n\t\tfor (int s = 0, e = 0; s <= N; s = e) {\n\t\t\tl.add(Arrays.copyOfRange(raw, s, (e = s + 23)));\n\t\t}\n\t\treturn true;\n\t}\n\tprotected ArrayList<byte[]> readLog24(Iso7816.StdTag tag, int sfi) throws IOException {\n\t\tfinal ArrayList<byte[]> ret = new ArrayList<byte[]>(MAX_LOG);\n\t\tfinal Iso7816.Response rsp = tag.readRecord(sfi);\n\t\tif (rsp.isOkey()) {\n\t\t\taddLog24(rsp, ret);\n\t\t} else {\n", "outputs": ["\t\t\tfor (int i = 1; i <= MAX_LOG; ++i) {"], "input_length": 1601, "output_length": 15, "length": 1616, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "179c9d13610206592e264744e616bd61f4e5a63e7dc34c27ee8b38424f7e8a03"}
{"input": "", "context": "import Object3DQt   as qt\nimport PyQt4.Qwt5 as Qwt5\nfrom VerticalSpacer import VerticalSpacer\nDEBUG = 0\nDRAW_MODES = ['NONE',\n              'POINT',\n              'WIRE',\n              'SURFACE']\nclass Object3DDrawingModeWidget(qt.QGroupBox):\n    def __init__(self, parent = None):\n        qt.QGroupBox.__init__(self, parent)\n        self.setTitle('Drawing Mode')\n        self.build()\n        self.setDrawingMode(1)\n    def build(self):\n        self.l = qt.QVBoxLayout(self)\n        self.l.setMargin(0)\n        self.l.setSpacing(4)\n        self.buttonGroup = qt.QButtonGroup(self)\n        j = 0\n        for mode in DRAW_MODES:\n            rButton = qt.QRadioButton(self)\n            rButton.setText(mode)\n            self.l.addWidget(rButton)\n            self.l.setAlignment(rButton, qt.Qt.AlignLeft)\n            self.buttonGroup.addButton(rButton)\n            self.buttonGroup.setId(rButton, j)\n            j += 1\n            self.connect(self.buttonGroup,\n                         qt.SIGNAL('buttonPressed(QAbstractButton *)'),\n                         self._slot)\n    def _slot(self, button):\n        button.setChecked(True)\n        self._signal()\n    def _signal(self, event = None):\n        if DEBUG:\n            print(\"emit Object3DDrawingModeSignal\")\n        if event is None:\n            event = 'DrawModeUpdated'\n        ddict = self.getParameters()\n        ddict['event']  = event\n        self.emit(qt.SIGNAL('Object3DDrawingModeSignal'), ddict)\n    def getParameters(self):\n        mode = self.getDrawingMode()\n        ddict = {}\n        ddict['mode']   = mode\n        ddict['label']  = str(self.buttonGroup.button(mode).text())\n        return ddict\n    def setParameters(self, ddict = None):\n        if DEBUG:\n            print(\"setParameters\")\n        if ddict is None:\n            ddict = {}\n        mode = ddict.get('mode', 1)\n        self.setDrawingMode(mode)\n    def setDrawingMode(self, mode):\n        if type(mode) == type(\" \"):\n            if mode.upper() in DRAW_MODES:\n                i = DRAW_MODES.index(mode)\n            else:\n                raise ValueError(\"Unknown drawing mode: %s \"  % mode)\n        else:\n            i = mode\n        self.buttonGroup.button(i).setChecked(True)\n    \n    def getDrawingMode(self):\n        mode = 0\n        n = self.buttonGroup.checkedId()\n        if n >= 0:\n            mode = n\n        else:\n            print(\"WARNING: getAnchor -> Unselected button\")\n        return mode\n    def setSupportedModes(self, modes):\n        current = self.getDrawingMode()\n        for i in modes:\n            if i < len(DRAW_MODES):\n                self.buttonGroup.button(i).setEnabled(True)\n        # always possible to draw nothing\n        self.buttonGroup.button(i).setEnabled(True)\n        if not self.buttonGroup.button(current).isEnabled():\n            self.buttonGroup.button(0).setChecked(True)\n            self._signal()\nclass Object3DAspect(qt.QGroupBox):\n    def __init__(self, parent = None):\n        qt.QGroupBox.__init__(self, parent)\n        self.setTitle('Aspect')\n        self.build()\n    def build(self):\n        self.l = qt.QGridLayout(self)\n        i = 0\n        # point size\n        label = qt.QLabel('Point size')\n        self.pointSize = Qwt5.QwtSlider(self, qt.Qt.Horizontal)\n        self.pointSize.setRange(1.0, 1.0, 1.0)\n        self.pointSize.setValue(1.0)\n        self.l.addWidget(label, i, 0)\n        self.l.addWidget(self.pointSize, i, 1)\n        self.connect(self.pointSize,\n                     qt.SIGNAL(\"valueChanged(double)\"),\n                     self._slot)\n        # line width\n        i += 1\n        label = qt.QLabel('Line width')\n        self.lineWidth = Qwt5.QwtSlider(self, qt.Qt.Horizontal)\n        self.lineWidth.setRange(1.0, 1.0, 1.0)\n        self.lineWidth.setValue(1.0)\n        self.l.addWidget(label, i, 0)\n        self.l.addWidget(self.lineWidth, i, 1)\n        self.connect(self.lineWidth,\n                     qt.SIGNAL(\"valueChanged(double)\"),\n                     self._slot)\n        # transparency\n        i += 1\n        label = qt.QLabel('Transparency')\n        self.transparency = Qwt5.QwtSlider(self, qt.Qt.Horizontal)\n        self.transparency.setRange(0.0, 1.0, 0.01)\n        self.transparency.setValue(0.0)\n        self.l.addWidget(label, i, 0)\n        self.l.addWidget(self.transparency, i, 1)\n        self.connect(self.transparency,\n                     qt.SIGNAL(\"valueChanged(double)\"),\n                     self._slot)\n        # bounding box\n        self.boundingBoxCheckBox = qt.QCheckBox(self)\n        self.boundingBoxCheckBox.setText(\"Show bounding box\")\n        self.connect(self.boundingBoxCheckBox,\n                                         qt.SIGNAL(\"stateChanged(int)\"),\n                                         self._signal)\n        i = 0\n        j = 2\n        self.l.addWidget(self.boundingBoxCheckBox, i, j)\n        self.showLimitsCheckBoxes = []\n        for t in ['X', 'Y', 'Z']:\n            i += 1\n            checkBox = qt.QCheckBox(self)\n            checkBox.setText('Show bbox %s limit' % t)\n            self.l.addWidget(checkBox, i, j)\n            self.connect(checkBox, qt.SIGNAL(\"stateChanged(int)\"), self._slot)\n            self.showLimitsCheckBoxes.append(checkBox)\n    def _slot(self, *var):\n        self._signal()\n    def getParameters(self):\n        pointSize = self.pointSize.value()\n        lineWidth = self.lineWidth.value()\n        transparency = self.transparency.value()\n        if self.boundingBoxCheckBox.isChecked():\n            showBBox = 1\n        else:\n            showBBox = 0\n        showLimits   = [0, 0, 0]\n        for i in range(3):\n            if self.showLimitsCheckBoxes[i].isChecked():\n                showLimits[i] = 1\n        ddict = {}\n        ddict['pointsize'] = pointSize\n        ddict['pointsizecapabilities'] = [self.pointSize.minValue(),\n                                          self.pointSize.maxValue(),\n                                          self.pointSize.step()]\n        ddict['linewidth'] = lineWidth\n        ddict['linewidthcapabilities'] = [self.lineWidth.minValue(),\n                                          self.lineWidth.maxValue(),\n                                          self.lineWidth.step()]\n        ddict['transparency'] = transparency\n        ddict['bboxflag' ]  = showBBox\n        ddict['showlimits'] = showLimits\n        return ddict\n    def setParameters(self, ddict = None):\n        if DEBUG:\n            print(\"setParameters\")\n        if ddict is None:\n            ddict = {}\n        pointSize = ddict.get('pointsize', 1.0)\n        pointSizeCapabilities = ddict.get('pointsizecapabilities',\n                                          [1.0, 1.0, 1.0])\n        lineWidth = ddict.get('linewidth', 1.0)\n        lineWidthCapabilities = ddict.get('linewidthcapabilities',\n                                          [1.0, 1.0, 1.0])\n        transparency = ddict.get('transparency', 0.0)\n        showBBox =  ddict.get('bboxflag', 1)\n        showLimits = ddict.get('showlimits', [1, 1, 1])\n        self.pointSize.setRange(pointSizeCapabilities[0],\n                                pointSizeCapabilities[1],\n                                pointSizeCapabilities[2])\n        self.pointSize.setValue(pointSize)\n        self.lineWidth.setRange(lineWidthCapabilities[0],\n                                lineWidthCapabilities[1],\n                                lineWidthCapabilities[2])\n        self.lineWidth.setValue(lineWidth)\n        if lineWidth > lineWidthCapabilities[1]:\n            lineWidth = lineWidthCapabilities[1]\n        self.transparency.setValue(transparency)\n        self.boundingBoxCheckBox.setChecked(showBBox)\n        \n        for i in [0, 1, 2]:\n            self.showLimitsCheckBoxes[i].setChecked(showLimits[i])\n    def _signal(self, event = None):\n        if DEBUG:\n            print(\"emitting Object3DAspectSignal\")\n        if event is None:\n            event = \"AspectUpdated\"\n        ddict = self.getParameters()\n        ddict['event'] = event\n        self.emit(qt.SIGNAL('Object3DAspectSignal'), ddict)\nclass Object3DScale(qt.QGroupBox):\n    def __init__(self, parent = None):\n        qt.QGroupBox.__init__(self, parent)\n        self.setTitle('Object Scaling')\n        self.l = qt.QGridLayout(self)\n        self.__disconnect = False\n        self.__oldScale = [1.0, 1.0, 1.0]\n        self.lineEditList = []\n        self.validatorList = []\n        i = 0\n        self._lineSlotList =[self._xLineSlot,\n                             self._yLineSlot,\n                             self._zLineSlot]\n        for axis in ['x', 'y', 'z']:\n            label = qt.QLabel(\"%s Scale\" % axis)\n            lineEdit = qt.QLineEdit(self)\n            v = qt.QDoubleValidator(lineEdit)\n            lineEdit.setValidator(v)\n            \n            self.validatorList.append(v)\n            self.l.addWidget(label, i, 0)\n            self.l.addWidget(lineEdit, i, 1)\n            self.lineEditList.append(lineEdit)\n            lineEdit.setText('1.0')\n            lineEdit.setFixedWidth(lineEdit.fontMetrics().width('######.#####'))\n            self.connect(lineEdit,\n                         qt.SIGNAL('editingFinished()'),\n                         self._lineSlotList[i])\n            i+= 1\n        # xScaling\n        i = 0\n        self.xScaleSlider = Qwt5.QwtSlider(self, qt.Qt.Horizontal)\n        self.xScaleSlider.setScale(-10.0, 10.0, 0.001)\n        self.xScaleSlider.setValue(1.0)\n        self.l.addWidget(self.xScaleSlider, i, 2)\n        self.connect(self.xScaleSlider,\n                     qt.SIGNAL(\"valueChanged(double)\"),\n                     self._xSliderSlot)\n        # yScaling\n        i += 1\n        self.yScaleSlider = Qwt5.QwtSlider(self, qt.Qt.Horizontal)\n        self.yScaleSlider.setRange(-100.0, 100.0, 0.01)\n        self.yScaleSlider.setValue(1.0)\n        self.l.addWidget(self.yScaleSlider, i, 2)\n        self.connect(self.yScaleSlider,\n                     qt.SIGNAL(\"valueChanged(double)\"),\n                     self._ySliderSlot)\n        # zScaling\n        i += 1\n        self.zScaleSlider = Qwt5.QwtSlider(self, qt.Qt.Horizontal)\n        self.zScaleSlider.setRange(-100.0, 100.0, 0.01)\n        self.zScaleSlider.setValue(1.0)\n        self.l.addWidget(self.zScaleSlider, i, 2)\n        self.connect(self.zScaleSlider,\n                     qt.SIGNAL(\"valueChanged(double)\"),\n                     self._zSliderSlot)\n    def _xSliderSlot(self, *var):\n        if not self.__disconnect:\n            scale = [self.xScaleSlider.value(),\n                     self.yScaleSlider.value(),\n                     self.zScaleSlider.value()]\n            self.__disconnect = True\n            for i in [0, 1, 2]:\n                if scale[i] != float(str(self.lineEditList[i].text())):\n                    self.lineEditList[i].setText(\"%.7g\" % scale[i])\n            self.__disconnect = False\n            if (self.__oldScale[0] != scale[0]) or \\\n               (self.__oldScale[1] != scale[1]) or \\\n               (self.__oldScale[2] != scale[2]) :\n                self.__oldScale = scale\n                self._signal(\"xScaleUpdated\")\n    def _ySliderSlot(self, *var):\n        if not self.__disconnect:\n            scale = [self.xScaleSlider.value(),\n                     self.yScaleSlider.value(),\n                     self.zScaleSlider.value()]\n            self.__disconnect = True\n            for i in [0, 1, 2]:\n                if scale[i] != float(str(self.lineEditList[i].text())):\n                    self.lineEditList[i].setText(\"%.7g\" % scale[i])\n            self.__disconnect = False\n            if (self.__oldScale[0] != scale[0]) or \\\n               (self.__oldScale[1] != scale[1]) or \\\n               (self.__oldScale[2] != scale[2]) :\n                self.__oldScale = scale\n                self._signal(\"yScaleUpdated\")\n    def _zSliderSlot(self, *var):\n        if not self.__disconnect:\n            scale = [self.xScaleSlider.value(),\n                     self.yScaleSlider.value(),\n                     self.zScaleSlider.value()]\n            self.__disconnect = True\n            for i in [0, 1, 2]:\n                if scale[i] != float(str(self.lineEditList[i].text())):\n                    self.lineEditList[i].setText(\"%.7g\" % scale[i])\n            self.__disconnect = False\n            if (self.__oldScale[0] != scale[0]) or \\\n               (self.__oldScale[1] != scale[1]) or \\\n               (self.__oldScale[2] != scale[2]) :\n                self.__oldScale = scale\n                self._signal(\"zScaleUpdated\")\n    def _xLineSlot(self):\n        if not self.__disconnect:\n            self.__disconnect = True\n            scale = [1, 1, 1]\n            for i in [0, 1 , 2]:\n                scale[i] = float(str(self.lineEditList[i].text()))\n            self.xScaleSlider.setValue(scale[0])\n            self.yScaleSlider.setValue(scale[1])\n            self.zScaleSlider.setValue(scale[2])\n            self.__disconnect = False\n            self._signal(\"xScaleUpdated\")\n    def _yLineSlot(self):\n        if not self.__disconnect:\n            self.__disconnect = True\n            scale = [1, 1, 1]\n            for i in [0, 1 , 2]:\n                scale[i] = float(str(self.lineEditList[i].text()))\n            self.xScaleSlider.setValue(scale[0])\n            self.yScaleSlider.setValue(scale[1])\n            self.zScaleSlider.setValue(scale[2])\n            self.__disconnect = False\n            self._signal(\"yScaleUpdated\")\n    def _zLineSlot(self):\n        if not self.__disconnect:\n            self.__disconnect = True\n            scale = [1, 1, 1]\n            for i in [0, 1 , 2]:\n                scale[i] = float(str(self.lineEditList[i].text()))\n            self.xScaleSlider.setValue(scale[0])\n            self.yScaleSlider.setValue(scale[1])\n            self.zScaleSlider.setValue(scale[2])\n            self.__disconnect = False\n            self._signal(\"zScaleUpdated\")\n    def _signal(self, event = None):\n        if DEBUG:\n            print(\"emitting Object3DScaleSignal\")\n        if self.__disconnect: return\n        if event is None:\n            event = \"ScaleUpdated\"\n        oldScale = self._lastParameters * 1\n        ddict = self.getParameters()\n        scale = ddict['scale']\n        emit = False\n        for i in range(3):\n            if abs((scale[i]-oldScale[i])) > 1.0e-10:\n                emit = True\n                ddict['magnification'] = scale[i]/oldScale[i] \n                break\n        if not emit:\n            return\n        ddict['event'] = event\n        self.emit(qt.SIGNAL('Object3DScaleSignal'), ddict)\n    def getParameters(self):\n        scale = [1.0, 1.0, 1.0]\n        for i in [0, 1 , 2]:\n            scale[i] = float(str(self.lineEditList[i].text()))\n        ddict = {}\n        ddict['scale'] = scale\n        self._lastParameters = scale\n        return ddict\n    def setParameters(self, ddict = None):\n        if DEBUG:\n            print(\"setParameters\", ddict)\n        if ddict is None:ddict = {}\n        scale = ddict.get('scale', [1.0, 1.0, 1.0])\n        \n        self.xScaleSlider.setValue(scale[0])\n        self.yScaleSlider.setValue(scale[1])\n        self.zScaleSlider.setValue(scale[2])\n        for i in [0, 1, 2]:\n            self.lineEditList[i].setText(\"%.7g\" % scale[i])\n        self._lastParameters = scale\nclass Object3DPrivateInterface(qt.QGroupBox):\n    def __init__(self, parent = None):\n        qt.QGroupBox.__init__(self, parent)\n        self.setTitle('Private Configuration')\n        self.mainLayout = qt.QVBoxLayout(self)\n        self.button = qt.QPushButton(self)\n        self.button.setText(\"More\")\n        self.mainLayout.addWidget(self.button)\n        self.mainLayout.addWidget(VerticalSpacer(self))\nclass Object3DProperties(qt.QWidget):\n    def __init__(self, parent = None):\n        qt.QWidget.__init__(self, parent)\n        self.l = qt.QHBoxLayout(self)\n        self.drawingModeWidget = Object3DDrawingModeWidget(self)\n", "outputs": ["        self.aspectWidget = Object3DAspect(self)"], "input_length": 2560, "output_length": 6, "length": 2566, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "aab1d1c75fc5efa66718a8d30114808bac43486501758547b398c8554cdbe1c8"}
{"input": "", "context": "/**\n * Copyright (c) 2013 James King [metapyziks@gmail.com]\n *\n * This file is part of OpenTKTK.\n * \n * OpenTKTK is free software: you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation, either version 3 of the License, or\n * (at your option) any later version.\n * \n * OpenTKTK is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n * GNU General Public License for more details.\n * \n * You should have received a copy of the GNU General Public License\n * along with OpenTKTK. If not, see <http://www.gnu.org/licenses/>.\n */\nusing System;\nusing System.Collections.Generic;\nusing System.Diagnostics;\nusing System.Linq;\nusing OpenTK;\nusing OpenTK.Graphics;\nusing OpenTK.Graphics.OpenGL;\nusing OpenTKTK.Textures;\nusing OpenTKTK.Utils;\nnamespace OpenTKTK.Shaders\n{\n    public class ShaderProgram : IDisposable\n    {\n        public class AttributeInfo\n        {\n            public ShaderProgram Shader { get; private set; }\n            public String Identifier { get; private set; }\n            public int Location { get; private set; }\n            public int Size { get; private set; }\n            public int Offset { get; private set; }\n            public int Divisor { get; private set; }\n            public int InputOffset { get; private set; }\n            public VertexAttribPointerType PointerType { get; private set; }\n            public bool Normalize { get; private set; }\n            public int Length\n            {\n                get\n                {\n                    switch (PointerType) {\n                        case VertexAttribPointerType.Byte:\n                        case VertexAttribPointerType.UnsignedByte:\n                            return Size * sizeof(byte);\n                        case VertexAttribPointerType.Short:\n                        case VertexAttribPointerType.UnsignedShort:\n                            return Size * sizeof(short);\n                        case VertexAttribPointerType.Int:\n                        case VertexAttribPointerType.UnsignedInt:\n                            return Size * sizeof(int);\n                        case VertexAttribPointerType.HalfFloat:\n                            return Size * sizeof(float) / 2;\n                        case VertexAttribPointerType.Float:\n                            return Size * sizeof(float);\n                        case VertexAttribPointerType.Double:\n                            return Size * sizeof(double);\n                        default:\n                            return 0;\n                    }\n                }\n            }\n            public AttributeInfo(ShaderProgram shader, String identifier,\n                int size, int offset, int divisor, int inputOffset,\n                VertexAttribPointerType pointerType =\n                    VertexAttribPointerType.Float,\n                bool normalize = false)\n            {\n                Shader = shader;\n                Identifier = identifier;\n                Location = GL.GetAttribLocation(shader.Program, Identifier);\n                Size = size;\n                Offset = offset;\n                Divisor = divisor;\n                InputOffset = inputOffset;\n                PointerType = pointerType;\n                Normalize = normalize;\n            }\n            public override String ToString()\n            {\n                return Identifier + \" @\" + Location + \", Size: \" + Size + \", Offset: \" + Offset;\n            }\n        }\n        private class TextureInfo\n        {\n            public ShaderProgram Shader { get; private set; }\n            public String Identifier { get; private set; }\n            public int UniformLocation { get; private set; }\n            public TextureUnit TextureUnit { get; private set; }\n            public Texture CurrentTexture { get; private set; }\n            public TextureInfo(ShaderProgram shader, String identifier,\n                TextureUnit textureUnit = TextureUnit.Texture0)\n            {\n                Shader = shader;\n                Identifier = identifier;\n                UniformLocation = GL.GetUniformLocation(Shader.Program, Identifier);\n                TextureUnit = textureUnit;\n                Shader.Use();\n                int val = (int) TextureUnit - (int) TextureUnit.Texture0;\n                GL.Uniform1(UniformLocation, val);\n                CurrentTexture = null;\n            }\n            public void SetCurrentTexture(Texture texture)\n            {\n                CurrentTexture = texture;\n                GL.ActiveTexture(TextureUnit);\n                CurrentTexture.Bind();\n            }\n        }\n        public class AttributeCollection : IEnumerable<AttributeInfo>\n        {\n            private static int GetAttributeSize(ShaderVarType type)\n            {\n                switch (type) {\n                    case ShaderVarType.Float:\n                    case ShaderVarType.Int:\n                        return 1;\n                    case ShaderVarType.Vec2:\n                        return 2;\n                    case ShaderVarType.Vec3:\n                        return 3;\n                    case ShaderVarType.Vec4:\n                        return 4;\n                    default:\n                        throw new ArgumentException(\"Invalid attribute type (\" + type + \").\");\n                }\n            }\n            private ShaderProgram _shader;\n            internal AttributeCollection(ShaderProgram shader)\n            {\n                _shader = shader;\n            }\n            public AttributeInfo this[int index]\n            {\n                get { return _shader._attributes[index]; }\n            }\n            public AttributeInfo this[String ident]\n            {\n                get { return _shader._attributes.First(x => x.Identifier == ident); }\n            }\n            public IEnumerator<AttributeInfo> GetEnumerator()\n            {\n                return _shader._attributes.GetEnumerator();\n            }\n            System.Collections.IEnumerator System.Collections.IEnumerable.GetEnumerator()\n            {\n                return _shader._attributes.GetEnumerator();\n            }\n        }\n        private static ShaderProgram _sCurProgram;\n        \n        public int VertexDataStride { get; private set; }\n        public int VertexDataSize { get; private set; }\n        private List<AttributeInfo> _attributes;\n        private Dictionary<String, TextureInfo> _textures;\n        private Dictionary<String, int> _uniforms;\n        public int Program { get; private set; }\n        public PrimitiveType PrimitiveType { get; protected set; }\n        public bool Flat { get; private set; }\n        public bool Active\n        {\n            get { return _sCurProgram == this; }\n        }\n        public bool Immediate { get; protected set; }\n        public bool Started { get; protected set; }\n        public AttributeCollection Attributes { get; private set; }\n        public ShaderProgram(bool flat)\n        {\n            PrimitiveType = PrimitiveType.Triangles;\n            Flat = flat;\n", "outputs": ["            _attributes = new List<AttributeInfo>();"], "input_length": 924, "output_length": 10, "length": 934, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "1bf2986f51768cf9ddf03cefedf2ecdf6e8e5e7e3375239c0931993fe8c460bc"}
{"input": "", "context": "//\n// System.IO.Ports.WinSerialStream.cs\n//\n// Authors:\n//\tCarlos Alberto Cortez (calberto.cortez@gmail.com)\n//\n// (c) Copyright 2006 Novell, Inc. (http://www.novell.com)\n//\nusing System;\nusing System.Text;\nusing System.IO;\nusing System.Runtime.InteropServices;\nusing System.Threading;\nusing System.ComponentModel;\nnamespace System.IO.Ports\n{\n\tclass WinSerialStream : Stream, ISerialStream, IDisposable\n\t{\n\t\t// Windows API Constants\n\t\tconst uint GenericRead = 0x80000000;\n\t\tconst uint GenericWrite = 0x40000000;\n\t\tconst uint OpenExisting = 3;\n\t\tconst uint FileFlagOverlapped = 0x40000000;\n\t\tconst uint PurgeRxClear = 0x0008;\n\t\tconst uint PurgeTxClear = 0x0004;\n\t\tconst uint WinInfiniteTimeout = 0xFFFFFFFF;\n\t\tconst uint FileIOPending = 997;\n\t\t// Signal constants\n\t\tconst uint SetRts = 3;\n\t\tconst uint ClearRts = 4;\n\t\tconst uint SetDtr = 5;\n\t\tconst uint ClearDtr = 6;\n\t\tconst uint SetBreak = 8;\n\t\tconst uint ClearBreak = 9;\n\t\tconst uint CtsOn = 0x0010;\n\t\tconst uint DsrOn = 0x0020;\n\t\tconst uint RsldOn = 0x0080;\n\t\t// Event constants\n\t\tconst uint EvRxChar = 0x0001;\n\t\tconst uint EvCts = 0x0008;\n\t\tconst uint EvDsr = 0x0010;\n\t\tconst uint EvRlsd = 0x0020;\n\t\tconst uint EvBreak = 0x0040;\n\t\tconst uint EvErr = 0x0080;\n\t\tconst uint EvRing = 0x0100;\n\t\tint handle;\n\t\tint read_timeout;\n\t\tint write_timeout;\n\t\tbool disposed;\n\t\tIntPtr write_overlapped;\n\t\tIntPtr read_overlapped;\n\t\tManualResetEvent read_event;\n\t\tManualResetEvent write_event;\n\t\tTimeouts timeouts;\n\t\t[DllImport(\"kernel32\", SetLastError = true)]\n\t\tstatic extern int CreateFile(string port_name, uint desired_access,\n\t\t\t\tuint share_mode, uint security_attrs, uint creation, uint flags,\n\t\t\t\tuint template);\n\t\t[DllImport(\"kernel32\", SetLastError = true)]\n\t\tstatic extern bool SetupComm(int handle, int read_buffer_size, int write_buffer_size);\n\t\t[DllImport(\"kernel32\", SetLastError = true)]\n\t\tstatic extern bool PurgeComm(int handle, uint flags);\n\t\t[DllImport(\"kernel32\", SetLastError = true)]\n\t\tstatic extern bool SetCommTimeouts(int handle, Timeouts timeouts);\n\t\tpublic WinSerialStream (string port_name, int baud_rate, int data_bits, Parity parity, StopBits sb,\n\t\t\t\tbool dtr_enable, bool rts_enable, Handshake hs, int read_timeout, int write_timeout,\n\t\t\t\tint read_buffer_size, int write_buffer_size)\n\t\t{\n\t\t\thandle = CreateFile (port_name != null && !port_name.StartsWith(@\"\\\\.\\\")\n\t\t\t\t\t? @\"\\\\.\\\" + port_name : port_name,\n\t\t\t\t\tGenericRead | GenericWrite, 0, 0, OpenExisting,\n\t\t\t\t\tFileFlagOverlapped, 0);\n\t\t\tif (handle == -1)\n\t\t\t\tReportIOError (port_name);\n\t\t\t// Set port low level attributes\n\t\t\tSetAttributes (baud_rate, parity, data_bits, sb, hs);\n\t\t\t// Clean buffers and set sizes\n\t\t\tif (!PurgeComm (handle, PurgeRxClear | PurgeTxClear) ||\n\t\t\t\t\t!SetupComm (handle, read_buffer_size, write_buffer_size))\n\t\t\t\tReportIOError (null);\n\t\t\t// Set timeouts\n\t\t\tthis.read_timeout = read_timeout;\n\t\t\tthis.write_timeout = write_timeout;\n\t\t\ttimeouts = new Timeouts (read_timeout, write_timeout);\n\t\t\tif (!SetCommTimeouts(handle, timeouts))\n\t\t\t\tReportIOError (null);\n\t\t\t/// Set DTR and RTS\n\t\t\tSetSignal(SerialSignal.Dtr, dtr_enable);\n\t\t\tif (hs != Handshake.RequestToSend &&\n\t\t\t\t\ths != Handshake.RequestToSendXOnXOff)\n\t\t\t\tSetSignal(SerialSignal.Rts, rts_enable);\n\t\t\t// Init overlapped structures\n\t\t\tNativeOverlapped wo = new NativeOverlapped ();\n\t\t\twrite_event = new ManualResetEvent (false);\n\t\t\two.EventHandle = write_event.Handle;\n\t\t\twrite_overlapped = Marshal.AllocHGlobal (Marshal.SizeOf (typeof (NativeOverlapped)));\n\t\t\tMarshal.StructureToPtr (wo, write_overlapped, true);\n\t\t\tNativeOverlapped ro = new NativeOverlapped ();\n\t\t\tread_event = new ManualResetEvent (false);\n\t\t\tro.EventHandle = read_event.Handle;\n\t\t\tread_overlapped = Marshal.AllocHGlobal (Marshal.SizeOf (typeof (NativeOverlapped)));\n\t\t\tMarshal.StructureToPtr (ro, read_overlapped, true);\n\t\t}\n\t\tpublic override bool CanRead {\n\t\t\tget {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\tpublic override bool CanSeek {\n\t\t\tget {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\tpublic override bool CanTimeout {\n\t\t\tget {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\tpublic override bool CanWrite {\n\t\t\tget {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\tpublic override int ReadTimeout {\n\t\t\tget {\n\t\t\t\treturn read_timeout;\n\t\t\t}\n\t\t\tset {\n\t\t\t\tif (value < 0 && value != SerialPort.InfiniteTimeout)\n\t\t\t\t\tthrow new ArgumentOutOfRangeException (\"value\");\n\t\t\t\ttimeouts.SetValues (value, write_timeout);\n\t\t\t\tif (!SetCommTimeouts (handle, timeouts))\n\t\t\t\t\tReportIOError (null);\n\t\t\t\tread_timeout = value;\n\t\t\t}\n\t\t}\n\t\tpublic override int WriteTimeout {\n\t\t\tget {\n\t\t\t\treturn write_timeout;\n\t\t\t}\n\t\t\tset\n\t\t\t{\n\t\t\t\tif (value < 0 && value != SerialPort.InfiniteTimeout)\n\t\t\t\t\tthrow new ArgumentOutOfRangeException (\"value\");\n\t\t\t\ttimeouts.SetValues (read_timeout, value);\n\t\t\t\tif (!SetCommTimeouts (handle, timeouts))\n\t\t\t\t\tReportIOError (null);\n\t\t\t\twrite_timeout = value;\n\t\t\t}\n\t\t}\n\t\tpublic override long Length {\n\t\t\tget {\n\t\t\t\tthrow new NotSupportedException ();\n\t\t\t}\n\t\t}\n\t\tpublic override long Position {\n\t\t\tget {\n\t\t\t\tthrow new NotSupportedException ();\n\t\t\t}\n\t\t\tset {\n\t\t\t\tthrow new NotSupportedException ();\n\t\t\t}\n\t\t}\n\t\t[DllImport(\"kernel32\", SetLastError = true)]\n\t\tstatic extern bool CloseHandle (int handle);\n\t\tprotected override void Dispose (bool disposing)\n\t\t{\n\t\t\tif (disposed)\n\t\t\t\treturn;\n\t\t\tdisposed = true;\n\t\t\tCloseHandle (handle);\n\t\t\tMarshal.FreeHGlobal (write_overlapped);\n\t\t\tMarshal.FreeHGlobal (read_overlapped);\n\t\t}\n\t\tvoid IDisposable.Dispose ()\n\t\t{\n\t\t\tDispose (true);\n\t\t\tGC.SuppressFinalize (this);\n\t\t}\n\t\tpublic override void Close ()\n\t\t{\n\t\t\t((IDisposable)this).Dispose ();\n\t\t}\n\t\t~WinSerialStream ()\n\t\t{\n\t\t\tDispose (false);\n\t\t}\n\t\tpublic override void Flush ()\n\t\t{\n\t\t\tCheckDisposed ();\n\t\t\t// No dothing by now\n\t\t}\n\t\tpublic override long Seek (long offset, SeekOrigin origin)\n\t\t{\n\t\t\tthrow new NotSupportedException();\n\t\t}\n\t\tpublic override void SetLength (long value)\n\t\t{\n\t\t\tthrow new NotSupportedException();\n\t\t}\n#if !TARGET_JVM\n\t\t[DllImport(\"kernel32\", SetLastError = true)]\n\t\t\tstatic extern unsafe bool ReadFile (int handle, byte* buffer, int bytes_to_read,\n\t\t\t\t\tout int bytes_read, IntPtr overlapped);\n\t\t[DllImport(\"kernel32\", SetLastError = true)]\n\t\t\tstatic extern unsafe bool GetOverlappedResult (int handle, IntPtr overlapped,\n\t\t\t\t\tref int bytes_transfered, bool wait);\n#endif\n\t\tpublic override int Read ([In, Out] byte [] buffer, int offset, int count)\n\t\t{\n\t\t\tCheckDisposed ();\n\t\t\tif (buffer == null)\n\t\t\t\tthrow new ArgumentNullException (\"buffer\");\n\t\t\tif (offset < 0 || count < 0)\n\t\t\t\tthrow new ArgumentOutOfRangeException (\"offset or count less than zero.\");\n\t\t\tif (buffer.Length - offset < count )\n\t\t\t\tthrow new ArgumentException (\"offset+count\",\n\t\t\t\t\t\t\t      \"The size of the buffer is less than offset + count.\");\n\t\t\tint bytes_read;\n\t\t\tunsafe {\n\t\t\t\tfixed (byte* ptr = buffer) {\n\t\t\t\t\tif (ReadFile (handle, ptr + offset, count, out bytes_read, read_overlapped))\n\t\t\t\t\t\treturn bytes_read;\n\t\t\t\t\n\t\t\t\t\t// Test for overlapped behavior\n\t\t\t\t\tif (Marshal.GetLastWin32Error () != FileIOPending)\n\t\t\t\t\t\tReportIOError (null);\n\t\t\t\t\n\t\t\t\t\tif (!GetOverlappedResult (handle, read_overlapped, ref bytes_read, true))\n\t\t\t\t\t\tReportIOError (null);\n\t\t\t\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (bytes_read == 0)\n\t\t\t\tthrow new TimeoutException (); // We didn't get any byte\n\t\t\treturn bytes_read;\n\t\t}\n#if !TARGET_JVM\n\t\t[DllImport(\"kernel32\", SetLastError = true)]\n\t\tstatic extern unsafe bool WriteFile (int handle, byte* buffer, int bytes_to_write,\n\t\t\t\tout int bytes_written, IntPtr overlapped);\n#endif\n\t\tpublic override void Write (byte [] buffer, int offset, int count)\n\t\t{\n\t\t\tCheckDisposed ();\n\t\t\tif (buffer == null)\n\t\t\t\tthrow new ArgumentNullException (\"buffer\");\n\t\t\tif (offset < 0 || count < 0)\n\t\t\t\tthrow new ArgumentOutOfRangeException ();\n\t\t\tif (buffer.Length - offset < count)\n\t\t\t\tthrow new ArgumentException (\"offset+count\",\n\t\t\t\t\t\t\t     \"The size of the buffer is less than offset + count.\");\n\t\t\tint bytes_written = 0;\n\t\t\tunsafe {\n\t\t\t\tfixed (byte* ptr = buffer) {\n\t\t\t\t\tif (WriteFile (handle, ptr + offset, count, out bytes_written, write_overlapped))\n\t\t\t\t\t\treturn;\n\t\t\t\t\tif (Marshal.GetLastWin32Error() != FileIOPending)\n\t\t\t\t\t\tReportIOError (null);\n\t\t\t\t\t\n\t\t\t\t\tif (!GetOverlappedResult(handle, write_overlapped, ref bytes_written, true))\n\t\t\t\t\t\tReportIOError (null);\n\t\t\t\t}\n\t\t\t}\n\t\t\t// If the operation timed out, then\n\t\t\t// we transfered less bytes than the requested ones\n\t\t\tif (bytes_written < count)\n\t\t\t\tthrow new TimeoutException ();\n\t\t}\n\t\t[DllImport(\"kernel32\", SetLastError = true)]\n\t\tstatic extern bool GetCommState (int handle, [Out] DCB dcb);\n\t\t[DllImport (\"kernel32\", SetLastError=true)]\n\t\tstatic extern bool SetCommState (int handle, DCB dcb);\n\t\tpublic void SetAttributes (int baud_rate, Parity parity, int data_bits, StopBits bits, Handshake hs)\n\t\t{\n\t\t\tDCB dcb = new DCB ();\n\t\t\tif (!GetCommState (handle, dcb))\n\t\t\t\tReportIOError (null);\n", "outputs": ["\t\t\tdcb.SetValues (baud_rate, parity, data_bits, bits, hs);"], "input_length": 1614, "output_length": 13, "length": 1627, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "e67ec90d06797e1e91cabaff89a73e03407990105684948b01090ed1288130c6"}
{"input": "", "context": "using Server.Spells;\nusing Server.Targeting;\nusing System;\nusing System.Collections;\nusing System.Collections.Generic;\nnamespace Server.Items\n{\n    public abstract class BaseConflagrationPotion : BasePotion\n    {\n        public abstract int MinDamage { get; }\n        public abstract int MaxDamage { get; }\n        public override bool RequireFreeHand => false;\n        public BaseConflagrationPotion(PotionEffect effect)\n            : base(0xF06, effect)\n        {\n            Hue = 0x489;\n        }\n        public BaseConflagrationPotion(Serial serial)\n            : base(serial)\n        {\n        }\n        public override void Drink(Mobile from)\n        {\n            if (from.Paralyzed || from.Frozen || (from.Spell != null && from.Spell.IsCasting))\n            {\n                from.SendLocalizedMessage(1062725); // You can not use that potion while paralyzed.\n                return;\n            }\n            int delay = GetDelay(from);\n            if (delay > 0)\n            {\n                from.SendLocalizedMessage(1072529, string.Format(\"{0}\\t{1}\", delay, delay > 1 ? \"seconds.\" : \"second.\")); // You cannot use that for another ~1_NUM~ ~2_TIMEUNITS~\n                return;\n            }\n            ThrowTarget targ = from.Target as ThrowTarget;\n            if (targ != null && targ.Potion == this)\n                return;\n            from.RevealingAction();\n            if (!m_Users.Contains(from))\n                m_Users.Add(from);\n            from.Target = new ThrowTarget(this);\n        }\n        public override void Serialize(GenericWriter writer)\n        {\n            base.Serialize(writer);\n            writer.Write(0); // version\n        }\n        public override void Deserialize(GenericReader reader)\n        {\n            base.Deserialize(reader);\n            int version = reader.ReadInt();\n        }\n        private readonly List<Mobile> m_Users = new List<Mobile>();\n        public void Explode_Callback(object state)\n        {\n            object[] states = (object[])state;\n            Explode((Mobile)states[0], (Point3D)states[1], (Map)states[2]);\n        }\n        public virtual void Explode(Mobile from, Point3D loc, Map map)\n        {\n            if (Deleted || map == null)\n                return;\n            Consume();\n            // Check if any other players are using this potion\n            for (int i = 0; i < m_Users.Count; i++)\n            {\n                ThrowTarget targ = m_Users[i].Target as ThrowTarget;\n                if (targ != null && targ.Potion == this)\n                    Target.Cancel(from);\n            }\n            // Effects\n            Effects.PlaySound(loc, map, 0x20C);\n            for (int i = -2; i <= 2; i++)\n            {\n                for (int j = -2; j <= 2; j++)\n                {\n                    Point3D p = new Point3D(loc.X + i, loc.Y + j, loc.Z);\n                    SpellHelper.AdjustField(ref p, map, 16, true);\n                    if (SpellHelper.CheckField(p, map) && map.LineOfSight(new Point3D(loc.X, loc.Y, loc.Z + 14), p))\n                        new InternalItem(from, p, map, MinDamage, MaxDamage);\n                }\n            }\n        }\n        #region Delay\n        private static readonly Hashtable m_Delay = new Hashtable();\n        public static void AddDelay(Mobile m)\n        {\n            Timer timer = m_Delay[m] as Timer;\n            if (timer != null)\n                timer.Stop();\n            m_Delay[m] = Timer.DelayCall(TimeSpan.FromSeconds(30), new TimerStateCallback(EndDelay_Callback), m);\n        }\n        public static int GetDelay(Mobile m)\n        {\n            Timer timer = m_Delay[m] as Timer;\n            if (timer != null && timer.Next > DateTime.UtcNow)\n                return (int)(timer.Next - DateTime.UtcNow).TotalSeconds;\n            return 0;\n        }\n        private static void EndDelay_Callback(object obj)\n        {\n            if (obj is Mobile)\n                EndDelay((Mobile)obj);\n        }\n        public static void EndDelay(Mobile m)\n        {\n            Timer timer = m_Delay[m] as Timer;\n            if (timer != null)\n            {\n                timer.Stop();\n                m_Delay.Remove(m);\n            }\n        }\n        #endregion\n        private class ThrowTarget : Target\n        {\n            private readonly BaseConflagrationPotion m_Potion;\n            public BaseConflagrationPotion Potion => m_Potion;\n            public ThrowTarget(BaseConflagrationPotion potion)\n                : base(12, true, TargetFlags.None)\n            {\n                m_Potion = potion;\n            }\n            protected override void OnTarget(Mobile from, object targeted)\n            {\n                if (m_Potion.Deleted || m_Potion.Map == Map.Internal)\n                    return;\n                IPoint3D p = targeted as IPoint3D;\n                if (p == null || from.Map == null)\n                    return;\n                // Add delay\n                if (from.AccessLevel == AccessLevel.Player)\n                {\n                    AddDelay(from);\n                }\n                SpellHelper.GetSurfaceTop(ref p);\n                from.RevealingAction();\n                IEntity to;\n                if (p is Mobile)\n                    to = (Mobile)p;\n                else\n                    to = new Entity(Serial.Zero, new Point3D(p), from.Map);\n                Effects.SendMovingEffect(from, to, 0xF0D, 7, 0, false, false, m_Potion.Hue, 0);\n                Timer.DelayCall(TimeSpan.FromSeconds(1.5), new TimerStateCallback(m_Potion.Explode_Callback), new object[] { from, new Point3D(p), from.Map });\n            }\n        }\n        public class InternalItem : Item\n        {\n            private Mobile m_From;\n            private int m_MinDamage;\n            private int m_MaxDamage;\n            private DateTime m_End;\n            private Timer m_Timer;\n            public Mobile From => m_From;\n            public override bool BlocksFit => true;\n            public InternalItem(Mobile from, Point3D loc, Map map, int min, int max)\n                : base(0x398C)\n            {\n                Movable = false;\n                Light = LightType.Circle300;\n                MoveToWorld(loc, map);\n                m_From = from;\n                m_End = DateTime.UtcNow + TimeSpan.FromSeconds(10);\n                SetDamage(min, max);\n                m_Timer = new InternalTimer(this, m_End);\n                m_Timer.Start();\n            }\n            public override void OnAfterDelete()\n            {\n                base.OnAfterDelete();\n                if (m_Timer != null)\n                    m_Timer.Stop();\n            }\n            public InternalItem(Serial serial)\n                : base(serial)\n            {\n            }\n            public int GetDamage()\n            {\n                return Utility.RandomMinMax(m_MinDamage, m_MaxDamage);\n            }\n            private void SetDamage(int min, int max)\n            {\n                /* \tnew way to apply alchemy bonus according to Stratics' calculator.\n                this gives a mean to values 25, 50, 75 and 100. Stratics' calculator is outdated.\n                Those goals will give 2 to alchemy bonus. It's not really OSI-like but it's an approximation. */\n                m_MinDamage = min;\n                m_MaxDamage = max;\n                if (m_From == null)\n                    return;\n                int alchemySkill = m_From.Skills.Alchemy.Fixed;\n                int alchemyBonus = alchemySkill / 125 + alchemySkill / 250;\n                m_MinDamage = Scale(m_From, m_MinDamage + alchemyBonus);\n                m_MaxDamage = Scale(m_From, m_MaxDamage + alchemyBonus);\n            }\n            public override void Serialize(GenericWriter writer)\n            {\n                base.Serialize(writer);\n                writer.Write(0); // version\n                writer.Write(m_From);\n                writer.Write(m_End);\n                writer.Write(m_MinDamage);\n                writer.Write(m_MaxDamage);\n            }\n            public override void Deserialize(GenericReader reader)\n            {\n                base.Deserialize(reader);\n                int version = reader.ReadInt();\n                m_From = reader.ReadMobile();\n                m_End = reader.ReadDateTime();\n                m_MinDamage = reader.ReadInt();\n                m_MaxDamage = reader.ReadInt();\n                m_Timer = new InternalTimer(this, m_End);\n                m_Timer.Start();\n            }\n            public override bool OnMoveOver(Mobile m)\n            {\n                if (Visible && m_From != null && m != m_From && SpellHelper.ValidIndirectTarget(m_From, m) && m_From.CanBeHarmful(m, false))\n                {\n                    m_From.DoHarmful(m);\n                    AOS.Damage(m, m_From, GetDamage(), 0, 100, 0, 0, 0);\n                    m.PlaySound(0x208);\n                }\n                return true;\n            }\n            private class InternalTimer : Timer\n            {\n                private readonly InternalItem m_Item;\n                private readonly DateTime m_End;\n                public InternalTimer(InternalItem item, DateTime end)\n                    : base(TimeSpan.Zero, TimeSpan.FromSeconds(1.0))\n                {\n                    m_Item = item;\n                    m_End = end;\n                    Priority = TimerPriority.FiftyMS;\n                }\n                protected override void OnTick()\n                {\n                    if (m_Item.Deleted)\n                        return;\n                    if (DateTime.UtcNow > m_End)\n                    {\n                        m_Item.Delete();\n                        Stop();\n                        return;\n                    }\n                    Mobile from = m_Item.From;\n                    if (m_Item.Map == null || from == null)\n                        return;\n                    List<Mobile> mobiles = new List<Mobile>();\n                    IPooledEnumerable eable = m_Item.GetMobilesInRange(0);\n                    foreach (Mobile mobile in eable)\n                        mobiles.Add(mobile);\n                    eable.Free();\n                    for (int i = 0; i < mobiles.Count; i++)\n                    {\n", "outputs": ["                        Mobile m = mobiles[i];"], "input_length": 1523, "output_length": 8, "length": 1531, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "78903019f3f10a5ab04285f0a99da300933d9de463704482c07adb3c922e62eb"}
{"input": "", "context": "using Server;\nusing System;\nusing Server.Mobiles;\nusing Server.Gumps;\nusing System.Collections.Generic;\nusing Server.Engines.Quests;\nusing Server.Network;\nusing Server.ContextMenus;\nusing Server.Multis;\nnamespace Server.Items\n{\n    public class MyrmidexRewardBag : Backpack\n    {\n        public MyrmidexRewardBag()\n        {\n            Hue = BaseReward.RewardBagHue();\n            switch (Utility.Random(4))\n            {\n                default:\n                case 0: DropItem(new RecipeScroll(Utility.RandomMinMax(900, 905))); break;\n                case 1: DropItem(new EodonTribeRewardTitleToken()); break;\n                case 2: DropItem(new RecipeScroll(455)); break;\n                case 3: DropItem(new MoonstoneCrystal()); break;\n            }\n        }\n        public MyrmidexRewardBag(Serial serial)\n            : base(serial)\n\t\t{\n\t\t}\n\t\t\n\t\tpublic override void Serialize(GenericWriter writer)\n\t\t{\n\t\t\tbase.Serialize(writer);\n\t\t\twriter.Write(0);\n\t\t}\n\t\t\n\t\tpublic override void Deserialize(GenericReader reader)\n\t\t{\n\t\t\tbase.Deserialize(reader);\n\t\t\tint version = reader.ReadInt();\n\t\t}\n    }\n    public class EodonianRewardBag : Backpack\n    {\n        public EodonianRewardBag()\n        {\n            Hue = BaseReward.RewardBagHue();\n            switch (Utility.Random(4))\n            {\n                default:\n                case 0: DropItem(new MonsterStatuette(MonsterStatuetteType.SakkhranBirdOfPrey)); break;\n                case 1: DropItem(new EodonTribeRewardTitleToken()); break;\n                case 2: DropItem(new RecipeScroll(1000)); break;\n                case 3:\n                    if (0.5 > Utility.RandomDouble())\n                        DropItem(new RawMoonstoneLargeAddonDeed());\n                    else\n                        DropItem(new RawMoonstoneSmallAddonDeed());\n                    break;\n            }\n        }\n        public EodonianRewardBag(Serial serial)\n            : base(serial)\n        {\n        }\n        public override void Serialize(GenericWriter writer)\n        {\n            base.Serialize(writer);\n            writer.Write(0);\n        }\n        public override void Deserialize(GenericReader reader)\n        {\n            base.Deserialize(reader);\n            int version = reader.ReadInt();\n        }\n    }\n\tpublic class MoonstoneCrystal : Item, ISecurable\n\t{\n\t\tpublic static Dictionary<int, Point3D> Locations { get; set; }\n        private SecureLevel m_SecureLevel;\n     \n\t\tpublic static void Initialize()\n\t\t{\n\t\t\tLocations = new Dictionary<int, Point3D>();\n\t\t\t\n\t\t\tLocations[1156706] = new Point3D(642, 1721, 40); // Barako Village\n            Locations[1156707] = new Point3D(701, 2106, 40); // Jukari Village\n\t\t\tLocations[1156708] = new Point3D(355, 1873, 0);  // Kurak Village\n\t\t\tLocations[1156709] = new Point3D(552, 1471, 40); // Sakkhra Village\n\t\t\tLocations[1156710] = new Point3D(412, 1595, 40); // Urali Village\n\t\t\tLocations[1156711] = new Point3D(167, 1800, 80); // Barrab Village\n\t\t\tLocations[1156712] = new Point3D(929, 2016, 50); // Shadowguard\n\t\t\tLocations[1156713] = new Point3D(731, 1603, 40); // The great ape cave\n\t\t\tLocations[1156714] = new Point3D(878, 2105, 40); // The Volcano\n\t\t\tLocations[1156715] = new Point3D(390, 1690, 40); // Dragon Turtle Habitat\n\t\t\tLocations[1156716] = new Point3D(269, 1726, 80); // Britannian Encampment\n\t\t}\n        [CommandProperty(AccessLevel.GameMaster)]\n        public SecureLevel Level\n        {\n            get\n            {\n                return this.m_SecureLevel;\n            }\n            set\n            {\n                this.m_SecureLevel = value;\n            }\n        }\n \n        public override void GetContextMenuEntries(Mobile from, List<ContextMenuEntry> list)\n        {\n            base.GetContextMenuEntries(from, list);\n            SetSecureLevelEntry.AddTo(from, this, list);\n        }\n     \n        public override int LabelNumber { get { return 1124143; } } // Moonstone Crystal\n\t\t\n\t\t[Constructable]\n\t\tpublic MoonstoneCrystal() : base(40123)\n\t\t{\n\t\t}\n\t\t\n\t\tpublic override void OnDoubleClick(Mobile from)\n\t\t{\n\t\t\tif((IsLockedDown || IsSecure) && from.InRange(GetWorldLocation(), 3))\n\t\t\t{\n\t\t\t\tfrom.SendGump(new InternalGump(from as PlayerMobile, this));\n\t\t\t}\n\t\t}\n\t\t\n\t\tprivate class InternalGump : Gump\n\t\t{\n\t\t\tpublic Item Moonstone { get; set; }\n            public PlayerMobile User { get; set; }\n\t\t\t\n\t\t\tpublic InternalGump(PlayerMobile pm, Item moonstone) : base(75, 75)\n\t\t\t{\n\t\t\t\tMoonstone = moonstone;\n                User = pm;\n                AddGumpLayout();\n\t\t\t}\n\t\t\t\n\t\t\tpublic void AddGumpLayout()\n\t\t\t{\n\t\t\t\tAddBackground( 0, 0, 400, 400, 9270 );\n\t\t\t\t\n\t\t\t\tAddHtmlLocalized( 0, 15, 400, 16, 1154645, \"#1156704\", 0xFFFF, false, false ); // Select your destination:\n                ColUtility.For<int, Point3D>(MoonstoneCrystal.Locations, (i, key, value) =>\n\t\t\t\t{\n\t\t\t\t\tAddHtmlLocalized(60, 45 + (i * 25), 250, 16, key, 0xFFFF, false, false);\n\t\t\t\t\tAddButton(20, 50 + (i * 25), 2117, 2118, key, GumpButtonType.Reply, 0);\n\t\t\t\t});\n\t\t\t}\n            public override void OnResponse(NetState state, RelayInfo info)\n            {\n                if (info.ButtonID > 0)\n                {\n                    int id = info.ButtonID;\n                    if (MoonstoneCrystal.Locations.ContainsKey(id))\n                    {\n                        Point3D p = MoonstoneCrystal.Locations[id];\n                        if (CheckTravel(p))\n                        {\n                            BaseCreature.TeleportPets(User, p, Map.TerMur);\n                            User.Combatant = null;\n                            User.Warmode = false;\n                            User.Hidden = true;\n                            User.MoveToWorld(p, Map.TerMur);\n                            Effects.PlaySound(p, Map.TerMur, 0x1FE);\n                        }\n                    }\n                }\n            }\n\t\t\t\n\t\t\tprivate bool CheckTravel(Point3D p)\n\t\t\t{\n\t\t\t\tif ( !User.InRange( Moonstone.GetWorldLocation(), 1 ) || User.Map != Moonstone.Map )\n\t\t\t\t{\n\t\t\t\t\tUser.SendLocalizedMessage( 1019002 ); // You are too far away to use the gate.\n\t\t\t\t}\n\t\t\t\t/* CEO - 02/20/06 - Removed to allow Reds access to other lands\n\t\t\t\telse if ( User.Murderer )\n\t\t\t\t{\n\t\t\t\t\tUser.SendLocalizedMessage( 1019004 ); // You are not allowed to travel there.\n\t\t\t\t}\n\t\t\t\t */\n\t\t\t\telse if ( Server.Factions.Sigil.ExistsOn( User ) )\n\t\t\t\t{\n\t\t\t\t\tUser.SendLocalizedMessage( 1019004 ); // You are not allowed to travel there.\n\t\t\t\t}\n\t\t\t\telse if ( User.Criminal )\n\t\t\t\t{\n\t\t\t\t\tUser.SendLocalizedMessage( 1005561, \"\", 0x22 ); // Thou'rt a criminal and cannot escape so easily.\n\t\t\t\t}\n\t\t\t\telse if ( Server.Spells.SpellHelper.CheckCombat( User ) )\n\t\t\t\t{\n\t\t\t\t\tUser.SendLocalizedMessage( 1005564, \"\", 0x22 ); // Wouldst thou flee during the heat of battle??\n\t\t\t\t}\n\t\t\t\telse if ( User.Spell != null )\n\t\t\t\t{\n\t\t\t\t\tUser.SendLocalizedMessage( 1049616 ); // You are too busy to do that at the moment.\n\t\t\t\t}\n\t\t\t\telse if ( User.Map == Map.TerMur && User.InRange( p, 1 ) )\n\t\t\t\t{\n\t\t\t\t\tUser.SendLocalizedMessage( 1019003 ); // You are already there.\n\t\t\t\t}\n                else\n                    return true;\n                return false;\n\t\t\t}\n\t\t}\n\t\t\n\t\tpublic MoonstoneCrystal(Serial serial) : base(serial)\n\t\t{\n\t\t}\n\t\t\n\t\tpublic override void Serialize(GenericWriter writer)\n\t\t{\n\t\t\tbase.Serialize(writer);\n\t\t\twriter.Write(0);\n            writer.Write((int)this.m_SecureLevel);  // At first, need to save world with this line before next starting.\n\t\t}\n\t\t\n\t\tpublic override void Deserialize(GenericReader reader)\n\t\t{\n\t\t\tbase.Deserialize(reader);\n\t\t\tint version = reader.ReadInt();\n            this.m_SecureLevel = (SecureLevel)reader.ReadInt();  // If you have not saved world with above line in Serialize(), you should not add this line.\n\t\t}\n\t}\n\t\n    [TypeAlias(\"Server.Items.KotlPowerCoil\")]\n\tpublic class KotlPowerCore : Item\n\t{\n        public override int LabelNumber { get { return 1124179; } } // Kotl Power Core\n\t\t[Constructable]\n\t\tpublic KotlPowerCore() : base(40147)\n\t\t{\n\t\t}\n\t\t\n\t\tpublic KotlPowerCore(Serial serial) : base(serial)\n\t\t{\n\t\t}\n\t\t\n\t\tpublic override void Serialize(GenericWriter writer)\n\t\t{\n\t\t\tbase.Serialize(writer);\n\t\t\twriter.Write(0);\n\t\t}\n\t\t\n\t\tpublic override void Deserialize(GenericReader reader)\n\t\t{\n\t\t\tbase.Deserialize(reader);\n\t\t\tint version = reader.ReadInt();\n\t\t}\n\t}\n\t\n\tpublic class EodonianWallMap : Item\n\t{\n\t\tpublic override int LabelNumber { get { return 1156690; } } // Wall Map of Eodon\n\t\t[Constructable]\n\t\tpublic EodonianWallMap() : base(11635)\n\t\t{\n\t\t}\n\t\t\n\t\tpublic override void OnDoubleClick(Mobile from)\n\t\t{\n\t\t\tif(from.InRange(GetWorldLocation(), 5))\n\t\t\t{\n", "outputs": ["\t\t\t\tGump g = new Gump(0, 0);"], "input_length": 1454, "output_length": 11, "length": 1465, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "4a0ad778fac85555266b7ebddeeb2c1195d4630053562f383f7331f0e3d81190"}
{"input": "", "context": "//\n// TypeDefinition.cs\n//\n// Author:\n//   Jb Evain (jbevain@gmail.com)\n//\n// Copyright (c) 2008 - 2011 Jb Evain\n//\n// Permission is hereby granted, free of charge, to any person obtaining\n// a copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to\n// permit persons to whom the Software is furnished to do so, subject to\n// the following conditions:\n//\n// The above copyright notice and this permission notice shall be\n// included in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n// EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n// NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\n// LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\n// OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\n// WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n//\nusing System;\nusing Mono.Collections.Generic;\nnamespace Mono.Cecil {\n\tpublic sealed class TypeDefinition : TypeReference, IMemberDefinition, ISecurityDeclarationProvider {\n\t\tuint attributes;\n\t\tTypeReference base_type;\n\t\tinternal Range fields_range;\n\t\tinternal Range methods_range;\n\t\tshort packing_size = Mixin.NotResolvedMarker;\n\t\tint class_size = Mixin.NotResolvedMarker;\n\t\tCollection<TypeReference> interfaces;\n\t\tCollection<TypeDefinition> nested_types;\n\t\tCollection<MethodDefinition> methods;\n\t\tCollection<FieldDefinition> fields;\n\t\tCollection<EventDefinition> events;\n\t\tCollection<PropertyDefinition> properties;\n\t\tCollection<CustomAttribute> custom_attributes;\n\t\tCollection<SecurityDeclaration> security_declarations;\n\t\tpublic TypeAttributes Attributes {\n\t\t\tget { return (TypeAttributes) attributes; }\n\t\t\tset { attributes = (uint) value; }\n\t\t}\n\t\tpublic TypeReference BaseType {\n\t\t\tget { return base_type; }\n\t\t\tset { base_type = value; }\n\t\t}\n\t\tvoid ResolveLayout ()\n\t\t{\n\t\t\tif (packing_size != Mixin.NotResolvedMarker || class_size != Mixin.NotResolvedMarker)\n\t\t\t\treturn;\n\t\t\tif (!HasImage) {\n\t\t\t\tpacking_size = Mixin.NoDataMarker;\n\t\t\t\tclass_size = Mixin.NoDataMarker;\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tvar row = Module.Read (this, (type, reader) => reader.ReadTypeLayout (type));\n\t\t\tpacking_size = row.Col1;\n\t\t\tclass_size = row.Col2;\n\t\t}\n\t\tpublic bool HasLayoutInfo {\n\t\t\tget {\n\t\t\t\tif (packing_size >= 0 || class_size >= 0)\n\t\t\t\t\treturn true;\n\t\t\t\tResolveLayout ();\n\t\t\t\treturn packing_size >= 0 || class_size >= 0;\n\t\t\t}\n\t\t}\n\t\tpublic short PackingSize {\n\t\t\tget {\n\t\t\t\tif (packing_size >= 0)\n\t\t\t\t\treturn packing_size;\n\t\t\t\tResolveLayout ();\n\t\t\t\treturn packing_size >= 0 ? packing_size : (short) -1;\n\t\t\t}\n\t\t\tset { packing_size = value; }\n\t\t}\n\t\tpublic int ClassSize {\n\t\t\tget {\n\t\t\t\tif (class_size >= 0)\n\t\t\t\t\treturn class_size;\n\t\t\t\tResolveLayout ();\n\t\t\t\treturn class_size >= 0 ? class_size : -1;\n\t\t\t}\n\t\t\tset { class_size = value; }\n\t\t}\n\t\tpublic bool HasInterfaces {\n\t\t\tget {\n\t\t\t\tif (interfaces != null)\n\t\t\t\t\treturn interfaces.Count > 0;\n\t\t\t\tif (HasImage)\n\t\t\t\t\treturn Module.Read (this, (type, reader) => reader.HasInterfaces (type));\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\tpublic Collection<TypeReference> Interfaces {\n\t\t\tget {\n\t\t\t\tif (interfaces != null)\n\t\t\t\t\treturn interfaces;\n\t\t\t\tif (HasImage)\n\t\t\t\t\treturn Module.Read (ref interfaces, this, (type, reader) => reader.ReadInterfaces (type));\n\t\t\t\treturn interfaces = new Collection<TypeReference> ();\n\t\t\t}\n\t\t}\n\t\tpublic bool HasNestedTypes {\n\t\t\tget {\n\t\t\t\tif (nested_types != null)\n\t\t\t\t\treturn nested_types.Count > 0;\n\t\t\t\tif (HasImage)\n\t\t\t\t\treturn Module.Read (this, (type, reader) => reader.HasNestedTypes (type));\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\tpublic Collection<TypeDefinition> NestedTypes {\n\t\t\tget {\n\t\t\t\tif (nested_types != null)\n\t\t\t\t\treturn nested_types;\n\t\t\t\tif (HasImage)\n\t\t\t\t\treturn Module.Read (ref nested_types, this, (type, reader) => reader.ReadNestedTypes (type));\n\t\t\t\treturn nested_types = new MemberDefinitionCollection<TypeDefinition> (this);\n\t\t\t}\n\t\t}\n\t\tpublic bool HasMethods {\n\t\t\tget {\n\t\t\t\tif (methods != null)\n\t\t\t\t\treturn methods.Count > 0;\n\t\t\t\tif (HasImage)\n\t\t\t\t\treturn methods_range.Length > 0;\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\tpublic Collection<MethodDefinition> Methods {\n\t\t\tget {\n\t\t\t\tif (methods != null)\n\t\t\t\t\treturn methods;\n\t\t\t\tif (HasImage)\n\t\t\t\t\treturn Module.Read (ref methods, this, (type, reader) => reader.ReadMethods (type));\n\t\t\t\treturn methods = new MemberDefinitionCollection<MethodDefinition> (this);\n\t\t\t}\n\t\t}\n\t\tpublic bool HasFields {\n\t\t\tget {\n\t\t\t\tif (fields != null)\n\t\t\t\t\treturn fields.Count > 0;\n\t\t\t\tif (HasImage)\n\t\t\t\t\treturn fields_range.Length > 0;\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\tpublic Collection<FieldDefinition> Fields {\n\t\t\tget {\n\t\t\t\tif (fields != null)\n\t\t\t\t\treturn fields;\n\t\t\t\tif (HasImage)\n\t\t\t\t\treturn Module.Read (ref fields, this, (type, reader) => reader.ReadFields (type));\n\t\t\t\treturn fields = new MemberDefinitionCollection<FieldDefinition> (this);\n\t\t\t}\n\t\t}\n\t\tpublic bool HasEvents {\n\t\t\tget {\n\t\t\t\tif (events != null)\n\t\t\t\t\treturn events.Count > 0;\n\t\t\t\tif (HasImage)\n\t\t\t\t\treturn Module.Read (this, (type, reader) => reader.HasEvents (type));\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\tpublic Collection<EventDefinition> Events {\n\t\t\tget {\n\t\t\t\tif (events != null)\n\t\t\t\t\treturn events;\n\t\t\t\tif (HasImage)\n\t\t\t\t\treturn Module.Read (ref events, this, (type, reader) => reader.ReadEvents (type));\n\t\t\t\treturn events = new MemberDefinitionCollection<EventDefinition> (this);\n\t\t\t}\n\t\t}\n\t\tpublic bool HasProperties {\n\t\t\tget {\n\t\t\t\tif (properties != null)\n\t\t\t\t\treturn properties.Count > 0;\n\t\t\t\tif (HasImage)\n\t\t\t\t\treturn Module.Read (this, (type, reader) => reader.HasProperties (type));\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\tpublic Collection<PropertyDefinition> Properties {\n\t\t\tget {\n\t\t\t\tif (properties != null)\n\t\t\t\t\treturn properties;\n\t\t\t\tif (HasImage)\n\t\t\t\t\treturn Module.Read (ref properties, this, (type, reader) => reader.ReadProperties (type));\n\t\t\t\treturn properties = new MemberDefinitionCollection<PropertyDefinition> (this);\n\t\t\t}\n\t\t}\n\t\tpublic bool HasSecurityDeclarations {\n\t\t\tget {\n\t\t\t\tif (security_declarations != null)\n\t\t\t\t\treturn security_declarations.Count > 0;\n\t\t\t\treturn this.GetHasSecurityDeclarations (Module);\n\t\t\t}\n\t\t}\n\t\tpublic Collection<SecurityDeclaration> SecurityDeclarations {\n\t\t\tget { return security_declarations ?? (this.GetSecurityDeclarations (ref security_declarations, Module)); }\n\t\t}\n\t\tpublic bool HasCustomAttributes {\n\t\t\tget {\n\t\t\t\tif (custom_attributes != null)\n\t\t\t\t\treturn custom_attributes.Count > 0;\n\t\t\t\treturn this.GetHasCustomAttributes (Module);\n\t\t\t}\n\t\t}\n\t\tpublic Collection<CustomAttribute> CustomAttributes {\n\t\t\tget { return custom_attributes ?? (this.GetCustomAttributes (ref custom_attributes, Module)); }\n\t\t}\n\t\tpublic override bool HasGenericParameters {\n\t\t\tget {\n\t\t\t\tif (generic_parameters != null)\n\t\t\t\t\treturn generic_parameters.Count > 0;\n\t\t\t\treturn this.GetHasGenericParameters (Module);\n\t\t\t}\n\t\t}\n\t\tpublic override Collection<GenericParameter> GenericParameters {\n\t\t\tget { return generic_parameters ?? (this.GetGenericParameters (ref generic_parameters, Module)); }\n\t\t}\n\t\t#region TypeAttributes\n\t\tpublic bool IsNotPublic {\n\t\t\tget { return attributes.GetMaskedAttributes ((uint) TypeAttributes.VisibilityMask, (uint) TypeAttributes.NotPublic); }\n\t\t\tset { attributes = attributes.SetMaskedAttributes ((uint) TypeAttributes.VisibilityMask, (uint) TypeAttributes.NotPublic, value); }\n\t\t}\n\t\tpublic bool IsPublic {\n\t\t\tget { return attributes.GetMaskedAttributes ((uint) TypeAttributes.VisibilityMask, (uint) TypeAttributes.Public); }\n\t\t\tset { attributes = attributes.SetMaskedAttributes ((uint) TypeAttributes.VisibilityMask, (uint) TypeAttributes.Public, value); }\n\t\t}\n\t\tpublic bool IsNestedPublic {\n\t\t\tget { return attributes.GetMaskedAttributes ((uint) TypeAttributes.VisibilityMask, (uint) TypeAttributes.NestedPublic); }\n\t\t\tset { attributes = attributes.SetMaskedAttributes ((uint) TypeAttributes.VisibilityMask, (uint) TypeAttributes.NestedPublic, value); }\n\t\t}\n\t\tpublic bool IsNestedPrivate {\n\t\t\tget { return attributes.GetMaskedAttributes ((uint) TypeAttributes.VisibilityMask, (uint) TypeAttributes.NestedPrivate); }\n\t\t\tset { attributes = attributes.SetMaskedAttributes ((uint) TypeAttributes.VisibilityMask, (uint) TypeAttributes.NestedPrivate, value); }\n\t\t}\n\t\tpublic bool IsNestedFamily {\n\t\t\tget { return attributes.GetMaskedAttributes ((uint) TypeAttributes.VisibilityMask, (uint) TypeAttributes.NestedFamily); }\n\t\t\tset { attributes = attributes.SetMaskedAttributes ((uint) TypeAttributes.VisibilityMask, (uint) TypeAttributes.NestedFamily, value); }\n\t\t}\n\t\tpublic bool IsNestedAssembly {\n\t\t\tget { return attributes.GetMaskedAttributes ((uint) TypeAttributes.VisibilityMask, (uint) TypeAttributes.NestedAssembly); }\n\t\t\tset { attributes = attributes.SetMaskedAttributes ((uint) TypeAttributes.VisibilityMask, (uint) TypeAttributes.NestedAssembly, value); }\n\t\t}\n\t\tpublic bool IsNestedFamilyAndAssembly {\n\t\t\tget { return attributes.GetMaskedAttributes ((uint) TypeAttributes.VisibilityMask, (uint) TypeAttributes.NestedFamANDAssem); }\n\t\t\tset { attributes = attributes.SetMaskedAttributes ((uint) TypeAttributes.VisibilityMask, (uint) TypeAttributes.NestedFamANDAssem, value); }\n\t\t}\n\t\tpublic bool IsNestedFamilyOrAssembly {\n\t\t\tget { return attributes.GetMaskedAttributes ((uint) TypeAttributes.VisibilityMask, (uint) TypeAttributes.NestedFamORAssem); }\n\t\t\tset { attributes = attributes.SetMaskedAttributes ((uint) TypeAttributes.VisibilityMask, (uint) TypeAttributes.NestedFamORAssem, value); }\n\t\t}\n\t\tpublic bool IsAutoLayout {\n\t\t\tget { return attributes.GetMaskedAttributes ((uint) TypeAttributes.LayoutMask, (uint) TypeAttributes.AutoLayout); }\n\t\t\tset { attributes = attributes.SetMaskedAttributes ((uint) TypeAttributes.LayoutMask, (uint) TypeAttributes.AutoLayout, value); }\n\t\t}\n\t\tpublic bool IsSequentialLayout {\n\t\t\tget { return attributes.GetMaskedAttributes ((uint) TypeAttributes.LayoutMask, (uint) TypeAttributes.SequentialLayout); }\n\t\t\tset { attributes = attributes.SetMaskedAttributes ((uint) TypeAttributes.LayoutMask, (uint) TypeAttributes.SequentialLayout, value); }\n\t\t}\n\t\tpublic bool IsExplicitLayout {\n\t\t\tget { return attributes.GetMaskedAttributes ((uint) TypeAttributes.LayoutMask, (uint) TypeAttributes.ExplicitLayout); }\n\t\t\tset { attributes = attributes.SetMaskedAttributes ((uint) TypeAttributes.LayoutMask, (uint) TypeAttributes.ExplicitLayout, value); }\n\t\t}\n\t\tpublic bool IsClass {\n\t\t\tget { return attributes.GetMaskedAttributes ((uint) TypeAttributes.ClassSemanticMask, (uint) TypeAttributes.Class); }\n\t\t\tset { attributes = attributes.SetMaskedAttributes ((uint) TypeAttributes.ClassSemanticMask, (uint) TypeAttributes.Class, value); }\n\t\t}\n\t\tpublic bool IsInterface {\n\t\t\tget { return attributes.GetMaskedAttributes ((uint) TypeAttributes.ClassSemanticMask, (uint) TypeAttributes.Interface); }\n\t\t\tset { attributes = attributes.SetMaskedAttributes ((uint) TypeAttributes.ClassSemanticMask, (uint) TypeAttributes.Interface, value); }\n\t\t}\n\t\tpublic bool IsAbstract {\n\t\t\tget { return attributes.GetAttributes ((uint) TypeAttributes.Abstract); }\n\t\t\tset { attributes = attributes.SetAttributes ((uint) TypeAttributes.Abstract, value); }\n\t\t}\n\t\tpublic bool IsSealed {\n\t\t\tget { return attributes.GetAttributes ((uint) TypeAttributes.Sealed); }\n\t\t\tset { attributes = attributes.SetAttributes ((uint) TypeAttributes.Sealed, value); }\n\t\t}\n\t\tpublic bool IsSpecialName {\n\t\t\tget { return attributes.GetAttributes ((uint) TypeAttributes.SpecialName); }\n\t\t\tset { attributes = attributes.SetAttributes ((uint) TypeAttributes.SpecialName, value); }\n\t\t}\n\t\tpublic bool IsImport {\n\t\t\tget { return attributes.GetAttributes ((uint) TypeAttributes.Import); }\n\t\t\tset { attributes = attributes.SetAttributes ((uint) TypeAttributes.Import, value); }\n\t\t}\n\t\tpublic bool IsSerializable {\n\t\t\tget { return attributes.GetAttributes ((uint) TypeAttributes.Serializable); }\n\t\t\tset { attributes = attributes.SetAttributes ((uint) TypeAttributes.Serializable, value); }\n\t\t}\n\t\tpublic bool IsAnsiClass {\n\t\t\tget { return attributes.GetMaskedAttributes ((uint) TypeAttributes.StringFormatMask, (uint) TypeAttributes.AnsiClass); }\n\t\t\tset { attributes = attributes.SetMaskedAttributes ((uint) TypeAttributes.StringFormatMask, (uint) TypeAttributes.AnsiClass, value); }\n\t\t}\n\t\tpublic bool IsUnicodeClass {\n\t\t\tget { return attributes.GetMaskedAttributes ((uint) TypeAttributes.StringFormatMask, (uint) TypeAttributes.UnicodeClass); }\n\t\t\tset { attributes = attributes.SetMaskedAttributes ((uint) TypeAttributes.StringFormatMask, (uint) TypeAttributes.UnicodeClass, value); }\n\t\t}\n\t\tpublic bool IsAutoClass {\n\t\t\tget { return attributes.GetMaskedAttributes ((uint) TypeAttributes.StringFormatMask, (uint) TypeAttributes.AutoClass); }\n\t\t\tset { attributes = attributes.SetMaskedAttributes ((uint) TypeAttributes.StringFormatMask, (uint) TypeAttributes.AutoClass, value); }\n\t\t}\n\t\tpublic bool IsBeforeFieldInit {\n\t\t\tget { return attributes.GetAttributes ((uint) TypeAttributes.BeforeFieldInit); }\n\t\t\tset { attributes = attributes.SetAttributes ((uint) TypeAttributes.BeforeFieldInit, value); }\n\t\t}\n\t\tpublic bool IsRuntimeSpecialName {\n\t\t\tget { return attributes.GetAttributes ((uint) TypeAttributes.RTSpecialName); }\n\t\t\tset { attributes = attributes.SetAttributes ((uint) TypeAttributes.RTSpecialName, value); }\n\t\t}\n\t\tpublic bool HasSecurity {\n\t\t\tget { return attributes.GetAttributes ((uint) TypeAttributes.HasSecurity); }\n\t\t\tset { attributes = attributes.SetAttributes ((uint) TypeAttributes.HasSecurity, value); }\n\t\t}\n\t\t#endregion\n\t\tpublic bool IsEnum {\n\t\t\tget { return base_type != null && base_type.IsTypeOf (\"System\", \"Enum\"); }\n\t\t}\n\t\tpublic override bool IsValueType {\n\t\t\tget {\n", "outputs": ["\t\t\t\tif (base_type == null)"], "input_length": 2270, "output_length": 6, "length": 2276, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "2d29d88404f0a1b0314ebfd23f6cd56bfe81cf0f3fb05798b0f1837d0c3b6702"}
{"input": "", "context": "# -*- coding: utf-8 -*-\n#\n# Copyright (C) 2015-2019 Bitergia\n#\n# This program is free software; you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation; either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program. If not, see <http://www.gnu.org/licenses/>.\n#\n# Authors:\n#     Valerio Cosentino <valcos@bitergia.com>\n#\nimport configparser\nimport json\nimport os\nimport requests\nimport sys\nimport unittest\nfrom datetime import datetime\nfrom elasticsearch import Elasticsearch\nif '..' not in sys.path:\n    sys.path.insert(0, '..')\nfrom grimoire_elk.elk import load_identities\nfrom grimoire_elk.utils import get_connectors, get_elastic\nfrom tests.model import ESMapping\nCONFIG_FILE = 'tests.conf'\nDB_SORTINGHAT = \"test_sh\"\nDB_PROJECTS = \"test_projects\"\nFILE_PROJECTS = \"data/projects-release.json\"\nSCHEMA_DIR = '../schema/'\ndef load_mapping(enrich_index, csv_name):\n    cvs_path = os.path.join(SCHEMA_DIR, csv_name + '.csv')\n    cvs_mapping = ESMapping.from_csv(enrich_index, cvs_path)\n    return cvs_mapping\ndef data2es(items, ocean):\n    def ocean_item(item):\n        # Hack until we decide the final id to use\n        if 'uuid' in item:\n            item['ocean-unique-id'] = item['uuid']\n        else:\n            # twitter comes from logstash and uses id\n            item['uuid'] = item['id']\n            item['ocean-unique-id'] = item['id']\n        # Hack until we decide when to drop this field\n        if 'updated_on' in item:\n            updated = datetime.fromtimestamp(item['updated_on'])\n            item['metadata__updated_on'] = updated.isoformat()\n        if 'timestamp' in item:\n            ts = datetime.fromtimestamp(item['timestamp'])\n            item['metadata__timestamp'] = ts.isoformat()\n        # the _fix_item does not apply to the test data for Twitter\n        try:\n            ocean._fix_item(item)\n        except KeyError:\n            pass\n        return item\n    items_pack = []  # to feed item in packs\n    for item in items:\n        item = ocean_item(item)\n        if len(items_pack) >= ocean.elastic.max_items_bulk:\n            ocean._items_to_es(items_pack)\n            items_pack = []\n        items_pack.append(item)\n    inserted = ocean._items_to_es(items_pack)\n    return inserted\ndef refresh_identities(enrich_backend):\n    total = 0\n    for eitem in enrich_backend.fetch():\n        roles = None\n        try:\n            roles = enrich_backend.roles\n        except AttributeError:\n            pass\n        new_identities = enrich_backend.get_item_sh_from_id(eitem, roles)\n        eitem.update(new_identities)\n        total += 1\n    return total\ndef refresh_projects(enrich_backend):\n    total = 0\n    for eitem in enrich_backend.fetch():\n        new_project = enrich_backend.get_item_project(eitem)\n        eitem.update(new_project)\n        total += 1\n    return total\nclass TestBaseBackend(unittest.TestCase):\n    \"\"\"Functional tests for GrimoireELK Backends\"\"\"\n    @classmethod\n    def setUpClass(cls):\n        cls.config = configparser.ConfigParser()\n        cls.config.read(CONFIG_FILE)\n        cls.es_con = dict(cls.config.items('ElasticSearch'))['url']\n        cls.connectors = get_connectors()\n        cls.maxDiff = None\n        # Sorting hat settings\n        cls.db_user = ''\n        cls.db_password = ''\n        if 'Database' in cls.config:\n            if 'user' in cls.config['Database']:\n                cls.db_user = cls.config['Database']['user']\n            if 'password' in cls.config['Database']:\n                cls.db_password = cls.config['Database']['password']\n    def setUp(self):\n        with open(os.path.join(\"data\", self.connector + \".json\")) as f:\n            self.items = json.load(f)\n        self.ocean_backend = None\n        self.enrich_backend = None\n        self.ocean_aliases = []\n        self.enrich_aliases = []\n    def tearDown(self):\n        delete_raw = self.es_con + \"/\" + self.ocean_index\n        requests.delete(delete_raw, verify=False)\n        delete_enrich = self.es_con + \"/\" + self.enrich_index\n        requests.delete(delete_enrich, verify=False)\n    def _test_items_to_raw(self):\n        \"\"\"Test whether fetched items are properly loaded to ES\"\"\"\n        clean = True\n        perceval_backend = None\n        self.ocean_backend = self.connectors[self.connector][1](perceval_backend)\n        elastic_ocean = get_elastic(self.es_con, self.ocean_index, clean, self.ocean_backend, self.ocean_aliases)\n        self.ocean_backend.set_elastic(elastic_ocean)\n        raw_items = data2es(self.items, self.ocean_backend)\n        return {'items': len(self.items), 'raw': raw_items}\n    def _test_raw_to_enrich(self, sortinghat=False, projects=False):\n        \"\"\"Test whether raw indexes are properly enriched\"\"\"\n        # populate raw index\n        perceval_backend = None\n        clean = True\n        self.ocean_backend = self.connectors[self.connector][1](perceval_backend)\n        elastic_ocean = get_elastic(self.es_con, self.ocean_index, clean, self.ocean_backend)\n        self.ocean_backend.set_elastic(elastic_ocean)\n        data2es(self.items, self.ocean_backend)\n        # populate enriched index\n        if not sortinghat and not projects:\n            self.enrich_backend = self.connectors[self.connector][2]()\n        elif sortinghat and not projects:\n            self.enrich_backend = self.connectors[self.connector][2](db_sortinghat=DB_SORTINGHAT,\n                                                                     db_user=self.db_user,\n                                                                     db_password=self.db_password)\n        elif not sortinghat and projects:\n            self.enrich_backend = self.connectors[self.connector][2](json_projects_map=FILE_PROJECTS,\n                                                                     db_user=self.db_user,\n                                                                     db_password=self.db_password)\n        elastic_enrich = get_elastic(self.es_con, self.enrich_index, clean, self.enrich_backend, self.enrich_aliases)\n        self.enrich_backend.set_elastic(elastic_enrich)\n        # Load SH identities\n        if sortinghat:\n            load_identities(self.ocean_backend, self.enrich_backend)\n        raw_count = len([item for item in self.ocean_backend.fetch()])\n        enrich_count = self.enrich_backend.enrich_items(self.ocean_backend)\n        # self._test_csv_mappings(sortinghat)\n        return {'raw': raw_count, 'enrich': enrich_count}\n    def _test_csv_mappings(self, sortinghat):\n        \"\"\"Test whether the mappings in the CSV are successfully met\"\"\"\n        result = {}\n        if not sortinghat:\n            return result\n        csv_mapping = load_mapping(self.enrich_index, self.connector)\n        client = Elasticsearch(self.es_con, timeout=30)\n        mapping_json = client.indices.get_mapping(index=self.enrich_index)\n", "outputs": ["        es_mapping = ESMapping.from_json(index_name=self.enrich_index,"], "input_length": 1077, "output_length": 6, "length": 1083, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "58963e52d347298800672150632e233be2badd8af88e1e895fc01fde697063ef"}
{"input": "", "context": "# This file is part of xmpp-backends (https://github.com/mathiasertl/xmpp-backends).\n#\n# xmpp-backends is free software: you can redistribute it and/or modify it under the terms of the GNU General\n# Public License as published by the Free Software Foundation, either version 3 of the License, or (at your\n# option) any later version.\n#\n# xmpp-backends is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the\n# implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n# for more details.\n#\n# You should have received a copy of the GNU General Public License along with xmpp-backends.  If not, see\n# <http://www.gnu.org/licenses/>.\nimport ipaddress\nimport logging\nimport time\nfrom datetime import datetime\nimport pytz\nfrom .base import BackendError\nfrom .base import UserExists\nfrom .base import UserNotFound\nfrom .base import UserSession\nfrom .base import XmppBackendBase\nfrom .constants import CONNECTION_XMPP\nlog = logging.getLogger(__name__)\nclass DummyBackend(XmppBackendBase):\n    \"\"\"A dummy backend for development using Djangos caching framework.\n    By default, Djangos caching framework uses in-memory data structures, so every registration will be\n    removed if you restart the development server.  You can configure a different cache (e.g. memcached), see\n    `Django's cache framework <https://docs.djangoproject.com/en/dev/topics/cache/>`_ for details.\n    :params domains: A list of domains to serve.\n    \"\"\"\n    library = 'django.core.cache.cache'\n    def __init__(self, domains):\n        super(DummyBackend, self).__init__()\n        self._domains = domains\n    def get_api_version(self):\n        return (1, 0)\n    def user_exists(self, username, domain):\n        if domain not in self._domains:\n            return False\n        user = '%s@%s' % (username, domain)\n        return self.module.get(user) is not None\n    def user_sessions(self, username, domain):\n        user = '%s@%s' % (username, domain)\n        return self.module.get(user, {}).get('sessions', set())\n    def start_user_session(self, username, domain, resource, **kwargs):\n        \"\"\"Method to add a user session for debugging.\n        Accepted parameters are the same as to the constructor of :py:class:`~xmpp_backends.base.UserSession`.\n        \"\"\"\n        kwargs.setdefault('uptime', pytz.utc.localize(datetime.utcnow()))\n        kwargs.setdefault('priority', 0)\n        kwargs.setdefault('status', 'online')\n        kwargs.setdefault('status_text', '')\n        kwargs.setdefault('connection_type', CONNECTION_XMPP)\n        kwargs.setdefault('encrypted', True)\n        kwargs.setdefault('compressed', False)\n        kwargs.setdefault('ip_address', '127.0.0.1')\n        if isinstance(kwargs['ip_address'], str):\n            kwargs['ip_address'] = ipaddress.ip_address(kwargs['ip_address'])\n        user = '%s@%s' % (username, domain)\n        session = UserSession(self, username, domain, resource, **kwargs)\n        data = self.module.get(user)\n        if data is None:\n            raise UserNotFound(username, domain, resource)\n        data.setdefault('sessions', set())\n        if isinstance(data['sessions'], list):\n            # Cast old data to set\n            data['sessions'] = set(data['sessions'])\n        data['sessions'].add(session)\n        self.module.set(user, data)\n        all_sessions = self.module.get('all_sessions', set())\n        all_sessions.add(session)\n        self.module.set('all_sessions', all_sessions)\n    def stop_user_session(self, username, domain, resource, reason=''):\n        user = '%s@%s' % (username, domain)\n        data = self.module.get(user)\n        if data is None:\n            raise UserNotFound(username, domain)\n        data['sessions'] = set([d for d in data.get('sessions', []) if d.resource != resource])\n        self.module.set(user, data)\n        all_sessions = self.module.get('all_sessions', set())\n        all_sessions = set([s for s in all_sessions if s.jid != user])\n        self.module.set('all_sessions', all_sessions)\n    def create_user(self, username, domain, password, email=None):\n        if domain not in self._domains:\n            raise BackendError('Backend does not serve domain %s.' % domain)\n        user = '%s@%s' % (username, domain)\n        log.debug('Create user: %s (%s)', user, password)\n        data = self.module.get(user)\n        if data is None:\n            data = {\n                'pass': password,\n                'last_status': (time.time(), 'Registered'),\n                'sessions': set(),\n            }\n            if email is not None:\n                data['email'] = email\n            self.module.set(user, data)\n            # maintain list of users in cache\n            users = self.module.get('all_users', set())\n            users.add(user)\n            self.module.set('all_users', users)\n        else:\n            raise UserExists()\n    def check_password(self, username, domain, password):\n        user = '%s@%s' % (username, domain)\n        log.debug('Check pass: %s -> %s', user, password)\n        data = self.module.get(user)\n        if data is None:\n            return False\n        else:\n            return data['pass'] == password\n    def check_email(self, username, domain, email):\n        user = '%s@%s' % (username, domain)\n        log.debug('Check email: %s --> %s', user, email)\n        data = self.module.get(user)\n        if data is None:\n            return False\n        else:\n            return data['email'] == email\n    def set_password(self, username, domain, password):\n        user = '%s@%s' % (username, domain)\n        log.debug('Set pass: %s -> %s', user, password)\n        data = self.module.get(user)\n        if data is None:\n            raise UserNotFound(username, domain)\n        else:\n            data['pass'] = password\n            self.module.set(user, data)\n    def set_email(self, username, domain, email):\n        user = '%s@%s' % (username, domain)\n        log.debug('Set email: %s --> %s', user, email)\n        data = self.module.get(user)\n        if data is None:\n            raise UserNotFound(username, domain)\n        else:\n            data['email'] = email\n            self.module.set(user, data)\n    def get_last_activity(self, username, domain):\n        user = '%s@%s' % (username, domain)\n        data = self.module.get(user)\n        if data is None:\n            raise UserNotFound(username, domain)\n        else:\n            return datetime.utcfromtimestamp(data['last_status'][0])\n    def set_last_activity(self, username, domain, status='', timestamp=None):\n        user = '%s@%s' % (username, domain)\n        if timestamp is None:\n            timestamp = time.time()\n        else:\n            timestamp = self.datetime_to_timestamp(timestamp)\n        data = self.module.get(user)\n        if data is None:\n            pass  # NOTE: real APIs provide no error either :-/\n        else:\n            data['last_status'] = (timestamp, status)\n            self.module.set(user, data)\n    def block_user(self, username, domain):\n        # overwritten so we pass tests\n        self.set_password(username, domain, self.get_random_password())\n    def all_domains(self):\n        \"\"\"Just returns the domains passed to the constructor.\"\"\"\n        return list(self._domains)\n    def all_users(self, domain):\n        return set([u.split('@')[0] for u in self.module.get('all_users', set())\n                    if u.endswith('@%s' % domain)])\n    def all_user_sessions(self):\n        return self.module.get('all_sessions', set())\n    def remove_user(self, username, domain):\n", "outputs": ["        user = '%s@%s' % (username, domain)"], "input_length": 1485, "output_length": 15, "length": 1500, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "853b3b5da18d1dbf7e90b91efb1d1caa78d3d39e4420bb9b93679cef5d4719c8"}
{"input": "", "context": "package org.netlib.lapack;\nimport org.netlib.blas.Dcopy;\nimport org.netlib.err.Xerbla;\nimport org.netlib.util.doubleW;\nimport org.netlib.util.intW;\npublic final class Dlasda\n{\n  public static void dlasda(int paramInt1, int paramInt2, int paramInt3, int paramInt4, double[] paramArrayOfDouble1, int paramInt5, double[] paramArrayOfDouble2, int paramInt6, double[] paramArrayOfDouble3, int paramInt7, int paramInt8, double[] paramArrayOfDouble4, int paramInt9, int[] paramArrayOfInt1, int paramInt10, double[] paramArrayOfDouble5, int paramInt11, double[] paramArrayOfDouble6, int paramInt12, double[] paramArrayOfDouble7, int paramInt13, double[] paramArrayOfDouble8, int paramInt14, int[] paramArrayOfInt2, int paramInt15, int[] paramArrayOfInt3, int paramInt16, int paramInt17, int[] paramArrayOfInt4, int paramInt18, double[] paramArrayOfDouble9, int paramInt19, double[] paramArrayOfDouble10, int paramInt20, double[] paramArrayOfDouble11, int paramInt21, double[] paramArrayOfDouble12, int paramInt22, int[] paramArrayOfInt5, int paramInt23, intW paramintW)\n  {\n    int i = 0;\n    int j = 0;\n    int k = 0;\n    int m = 0;\n    int n = 0;\n    int i1 = 0;\n    int i2 = 0;\n    int i3 = 0;\n    int i4 = 0;\n    int i5 = 0;\n    int i6 = 0;\n    int i7 = 0;\n    int i8 = 0;\n    int i9 = 0;\n    int i10 = 0;\n    int i11 = 0;\n    intW localintW1 = new intW(0);\n    int i12 = 0;\n    int i13 = 0;\n    int i14 = 0;\n    int i15 = 0;\n    int i16 = 0;\n    int i17 = 0;\n    intW localintW2 = new intW(0);\n    int i18 = 0;\n    int i19 = 0;\n    int i20 = 0;\n    int i21 = 0;\n    int i22 = 0;\n    int i23 = 0;\n    int i24 = 0;\n    int i25 = 0;\n    int i26 = 0;\n    int i27 = 0;\n    int i28 = 0;\n    int i29 = 0;\n    doubleW localdoubleW1 = new doubleW(0.0D);\n    doubleW localdoubleW2 = new doubleW(0.0D);\n    paramintW.val = 0;\n    if ((paramInt1 >= 0 ? 0 : 1) == 0) {}\n    if (((paramInt1 <= 1 ? 0 : 1) == 0 ? 0 : 1) != 0)\n    {\n      paramintW.val = -1;\n    }\n    else if ((paramInt2 >= 3 ? 0 : 1) != 0)\n    {\n      paramintW.val = -2;\n    }\n    else if ((paramInt3 >= 0 ? 0 : 1) != 0)\n    {\n      paramintW.val = -3;\n    }\n    else\n    {\n      if ((paramInt4 >= 0 ? 0 : 1) == 0) {}\n      if (((paramInt4 <= 1 ? 0 : 1) == 0 ? 0 : 1) != 0) {\n        paramintW.val = -4;\n      } else if ((paramInt8 >= paramInt3 + paramInt4 ? 0 : 1) != 0) {\n        paramintW.val = -8;\n      } else if ((paramInt17 >= paramInt3 ? 0 : 1) != 0) {\n        paramintW.val = -17;\n      }\n    }\n    if ((paramintW.val == 0 ? 0 : 1) != 0)\n    {\n      Xerbla.xerbla(\"DLASDA\", -paramintW.val);\n      return;\n    }\n    i10 = paramInt3 + paramInt4;\n    if ((paramInt3 > paramInt2 ? 0 : 1) != 0)\n    {\n      if ((paramInt1 != 0 ? 0 : 1) != 0) {\n        Dlasdq.dlasdq(\"U\", paramInt4, paramInt3, 0, 0, 0, paramArrayOfDouble1, paramInt5, paramArrayOfDouble2, paramInt6, paramArrayOfDouble4, paramInt9, paramInt8, paramArrayOfDouble3, paramInt7, paramInt8, paramArrayOfDouble3, paramInt7, paramInt8, paramArrayOfDouble12, paramInt22, paramintW);\n      } else {\n        Dlasdq.dlasdq(\"U\", paramInt4, paramInt3, i10, paramInt3, 0, paramArrayOfDouble1, paramInt5, paramArrayOfDouble2, paramInt6, paramArrayOfDouble4, paramInt9, paramInt8, paramArrayOfDouble3, paramInt7, paramInt8, paramArrayOfDouble3, paramInt7, paramInt8, paramArrayOfDouble12, paramInt22, paramintW);\n      }\n      return;\n    }\n    i2 = 1;\n    i13 = i2 + paramInt3;\n    i14 = i13 + paramInt3;\n    m = i14 + paramInt3;\n    i4 = m + paramInt3;\n    i11 = 0;\n    i21 = 0;\n    i24 = paramInt2 + 1;\n    i26 = 1;\n    i28 = i26 + i10;\n    i22 = i28 + i10;\n    i23 = i22 + i24 * i24;\n    Dlasdt.dlasdt(paramInt3, localintW2, localintW1, paramArrayOfInt5, i2 - 1 + paramInt23, paramArrayOfInt5, i13 - 1 + paramInt23, paramArrayOfInt5, i14 - 1 + paramInt23, paramInt2);\n    i12 = (localintW1.val + 1) / 2;\n    i = i12;\n    int i31;\n    for (int i30 = localintW1.val - i12 + 1; i30 > 0; i30--)\n    {\n      j = i - 1;\n      k = paramArrayOfInt5[(i2 + j - 1 + paramInt23)];\n      i15 = paramArrayOfInt5[(i13 + j - 1 + paramInt23)];\n      i17 = i15 + 1;\n      i18 = paramArrayOfInt5[(i14 + j - 1 + paramInt23)];\n      i16 = k - i15;\n      i19 = k + 1;\n      n = m + i16 - 2;\n      i27 = i26 + i16 - 1;\n      i29 = i28 + i16 - 1;\n      i25 = 1;\n      if ((paramInt1 != 0 ? 0 : 1) != 0)\n      {\n        Dlaset.dlaset(\"A\", i17, i17, 0.0D, 1.0D, paramArrayOfDouble12, i22 - 1 + paramInt22, i24);\n        Dlasdq.dlasdq(\"U\", i25, i15, i17, i21, i11, paramArrayOfDouble1, i16 - 1 + paramInt5, paramArrayOfDouble2, i16 - 1 + paramInt6, paramArrayOfDouble12, i22 - 1 + paramInt22, i24, paramArrayOfDouble12, i23 - 1 + paramInt22, i15, paramArrayOfDouble12, i23 - 1 + paramInt22, i15, paramArrayOfDouble12, i23 - 1 + paramInt22, paramintW);\n        i3 = i22 + i15 * i24;\n        Dcopy.dcopy(i17, paramArrayOfDouble12, i22 - 1 + paramInt22, 1, paramArrayOfDouble12, i27 - 1 + paramInt22, 1);\n        Dcopy.dcopy(i17, paramArrayOfDouble12, i3 - 1 + paramInt22, 1, paramArrayOfDouble12, i29 - 1 + paramInt22, 1);\n      }\n      else\n      {\n        Dlaset.dlaset(\"A\", i15, i15, 0.0D, 1.0D, paramArrayOfDouble3, i16 - 1 + (1 - 1) * paramInt8 + paramInt7, paramInt8);\n        Dlaset.dlaset(\"A\", i17, i17, 0.0D, 1.0D, paramArrayOfDouble4, i16 - 1 + (1 - 1) * paramInt8 + paramInt9, paramInt8);\n        Dlasdq.dlasdq(\"U\", i25, i15, i17, i15, i11, paramArrayOfDouble1, i16 - 1 + paramInt5, paramArrayOfDouble2, i16 - 1 + paramInt6, paramArrayOfDouble4, i16 - 1 + (1 - 1) * paramInt8 + paramInt9, paramInt8, paramArrayOfDouble3, i16 - 1 + (1 - 1) * paramInt8 + paramInt7, paramInt8, paramArrayOfDouble3, i16 - 1 + (1 - 1) * paramInt8 + paramInt7, paramInt8, paramArrayOfDouble12, i22 - 1 + paramInt22, paramintW);\n        Dcopy.dcopy(i17, paramArrayOfDouble4, i16 - 1 + (1 - 1) * paramInt8 + paramInt9, 1, paramArrayOfDouble12, i27 - 1 + paramInt22, 1);\n        Dcopy.dcopy(i17, paramArrayOfDouble4, i16 - 1 + (i17 - 1) * paramInt8 + paramInt9, 1, paramArrayOfDouble12, i29 - 1 + paramInt22, 1);\n      }\n      if ((paramintW.val == 0 ? 0 : 1) != 0) {\n        return;\n      }\n      i5 = 1;\n      for (i31 = i15 - 1 + 1; i31 > 0; i31--)\n      {\n        paramArrayOfInt5[(n + i5 - 1 + paramInt23)] = i5;\n        i5 += 1;\n      }\n      if ((i != localintW1.val ? 0 : 1) != 0) {}\n      if (((paramInt4 != 0 ? 0 : 1) != 0 ? 1 : 0) != 0) {\n        i25 = 0;\n      } else {\n        i25 = 1;\n      }\n      n += i17;\n      i27 += i17;\n      i29 += i17;\n      i20 = i18 + i25;\n      if ((paramInt1 != 0 ? 0 : 1) != 0)\n      {\n        Dlaset.dlaset(\"A\", i20, i20, 0.0D, 1.0D, paramArrayOfDouble12, i22 - 1 + paramInt22, i24);\n        Dlasdq.dlasdq(\"U\", i25, i18, i20, i21, i11, paramArrayOfDouble1, i19 - 1 + paramInt5, paramArrayOfDouble2, i19 - 1 + paramInt6, paramArrayOfDouble12, i22 - 1 + paramInt22, i24, paramArrayOfDouble12, i23 - 1 + paramInt22, i18, paramArrayOfDouble12, i23 - 1 + paramInt22, i18, paramArrayOfDouble12, i23 - 1 + paramInt22, paramintW);\n        i3 = i22 + (i20 - 1) * i24;\n        Dcopy.dcopy(i20, paramArrayOfDouble12, i22 - 1 + paramInt22, 1, paramArrayOfDouble12, i27 - 1 + paramInt22, 1);\n        Dcopy.dcopy(i20, paramArrayOfDouble12, i3 - 1 + paramInt22, 1, paramArrayOfDouble12, i29 - 1 + paramInt22, 1);\n      }\n      else\n      {\n        Dlaset.dlaset(\"A\", i18, i18, 0.0D, 1.0D, paramArrayOfDouble3, i19 - 1 + (1 - 1) * paramInt8 + paramInt7, paramInt8);\n        Dlaset.dlaset(\"A\", i20, i20, 0.0D, 1.0D, paramArrayOfDouble4, i19 - 1 + (1 - 1) * paramInt8 + paramInt9, paramInt8);\n        Dlasdq.dlasdq(\"U\", i25, i18, i20, i18, i11, paramArrayOfDouble1, i19 - 1 + paramInt5, paramArrayOfDouble2, i19 - 1 + paramInt6, paramArrayOfDouble4, i19 - 1 + (1 - 1) * paramInt8 + paramInt9, paramInt8, paramArrayOfDouble3, i19 - 1 + (1 - 1) * paramInt8 + paramInt7, paramInt8, paramArrayOfDouble3, i19 - 1 + (1 - 1) * paramInt8 + paramInt7, paramInt8, paramArrayOfDouble12, i22 - 1 + paramInt22, paramintW);\n        Dcopy.dcopy(i20, paramArrayOfDouble4, i19 - 1 + (1 - 1) * paramInt8 + paramInt9, 1, paramArrayOfDouble12, i27 - 1 + paramInt22, 1);\n        Dcopy.dcopy(i20, paramArrayOfDouble4, i19 - 1 + (i20 - 1) * paramInt8 + paramInt9, 1, paramArrayOfDouble12, i29 - 1 + paramInt22, 1);\n      }\n      if ((paramintW.val == 0 ? 0 : 1) != 0) {\n        return;\n      }\n      i5 = 1;\n      for (i31 = i18 - 1 + 1; i31 > 0; i31--)\n      {\n        paramArrayOfInt5[(n + i5 - 1 + paramInt23)] = i5;\n        i5 += 1;\n      }\n      i += 1;\n    }\n    i5 = (int)Math.pow(2, localintW2.val);\n    i8 = localintW2.val;\n    for (int i30 = (1 - localintW2.val + -1) / -1; i30 > 0; i30--)\n    {\n      i9 = i8 * 2 - 1;\n      if ((i8 != 1 ? 0 : 1) != 0)\n      {\n        i6 = 1;\n        i7 = 1;\n      }\n      else\n      {\n        i6 = (int)Math.pow(2, i8 - 1);\n        i7 = 2 * i6 - 1;\n      }\n      i = i6;\n      for (i31 = i7 - i6 + 1; i31 > 0; i31--)\n      {\n        i1 = i - 1;\n        k = paramArrayOfInt5[(i2 + i1 - 1 + paramInt23)];\n        i15 = paramArrayOfInt5[(i13 + i1 - 1 + paramInt23)];\n        i18 = paramArrayOfInt5[(i14 + i1 - 1 + paramInt23)];\n        i16 = k - i15;\n        i19 = k + 1;\n", "outputs": ["        if ((i != i7 ? 0 : 1) != 0) {"], "input_length": 2190, "output_length": 17, "length": 2207, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "d59b8a0828980ced041382e29e38294bb81b551c58b8abab0a25c572c45e4184"}
{"input": "", "context": "/**\n * Copyright (C) 2001-2020 by RapidMiner and the contributors\n * \n * Complete list of developers available at our web site:\n * \n * http://rapidminer.com\n * \n * This program is free software: you can redistribute it and/or modify it under the terms of the\n * GNU Affero General Public License as published by the Free Software Foundation, either version 3\n * of the License, or (at your option) any later version.\n * \n * This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without\n * even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\n * Affero General Public License for more details.\n * \n * You should have received a copy of the GNU Affero General Public License along with this program.\n * If not, see http://www.gnu.org/licenses/.\n*/\npackage com.rapidminer.operator.learner.rules;\nimport java.util.Arrays;\nimport java.util.Collection;\nimport java.util.Iterator;\nimport java.util.List;\nimport java.util.Vector;\nimport com.rapidminer.example.Attribute;\nimport com.rapidminer.example.Example;\nimport com.rapidminer.example.ExampleSet;\nimport com.rapidminer.operator.Model;\nimport com.rapidminer.operator.OperatorCapability;\nimport com.rapidminer.operator.OperatorDescription;\nimport com.rapidminer.operator.OperatorException;\nimport com.rapidminer.operator.learner.AbstractLearner;\nimport com.rapidminer.operator.learner.PredictionModel;\nimport com.rapidminer.parameter.ParameterType;\nimport com.rapidminer.parameter.ParameterTypeBoolean;\nimport com.rapidminer.parameter.ParameterTypeCategory;\nimport com.rapidminer.parameter.ParameterTypeInt;\nimport com.rapidminer.parameter.UndefinedParameterError;\n/**\n * This operator returns the best rule regarding WRAcc using exhaustive search. Features like the\n * incorporation of other metrics and the search for more than a single rule are prepared.\n *\n * The search strategy is BFS, with save pruning whenever applicable. This operator can easily be\n * extended to support other search strategies.\n *\n * @author Martin Scholz\n */\npublic class BestRuleInduction extends AbstractLearner {\n\t/** Helper class containing a rule and an upper bound for the score. */\n\tpublic static class RuleWithScoreUpperBound implements Comparable<Object> {\n\t\tprivate final ConjunctiveRuleModel rule;\n\t\tprivate final double scoreUpperBound;\n\t\tpublic RuleWithScoreUpperBound(ConjunctiveRuleModel rule, double scoreUpperBound) {\n\t\t\tthis.rule = rule;\n\t\t\tthis.scoreUpperBound = scoreUpperBound;\n\t\t}\n\t\tpublic ConjunctiveRuleModel getRule() {\n\t\t\treturn this.rule;\n\t\t}\n\t\tpublic double getScoreBound() {\n\t\t\treturn this.scoreUpperBound;\n\t\t}\n\t\t@Override\n\t\tpublic int compareTo(Object obj) {\n\t\t\tif (obj instanceof RuleWithScoreUpperBound) {\n\t\t\t\tdouble otherScore = ((RuleWithScoreUpperBound) obj).getScoreBound();\n\t\t\t\tif (this.getScoreBound() < otherScore) {\n\t\t\t\t\treturn -1;\n\t\t\t\t} else if (this.getScoreBound() > otherScore) {\n\t\t\t\t\treturn 1;\n\t\t\t\t} else {\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn this.getClass().getName().compareTo(obj.getClass().getName());\n\t\t\t}\n\t\t}\n\t\t@Override\n\t\tpublic boolean equals(Object o) {\n\t\t\tif (!(o instanceof RuleWithScoreUpperBound)) {\n\t\t\t\treturn false;\n\t\t\t} else {\n\t\t\t\treturn this.rule.equals(((RuleWithScoreUpperBound) o).rule);\n\t\t\t}\n\t\t}\n\t\t@Override\n\t\tpublic int hashCode() {\n\t\t\treturn this.rule.hashCode();\n\t\t}\n\t}\n\tprivate static final String PARAMETER_MAX_DEPTH = \"max_depth\";\n\tprivate static final String PARAMETER_UTILITY_FUNCTION = \"utility_function\";\n\tprivate static final String PARAMETER_MAX_CACHE = \"max_cache\";\n\tprivate static final String PARAMETER_RELATIVE_TO_PREDICTIONS = \"relative_to_predictions\";\n\tprivate static final String WRACC = \"weighted relative accuracy\";\n\tprivate static final String BINOMIAL = \"binomial test function\";\n\tprivate static final String[] UTILITY_FUNCTION_LIST = new String[] { WRACC, BINOMIAL };\n\tprivate double globalP;\n\tprivate double globalN;\n\tprotected ConjunctiveRuleModel bestRule;\n\tprivate double bestScore;\n\tprivate int maxDepth;\n\t// nodes under consideration\n\tprivate final Vector<RuleWithScoreUpperBound> openNodes = new Vector<RuleWithScoreUpperBound>();\n\t// keep track of rules that have been pruned, to avoid\n\t// evaluations for any kind of refinements\n\tprivate final Vector<ConjunctiveRuleModel> prunedNodes = new Vector<ConjunctiveRuleModel>();\n\tpublic BestRuleInduction(OperatorDescription description) {\n\t\tsuper(description);\n\t}\n\t@Override\n\tpublic boolean supportsCapability(OperatorCapability lc) {\n\t\tif (lc == com.rapidminer.operator.OperatorCapability.POLYNOMINAL_ATTRIBUTES) {\n\t\t\treturn true;\n\t\t}\n\t\tif (lc == com.rapidminer.operator.OperatorCapability.BINOMINAL_ATTRIBUTES) {\n\t\t\treturn true;\n\t\t}\n\t\tif (lc == com.rapidminer.operator.OperatorCapability.BINOMINAL_LABEL) {\n\t\t\treturn true;\n\t\t}\n\t\tif (lc == com.rapidminer.operator.OperatorCapability.WEIGHTED_EXAMPLES) {\n\t\t\treturn true;\n\t\t}\n\t\treturn false;\n\t}\n\tprotected void initHighscore() {\n\t\tthis.bestRule = null;\n\t\tthis.bestScore = Double.NEGATIVE_INFINITY;\n\t}\n\t/**\n\t * Adds a rule to the set of best rules if its score is high enough. Currently just a single\n\t * rule is stored. Additionally it is checked whether the rule is bad enough to be pruned.\n\t *\n\t * @return true iff the rule can be pruned\n\t */\n\tprotected boolean communicateToHighscore(ConjunctiveRuleModel rule, double[] counts) throws UndefinedParameterError {\n\t\tdouble optimisticScore = this.getOptimisticScore(counts);\n\t\tif (optimisticScore <= this.getPruningScore()) {\n\t\t\treturn true; // indicates pruning\n\t\t} else {\n\t\t\tdouble posScore = this.getScore(counts, true);\n\t\t\tdouble negScore = this.getScore(counts, false);\n\t\t\tif (posScore > this.bestScore) {\n\t\t\t\tthis.bestRule = rule;\n\t\t\t\tthis.bestScore = posScore;\n\t\t\t}\n\t\t\tif (negScore > this.bestScore) {\n\t\t\t\tConjunctiveRuleModel negRule = new ConjunctiveRuleModel(rule,\n\t\t\t\t\t\trule.getLabel().getMapping().getNegativeIndex());\n\t\t\t\tthis.bestRule = negRule;\n\t\t\t\tthis.bestScore = negScore;\n\t\t\t}\n\t\t\treturn false; // no pruning\n\t\t}\n\t}\n\t/** @return the best rule found */\n\tprotected ConjunctiveRuleModel getBestRule() {\n\t\treturn this.bestRule;\n\t}\n\t/** @return the lowest score of the stored best rules for pruning */\n\tprotected double getPruningScore() {\n\t\treturn this.bestScore;\n\t}\n\t@Override\n\tpublic Model learn(ExampleSet exampleSet) throws OperatorException {\n\t\tthis.initHighscore();\n\t\tint positiveLabel = exampleSet.getAttributes().getLabel().getMapping().getPositiveIndex();\n\t\t// int negativeLabel = exampleSet.getLabel().getNegativeIndex();\n\t\tConjunctiveRuleModel defaultRule = new ConjunctiveRuleModel(exampleSet, positiveLabel);\n\t\t// ConjunctiveRuleModel negRule = new\n\t\t// ConjunctiveRuleModel(exampleSet.getLabel(), negativeLabel);\n\t\tdouble[] globalCounts = this.getCounts(defaultRule, exampleSet);\n\t\tthis.globalP = globalCounts[0];\n\t\tthis.globalN = globalCounts[1];\n\t\tthis.communicateToHighscore(defaultRule, globalCounts);\n\t\tdouble optimisticScore = this.getOptimisticScore(globalCounts);\n\t\tthis.openNodes.clear();\n\t\tthis.prunedNodes.clear();\n\t\tthis.addRulesToOpenNodes(defaultRule.getAllRefinedRules(exampleSet), optimisticScore);\n\t\tint length = 1;\n\t\tmaxDepth = this.getParameterAsInt(PARAMETER_MAX_DEPTH);\n\t\tint maxCache = this.getParameterAsInt(PARAMETER_MAX_CACHE);\n\t\twhile (!this.openNodes.isEmpty() && length <= maxDepth) {\n\t\t\tint ignored = 0;\n\t\t\tlog(\"Evaluating \" + this.openNodes.size() + \" rules of length \" + length);\n\t\t\tif (this.openNodes.size() > maxCache) {\n\t\t\t\tlog(\"Ignoring all but the \" + maxCache + \" rules with highest support.\");\n\t\t\t}\n\t\t\tRuleWithScoreUpperBound[] ruleArray = new RuleWithScoreUpperBound[this.openNodes.size()];\n\t\t\tthis.openNodes.toArray(ruleArray);\n\t\t\tArrays.sort(ruleArray);\n\t\t\tint stopAtIndex = Math.max(0, ruleArray.length - maxCache);\n\t\t\tthis.openNodes.clear();\n\t\t\tfor (int i = ruleArray.length - 1; i >= stopAtIndex; i--) {\n\t\t\t\tRuleWithScoreUpperBound rulePlusScore = ruleArray[i];\n\t\t\t\tConjunctiveRuleModel rule = rulePlusScore.getRule();\n\t\t\t\tif (this.isRefinementOfPrunedRule(rule)) {\n\t\t\t\t\tignored++;\n\t\t\t\t} else if (rulePlusScore.getScoreBound() <= this.getPruningScore()) {\n\t\t\t\t\tignored++;\n\t\t\t\t\t// This pruning could not be derived from prunedNodes and\n\t\t\t\t\t// may be useful\n\t\t\t\t\t// later on for refined rules with a less precise optimistic\n\t\t\t\t\t// estimate.\n\t\t\t\t\tthis.prunedNodes.add(rulePlusScore.getRule());\n\t\t\t\t} else {\n\t\t\t\t\tthis.expandNode(rule, exampleSet);\n\t\t\t\t}\n\t\t\t\tcheckForStop();\n\t\t\t}\n\t\t\tlog(\"Could ignore \" + ignored + \" rules as refinements of pruned rules or by optimistic estimates.\");\n\t\t\tlog(\"Number of pruned rules in cache: \" + this.prunedNodes.size());\n\t\t\tlog(\"Best rule is \" + this.getBestRule().toString());\n\t\t\tlog(\"Score is \" + this.getPruningScore());\n\t\t\tlength++;\n\t\t}\n\t\tthis.openNodes.clear();\n\t\tthis.prunedNodes.clear();\n\t\treturn this.getBestRule();\n\t}\n\t/**\n\t * Annotates the collection of ConjunctiveRuleModels with an optimistic score they may achieve\n\t * in the best case and adds them to the collection of open nodes.\n\t */\n\tprivate void addRulesToOpenNodes(Collection<ConjunctiveRuleModel> rules, double scoreUpperBound) {\n\t\tif (scoreUpperBound <= this.getPruningScore()) {\n\t\t\treturn;\n\t\t}\n\t\tfor (ConjunctiveRuleModel rule : rules) {\n\t\t\tthis.openNodes.add(new RuleWithScoreUpperBound(rule, scoreUpperBound));\n\t\t}\n\t}\n\t/**\n\t * Evaluates a single rule by computing its score, and the best possible score after refining\n\t * this rule. If this cannot improve over the currently best rules, then the refinements are\n\t * pruned. Otherwise all refinements plus optimistic estimates are added to the collection of\n\t * open nodes.\n\t *\n\t * If the evaluated rule is good enough, then it is stored toghether with its score.\n\t */\n\tprivate void expandNode(ConjunctiveRuleModel rule, ExampleSet exampleSet) throws OperatorException {\n\t\t// Compute counts:\n\t\tdouble[] counts = this.getCounts(rule, exampleSet);\n\t\t// Store in highscore if necessary and check whether it may be pruned.\n\t\tboolean pruning = this.communicateToHighscore(rule, counts);\n\t\tif (pruning == true) {\n\t\t\tthis.prunedNodes.add(rule);\n\t\t\t// Nothing to add to the collection of open nodes ..\n\t\t} else if (rule.getRuleLength() < maxDepth) {\n\t\t\t// Store all the refinements for later investigation:\n\t\t\tthis.addRulesToOpenNodes(rule.getAllRefinedRules(exampleSet), this.getOptimisticScore(counts));\n\t\t}\n\t}\n\t/**\n\t * @param rule\n\t *            a ConjuctiveRuleModel for which it is checked whether a more general rule has\n\t *            already been pruned.\n\t * @return true, if this rule is a refinement of a pruned rule. The rules are compared using the\n\t *         method <code>ConjunctiveRuleModel.isRefinementOf(ConjunctiveRuleModel model)</code>\n\t */\n\tpublic boolean isRefinementOfPrunedRule(ConjunctiveRuleModel rule) {\n\t\tfor (ConjunctiveRuleModel prunedRule : prunedNodes) {\n\t\t\t// In this collection all rules predict positive, but the scores are\n\t\t\t// computed for the best label. For this reason the following\n\t\t\t// refinement test is valid.\n\t\t\tif (rule.isRefinementOf(prunedRule)) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}\n\t/**\n\t * Computes the WRAcc or BINOMIAL TEST FUNCTION based on p, n, and the global values P and N\n\t * stored in this object. First two entries of counts are p and n, optionally estimates for p\n\t * and n can be supplied as further parameters.\n\t */\n\tprotected double getScore(double[] counts, boolean predictPositives) throws UndefinedParameterError {\n\t\tdouble p = counts[0];\n\t\tdouble n = counts[1];\n\t\tdouble cov = (p + n) / (globalP + globalN);\n\t\tdouble pnRel = predictPositives ? p : n;\n\t\tString function = UTILITY_FUNCTION_LIST[this.getParameterAsInt(PARAMETER_UTILITY_FUNCTION)];\n\t\tUndefinedParameterError upe = new UndefinedParameterError(PARAMETER_UTILITY_FUNCTION, this);\n\t\tdouble score;\n\t\tif (this.getParameterAsBoolean(PARAMETER_RELATIVE_TO_PREDICTIONS) == false || counts.length != 4) {\n\t\t\tdouble pnAbs = predictPositives ? globalP : globalN;\n\t\t\tif (function.equals(WRACC)) {\n\t\t\t\tscore = cov * (pnRel / (p + n) - pnAbs / (globalP + globalN));\n\t\t\t} else if (function.equals(BINOMIAL)) {\n\t\t\t\tscore = Math.sqrt(cov) * (pnRel / (p + n) - pnAbs / (globalP + globalN));\n\t\t\t} else {\n\t\t\t\tthrow upe;\n\t\t\t}\n\t\t} else {\n\t\t\tdouble estP = counts[2];\n\t\t\tdouble estN = counts[3];\n\t\t\tdouble pnEst = predictPositives ? estP : estN;\n\t\t\tif (function.equals(WRACC)) {\n\t\t\t\tscore = cov * (pnRel / (p + n) - pnEst / (estP + estN));\n\t\t\t} else if (function.equals(BINOMIAL)) {\n\t\t\t\tscore = Math.sqrt(cov) * (pnRel / (p + n) - pnEst / (estP + estN));\n\t\t\t} else {\n\t\t\t\tthrow upe;\n\t\t\t}\n\t\t}\n\t\treturn score;\n\t}\n\t/**\n\t * Computes the best possible score that might be achieved by refining the rule. During learning\n\t * the conclusion is normalized to \"positive\", so the better of the estimates of the better\n\t * conclusion is returned.\n\t */\n\tprotected double getOptimisticScore(double[] counts) throws UndefinedParameterError {\n\t\tdouble p = counts[0];\n\t\tdouble n = counts[1];\n\t\tif (this.getParameterAsBoolean(PARAMETER_RELATIVE_TO_PREDICTIONS) == false || counts.length != 4) {\n\t\t\t// For reasonable utility functions adding just negatives decreases\n\t\t\t// the score.\n\t\t\treturn Math.max(this.getScore(new double[] { p, 0 }, true), this.getScore(new double[] { 0, n }, false));\n\t\t} else {\n\t\t\t// Improvement for positive rules: discard all negatives, which are\n\t\t\t// at the same time considered to be positives with confidence of 1\n\t\t\t// by the given prediction. As a complex second step discarding\n\t\t\t// further\n\t\t\t// positives might help to improve the score, since this allows to\n\t\t\t// lower the estimated precision term.\n\t\t\t// To keep things simple a non-tight optimistic score is computed:\n\t\t\t// 1. Keep all positives, discard all negatives: p'=p, n'=0\n\t\t\t// 2. Lower the estimated confidence to 0, simply estP' = 0, estN' =\n\t\t\t// 0.\n\t\t\t// Analogously for the negatively predicting rule.\n\t\t\tdouble estP = counts[2];\n", "outputs": ["\t\t\tdouble estN = counts[3];"], "input_length": 2431, "output_length": 8, "length": 2439, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "aaa4db380c2fcbec84728c3940bd4e25d8159faba3dbf923415816e28b69fe25"}
{"input": "", "context": "# (C) 2009 Frank-Rene Schaefer\n\"\"\"\nABSTRACT:\n    !! UTF16 state split is similar to UTF8 state split as shown in file !!\n    !! \"uf8_state_split.py\". Please, read the documentation there about  !!\n    !! the details of the basic idea.                                    !!\n    Due to the fact that utf16 conversion has only two possible byte sequence\n    lengths, 2 and 4 bytes, the state split process is significantly easier\n    than the utf8 state split.\n    The principle idea remains: A single transition from state A to state B is\n    translated (sometimes) into an intermediate state transition to reflect\n    that the unicode point is represent by a value sequence.\n    The special case utf16 again is easier, since, for any unicode point <=\n    0xFFFF the representation value remains exactly the same, thus those\n    intervals do not have to be adapted at all!\n    \n    Further, the identification of 'contigous' intervals where the last value\n    runs repeatedly from min to max is restricted to the consideration of a\n    single word. UTF16 character codes can contain at max two values (a\n    'surrogate pair') coded in two 'words' (1 word = 2 bytes). The overun\n    happens every 2*10 code points.  Since such intervals are pretty large and\n    the probability that a range runs over multiple such ranges is low, it does\n    not make sense to try to combine them. The later Hopcroft Minimization will\n    not be overwhelmed by a little extra work.\n\"\"\"\nimport os\nimport sys\nsys.path.append(os.environ[\"QUEX_PATH\"])\nfrom   quex.engine.utf16                    import utf16_to_unicode, unicode_to_utf16\nfrom   quex.engine.interval_handling        import Interval, NumberSet\nimport quex.engine.state_machine.algorithm.beautifier as beautifier\nForbiddenRange = Interval(0xD800, 0xE000)\ndef do(sm):\n    global ForbiddenRange\n    state_list = sm.states.items()\n    for state_index, state in state_list:\n        # Get the 'transition_list', i.e. a list of pairs (TargetState, NumberSet)\n        # which indicates what target state is reached via what number set.\n        transition_list = state.target_map.get_map().items()\n        # Clear the state's transitions, now. This way it can absorb new\n        # transitions to intermediate states.\n        state.target_map.clear()\n        # Loop over all transitions\n        for target_state_index, number_set in transition_list:\n            # -- 1st check whether a modification is necessary\n            if number_set.supremum() <= 0x10000:\n                sm.states[state_index].add_transition(number_set, target_state_index)\n                continue\n            # -- We help: General regular expressions may not bother with \n            #    the 'ForbiddenRange'. Let us be so kind and cut it here.\n            number_set.subtract(ForbiddenRange)\n            number_set.cut_lesser(0)\n            number_set.cut_greater_or_equal(0x110000)\n            # -- Add intermediate States\n            #    We take the intervals with 'PromiseToTreatWellF' even though they\n            #    are changed. This is because the intervals would be lost anyway\n            #    after the state split, so we use the same memory and do not \n            #    cause a time consuming memory copy and constructor calls.\n            interval_list = number_set.get_intervals(PromiseToTreatWellF=True)\n            for interval in interval_list:\n                create_intermediate_states(sm, state_index, target_state_index, interval)\n    \n    result = beautifier.do(sm)\n    return result\ndef do_set(NSet):\n    \"\"\"Unicode values > 0xFFFF are translated into byte sequences, thus, only number\n       sets below that value can be transformed into number sets. They, actually\n       remain the same.\n    \"\"\"\n    for interval in NSet.get_intervals(PromiseToTreatWellF=True):\n        if interval.end > 0x10000: return None\n    return NSet\ndef homogeneous_chunk_n_per_character(CharacterSet):\n    \"\"\"If all characters in a unicode character set state machine require the\n    same number of bytes to be represented this number is returned.  Otherwise,\n    'None' is returned.\n    RETURNS:   N > 0  number of bytes required to represent any character in the \n                      given state machine.\n               None   characters in the state machine require different numbers of\n                      bytes.\n    \"\"\"\n    assert isinstance(CharacterSet, NumberSet)\n    interval_list = CharacterSet.get_intervals(PromiseToTreatWellF=True)\n    front = interval_list[0].begin     # First element of number set\n    back  = interval_list[-1].end - 1  # Last element of number set\n    # Determine number of bytes required to represent the first and the \n    # last character of the number set. The number of bytes per character\n    # increases monotonously, so only borders have to be considered.\n    front_chunk_n = len(unicode_to_utf16(front))\n    back_chunk_n  = len(unicode_to_utf16(back))\n    if front_chunk_n != back_chunk_n: return None\n    else:                             return front_chunk_n\ndef create_intermediate_states(sm, StartStateIdx, EndStateIdx, X):\n    # Split the interval into a range below and above 0xFFFF. This corresponds\n    # unicode values that are represented in utf16 via 2 and 4 bytes (1 and 2 words).\n    interval_1word, intervals_2word = get_contigous_intervals(X)\n    if interval_1word is not None:\n        sm.add_transition(StartStateIdx, interval_1word, EndStateIdx)\n    if intervals_2word is not None:\n        for interval in intervals_2word:\n            # Introduce intermediate state\n            trigger_seq = get_trigger_sequence_for_interval(interval)\n            s_idx = sm.add_transition(StartStateIdx, trigger_seq[0])\n            sm.add_transition(s_idx, trigger_seq[1], EndStateIdx)\ndef get_contigous_intervals(X):\n    \"\"\"Split Unicode interval into intervals where all values\n       have the same utf16-byte sequence length. This is fairly \n       simple in comparison with utf8-byte sequence length: There\n       are only two lengths: 2 bytes and 2 x 2 bytes.\n       RETURNS:  [X0, List1]  \n                 X0   = the sub-interval where all values are 1 word (2 byte)\n                        utf16 encoded. \n                         \n                        None => No such interval\n                \n                List1 = list of contigous sub-intervals where coded as 2 words.\n                        None => No such intervals\n    \"\"\"\n    global ForbiddenRange\n    if X.begin == -sys.maxint: X.begin = 0\n    if X.end   == sys.maxint:  X.end   = 0x110000\n    assert X.end != X.begin     # Empty intervals are nonsensical\n    assert X.end <= 0x110000    # Interval must lie in unicode range\n    assert not X.check_overlap(ForbiddenRange) # The 'forbidden range' is not to be covered.\n    if   X.end   <= 0x10000: return [X, None]\n    elif X.begin >= 0x10000: return [None, split_contigous_intervals_for_surrogates(X.begin, X.end)]\n    else:                    return [Interval(X.begin, 0x10000), split_contigous_intervals_for_surrogates(0x10000, X.end)]\ndef split_contigous_intervals_for_surrogates(Begin, End):\n    \"\"\"Splits the interval X into sub interval so that no interval runs over a 'surrogate'\n       border of the last word. For that, it is simply checked if the End falls into the\n       same 'surrogate' domain of 'front' (start value of front = Begin). If it does not\n       an interval [front, end_of_domain) is split up and front is set to end of domain.\n       This procedure repeats until front and End lie in the same domain.\n    \"\"\"\n    global ForbiddenRange\n    assert Begin >= 0x10000\n    assert End   <= 0x110000\n    assert End   > Begin\n    front_seq = unicode_to_utf16(Begin)\n    back_seq  = unicode_to_utf16(End - 1)\n    # (*) First word is the same.\n    #     Then,\n    #       -- it is either a one word character.\n    #       -- it is a range of two word characters, but the range \n    #          extends in one contigous range in the second surrogate.\n    #     In both cases, the interval is contigous.\n    if front_seq[0] == back_seq[0]:\n        return [Interval(Begin, End)]\n    # (*) First word is NOT the same\n    # Separate into three domains:\n    #\n    # (1) Interval from Begin until second surrogate hits border 0xE000\n    # (2) Interval where the first surrogate inreases while second \n    #     surrogate iterates over [0xDC00, 0xDFFF]\n    # (3) Interval from begin of last surrogate border to End\n    result = []\n    end    = utf16_to_unicode([front_seq[0], ForbiddenRange.end - 1]) + 1\n    \n    # (1) 'Begin' until second surrogate hits border 0xE000\n    #      (The following **must** hold according to entry condition about \n    #       front and back sequence.)\n    assert End > end\n    result.append(Interval(Begin, end))\n    if front_seq[0] + 1 != back_seq[0]: \n        # (2) Second surrogate iterates over [0xDC00, 0xDFFF]\n        mid_end = utf16_to_unicode([back_seq[0] - 1, ForbiddenRange.end - 1]) + 1\n        #     (The following **must** hold according to entry condition about \n        #      front and back sequence.)\n        assert mid_end > end\n        result.append(Interval(end, mid_end)) \n        end     = mid_end\n         \n    # (3) Last surrogate border to End\n    if End > end:\n        result.append(Interval(end, End)) \n    return result\n    \ndef get_trigger_sequence_for_interval(X):\n    # The interval either lies entirely >= 0x10000 or entirely < 0x10000\n    assert X.begin >= 0x10000 or X.end < 0x10000\n    # An interval below < 0x10000 remains the same\n    if X.end < 0x10000: return [ X ]\n    \n    # In case that the interval >= 0x10000 it the value is split up into\n    # two values.\n", "outputs": ["    front_seq = unicode_to_utf16(X.begin)"], "input_length": 1628, "output_length": 6, "length": 1634, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "646e09628f1c1703925b9ad08af5192738a0c276422d664622d0f563359fd223"}
{"input": "", "context": "/*\n * jPOS Project [http://jpos.org]\n * Copyright (C) 2000-2015 Alejandro P. Revilla\n *\n * This program is free software: you can redistribute it and/or modify\n * it under the terms of the GNU Affero General Public License as\n * published by the Free Software Foundation, either version 3 of the\n * License, or (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU Affero General Public License for more details.\n *\n * You should have received a copy of the GNU Affero General Public License\n * along with this program.  If not, see <http://www.gnu.org/licenses/>.\n */\npackage org.jpos.space;\nimport java.io.*;\nimport java.util.Map;\nimport java.util.HashMap;\nimport java.util.Set;\nimport java.util.concurrent.Future;\nimport java.util.concurrent.Semaphore;\nimport com.sleepycat.je.*;\nimport com.sleepycat.persist.EntityStore; \nimport com.sleepycat.persist.StoreConfig; \nimport com.sleepycat.persist.EntityCursor;\nimport com.sleepycat.persist.PrimaryIndex;\nimport com.sleepycat.persist.SecondaryIndex;\nimport com.sleepycat.persist.model.Entity;\nimport com.sleepycat.persist.model.Persistent;\nimport com.sleepycat.persist.model.PrimaryKey;\nimport com.sleepycat.persist.model.SecondaryKey;\nimport com.sleepycat.persist.model.Relationship;\nimport java.util.HashSet;\nimport java.util.concurrent.TimeUnit;\nimport org.jpos.util.Log;\nimport org.jpos.util.Loggeable;\n/**\n * BerkeleyDB Jave Edition based persistent space implementation\n *\n * @author Alejandro Revilla\n * @since 1.6.5\n */\n@SuppressWarnings(\"unchecked\")\npublic class JESpace<K,V> extends Log implements LocalSpace<K,V>, Loggeable, Runnable {\n    Environment dbe = null;\n    EntityStore store = null;\n    PrimaryIndex<Long, Ref> pIndex = null;\n    PrimaryIndex<Long,GCRef> gcpIndex = null;\n    SecondaryIndex<String,Long, Ref> sIndex = null;\n    SecondaryIndex<Long,Long,GCRef> gcsIndex = null;\n    Semaphore gcSem = new Semaphore(1);\n    LocalSpace<Object,SpaceListener> sl;\n    private static final long NRD_RESOLUTION = 500L;\n    public static final long GC_DELAY = 60*1000L;\n    private Future gcTask;\n    static final Map<String,Space> spaceRegistrar = \n        new HashMap<String,Space> ();\n    public JESpace(String name, String path) throws SpaceError {\n        super();\n        try {\n            EnvironmentConfig envConfig = new EnvironmentConfig();\n            StoreConfig storeConfig = new StoreConfig();\n            envConfig.setAllowCreate (true);\n            envConfig.setTransactional(true);\n            // envConfig.setTxnTimeout(5L, TimeUnit.MINUTES);\n            envConfig.setLockTimeout(5, TimeUnit.SECONDS);\n            storeConfig.setAllowCreate (true);\n            storeConfig.setTransactional (true);\n            File dir = new File(path);\n            dir.mkdirs();\n            dbe = new Environment (dir, envConfig);\n            store = new EntityStore (dbe, name, storeConfig);\n            pIndex = store.getPrimaryIndex (Long.class, Ref.class);\n            gcpIndex = store.getPrimaryIndex (Long.class, GCRef.class);\n            sIndex = store.getSecondaryIndex (pIndex, String.class, \"key\");\n            gcsIndex = store.getSecondaryIndex (gcpIndex, Long.class, \"expires\");\n            gcTask = SpaceFactory.getGCExecutor().scheduleAtFixedRate(this, GC_DELAY, GC_DELAY, TimeUnit.MILLISECONDS);\n        } catch (Exception e) {\n            throw new SpaceError (e);\n        }\n    }\n    public void out (K key, V value) {\n        out (key, value, 0L);\n    }\n    public void out (K key, V value, long timeout) {\n        Transaction txn = null;\n        try {\n            txn = dbe.beginTransaction (null, null);\n            Ref ref = new Ref(key.toString(), value, timeout);\n            pIndex.put (ref);\n            if (timeout > 0L)\n                gcpIndex.putNoReturn (\n                    new GCRef (ref.getId(), ref.getExpiration())\n                );\n            txn.commit();\n            txn = null;\n            synchronized (this) {\n                notifyAll ();\n            }\n            if (sl != null)\n                notifyListeners(key, value);\n        } catch (Exception e) {\n            throw new SpaceError (e);\n        } finally {\n            if (txn != null)\n                abort (txn);\n        }\n    }\n    public void push (K key, V value, long timeout) {\n        Transaction txn = null;\n        try {\n            txn = dbe.beginTransaction (null, null);\n            Ref ref = new Ref(key.toString(), value, timeout);\n            pIndex.put (ref);\n            pIndex.delete (ref.getId());\n            ref.reverseId();\n            pIndex.put (ref);\n            txn.commit();\n            txn = null;\n            synchronized (this) {\n                notifyAll ();\n            }\n            if (sl != null)\n                notifyListeners(key, value);\n        } catch (Exception e) {\n            throw new SpaceError (e);\n        } finally {\n            if (txn != null)\n                abort (txn);\n        }\n    }\n    public void push (K key, V value) {\n        push (key, value, 0L);\n    }\n    @SuppressWarnings(\"unchecked\")\n    public V rdp (Object key) {\n        try {\n            return (V) getObject (key, false);\n        } catch (DatabaseException e) {\n            throw new SpaceError (e);\n        }\n    }\n    @SuppressWarnings(\"unchecked\")\n    public synchronized V in (Object key) {\n        Object obj;\n        while ((obj = inp (key)) == null) {\n            try {\n                this.wait ();\n            } catch (InterruptedException ignored) { }\n        }\n        return (V) obj;\n    }\n    @SuppressWarnings(\"unchecked\")\n    public synchronized V in (Object key, long timeout) {\n        Object obj;\n        long now = System.currentTimeMillis();\n        long end = now + timeout;\n        while ((obj = inp (key)) == null &&\n                (now = System.currentTimeMillis()) < end)\n        {\n            try {\n                this.wait (end - now);\n            } catch (InterruptedException ignored) { }\n        }\n        return (V) obj;\n    }\n    @SuppressWarnings(\"unchecked\")\n    public synchronized V rd  (Object key) {\n        Object obj;\n        while ((obj = rdp (key)) == null) {\n            try {\n                this.wait ();\n            } catch (InterruptedException ignored) { }\n        }\n        return (V) obj;\n    }\n    @SuppressWarnings(\"unchecked\")\n    public synchronized V rd  (Object key, long timeout) {\n        Object obj;\n        long now = System.currentTimeMillis();\n        long end = now + timeout;\n        while ((obj = rdp (key)) == null &&\n                (now = System.currentTimeMillis()) < end)\n        {\n            try {\n                this.wait (end - now);\n            } catch (InterruptedException ignored) { }\n        }\n        return (V) obj;\n    }\n    public synchronized void nrd  (Object key) {\n        while (rdp (key) != null) {\n            try {\n                this.wait (NRD_RESOLUTION);\n            } catch (InterruptedException ignored) { }\n        }\n    }\n    public synchronized V nrd  (Object key, long timeout) {\n        Object obj;\n        long now = System.currentTimeMillis();\n        long end = now + timeout;\n        while ((obj = rdp (key)) != null &&\n                (now = System.currentTimeMillis()) < end)\n        {\n            try {\n                this.wait (Math.min(NRD_RESOLUTION, end - now));\n            } catch (InterruptedException ignored) { }\n        }\n        return (V) obj;\n    }\n    @SuppressWarnings(\"unchecked\")\n    public V inp (Object key) {\n        try {\n            return (V) getObject (key, true);\n        } catch (DatabaseException e) {\n            throw new SpaceError (e);\n        }\n    }\n    public boolean existAny (Object[] keys) {\n        for (Object key : keys) {\n            if (rdp(key) != null) {\n                return true;\n            }\n        }\n        return false;\n    }\n    public boolean existAny (Object[] keys, long timeout) {\n        long now = System.currentTimeMillis();\n        long end = now + timeout;\n        while ((now = System.currentTimeMillis()) < end) {\n            if (existAny (keys))\n                return true;\n            synchronized (this) {\n                try {\n                    wait (end - now);\n                } catch (InterruptedException ignored) { }\n            }\n        }\n        return false;\n    }\n    public synchronized void put (K key, V value, long timeout) {\n        while (inp (key) != null)\n            ;\n        out (key, value, timeout);\n    }\n    public synchronized void put (K key, V value) {\n        while (inp (key) != null)\n            ;\n        out (key, value);\n    }\n    public void gc () throws DatabaseException {\n        Transaction txn = null;\n        EntityCursor<GCRef> cursor = null;\n        try {\n            if (!gcSem.tryAcquire())\n                return;\n            txn = dbe.beginTransaction (null, null);\n            cursor = gcsIndex.entities (\n                txn, 0L, true, System.currentTimeMillis(), false, null\n            );\n            for (GCRef gcRef: cursor) {\n                pIndex.delete (gcRef.getId());\n                cursor.delete ();\n            }\n            cursor.close();\n            cursor = null;\n            txn.commit();\n            txn = null;\n            if (sl != null) {\n                synchronized (this) {\n                    if (sl != null && sl.getKeySet().isEmpty())\n                        sl = null;\n                }\n            }\n        } finally {\n            if (cursor != null)\n                cursor.close();\n            if (txn != null)\n                abort (txn);\n            gcSem.release();\n        }\n    }\n    public void run() {\n        try {\n            gc();\n        } catch (DatabaseException e) {\n            warn(e);\n        }\n    }\n    public void close () throws DatabaseException {\n        gcSem.acquireUninterruptibly();\n        gcTask.cancel(false);\n        while (!gcTask.isDone()) {\n            try {\n                Thread.sleep(500L);\n            } catch (InterruptedException ignored) { }\n        }\n        store.close ();\n        dbe.close();\n    }\n    public synchronized static JESpace getSpace (String name, String path)\n    {\n        JESpace sp = (JESpace) spaceRegistrar.get (name);\n        if (sp == null) {\n", "outputs": ["            sp = new JESpace(name, path);"], "input_length": 1817, "output_length": 10, "length": 1827, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "9660a55c3a805e4d61b9de73b6f37426e51b26413634656f34c3478138fbd853"}
{"input": "", "context": "import ROOT\nfrom ..core import Object, isbasictype, snake_case_methods\nfrom .core import Plottable, dim\nfrom ..objectproxy import ObjectProxy\nfrom ..registry import register\nfrom .graph import Graph\nfrom array import array\nclass DomainError(Exception):\n    pass\nclass _HistBase(Plottable, Object):\n    TYPES = {\n        'C': [ROOT.TH1C, ROOT.TH2C, ROOT.TH3C],\n        'S': [ROOT.TH1S, ROOT.TH2S, ROOT.TH3S],\n        'I': [ROOT.TH1I, ROOT.TH2I, ROOT.TH3I],\n        'F': [ROOT.TH1F, ROOT.TH2F, ROOT.TH3F],\n        'D': [ROOT.TH1D, ROOT.TH2D, ROOT.TH3D]\n    }\n    def __init__(self):\n        Plottable.__init__(self)\n    def _parse_args(self, *args):\n        params = [{'bins': None,\n                   'nbins': None,\n                   'low': None,\n                   'high': None} for _ in xrange(dim(self))]\n        for param in params:\n            if len(args) == 0:\n                raise TypeError(\"Did not receive expected number of arguments\")\n            if type(args[0]) in [tuple, list]:\n                if list(sorted(args[0])) != list(args[0]):\n                    raise ValueError(\n                        \"Bin edges must be sorted in ascending order\")\n                if len(set(args[0])) != len(args[0]):\n                    raise ValueError(\"Bin edges must not be repeated\")\n                param['bins'] = args[0]\n                param['nbins'] = len(args[0]) - 1\n                args = args[1:]\n            elif len(args) >= 3:\n                nbins = args[0]\n                if type(nbins) is not int:\n                    raise TypeError(\n                        \"Type of first argument (got %s %s) must be an int\" %\n                        (type(nbins), nbins))\n                low = args[1]\n                if not isbasictype(low):\n                    raise TypeError(\n                        \"Type of second argument must be int, float, or long\")\n                high = args[2]\n                if not isbasictype(high):\n                    raise TypeError(\n                        \"Type of third argument must be int, float, or long\")\n                param['nbins'] = nbins\n                param['low'] = low\n                param['high'] = high\n                if low >= high:\n                    raise ValueError(\n                        \"Upper bound (you gave %f) must be greater than lower \"\n                        \"bound (you gave %f)\" % (float(low), float(high)))\n                args = args[3:]\n            else:\n                raise TypeError(\n                    \"Did not receive expected number of arguments\")\n        if len(args) != 0:\n            raise TypeError(\n                \"Did not receive expected number of arguments\")\n        return params\n    @classmethod\n    def divide(cls, h1, h2, c1=1., c2=1., option=''):\n        ratio = h1.Clone()\n        rootbase = h1.__class__.__bases__[-1]\n        rootbase.Divide(ratio, h1, h2, c1, c2, option)\n        return ratio\n    def Fill(self, *args):\n        bin = self.__class__.__bases__[-1].Fill(self, *args)\n        if bin > 0:\n            return bin - 1\n        return bin\n    def nbins(self, axis=1):\n        if axis == 1:\n            return self.GetNbinsX()\n        elif axis == 2:\n            return self.GetNbinsY()\n        elif axis == 3:\n            return self.GetNbinsZ()\n        else:\n            raise ValueError(\"%s is not a valid axis index!\" % axis)\n    def axis(self, axis=1):\n        if axis == 1:\n            return self.GetXaxis()\n        elif axis == 2:\n            return self.GetYaxis()\n        elif axis == 3:\n            return self.GetZaxis()\n        else:\n            raise ValueError(\"%s is not a valid axis index!\" % axis)\n    @property\n    def xaxis(self):\n        return self.GetXaxis()\n    @property\n    def yaxis(self):\n        return self.GetYaxis()\n    @property\n    def zaxis(self):\n        return self.GetZaxis()\n    def underflow(self, axis=1):\n        \"\"\"\n        Return the underflow for the given axis.\n        Depending on the dimension of the histogram, may return an array.\n        \"\"\"\n        if axis not in [1, 2, 3]:\n            raise ValueError(\"%s is not a valid axis index!\" % axis)\n        if self.DIM == 1:\n            return self.GetBinContent(0)\n        elif self.DIM == 2:\n            return [self.GetBinContent(*[i].insert(axis - 1, 0))\n                    for i in xrange(self.nbins((axis + 1) % 2))]\n        elif self.DIM == 3:\n            axis2, axis3 = [1, 2, 3].remove(axis)\n            return [[self.GetBinContent(*[i, j].insert(axis - 1, 0))\n                     for i in xrange(self.nbins(axis2))]\n                    for j in xrange(self.nbins(axis3))]\n    def overflow(self, axis=1):\n        \"\"\"\n        Return the overflow for the given axis.\n        Depending on the dimension of the histogram, may return an array.\n        \"\"\"\n        if axis not in [1, 2, 3]:\n            raise ValueError(\"%s is not a valid axis index!\" % axis)\n        if self.DIM == 1:\n            return self.GetBinContent(self.nbins(1) + 1)\n        elif self.DIM == 2:\n            axis2 = [1, 2].remove(axis)\n            return [self.GetBinContent(*[i].insert(axis - 1, self.nbins(axis)))\n                    for i in xrange(self.nbins(axis2))]\n        elif self.DIM == 3:\n            axis2, axis3 = [1, 2, 3].remove(axis)\n            return [[self.GetBinContent(\n                     *[i, j].insert(axis - 1, self.nbins(axis)))\n                     for i in xrange(self.nbins(axis2))]\n                     for j in xrange(self.nbins(axis3))]\n    def lowerbound(self, axis=1):\n        if axis == 1:\n            return self.xedges(0)\n        if axis == 2:\n            return self.yedges(0)\n        if axis == 3:\n            return self.zedges(0)\n        return ValueError(\"axis must be 1, 2, or 3\")\n    def upperbound(self, axis=1):\n        if axis == 1:\n            return self.xedges(-1)\n        if axis == 2:\n            return self.yedges(-1)\n        if axis == 3:\n            return self.zedges(-1)\n        return ValueError(\"axis must be 1, 2, or 3\")\n    def _centers(self, axis, index=None):\n        if index is None:\n            return (self._centers(axis, i) for i in xrange(self.nbins(axis)))\n        index = index % self.nbins(axis)\n        return (self._edgesl(axis, index) + self._edgesh(axis, index)) / 2\n    def _edgesl(self, axis, index=None):\n        if index is None:\n            return (self._edgesl(axis, i) for i in xrange(self.nbins(axis)))\n        index = index % self.nbins(axis)\n        return self.axis(axis).GetBinLowEdge(index + 1)\n    def _edgesh(self, axis, index=None):\n        if index is None:\n            return (self._edgesh(axis, i) for i in xrange(self.nbins(axis)))\n        index = index % self.nbins(axis)\n        return self.axis(axis).GetBinUpEdge(index + 1)\n    def _edges(self, axis, index=None):\n        nbins = self.nbins(axis)\n        if index is None:\n            def temp_generator():\n                for index in xrange(nbins):\n                    yield self._edgesl(axis, index)\n                yield self._edgesh(axis, index)\n            return temp_generator()\n        index = index % (nbins + 1)\n        if index == nbins:\n            return self._edgesh(axis, -1)\n        return self._edgesl(axis, index)\n    def _width(self, axis, index=None):\n        if index is None:\n            return (self._width(axis, i) for i in xrange(self.nbins(axis)))\n        index = index % self.nbins(axis)\n        return self._edgesh(axis, index) - self._edgesl(axis, index)\n    def _erravg(self, axis, index=None):\n        if index is None:\n            return (self._erravg(axis, i) for i in xrange(self.nbins(axis)))\n        index = index % self.nbins(axis)\n        return self._width(axis, index) / 2\n    def _err(self, axis, index=None):\n        if index is None:\n            return ((self._erravg(axis, i), self._erravg(axis, i))\n                    for i in xrange(self.nbins(axis)))\n        index = index % self.nbins(axis)\n        return (self._erravg(axis, index), self._erravg(axis, index))\n    def __add__(self, other):\n        copy = self.Clone()\n        copy += other\n        return copy\n    def __iadd__(self, other):\n        if isbasictype(other):\n            if not isinstance(self, _Hist):\n                raise ValueError(\n                    \"A multidimensional histogram must be filled with a tuple\")\n            self.Fill(other)\n        elif type(other) in [list, tuple]:\n            if dim(self) not in [len(other), len(other) - 1]:\n                raise ValueError(\n                    \"Dimension of %s does not match dimension \"\n                    \"of histogram (with optional weight as last element)\" %\n                    str(other))\n            self.Fill(*other)\n        else:\n            self.Add(other)\n        return self\n    def __sub__(self, other):\n        copy = self.Clone()\n        copy -= other\n        return copy\n    def __isub__(self, other):\n        if isbasictype(other):\n            if not isinstance(self, _Hist):\n                raise ValueError(\n                    \"A multidimensional histogram must be filled with a tuple\")\n            self.Fill(other, -1)\n        elif type(other) in [list, tuple]:\n            if len(other) == dim(self):\n                self.Fill(*(other + (-1, )))\n            elif len(other) == dim(self) + 1:\n                # negate last element\n                self.Fill(*(other[:-1] + (-1 * other[-1], )))\n            else:\n                raise ValueError(\n                    \"Dimension of %s does not match dimension \"\n                    \"of histogram (with optional weight as last element)\" %\n                    str(other))\n        else:\n            self.Add(other, -1.)\n        return self\n    def __mul__(self, other):\n        copy = self.Clone()\n        copy *= other\n        return copy\n    def __imul__(self, other):\n        if isbasictype(other):\n            self.Scale(other)\n            return self\n        self.Multiply(other)\n        return self\n    def __div__(self, other):\n        copy = self.Clone()\n        copy /= other\n        return copy\n    def __idiv__(self, other):\n        if isbasictype(other):\n            if other == 0:\n                raise ZeroDivisionError()\n            self.Scale(1. / other)\n            return self\n        self.Divide(other)\n        return self\n    def __radd__(self, other):\n        if other == 0:\n            return self.Clone()\n        raise TypeError(\"unsupported operand type(s) for +: '%s' and '%s'\" %\n                (other.__class__.__name__, self.__class__.__name__))\n    def __rsub__(self, other):\n        if other == 0:\n            return self.Clone()\n        raise TypeError(\"unsupported operand type(s) for -: '%s' and '%s'\" %\n                (other.__class__.__name__, self.__class__.__name__))\n    def __len__(self):\n        return self.GetNbinsX()\n    def __getitem__(self, index):\n        # TODO: Perhaps this should return a Hist object of dimension (DIM - 1)\n        if index not in range(-1, len(self) + 1):\n            raise IndexError(\"bin index %i out of range\" % index)\n    def __setitem__(self, index):\n        if index not in range(-1, len(self) + 1):\n            raise IndexError(\"bin index %i out of range\" % index)\n    def __iter__(self):\n        return iter(self._content())\n    def __cmp__(self, other):\n        diff = self.maximum() - other.maximum()\n        if diff > 0:\n            return 1\n        if diff < 0:\n            return -1\n        return 0\n    def errors(self):\n        return iter(self._error_content())\n    def asarray(self, typecode='f'):\n        return array(typecode, self._content())\nclass _Hist(_HistBase):\n    DIM = 1\n    def __init__(self, *args, **kwargs):\n        name = kwargs.get('name', None)\n        title = kwargs.get('title', None)\n        params = self._parse_args(*args)\n        if params[0]['bins'] is None:\n            Object.__init__(self, name, title,\n                params[0]['nbins'], params[0]['low'], params[0]['high'])\n        else:\n            Object.__init__(self, name, title,\n                params[0]['nbins'], array('d', params[0]['bins']))\n        self._post_init(**kwargs)\n    def _post_init(self, **kwargs):\n        _HistBase.__init__(self)\n        self.decorate(**kwargs)\n    def x(self, index=None):\n        return self._centers(1, index)\n    def xerravg(self, index=None):\n        return self._erravg(1, index)\n    def xerrl(self, index=None):\n        return self._erravg(1, index)\n    def xerrh(self, index=None):\n        return self._erravg(1, index)\n    def xerr(self, index=None):\n        return self._err(1, index)\n    def xwidth(self, index=None):\n        return self._width(1, index)\n    def xedgesl(self, index=None):\n        return self._edgesl(1, index)\n    def xedgesh(self, index=None):\n        return self._edgesh(1, index)\n    def xedges(self, index=None):\n        return self._edges(1, index)\n    def yerrh(self, index=None):\n        return self.yerravg(index)\n    def yerrl(self, index=None):\n        return self.yerravg(index)\n    def y(self, index=None):\n        if index is None:\n            return (self.y(i) for i in xrange(self.nbins(1)))\n        index = index % len(self)\n        return self.GetBinContent(index + 1)\n    def yerravg(self, index=None):\n        if index is None:\n            return (self.yerravg(i) for i in xrange(self.nbins(1)))\n        index = index % len(self)\n        return self.GetBinError(index + 1)\n    def yerr(self, index=None):\n        if index is None:\n            return ((self.yerrl(i), self.yerrh(i))\n                    for i in xrange(self.nbins(1)))\n        index = index % len(self)\n        return (self.yerrl(index), self.yerrh(index))\n    def GetMaximum(self, **kwargs):\n        return self.maximum(**kwargs)\n    def maximum(self, include_error=False):\n        if not include_error:\n            return self.__class__.__bases__[-1].GetMaximum(self)\n        clone = self.Clone()\n        for i in xrange(clone.GetNbinsX()):\n            clone.SetBinContent(\n                i + 1, clone.GetBinContent(i + 1) + clone.GetBinError(i + 1))\n        return clone.maximum()\n    def GetMinimum(self, **kwargs):\n        return self.minimum(**kwargs)\n    def minimum(self, include_error=False):\n        if not include_error:\n            return self.__class__.__bases__[-1].GetMinimum(self)\n        clone = self.Clone()\n        for i in xrange(clone.GetNbinsX()):\n            clone.SetBinContent(\n                i + 1, clone.GetBinContent(i + 1) - clone.GetBinError(i + 1))\n        return clone.minimum()\n    def expectation(self, startbin=0, endbin=None):\n        if endbin is not None and endbin < startbin:\n            raise DomainError(\"endbin should be greated than startbin\")\n        if endbin is None:\n            endbin = len(self) - 1\n        expect = 0.\n        norm = 0.\n        for index in xrange(startbin, endbin + 1):\n            val = self[index]\n            expect += val * self.x(index)\n            norm += val\n        if norm > 0:\n            return expect / norm\n        else:\n            return (self.xedges(endbin + 1) + self.xedges(startbin)) / 2\n    def _content(self):\n        return self.y()\n    def _error_content(self):\n        return self.yerravg()\n    def __getitem__(self, index):\n        \"\"\"\n        if type(index) is slice:\n            return self._content()[index]\n        \"\"\"\n        _HistBase.__getitem__(self, index)\n        return self.y(index)\n    def __getslice__(self, i, j):\n        # TODO: getslice is deprecated.  getitem should accept slice objects.\n        return list(self)[i:j]\n    def __setitem__(self, index, value):\n        _HistBase.__setitem__(self, index)\n        self.SetBinContent(index + 1, value)\nclass _Hist2D(_HistBase):\n    DIM = 2\n    def __init__(self, *args, **kwargs):\n        name = kwargs.get('name', None)\n        title = kwargs.get('title', None)\n        params = self._parse_args(*args)\n        if params[0]['bins'] is None and params[1]['bins'] is None:\n            Object.__init__(self, name, title,\n                params[0]['nbins'], params[0]['low'], params[0]['high'],\n                params[1]['nbins'], params[1]['low'], params[1]['high'])\n        elif params[0]['bins'] is None and params[1]['bins'] is not None:\n            Object.__init__(self, name, title,\n                params[0]['nbins'], params[0]['low'], params[0]['high'],\n                params[1]['nbins'], array('d', params[1]['bins']))\n        elif params[0]['bins'] is not None and params[1]['bins'] is None:\n            Object.__init__(self, name, title,\n                params[0]['nbins'], array('d', params[0]['bins']),\n                params[1]['nbins'], params[1]['low'], params[1]['high'])\n        else:\n            Object.__init__(self, name, title,\n                params[0]['nbins'], array('d', params[0]['bins']),\n                params[1]['nbins'], array('d', params[1]['bins']))\n        self._post_init(**kwargs)\n    def _post_init(self, **kwargs):\n        _HistBase.__init__(self)\n        self.decorate(**kwargs)\n    def x(self, index=None):\n        return self._centers(1, index)\n    def xerravg(self, index=None):\n        return self._erravg(1, index)\n    def xerrl(self, index=None):\n        return self._erravg(1, index)\n    def xerrh(self, index=None):\n        return self._erravg(1, index)\n    def xerr(self, index=None):\n        return self._err(1, index)\n    def xwidth(self, index=None):\n        return self._width(1, index)\n    def xedgesl(self, index=None):\n        return self._edgesl(1, index)\n    def xedgesh(self, index=None):\n        return self._edgesh(1, index)\n    def xedges(self, index=None):\n        return self._edges(1, index)\n    def y(self, index=None):\n        return self._centers(2, index)\n    def yerravg(self, index=None):\n        return self._erravg(2, index)\n    def yerrl(self, index=None):\n        return self._erravg(2, index)\n    def yerrh(self, index=None):\n        return self._erravg(2, index)\n    def yerr(self, index=None):\n        return self._err(2, index)\n    def ywidth(self, index=None):\n        return self._width(2, index)\n    def yedgesl(self, index=None):\n        return self._edgesl(2, index)\n    def yedgesh(self, index=None):\n        return self._edgesh(2, index)\n    def yedges(self, index=None):\n        return self._edges(2, index)\n    def zerrh(self, index=None):\n        return self.zerravg(index)\n    def zerrl(self, index=None):\n        return self.zerravg(index)\n    def z(self, ix=None, iy=None):\n        if ix is None and iy is None:\n            return [[self.z(ix, iy)\n                    for iy in xrange(self.nbins(2))]\n                    for ix in xrange(self.nbins(1))]\n        ix = ix % self.nbins(1)\n        iy = iy % self.nbins(2)\n        return self.GetBinContent(ix + 1, iy + 1)\n    def zerravg(self, ix=None, iy=None):\n        if ix is None and iy is None:\n            return [[self.zerravg(ix, iy)\n                    for iy in xrange(self.nbins(2))]\n                    for ix in xrange(self.nbins(1))]\n        ix = ix % self.nbins(1)\n        iy = iy % self.nbins(2)\n        return self.GetBinError(ix + 1, iy + 1)\n    def zerr(self, ix=None, iy=None):\n        if ix is None and iy is None:\n            return [[(self.zerravg(ix, iy), self.zerravg(ix, iy))\n                    for iy in xrange(self.nbins(2))]\n                    for ix in xrange(self.nbins(1))]\n        ix = ix % self.nbins(1)\n        iy = iy % self.nbins(2)\n        return (self.GetBinError(ix + 1, iy + 1),\n                self.GetBinError(ix + 1, iy + 1))\n    def _content(self):\n        return self.z()\n    def _error_content(self):\n        return self.zerravg()\n    def __getitem__(self, index):\n        if isinstance(index, tuple):\n            # support indexing like h[1,2]\n            return self.z(*index)\n        _HistBase.__getitem__(self, index)\n        a = ObjectProxy([\n            self.GetBinContent(index + 1, j)\n                for j in xrange(1, self.GetNbinsY() + 1)])\n        a.__setposthook__('__setitem__', self._setitem(index))\n        return a\n    def _setitem(self, i):\n        def __setitem(j, value):\n            self.SetBinContent(i + 1, j + 1, value)\n        return __setitem\n    def ravel(self):\n        \"\"\"\n        Convert 2D histogram into 1D histogram with the y-axis repeated along\n        the x-axis, similar to NumPy's ravel().\n        \"\"\"\n        nbinsx = self.nbins(1)\n        nbinsy = self.nbins(2)\n        out = Hist(self.nbins(1) * nbinsy,\n                self.xedgesl(0), self.xedgesh(-1) * nbinsy,\n                type=self.TYPE,\n                title=self.title,\n                **self.decorators)\n        for i in range(nbinsx):\n            for j in range(nbinsy):\n                out[i + nbinsy * j] = self[i, j]\n                out.SetBinError(i + nbinsy * j + 1,\n                        self.GetBinError(i + 1, j + 1))\n        return out\nclass _Hist3D(_HistBase):\n    DIM = 3\n    def __init__(self, *args, **kwargs):\n        name = kwargs.get('name', None)\n        title = kwargs.get('title', None)\n        params = self._parse_args(*args)\n        # ROOT is missing constructors for TH3F...\n        if params[0]['bins'] is None and \\\n           params[1]['bins'] is None and \\\n           params[2]['bins'] is None:\n            Object.__init__(self, name, title,\n                params[0]['nbins'], params[0]['low'], params[0]['high'],\n                params[1]['nbins'], params[1]['low'], params[1]['high'],\n                params[2]['nbins'], params[2]['low'], params[2]['high'])\n        else:\n            if params[0]['bins'] is None:\n                step = (params[0]['high'] - params[0]['low'])\\\n                    / float(params[0]['nbins'])\n                params[0]['bins'] = [\n                    params[0]['low'] + n * step\n", "outputs": ["                        for n in xrange(params[0]['nbins'] + 1)]"], "input_length": 4621, "output_length": 17, "length": 4638, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "6e75fd155b62d6f1df45413133d1a605c3dcc9abaa12510e4351d4b8de0f16b1"}
{"input": "", "context": "/*\n * Phosphorus Five, copyright 2014 - 2017, Thomas Hansen, thomas@gaiasoul.com\n * \n * This file is part of Phosphorus Five.\n *\n * Phosphorus Five is free software: you can redistribute it and/or modify\n * it under the terms of the GNU General Public License version 3, as published by\n * the Free Software Foundation.\n *\n *\n * Phosphorus Five is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with Phosphorus Five.  If not, see <http://www.gnu.org/licenses/>.\n * \n * If you cannot for some reasons use the GPL license, Phosphorus\n * Five is also commercially available under Quid Pro Quo terms. Check \n * out our website at http://gaiasoul.com for more details.\n */\nusing System;\nusing System.IO;\nusing p5.exp;\nusing p5.core;\nusing p5.io.common;\nusing p5.exp.exceptions;\nnamespace p5.io.file\n{\n    /// <summary>\n    ///     Loads one or more file(s).\n    /// </summary>\n    public static class Load\n    {\n        /// <summary>\n        ///     Loads one or more file(s) from local disc.\n        /// </summary>\n        /// <param name=\"context\">Application Context</param>\n        /// <param name=\"e\">Parameters passed into Active Event</param>\n        [ActiveEvent (Name = \"load-file\")]\n        [ActiveEvent (Name = \"p5.io.file.load\")]\n        public static void p5_io_file_load (ApplicationContext context, ActiveEventArgs e)\n        {\n            ObjectIterator.Iterate (\n                context,\n                e.Args,\n                true,\n                \"read-file\",\n                delegate (string filename, string fullpath) {\n                    if (File.Exists (fullpath)) {\n                        // Text files and binary files are loaded differently.\n                        // Text file might for instance be converted automatically.\n                        if (IsTextFile (filename)) {\n                            // Text file of some sort.\n                            LoadTextFile (context, e.Args, fullpath, filename);\n                        } else {\n                            // Some sort of binary file (probably).\n                            LoadBinaryFile (e.Args, fullpath, filename);\n                        }\n                    } else {\n                        // Oops, file didn't exist.\n                        throw new LambdaException (\n                            string.Format (\"Couldn't find file '{0}'\", filename),\n                            e.Args,\n                            context);\n                    }\n                });\n        }\n        /// <summary>\n        ///     Loads one or more file(s) from local disc and saves into given stream.\n        /// </summary>\n        /// <param name=\"context\">Application Context</param>\n        /// <param name=\"e\">Parameters passed into Active Event</param>\n        [ActiveEvent (Name = \".p5.io.file.serialize-to-stream\")]\n        public static void _p5_io_file_serialize_to_stream (ApplicationContext context, ActiveEventArgs e)\n        {\n            // Retrieving stream argument.\n            var tuple = e.Args.Value as Tuple<object, Stream>;\n            // Retrieving stream and doing some basic sanity check.\n            var outStream = tuple.Item2;\n            if (outStream == null)\n                throw new LambdaException (\"No stream supplied to [.p5.io.file.serialize-to-stream]\", e.Args, context);\n            // Iterating through files specified.\n            ObjectIterator.Iterate (\n                context,\n                e.Args,\n                true,\n                \"read-file\",\n                delegate (string filename, string fullpath) {\n                    if (File.Exists (fullpath)) {\n                        // Serializing file into stream.\n                        using (FileStream stream = File.OpenRead (fullpath)) {\n                            stream.CopyTo (outStream);\n                        }\n                    } else {\n                        // Oops, file didn't exist.\n                        throw new LambdaException (\n                            string.Format (\"Couldn't find file '{0}'\", filename),\n                            e.Args,\n                            context);\n                    }\n                });\n        }\n        /*\n         * Determines if file is text according to the most common file extensions\n         */\n        static bool IsTextFile (string fileName)\n        {\n            switch (Path.GetExtension (fileName)) {\n            case \".txt\":\n            case \".md\":\n            case \".css\":\n            case \".js\":\n            case \".html\":\n            case \".htm\":\n            case \".hl\":\n            case \".xml\":\n            case \".csv\":\n                return true;\n            default:\n                return false;\n            }\n        }\n        /*\n         * Loads specified file as text and appends into args, possibly converting into lambda.\n         */\n        static void LoadTextFile (\n            ApplicationContext context,\n            Node args,\n            string fullpath,\n            string fileName)\n        {\n            // Checking if we should automatically convert file content to lambda.\n            if (fileName.EndsWithEx (\".hl\") && args.GetExChildValue (\"convert\", context, true)) {\n                // Automatically converting to lambda before returning, making sure we \n                // parse the lambda directly from the stream.\n                using (Stream stream = File.OpenRead (fullpath)) {\n                    // Invoking our \"stream to lambda\" event.\n                    var fileNode = args.Add (fileName, stream).LastChild;\n                    try {\n                        context.RaiseEvent (\".stream2lambda\", fileNode);\n                    } finally {\n                        fileNode.Value = null;\n                    }\n                }\n            } else {\n                // Using a TextReader to read file's content.\n                using (TextReader reader = File.OpenText (fullpath)) {\n                    // Reading file content.\n                    string fileContent = reader.ReadToEnd ();\n                    if (fileName.EndsWithEx (\".csv\") && args.GetExChildValue (\"convert\", context, true)) {\n                        // Automatically converting to lambda before returning.\n                        var csvLambda = new Node (\"\", fileContent);\n                        context.RaiseEvent (\"p5.csv.csv2lambda\", csvLambda);\n                        args.Add (fileName, null, csvLambda [\"result\"].Children);\n                    } else {\n                        // Adding file content as string.\n                        args.Add (fileName, fileContent);\n                    }\n                }\n            }\n        }\n        /*\n         * Loads a binary file and appends as blob/byte[] into args.\n         */\n        static void LoadBinaryFile (\n            Node args,\n            string fullpath,\n            string filename)\n        {\n            using (FileStream stream = File.OpenRead (fullpath)) {\n                // Reading file content\n                var buffer = new byte [stream.Length];\n", "outputs": ["                stream.Read (buffer, 0, buffer.Length);"], "input_length": 1094, "output_length": 9, "length": 1103, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "236c2522f5a69c695fa94a65d22f9d0058b74d5aac6d77b82fd5ecdce438352a"}
{"input": "", "context": "package edu.stanford.nlp.parser.lexparser;\nimport java.util.regex.Matcher;\n/** Does iterative deepening search inside the CKY algorithm for faster\n *  parsing. This is still guaranteed to find the optimal parse.  This\n *  iterative deepening is only implemented in insideScores().\n *  Implements the algorithm described in Tsuruoka and Tsujii (2004)\n *  IJCNLP.\n *\n *  @author Christopher Manning\n */\npublic class IterativeCKYPCFGParser extends ExhaustivePCFGParser {\n  private static final float STEP_SIZE = -11.0F; // value suggested in their paper\n  public IterativeCKYPCFGParser(BinaryGrammar bg, UnaryGrammar ug, Lexicon lex, Options op) {\n    super(bg, ug, lex, op);\n  }\n  /** Fills in the iScore array of each category over each span\n   *  of length 2 or more.\n   */\n  @Override\n  void doInsideScores() {\n    float threshold = STEP_SIZE;\n    while ( ! doInsideScoresHelper(threshold)) {\n      threshold += STEP_SIZE;\n    }\n  }\n  /** Fills in the iScore array of each category over each spanof length 2\n   *  or more, providing\n   *  a state's probability is greater than a threshold.\n   *\n   *  @param threshold The threshold up to which to parse as a log\n   *      probability (i.e., a non-positive number)\n   *  @return true iff a parse was found with this threshold or else\n   *      it has been determined that no parse exists.\n   */\n  private boolean doInsideScoresHelper(float threshold) {\n    boolean prunedSomething = false;\n    for (int diff = 2; diff <= length; diff++) {\n      // usually stop one short because boundary symbol only combines\n      // with whole sentence span\n      for (int start = 0; start < ((diff == length) ? 1: length - diff); start++) {\n        if (spillGuts) {\n          tick(\"Binaries for span \" + diff + \"...\");\n        }\n        int end = start + diff;\n        if (Test.constraints != null) {\n          boolean skip = false;\n          for (Test.Constraint c : Test.constraints) {\n            if ((start > c.start && start < c.end && end > c.end) || (end > c.start && end < c.end && start < c.start)) {\n              skip = true;\n              break;\n            }\n          }\n          if (skip) {\n            continue;\n          }\n        }\n        for (int leftState = 0; leftState < numStates; leftState++) {\n          int narrowR = narrowRExtent[start][leftState];\n          boolean iPossibleL = (narrowR < end); // can this left constituent leave space for a right constituent?\n          if (!iPossibleL) {\n            continue;\n          }\n          BinaryRule[] leftRules = bg.splitRulesWithLC(leftState);\n          //      if (spillGuts) System.out.println(\"Found \" + leftRules.length + \" left rules for state \" + stateNumberer.object(leftState));\n          for (int i = 0; i < leftRules.length; i++) {\n            //      if (spillGuts) System.out.println(\"Considering rule for \" + start + \" to \" + end + \": \" + leftRules[i]);\n            BinaryRule r = leftRules[i];\n            int narrowL = narrowLExtent[end][r.rightChild];\n            boolean iPossibleR = (narrowL >= narrowR); // can this right constituent fit next to the left constituent?\n            if (!iPossibleR) {\n              continue;\n            }\n            int min1 = narrowR;\n            int min2 = wideLExtent[end][r.rightChild];\n            int min = (min1 > min2 ? min1 : min2);\n            if (min > narrowL) { // can this right constituent stretch far enough to reach the left constituent?\n              continue;\n            }\n            int max1 = wideRExtent[start][leftState];\n            int max2 = narrowL;\n            int max = (max1 < max2 ? max1 : max2);\n            if (min > max) { // can this left constituent stretch far enough to reach the right constituent?\n              continue;\n            }\n            float pS = r.score;\n            int parentState = r.parent;\n            float oldIScore = iScore[start][end][parentState];\n            float bestIScore = oldIScore;\n            boolean foundBetter;  // always set below for this rule\n            //System.out.println(\"Min \"+min+\" max \"+max+\" start \"+start+\" end \"+end);\n            if (!Test.lengthNormalization) {\n              // find the split that can use this rule to make the max score\n              for (int split = min; split <= max; split++) {\n                if (Test.constraints != null) {\n                  boolean skip = false;\n                  for (Test.Constraint c : Test.constraints) {\n                    if (((start < c.start && end >= c.end) || (start <= c.start && end > c.end)) && split > c.start && split < c.end) {\n                      skip = true;\n                      break;\n                    }\n                    if ((start == c.start && split == c.end)) {\n                      String tag = (String) stateNumberer.object(leftState);\n                      Matcher m = c.state.matcher(tag);\n                      if (!m.matches()) {\n                        skip = true;\n                        break;\n                      }\n                    }\n                    if ((split == c.start && end == c.end)) {\n                      String tag = (String) stateNumberer.object(r.rightChild);\n                      Matcher m = c.state.matcher(tag);\n                      if (!m.matches()) {\n                        skip = true;\n                        break;\n                      }\n                    }\n                  }\n                  if (skip) {\n                    continue;\n                  }\n                }\n                float lS = iScore[start][split][leftState];\n                if (lS == Float.NEGATIVE_INFINITY) {\n                  continue;\n                }\n                float rS = iScore[split][end][r.rightChild];\n                if (rS == Float.NEGATIVE_INFINITY) {\n                  continue;\n                }\n                float tot = pS + lS + rS;\n                if (tot > bestIScore) {\n                  bestIScore = tot;\n                }\n              } // for split point\n              foundBetter = bestIScore > oldIScore;\n            } else {\n              // find split that uses this rule to make the max *length normalized* score\n              int bestWordsInSpan = wordsInSpan[start][end][parentState];\n              float oldNormIScore = oldIScore / bestWordsInSpan;\n              float bestNormIScore = oldNormIScore;\n              for (int split = min; split <= max; split++) {\n                float lS = iScore[start][split][leftState];\n                if (lS == Float.NEGATIVE_INFINITY) {\n                  continue;\n                }\n                float rS = iScore[split][end][r.rightChild];\n                if (rS == Float.NEGATIVE_INFINITY) {\n                  continue;\n                }\n                float tot = pS + lS + rS;\n                int newWordsInSpan = wordsInSpan[start][split][leftState] + wordsInSpan[split][end][r.rightChild];\n                float normTot = tot / newWordsInSpan;\n                if (normTot > bestNormIScore) {\n                  bestIScore = tot;\n                  bestNormIScore = normTot;\n                  bestWordsInSpan = newWordsInSpan;\n                }\n              } // for split point\n              foundBetter = bestNormIScore > oldNormIScore;\n              if (foundBetter && bestIScore > threshold) {\n                wordsInSpan[start][end][parentState] = bestWordsInSpan;\n              }\n            } // fi Test.lengthNormalization\n            if (foundBetter) {\n              if (bestIScore > threshold) {\n                // this way of making \"parentState\" is better than previous\n                // and sufficiently good to be stored on this iteration\n                iScore[start][end][parentState] = bestIScore;\n                //              if (spillGuts) System.out.println(\"Could build \" + stateNumberer.object(parentState) + \" from \" + start + \" to \" + end);\n                if (oldIScore == Float.NEGATIVE_INFINITY) {\n                  if (start > narrowLExtent[end][parentState]) {\n                    narrowLExtent[end][parentState] = start;\n                    wideLExtent[end][parentState] = start;\n                  } else {\n                    if (start < wideLExtent[end][parentState]) {\n                      wideLExtent[end][parentState] = start;\n                    }\n                  }\n                  if (end < narrowRExtent[start][parentState]) {\n                    narrowRExtent[start][parentState] = end;\n                    wideRExtent[start][parentState] = end;\n                  } else {\n                    if (end > wideRExtent[start][parentState]) {\n                      wideRExtent[start][parentState] = end;\n                    }\n                  }\n                }\n              } else {\n                prunedSomething = true;\n              }\n            } // end if foundBetter\n          } // end for leftRules\n        } // end for leftState\n        // do right restricted rules\n        for (int rightState = 0; rightState < numStates; rightState++) {\n          int narrowL = narrowLExtent[end][rightState];\n          boolean iPossibleR = (narrowL > start);\n          if (!iPossibleR) {\n            continue;\n          }\n          BinaryRule[] rightRules = bg.splitRulesWithRC(rightState);\n          //      if (spillGuts) System.out.println(\"Found \" + rightRules.length + \" right rules for state \" + stateNumberer.object(rightState));\n          for (int i = 0; i < rightRules.length; i++) {\n            //      if (spillGuts) System.out.println(\"Considering rule for \" + start + \" to \" + end + \": \" + rightRules[i]);\n            BinaryRule r = rightRules[i];\n            int narrowR = narrowRExtent[start][r.leftChild];\n            boolean iPossibleL = (narrowR <= narrowL);\n            if (!iPossibleL) {\n              continue;\n            }\n            int min1 = narrowR;\n", "outputs": ["            int min2 = wideLExtent[end][rightState];"], "input_length": 1668, "output_length": 11, "length": 1679, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "19c995afb185647571357993cfa3f0b3bc5bfcafcc452913e032270da10f631f"}
{"input": "", "context": "/**\n * Copyright (c) 2002-2012 \"Neo Technology,\"\n * Network Engine for Objects in Lund AB [http://neotechnology.com]\n *\n * This file is part of Neo4j.\n *\n * Neo4j is free software: you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation, either version 3 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program.  If not, see <http://www.gnu.org/licenses/>.\n */\npackage org.neo4j.graphmatching;\nimport java.util.Arrays;\nimport java.util.Collection;\nimport java.util.HashMap;\nimport java.util.HashSet;\nimport java.util.Map;\nimport java.util.Set;\nimport org.neo4j.graphdb.Node;\nimport org.neo4j.graphmatching.filter.AbstractFilterExpression;\nimport org.neo4j.graphmatching.filter.FilterBinaryNode;\nimport org.neo4j.graphmatching.filter.FilterExpression;\nimport org.neo4j.graphmatching.filter.FilterValueGetter;\nimport org.neo4j.helpers.Predicate;\nimport org.neo4j.helpers.collection.FilteringIterable;\n/**\n * The PatternMatcher is the engine that performs the matching of a graph\n * pattern with the actual graph.\n */\n@Deprecated\npublic class PatternMatcher\n{\n\tprivate static PatternMatcher matcher = new PatternMatcher();\n\tprivate PatternMatcher()\n\t{\n\t}\n    /**\n     * Get the sole instance of the {@link PatternMatcher}.\n     *\n     * @return the instance of {@link PatternMatcher}.\n     */\n\tpublic static PatternMatcher getMatcher()\n\t{\n\t\treturn matcher;\n\t}\n    /**\n     * Find occurrences of the pattern defined by the given {@link PatternNode}\n     * where the given {@link PatternNode} starts matching at the given\n     * {@link Node}.\n     *\n     * @param start the {@link PatternNode} to start matching at.\n     * @param startNode the {@link Node} to start matching at.\n     * @return all matching instances of the pattern.\n     */\n    public Iterable<PatternMatch> match( PatternNode start,\n        Node startNode )\n    {\n        return match( start, startNode, null );\n    }\n    /**\n     * Find occurrences of the pattern defined by the given {@link PatternNode}\n     * where the given {@link PatternNode} starts matching at the given\n     * {@link Node}.\n     *\n     * @param start the {@link PatternNode} to start matching at.\n     * @param startNode the {@link Node} to start matching at.\n     * @param objectVariables mapping from names to {@link PatternNode}s.\n     * @return all matching instances of the pattern.\n     */\n\tpublic Iterable<PatternMatch> match( PatternNode start,\n\t\tNode startNode, Map<String, PatternNode> objectVariables )\n\t{\n\t\treturn match( start, startNode, objectVariables,\n\t\t    ( Collection<PatternNode> ) null );\n\t}\n    /**\n     * Find occurrences of the pattern defined by the given {@link PatternNode}\n     * where the given {@link PatternNode} starts matching at the given\n     * {@link Node}.\n     *\n     * @param start the {@link PatternNode} to start matching at.\n     * @param objectVariables mapping from names to {@link PatternNode}s.\n     * @param optional nodes that form sub-patterns connected to this pattern.\n     * @return all matching instances of the pattern.\n     */\n    public Iterable<PatternMatch> match( PatternNode start,\n            Map<String, PatternNode> objectVariables,\n            PatternNode... optional )\n    {\n        return match( start, objectVariables,\n            Arrays.asList( optional ) );\n    }\n    /**\n     * Find occurrences of the pattern defined by the given {@link PatternNode}\n     * where the given {@link PatternNode} starts matching at the given\n     * {@link Node}.\n     *\n     * @param start the {@link PatternNode} to start matching at.\n     * @param objectVariables mapping from names to {@link PatternNode}s.\n     * @param optional nodes that form sub-patterns connected to this pattern.\n     * @return all matching instances of the pattern.\n     */\n\tpublic Iterable<PatternMatch> match( PatternNode start,\n\t        Map<String, PatternNode> objectVariables,\n\t        Collection<PatternNode> optional )\n    {\n\t    Node startNode = start.getAssociation();\n        if ( startNode == null )\n        {\n            throw new IllegalStateException(\n                    \"Associating node for start pattern node is null\" );\n        }\n\t    return match( start, startNode, objectVariables, optional );\n    }\n    /**\n     * Find occurrences of the pattern defined by the given {@link PatternNode}\n     * where the given {@link PatternNode} starts matching at the given\n     * {@link Node}.\n     *\n     * @param start the {@link PatternNode} to start matching at.\n     * @param startNode the {@link Node} to start matching at.\n     * @param objectVariables mapping from names to {@link PatternNode}s.\n     * @param optional nodes that form sub-patterns connected to this pattern.\n     * @return all matching instances of the pattern.\n     */\n\tpublic Iterable<PatternMatch> match( PatternNode start,\n\t\tNode startNode, Map<String, PatternNode> objectVariables,\n\t\tCollection<PatternNode> optional )\n\t{\n        Node currentStartNode = start.getAssociation();\n        if ( currentStartNode != null && !currentStartNode.equals( startNode ) )\n        {\n            throw new IllegalStateException(\n                    \"Start patter node already has associated \" +\n                    currentStartNode + \", can not start with \" + startNode );\n        }\n\t    Iterable<PatternMatch> result = null;\n\t\tif ( optional == null || optional.size() < 1 )\n\t\t{\n\t\t\tresult = new PatternFinder( this, start, startNode );\n\t\t}\n\t\telse\n\t\t{\n\t\t\tresult = new PatternFinder( this, start, startNode, false,\n\t\t\t    optional );\n\t\t}\n\t\tif ( objectVariables != null )\n\t\t{\n    \t\t// Uses the FILTER expressions\n    \t\tresult = new FilteredPatternFinder( result, objectVariables );\n\t\t}\n\t\treturn result;\n\t}\n    /**\n     * Find occurrences of the pattern defined by the given {@link PatternNode}\n     * where the given {@link PatternNode} starts matching at the given\n     * {@link Node}.\n     *\n     * @param start the {@link PatternNode} to start matching at.\n     * @param startNode the {@link Node} to start matching at.\n     * @param objectVariables mapping from names to {@link PatternNode}s.\n     * @param optional nodes that form sub-patterns connected to this pattern.\n     * @return all matching instances of the pattern.\n     */\n\tpublic Iterable<PatternMatch> match( PatternNode start,\n\t\tNode startNode, Map<String, PatternNode> objectVariables,\n\t\tPatternNode... optional )\n\t{\n\t\treturn match( start, startNode, objectVariables,\n\t\t    Arrays.asList( optional ) );\n\t}\n\tprivate static class SimpleRegexValueGetter implements FilterValueGetter\n\t{\n\t    private PatternMatch match;\n\t    private Map<String, PatternNode> labelToNode =\n\t        new HashMap<String, PatternNode>();\n\t    private Map<String, String> labelToProperty =\n\t        new HashMap<String, String>();\n\t    SimpleRegexValueGetter( Map<String, PatternNode> objectVariables,\n\t        PatternMatch match, FilterExpression[] expressions )\n\t    {\n            this.match = match;\n            for ( FilterExpression expression : expressions )\n            {\n                mapFromExpression( expression );\n            }\n            this.labelToNode = objectVariables;\n\t    }\n\t    private void mapFromExpression( FilterExpression expression )\n\t    {\n\t        if ( expression instanceof FilterBinaryNode )\n\t        {\n\t            FilterBinaryNode node = ( FilterBinaryNode ) expression;\n\t            mapFromExpression( node.getLeftExpression() );\n\t            mapFromExpression( node.getRightExpression() );\n\t        }\n\t        else\n\t        {\n\t            AbstractFilterExpression pattern =\n\t                ( AbstractFilterExpression ) expression;\n\t            labelToProperty.put( pattern.getLabel(),\n\t                pattern.getProperty() );\n\t        }\n\t    }\n        public String[] getValues( String label )\n        {\n            PatternNode pNode = labelToNode.get( label );\n            if ( pNode == null )\n            {\n                throw new RuntimeException( \"No node for label '\" + label +\n                    \"'\" );\n            }\n            Node node = this.match.getNodeFor( pNode );\n            String propertyKey = labelToProperty.get( label );\n            if ( propertyKey == null )\n            {\n                throw new RuntimeException( \"No property key for label '\" +\n                    label + \"'\" );\n            }\n            Object rawValue = node.getProperty( propertyKey, null );\n            if ( rawValue == null )\n            {\n                return new String[ 0 ];\n            }\n            Collection<Object> values =\n                ArrayPropertyUtil.propertyValueToCollection( rawValue );\n            String[] result = new String[ values.size() ];\n            int counter = 0;\n            for ( Object value : values )\n            {\n                result[ counter++ ] = ( String ) value;\n            }\n            return result;\n        }\n\t}\n\tprivate static class FilteredPatternFinder\n\t    extends FilteringIterable<PatternMatch>\n\t{\n        public FilteredPatternFinder( Iterable<PatternMatch> source,\n            final Map<String, PatternNode> objectVariables )\n        {\n", "outputs": ["            super( source, new Predicate<PatternMatch>()"], "input_length": 1601, "output_length": 11, "length": 1612, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "c99ee8c056cf53ca706858cf8ef6e1d0f0935909e2a327a1bfee1a31cd8ecebd"}
{"input": "", "context": "/*\n * Copyright (C) 2006-2010 - Frictional Games\n *\n * This file is part of HPL1 Engine.\n *\n * HPL1 Engine is free software: you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation, either version 3 of the License, or\n * (at your option) any later version.\n *\n * HPL1 Engine is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with HPL1 Engine.  If not, see <http://www.gnu.org/licenses/>.\n */\nusing System;\nusing System.Drawing;\nusing System.Collections;\nusing System.ComponentModel;\nusing System.Windows.Forms;\nnamespace Mapeditor\n{\n\t/// <summary>\n\t/// Summary description for PropertiesLightForm.\n\t/// </summary>\n\tpublic class frmPropertiesArea : System.Windows.Forms.Form\n\t{\n\t\tpublic bool mbOkWasPressed=false;\n\t\tcArea mArea;\n        private System.Windows.Forms.Label objNameLabel;\n\t\tprivate System.Windows.Forms.Label label1;\n\t\tpublic System.Windows.Forms.Button objOkButton;\n\t\tpublic System.Windows.Forms.Button objCancelButtom;\n\t\tpublic System.Windows.Forms.TextBox objNameText;\n\t\tprivate System.Windows.Forms.Label label6;\n\t\tpublic System.Windows.Forms.ComboBox objActiveBox;\n\t\tpublic System.Windows.Forms.TextBox objXText;\n\t\tprivate System.Windows.Forms.Label objXLabel;\n\t\tprivate System.Windows.Forms.Label objYLabel;\n\t\tprivate System.Windows.Forms.Label label3;\n\t\tpublic System.Windows.Forms.TextBox objZText;\n\t\tprivate System.Windows.Forms.Label label4;\n\t\tpublic System.Windows.Forms.ComboBox objTypeBox;\n\t\tprivate System.Windows.Forms.Label label5;\n\t\tpublic System.Windows.Forms.TextBox objYText;\n\t\tprivate System.Windows.Forms.Label objZLabel;\n\t\tpublic System.Windows.Forms.TextBox objWidthText;\n\t\tprivate System.Windows.Forms.Label label7;\n\t\tpublic System.Windows.Forms.TextBox objHeightText;\n\t\tprivate System.Windows.Forms.Label label8;\n\t\t/// <summary>\n\t\t/// Required designer variable.\n\t\t/// </summary>\n\t\tprivate System.ComponentModel.Container components = null;\n\t\tpublic frmPropertiesArea(cArea aArea)\n\t\t{\n\t\t\t//\n\t\t\t// Required for Windows Form Designer support\n\t\t\t//\n\t\t\tInitializeComponent();\n\t\t\t//\n\t\t\t// TODO: Add any constructor code after InitializeComponent call\n\t\t\t//\n\t\t\tmArea = aArea;\n\t\t\tobjNameText.Text = aArea.msName;\n\t\t\tobjActiveBox.SelectedIndex = aArea.mbActive?1:0;\n\t\t\t\n\t\t\tobjHeightText.Text = aArea.mfHeight.ToString();\n\t\t\tobjWidthText.Text = aArea.mfWidth.ToString();\n\t\t\t\n\t\t\tobjXLabel.Text = ((cAreaType)aArea.mAForm.mlstTypes[aArea.mlTypeNum]).msDesc[0];\n\t\t\tobjXText.Text = aArea.mfSizeX.ToString();\n\t\t\t\n\t\t\tobjYLabel.Text = ((cAreaType)aArea.mAForm.mlstTypes[aArea.mlTypeNum]).msDesc[1];\n\t\t\tobjYText.Text = aArea.mfSizeY.ToString();\n\t\t\t\n\t\t\tobjZLabel.Text = ((cAreaType)aArea.mAForm.mlstTypes[aArea.mlTypeNum]).msDesc[2];\n\t\t\tobjZText.Text = aArea.mfSizeZ.ToString();\n\t\t\t\n\t\t\tforeach(string sN in aArea.mAForm.objTypeList.Items)\n\t\t\t{\n\t\t\t\tobjTypeBox.Items.Add(sN);\n\t\t\t}\n\t\t\tobjTypeBox.SelectedIndex = aArea.mlTypeNum;\n\t   }\n\t\t/// <summary>\n\t\t/// Clean up any resources being used.\n\t\t/// </summary>\n\t\tprotected override void Dispose( bool disposing )\n\t\t{\n\t\t\tif( disposing )\n\t\t\t{\n\t\t\t\tif(components != null)\n\t\t\t\t{\n\t\t\t\t\tcomponents.Dispose();\n\t\t\t\t}\n\t\t\t}\n\t\t\tbase.Dispose( disposing );\n\t\t}\n\t\t#region Windows Form Designer generated code\n\t\t/// <summary>\n\t\t/// Required method for Designer support - do not modify\n\t\t/// the contents of this method with the code editor.\n\t\t/// </summary>\n\t\tprivate void InitializeComponent()\n\t\t{\n\t\t\tthis.objNameLabel = new System.Windows.Forms.Label();\n\t\t\tthis.label1 = new System.Windows.Forms.Label();\n\t\t\tthis.objNameText = new System.Windows.Forms.TextBox();\n\t\t\tthis.objXText = new System.Windows.Forms.TextBox();\n\t\t\tthis.objOkButton = new System.Windows.Forms.Button();\n\t\t\tthis.objCancelButtom = new System.Windows.Forms.Button();\n\t\t\tthis.objXLabel = new System.Windows.Forms.Label();\n\t\t\tthis.label6 = new System.Windows.Forms.Label();\n\t\t\tthis.objActiveBox = new System.Windows.Forms.ComboBox();\n\t\t\tthis.objYLabel = new System.Windows.Forms.Label();\n\t\t\tthis.objYText = new System.Windows.Forms.TextBox();\n\t\t\tthis.label3 = new System.Windows.Forms.Label();\n\t\t\tthis.objZLabel = new System.Windows.Forms.Label();\n\t\t\tthis.objZText = new System.Windows.Forms.TextBox();\n\t\t\tthis.label4 = new System.Windows.Forms.Label();\n\t\t\tthis.objTypeBox = new System.Windows.Forms.ComboBox();\n\t\t\tthis.label5 = new System.Windows.Forms.Label();\n\t\t\tthis.objWidthText = new System.Windows.Forms.TextBox();\n\t\t\tthis.label7 = new System.Windows.Forms.Label();\n\t\t\tthis.objHeightText = new System.Windows.Forms.TextBox();\n\t\t\tthis.label8 = new System.Windows.Forms.Label();\n\t\t\tthis.SuspendLayout();\n\t\t\t// \n\t\t\t// objNameLabel\n\t\t\t// \n\t\t\tthis.objNameLabel.Location = new System.Drawing.Point(16, 16);\n\t\t\tthis.objNameLabel.Name = \"objNameLabel\";\n\t\t\tthis.objNameLabel.Size = new System.Drawing.Size(64, 16);\n\t\t\tthis.objNameLabel.TabIndex = 0;\n\t\t\tthis.objNameLabel.Text = \"Name:\";\n\t\t\t// \n\t\t\t// label1\n\t\t\t// \n\t\t\tthis.label1.Location = new System.Drawing.Point(16, 200);\n\t\t\tthis.label1.Name = \"label1\";\n\t\t\tthis.label1.Size = new System.Drawing.Size(48, 16);\n\t\t\tthis.label1.TabIndex = 1;\n\t\t\tthis.label1.Text = \"Var X:\";\n\t\t\t// \n\t\t\t// objNameText\n\t\t\t// \n\t\t\tthis.objNameText.Location = new System.Drawing.Point(104, 16);\n\t\t\tthis.objNameText.MaxLength = 40;\n\t\t\tthis.objNameText.Name = \"objNameText\";\n\t\t\tthis.objNameText.Size = new System.Drawing.Size(104, 20);\n\t\t\tthis.objNameText.TabIndex = 3;\n\t\t\tthis.objNameText.Text = \"\";\n\t\t\t// \n\t\t\t// objXText\n\t\t\t// \n\t\t\tthis.objXText.Location = new System.Drawing.Point(104, 192);\n\t\t\tthis.objXText.MaxLength = 40;\n\t\t\tthis.objXText.Name = \"objXText\";\n\t\t\tthis.objXText.Size = new System.Drawing.Size(104, 20);\n\t\t\tthis.objXText.TabIndex = 4;\n\t\t\tthis.objXText.Text = \"\";\n\t\t\t// \n\t\t\t// objOkButton\n\t\t\t// \n\t\t\tthis.objOkButton.Location = new System.Drawing.Point(24, 432);\n\t\t\tthis.objOkButton.Name = \"objOkButton\";\n\t\t\tthis.objOkButton.Size = new System.Drawing.Size(72, 24);\n\t\t\tthis.objOkButton.TabIndex = 7;\n\t\t\tthis.objOkButton.Text = \"OK\";\n\t\t\tthis.objOkButton.Click += new System.EventHandler(this.objOkButton_Click);\n\t\t\t// \n\t\t\t// objCancelButtom\n\t\t\t// \n\t\t\tthis.objCancelButtom.Location = new System.Drawing.Point(120, 432);\n\t\t\tthis.objCancelButtom.Name = \"objCancelButtom\";\n\t\t\tthis.objCancelButtom.Size = new System.Drawing.Size(72, 24);\n\t\t\tthis.objCancelButtom.TabIndex = 8;\n\t\t\tthis.objCancelButtom.Text = \"Cancel\";\n\t\t\tthis.objCancelButtom.Click += new System.EventHandler(this.objCancelButtom_Click);\n\t\t\t// \n\t\t\t// objXLabel\n\t\t\t// \n\t\t\tthis.objXLabel.Font = new System.Drawing.Font(\"Microsoft Sans Serif\", 8.25F, System.Drawing.FontStyle.Italic, System.Drawing.GraphicsUnit.Point, ((System.Byte)(0)));\n\t\t\tthis.objXLabel.Location = new System.Drawing.Point(16, 160);\n\t\t\tthis.objXLabel.Name = \"objXLabel\";\n\t\t\tthis.objXLabel.Size = new System.Drawing.Size(200, 32);\n\t\t\tthis.objXLabel.TabIndex = 12;\n\t\t\tthis.objXLabel.Text = \"Description...\";\n\t\t\t// \n\t\t\t// label6\n\t\t\t// \n\t\t\tthis.label6.Location = new System.Drawing.Point(16, 48);\n\t\t\tthis.label6.Name = \"label6\";\n\t\t\tthis.label6.Size = new System.Drawing.Size(48, 16);\n\t\t\tthis.label6.TabIndex = 15;\n\t\t\tthis.label6.Text = \"Active:\";\n\t\t\t// \n\t\t\t// objActiveBox\n\t\t\t// \n\t\t\tthis.objActiveBox.Items.AddRange(new object[] {\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  \"False\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  \"True\"});\n\t\t\tthis.objActiveBox.Location = new System.Drawing.Point(104, 48);\n\t\t\tthis.objActiveBox.Name = \"objActiveBox\";\n\t\t\tthis.objActiveBox.Size = new System.Drawing.Size(104, 21);\n\t\t\tthis.objActiveBox.TabIndex = 16;\n\t\t\t// \n\t\t\t// objYLabel\n\t\t\t// \n\t\t\tthis.objYLabel.Font = new System.Drawing.Font(\"Microsoft Sans Serif\", 8.25F, System.Drawing.FontStyle.Italic, System.Drawing.GraphicsUnit.Point, ((System.Byte)(0)));\n\t\t\tthis.objYLabel.Location = new System.Drawing.Point(16, 224);\n\t\t\tthis.objYLabel.Name = \"objYLabel\";\n", "outputs": ["\t\t\tthis.objYLabel.Size = new System.Drawing.Size(200, 32);"], "input_length": 1158, "output_length": 10, "length": 1168, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "9292880f4ff5ead1eec499f1faccc61674c960cfe1f27cdd92a70b295cb3454a"}
{"input": "", "context": "# -*- coding: utf-8 -*-\n##\n## This file is part of Invenio.\n## Copyright (C) 2012, 2013 CERN.\n##\n## Invenio is free software; you can redistribute it and/or\n## modify it under the terms of the GNU General Public License as\n## published by the Free Software Foundation; either version 2 of the\n## License, or (at your option) any later version.\n##\n## Invenio is distributed in the hope that it will be useful, but\n## WITHOUT ANY WARRANTY; without even the implied warranty of\n## MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n## General Public License for more details.\n##\n## You should have received a copy of the GNU General Public License\n## along with Invenio; if not, write to the Free Software Foundation, Inc.,\n## 59 Temple Place, Suite 330, Boston, MA 02111-1307, USA.\nfrom invenio.legacy.dbquery import run_sql, OperationalError\nfrom six.moves import cPickle\nimport logging\ndepends_on = ['invenio_release_1_1_0']\nupdate_needed = True\ndef info():\n    return \"Change of the underlying data model allowing extended BibDocs and MoreInfo\"\ndef do_upgrade():\n    \"\"\" Implement your upgrades here  \"\"\"\n    logger = logging.getLogger('invenio_upgrader')\n    if update_needed:\n        _backup_tables(logger)\n        _update_database_structure_pre(logger)\n        recids = _retrieve_fulltext_recids()\n        for recid in recids:\n            if not _fix_recid(recid, logger):\n                logger.info(\"ERROR: Failed fixing the record %s\" % (str(recid)))\n        _update_database_structure_post(logger)\n    else:\n        logger.info(\"Update executed but not needed. skipping\")\ndef estimate():\n    \"\"\"  Estimate running time of upgrade in seconds (optional). \"\"\"\n    res = run_sql(\"select count(*) from bibdoc\")\n    if res:\n        return int(float(res[0][0]) / 40)\n    return 0\ndef pre_upgrade():\n    \"\"\"  Run pre-upgrade checks (optional). \"\"\"\n    # Example of raising errors:\n    res = run_sql(\"show create table bibdoc\")[0][1]\n    global update_needed\n    if not \"more_info\" in res:\n        update_needed = False\ndef post_upgrade():\n    \"\"\"  Run post-upgrade checks (optional). \"\"\"\n    # Example of issuing warnings:\n    # warnings.warn(\"A continuable error occurred\")\n    pass\n# private methods\ndef _update_database_structure_pre(logger):\n    \"\"\"This function alters the already existing database by adding additional columns ... the step from before modification\"\"\"\n    logger.info(\"Adding missing columns to tables\")\n    try:\n        run_sql(\"ALTER TABLE bibdoc ADD COLUMN doctype varchar(255) AFTER more_info\")\n    except Exception as e:\n        logger.info(\"WARNING: Problem when altering table. Is the database really in the state from before the upgrade ? \" + str(e))\n    try:\n        run_sql(\"ALTER TABLE bibdoc CHANGE COLUMN docname docname varchar(250) COLLATE utf8_bin default NULL\")\n    except Exception as e:\n        logger.info(\"WARNING: Problem when altering table. Is the database really in the state from before the upgrade ? \" + str(e))\n    try:\n        run_sql(\"ALTER TABLE bibrec_bibdoc ADD COLUMN docname varchar(250) COLLATE utf8_bin NOT NULL default 'file' AFTER id_bibdoc, ADD KEY docname(docname)\")\n    except Exception as e:\n        logger.info(\"WARNING: Problem when altering table. Is the database really in the state from before the upgrade ? \" + str(e))\n    try:\n        run_sql(\"ALTER TABLE bibdoc_bibdoc CHANGE COLUMN id_bibdoc1 id_bibdoc1 mediumint(9) unsigned DEFAULT NULL\")\n        run_sql(\"ALTER TABLE bibdoc_bibdoc CHANGE COLUMN id_bibdoc2 id_bibdoc2 mediumint(9) unsigned DEFAULT NULL\")\n        run_sql(\"ALTER TABLE bibdoc_bibdoc ADD COLUMN id mediumint(9) unsigned NOT NULL auto_increment FIRST, ADD COLUMN version1 tinyint(4) unsigned AFTER id_bibdoc1, ADD COLUMN format1 varchar(50) AFTER version1, ADD COLUMN version2 tinyint(4) unsigned AFTER id_bibdoc2, ADD COLUMN format2 varchar(50) AFTER version2, CHANGE COLUMN type rel_type varchar(255) AFTER format2, ADD KEY (id)\")\n    except Exception as e:\n        logger.info(\"WARNING: Problem when altering table. Is the database really in the state from before the upgrade ? \" + str(e))\n    run_sql(\"\"\"CREATE TABLE IF NOT EXISTS bibdocmoreinfo (\n        id_bibdoc mediumint(9) unsigned DEFAULT NULL,\n        version tinyint(4) unsigned DEFAULT NULL,\n        format VARCHAR(50) DEFAULT NULL,\n        id_rel mediumint(9) unsigned DEFAULT NULL,\n        namespace VARCHAR(25) DEFAULT NULL,\n        data_key VARCHAR(25),\n        data_value MEDIUMBLOB,\n        KEY (id_bibdoc, version, format, id_rel, namespace, data_key)\n    ) ENGINE=MyISAM;\"\"\")\ndef _update_database_structure_post(logger):\n    \"\"\"This function alters the already existing database by removing columns ... the step after the modification\"\"\"\n    logger.info(\"Removing unnecessary columns from tables\")\n    run_sql(\"ALTER TABLE bibdoc DROP COLUMN more_info\")\ndef _backup_tables(logger):\n    \"\"\"This function create a backup of bibrec_bibdoc, bibdoc and bibdoc_bibdoc tables. Returns False in case dropping of previous table is needed.\"\"\"\n    logger.info(\"droping old backup tables\")\n    run_sql('DROP TABLE IF EXISTS bibrec_bibdoc_backup_newdatamodel')\n    run_sql('DROP TABLE IF EXISTS bibdoc_backup_newdatamodel')\n    run_sql('DROP TABLE IF EXISTS bibdoc_bibdoc_backup_newdatamodel')\n    try:\n        run_sql(\"\"\"CREATE TABLE bibrec_bibdoc_backup_newdatamodel SELECT * FROM bibrec_bibdoc\"\"\")\n        run_sql(\"\"\"CREATE TABLE bibdoc_backup_newdatamodel SELECT * FROM bibdoc\"\"\")\n        run_sql(\"\"\"CREATE TABLE bibdoc_bibdoc_backup_newdatamodel SELECT * FROM bibdoc_bibdoc\"\"\")\n    except OperationalError as e:\n        logger.info(\"Problem when backing up tables\")\n        raise\n    return True\ndef _retrieve_fulltext_recids():\n    \"\"\"Returns the list of all the recid number linked with at least a fulltext\n    file.\"\"\"\n    res = run_sql('SELECT DISTINCT id_bibrec FROM bibrec_bibdoc')\n    return [int(x[0]) for x in res]\ndef _fix_recid(recid, logger):\n    \"\"\"Fix a given recid.\"\"\"\n    #logger.info(\"Upgrading record %s:\" % recid)\n    # 1) moving docname and type to the relation with bibrec\n    bibrec_docs = run_sql(\"select id_bibdoc, type from bibrec_bibdoc where id_bibrec=%s\", (recid, ))\n    are_equal = True\n    for docid_str in bibrec_docs:\n        docid = str(docid_str[0])\n        doctype = str(docid_str[1])\n        #logger.info(\"Upgrading document %s:\" % (docid, ))\n        res2 = run_sql(\"select docname, more_info from bibdoc where id=%s\", (docid,))\n        if not res2:\n            logger.error(\"Error when migrating document %s attached to the record %s: can not retrieve from the bibdoc table \" % (docid, recid))\n        else:\n            docname = str(res2[0][0])\n            run_sql(\"update bibrec_bibdoc set docname=%%s where id_bibrec=%s and id_bibdoc=%s\" % (str(recid), docid), (docname, ))\n            run_sql(\"update bibdoc set doctype=%%s where id=%s\" % (docid,), (doctype, ))\n        # 2) moving moreinfo to the new moreinfo structures (default namespace)\n        if res2[0][1]:\n            minfo = cPickle.loads(res2[0][1])\n            # 2a migrating descriptions->version->format\n            new_value = cPickle.dumps(minfo['descriptions'])\n            run_sql(\"INSERT INTO bibdocmoreinfo (id_bibdoc, namespace, data_key, data_value) VALUES (%s, %s, %s, %s)\", (str(docid), \"\", \"descriptions\", new_value))\n            # 2b migrating comments->version->format\n            new_value = cPickle.dumps(minfo['comments'])\n            run_sql(\"INSERT INTO bibdocmoreinfo (id_bibdoc, namespace, data_key, data_value) VALUES (%s, %s, %s, %s)\", (str(docid), \"\", \"comments\", new_value))\n            # 2c migrating flags->flagname->version->format\n            new_value = cPickle.dumps(minfo['flags'])\n            run_sql(\"INSERT INTO bibdocmoreinfo (id_bibdoc, namespace, data_key, data_value) VALUES (%s, %s, %s, %s)\", (str(docid), \"\", \"flags\", new_value))\n            # 3) Verify the correctness of moreinfo transformations\n            try:\n                descriptions = cPickle.loads(run_sql(\"SELECT data_value FROM bibdocmoreinfo WHERE id_bibdoc=%s AND namespace=%s AND data_key=%s\", (str(docid), '', 'descriptions'))[0][0])\n                for version in minfo['descriptions']:\n                    for docformat in minfo['descriptions'][version]:\n                        v1 = descriptions[version][docformat]\n                        v2 = minfo['descriptions'][version][docformat]\n                        if v1 != v2:\n                            are_equal = False\n                            logger.info(\"ERROR: Document %s: Expected description %s and got %s\" % (str(docid), str(v2), str(v1)))\n            except Exception as e:\n                logger.info(\"ERROR: Document %s: Problem with retrieving descriptions: %s  MoreInfo: %s Descriptions: %s\" % (str(docid), str(e), str(minfo), str(descriptions)))\n            try:\n                comments = cPickle.loads(run_sql(\"SELECT data_value FROM bibdocmoreinfo WHERE id_bibdoc=%s AND namespace=%s AND data_key=%s\", (str(docid), '', 'comments'))[0][0])\n                for version in minfo['comments']:\n                    for docformat in minfo['comments'][version]:\n                        v1 = comments[version][docformat]\n                        v2 = minfo['comments'][version][docformat]\n                        if v1 != v2:\n                            are_equal = False\n                            logger.info(\"ERROR: Document %s: Expected comment %s and got %s\" % (str(docid), str(v2), str(v1)))\n            except Exception as e:\n                logger.info(\"ERROR: Document %s: Problem with retrieving comments: %s MoreInfo: %s  Comments: %s\" % (str(docid), str(e), str(minfo), str(comments)))\n            try:\n                flags = cPickle.loads(run_sql(\"SELECT data_value FROM bibdocmoreinfo WHERE id_bibdoc=%s AND namespace=%s AND data_key=%s\", (str(docid), '', 'flags'))[0][0])\n                for flagname in minfo['flags']:\n                    for version in minfo['flags'][flagname]:\n                        for docformat in minfo['flags'][flagname][version]:\n                            if minfo['flags'][flagname][version][docformat]:\n                                are_equal = are_equal and (docformat in flags[flagname][version])\n", "outputs": ["                                if not (docformat in flags[flagname][version]):"], "input_length": 2129, "output_length": 14, "length": 2143, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "bc73c792794bb99a11d5ea89881572d84196d16296e23138ab4233d0b7eabc99"}
{"input": "", "context": "\"\"\"\nFixture to create a course and course components (XBlocks).\n\"\"\"\nimport datetime\nimport json\nimport mimetypes\nfrom collections import namedtuple\nfrom textwrap import dedent\nimport six\nfrom opaque_keys.edx.keys import CourseKey\nfrom path import Path\nfrom common.test.acceptance.fixtures import STUDIO_BASE_URL\nfrom common.test.acceptance.fixtures.base import FixtureError, XBlockContainerFixture\nclass XBlockFixtureDesc(object):\n    \"\"\"\n    Description of an XBlock, used to configure a course fixture.\n    \"\"\"\n    def __init__(self, category, display_name, data=None,\n                 metadata=None, grader_type=None, publish='make_public', **kwargs):\n        \"\"\"\n        Configure the XBlock to be created by the fixture.\n        These arguments have the same meaning as in the Studio REST API:\n            * `category`\n            * `display_name`\n            * `data`\n            * `metadata`\n            * `grader_type`\n            * `publish`\n        \"\"\"\n        self.category = category\n        self.display_name = display_name\n        self.data = data\n        self.metadata = metadata\n        self.grader_type = grader_type\n        self.publish = publish\n        self.children = []\n        self.locator = None\n        self.fields = kwargs\n    def add_children(self, *args):\n        \"\"\"\n        Add child XBlocks to this XBlock.\n        Each item in `args` is an `XBlockFixtureDesc` object.\n        Returns the `xblock_desc` instance to allow chaining.\n        \"\"\"\n        self.children.extend(args)\n        return self\n    def serialize(self):\n        \"\"\"\n        Return a JSON representation of the XBlock, suitable\n        for sending as POST data to /xblock\n        XBlocks are always set to public visibility.\n        \"\"\"\n        returned_data = {\n            'display_name': self.display_name,\n            'data': self.data,\n            'metadata': self.metadata,\n            'graderType': self.grader_type,\n            'publish': self.publish,\n            'fields': self.fields,\n        }\n        return json.dumps(returned_data)\n    def __str__(self):\n        \"\"\"\n        Return a string representation of the description.\n        Useful for error messages.\n        \"\"\"\n        return dedent(u\"\"\"\n            <XBlockFixtureDescriptor:\n                category={0},\n                data={1},\n                metadata={2},\n                grader_type={3},\n                publish={4},\n                children={5},\n                locator={6},\n            >\n        \"\"\").strip().format(\n            self.category, self.data, self.metadata,\n            self.grader_type, self.publish, self.children, self.locator\n        )\n# Description of course updates to add to the course\n# `date` is a str (e.g. \"January 29, 2014)\n# `content` is also a str (e.g. \"Test course\")\nCourseUpdateDesc = namedtuple(\"CourseUpdateDesc\", ['date', 'content'])\nclass CourseFixture(XBlockContainerFixture):\n    \"\"\"\n    Fixture for ensuring that a course exists.\n    WARNING: This fixture is NOT idempotent.  To avoid conflicts\n    between tests, you should use unique course identifiers for each fixture.\n    \"\"\"\n    def __init__(self, org, number, run, display_name, start_date=None, end_date=None, settings=None):\n        \"\"\"\n        Configure the course fixture to create a course with\n        `org`, `number`, `run`, and `display_name` (all unicode).\n        `start_date` and `end_date` are datetime objects indicating the course start and end date.\n        The default is for the course to have started in the distant past, which is generally what\n        we want for testing so students can enroll.\n        `settings` can be any additional course settings needs to be enabled. for example\n        to enable entrance exam settings would be a dict like this {\"entrance_exam_enabled\": \"true\"}\n        These have the same meaning as in the Studio restful API /course end-point.\n        \"\"\"\n        super(CourseFixture, self).__init__()  # lint-amnesty, pylint: disable=super-with-arguments\n        self._course_dict = {\n            'org': org,\n            'number': number,\n            'run': run,\n            'display_name': display_name\n        }\n        # Set a default start date to the past, but use Studio's\n        # default for the end date (meaning we don't set it here)\n        if start_date is None:\n            start_date = datetime.datetime(1970, 1, 1)\n        self._course_details = {\n            'start_date': start_date.isoformat(),\n        }\n        if end_date is not None:\n            self._course_details['end_date'] = end_date.isoformat()\n        if settings is not None:\n            self._course_details.update(settings)\n        self._updates = []\n        self._handouts = []\n        self._assets = []\n        self._textbooks = []\n        self._advanced_settings = {}\n        self._course_key = None\n    def __str__(self):\n        \"\"\"\n        String representation of the course fixture, useful for debugging.\n        \"\"\"\n        return u\"<CourseFixture: org='{org}', number='{number}', run='{run}'>\".format(**self._course_dict)\n    def add_course_details(self, course_details):\n        \"\"\"\n        Add course details to dict of course details to be updated when configure_course or install is called.\n        Arguments:\n            Dictionary containing key value pairs for course updates,\n            e.g. {'start_date': datetime.now() }\n        \"\"\"\n        if 'start_date' in course_details:\n            course_details['start_date'] = course_details['start_date'].isoformat()\n        if 'end_date' in course_details:\n            course_details['end_date'] = course_details['end_date'].isoformat()\n        self._course_details.update(course_details)\n    def add_update(self, update):\n        \"\"\"\n        Add an update to the course.  `update` should be a `CourseUpdateDesc`.\n        \"\"\"\n        self._updates.append(update)\n    def add_handout(self, asset_name):\n        \"\"\"\n        Add the handout named `asset_name` to the course info page.\n        Note that this does not actually *create* the static asset; it only links to it.\n        \"\"\"\n        self._handouts.append(asset_name)\n    def add_asset(self, asset_name):\n        \"\"\"\n        Add the asset to the list of assets to be uploaded when the install method is called.\n        \"\"\"\n        self._assets.extend(asset_name)\n    def add_textbook(self, book_title, chapters):\n        \"\"\"\n        Add textbook to the list of textbooks to be added when the install method is called.\n        \"\"\"\n        self._textbooks.append({\"chapters\": chapters, \"tab_title\": book_title})\n    def add_advanced_settings(self, settings):\n        \"\"\"\n        Adds advanced settings to be set on the course when the install method is called.\n        \"\"\"\n        self._advanced_settings.update(settings)\n    def install(self):\n        \"\"\"\n        Create the course and XBlocks within the course.\n        This is NOT an idempotent method; if the course already exists, this will\n        raise a `FixtureError`.  You should use unique course identifiers to avoid\n        conflicts between tests.\n        \"\"\"\n        self._create_course()\n        self._install_course_updates()\n        self._install_course_handouts()\n        self._install_course_textbooks()\n        self._configure_course()\n        self._upload_assets()\n        self._add_advanced_settings()\n        self._create_xblock_children(self._course_location, self.children)\n        return self\n    def configure_course(self):\n        \"\"\"\n        Configure Course Settings, take new course settings from self._course_details dict object\n        \"\"\"\n        self._configure_course()\n    @property\n    def studio_course_outline_as_json(self):\n        \"\"\"\n        Retrieves Studio course outline in JSON format.\n        \"\"\"\n        url = STUDIO_BASE_URL + '/course/' + self._course_key + \"?format=json\"\n        response = self.session.get(url, headers=self.headers)\n        if not response.ok:\n            raise FixtureError(\n                u\"Could not retrieve course outline json.  Status was {0}\".format(\n                    response.status_code))\n        try:\n            course_outline_json = response.json()\n        except ValueError:\n            raise FixtureError(  # lint-amnesty, pylint: disable=raise-missing-from\n                u\"Could not decode course outline as JSON: '{0}'\".format(response)\n            )\n        return course_outline_json\n    @property\n    def _course_location(self):\n        \"\"\"\n        Return the locator string for the course.\n        \"\"\"\n", "outputs": ["        course_key = CourseKey.from_string(self._course_key)"], "input_length": 1381, "output_length": 6, "length": 1387, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "79b89c994d01cbd9c169c14ed3abaf0fe4bbb40bb9c144886ce03668c1585b1a"}
{"input": "", "context": "\"\"\"\nGather information about a system and report it using plugins\nsupplied for application-specific information\n\"\"\"\n# sosreport.py\n# gather information about a system and report it\n# Copyright (C) 2006 Steve Conklin <sconklin@redhat.com>\n# This program is free software; you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation; either version 2 of the License, or\n# (at your option) any later version.\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n# You should have received a copy of the GNU General Public License\n# along with this program; if not, write to the Free Software\n# Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.\nimport sys\nimport traceback\nimport os\nimport errno\nimport logging\nfrom optparse import OptionParser, Option\nfrom sos.plugins import import_plugin\nfrom sos.utilities import ImporterHelper\nfrom stat import ST_UID, ST_GID, ST_MODE, ST_CTIME, ST_ATIME, ST_MTIME, S_IMODE\nfrom time import strftime, localtime\nfrom collections import deque\nimport tempfile\nfrom sos import _sos as _\nfrom sos import __version__\nimport sos.policies\nfrom sos.archive import TarFileArchive, ZipFileArchive\nfrom sos.reporting import (Report, Section, Command, CopiedFile, CreatedFile,\n                           Alert, Note, PlainTextReport)\n# PYCOMPAT\nimport six\nfrom six.moves import zip, input\nif six.PY3:\n    from configparser import ConfigParser\nelse:\n    from ConfigParser import ConfigParser\nfrom six import print_\n# file system errors that should terminate a run\nfatal_fs_errors = (errno.ENOSPC, errno.EROFS)\ndef _format_list(first_line, items, indent=False):\n    lines = []\n    line = first_line\n    if indent:\n        newline = len(first_line) * ' '\n    else:\n        newline = \"\"\n    for item in items:\n        if len(line) + len(item) + 2 > 72:\n            lines.append(line)\n            line = newline\n        line = line + item + ', '\n    if line[-2:] == ', ':\n        line = line[:-2]\n    lines.append(line)\n    return lines\nclass TempFileUtil(object):\n    def __init__(self, tmp_dir):\n        self.tmp_dir = tmp_dir\n        self.files = []\n    def new(self):\n        fd, fname = tempfile.mkstemp(dir=self.tmp_dir)\n        fobj = open(fname, 'w')\n        self.files.append((fname, fobj))\n        return fobj\n    def clean(self):\n        for fname, f in self.files:\n            try:\n                f.flush()\n                f.close()\n            except Exception:\n                pass\n            try:\n                os.unlink(fname)\n            except Exception:\n                pass\n        self.files = []\nclass OptionParserExtended(OptionParser):\n    \"\"\" Show examples \"\"\"\n    def print_help(self, out=sys.stdout):\n        \"\"\" Prints help content including examples \"\"\"\n        OptionParser.print_help(self, out)\n        print_()\n        print_(\"Some examples:\")\n        print_()\n        print_(\" enable cluster plugin only and collect dlm lockdumps:\")\n        print_(\"   # sosreport -o cluster -k cluster.lockdump\")\n        print_()\n        print_(\" disable memory and samba plugins, turn off rpm -Va \"\n               \"collection:\")\n        print_(\"   # sosreport -n memory,samba -k rpm.rpmva=off\")\n        print_()\nclass SosOption(Option):\n    \"\"\"Allow to specify comma delimited list of plugins\"\"\"\n    ACTIONS = Option.ACTIONS + (\"extend\",)\n    STORE_ACTIONS = Option.STORE_ACTIONS + (\"extend\",)\n    TYPED_ACTIONS = Option.TYPED_ACTIONS + (\"extend\",)\n    def take_action(self, action, dest, opt, value, values, parser):\n        \"\"\" Performs list extension on plugins \"\"\"\n        if action == \"extend\":\n            try:\n                lvalue = value.split(\",\")\n            except:\n                pass\n            else:\n                values.ensure_value(dest, deque()).extend(lvalue)\n        else:\n            Option.take_action(self, action, dest, opt, value, values, parser)\nclass XmlReport(object):\n    \"\"\" Report build class \"\"\"\n    def __init__(self):\n        try:\n            import libxml2\n        except ImportError:\n            self.enabled = False\n            return\n        else:\n            self.enabled = False\n            return\n        self.doc = libxml2.newDoc(\"1.0\")\n        self.root = self.doc.newChild(None, \"sos\", None)\n        self.commands = self.root.newChild(None, \"commands\", None)\n        self.files = self.root.newChild(None, \"files\", None)\n    def add_command(self, cmdline, exitcode, stdout=None, stderr=None,\n                    f_stdout=None, f_stderr=None, runtime=None):\n        \"\"\" Appends command run into report \"\"\"\n        if not self.enabled:\n            return\n        cmd = self.commands.newChild(None, \"cmd\", None)\n        cmd.setNsProp(None, \"cmdline\", cmdline)\n        cmdchild = cmd.newChild(None, \"exitcode\", str(exitcode))\n        if runtime:\n            cmd.newChild(None, \"runtime\", str(runtime))\n        if stdout or f_stdout:\n            cmdchild = cmd.newChild(None, \"stdout\", stdout)\n            if f_stdout:\n                cmdchild.setNsProp(None, \"file\", f_stdout)\n        if stderr or f_stderr:\n            cmdchild = cmd.newChild(None, \"stderr\", stderr)\n            if f_stderr:\n                cmdchild.setNsProp(None, \"file\", f_stderr)\n    def add_file(self, fname, stats):\n        \"\"\" Appends file(s) added to report \"\"\"\n        if not self.enabled:\n            return\n        cfile = self.files.newChild(None, \"file\", None)\n        cfile.setNsProp(None, \"fname\", fname)\n        cchild = cfile.newChild(None, \"uid\", str(stats[ST_UID]))\n        cchild = cfile.newChild(None, \"gid\", str(stats[ST_GID]))\n        cfile.newChild(None, \"mode\", str(oct(S_IMODE(stats[ST_MODE]))))\n        cchild = cfile.newChild(None, \"ctime\",\n                                strftime('%a %b %d %H:%M:%S %Y',\n                                         localtime(stats[ST_CTIME])))\n        cchild.setNsProp(None, \"tstamp\", str(stats[ST_CTIME]))\n        cchild = cfile.newChild(None, \"atime\",\n                                strftime('%a %b %d %H:%M:%S %Y',\n                                         localtime(stats[ST_ATIME])))\n        cchild.setNsProp(None, \"tstamp\", str(stats[ST_ATIME]))\n        cchild = cfile.newChild(None, \"mtime\",\n                                strftime('%a %b %d %H:%M:%S %Y',\n                                         localtime(stats[ST_MTIME])))\n        cchild.setNsProp(None, \"tstamp\", str(stats[ST_MTIME]))\n    def serialize(self):\n        \"\"\" Serializes xml \"\"\"\n        if not self.enabled:\n            return\n        self.ui_log.info(self.doc.serialize(None,  1))\n    def serialize_to_file(self, fname):\n        \"\"\" Serializes to file \"\"\"\n        if not self.enabled:\n            return\n        outf = tempfile.NamedTemporaryFile()\n        outf.write(self.doc.serialize(None, 1))\n        outf.flush()\n        self.archive.add_file(outf.name, dest=fname)\n        outf.close()\nclass SoSOptions(object):\n    _list_plugins = False\n    _noplugins = []\n    _enableplugins = []\n    _onlyplugins = []\n    _plugopts = []\n    _usealloptions = False\n    _all_logs = False\n    _log_size = 10\n    _batch = False\n    _build = False\n    _verbosity = 0\n    _verify = False\n    _quiet = False\n    _debug = False\n    _case_id = \"\"\n    _customer_name = \"\"\n    _profiles = deque()\n    _list_profiles = False\n    _config_file = \"\"\n    _tmp_dir = \"\"\n    _report = True\n    _compression_type = 'auto'\n    _options = None\n    def __init__(self, args=None):\n        if args:\n            self._options = self._parse_args(args)\n        else:\n            self._options = None\n    def _check_options_initialized(self):\n        if self._options is not None:\n            raise ValueError(\"SoSOptions object already initialized \"\n                             + \"from command line\")\n    @property\n    def list_plugins(self):\n        if self._options is not None:\n            return self._options.list_plugins\n        return self._list_plugins\n    @list_plugins.setter\n    def list_plugins(self, value):\n        self._check_options_initialized()\n        if not isinstance(value, bool):\n            raise TypeError(\"SoSOptions.list_plugins expects a boolean\")\n        self._list_plugins = value\n    @property\n    def noplugins(self):\n        if self._options is not None:\n            return self._options.noplugins\n        return self._noplugins\n    @noplugins.setter\n    def noplugins(self, value):\n        self._check_options_initialized()\n        self._noplugins = value\n    @property\n    def enableplugins(self):\n        if self._options is not None:\n            return self._options.enableplugins\n        return self._enableplugins\n    @enableplugins.setter\n    def enableplugins(self, value):\n        self._check_options_initialized()\n        self._enableplugins = value\n    @property\n    def onlyplugins(self):\n        if self._options is not None:\n            return self._options.onlyplugins\n        return self._onlyplugins\n    @onlyplugins.setter\n    def onlyplugins(self, value):\n        self._check_options_initialized()\n        self._onlyplugins = value\n    @property\n    def plugopts(self):\n        if self._options is not None:\n            return self._options.plugopts\n        return self._plugopts\n    @plugopts.setter\n    def plugopts(self, value):\n        # If we check for anything it should be itterability.\n        # if not isinstance(value, list):\n        #    raise TypeError(\"SoSOptions.plugopts expects a list\")\n        self._plugopts = value\n    @property\n    def usealloptions(self):\n        if self._options is not None:\n            return self._options.usealloptions\n        return self._usealloptions\n    @usealloptions.setter\n    def usealloptions(self, value):\n        self._check_options_initialized()\n        if not isinstance(value, bool):\n            raise TypeError(\"SoSOptions.usealloptions expects a boolean\")\n        self._usealloptions = value\n    @property\n    def all_logs(self):\n        if self._options is not None:\n            return self._options.all_logs\n        return self._all_logs\n    @all_logs.setter\n    def all_logs(self, value):\n        self._check_options_initialized()\n        if not isinstance(value, bool):\n            raise TypeError(\"SoSOptions.all_logs expects a boolean\")\n        self._all_logs = value\n    @property\n    def log_size(self):\n        if self._options is not None:\n            return self._options.log_size\n        return self._log_size\n    @log_size.setter\n    def log_size(self, value):\n        self._check_options_initialized()\n        if value < 0:\n            raise ValueError(\"SoSOptions.log_size expects a value greater \"\n                             \"than zero\")\n        self._log_size = value\n    @property\n    def batch(self):\n        if self._options is not None:\n            return self._options.batch\n        return self._batch\n    @batch.setter\n    def batch(self, value):\n        self._check_options_initialized()\n        if not isinstance(value, bool):\n            raise TypeError(\"SoSOptions.batch expects a boolean\")\n        self._batch = value\n    @property\n    def build(self):\n        if self._options is not None:\n            return self._options.build\n        return self._build\n    @build.setter\n    def build(self, value):\n        self._check_options_initialized()\n        if not isinstance(value, bool):\n            raise TypeError(\"SoSOptions.build expects a boolean\")\n        self._build = value\n    @property\n    def verbosity(self):\n        if self._options is not None:\n            return self._options.verbosity\n        return self._verbosity\n    @verbosity.setter\n    def verbosity(self, value):\n        self._check_options_initialized()\n        if value < 0 or value > 3:\n            raise ValueError(\"SoSOptions.verbosity expects a value [0..3]\")\n        self._verbosity = value\n    @property\n    def verify(self):\n        if self._options is not None:\n            return self._options.verify\n        return self._verify\n    @verify.setter\n    def verify(self, value):\n        self._check_options_initialized()\n        if value < 0 or value > 3:\n            raise ValueError(\"SoSOptions.verify expects a value [0..3]\")\n        self._verify = value\n    @property\n    def quiet(self):\n        if self._options is not None:\n            return self._options.quiet\n        return self._quiet\n    @quiet.setter\n    def quiet(self, value):\n        self._check_options_initialized()\n        if not isinstance(value, bool):\n            raise TypeError(\"SoSOptions.quiet expects a boolean\")\n        self._quiet = value\n    @property\n    def debug(self):\n        if self._options is not None:\n            return self._options.debug\n        return self._debug\n    @debug.setter\n    def debug(self, value):\n        self._check_options_initialized()\n        if not isinstance(value, bool):\n            raise TypeError(\"SoSOptions.debug expects a boolean\")\n        self._debug = value\n    @property\n    def case_id(self):\n        if self._options is not None:\n            return self._options.case_id\n        return self._case_id\n    @case_id.setter\n    def case_id(self, value):\n        self._check_options_initialized()\n        self._case_id = value\n    @property\n    def customer_name(self):\n        if self._options is not None:\n            return self._options.customer_name\n        return self._customer_name\n    @customer_name.setter\n    def customer_name(self, value):\n        self._check_options_initialized()\n        self._customer_name = value\n    @property\n    def profiles(self):\n        if self._options is not None:\n            return self._options.profiles\n        return self._profiles\n    @profiles.setter\n    def profiles(self, value):\n        self._check_options_initialized()\n        self._profiles = value\n    @property\n    def list_profiles(self):\n        if self._options is not None:\n            return self._options.list_profiles\n        return self._list_profiles\n    @list_profiles.setter\n    def list_profiles(self, value):\n        self._check_options_initialized()\n        self._list_profiles = value\n    @property\n    def config_file(self):\n        if self._options is not None:\n            return self._options.config_file\n        return self._config_file\n    @config_file.setter\n    def config_file(self, value):\n        self._check_options_initialized()\n        self._config_file = value\n    @property\n    def tmp_dir(self):\n        if self._options is not None:\n            return self._options.tmp_dir\n        return self._tmp_dir\n    @tmp_dir.setter\n    def tmp_dir(self, value):\n        self._check_options_initialized()\n        self._tmp_dir = value\n    @property\n    def report(self):\n        if self._options is not None:\n            return self._options.report\n        return self._report\n    @report.setter\n    def report(self, value):\n        self._check_options_initialized()\n        if not isinstance(value, bool):\n            raise TypeError(\"SoSOptions.report expects a boolean\")\n        self._report = value\n    @property\n    def compression_type(self):\n        if self._options is not None:\n            return self._options.compression_type\n        return self._compression_type\n    @compression_type.setter\n    def compression_type(self, value):\n        self._check_options_initialized()\n        self._compression_type = value\n    def _parse_args(self, args):\n        \"\"\" Parse command line options and arguments\"\"\"\n        self.parser = parser = OptionParserExtended(option_class=SosOption)\n        parser.add_option(\"-l\", \"--list-plugins\", action=\"store_true\",\n                          dest=\"list_plugins\", default=False,\n                          help=\"list plugins and available plugin options\")\n        parser.add_option(\"-n\", \"--skip-plugins\", action=\"extend\",\n                          dest=\"noplugins\", type=\"string\",\n                          help=\"disable these plugins\", default=deque())\n        parser.add_option(\"-e\", \"--enable-plugins\", action=\"extend\",\n                          dest=\"enableplugins\", type=\"string\",\n                          help=\"enable these plugins\", default=deque())\n        parser.add_option(\"-o\", \"--only-plugins\", action=\"extend\",\n                          dest=\"onlyplugins\", type=\"string\",\n                          help=\"enable these plugins only\", default=deque())\n        parser.add_option(\"-k\", \"--plugin-option\", action=\"extend\",\n                          dest=\"plugopts\", type=\"string\",\n                          help=\"plugin options in plugname.option=value \"\n                               \"format (see -l)\",\n                          default=deque())\n        parser.add_option(\"--log-size\", action=\"store\",\n                          dest=\"log_size\", default=10, type=\"int\",\n                          help=\"set a limit on the size of collected logs\")\n        parser.add_option(\"-a\", \"--alloptions\", action=\"store_true\",\n                          dest=\"usealloptions\", default=False,\n                          help=\"enable all options for loaded plugins\")\n        parser.add_option(\"--all-logs\", action=\"store_true\",\n                          dest=\"all_logs\", default=False,\n                          help=\"collect all available logs regardless of size\")\n        parser.add_option(\"--batch\", action=\"store_true\",\n                          dest=\"batch\", default=False,\n                          help=\"batch mode - do not prompt interactively\")\n        parser.add_option(\"--build\", action=\"store_true\",\n                          dest=\"build\", default=False,\n                          help=\"preserve the temporary directory and do not \"\n                               \"package results\")\n        parser.add_option(\"-v\", \"--verbose\", action=\"count\",\n                          dest=\"verbosity\",\n                          help=\"increase verbosity\")\n        parser.add_option(\"\", \"--verify\", action=\"store_true\",\n                          dest=\"verify\", default=False,\n                          help=\"perform data verification during collection\")\n        parser.add_option(\"\", \"--quiet\", action=\"store_true\",\n                          dest=\"quiet\", default=False,\n                          help=\"only print fatal errors\")\n        parser.add_option(\"--debug\", action=\"count\",\n                          dest=\"debug\",\n                          help=\"enable interactive debugging using the python \"\n                               \"debugger\")\n        parser.add_option(\"--ticket-number\", action=\"store\",\n                          dest=\"case_id\",\n                          help=\"specify ticket number\")\n        parser.add_option(\"--case-id\", action=\"store\",\n                          dest=\"case_id\",\n                          help=\"specify case identifier\")\n        parser.add_option(\"-p\", \"--profile\", action=\"extend\",\n                          dest=\"profiles\", type=\"string\", default=deque(),\n                          help=\"enable plugins selected by the given profiles\")\n        parser.add_option(\"--list-profiles\", action=\"store_true\",\n                          dest=\"list_profiles\", default=False)\n        parser.add_option(\"--name\", action=\"store\",\n                          dest=\"customer_name\",\n                          help=\"specify report name\")\n        parser.add_option(\"--config-file\", action=\"store\",\n                          dest=\"config_file\",\n                          help=\"specify alternate configuration file\")\n        parser.add_option(\"--tmp-dir\", action=\"store\",\n                          dest=\"tmp_dir\",\n                          help=\"specify alternate temporary directory\",\n                          default=None)\n        parser.add_option(\"--no-report\", action=\"store_true\",\n                          dest=\"report\",\n                          help=\"Disable HTML/XML reporting\", default=False)\n        parser.add_option(\"-z\", \"--compression-type\", dest=\"compression_type\",\n                          help=\"compression technology to use [auto, zip, \"\n                               \"gzip, bzip2, xz] (default=auto)\",\n                          default=\"auto\")\n        return parser.parse_args(args)[0]\nclass SoSReport(object):\n    \"\"\"The main sosreport class\"\"\"\n    def __init__(self, args):\n        self.loaded_plugins = deque()\n        self.skipped_plugins = deque()\n        self.all_options = deque()\n        self.xml_report = XmlReport()\n        self.global_plugin_options = {}\n        self.archive = None\n        self.tempfile_util = None\n        self._args = args\n        try:\n            import signal\n            signal.signal(signal.SIGTERM, self.get_exit_handler())\n        except Exception:\n            pass  # not available in java, but we don't care\n        self.opts = SoSOptions(args)\n        self._set_debug()\n        self._read_config()\n        try:\n            self.policy = sos.policies.load()\n        except KeyboardInterrupt:\n            self._exit(0)\n        self._is_root = self.policy.is_root()\n        self.tmpdir = os.path.abspath(\n            self.policy.get_tmp_dir(self.opts.tmp_dir))\n        if not os.path.isdir(self.tmpdir) \\\n                or not os.access(self.tmpdir, os.W_OK):\n            # write directly to stderr as logging is not initialised yet\n            sys.stderr.write(\"temporary directory %s \" % self.tmpdir\n                             + \"does not exist or is not writable\\n\")\n            self._exit(1)\n        self.tempfile_util = TempFileUtil(self.tmpdir)\n        self._set_directories()\n    def print_header(self):\n        self.ui_log.info(\"\\n%s\\n\" % _(\"sosreport (version %s)\" %\n                         (__version__,)))\n    def get_commons(self):\n        return {\n            'cmddir': self.cmddir,\n            'logdir': self.logdir,\n            'rptdir': self.rptdir,\n            'tmpdir': self.tmpdir,\n            'soslog': self.soslog,\n            'policy': self.policy,\n            'verbosity': self.opts.verbosity,\n            'xmlreport': self.xml_report,\n            'cmdlineopts': self.opts,\n            'config': self.config,\n            'global_plugin_options': self.global_plugin_options,\n            }\n    def get_temp_file(self):\n        return self.tempfile_util.new()\n    def _set_archive(self):\n        archive_name = os.path.join(self.tmpdir,\n                                    self.policy.get_archive_name())\n        if self.opts.compression_type == 'auto':\n            auto_archive = self.policy.get_preferred_archive()\n            self.archive = auto_archive(archive_name, self.tmpdir)\n        elif self.opts.compression_type == 'zip':\n            self.archive = ZipFileArchive(archive_name, self.tmpdir)\n        else:\n            self.archive = TarFileArchive(archive_name, self.tmpdir)\n        self.archive.set_debug(True if self.opts.debug else False)\n    def _make_archive_paths(self):\n        self.archive.makedirs(self.cmddir, 0o755)\n        self.archive.makedirs(self.logdir, 0o755)\n        self.archive.makedirs(self.rptdir, 0o755)\n    def _set_directories(self):\n        self.cmddir = 'sos_commands'\n        self.logdir = 'sos_logs'\n        self.rptdir = 'sos_reports'\n    def _set_debug(self):\n        if self.opts.debug:\n            sys.excepthook = self._exception\n            self.raise_plugins = True\n        else:\n            self.raise_plugins = False\n    @staticmethod\n    def _exception(etype, eval_, etrace):\n        \"\"\" Wrap exception in debugger if not in tty \"\"\"\n        if hasattr(sys, 'ps1') or not sys.stderr.isatty():\n            # we are in interactive mode or we don't have a tty-like\n            # device, so we call the default hook\n            sys.__excepthook__(etype, eval_, etrace)\n        else:\n            import pdb\n            # we are NOT in interactive mode, print the exception...\n            traceback.print_exception(etype, eval_, etrace, limit=2,\n                                      file=sys.stdout)\n            print_()\n            # ...then start the debugger in post-mortem mode.\n            pdb.pm()\n    def _exit(self, error=0):\n        raise SystemExit()\n#        sys.exit(error)\n    def get_exit_handler(self):\n        def exit_handler(signum, frame):\n            self._exit()\n        return exit_handler\n    def _read_config(self):\n        self.config = ConfigParser()\n        if self.opts.config_file:\n            config_file = self.opts.config_file\n        else:\n            config_file = '/etc/sos.conf'\n        try:\n            self.config.readfp(open(config_file))\n        except IOError:\n            pass\n    def _setup_logging(self):\n        # main soslog\n        self.soslog = logging.getLogger('sos')\n        self.soslog.setLevel(logging.DEBUG)\n        self.sos_log_file = self.get_temp_file()\n        self.sos_log_file.close()\n        flog = logging.FileHandler(self.sos_log_file.name)\n        flog.setFormatter(logging.Formatter(\n            '%(asctime)s %(levelname)s: %(message)s'))\n        flog.setLevel(logging.INFO)\n        self.soslog.addHandler(flog)\n        if not self.opts.quiet:\n            console = logging.StreamHandler(sys.stderr)\n            console.setFormatter(logging.Formatter('%(message)s'))\n            if self.opts.verbosity and self.opts.verbosity > 1:\n                console.setLevel(logging.DEBUG)\n                flog.setLevel(logging.DEBUG)\n            elif self.opts.verbosity and self.opts.verbosity > 0:\n                console.setLevel(logging.INFO)\n                flog.setLevel(logging.DEBUG)\n            else:\n                console.setLevel(logging.WARNING)\n            self.soslog.addHandler(console)\n        # ui log\n        self.ui_log = logging.getLogger('sos_ui')\n        self.ui_log.setLevel(logging.INFO)\n        self.sos_ui_log_file = self.get_temp_file()\n        self.sos_ui_log_file.close()\n        ui_fhandler = logging.FileHandler(self.sos_ui_log_file.name)\n        ui_fhandler.setFormatter(logging.Formatter(\n            '%(asctime)s %(levelname)s: %(message)s'))\n        self.ui_log.addHandler(ui_fhandler)\n        if not self.opts.quiet:\n            ui_console = logging.StreamHandler(sys.stdout)\n            ui_console.setFormatter(logging.Formatter('%(message)s'))\n            ui_console.setLevel(logging.INFO)\n            self.ui_log.addHandler(ui_console)\n    def _finish_logging(self):\n        logging.shutdown()\n        # Make sure the log files are added before we remove the log\n        # handlers. This prevents \"No handlers could be found..\" messages\n        # from leaking to the console when running in --quiet mode when\n        # Archive classes attempt to acess the log API.\n        if getattr(self, \"sos_log_file\", None):\n            self.archive.add_file(self.sos_log_file.name,\n                                  dest=os.path.join('sos_logs', 'sos.log'))\n        if getattr(self, \"sos_ui_log_file\", None):\n            self.archive.add_file(self.sos_ui_log_file.name,\n                                  dest=os.path.join('sos_logs', 'ui.log'))\n    def _get_disabled_plugins(self):\n        disabled = []\n        if self.config.has_option(\"plugins\", \"disable\"):\n            disabled = [plugin.strip() for plugin in\n                        self.config.get(\"plugins\", \"disable\").split(',')]\n        return disabled\n    def _is_in_profile(self, plugin_class):\n        onlyplugins = self.opts.onlyplugins\n        if not len(self.opts.profiles):\n            return True\n        if not hasattr(plugin_class, \"profiles\"):\n            return False\n        if onlyplugins and not self._is_not_specified(plugin_class.name()):\n            return True\n        return any([p in self.opts.profiles for p in plugin_class.profiles])\n    def _is_skipped(self, plugin_name):\n        return (plugin_name in self.opts.noplugins or\n                plugin_name in self._get_disabled_plugins())\n    def _is_inactive(self, plugin_name, pluginClass):\n        return (not pluginClass(self.get_commons()).check_enabled() and\n                plugin_name not in self.opts.enableplugins and\n                plugin_name not in self.opts.onlyplugins)\n    def _is_not_default(self, plugin_name, pluginClass):\n        return (not pluginClass(self.get_commons()).default_enabled() and\n                plugin_name not in self.opts.enableplugins and\n                plugin_name not in self.opts.onlyplugins)\n    def _is_not_specified(self, plugin_name):\n        return (self.opts.onlyplugins and\n                plugin_name not in self.opts.onlyplugins)\n    def _skip(self, plugin_class, reason=\"unknown\"):\n        self.skipped_plugins.append((\n            plugin_class.name(),\n            plugin_class(self.get_commons()),\n            reason\n        ))\n    def _load(self, plugin_class):\n        self.loaded_plugins.append((\n            plugin_class.name(),\n            plugin_class(self.get_commons())\n        ))\n    def load_plugins(self):\n        import sos.plugins\n        helper = ImporterHelper(sos.plugins)\n        plugins = helper.get_modules()\n        self.plugin_names = deque()\n        self.profiles = set()\n        using_profiles = len(self.opts.profiles)\n        # validate and load plugins\n        for plug in plugins:\n            plugbase, ext = os.path.splitext(plug)\n            try:\n                plugin_classes = import_plugin(\n                    plugbase, tuple(self.policy.valid_subclasses))\n                if not len(plugin_classes):\n                    # no valid plugin classes for this policy\n                    continue\n                plugin_class = self.policy.match_plugin(plugin_classes)\n                if not self.policy.validate_plugin(plugin_class):\n                    self.soslog.warning(\n                        _(\"plugin %s does not validate, skipping\") % plug)\n                    if self.opts.verbosity > 0:\n                        self._skip(plugin_class, _(\"does not validate\"))\n                        continue\n                if plugin_class.requires_root and not self._is_root:\n                    self.soslog.info(_(\"plugin %s requires root permissions\"\n                                       \"to execute, skipping\") % plug)\n                    self._skip(plugin_class, _(\"requires root\"))\n                    continue\n                # plug-in is valid, let's decide whether run it or not\n                self.plugin_names.append(plugbase)\n                if hasattr(plugin_class, \"profiles\"):\n                    self.profiles.update(plugin_class.profiles)\n                in_profile = self._is_in_profile(plugin_class)\n                if not in_profile:\n                    self._skip(plugin_class, _(\"excluded\"))\n                    continue\n                if self._is_skipped(plugbase):\n                    self._skip(plugin_class, _(\"skipped\"))\n                    continue\n                if self._is_inactive(plugbase, plugin_class):\n                    self._skip(plugin_class, _(\"inactive\"))\n                    continue\n                if self._is_not_default(plugbase, plugin_class):\n                    self._skip(plugin_class, _(\"optional\"))\n                    continue\n                # true when the null (empty) profile is active\n                default_profile = not using_profiles and in_profile\n                if self._is_not_specified(plugbase) and default_profile:\n                    self._skip(plugin_class, _(\"not specified\"))\n                    continue\n                self._load(plugin_class)\n            except Exception as e:\n                self.soslog.warning(_(\"plugin %s does not install, \"\n                                    \"skipping: %s\") % (plug, e))\n                if self.raise_plugins:\n                    raise\n    def _set_all_options(self):\n        if self.opts.usealloptions:\n            for plugname, plug in self.loaded_plugins:\n                for name, parms in zip(plug.opt_names, plug.opt_parms):\n                    if type(parms[\"enabled\"]) == bool:\n                        parms[\"enabled\"] = True\n    def _set_tunables(self):\n        if self.config.has_section(\"tunables\"):\n            if not self.opts.plugopts:\n                self.opts.plugopts = deque()\n            for opt, val in self.config.items(\"tunables\"):\n                if not opt.split('.')[0] in self._get_disabled_plugins():\n                    self.opts.plugopts.append(opt + \"=\" + val)\n        if self.opts.plugopts:\n            opts = {}\n            for opt in self.opts.plugopts:\n                # split up \"general.syslogsize=5\"\n                try:\n                    opt, val = opt.split(\"=\")\n                except:\n                    val = True\n                else:\n                    if val.lower() in [\"off\", \"disable\", \"disabled\", \"false\"]:\n                        val = False\n                    else:\n                        # try to convert string \"val\" to int()\n                        try:\n                            val = int(val)\n                        except:\n                            pass\n                # split up \"general.syslogsize\"\n                try:\n                    plug, opt = opt.split(\".\")\n                except:\n                    plug = opt\n                    opt = True\n                try:\n                    opts[plug]\n                except KeyError:\n                    opts[plug] = deque()\n                opts[plug].append((opt, val))\n            for plugname, plug in self.loaded_plugins:\n                if plugname in opts:\n                    for opt, val in opts[plugname]:\n                        if not plug.set_option(opt, val):\n                            self.soslog.error('no such option \"%s\" for plugin '\n                                              '(%s)' % (opt, plugname))\n                            self._exit(1)\n                    del opts[plugname]\n            for plugname in opts.keys():\n                self.soslog.error('unable to set option for disabled or '\n                                  'non-existing plugin (%s)' % (plugname))\n    def _check_for_unknown_plugins(self):\n        import itertools\n        for plugin in itertools.chain(self.opts.onlyplugins,\n                                      self.opts.noplugins,\n                                      self.opts.enableplugins):\n            plugin_name = plugin.split(\".\")[0]\n            if plugin_name not in self.plugin_names:\n                self.soslog.fatal('a non-existing plugin (%s) was specified '\n                                  'in the command line' % (plugin_name))\n                self._exit(1)\n    def _set_plugin_options(self):\n        for plugin_name, plugin in self.loaded_plugins:\n            names, parms = plugin.get_all_options()\n            for optname, optparm in zip(names, parms):\n                self.all_options.append((plugin, plugin_name, optname,\n                                         optparm))\n    def list_plugins(self):\n        if not self.loaded_plugins and not self.skipped_plugins:\n            self.soslog.fatal(_(\"no valid plugins found\"))\n            return\n        if self.loaded_plugins:\n            self.ui_log.info(_(\"The following plugins are currently enabled:\"))\n            self.ui_log.info(\"\")\n            for (plugname, plug) in self.loaded_plugins:\n                self.ui_log.info(\" %-20s %s\" % (plugname,\n                                                plug.get_description()))\n        else:\n            self.ui_log.info(_(\"No plugin enabled.\"))\n        self.ui_log.info(\"\")\n        if self.skipped_plugins:\n            self.ui_log.info(_(\"The following plugins are currently \"\n                             \"disabled:\"))\n            self.ui_log.info(\"\")\n            for (plugname, plugclass, reason) in self.skipped_plugins:\n                self.ui_log.info(\" %-20s %-14s %s\" % (\n                    plugname,\n                    reason,\n                    plugclass.get_description()))\n        self.ui_log.info(\"\")\n        if self.all_options:\n            self.ui_log.info(_(\"The following plugin options are available:\"))\n            self.ui_log.info(\"\")\n            for (plug, plugname, optname, optparm) in self.all_options:\n                # format option value based on its type (int or bool)\n                if type(optparm[\"enabled\"]) == bool:\n                    if optparm[\"enabled\"] is True:\n                        tmpopt = \"on\"\n                    else:\n                        tmpopt = \"off\"\n                else:\n                    tmpopt = optparm[\"enabled\"]\n                self.ui_log.info(\" %-25s %-15s %s\" % (\n                    plugname + \".\" + optname, tmpopt, optparm[\"desc\"]))\n        else:\n            self.ui_log.info(_(\"No plugin options available.\"))\n        self.ui_log.info(\"\")\n        profiles = list(self.profiles)\n        profiles.sort()\n        lines = _format_list(\"Profiles: \", profiles, indent=True)\n        for line in lines:\n            self.ui_log.info(\" %s\" % line)\n        self.ui_log.info(\"\")\n        self.ui_log.info(\" %d profiles, %d plugins\"\n                         % (len(self.profiles), len(self.loaded_plugins)))\n        self.ui_log.info(\"\")\n    def list_profiles(self):\n        if not self.profiles:\n            self.soslog.fatal(_(\"no valid profiles found\"))\n            return\n        self.ui_log.info(_(\"The following profiles are available:\"))\n        self.ui_log.info(\"\")\n        def _has_prof(c):\n            return hasattr(c, \"profiles\")\n        profiles = list(self.profiles)\n        profiles.sort()\n        for profile in profiles:\n            plugins = []\n            for name, plugin in self.loaded_plugins:\n                if _has_prof(plugin) and profile in plugin.profiles:\n                    plugins.append(name)\n            lines = _format_list(\"%-15s \" % profile, plugins, indent=True)\n            for line in lines:\n                self.ui_log.info(\" %s\" % line)\n        self.ui_log.info(\"\")\n        self.ui_log.info(\" %d profiles, %d plugins\"\n                         % (len(profiles), len(self.loaded_plugins)))\n        self.ui_log.info(\"\")\n    def batch(self):\n        if self.opts.batch:\n            self.ui_log.info(self.policy.get_msg())\n        else:\n            msg = self.policy.get_msg()\n            msg += _(\"Press ENTER to continue, or CTRL-C to quit.\\n\")\n            try:\n                input(msg)\n            except:\n                self.ui_log.info(\"\")\n                self._exit()\n    def _log_plugin_exception(self, plugin_name):\n        self.soslog.error(\"%s\\n%s\" % (plugin_name, traceback.format_exc()))\n    def prework(self):\n        self.policy.pre_work()\n        try:\n            self.ui_log.info(_(\" Setting up archive ...\"))\n            compression_methods = ('auto', 'zip', 'bzip2', 'gzip', 'xz')\n            method = self.opts.compression_type\n            if method not in compression_methods:\n                compression_list = ', '.join(compression_methods)\n                self.ui_log.error(\"\")\n                self.ui_log.error(\"Invalid compression specified: \" + method)\n                self.ui_log.error(\"Valid types are: \" + compression_list)\n                self.ui_log.error(\"\")\n                self._exit(1)\n            self._set_archive()\n            self._make_archive_paths()\n            return\n        except (OSError, IOError) as e:\n            if e.errno in fatal_fs_errors:\n                self.ui_log.error(\"\")\n                self.ui_log.error(\" %s while setting up archive\" % e.strerror)\n                self.ui_log.error(\"\")\n            else:\n                raise e\n        except Exception as e:\n            import traceback\n            self.ui_log.error(\"\")\n            self.ui_log.error(\" Unexpected exception setting up archive:\")\n            traceback.print_exc(e)\n            self.ui_log.error(e)\n        self._exit(1)\n    def setup(self):\n        msg = \"[%s:%s] executing 'sosreport %s'\"\n        self.soslog.info(msg % (__name__, \"setup\", \" \".join(self._args)))\n        self.ui_log.info(_(\" Setting up plugins ...\"))\n        for plugname, plug in self.loaded_plugins:\n            try:\n                plug.archive = self.archive\n                plug.setup()\n            except KeyboardInterrupt:\n                raise\n            except (OSError, IOError) as e:\n                if e.errno in fatal_fs_errors:\n                    self.ui_log.error(\"\")\n                    self.ui_log.error(\" %s while setting up plugins\"\n                                      % e.strerror)\n                    self.ui_log.error(\"\")\n                    self._exit(1)\n            except:\n                if self.raise_plugins:\n                    raise\n                else:\n                    self._log_plugin_exception(plugname)\n    def version(self):\n        \"\"\"Fetch version information from all plugins and store in the report\n        version file\"\"\"\n        versions = []\n        versions.append(\"sosreport: %s\" % __version__)\n        for plugname, plug in self.loaded_plugins:\n            versions.append(\"%s: %s\" % (plugname, plug.version))\n        self.archive.add_string(content=\"\\n\".join(versions),\n                                dest='version.txt')\n    def collect(self):\n        self.ui_log.info(_(\" Running plugins. Please wait ...\"))\n        self.ui_log.info(\"\")\n        plugruncount = 0\n", "outputs": ["        for i in zip(self.loaded_plugins):"], "input_length": 6255, "output_length": 8, "length": 6263, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "1a63d79b75238aadb0b25926ea0702b5880a266458c65e5e7810a6240c761a10"}
{"input": "", "context": "# -*- coding: utf-8 -*-\n#\n# @file sge_jobs.py\n#\n# @remark Copyright 2014 Philippe Elie\n# @remark Read the file COPYING\n#\n# @author Philippe Elie\nimport sys\nimport os\nsys.path.append(os.path.expanduser('~/phe/common'))\nimport utils\nimport json\nimport hashlib\nimport time\nimport MySQLdb\nimport subprocess\nimport qstat\nimport re\nimport db\nimport collections\njsub = '/usr/bin/jsub'\nclass DbJob(db.UserDb):\n    def __init__(self):\n        super(DbJob, self).__init__('sge_jobs')\n        self.Accounting = collections.namedtuple('Accounting',\n            [\n             'qname',           'hostname',             'group',\n             'owner',           'jobname',              'jobnumber',\n             'account',         'priority',             'qsub_time',\n             'start_time',      'end_time',             'failed',\n             'exit_status',     'ru_wallclock',         'ru_utime',\n             'ru_stime',        'ru_maxrss',            'ru_ixrss',\n             'ru_ismrss',       'ru_idrss',             'ru_isrsst',\n             'ru_minflt',       'ru_majflt',            'ru_nswap',\n             'ru_inblock',      'ru_oublock',           'ru_msdsnd',\n             'ru_msgrcv',       'ru_nsignals',          'ru_nvcsw',\n             'ru_nivcsw',       'project',              'departement',\n             'granted',         'slots',                'task',\n             'cpu',             'mem',                  'io',\n             'category',        'iow',                  'pe_taskid',\n             'used_maxvmem',    'arid',                 'ar_submission_time'\n             ])\n        self.all_state = set(['pending', 'running', 'success', 'accounting',\n                              'sge_fail', 'fail'])\n    def get_job_table(self, state_filter, limit = 50, offset = 0):\n        limit += 1\n        data = []\n        state_filter = state_filter.split('|')\n        if state_filter:\n            for s in state_filter[:]:\n                if s != 'all' and s not in self.all_state:\n                    state_filter.remove(s)\n            state_filter = tuple(state_filter)\n        if not state_filter:\n            state_filter = tuple([ 'fail', 'pending', 'running' ])\n        if 'all' in state_filter:\n            state_filter = tuple([ x for x in self.all_state ])\n        with db.connection(self):\n            fmt_strs = ', '.join(['%s'] * len(state_filter))\n            q = 'SELECT * FROM job WHERE job_state IN (' + fmt_strs + ') ORDER BY job_id DESC LIMIT %s OFFSET %s'\n            #print >> sys.stderr, q % (state_filter + (limit, ) + (offset,))\n            self.cursor.execute(q, state_filter + (limit, ) + (offset,))\n            data = self.cursor.fetchall()\n        has_next = True if len(data) == limit else False\n        return data[:limit-1], has_next\n    def get_accounting_table(self, limit = 50, offset = 0, job_ids = None):\n        limit += 1\n        data = []\n        if not job_ids:\n            job_ids = []\n        if type(job_ids) != type([]):\n            jobs_ids = [ job_ids ]\n        with db.connection(self):\n            q = 'SELECT * from accounting '\n            if job_ids:\n                fmt_strs = ', '.join(['%s'] * len(job_ids))\n                q += 'WHERE job_id in (' + fmt_strs + ') '\n            q += 'ORDER BY job_id DESC, sge_jobnumber DESC, sge_hostname LIMIT %s OFFSET %s'\n            self.cursor.execute(q, tuple(job_ids) + (limit, ) + (offset,))\n            data = self.cursor.fetchall()\n        has_next = True if len(data) == limit else False\n        return data[:limit-1], has_next\n    def pending_request(self, limit = 16, offset = 0):\n        data = []\n        with db.connection(self):\n            self.cursor.execute(\"SELECT * FROM job WHERE job_state='pending' LIMIT %s OFFSET %s\",\n                                [ limit, offset ])\n            data = self.cursor.fetchall()\n        return data\n    def _add_request(self, jobname, run_cmd, args, max_vmem, cpu_bound, force):\n        job_id = 0\n        args = json.dumps(args)\n        h = hashlib.sha1()\n        h.update(run_cmd + args)\n        sha1 = h.hexdigest()\n        q = 'SELECT * FROM job WHERE job_sha1 = %s'\n        self.cursor.execute(q, [sha1])\n        num = self.cursor.fetchone()\n        if num:\n            job_id = num['job_id']\n        if num and not num['job_state'] in [ 'pending', 'running', 'accounting' ]:\n            q = 'SELECT COUNT(*) FROM accounting WHERE job_id=%s'\n            self.cursor.execute(q, [ job_id ])\n            count = self.cursor.fetchone()['COUNT(*)']\n            if count < 3 or force:\n                q = 'UPDATE job SET job_state=\"pending\" WHERE job_id=%s'\n                self.cursor.execute(q, [ job_id ] )\n            else:\n                print >> sys.stderr, \"Job %d reached its max try count, rejected\" % job_id, args\n        elif not num:\n            job_data = {\n                'job_sha1' : sha1,\n                'job_jobname' : jobname,\n                'job_cpu_bound' : cpu_bound,\n                'job_submit_time' : int(time.time()),\n                'job_run_cmd' : run_cmd,\n                'job_log_dir' : os.path.expanduser('~/log/sge/'),\n                'job_args' : args,\n                'job_state' : 'pending',\n                'job_max_vmem' : max_vmem,\n                }\n            add_job_field = '(' + ', '.join(job_data.keys()) + ') '\n            # Quoting is done by execute so it's secure.\n            add_job_value_list = [ '%%(%s)s' % k for k in job_data.keys() ]\n            add_job_value = 'VALUE (' + ', '.join(add_job_value_list) + ')'\n            add_job = ('INSERT INTO job ' + add_job_field + add_job_value)\n            self.cursor.execute(add_job, job_data)\n            self.cursor.execute('SELECT LAST_INSERT_ID()')\n            job_id = self.cursor.fetchone()['LAST_INSERT_ID()']\n        return job_id\n    def add_request(self, jobname, run_cmd, args,  max_vmem,\n                    cpu_bound = True, force = False):\n        job_id = 0\n        with db.connection(self):\n            job_id = self._add_request(jobname, run_cmd, args,\n                                       max_vmem, cpu_bound, force)\n        return job_id\n    def exec_request(self, r):\n        sge_job_nr = 0\n        # This is a bit convoluted but we need it to avoid a race condition:\n        # we set the job as running before starting it so on if this script\n        # run twice in parallel we don't try to start the same job twice. Then\n        # when the job really started or fail to start we update its state\n        # again. As we don't know yet the sge job number, we setup it as zero.\n        # Note this could be done in pending_request() but I prefer to protect\n        # it locally.\n        really_pending = False\n        with db.connection(self):\n            q = 'UPDATE job SET job_state=%s, sge_jobnumber=%s WHERE job_id=%s AND job_state=\"pending\"'\n            if self.cursor.execute(q, [ 'running', 0, r['job_id'] ]):\n                really_pending = True\n        if not really_pending:\n            print >> sys.stderr, \"run request for job_id %s cancelled, as it's no longer pending\" % r['job_id']\n            return\n        cmdline_arg = job_cmdline_arg(r, 'job_run_cmd')\n        sge_cmdline = sge_cmdline_arg(r)\n        ls = subprocess.Popen(sge_cmdline + cmdline_arg,\n                              stdin=None, stdout=subprocess.PIPE,\n                              close_fds = True)\n        text = ls.stdout.read()\n        ls.wait()\n        try:\n            sge_job_nr = int(re.search('Your job (\\d+) ', text).group(1))\n            new_state = 'running'\n        except:\n            utils.print_traceback(\"sge failure to exec job: %d\" % r['job_id'], text)\n            new_state = 'sge_fail'\n        # Now we can really update the job state, see comment above.\n        with db.connection(self):\n            q = 'UPDATE job SET job_state=%s, sge_jobnumber=%s WHERE job_id=%s'\n            self.cursor.execute(q, [ new_state, sge_job_nr, r['job_id'] ])\n    def run_batch(self, nr_running, limit = 16):\n        max_to_run = max(min(limit - nr_running, limit), 0)\n        if max_to_run:\n            for r in self.pending_request(max_to_run):\n                print \"starting:\", r\n                self.exec_request(r)\n    def _exec_check(self, request):\n        q = 'UPDATE job SET job_state=\"accounting\" WHERE job_id=%s'\n        self.cursor.execute(q, [ request['job_id'] ])\n        q = 'INSERT into accounting (job_id, sge_jobnumber) VALUE (%s, %s)'\n        self.cursor.execute(q, [ request['job_id'], request['sge_jobnumber'] ])\n        self.conn.commit()\n    def check_running(self):\n        sge_running = qstat.running_jobs('')\n        if sge_running:\n            with db.connection(self):\n                q = 'SELECT job_id, sge_jobnumber, job_args FROM job WHERE job_state=\"running\"'\n                self.cursor.execute(q)\n                for r in self.cursor.fetchall():\n                    if not r['sge_jobnumber'] in sge_running:\n                        self._exec_check(r)\n            return len(sge_running)\n        return None\n    # Limiting is necessary because a job can be finished but not yet in the\n    # accouting file (cache effect) so we can easily scan the whole file. To\n    # avoid that we limit the backward search to two days by default.\n    # float is allowed so last_time_day = 1.0/24 is an hour.\n    def search_accounting(self, jobs, last_time_day = 2):\n        last_time_day = max(1.0/24, last_time_day)\n        now = int(time.time())\n        count = 0\n        nr_job = len(jobs)\n        for line in utils.readline_backward('/data/project/.system/accounting'):\n            accounting = self.Accounting(*line.split(':'))\n            jobnumber = int(accounting.jobnumber)\n            count += 1\n            if jobnumber in jobs:\n                jobs[jobnumber].append(accounting)\n                nr_job -= 1\n                if nr_job == 0:\n                    print \"breaking after %d line\" % count\n                    break\n            # end_time == 0 occur when sge failed to start a task, don't\n            # use it to get the elapsed time between end_time and now.\n            if int(accounting.end_time) and now - int(accounting.end_time) >= last_time_day * 86400:\n                print \"breaking after %d line, TIMEOUT\" % count\n                break\n    def update_accounting(self):\n        jobs = {}  \n        with db.connection(self):\n            q = 'SELECT job_id, sge_jobnumber, sge_hostname FROM accounting WHERE sge_hostname=\"\"'\n            self.cursor.execute(q)\n            for data in self.cursor.fetchall():\n                jobs[data['sge_jobnumber']] = [ data ]\n        if not len(jobs):\n            return\n        self.search_accounting(jobs)\n        with db.connection(self):\n            fields = [ 'hostname', 'qsub_time', 'start_time', 'end_time',\n                       'failed', 'exit_status', 'ru_utime', 'ru_stime',\n                       'ru_wallclock', 'used_maxvmem' ]\n            set_str = []\n            for f in fields:\n                set_str.append('sge_%s=%%(%s)s' % (f, f))\n            set_str = ', '.join(set_str)\n            for sge_jobnumber in jobs:\n                sge_jobnumber = int(sge_jobnumber)\n                # Accounting not found, it'll found in the next run.\n                if len(jobs[sge_jobnumber]) <= 1:\n                    continue\n                q  = \"UPDATE accounting SET \" + set_str\n                # We can't let execute() do the quoting for jobnumber, but \n                # sge_jobnumber is forced to int so this code is sql injection\n                # safe.\n                q += ' WHERE sge_jobnumber=%d' % sge_jobnumber\n                # Kludge, execute() don't accept a namedtuple nor an\n                # OrderedDict so convert it explicitly to a dict.\n                d = jobs[sge_jobnumber][1]._asdict()\n                d = dict(zip(d.keys(), d.values()))\n                self.cursor.execute(q, d)\n                job = jobs[sge_jobnumber][0]\n                new_state = 'success'\n                if int(d['failed']) or int(d['exit_status']):\n                    new_state = 'fail'\n                q = 'UPDATE job SET job_state=%s WHERE job_id=%s'\n                self.cursor.execute(q, [ new_state, job['job_id'] ])\ndef quote_arg(arg):\n    return \"'\" + arg.replace(\"'\", r\"'\\''\") + \"'\"\ndef job_cmdline_arg(request, cmd):\n    cmd_arg  = [ request[cmd] ]\n    cmd_arg += [ quote_arg(x) for x in json.loads(request['job_args']) ]\n    return cmd_arg\ndef sge_cmdline_arg(request):\n    job_name = request['job_jobname']\n    log_name = request['job_log_dir'] + job_name + '_' + str(request['job_id'])\n    sge_cmd_arg = [\n        jsub,\n        '-b', 'y',\n", "outputs": ["        '-l', 'h_vmem=%dM' % request['job_max_vmem'],"], "input_length": 2286, "output_length": 14, "length": 2300, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "21f59a1879525c4d2a37531b06cc025ff160a9e87ce55b6cdb68e35d1f3357bb"}
{"input": "", "context": "#region License\n// Copyright (c) 2013, ClearCanvas Inc.\n// All rights reserved.\n// http://www.clearcanvas.ca\n//\n// This file is part of the ClearCanvas RIS/PACS open source project.\n//\n// The ClearCanvas RIS/PACS open source project is free software: you can\n// redistribute it and/or modify it under the terms of the GNU General Public\n// License as published by the Free Software Foundation, either version 3 of the\n// License, or (at your option) any later version.\n//\n// The ClearCanvas RIS/PACS open source project is distributed in the hope that it\n// will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of\n// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General\n// Public License for more details.\n//\n// You should have received a copy of the GNU General Public License along with\n// the ClearCanvas RIS/PACS open source project.  If not, see\n// <http://www.gnu.org/licenses/>.\n#endregion\nusing System;\nusing System.Collections.Generic;\nusing ClearCanvas.Common;\nusing ClearCanvas.Desktop;\nusing ClearCanvas.Desktop.Tables;\nusing ClearCanvas.Enterprise.Common;\nusing ClearCanvas.Ris.Application.Common;\nusing ClearCanvas.Ris.Application.Common.BrowsePatientData;\nusing ClearCanvas.Ris.Application.Common.RegistrationWorkflow.OrderEntry;\nusing ClearCanvas.Ris.Client.Formatting;\nusing ClearCanvas.Common.Utilities;\nnamespace ClearCanvas.Ris.Client.Workflow\n{\n\t/// <summary>\n\t/// Defines an interface for providing custom pages to be displayed in the merge orders component.\n\t/// </summary>\n\tpublic interface IMergeOrdersPageProvider : IExtensionPageProvider<IMergeOrdersPage, IMergeOrdersContext>\n\t{\n\t}\n\t/// <summary>\n\t/// Defines an interface to a custom merge orders page.\n\t/// </summary>\n\tpublic interface IMergeOrdersPage : IExtensionPage\n\t{\n\t}\n\t/// <summary>\n\t/// Defines an interface for providing a custom page with access to the merge orders context.\n\t/// </summary>\n\tpublic interface IMergeOrdersContext\n\t{\n\t\tevent EventHandler DryRunMergedOrderChanged;\n\t\tOrderDetail DryRunMergedOrder { get; }\n\t}\n\t/// <summary>\n\t/// Defines an extension point for adding custom pages to the merge orders component.\n\t/// </summary>\n\t[ExtensionPoint]\n\tpublic class MergeOrdersPageProviderExtensionPoint : ExtensionPoint<IMergeOrdersPageProvider>\n\t{\n\t}\n\t/// <summary>\n\t/// Extension point for views onto <see cref=\"MergeOrdersComponent\"/>.\n\t/// </summary>\n\t[ExtensionPoint]\n\tpublic sealed class MergeOrdersComponentViewExtensionPoint : ExtensionPoint<IApplicationComponentView>\n\t{\n\t}\n\t/// <summary>\n\t/// MergeOrdersComponent class.\n\t/// </summary>\n\t[AssociateView(typeof(MergeOrdersComponentViewExtensionPoint))]\n\tpublic class MergeOrdersComponent : ApplicationComponent\n\t{\n\t\tclass MergeOrdersTable : Table<OrderDetail>\n\t\t{\n\t\t\tpublic MergeOrdersTable()\n\t\t\t{\n\t\t\t\tITableColumn accesionNumberColumn;\n\t\t\t\tthis.Columns.Add(accesionNumberColumn = new TableColumn<OrderDetail, string>(SR.ColumnAccessionNumber, o => AccessionFormat.Format(o.AccessionNumber), 0.25f));\n\t\t\t\tthis.Columns.Add(new TableColumn<OrderDetail, string>(SR.ColumnImagingService, o => o.DiagnosticService.Name, 0.75f));\n\t\t\t\tthis.Sort(new TableSortParams(accesionNumberColumn, true));\n\t\t\t}\n\t\t}\n\t\tclass MergeOrdersContext : IMergeOrdersContext\n\t\t{\n\t\t\tprivate readonly MergeOrdersComponent _owner;\n\t\t\tpublic MergeOrdersContext(MergeOrdersComponent owner)\n\t\t\t{\n\t\t\t\t_owner = owner;\n\t\t\t}\n\t\t\tpublic event EventHandler DryRunMergedOrderChanged;\n\t\t\tpublic OrderDetail DryRunMergedOrder\n\t\t\t{\n\t\t\t\tget { return _owner._dryRunMergedOrder; }\n\t\t\t}\n\t\t\tinternal void NotifyDryRunMergedOrderChanged()\n\t\t\t{\n\t\t\t\tEventsHelper.Fire(DryRunMergedOrderChanged, this, EventArgs.Empty);\n\t\t\t}\n\t\t}\n\t\tprivate readonly List<EntityRef> _orderRefs;\n\t\tprivate readonly MergeOrdersTable _ordersTable;\n\t\tprivate OrderDetail _selectedOrder;\n\t\tprivate OrderDetail _dryRunMergedOrder;\n\t\tprivate TabComponentContainer _mergedOrderViewComponentContainer;\n\t\tprivate ChildComponentHost _mergedOrderPreviewComponentHost;\n\t\tprivate MergedOrderDetailViewComponent _orderPreviewComponent;\n\t\tprivate AttachedDocumentPreviewComponent _attachmentSummaryComponent;\n\t\tprivate readonly List<IMergeOrdersPage> _extensionPages = new List<IMergeOrdersPage>();\n\t\tprivate readonly MergeOrdersContext _extensionPageContext;\n\t\tpublic MergeOrdersComponent(List<EntityRef> orderRefs)\n\t\t{\n\t\t\t_orderRefs = orderRefs;\n\t\t\t_ordersTable = new MergeOrdersTable();\n\t\t\t_extensionPageContext = new MergeOrdersContext(this);\n\t\t}\n\t\tpublic override void Start()\n\t\t{\n\t\t\t_mergedOrderViewComponentContainer = new TabComponentContainer();\n\t\t\t_mergedOrderPreviewComponentHost = new ChildComponentHost(this.Host, _mergedOrderViewComponentContainer);\n\t\t\t_mergedOrderPreviewComponentHost.StartComponent();\n\t\t\t_mergedOrderViewComponentContainer.Pages.Add(new TabPage(SR.TitleOrder, _orderPreviewComponent = new MergedOrderDetailViewComponent()));\n\t\t\t_mergedOrderViewComponentContainer.Pages.Add(new TabPage(SR.TitleOrderAttachments, _attachmentSummaryComponent = new AttachedDocumentPreviewComponent(true, AttachmentSite.Order)));\n\t\t\t// instantiate all extension pages\n\t\t\tforeach (IMergeOrdersPageProvider pageProvider in new MergeOrdersPageProviderExtensionPoint().CreateExtensions())\n\t\t\t{\n\t\t\t\t_extensionPages.AddRange(pageProvider.GetPages(_extensionPageContext));\n\t\t\t}\n\t\t\t// add extension pages to container and set initial context\n\t\t\t// the container will start those components if the user goes to that page\n\t\t\tforeach (var page in _extensionPages)\n\t\t\t{\n\t\t\t\t_mergedOrderViewComponentContainer.Pages.Add(new TabPage(page.Path, page.GetComponent()));\n\t\t\t}\n\t\t\t// Load form data\n\t\t\tPlatform.GetService(\n\t\t\t\tdelegate(IBrowsePatientDataService service)\n\t\t\t\t{\n\t\t\t\t\tvar request = new GetDataRequest { GetOrderDetailRequest = new GetOrderDetailRequest() };\n\t\t\t\t\tforeach (var orderRef in _orderRefs)\n\t\t\t\t\t{\n\t\t\t\t\t\trequest.GetOrderDetailRequest.OrderRef = orderRef;\n\t\t\t\t\t\tvar response = service.GetData(request);\n\t\t\t\t\t\t_ordersTable.Items.Add(response.GetOrderDetailResponse.Order);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t_ordersTable.Sort();\n\t\t\t// Re-populate orderRef list by sorted accession number\n\t\t\t_orderRefs.Clear();\n\t\t\t_orderRefs.AddRange(CollectionUtils.Map<OrderDetail, EntityRef>(_ordersTable.Items, item => item.OrderRef));\n\t\t\t_selectedOrder = CollectionUtils.FirstElement(_ordersTable.Items);\n\t\t\tDryRunForSelectedOrder();\n\t\t\tbase.Start();\n\t\t}\n\t\tpublic override void Stop()\n\t\t{\n\t\t\tif (_mergedOrderPreviewComponentHost != null)\n\t\t\t{\n\t\t\t\t_mergedOrderPreviewComponentHost.StopComponent();\n\t\t\t\t_mergedOrderPreviewComponentHost = null;\n\t\t\t}\n\t\t\tbase.Stop();\n\t\t}\n\t\t#region Presentation Model\n\t\tpublic ITable OrdersTable\n\t\t{\n\t\t\tget { return _ordersTable; }\n\t\t}\n\t\tpublic ISelection OrdersTableSelection\n\t\t{\n\t\t\tget\n\t\t\t{\n\t\t\t\treturn new Selection(_selectedOrder);\n\t\t\t}\n\t\t\tset\n\t\t\t{\n\t\t\t\tvar previousSelection = new Selection(_selectedOrder);\n\t\t\t\tif (previousSelection.Equals(value))\n\t\t\t\t\treturn;\n\t\t\t\t_selectedOrder = (OrderDetail) value.Item;\n\t\t\t\tDryRunForSelectedOrder();\n\t\t\t\tNotifyPropertyChanged(\"SummarySelection\");\n\t\t\t}\n\t\t}\n\t\tpublic bool AcceptEnabled\n\t\t{\n\t\t\tget\n\t\t\t{\n\t\t\t\treturn _ordersTable.Items.Count > 0\n\t\t\t\t\t&& _selectedOrder != null\n\t\t\t\t\t&& _dryRunMergedOrder != null;\n\t\t\t}\n\t\t}\n\t\tpublic ApplicationComponentHost MergedOrderPreviewComponentHost\n\t\t{\n\t\t\tget { return _mergedOrderPreviewComponentHost; }\n\t\t}\n\t\tpublic void Accept()\n\t\t{\n\t\t\ttry\n\t\t\t{\n\t\t\t\tvar destAccNumber = _selectedOrder.AccessionNumber;\n\t\t\t\tvar sourceAccNumbers = CollectionUtils.Map(_ordersTable.Items, (OrderDetail o) => o.AccessionNumber);\n\t\t\t\tsourceAccNumbers.Remove(destAccNumber);\n\t\t\t\tvar message = string.Format(\"Merge order(s) {0} into order {1}?\",\n\t\t\t\t\tStringUtilities.Combine(sourceAccNumbers, \",\"),\n\t\t\t\t\tdestAccNumber);\n\t\t\t\tif (DialogBoxAction.No == this.Host.DesktopWindow.ShowMessageBox(message, MessageBoxActions.YesNo))\n\t\t\t\t\treturn;\n\t\t\t\tvar destinationOrderRef = _selectedOrder.OrderRef;\n\t\t\t\tvar sourceOrderRefs = new List<EntityRef>(_orderRefs);\n\t\t\t\tsourceOrderRefs.Remove(_selectedOrder.OrderRef);\n\t\t\t\tPlatform.GetService(\n\t\t\t\t\tdelegate(IOrderEntryService service)\n\t\t\t\t\t{\n\t\t\t\t\t\tvar request = new MergeOrderRequest(sourceOrderRefs, destinationOrderRef) { DryRun = false };\n\t\t\t\t\t\tservice.MergeOrder(request);\n\t\t\t\t\t});\n\t\t\t\t\n\t\t\t\tthis.Exit(ApplicationComponentExitCode.Accepted);\n\t\t\t}\n\t\t\tcatch (Exception e)\n\t\t\t{\n\t\t\t\tExceptionHandler.Report(e, SR.ExceptionMergeOrdersTool, this.Host.DesktopWindow,\n\t\t\t\t\t() => this.Exit(ApplicationComponentExitCode.Error));\n\t\t\t}\n\t\t}\n\t\tpublic void Cancel()\n\t\t{\n\t\t\tthis.Exit(ApplicationComponentExitCode.None);\n\t\t}\n\t\t#endregion\n\t\tprivate void DryRunForSelectedOrder()\n\t\t{\n\t\t\tstring failureReason;\n\t\t\tMergeOrderDryRun(out _dryRunMergedOrder, out failureReason);\n\t\t\tif (!string.IsNullOrEmpty(failureReason))\n\t\t\t\tthis.Host.ShowMessageBox(failureReason, MessageBoxActions.Ok);\n\t\t\t// Update order preview components\n\t\t\tif (_dryRunMergedOrder == null)\n\t\t\t{\n\t\t\t\t_orderPreviewComponent.Context = null;\n\t\t\t\t_attachmentSummaryComponent.Attachments = new List<AttachmentSummary>();\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\t_orderPreviewComponent.Context = _dryRunMergedOrder;\n\t\t\t\t_attachmentSummaryComponent.Attachments = _dryRunMergedOrder.Attachments;\n\t\t\t}\n\t\t\t_extensionPageContext.NotifyDryRunMergedOrderChanged();\n\t\t}\n\t\tprivate void MergeOrderDryRun(out OrderDetail mergedOrder, out string failureReason)\n\t\t{\n\t\t\tif (_selectedOrder == null)\n\t\t\t{\n\t\t\t\tfailureReason = null;\n\t\t\t\tmergedOrder = null;\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tvar destinationOrderRef = _selectedOrder.OrderRef;\n\t\t\tvar sourceOrderRefs = new List<EntityRef>(_orderRefs);\n\t\t\tsourceOrderRefs.Remove(_selectedOrder.OrderRef);\n\t\t\ttry\n\t\t\t{\n\t\t\t\tMergeOrderResponse response = null;\n\t\t\t\tPlatform.GetService(\n\t\t\t\t\tdelegate(IOrderEntryService service)\n\t\t\t\t\t{\n\t\t\t\t\t\tvar request = new MergeOrderRequest(sourceOrderRefs, destinationOrderRef) { DryRun = true };\n", "outputs": ["\t\t\t\t\t\tresponse = service.MergeOrder(request);"], "input_length": 1354, "output_length": 7, "length": 1361, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "4983117b35c17e54660897117461ece7a133a9d67727da3265f10fbc055188b1"}
{"input": "", "context": "# -*- coding: utf-8 -*-\n# Copyright (C) 2010, 2011, 2012 Sebastian Wiesner <lunaryorn@gmail.com>\n# This library is free software; you can redistribute it and/or modify it\n# under the terms of the GNU Lesser General Public License as published by the\n# Free Software Foundation; either version 2.1 of the License, or (at your\n# option) any later version.\n# This library is distributed in the hope that it will be useful, but WITHOUT\n# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License\n# for more details.\n# You should have received a copy of the GNU Lesser General Public License\n# along with this library; if not, write to the Free Software Foundation,\n# Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA\nfrom __future__ import (print_function, division, unicode_literals,\n                        absolute_import)\nimport pytest\nimport mock\nfrom pyudev import Enumerator, Device\ndef pytest_funcarg__enumerator(request):\n    context = request.getfuncargvalue('context')\n    return context.list_devices()\nclass TestEnumerator(object):\n    def test_match_subsystem(self, context):\n        devices = context.list_devices().match_subsystem('input')\n        for device in devices:\n            assert device.subsystem == 'input'\n    def test_match_subsystem_nomatch(self, context):\n        devices = context.list_devices().match_subsystem('input', nomatch=True)\n        for device in devices:\n            assert device.subsystem != 'input'\n    def test_match_subsystem_nomatch_unfulfillable(self, context):\n        devices = context.list_devices()\n        devices.match_subsystem('input')\n        devices.match_subsystem('input', nomatch=True)\n        assert not list(devices)\n    def test_match_sys_name(self, context):\n        devices = context.list_devices().match_sys_name('sda')\n        for device in devices:\n            assert device.sys_name == 'sda'\n    def test_match_property_string(self, context):\n        devices = list(context.list_devices().match_property('DRIVER', 'usb'))\n        for device in devices:\n            assert device['DRIVER'] == 'usb'\n            assert device.driver == 'usb'\n    def test_match_property_int(self, context):\n        devices = list(context.list_devices().match_property(\n            'ID_INPUT_KEY', 1))\n        for device in devices:\n            assert device['ID_INPUT_KEY'] == '1'\n            assert device.asint('ID_INPUT_KEY') == 1\n    def test_match_property_bool(self, context):\n        devices = list(context.list_devices().match_property(\n            'ID_INPUT_KEY', True))\n        for device in devices:\n            assert device['ID_INPUT_KEY'] == '1'\n            assert device.asbool('ID_INPUT_KEY')\n    def test_match_attribute_nomatch(self, context):\n        devices = context.list_devices().match_attribute(\n            'driver', 'usb', nomatch=True)\n        for device in devices:\n            assert device.attributes.get('driver') != 'usb'\n    def test_match_attribute_nomatch_unfulfillable(self, context):\n        devices = context.list_devices()\n        devices.match_attribute('driver', 'usb')\n        devices.match_attribute('driver', 'usb', nomatch=True)\n        assert not list(devices)\n    def test_match_attribute_string(self, context):\n        devices = list(context.list_devices().match_attribute('driver', 'usb'))\n        for device in devices:\n            assert device.attributes['driver'] == b'usb'\n    def test_match_attribute_int(self, context):\n        # busnum gives us the number of a USB bus.  And any decent system\n        # likely has two or more usb buses, so this should work on more or less\n        # any system.  I didn't find any other attribute that is likely to be\n        # present on a wide range of system, so this is probably as general as\n        # possible.  Still it may fail because the attribute isn't present on\n        # any device at all on the system running the test\n        devices = list(context.list_devices().match_attribute('busnum', 2))\n        for device in devices:\n            assert device.attributes['busnum'] == b'2'\n            assert device.attributes.asint('busnum') == 2\n    def test_match_attribute_bool(self, context):\n        # ro tells us whether a volumne is mounted read-only or not.  And any\n        # developers system should have at least one readable volume, thus this\n        # test should work on all systems these tests are ever run on\n        devices = list(context.list_devices().match_attribute('ro', False))\n        for device in devices:\n            assert device.attributes['ro'] == b'0'\n            assert not device.attributes.asbool('ro')\n    @pytest.mark.udev_version('>= 154')\n    def test_match_tag_mock(self, context):\n        enumerator = context.list_devices()\n        funcname = 'udev_enumerate_add_match_tag'\n        spec = lambda e, t: None\n        with mock.patch.object(enumerator._libudev, funcname,\n                               autospec=spec) as func:\n            retval = enumerator.match_tag('spam')\n            assert retval is enumerator\n            func.assert_called_with(enumerator, b'spam')\n    @pytest.mark.udev_version('>= 154')\n    def test_match_tag(self, context):\n        devices = list(context.list_devices().match_tag('seat'))\n        for device in devices:\n            assert 'seat' in device.tags\n    @pytest.mark.parametrize('device_data', pytest.config.udev_device_sample)\n    @pytest.mark.udev_version('>= 172')\n    def test_match_parent(self, context, device_data):\n        device = Device.from_path(context, device_data.device_path)\n        parent = device.parent\n        if parent is None:\n            pytest.skip('Device {0!r} has no parent'.format(device))\n        else:\n            children = list(context.list_devices().match_parent(parent))\n            assert device in children\n            assert parent in children\n    @pytest.mark.udev_version('>= 165')\n    def test_match_is_initialized_mock(self, context):\n        enumerator = context.list_devices()\n        funcname = 'udev_enumerate_add_match_is_initialized'\n        spec = lambda e: None\n        with mock.patch.object(enumerator._libudev, funcname,\n                               autospec=spec) as func:\n            retval = enumerator.match_is_initialized()\n            assert retval is enumerator\n            func.assert_called_with(enumerator)\n    def test_combined_matches_of_same_type(self, context):\n        \"\"\"\n        Test for behaviour as observed in #1\n        \"\"\"\n        properties = ('DEVTYPE', 'ID_TYPE')\n        devices = context.list_devices()\n        for property in properties:\n            devices.match_property(property, 'disk')\n        for device in devices:\n            assert (device.get('DEVTYPE') == 'disk' or\n                    device.get('ID_TYPE') == 'disk')\n    def test_combined_matches_of_different_types(self, context):\n        properties = ('DEVTYPE', 'ID_TYPE')\n        devices = context.list_devices().match_subsystem('input')\n        for property in properties:\n            devices.match_property(property, 'disk')\n        devices = list(devices)\n        assert not devices\n    def test_match(self, context):\n        devices = list(context.list_devices().match(\n            subsystem='input', ID_INPUT_MOUSE=True, sys_name='mouse0'))\n        for device in devices:\n            assert device.subsystem == 'input'\n            assert device.asbool('ID_INPUT_MOUSE')\n            assert device.sys_name == 'mouse0'\n    def test_match_passthrough_subsystem(self, enumerator):\n        with mock.patch.object(enumerator, 'match_subsystem',\n                               autospec=True) as match_subsystem:\n            enumerator.match(subsystem=mock.sentinel.subsystem)\n            match_subsystem.assert_called_with(mock.sentinel.subsystem)\n    def test_match_passthrough_sys_name(self, enumerator):\n        with mock.patch.object(enumerator, 'match_sys_name',\n                               autospec=True) as match_sys_name:\n            enumerator.match(sys_name=mock.sentinel.sys_name)\n            match_sys_name.assert_called_with(mock.sentinel.sys_name)\n    def test_match_passthrough_tag(self, enumerator):\n        with mock.patch.object(enumerator, 'match_tag',\n                               autospec=True) as match_tag:\n            enumerator.match(tag=mock.sentinel.tag)\n            match_tag.assert_called_with(mock.sentinel.tag)\n    @pytest.mark.udev_version('>= 172')\n    def test_match_passthrough_parent(self, enumerator):\n        with mock.patch.object(enumerator, 'match_parent',\n                               autospec=True) as match_parent:\n            enumerator.match(parent=mock.sentinel.parent)\n            match_parent.assert_called_with(mock.sentinel.parent)\n    def test_match_passthrough_property(self, enumerator):\n        with mock.patch.object(enumerator, 'match_property',\n                               autospec=True) as match_property:\n            enumerator.match(eggs=mock.sentinel.eggs, spam=mock.sentinel.spam)\n            assert match_property.call_count == 2\n            posargs = [args for args, _ in match_property.call_args_list]\n            assert ('spam', mock.sentinel.spam) in posargs\n            assert ('eggs', mock.sentinel.eggs) in posargs\nclass TestContext(object):\n    @pytest.mark.match\n    def test_list_devices(self, context):\n        devices = list(context.list_devices(\n", "outputs": ["            subsystem='input', ID_INPUT_MOUSE=True, sys_name='mouse0'))"], "input_length": 1404, "output_length": 9, "length": 1413, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "9454c7bd44ea6c0f3aaeeee923fce28e5b9e5b0bb67214865563771c276d59a0"}
{"input": "", "context": "# -*- coding: utf-8 -*-\n##################################################################################\n#\n# Copyright (c) 2005-2006 Axelor SARL. (http://www.axelor.com)\n# and 2004-2010 Tiny SPRL (<http://tiny.be>).\n#\n# $Id: hr.py 4656 2006-11-24 09:58:42Z Cyp $\n#\n#     This program is free software: you can redistribute it and/or modify\n#     it under the terms of the GNU Affero General Public License as\n#     published by the Free Software Foundation, either version 3 of the\n#     License, or (at your option) any later version.\n#\n#     This program is distributed in the hope that it will be useful,\n#     but WITHOUT ANY WARRANTY; without even the implied warranty of\n#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#     GNU Affero General Public License for more details.\n#\n#     You should have received a copy of the GNU Affero General Public License\n#     along with this program.  If not, see <http://www.gnu.org/licenses/>.\n#\n##############################################################################\nimport datetime\nimport math\nimport time\nfrom operator import attrgetter\nfrom openerp.exceptions import Warning\nfrom openerp import tools\nfrom openerp.osv import fields, osv\nfrom openerp.tools.translate import _\nclass hr_holidays_status(osv.osv):\n    _name = \"hr.holidays.status\"\n    _description = \"Leave Type\"\n    def get_days(self, cr, uid, ids, employee_id, context=None):\n        result = dict((id, dict(max_leaves=0, leaves_taken=0, remaining_leaves=0,\n                                virtual_remaining_leaves=0)) for id in ids)\n        holiday_ids = self.pool['hr.holidays'].search(cr, uid, [('employee_id', '=', employee_id),\n                                                                ('state', 'in', ['confirm', 'validate1', 'validate']),\n                                                                ('holiday_status_id', 'in', ids)\n                                                                ], context=context)\n        for holiday in self.pool['hr.holidays'].browse(cr, uid, holiday_ids, context=context):\n            status_dict = result[holiday.holiday_status_id.id]\n            if holiday.type == 'add':\n                status_dict['virtual_remaining_leaves'] += holiday.number_of_days_temp\n                if holiday.state == 'validate':\n                    status_dict['max_leaves'] += holiday.number_of_days_temp\n                    status_dict['remaining_leaves'] += holiday.number_of_days_temp\n            elif holiday.type == 'remove':  # number of days is negative\n                status_dict['virtual_remaining_leaves'] -= holiday.number_of_days_temp\n                if holiday.state == 'validate':\n                    status_dict['leaves_taken'] += holiday.number_of_days_temp\n                    status_dict['remaining_leaves'] -= holiday.number_of_days_temp\n        return result\n    def _user_left_days(self, cr, uid, ids, name, args, context=None):\n        employee_id = False\n        if context and 'employee_id' in context:\n            employee_id = context['employee_id']\n        else:\n            employee_ids = self.pool.get('hr.employee').search(cr, uid, [('user_id', '=', uid)], context=context)\n            if employee_ids:\n                employee_id = employee_ids[0]\n        if employee_id:\n            res = self.get_days(cr, uid, ids, employee_id, context=context)\n        else:\n            res = dict((res_id, {'leaves_taken': 0, 'remaining_leaves': 0, 'max_leaves': 0}) for res_id in ids)\n        return res\n    _columns = {\n        'name': fields.char('Leave Type', size=64, required=True, translate=True),\n        'categ_id': fields.many2one('calendar.event.type', 'Meeting Type',\n            help='Once a leave is validated, Odoo will create a corresponding meeting of this type in the calendar.'),\n        'color_name': fields.selection([('red', 'Red'),('blue','Blue'), ('lightgreen', 'Light Green'), ('lightblue','Light Blue'), ('lightyellow', 'Light Yellow'), ('magenta', 'Magenta'),('lightcyan', 'Light Cyan'),('black', 'Black'),('lightpink', 'Light Pink'),('brown', 'Brown'),('violet', 'Violet'),('lightcoral', 'Light Coral'),('lightsalmon', 'Light Salmon'),('lavender', 'Lavender'),('wheat', 'Wheat'),('ivory', 'Ivory')],'Color in Report', required=True, help='This color will be used in the leaves summary located in Reporting\\Leaves by Department.'),\n        'limit': fields.boolean('Allow to Override Limit', help='If you select this check box, the system allows the employees to take more leaves than the available ones for this type and will not take them into account for the \"Remaining Legal Leaves\" defined on the employee form.'),\n        'active': fields.boolean('Active', help=\"If the active field is set to false, it will allow you to hide the leave type without removing it.\"),\n        'max_leaves': fields.function(_user_left_days, string='Maximum Allowed', help='This value is given by the sum of all holidays requests with a positive value.', multi='user_left_days'),\n        'leaves_taken': fields.function(_user_left_days, string='Leaves Already Taken', help='This value is given by the sum of all holidays requests with a negative value.', multi='user_left_days'),\n        'remaining_leaves': fields.function(_user_left_days, string='Remaining Leaves', help='Maximum Leaves Allowed - Leaves Already Taken', multi='user_left_days'),\n        'virtual_remaining_leaves': fields.function(_user_left_days, string='Virtual Remaining Leaves', help='Maximum Leaves Allowed - Leaves Already Taken - Leaves Waiting Approval', multi='user_left_days'),\n        'double_validation': fields.boolean('Apply Double Validation', help=\"When selected, the Allocation/Leave Requests for this type require a second validation to be approved.\"),\n    }\n    _defaults = {\n        'color_name': 'red',\n        'active': True,\n    }\n    def name_get(self, cr, uid, ids, context=None):\n        if context is None:\n            context = {}\n        if not context.get('employee_id',False):\n            # leave counts is based on employee_id, would be inaccurate if not based on correct employee\n            return super(hr_holidays_status, self).name_get(cr, uid, ids, context=context)\n        res = []\n        for record in self.browse(cr, uid, ids, context=context):\n            name = record.name\n            if not record.limit:\n                name = name + ('  (%g/%g)' % (record.leaves_taken or 0.0, record.max_leaves or 0.0))\n            res.append((record.id, name))\n        return res\nclass hr_holidays(osv.osv):\n    _name = \"hr.holidays\"\n    _description = \"Leave\"\n    _order = \"type desc, date_from asc\"\n    _inherit = ['mail.thread', 'ir.needaction_mixin']\n    _track = {\n        'state': {\n            'hr_holidays.mt_holidays_approved': lambda self, cr, uid, obj, ctx=None: obj.state == 'validate',\n            'hr_holidays.mt_holidays_refused': lambda self, cr, uid, obj, ctx=None: obj.state == 'refuse',\n            'hr_holidays.mt_holidays_confirmed': lambda self, cr, uid, obj, ctx=None: obj.state == 'confirm',\n        },\n    }\n    def _employee_get(self, cr, uid, context=None):        \n        emp_id = context.get('default_employee_id', False)\n        if emp_id:\n            return emp_id\n        ids = self.pool.get('hr.employee').search(cr, uid, [('user_id', '=', uid)], context=context)\n        if ids:\n            return ids[0]\n        return False\n    def _compute_number_of_days(self, cr, uid, ids, name, args, context=None):\n        result = {}\n        for hol in self.browse(cr, uid, ids, context=context):\n            if hol.type=='remove':\n                result[hol.id] = -hol.number_of_days_temp\n            else:\n                result[hol.id] = hol.number_of_days_temp\n        return result\n    def _get_can_reset(self, cr, uid, ids, name, arg, context=None):\n        \"\"\"User can reset a leave request if it is its own leave request or if\n        he is an Hr Manager. \"\"\"\n        user = self.pool['res.users'].browse(cr, uid, uid, context=context)\n        group_hr_manager_id = self.pool.get('ir.model.data').get_object_reference(cr, uid, 'base', 'group_hr_manager')[1]\n        if group_hr_manager_id in [g.id for g in user.groups_id]:\n            return dict.fromkeys(ids, True)\n        result = dict.fromkeys(ids, False)\n        for holiday in self.browse(cr, uid, ids, context=context):\n            if holiday.employee_id and holiday.employee_id.user_id and holiday.employee_id.user_id.id == uid:\n                result[holiday.id] = True\n        return result\n    def _check_date(self, cr, uid, ids, context=None):\n        for holiday in self.browse(cr, uid, ids, context=context):\n            domain = [\n                ('date_from', '<=', holiday.date_to),\n                ('date_to', '>=', holiday.date_from),\n                ('employee_id', '=', holiday.employee_id.id),\n                ('id', '!=', holiday.id),\n                ('state', 'not in', ['cancel', 'refuse']),\n            ]\n            nholidays = self.search_count(cr, uid, domain, context=context)\n            if nholidays:\n                return False\n        return True\n    _check_holidays = lambda self, cr, uid, ids, context=None: self.check_holidays(cr, uid, ids, context=context)\n    _columns = {\n        'name': fields.char('Description', size=64),\n        'state': fields.selection([('draft', 'To Submit'), ('cancel', 'Cancelled'),('confirm', 'To Approve'), ('refuse', 'Refused'), ('validate1', 'Second Approval'), ('validate', 'Approved')],\n            'Status', readonly=True, track_visibility='onchange', copy=False,\n            help='The status is set to \\'To Submit\\', when a holiday request is created.\\\n            \\nThe status is \\'To Approve\\', when holiday request is confirmed by user.\\\n            \\nThe status is \\'Refused\\', when holiday request is refused by manager.\\\n            \\nThe status is \\'Approved\\', when holiday request is approved by manager.'),\n        'user_id':fields.related('employee_id', 'user_id', type='many2one', relation='res.users', string='User', store=True),\n        'date_from': fields.datetime('Start Date', readonly=True, states={'draft':[('readonly',False)], 'confirm':[('readonly',False)]}, select=True, copy=False),\n        'date_to': fields.datetime('End Date', readonly=True, states={'draft':[('readonly',False)], 'confirm':[('readonly',False)]}, copy=False),\n        'holiday_status_id': fields.many2one(\"hr.holidays.status\", \"Leave Type\", required=True,readonly=True, states={'draft':[('readonly',False)], 'confirm':[('readonly',False)]}),\n        'employee_id': fields.many2one('hr.employee', \"Employee\", select=True, invisible=False, readonly=True, states={'draft':[('readonly',False)], 'confirm':[('readonly',False)]}),\n        'manager_id': fields.many2one('hr.employee', 'First Approval', invisible=False, readonly=True, copy=False,\n                                      help='This area is automatically filled by the user who validate the leave'),\n        'notes': fields.text('Reasons',readonly=True, states={'draft':[('readonly',False)], 'confirm':[('readonly',False)]}),\n        'number_of_days_temp': fields.float('Allocation', readonly=True, states={'draft':[('readonly',False)], 'confirm':[('readonly',False)]}, copy=False),\n        'number_of_days': fields.function(_compute_number_of_days, string='Number of Days', store=True),\n        'meeting_id': fields.many2one('calendar.event', 'Meeting'),\n        'type': fields.selection([('remove','Leave Request'),('add','Allocation Request')], 'Request Type', required=True, readonly=True, states={'draft':[('readonly',False)], 'confirm':[('readonly',False)]}, help=\"Choose 'Leave Request' if someone wants to take an off-day. \\nChoose 'Allocation Request' if you want to increase the number of leaves available for someone\", select=True),\n        'parent_id': fields.many2one('hr.holidays', 'Parent'),\n        'linked_request_ids': fields.one2many('hr.holidays', 'parent_id', 'Linked Requests',),\n        'department_id':fields.related('employee_id', 'department_id', string='Department', type='many2one', relation='hr.department', readonly=True, store=True),\n        'category_id': fields.many2one('hr.employee.category', \"Employee Tag\", help='Category of Employee', readonly=True, states={'draft':[('readonly',False)], 'confirm':[('readonly',False)]}),\n        'holiday_type': fields.selection([('employee','By Employee'),('category','By Employee Tag')], 'Allocation Mode', readonly=True, states={'draft':[('readonly',False)], 'confirm':[('readonly',False)]}, help='By Employee: Allocation/Request for individual Employee, By Employee Tag: Allocation/Request for group of employees in category', required=True),\n        'manager_id2': fields.many2one('hr.employee', 'Second Approval', readonly=True, copy=False,\n                                       help='This area is automaticly filled by the user who validate the leave with second level (If Leave type need second validation)'),\n        'double_validation': fields.related('holiday_status_id', 'double_validation', type='boolean', relation='hr.holidays.status', string='Apply Double Validation'),\n        'can_reset': fields.function(\n            _get_can_reset,\n            type='boolean'),\n    }\n    _defaults = {\n        'employee_id': _employee_get,\n        'state': 'confirm',\n        'type': 'remove',\n        'user_id': lambda obj, cr, uid, context: uid,\n        'holiday_type': 'employee'\n    }\n    _constraints = [\n        (_check_date, 'You can not have 2 leaves that overlaps on same day!', ['date_from','date_to']),\n        (_check_holidays, 'The number of remaining leaves is not sufficient for this leave type', ['state','number_of_days_temp'])\n    ] \n    \n    _sql_constraints = [\n        ('type_value', \"CHECK( (holiday_type='employee' AND employee_id IS NOT NULL) or (holiday_type='category' AND category_id IS NOT NULL))\", \n         \"The employee or employee category of this request is missing. Please make sure that your user login is linked to an employee.\"),\n        ('date_check2', \"CHECK ( (type='add') OR (date_from <= date_to))\", \"The start date must be anterior to the end date.\"),\n        ('date_check', \"CHECK ( number_of_days_temp >= 0 )\", \"The number of days must be greater than 0.\"),\n    ]\n    def _create_resource_leave(self, cr, uid, leaves, context=None):\n        '''This method will create entry in resource calendar leave object at the time of holidays validated '''\n        obj_res_leave = self.pool.get('resource.calendar.leaves')\n        for leave in leaves:\n            vals = {\n                'name': leave.name,\n                'date_from': leave.date_from,\n                'holiday_id': leave.id,\n                'date_to': leave.date_to,\n                'resource_id': leave.employee_id.resource_id.id,\n                'calendar_id': leave.employee_id.resource_id.calendar_id.id\n            }\n            obj_res_leave.create(cr, uid, vals, context=context)\n        return True\n    def _remove_resource_leave(self, cr, uid, ids, context=None):\n        '''This method will create entry in resource calendar leave object at the time of holidays cancel/removed'''\n        obj_res_leave = self.pool.get('resource.calendar.leaves')\n        leave_ids = obj_res_leave.search(cr, uid, [('holiday_id', 'in', ids)], context=context)\n        return obj_res_leave.unlink(cr, uid, leave_ids, context=context)\n    def onchange_type(self, cr, uid, ids, holiday_type, employee_id=False, context=None):\n        result = {}\n        if holiday_type == 'employee' and not employee_id:\n            ids_employee = self.pool.get('hr.employee').search(cr, uid, [('user_id','=', uid)])\n            if ids_employee:\n                result['value'] = {\n                    'employee_id': ids_employee[0]\n                }\n        elif holiday_type != 'employee':\n            result['value'] = {\n                    'employee_id': False\n                }\n        return result\n    def onchange_employee(self, cr, uid, ids, employee_id):\n        result = {'value': {'department_id': False}}\n        if employee_id:\n            employee = self.pool.get('hr.employee').browse(cr, uid, employee_id)\n            result['value'] = {'department_id': employee.department_id.id}\n        return result\n    # TODO: can be improved using resource calendar method\n    def _get_number_of_days(self, date_from, date_to):\n        \"\"\"Returns a float equals to the timedelta between two dates given as string.\"\"\"\n        DATETIME_FORMAT = \"%Y-%m-%d %H:%M:%S\"\n        from_dt = datetime.datetime.strptime(date_from, DATETIME_FORMAT)\n        to_dt = datetime.datetime.strptime(date_to, DATETIME_FORMAT)\n        timedelta = to_dt - from_dt\n        diff_day = timedelta.days + float(timedelta.seconds) / 86400\n        return diff_day\n    def unlink(self, cr, uid, ids, context=None):\n        for rec in self.browse(cr, uid, ids, context=context):\n            if rec.state not in ['draft', 'cancel', 'confirm']:\n                raise osv.except_osv(_('Warning!'),_('You cannot delete a leave which is in %s state.')%(rec.state))\n        return super(hr_holidays, self).unlink(cr, uid, ids, context)\n    def onchange_date_from(self, cr, uid, ids, date_to, date_from):\n        \"\"\"\n        If there are no date set for date_to, automatically set one 8 hours later than\n        the date_from.\n        Also update the number_of_days.\n        \"\"\"\n        # date_to has to be greater than date_from\n        if (date_from and date_to) and (date_from > date_to):\n            raise osv.except_osv(_('Warning!'),_('The start date must be anterior to the end date.'))\n        result = {'value': {}}\n        # No date_to set so far: automatically compute one 8 hours later\n        if date_from and not date_to:\n            date_to_with_delta = datetime.datetime.strptime(date_from, tools.DEFAULT_SERVER_DATETIME_FORMAT) + datetime.timedelta(hours=8)\n            result['value']['date_to'] = str(date_to_with_delta)\n        # Compute and update the number of days\n        if (date_to and date_from) and (date_from <= date_to):\n            diff_day = self._get_number_of_days(date_from, date_to)\n            result['value']['number_of_days_temp'] = round(math.floor(diff_day))+1\n        else:\n            result['value']['number_of_days_temp'] = 0\n        return result\n    def onchange_date_to(self, cr, uid, ids, date_to, date_from):\n        \"\"\"\n        Update the number_of_days.\n        \"\"\"\n        # date_to has to be greater than date_from\n        if (date_from and date_to) and (date_from > date_to):\n            raise osv.except_osv(_('Warning!'),_('The start date must be anterior to the end date.'))\n        result = {'value': {}}\n        # Compute and update the number of days\n        if (date_to and date_from) and (date_from <= date_to):\n            diff_day = self._get_number_of_days(date_from, date_to)\n            result['value']['number_of_days_temp'] = round(math.floor(diff_day))+1\n        else:\n            result['value']['number_of_days_temp'] = 0\n        return result\n    def add_follower(self, cr, uid, ids, employee_id, context=None):\n        employee = self.pool['hr.employee'].browse(cr, uid, employee_id, context=context)\n        if employee.user_id:\n            self.message_subscribe(cr, uid, ids, [employee.user_id.partner_id.id], context=context)\n    def create(self, cr, uid, values, context=None):\n        \"\"\" Override to avoid automatic logging of creation \"\"\"\n        if context is None:\n            context = {}\n        employee_id = values.get('employee_id', False)\n        context = dict(context, mail_create_nolog=True, mail_create_nosubscribe=True)\n        if values.get('state') and values['state'] not in ['draft', 'confirm', 'cancel'] and not self.pool['res.users'].has_group(cr, uid, 'base.group_hr_user'):\n            raise osv.except_osv(_('Warning!'), _('You cannot set a leave request as \\'%s\\'. Contact a human resource manager.') % values.get('state'))\n        hr_holiday_id = super(hr_holidays, self).create(cr, uid, values, context=context)\n        self.add_follower(cr, uid, [hr_holiday_id], employee_id, context=context)\n        return hr_holiday_id\n    def write(self, cr, uid, ids, vals, context=None):\n        employee_id = vals.get('employee_id', False)\n        if vals.get('state') and vals['state'] not in ['draft', 'confirm', 'cancel'] and not self.pool['res.users'].has_group(cr, uid, 'base.group_hr_user'):\n            raise osv.except_osv(_('Warning!'), _('You cannot set a leave request as \\'%s\\'. Contact a human resource manager.') % vals.get('state'))\n        hr_holiday_id = super(hr_holidays, self).write(cr, uid, ids, vals, context=context)\n        self.add_follower(cr, uid, ids, employee_id, context=context)\n        return hr_holiday_id\n    def holidays_reset(self, cr, uid, ids, context=None):\n        self.write(cr, uid, ids, {\n            'state': 'draft',\n            'manager_id': False,\n            'manager_id2': False,\n        })\n        to_unlink = []\n        for record in self.browse(cr, uid, ids, context=context):\n            for record2 in record.linked_request_ids:\n                self.holidays_reset(cr, uid, [record2.id], context=context)\n                to_unlink.append(record2.id)\n        if to_unlink:\n            self.unlink(cr, uid, to_unlink, context=context)\n        return True\n    def holidays_first_validate(self, cr, uid, ids, context=None):\n        obj_emp = self.pool.get('hr.employee')\n        ids2 = obj_emp.search(cr, uid, [('user_id', '=', uid)])\n        manager = ids2 and ids2[0] or False\n        self.holidays_first_validate_notificate(cr, uid, ids, context=context)\n        return self.write(cr, uid, ids, {'state':'validate1', 'manager_id': manager})\n    def holidays_validate(self, cr, uid, ids, context=None):\n", "outputs": ["        obj_emp = self.pool.get('hr.employee')"], "input_length": 4270, "output_length": 7, "length": 4277, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "4996467c353cc3c33ea9253cd2c10cd5cf58377d0bcbd645ab9a022bcadb6447"}
{"input": "", "context": "/*\n * Copyright (C) 2000 - 2011 Silverpeas\n *\n * This program is free software: you can redistribute it and/or modify\n * it under the terms of the GNU Affero General Public License as\n * published by the Free Software Foundation, either version 3 of the\n * License, or (at your option) any later version.\n *\n * As a special exception to the terms and conditions of version 3.0 of\n * the GPL, you may redistribute this Program in connection with Free/Libre\n * Open Source Software (\"FLOSS\") applications as described in Silverpeas's\n * FLOSS exception.  You should have recieved a copy of the text describing\n * the FLOSS exception, and it is also available here:\n * \"http://www.silverpeas.org/legal/licensing\"\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU Affero General Public License for more details.\n *\n * You should have received a copy of the GNU Affero General Public License\n * along with this program.  If not, see <http://www.gnu.org/licenses/>.\n */\npackage com.stratelia.webactiv.almanach.control.ejb;\nimport com.silverpeas.calendar.Datable;\nimport com.silverpeas.calendar.Date;\nimport static com.silverpeas.util.StringUtil.isDefined;\nimport com.stratelia.webactiv.almanach.control.ExceptionDatesGenerator;\nimport com.stratelia.webactiv.almanach.model.EventDetail;\nimport com.stratelia.webactiv.almanach.model.EventOccurrence;\nimport static com.stratelia.webactiv.almanach.model.EventOccurrence.*;\nimport com.stratelia.webactiv.almanach.model.Periodicity;\nimport com.stratelia.webactiv.almanach.model.PeriodicityException;\nimport com.stratelia.webactiv.persistence.IdPK;\nimport com.stratelia.webactiv.persistence.PersistenceException;\nimport com.stratelia.webactiv.persistence.SilverpeasBeanDAO;\nimport com.stratelia.webactiv.persistence.SilverpeasBeanDAOFactory;\nimport static com.stratelia.webactiv.util.DateUtil.extractHour;\nimport static com.stratelia.webactiv.util.DateUtil.extractMinutes;\nimport com.stratelia.webactiv.util.ResourceLocator;\nimport com.stratelia.webactiv.util.exception.SilverpeasRuntimeException;\nimport java.util.*;\nimport java.util.TimeZone;\nimport net.fortuna.ical4j.model.Calendar;\nimport net.fortuna.ical4j.model.*;\nimport net.fortuna.ical4j.model.component.VEvent;\nimport net.fortuna.ical4j.model.property.CalScale;\nimport net.fortuna.ical4j.model.property.Categories;\nimport net.fortuna.ical4j.model.property.ExDate;\n/**\n * A generator of event occurrences built on the iCal4J library.\n */\npublic class ICal4JEventOccurrencesGenerator implements EventOccurrenceGenerator {\n  @Override\n  public List<EventOccurrence> generateOccurrencesInYear(java.util.Calendar year,\n          List<EventDetail> events) {\n    java.util.Calendar firstDayYear = java.util.Calendar.getInstance();\n    firstDayYear.set(java.util.Calendar.YEAR, year.get(java.util.Calendar.YEAR));\n    firstDayYear.set(java.util.Calendar.DAY_OF_MONTH, 1);\n    firstDayYear.set(java.util.Calendar.MONTH, java.util.Calendar.JANUARY);\n    firstDayYear.set(java.util.Calendar.HOUR_OF_DAY, 0);\n    firstDayYear.set(java.util.Calendar.MINUTE, 0);\n    firstDayYear.set(java.util.Calendar.SECOND, 0);\n    firstDayYear.set(java.util.Calendar.MILLISECOND, 0);\n    java.util.Calendar lastDayYear = java.util.Calendar.getInstance();\n    lastDayYear.set(java.util.Calendar.YEAR, year.get(java.util.Calendar.YEAR));\n    lastDayYear.set(java.util.Calendar.DAY_OF_MONTH, 1);\n    lastDayYear.set(java.util.Calendar.MONTH, java.util.Calendar.JANUARY);\n    lastDayYear.set(java.util.Calendar.HOUR_OF_DAY, 0);\n    lastDayYear.set(java.util.Calendar.MINUTE, 0);\n    lastDayYear.set(java.util.Calendar.SECOND, 0);\n    lastDayYear.set(java.util.Calendar.MILLISECOND, 0);\n    lastDayYear.add(java.util.Calendar.YEAR, 1);\n    Period theYear = new Period(new DateTime(firstDayYear.getTime()),\n            new DateTime(lastDayYear.getTime()));\n    return generateOccurrencesOf(events, occuringIn(theYear));\n  }\n  @Override\n  public List<EventOccurrence> generateOccurrencesInMonth(java.util.Calendar month,\n          List<EventDetail> events) {\n    java.util.Calendar firstDayMonth = java.util.Calendar.getInstance();\n    firstDayMonth.set(java.util.Calendar.YEAR, month.get(java.util.Calendar.YEAR));\n    firstDayMonth.set(java.util.Calendar.DAY_OF_MONTH, 1);\n    firstDayMonth.set(java.util.Calendar.MONTH, month.get(java.util.Calendar.MONTH));\n    firstDayMonth.set(java.util.Calendar.HOUR_OF_DAY, 0);\n    firstDayMonth.set(java.util.Calendar.MINUTE, 0);\n    firstDayMonth.set(java.util.Calendar.SECOND, 0);\n    firstDayMonth.set(java.util.Calendar.MILLISECOND, 0);\n    java.util.Calendar lastDayMonth = java.util.Calendar.getInstance();\n    lastDayMonth.set(java.util.Calendar.YEAR, month.get(java.util.Calendar.YEAR));\n    lastDayMonth.set(java.util.Calendar.DAY_OF_MONTH, 1);\n    lastDayMonth.set(java.util.Calendar.MONTH, month.get(java.util.Calendar.MONTH));\n    lastDayMonth.set(java.util.Calendar.HOUR_OF_DAY, 0);\n    lastDayMonth.set(java.util.Calendar.MINUTE, 0);\n    lastDayMonth.set(java.util.Calendar.SECOND, 0);\n    lastDayMonth.set(java.util.Calendar.MILLISECOND, 0);\n    lastDayMonth.add(java.util.Calendar.MONTH, 1);\n    Period theMonth = new Period(new DateTime(firstDayMonth.getTime()),\n            new DateTime(lastDayMonth.getTime()));\n    return generateOccurrencesOf(events, occuringIn(theMonth));\n  }\n  @Override\n  public List<EventOccurrence> generateOccurrencesInWeek(java.util.Calendar week,\n          List<EventDetail> events) {\n    java.util.Calendar firstDayWeek = java.util.Calendar.getInstance();\n    firstDayWeek.setTime(week.getTime());\n    firstDayWeek.set(java.util.Calendar.DAY_OF_WEEK, week.getFirstDayOfWeek());\n    firstDayWeek.set(java.util.Calendar.HOUR_OF_DAY, 0);\n    firstDayWeek.set(java.util.Calendar.MINUTE, 0);\n    firstDayWeek.set(java.util.Calendar.SECOND, 0);\n    firstDayWeek.set(java.util.Calendar.MILLISECOND, 0);\n    java.util.Calendar lastDayWeek = java.util.Calendar.getInstance();\n    lastDayWeek.setTime(week.getTime());\n    lastDayWeek.set(java.util.Calendar.HOUR_OF_DAY, 0);\n    lastDayWeek.set(java.util.Calendar.MINUTE, 0);\n    lastDayWeek.set(java.util.Calendar.SECOND, 0);\n    lastDayWeek.set(java.util.Calendar.MILLISECOND, 0);\n    lastDayWeek.set(java.util.Calendar.DAY_OF_WEEK, week.getFirstDayOfWeek());\n    lastDayWeek.add(java.util.Calendar.WEEK_OF_YEAR, 1);\n    Period theWeek = new Period(new DateTime(firstDayWeek.getTime()),\n            new DateTime(lastDayWeek.getTime()));\n    return generateOccurrencesOf(events, occuringIn(theWeek));\n  }\n  @Override\n  public List<EventOccurrence> generateOccurrencesInRange(Date startDate,  Date endDate,\n    List<EventDetail> events) {\n    Period period = new Period(new DateTime(startDate), new DateTime(endDate));\n    return generateOccurrencesOf(events, occuringIn(period));\n  }\n  \n  @Override\n  public List<EventOccurrence> generateOccurrencesFrom(Date date,  List<EventDetail> events) {\n    java.util.Calendar endDate = java.util.Calendar.getInstance();\n    // a hack as the iCal4J Period objects don't support null end date or infinite end date.\n    endDate.add(java.util.Calendar.YEAR, 100);\n    return generateOccurrencesInRange(date, new Date(endDate.getTime()), events);\n  }\n  /**\n   * Generates the occurrences of the specified events that occur in the specified period.\n   * @param events the events for which the occurrences has to be generated.\n   * @param inPeriod the period.\n   * @return a list of event occurrences that occur in the specified period.\n   */\n  private List<EventOccurrence> generateOccurrencesOf(final List<EventDetail> events,\n          final Period inPeriod) {\n    List<EventOccurrence> occurrences = new ArrayList<EventOccurrence>();\n    Calendar iCal4JCalendar = anICalCalendarWith(events);\n    ComponentList componentList = iCal4JCalendar.getComponents(Component.VEVENT);\n    for (Object eventObject : componentList) {\n      VEvent iCalEvent = (VEvent) eventObject;\n      int index = Integer.parseInt(iCalEvent.getProperties().getProperty(Property.CATEGORIES).\n              getValue());\n      EventDetail event = events.get(index);\n      PeriodList periodList = iCalEvent.calculateRecurrenceSet(inPeriod);\n      for (Object recurrencePeriodObject : periodList) {\n        Period recurrencePeriod = (Period) recurrencePeriodObject;\n        Datable<?> startDate = toDatable(recurrencePeriod.getStart(), event.getStartHour());\n        Datable<?> endDate = toDatable(recurrencePeriod.getEnd(), event.getEndHour());\n        EventOccurrence occurrence = anOccurrenceOf(event, startingAt(startDate), endingAt(endDate)).\n                withPriority(event.isPriority());\n        occurrences.add(occurrence);\n      }\n    }\n    Collections.sort(occurrences);\n    return occurrences;\n  }\n  /**\n   * Gets an iCal calendar with the specified events.\n   * It uses ical4J to build the ical calendar.\n   * @param events the events to register in the iCal4J calendar to return.\n   * @return an iCal4J calendar instance with the events specified in parameter.\n   */\n  private Calendar anICalCalendarWith(final List<EventDetail> events) {\n    Calendar calendarAlmanach = new Calendar();\n    calendarAlmanach.getProperties().add(CalScale.GREGORIAN);\n    for (int i = 0; i < events.size(); i++) {\n      EventDetail event = events.get(i);\n      ExDate exceptionDates = null;\n      if (event.isPeriodic()) {\n        exceptionDates = generateExceptionDates(event);\n      }\n      VEvent iCalEvent = event.icalConversion(exceptionDates);\n      iCalEvent.getProperties().add(new Categories(String.valueOf(i)));\n      calendarAlmanach.getComponents().add(iCalEvent);\n    }\n    return calendarAlmanach;\n  }\n  /**\n   * Generates the dates at which it exist some exceptions in the periodicity of the specified event.\n   * @param event the detail on the event for which it can exist some exceptions in his recurrence.\n   * @return an ExDate instance with all of the exception dates.\n   */\n  private ExDate generateExceptionDates(final EventDetail event) {\n    ExceptionDatesGenerator generator = new ExceptionDatesGenerator();\n    Set<java.util.Date> exceptionDates = generator.generateExceptionDates(event);\n    DateList exDateList = new DateList();\n", "outputs": ["    for (java.util.Date anExceptionDate : exceptionDates) {"], "input_length": 1480, "output_length": 8, "length": 1488, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "84ecf131d75346117dd1075bca7c4de7377a4e2503552959355d7cb13c60bf31"}
{"input": "", "context": "package org.zeromq;\nimport static org.hamcrest.CoreMatchers.is;\nimport static org.hamcrest.CoreMatchers.notNullValue;\nimport static org.hamcrest.MatcherAssert.assertThat;\nimport java.io.IOException;\nimport java.lang.Thread.UncaughtExceptionHandler;\nimport java.util.concurrent.Callable;\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\nimport java.util.concurrent.Future;\nimport java.util.concurrent.ThreadFactory;\nimport java.util.concurrent.TimeUnit;\nimport org.junit.Ignore;\nimport org.junit.Test;\nimport org.zeromq.ZMQ.Socket;\npublic class PubSubTest\n{\n    @Test\n    @Ignore\n    public void testRaceConditionIssue322() throws IOException, InterruptedException\n    {\n        final ZMQ.Context context = ZMQ.context(1);\n        final String address = \"tcp://localhost:\" + Utils.findOpenPort();\n        final byte[] msg = \"abc\".getBytes();\n        final int messagesNumber = 1000;\n        //run publisher\n        Runnable pub = new Runnable()\n        {\n            @Override\n            public void run()\n            {\n                ZMQ.Socket publisher = context.socket(SocketType.PUB);\n                publisher.bind(address);\n                int count = messagesNumber;\n                while (count-- > 0) {\n                    publisher.send(msg);\n                    System.out.println(\"Send message \" + count);\n                }\n                publisher.close();\n            }\n        };\n        //run subscriber\n        Runnable sub = new Runnable()\n        {\n            @Override\n            public void run()\n            {\n                ZMQ.Socket subscriber = context.socket(SocketType.SUB);\n                subscriber.connect(address);\n                subscriber.subscribe(ZMQ.SUBSCRIPTION_ALL);\n                int count = messagesNumber;\n                while (count-- > 0) {\n                    subscriber.recv();\n                    System.out.println(\"Received message \" + count);\n                }\n                subscriber.close();\n            }\n        };\n        ExecutorService executor = Executors.newFixedThreadPool(2, new ThreadFactory()\n        {\n            @Override\n            public Thread newThread(Runnable r)\n            {\n                Thread thread = new Thread(r);\n                thread.setUncaughtExceptionHandler(new UncaughtExceptionHandler()\n                {\n                    @Override\n                    public void uncaughtException(Thread t, Throwable e)\n                    {\n                        e.printStackTrace();\n                    }\n                });\n                return thread;\n            }\n        });\n        executor.submit(sub);\n        zmq.ZMQ.sleep(1);\n        executor.submit(pub);\n        executor.shutdown();\n        executor.awaitTermination(30, TimeUnit.SECONDS);\n        context.close();\n    }\n    @Test\n    @Ignore\n    public void testPubConnectSubBindIssue289and342() throws IOException\n    {\n        ZMQ.Context context = ZMQ.context(1);\n        Socket pub = context.socket(SocketType.XPUB);\n        assertThat(pub, notNullValue());\n        Socket sub = context.socket(SocketType.SUB);\n        assertThat(sub, notNullValue());\n        boolean rc = sub.subscribe(new byte[0]);\n        assertThat(rc, is(true));\n        String host = \"tcp://localhost:\" + Utils.findOpenPort();\n        rc = sub.bind(host);\n        assertThat(rc, is(true));\n        rc = pub.connect(host);\n        assertThat(rc, is(true));\n        zmq.ZMQ.msleep(300);\n        rc = pub.send(\"test\");\n        assertThat(rc, is(true));\n        assertThat(sub.recvStr(), is(\"test\"));\n        pub.close();\n        sub.close();\n        context.term();\n    }\n    @Test\n    public void testUnsubscribeIssue554() throws Exception\n    {\n        final int port = Utils.findOpenPort();\n        final ExecutorService service = Executors.newFixedThreadPool(2);\n        final Callable<Boolean> pub = new Callable<Boolean>()\n        {\n            @Override\n            public Boolean call()\n            {\n                final ZMQ.Context ctx = ZMQ.context(1);\n                assertThat(ctx, notNullValue());\n                final ZMQ.Socket pubsocket = ctx.socket(SocketType.PUB);\n                assertThat(pubsocket, notNullValue());\n                boolean rc = pubsocket.bind(\"tcp://*:\" + port);\n                assertThat(rc, is(true));\n                for (int idx = 1; idx <= 15; ++idx) {\n                    rc = pubsocket.sendMore(\"test/\");\n                    assertThat(rc, is(true));\n                    rc = pubsocket.send(\"data\" + idx);\n                    assertThat(rc, is(true));\n                    System.out.printf(\"Send-%d/\", idx);\n                    ZMQ.msleep(100);\n                }\n                pubsocket.close();\n                ctx.close();\n                return true;\n            }\n        };\n        final Callable<Integer> sub = new Callable<Integer>()\n        {\n            @Override\n            public Integer call() throws Exception\n            {\n                final ZMQ.Context ctx = ZMQ.context(1);\n                assertThat(ctx, notNullValue());\n                final ZMQ.Socket sub = ctx.socket(SocketType.SUB);\n                assertThat(sub, notNullValue());\n                boolean rc = sub.setReceiveTimeOut(3000);\n                assertThat(rc, is(true));\n                rc = sub.subscribe(\"test/\");\n                assertThat(rc, is(true));\n                rc = sub.connect(\"tcp://localhost:\" + port);\n                assertThat(rc, is(true));\n                System.out.println(\"[SUB]\");\n                int received = receive(sub, 5);\n                assertThat(received > 1, is(true));\n                // unsubscribe from the topic and verify that we don't receive messages anymore\n                rc = sub.unsubscribe(\"test/\");\n                assertThat(rc, is(true));\n                System.out.printf(\"%n[UNSUB]%n\");\n                received = receive(sub, 10);\n                sub.close();\n                ctx.close();\n                return received;\n            }\n            private int receive(ZMQ.Socket socket, int maxSeconds)\n            {\n                int received = 0;\n                long current = System.currentTimeMillis();\n                long end = current + maxSeconds * 1000;\n                while (current < end) {\n                    ZMsg msg = ZMsg.recvMsg(socket);\n                    current = System.currentTimeMillis();\n                    if (msg == null) {\n                        continue;\n                    }\n                    ++received;\n                }\n                return received;\n            }\n        };\n        final Future<Integer> rc = service.submit(sub);\n", "outputs": ["        final Future<Boolean> pubf = service.submit(pub);"], "input_length": 1021, "output_length": 12, "length": 1033, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "f9af5862b4ebe140172bfd2ffaa5a5c78b0f9f1fa12acd45ca9226563bc775e5"}
{"input": "", "context": "# -*- coding: utf-8 -*-\n\"\"\"\nCopyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>\nLicensed under LGPLv3, see LICENSE.txt for terms and conditions.\n\"\"\"\nfrom __future__ import absolute_import, division, print_function, unicode_literals\n# stdlib\nimport logging\nfrom functools import wraps\n# SQLAlchemy\nfrom sqlalchemy import func, not_\nfrom sqlalchemy.orm import aliased\nfrom sqlalchemy.sql.expression import case\n# Zato\nfrom zato.common import DEFAULT_HTTP_PING_METHOD, DEFAULT_HTTP_POOL_SIZE, HTTP_SOAP_SERIALIZATION_TYPE, PARAMS_PRIORITY, \\\n     URL_PARAMS_PRIORITY\nfrom zato.common.odb.model import AWSS3, APIKeySecurity, AWSSecurity, CassandraConn, CassandraQuery, ChannelAMQP, \\\n     ChannelSTOMP, ChannelWebSocket, ChannelWMQ, ChannelZMQ, Cluster, ConnDefAMQP, ConnDefWMQ, CronStyleJob, \\\n     DeliveryDefinitionBase, Delivery, DeliveryHistory, DeliveryPayload, ElasticSearch, HTTPBasicAuth, HTTPSOAP, HTTSOAPAudit, \\\n     IMAP, IntervalBasedJob, Job, JSONPointer, JWT, MsgNamespace, NotificationOpenStackSwift as NotifOSS, \\\n     NotificationSQL as NotifSQL, NTLM, OAuth, OutgoingOdoo, OpenStackSecurity, OpenStackSwift, OutgoingAMQP, OutgoingFTP, \\\n     OutgoingSTOMP, OutgoingWMQ, OutgoingZMQ, PubSubConsumer, PubSubProducer, PubSubTopic, RBACClientRole, RBACPermission, \\\n     RBACRole, RBACRolePermission, SecurityBase, Server, Service, SMTP, Solr, SQLConnectionPool, TechnicalAccount, TLSCACert, \\\n     TLSChannelSecurity, TLSKeyCertSecurity, WebSocketClient, WebSocketSubscription, WSSDefinition, VaultConnection, \\\n     XPath, XPathSecurity\n# ################################################################################################################################\nlogger = logging.getLogger(__name__)\n# ################################################################################################################################\n_no_page_limit = 2 ** 24 # ~16.7 million results, tops\n# ################################################################################################################################\nclass _SearchResult(object):\n    def __init__(self, q, result, columns, total):\n        self.q = q\n        self.result = result\n        self.total = total\n        self.columns = columns\n        self.num_pages = 0\n        self.cur_page = 0\n        self.prev_page = 0\n        self.next_page = 0\n        self.has_prev_page = False\n        self.has_next_page = False\n    def __iter__(self):\n        return iter(self.result)\n    def __repr__(self):\n        # To avoice circular imports - this is OK because we very rarely repr(self) anyway\n        from zato.common.util import make_repr\n        return make_repr(self)\nclass _SearchWrapper(object):\n    \"\"\" Wraps results in pagination and/or filters out objects by their name or other attributes.\n    \"\"\"\n    def __init__(self, q, default_page_size=_no_page_limit, **config):\n        # Apply WHERE conditions\n        for filter_by in config.get('filter_by', []):\n            for criterion in config.get('query', []):\n                q = q.filter(filter_by.contains(criterion))\n        # Total number of results\n        total_q = q.statement.with_only_columns([func.count()]).order_by(None)\n        self.total = q.session.execute(total_q).scalar()\n        # Pagination\n        page_size = config.get('page_size', default_page_size)\n        cur_page = config.get('cur_page', 0)\n        slice_from = cur_page * page_size\n        slice_to = slice_from + page_size\n        self.q = q.slice(slice_from, slice_to)\n# ################################################################################################################################\ndef query_wrapper(func):\n    \"\"\" A decorator for queries which works out whether a given query function should return the result only\n    or a column list retrieved in addition to the result. This is useful because some callers prefer the former\n    and some need the latter. Also, paginages the results if requested to by the caller.\n    \"\"\"\n    @wraps(func)\n    def inner(*args, **kwargs):\n        # needs_columns is always the last argument\n        # so we don't have to look it up using the 'inspect' module or anything like that.\n        needs_columns = args[-1]\n        tool = _SearchWrapper(func(*args), **kwargs)\n        result = _SearchResult(tool.q, tool.q.all(), tool.q.statement.columns, tool.total)\n        if needs_columns:\n            return result, result.columns\n        return result\n    return inner\n# ################################################################################################################################\ndef internal_channel_list(session, cluster_id):\n    \"\"\" All the HTTP/SOAP channels that point to internal services.\n    \"\"\"\n    return session.query(\n        HTTPSOAP.soap_action, Service.name).\\\n        filter(HTTPSOAP.cluster_id==Cluster.id).\\\n        filter(HTTPSOAP.service_id==Service.id).filter(Service.is_internal==True).filter(Cluster.id==cluster_id).filter(Cluster.id==HTTPSOAP.cluster_id) # noqa\n# ################################################################################################################################\ndef _job(session, cluster_id):\n    return session.query(\n        Job.id, Job.name, Job.is_active,\n        Job.job_type, Job.start_date, Job.extra,\n        Service.name.label('service_name'), Service.impl_name.label('service_impl_name'),\n        Service.id.label('service_id'),\n        IntervalBasedJob.weeks, IntervalBasedJob.days,\n        IntervalBasedJob.hours, IntervalBasedJob.minutes,\n        IntervalBasedJob.seconds, IntervalBasedJob.repeats,\n        CronStyleJob.cron_definition).\\\n        outerjoin(IntervalBasedJob, Job.id==IntervalBasedJob.job_id).\\\n        outerjoin(CronStyleJob, Job.id==CronStyleJob.job_id).\\\n        filter(Job.cluster_id==Cluster.id).\\\n        filter(Job.service_id==Service.id).\\\n        filter(Cluster.id==cluster_id).\\\n        order_by('job.name')\n@query_wrapper\ndef job_list(session, cluster_id, needs_columns=False):\n    \"\"\" All the scheduler's jobs defined in the ODB.\n    \"\"\"\n    return _job(session, cluster_id)\ndef job_by_name(session, cluster_id, name):\n    \"\"\" A scheduler's job fetched by its name.\n    \"\"\"\n    return _job(session, cluster_id).\\\n        filter(Job.name==name).\\\n        one()\n# ################################################################################################################################\n@query_wrapper\ndef apikey_security_list(session, cluster_id, needs_columns=False):\n    \"\"\" All the API keys.\n    \"\"\"\n    return session.query(\n        APIKeySecurity.id, APIKeySecurity.name,\n        APIKeySecurity.is_active,\n        APIKeySecurity.username,\n        APIKeySecurity.password, APIKeySecurity.sec_type).\\\n        filter(Cluster.id==cluster_id).\\\n        filter(Cluster.id==APIKeySecurity.cluster_id).\\\n        filter(SecurityBase.id==APIKeySecurity.id).\\\n        order_by('sec_base.name')\n@query_wrapper\ndef aws_security_list(session, cluster_id, needs_columns=False):\n    \"\"\" All the Amazon security definitions.\n    \"\"\"\n    return session.query(\n        AWSSecurity.id, AWSSecurity.name,\n        AWSSecurity.is_active,\n        AWSSecurity.username,\n        AWSSecurity.password, AWSSecurity.sec_type).\\\n        filter(Cluster.id==cluster_id).\\\n        filter(Cluster.id==AWSSecurity.cluster_id).\\\n        filter(SecurityBase.id==AWSSecurity.id).\\\n        order_by('sec_base.name')\n@query_wrapper\ndef basic_auth_list(session, cluster_id, cluster_name, needs_columns=False):\n    \"\"\" All the HTTP Basic Auth definitions.\n    \"\"\"\n    q = session.query(\n        HTTPBasicAuth.id, HTTPBasicAuth.name,\n        HTTPBasicAuth.is_active,\n        HTTPBasicAuth.username, HTTPBasicAuth.realm,\n        HTTPBasicAuth.password, HTTPBasicAuth.sec_type,\n        HTTPBasicAuth.password_type,\n        Cluster.id.label('cluster_id'), Cluster.name.label('cluster_name')).\\\n        filter(Cluster.id==HTTPBasicAuth.cluster_id)\n    if cluster_id:\n        q = q.filter(Cluster.id==cluster_id)\n    else:\n        q = q.filter(Cluster.name==cluster_name)\n    q = q.filter(SecurityBase.id==HTTPBasicAuth.id).\\\n        order_by('sec_base.name')\n    return q\ndef _jwt(session, cluster_id, cluster_name, needs_columns=False):\n    \"\"\" All the JWT definitions.\n    \"\"\"\n    q = session.query(\n        JWT.id, JWT.name, JWT.is_active, JWT.username, JWT.password,\n        JWT.ttl, JWT.sec_type, JWT.password_type,\n        Cluster.id.label('cluster_id'),\n        Cluster.name.label('cluster_name')).\\\n        filter(Cluster.id==JWT.cluster_id)\n    if cluster_id:\n        q = q.filter(Cluster.id==cluster_id)\n    else:\n        q = q.filter(Cluster.name==cluster_name)\n    q = q.filter(SecurityBase.id==JWT.id).\\\n        order_by('sec_base.name')\n    return q\n@query_wrapper\ndef jwt_list(*args, **kwargs):\n    return _jwt(*args, **kwargs)\ndef jwt_by_username(session, cluster_id, username, needs_columns=False):\n    \"\"\" An individual JWT definition by its username.\n    \"\"\"\n    return _jwt(session, cluster_id, None, needs_columns).\\\n        filter(JWT.username==username).\\\n        one()\n@query_wrapper\ndef ntlm_list(session, cluster_id, needs_columns=False):\n    \"\"\" All the NTLM definitions.\n    \"\"\"\n    return session.query(\n        NTLM.id, NTLM.name,\n        NTLM.is_active,\n        NTLM.username,\n        NTLM.password, NTLM.sec_type,\n        NTLM.password_type).\\\n        filter(Cluster.id==cluster_id).\\\n        filter(Cluster.id==NTLM.cluster_id).\\\n        filter(SecurityBase.id==NTLM.id).\\\n        order_by('sec_base.name')\n@query_wrapper\ndef oauth_list(session, cluster_id, needs_columns=False):\n    \"\"\" All the OAuth definitions.\n    \"\"\"\n    return session.query(\n        OAuth.id, OAuth.name,\n        OAuth.is_active,\n        OAuth.username, OAuth.password,\n        OAuth.proto_version, OAuth.sig_method,\n        OAuth.max_nonce_log, OAuth.sec_type).\\\n        filter(Cluster.id==cluster_id).\\\n        filter(Cluster.id==OAuth.cluster_id).\\\n        filter(SecurityBase.id==OAuth.id).\\\n        order_by('sec_base.name')\n@query_wrapper\ndef openstack_security_list(session, cluster_id, needs_columns=False):\n    \"\"\" All the OpenStackSecurity definitions.\n    \"\"\"\n    return session.query(\n        OpenStackSecurity.id, OpenStackSecurity.name, OpenStackSecurity.is_active,\n        OpenStackSecurity.username, OpenStackSecurity.sec_type).\\\n        filter(Cluster.id==cluster_id).\\\n        filter(Cluster.id==OpenStackSecurity.cluster_id).\\\n        filter(SecurityBase.id==OpenStackSecurity.id).\\\n        order_by('sec_base.name')\n@query_wrapper\ndef tech_acc_list(session, cluster_id, needs_columns=False):\n    \"\"\" All the technical accounts.\n    \"\"\"\n    return session.query(\n        TechnicalAccount.id, TechnicalAccount.name,\n        TechnicalAccount.is_active,\n        TechnicalAccount.password, TechnicalAccount.salt,\n        TechnicalAccount.sec_type, TechnicalAccount.password_type).\\\n        order_by(TechnicalAccount.name).\\\n        filter(Cluster.id==cluster_id).\\\n        filter(Cluster.id==TechnicalAccount.cluster_id).\\\n        filter(SecurityBase.id==TechnicalAccount.id).\\\n        order_by('sec_base.name')\n@query_wrapper\ndef tls_ca_cert_list(session, cluster_id, needs_columns=False):\n    \"\"\" TLS CA certs.\n    \"\"\"\n    return session.query(TLSCACert).\\\n        filter(Cluster.id==cluster_id).\\\n        filter(Cluster.id==TLSCACert.cluster_id).\\\n        order_by('sec_tls_ca_cert.name')\n@query_wrapper\ndef tls_channel_sec_list(session, cluster_id, needs_columns=False):\n    \"\"\" TLS-based channel security.\n    \"\"\"\n    return session.query(\n        TLSChannelSecurity.id, TLSChannelSecurity.name,\n        TLSChannelSecurity.is_active, TLSChannelSecurity.value,\n        TLSChannelSecurity.sec_type).\\\n        filter(Cluster.id==cluster_id).\\\n        filter(Cluster.id==TLSChannelSecurity.cluster_id).\\\n        filter(SecurityBase.id==TLSChannelSecurity.id).\\\n        order_by('sec_base.name')\n@query_wrapper\ndef tls_key_cert_list(session, cluster_id, needs_columns=False):\n    \"\"\" TLS key/cert pairs.\n    \"\"\"\n    return session.query(\n        TLSKeyCertSecurity.id, TLSKeyCertSecurity.name,\n        TLSKeyCertSecurity.is_active, TLSKeyCertSecurity.info,\n        TLSKeyCertSecurity.value, TLSKeyCertSecurity.sec_type).\\\n        filter(Cluster.id==cluster_id).\\\n        filter(Cluster.id==TLSKeyCertSecurity.cluster_id).\\\n        filter(SecurityBase.id==TLSKeyCertSecurity.id).\\\n        order_by('sec_base.name')\n@query_wrapper\ndef wss_list(session, cluster_id, needs_columns=False):\n    \"\"\" All the WS-Security definitions.\n    \"\"\"\n    return session.query(\n        WSSDefinition.id, WSSDefinition.name, WSSDefinition.is_active,\n        WSSDefinition.username, WSSDefinition.password, WSSDefinition.password_type,\n        WSSDefinition.reject_empty_nonce_creat, WSSDefinition.reject_stale_tokens,\n        WSSDefinition.reject_expiry_limit, WSSDefinition.nonce_freshness_time,\n        WSSDefinition.sec_type).\\\n        filter(Cluster.id==cluster_id).\\\n        filter(Cluster.id==WSSDefinition.cluster_id).\\\n        filter(SecurityBase.id==WSSDefinition.id).\\\n        order_by('sec_base.name')\n@query_wrapper\ndef xpath_sec_list(session, cluster_id, needs_columns=False):\n    \"\"\" All the XPath security definitions.\n    \"\"\"\n    return session.query(\n        XPathSecurity.id, XPathSecurity.name, XPathSecurity.is_active, XPathSecurity.username, XPathSecurity.username_expr,\n        XPathSecurity.password_expr, XPathSecurity.password, XPathSecurity.sec_type).\\\n        filter(Cluster.id==cluster_id).\\\n        filter(Cluster.id==XPathSecurity.cluster_id).\\\n        filter(SecurityBase.id==XPathSecurity.id).\\\n        order_by('sec_base.name')\n# ################################################################################################################################\ndef _def_amqp(session, cluster_id):\n    return session.query(\n        ConnDefAMQP.name, ConnDefAMQP.id, ConnDefAMQP.host,\n        ConnDefAMQP.port, ConnDefAMQP.vhost, ConnDefAMQP.username,\n        ConnDefAMQP.frame_max, ConnDefAMQP.heartbeat, ConnDefAMQP.password).\\\n        filter(ConnDefAMQP.def_type=='amqp').\\\n        filter(Cluster.id==ConnDefAMQP.cluster_id).\\\n        filter(Cluster.id==cluster_id).\\\n        order_by(ConnDefAMQP.name)\ndef def_amqp(session, cluster_id, id):\n    \"\"\" A particular AMQP definition\n    \"\"\"\n    return _def_amqp(session, cluster_id).\\\n        filter(ConnDefAMQP.id==id).\\\n        one()\n@query_wrapper\ndef def_amqp_list(session, cluster_id, needs_columns=False):\n    \"\"\" AMQP connection definitions.\n    \"\"\"\n    return _def_amqp(session, cluster_id)\n# ################################################################################################################################\ndef _def_jms_wmq(session, cluster_id):\n    return session.query(\n        ConnDefWMQ.id, ConnDefWMQ.name, ConnDefWMQ.host,\n        ConnDefWMQ.port, ConnDefWMQ.queue_manager, ConnDefWMQ.channel,\n        ConnDefWMQ.cache_open_send_queues, ConnDefWMQ.cache_open_receive_queues,\n        ConnDefWMQ.use_shared_connections, ConnDefWMQ.ssl, ConnDefWMQ.ssl_cipher_spec,\n        ConnDefWMQ.ssl_key_repository, ConnDefWMQ.needs_mcd, ConnDefWMQ.max_chars_printed).\\\n        filter(Cluster.id==ConnDefWMQ.cluster_id).\\\n        filter(Cluster.id==cluster_id).\\\n        order_by(ConnDefWMQ.name)\ndef def_jms_wmq(session, cluster_id, id):\n    \"\"\" A particular JMS WebSphere MQ definition\n    \"\"\"\n    return _def_jms_wmq(session, cluster_id).\\\n        filter(ConnDefWMQ.id==id).\\\n        one()\n@query_wrapper\ndef def_jms_wmq_list(session, cluster_id, needs_columns=False):\n    \"\"\" JMS WebSphere MQ connection definitions.\n    \"\"\"\n    return _def_jms_wmq(session, cluster_id)\n# ################################################################################################################################\ndef _out_amqp(session, cluster_id):\n    return session.query(\n        OutgoingAMQP.id, OutgoingAMQP.name, OutgoingAMQP.is_active,\n        OutgoingAMQP.delivery_mode, OutgoingAMQP.priority, OutgoingAMQP.content_type,\n        OutgoingAMQP.content_encoding, OutgoingAMQP.expiration, OutgoingAMQP.user_id,\n        OutgoingAMQP.app_id, ConnDefAMQP.name.label('def_name'), OutgoingAMQP.def_id).\\\n        filter(OutgoingAMQP.def_id==ConnDefAMQP.id).\\\n        filter(ConnDefAMQP.id==OutgoingAMQP.def_id).\\\n        filter(Cluster.id==ConnDefAMQP.cluster_id).\\\n        filter(Cluster.id==cluster_id).\\\n        order_by(OutgoingAMQP.name)\ndef out_amqp(session, cluster_id, id):\n    \"\"\" An outgoing AMQP connection.\n    \"\"\"\n    return _out_amqp(session, cluster_id).\\\n        filter(OutgoingAMQP.id==id).\\\n        one()\n@query_wrapper\ndef out_amqp_list(session, cluster_id, needs_columns=False):\n    \"\"\" Outgoing AMQP connections.\n    \"\"\"\n    return _out_amqp(session, cluster_id)\n# ################################################################################################################################\ndef _out_jms_wmq(session, cluster_id):\n    return session.query(\n        OutgoingWMQ.id, OutgoingWMQ.name, OutgoingWMQ.is_active,\n        OutgoingWMQ.delivery_mode, OutgoingWMQ.priority, OutgoingWMQ.expiration,\n        ConnDefWMQ.name.label('def_name'), OutgoingWMQ.def_id).\\\n        filter(OutgoingWMQ.def_id==ConnDefWMQ.id).\\\n        filter(ConnDefWMQ.id==OutgoingWMQ.def_id).\\\n        filter(Cluster.id==ConnDefWMQ.cluster_id).\\\n        filter(Cluster.id==cluster_id).\\\n        order_by(OutgoingWMQ.name)\ndef out_jms_wmq(session, cluster_id, id):\n    \"\"\" An outgoing JMS WebSphere MQ connection (by ID).\n    \"\"\"\n    return _out_jms_wmq(session, cluster_id).\\\n        filter(OutgoingWMQ.id==id).\\\n        one()\ndef out_jms_wmq_by_name(session, cluster_id, name):\n    \"\"\" An outgoing JMS WebSphere MQ connection (by name).\n    \"\"\"\n    return _out_jms_wmq(session, cluster_id).\\\n        filter(OutgoingWMQ.name==name).\\\n        first()\n@query_wrapper\ndef out_jms_wmq_list(session, cluster_id, needs_columns=False):\n    \"\"\" Outgoing JMS WebSphere MQ connections.\n    \"\"\"\n    return _out_jms_wmq(session, cluster_id)\n# ################################################################################################################################\ndef _channel_amqp(session, cluster_id):\n    return session.query(\n        ChannelAMQP.id, ChannelAMQP.name, ChannelAMQP.is_active,\n        ChannelAMQP.queue, ChannelAMQP.consumer_tag_prefix,\n        ConnDefAMQP.name.label('def_name'), ChannelAMQP.def_id,\n        ChannelAMQP.data_format,\n        Service.name.label('service_name'),\n        Service.impl_name.label('service_impl_name')).\\\n        filter(ChannelAMQP.def_id==ConnDefAMQP.id).\\\n        filter(ChannelAMQP.service_id==Service.id).\\\n        filter(Cluster.id==ConnDefAMQP.cluster_id).\\\n        filter(Cluster.id==cluster_id).\\\n        order_by(ChannelAMQP.name)\ndef channel_amqp(session, cluster_id, id):\n    \"\"\" A particular AMQP channel.\n    \"\"\"\n    return _channel_amqp(session, cluster_id).\\\n        filter(ChannelAMQP.id==id).\\\n        one()\n@query_wrapper\ndef channel_amqp_list(session, cluster_id, needs_columns=False):\n    \"\"\" AMQP channels.\n    \"\"\"\n    return _channel_amqp(session, cluster_id)\n# ################################################################################################################################\ndef _channel_stomp(session, cluster_id):\n    return session.query(\n        ChannelSTOMP.id, ChannelSTOMP.name, ChannelSTOMP.is_active, ChannelSTOMP.username,\n        ChannelSTOMP.password, ChannelSTOMP.address, ChannelSTOMP.proto_version,\n        ChannelSTOMP.timeout, ChannelSTOMP.sub_to, ChannelSTOMP.service_id,\n        Service.name.label('service_name')).\\\n        filter(Service.id==ChannelSTOMP.service_id).\\\n        filter(Cluster.id==ChannelSTOMP.cluster_id).\\\n        filter(Cluster.id==cluster_id).\\\n        order_by(ChannelSTOMP.name)\ndef channel_stomp(session, cluster_id, id):\n    \"\"\" A STOMP channel.\n    \"\"\"\n    return _channel_stomp(session, cluster_id).\\\n        filter(ChannelSTOMP.id==id).\\\n        one()\n@query_wrapper\ndef channel_stomp_list(session, cluster_id, needs_columns=False):\n    \"\"\" A list of STOMP channels.\n    \"\"\"\n    return _channel_stomp(session, cluster_id)\n# ################################################################################################################################\ndef _channel_jms_wmq(session, cluster_id):\n    return session.query(\n        ChannelWMQ.id, ChannelWMQ.name, ChannelWMQ.is_active,\n        ChannelWMQ.queue, ConnDefWMQ.name.label('def_name'), ChannelWMQ.def_id,\n        ChannelWMQ.data_format, Service.name.label('service_name'),\n        Service.impl_name.label('service_impl_name')).\\\n        filter(ChannelWMQ.def_id==ConnDefWMQ.id).\\\n        filter(ChannelWMQ.service_id==Service.id).\\\n        filter(Cluster.id==ConnDefWMQ.cluster_id).\\\n        filter(Cluster.id==cluster_id).\\\n        order_by(ChannelWMQ.name)\ndef channel_jms_wmq(session, cluster_id, id):\n    \"\"\" A particular JMS WebSphere MQ channel.\n    \"\"\"\n    return _channel_jms_wmq(session, cluster_id).\\\n        filter(ChannelWMQ.id==id).\\\n        one()\n@query_wrapper\ndef channel_jms_wmq_list(session, cluster_id, needs_columns=False):\n    \"\"\" JMS WebSphere MQ channels.\n    \"\"\"\n    return _channel_jms_wmq(session, cluster_id)\n# ################################################################################################################################\ndef _out_stomp(session, cluster_id):\n    return session.query(OutgoingSTOMP).\\\n        filter(Cluster.id==OutgoingSTOMP.cluster_id).\\\n        filter(Cluster.id==cluster_id).\\\n        order_by(OutgoingSTOMP.name)\ndef out_stomp(session, cluster_id, id):\n    \"\"\" An outgoing STOMP connection.\n    \"\"\"\n    return _out_zmq(session, cluster_id).\\\n        filter(OutgoingSTOMP.id==id).\\\n        one()\n@query_wrapper\ndef out_stomp_list(session, cluster_id, needs_columns=False):\n    \"\"\" Outgoing STOMP connections.\n    \"\"\"\n    return _out_stomp(session, cluster_id)\n# ################################################################################################################################\ndef _out_zmq(session, cluster_id):\n    return session.query(\n        OutgoingZMQ.id, OutgoingZMQ.name, OutgoingZMQ.is_active,\n        OutgoingZMQ.address, OutgoingZMQ.socket_type).\\\n        filter(Cluster.id==OutgoingZMQ.cluster_id).\\\n        filter(Cluster.id==cluster_id).\\\n        order_by(OutgoingZMQ.name)\ndef out_zmq(session, cluster_id, id):\n    \"\"\" An outgoing ZeroMQ connection.\n    \"\"\"\n    return _out_zmq(session, cluster_id).\\\n        filter(OutgoingZMQ.id==id).\\\n        one()\n@query_wrapper\ndef out_zmq_list(session, cluster_id, needs_columns=False):\n    \"\"\" Outgoing ZeroMQ connections.\n    \"\"\"\n    return _out_zmq(session, cluster_id)\n# ################################################################################################################################\ndef _channel_zmq(session, cluster_id):\n    return session.query(\n        ChannelZMQ.id, ChannelZMQ.name, ChannelZMQ.is_active,\n        ChannelZMQ.address, ChannelZMQ.socket_type, ChannelZMQ.socket_method, ChannelZMQ.sub_key,\n        ChannelZMQ.pool_strategy, ChannelZMQ.service_source, ChannelZMQ.data_format,\n        Service.name.label('service_name'), Service.impl_name.label('service_impl_name')).\\\n        filter(Service.id==ChannelZMQ.service_id).\\\n        filter(Cluster.id==ChannelZMQ.cluster_id).\\\n        filter(Cluster.id==cluster_id).\\\n        order_by(ChannelZMQ.name)\ndef channel_zmq(session, cluster_id, id):\n    \"\"\" An incoming ZeroMQ connection.\n    \"\"\"\n    return _channel_zmq(session, cluster_id).\\\n        filter(ChannelZMQ.id==id).\\\n        one()\n@query_wrapper\ndef channel_zmq_list(session, cluster_id, needs_columns=False):\n    \"\"\" Incoming ZeroMQ connections.\n    \"\"\"\n    return _channel_zmq(session, cluster_id)\n# ################################################################################################################################\ndef _http_soap(session, cluster_id):\n    return session.query(\n        HTTPSOAP.id, HTTPSOAP.name, HTTPSOAP.is_active,\n        HTTPSOAP.is_internal, HTTPSOAP.transport, HTTPSOAP.host,\n        HTTPSOAP.url_path, HTTPSOAP.method, HTTPSOAP.soap_action,\n        HTTPSOAP.soap_version, HTTPSOAP.data_format, HTTPSOAP.security_id,\n        HTTPSOAP.has_rbac,\n        HTTPSOAP.connection, HTTPSOAP.content_type,\n        case([(HTTPSOAP.ping_method != None, HTTPSOAP.ping_method)], else_=DEFAULT_HTTP_PING_METHOD).label('ping_method'), # noqa\n        case([(HTTPSOAP.pool_size != None, HTTPSOAP.pool_size)], else_=DEFAULT_HTTP_POOL_SIZE).label('pool_size'),\n        case([(HTTPSOAP.merge_url_params_req != None, HTTPSOAP.merge_url_params_req)], else_=True).label('merge_url_params_req'),\n        case([(HTTPSOAP.url_params_pri != None, HTTPSOAP.url_params_pri)], else_=URL_PARAMS_PRIORITY.DEFAULT).label('url_params_pri'),\n        case([(HTTPSOAP.params_pri != None, HTTPSOAP.params_pri)], else_=PARAMS_PRIORITY.DEFAULT).label('params_pri'),\n        case([(\n            HTTPSOAP.serialization_type != None, HTTPSOAP.serialization_type)],\n             else_=HTTP_SOAP_SERIALIZATION_TYPE.DEFAULT.id).label('serialization_type'),\n        HTTPSOAP.audit_enabled,\n        HTTPSOAP.audit_back_log,\n        HTTPSOAP.audit_max_payload,\n        HTTPSOAP.audit_repl_patt_type,\n        HTTPSOAP.timeout,\n        HTTPSOAP.sec_tls_ca_cert_id,\n        HTTPSOAP.sec_use_rbac,\n        TLSCACert.name.label('sec_tls_ca_cert_name'),\n        SecurityBase.sec_type,\n        Service.name.label('service_name'),\n        Service.id.label('service_id'),\n        Service.impl_name.label('service_impl_name'),\n        SecurityBase.name.label('security_name'),\n        SecurityBase.username.label('username'),\n        SecurityBase.password.label('password'),\n        SecurityBase.password_type.label('password_type'),).\\\n        outerjoin(Service, Service.id==HTTPSOAP.service_id).\\\n        outerjoin(TLSCACert, TLSCACert.id==HTTPSOAP.sec_tls_ca_cert_id).\\\n        outerjoin(SecurityBase, HTTPSOAP.security_id==SecurityBase.id).\\\n        filter(Cluster.id==HTTPSOAP.cluster_id).\\\n        filter(Cluster.id==cluster_id).\\\n        order_by(HTTPSOAP.name)\ndef http_soap_security_list(session, cluster_id, connection=None):\n    \"\"\" HTTP/SOAP security definitions.\n    \"\"\"\n    q = _http_soap(session, cluster_id)\n    if connection:\n        q = q.filter(HTTPSOAP.connection==connection)\n    return q\ndef http_soap(session, cluster_id, id):\n    \"\"\" An HTTP/SOAP connection.\n    \"\"\"\n    return _http_soap(session, cluster_id).\\\n        filter(HTTPSOAP.id==id).\\\n        one()\n@query_wrapper\ndef http_soap_list(session, cluster_id, connection=None, transport=None, return_internal=True, needs_columns=False, **kwargs):\n    \"\"\" HTTP/SOAP connections, both channels and outgoing ones.\n    \"\"\"\n    q = _http_soap(session, cluster_id)\n    if connection:\n        q = q.filter(HTTPSOAP.connection==connection)\n    if transport:\n        q = q.filter(HTTPSOAP.transport==transport)\n    if not return_internal:\n        q = q.filter(not_(HTTPSOAP.name.startswith('zato')))\n    return q\n# ################################################################################################################################\ndef _out_sql(session, cluster_id):\n    return session.query(SQLConnectionPool).\\\n        filter(Cluster.id==SQLConnectionPool.cluster_id).\\\n        filter(Cluster.id==cluster_id).\\\n        order_by(SQLConnectionPool.name)\ndef out_sql(session, cluster_id, id):\n    \"\"\" An outgoing SQL connection.\n    \"\"\"\n    return _out_sql(session, cluster_id).\\\n        filter(SQLConnectionPool.id==id).\\\n        one()\n@query_wrapper\ndef out_sql_list(session, cluster_id, needs_columns=False):\n    \"\"\" Outgoing SQL connections.\n    \"\"\"\n    return _out_sql(session, cluster_id)\n# ################################################################################################################################\ndef _out_ftp(session, cluster_id):\n    return session.query(\n        OutgoingFTP.id, OutgoingFTP.name, OutgoingFTP.is_active,\n        OutgoingFTP.host, OutgoingFTP.port, OutgoingFTP.user, OutgoingFTP.password,\n        OutgoingFTP.acct, OutgoingFTP.timeout, OutgoingFTP.dircache).\\\n        filter(Cluster.id==OutgoingFTP.cluster_id).\\\n        filter(Cluster.id==cluster_id).\\\n        order_by(OutgoingFTP.name)\ndef out_ftp(session, cluster_id, id):\n    \"\"\" An outgoing FTP connection.\n    \"\"\"\n    return _out_ftp(session, cluster_id).\\\n        filter(OutgoingFTP.id==id).\\\n        one()\n@query_wrapper\ndef out_ftp_list(session, cluster_id, needs_columns=False):\n    \"\"\" Outgoing FTP connections.\n    \"\"\"\n    return _out_ftp(session, cluster_id)\n# ################################################################################################################################\ndef _service(session, cluster_id):\n    return session.query(\n        Service.id, Service.name, Service.is_active,\n        Service.impl_name, Service.is_internal, Service.slow_threshold).\\\n        filter(Cluster.id==Service.cluster_id).\\\n        filter(Cluster.id==cluster_id).\\\n        order_by(Service.name)\ndef service(session, cluster_id, id):\n    \"\"\" A service.\n    \"\"\"\n    return _service(session, cluster_id).\\\n        filter(Service.id==id).\\\n        one()\n@query_wrapper\ndef service_list(session, cluster_id, return_internal=True, needs_columns=False):\n    \"\"\" All services.\n    \"\"\"\n    result = _service(session, cluster_id)\n    if not return_internal:\n        result = result.filter(not_(Service.name.startswith('zato')))\n    return result\n# ################################################################################################################################\ndef _delivery_definition(session, cluster_id):\n    return session.query(DeliveryDefinitionBase).\\\n        filter(Cluster.id==DeliveryDefinitionBase.cluster_id).\\\n        filter(Cluster.id==cluster_id).\\\n        order_by(DeliveryDefinitionBase.name)\ndef delivery_definition_list(session, cluster_id, target_type=None):\n    \"\"\" Returns a list of delivery definitions for a given target type.\n    \"\"\"\n    def_list = _delivery_definition(session, cluster_id)\n    if target_type:\n        def_list = def_list.\\\n            filter(DeliveryDefinitionBase.target_type==target_type)\n    return def_list\n# ################################################################################################################################\ndef delivery_count_by_state(session, def_id):\n    return session.query(Delivery.state, func.count(Delivery.state)).\\\n        filter(Delivery.definition_id==def_id).\\\n        group_by(Delivery.state)\ndef delivery_list(session, cluster_id, def_name, state, start=None, stop=None, needs_payload=False):\n    columns = [\n        DeliveryDefinitionBase.name.label('def_name'),\n        DeliveryDefinitionBase.target_type,\n        Delivery.task_id,\n        Delivery.creation_time.label('creation_time_utc'),\n        Delivery.last_used.label('last_used_utc'),\n        Delivery.source_count,\n        Delivery.target_count,\n        Delivery.resubmit_count,\n        Delivery.state,\n        DeliveryDefinitionBase.retry_repeats,\n        DeliveryDefinitionBase.check_after,\n        DeliveryDefinitionBase.retry_seconds\n    ]\n    if needs_payload:\n        columns.extend([DeliveryPayload.payload, Delivery.args, Delivery.kwargs])\n    q = session.query(*columns).\\\n        filter(DeliveryDefinitionBase.id==Delivery.definition_id).\\\n        filter(DeliveryDefinitionBase.cluster_id==cluster_id).\\\n        filter(DeliveryDefinitionBase.name==def_name).\\\n        filter(Delivery.state.in_(state))\n    if needs_payload:\n        q = q.filter(DeliveryPayload.task_id==Delivery.task_id)\n    if start:\n        q = q.filter(Delivery.last_used >= start)\n    if stop:\n        q = q.filter(Delivery.last_used <= stop)\n    q = q.order_by(Delivery.last_used.desc())\n    return q\ndef delivery(session, task_id, target_def_class):\n    return session.query(\n        target_def_class.name.label('def_name'),\n        target_def_class.target_type,\n        Delivery.task_id,\n        Delivery.creation_time.label('creation_time_utc'),\n        Delivery.last_used.label('last_used_utc'),\n        Delivery.source_count,\n        Delivery.target_count,\n        Delivery.resubmit_count,\n        Delivery.state,\n        target_def_class.retry_repeats,\n        target_def_class.check_after,\n        target_def_class.retry_seconds,\n        DeliveryPayload.payload,\n        Delivery.args,\n        Delivery.kwargs,\n        target_def_class.target,\n        ).\\\n        filter(target_def_class.id==Delivery.definition_id).\\\n        filter(Delivery.task_id==task_id).\\\n        filter(DeliveryPayload.task_id==Delivery.task_id)\n@query_wrapper\ndef delivery_history_list(session, task_id, needs_columns=True):\n    return session.query(\n        DeliveryHistory.entry_type,\n        DeliveryHistory.entry_time,\n        DeliveryHistory.entry_ctx,\n        DeliveryHistory.resubmit_count).\\\n        filter(DeliveryHistory.task_id==task_id).\\\n        order_by(DeliveryHistory.entry_time.desc())\n# ################################################################################################################################\ndef _msg_list(class_, order_by, session, cluster_id, needs_columns=False):\n    \"\"\" All the namespaces.\n    \"\"\"\n    return session.query(\n        class_.id, class_.name,\n        class_.value).\\\n        filter(Cluster.id==cluster_id).\\\n        filter(Cluster.id==class_.cluster_id).\\\n        order_by(order_by)\n@query_wrapper\ndef namespace_list(session, cluster_id, needs_columns=False):\n    \"\"\" All the namespaces.\n    \"\"\"\n    return _msg_list(MsgNamespace, 'msg_ns.name', session, cluster_id, query_wrapper)\n@query_wrapper\ndef xpath_list(session, cluster_id, needs_columns=False):\n    \"\"\" All the XPaths.\n    \"\"\"\n    return _msg_list(XPath, 'msg_xpath.name', session, cluster_id, query_wrapper)\n@query_wrapper\ndef json_pointer_list(session, cluster_id, needs_columns=False):\n    \"\"\" All the JSON Pointers.\n    \"\"\"\n    return _msg_list(JSONPointer, 'msg_json_pointer.name', session, cluster_id, query_wrapper)\n# ################################################################################################################################\ndef _http_soap_audit(session, cluster_id, conn_id=None, start=None, stop=None, query=None, id=None, needs_req_payload=False):\n    columns = [\n        HTTSOAPAudit.id,\n        HTTSOAPAudit.name.label('conn_name'),\n        HTTSOAPAudit.cid,\n        HTTSOAPAudit.transport,\n        HTTSOAPAudit.connection,\n        HTTSOAPAudit.req_time.label('req_time_utc'),\n        HTTSOAPAudit.resp_time.label('resp_time_utc'),\n        HTTSOAPAudit.user_token,\n        HTTSOAPAudit.invoke_ok,\n        HTTSOAPAudit.auth_ok,\n        HTTSOAPAudit.remote_addr,\n    ]\n    if needs_req_payload:\n        columns.extend([\n            HTTSOAPAudit.req_headers, HTTSOAPAudit.req_payload, HTTSOAPAudit.resp_headers, HTTSOAPAudit.resp_payload\n        ])\n    q = session.query(*columns)\n    if query:\n        query = '%{}%'.format(query)\n        q = q.filter(\n            HTTSOAPAudit.cid.ilike(query) |\n            HTTSOAPAudit.req_headers.ilike(query) | HTTSOAPAudit.req_payload.ilike(query) |\n            HTTSOAPAudit.resp_headers.ilike(query) | HTTSOAPAudit.resp_payload.ilike(query)\n        )\n    if id:\n        q = q.filter(HTTSOAPAudit.id == id)\n    if conn_id:\n        q = q.filter(HTTSOAPAudit.conn_id == conn_id)\n    if start:\n        q = q.filter(HTTSOAPAudit.req_time >= start)\n    if stop:\n        q = q.filter(HTTSOAPAudit.req_time <= start)\n    q = q.order_by(HTTSOAPAudit.req_time.desc())\n    return q\n@query_wrapper\ndef http_soap_audit_item_list(session, cluster_id, conn_id, start, stop, query, needs_req_payload, needs_columns=False):\n    return _http_soap_audit(session, cluster_id, conn_id, start, stop, query)\n@query_wrapper\ndef http_soap_audit_item(session, cluster_id, id, needs_columns=False):\n    return _http_soap_audit(session, cluster_id, id=id, needs_req_payload=True)\n# ################################################################################################################################\ndef _cloud_openstack_swift(session, cluster_id):\n    return session.query(OpenStackSwift).\\\n        filter(Cluster.id==cluster_id).\\\n        filter(Cluster.id==OpenStackSwift.cluster_id).\\\n        order_by(OpenStackSwift.name)\ndef cloud_openstack_swift(session, cluster_id, id):\n    \"\"\" An OpenStack Swift connection.\n    \"\"\"\n    return _cloud_openstack_swift(session, cluster_id).\\\n        filter(OpenStackSwift.id==id).\\\n        one()\n@query_wrapper\ndef cloud_openstack_swift_list(session, cluster_id, needs_columns=False):\n    \"\"\" OpenStack Swift connections.\n    \"\"\"\n    return _cloud_openstack_swift(session, cluster_id)\n# ################################################################################################################################\ndef _cloud_aws_s3(session, cluster_id):\n    return session.query(\n        AWSS3.id, AWSS3.name, AWSS3.is_active, AWSS3.pool_size, AWSS3.address, AWSS3.debug_level, AWSS3.suppr_cons_slashes,\n        AWSS3.content_type, AWSS3.metadata_, AWSS3.security_id, AWSS3.bucket, AWSS3.encrypt_at_rest, AWSS3.storage_class,\n        SecurityBase.username, SecurityBase.password).\\\n        filter(Cluster.id==cluster_id).\\\n        filter(AWSS3.security_id==SecurityBase.id).\\\n        order_by(AWSS3.name)\ndef cloud_aws_s3(session, cluster_id, id):\n    \"\"\" An AWS S3 connection.\n    \"\"\"\n    return _cloud_aws_s3(session, cluster_id).\\\n        filter(AWSS3.id==id).\\\n        one()\n@query_wrapper\ndef cloud_aws_s3_list(session, cluster_id, needs_columns=False):\n    \"\"\" AWS S3 connections.\n    \"\"\"\n    return _cloud_aws_s3(session, cluster_id)\n# ################################################################################################################################\ndef _pubsub_topic(session, cluster_id):\n    return session.query(PubSubTopic.id, PubSubTopic.name, PubSubTopic.is_active, PubSubTopic.max_depth).\\\n        filter(Cluster.id==PubSubTopic.cluster_id).\\\n        filter(Cluster.id==cluster_id).\\\n        order_by(PubSubTopic.name)\ndef pubsub_topic(session, cluster_id, id):\n    \"\"\" A pub/sub topic.\n    \"\"\"\n    return _pubsub_topic(session, cluster_id).\\\n        filter(PubSubTopic.id==id).\\\n        one()\n@query_wrapper\ndef pubsub_topic_list(session, cluster_id, needs_columns=False):\n    \"\"\" All pub/sub topics.\n    \"\"\"\n    return _pubsub_topic(session, cluster_id)\ndef pubsub_default_client(session, cluster_id, name):\n    \"\"\" Returns a client ID of a given name used internally for pub/sub.\n    \"\"\"\n    return session.query(HTTPBasicAuth.id, HTTPBasicAuth.name).\\\n        filter(Cluster.id==cluster_id).\\\n        filter(Cluster.id==HTTPBasicAuth.cluster_id).\\\n        filter(HTTPBasicAuth.name==name).\\\n        first()\n# ################################################################################################################################\ndef _pubsub_producer(session, cluster_id, needs_columns=False):\n    return session.query(\n        PubSubProducer.id,\n        PubSubProducer.is_active,\n        SecurityBase.id.label('client_id'),\n        SecurityBase.name,\n        SecurityBase.sec_type,\n        PubSubTopic.name.label('topic_name')).\\\n        filter(Cluster.id==cluster_id).\\\n        filter(PubSubProducer.topic_id==PubSubTopic.id).\\\n        filter(PubSubProducer.cluster_id==Cluster.id).\\\n        filter(PubSubProducer.sec_def_id==SecurityBase.id).\\\n        order_by(SecurityBase.sec_type, SecurityBase.name)\n@query_wrapper\ndef pubsub_producer_list(session, cluster_id, topic_name, needs_columns=False):\n    \"\"\" All pub/sub producers.\n    \"\"\"\n    response = _pubsub_producer(session, cluster_id, query_wrapper)\n    if topic_name:\n        response = response.filter(PubSubTopic.name==topic_name)\n    return response\n# ################################################################################################################################\ndef _pubsub_consumer(session, cluster_id, needs_columns=False):\n    return session.query(\n        PubSubConsumer.id,\n        PubSubConsumer.is_active,\n        PubSubConsumer.max_depth,\n        PubSubConsumer.sub_key,\n        PubSubConsumer.delivery_mode,\n        PubSubConsumer.callback_id,\n        PubSubConsumer.callback_type,\n        HTTPSOAP.name.label('callback_name'),\n        HTTPSOAP.soap_version,\n        SecurityBase.id.label('client_id'),\n        SecurityBase.name,\n        SecurityBase.sec_type,\n        PubSubTopic.name.label('topic_name')).\\\n        outerjoin(HTTPSOAP, HTTPSOAP.id==PubSubConsumer.callback_id).\\\n        filter(Cluster.id==cluster_id).\\\n        filter(PubSubConsumer.topic_id==PubSubTopic.id).\\\n        filter(PubSubConsumer.cluster_id==Cluster.id).\\\n        filter(PubSubConsumer.sec_def_id==SecurityBase.id).\\\n        order_by(SecurityBase.sec_type, SecurityBase.name)\n@query_wrapper\ndef pubsub_consumer_list(session, cluster_id, topic_name, needs_columns=False):\n    \"\"\" All pub/sub consumers.\n    \"\"\"\n", "outputs": ["    response = _pubsub_consumer(session, cluster_id, query_wrapper)"], "input_length": 8934, "output_length": 10, "length": 8944, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "3bf856512e7a28496cab214a8e57602a61b5aca49902ab80a59cecb71aacc0b2"}
{"input": "", "context": "# Nikita Akimov\n# interplanety@interplanety.org\n#\n# GitHub\n#   https://github.com/Korchy/BIS\n# Mesh Modifiers\n# -------------------------------------------------\n# old - remove after recreating meshes through import\n# -------------------------------------------------\nimport os\nimport bpy\nfrom .bl_types_conversion import BLset, BLObject, BLCacheFile, BLVector, BLImage, BLbpy_prop_collection, BLbpy_prop_array, BLCurveMapping, BLTexture\nclass MeshModifierCommon:\n    @classmethod\n    def to_json(cls, modifier):\n        # base specification\n        modifier_json = {\n            'type': modifier.type,\n            'name': modifier.name,\n            'show_expanded': modifier.show_expanded,\n            'show_render': modifier.show_render,\n            'show_viewport': modifier.show_viewport,\n            'show_in_editmode': modifier.show_in_editmode,\n            'show_on_cage': modifier.show_on_cage,\n            'use_apply_on_spline': modifier.use_apply_on_spline\n        }\n        # for current specifications\n        cls._to_json_spec(modifier_json, modifier)\n        return modifier_json\n    @classmethod\n    def _to_json_spec(cls, modifier_json, modifier):\n        # extend to current modifier data\n        pass\n    @classmethod\n    def from_json(cls, mesh, modifier_json):\n        # for current specifications\n        modifier = mesh.modifiers.new(modifier_json['name'], modifier_json['type'])\n        modifier.show_expanded = modifier_json['show_expanded']\n        modifier.show_render = modifier_json['show_render']\n        modifier.show_viewport = modifier_json['show_viewport']\n        modifier.show_in_editmode = modifier_json['show_in_editmode']\n        modifier.show_on_cage = modifier_json['show_on_cage']\n        modifier.use_apply_on_spline = modifier_json['use_apply_on_spline']\n        cls._from_json_spec(modifier=modifier, modifier_json=modifier_json)\n        return mesh\n    @classmethod\n    def _from_json_spec(cls, modifier, modifier_json):\n        # extend to current modifier data\n        pass\nclass MeshModifierSUBSURF(MeshModifierCommon):\n    @classmethod\n    def _to_json_spec(cls, modifier_json, modifier):\n        modifier_json['levels'] = modifier.levels\n        modifier_json['render_levels'] = modifier.render_levels\n        modifier_json['show_only_control_edges'] = modifier.show_only_control_edges\n        modifier_json['subdivision_type'] = modifier.subdivision_type\n        if hasattr(modifier, 'use_opensubdiv'):\n            modifier_json['use_opensubdiv'] = modifier.use_opensubdiv\n        if hasattr(modifier, 'use_subsurf_uv'):\n            modifier_json['use_subsurf_uv'] = modifier.use_subsurf_uv\n    @classmethod\n    def _from_json_spec(cls, modifier, modifier_json):\n        modifier.levels = modifier_json['levels']\n        modifier.render_levels = modifier_json['render_levels']\n        modifier.show_only_control_edges = modifier_json['show_only_control_edges']\n        modifier.subdivision_type = modifier_json['subdivision_type']\n        if 'use_opensubdiv' in modifier_json and hasattr(modifier, 'use_opensubdiv'):\n            modifier.use_opensubdiv = modifier_json['use_opensubdiv']\n        if 'use_subsurf_uv' in modifier_json and hasattr(modifier, 'use_subsurf_uv'):\n            modifier.use_subsurf_uv = modifier_json['use_subsurf_uv']\nclass MeshModifierDATA_TRANSFER(MeshModifierCommon):\n    @classmethod\n    def _to_json_spec(cls, modifier_json, modifier):\n        modifier_json['object'] = BLObject.to_json(instance=modifier.object)\n        modifier_json['use_poly_data'] = modifier.use_poly_data\n        modifier_json['use_vert_data'] = modifier.use_vert_data\n        modifier_json['use_edge_data'] = modifier.use_edge_data\n        modifier_json['use_loop_data'] = modifier.use_loop_data\n        modifier_json['data_types_edges'] = BLset.to_json(modifier.data_types_edges)\n        modifier_json['data_types_loops'] = BLset.to_json(modifier.data_types_loops)\n        modifier_json['data_types_polys'] = BLset.to_json(modifier.data_types_polys)\n        modifier_json['data_types_verts'] = BLset.to_json(modifier.data_types_verts)\n        modifier_json['edge_mapping'] = modifier.edge_mapping\n        modifier_json['invert_vertex_group'] = modifier.invert_vertex_group\n        modifier_json['islands_precision'] = modifier.islands_precision\n        modifier_json['layers_uv_select_dst'] = modifier.layers_uv_select_dst\n        modifier_json['layers_uv_select_src'] = modifier.layers_uv_select_src\n        modifier_json['layers_vcol_select_dst'] = modifier.layers_vcol_select_dst\n        modifier_json['layers_vcol_select_src'] = modifier.layers_vcol_select_src\n        modifier_json['layers_vgroup_select_dst'] = modifier.layers_vgroup_select_dst\n        modifier_json['layers_vgroup_select_src'] = modifier.layers_vgroup_select_src\n        modifier_json['loop_mapping'] = modifier.loop_mapping\n        modifier_json['max_distance'] = modifier.max_distance\n        modifier_json['mix_factor'] = modifier.mix_factor\n        modifier_json['mix_mode'] = modifier.mix_mode\n        modifier_json['poly_mapping'] = modifier.poly_mapping\n        modifier_json['ray_radius'] = modifier.ray_radius\n        modifier_json['use_max_distance'] = modifier.use_max_distance\n        modifier_json['use_object_transform'] = modifier.use_object_transform\n        modifier_json['vert_mapping'] = modifier.vert_mapping\n        modifier_json['vertex_group'] = modifier.vertex_group\n    @classmethod\n    def _from_json_spec(cls, modifier, modifier_json):\n        BLObject.from_json(instance=modifier, json=modifier_json['object'])\n        modifier.use_poly_data = modifier_json['use_poly_data']\n        modifier.use_vert_data = modifier_json['use_vert_data']\n        modifier.use_edge_data = modifier_json['use_edge_data']\n        modifier.use_loop_data = modifier_json['use_loop_data']\n        modifier.use_max_distance = modifier_json['use_max_distance']\n        modifier.use_object_transform = modifier_json['use_object_transform']\n        modifier.data_types_edges = BLset.from_json(json=modifier_json['data_types_edges'])\n        modifier.data_types_loops = BLset.from_json(json=modifier_json['data_types_loops'])\n        modifier.data_types_polys = BLset.from_json(json=modifier_json['data_types_polys'])\n        modifier.data_types_verts = BLset.from_json(json=modifier_json['data_types_verts'])\n        modifier.edge_mapping = modifier_json['edge_mapping']\n        modifier.invert_vertex_group = modifier_json['invert_vertex_group']\n        modifier.islands_precision = modifier_json['islands_precision']\n        modifier.layers_uv_select_dst = modifier_json['layers_uv_select_dst']\n        modifier.layers_uv_select_src = modifier_json['layers_uv_select_src']\n        modifier.layers_vcol_select_dst = modifier_json['layers_vcol_select_dst']\n        modifier.layers_vcol_select_src = modifier_json['layers_vcol_select_src']\n        modifier.layers_vgroup_select_dst = modifier_json['layers_vgroup_select_dst']\n        modifier.layers_vgroup_select_src = modifier_json['layers_vgroup_select_src']\n        modifier.loop_mapping = modifier_json['loop_mapping']\n        modifier.max_distance = modifier_json['max_distance']\n        modifier.mix_factor = modifier_json['mix_factor']\n        modifier.mix_mode = modifier_json['mix_mode']\n        modifier.poly_mapping = modifier_json['poly_mapping']\n        modifier.ray_radius = modifier_json['ray_radius']\n        modifier.vert_mapping = modifier_json['vert_mapping']\n        modifier.vertex_group = modifier_json['vertex_group']\nclass MeshModifierMESH_CACHE(MeshModifierCommon):\n    @classmethod\n    def _to_json_spec(cls, modifier_json, modifier):\n        modifier_json['cache_format'] = modifier.cache_format\n        modifier_json['deform_mode'] = modifier.deform_mode\n        modifier_json['eval_factor'] = modifier.eval_factor\n        modifier_json['eval_frame'] = modifier.eval_frame\n        modifier_json['eval_time'] = modifier.eval_time\n        modifier_json['factor'] = modifier.factor\n        modifier_json['filepath'] = modifier.filepath\n        modifier_json['flip_axis'] = BLset.to_json(modifier.flip_axis)\n        modifier_json['forward_axis'] = modifier.forward_axis\n        modifier_json['frame_scale'] = modifier.frame_scale\n        modifier_json['frame_start'] = modifier.frame_start\n        modifier_json['interpolation'] = modifier.interpolation\n        modifier_json['play_mode'] = modifier.play_mode\n        modifier_json['time_mode'] = modifier.time_mode\n        modifier_json['up_axis'] = modifier.up_axis\n    @classmethod\n    def _from_json_spec(cls, modifier, modifier_json):\n        modifier.cache_format = modifier_json['cache_format']\n        modifier.deform_mode = modifier_json['deform_mode']\n        modifier.eval_factor = modifier_json['eval_factor']\n        modifier.eval_frame = modifier_json['eval_frame']\n        modifier.eval_time = modifier_json['eval_time']\n        modifier.factor = modifier_json['factor']\n        modifier.filepath = modifier_json['filepath']\n        modifier.flip_axis = BLset.from_json(json=modifier_json['flip_axis'])\n        modifier.forward_axis = modifier_json['forward_axis']\n        modifier.frame_scale = modifier_json['frame_scale']\n        modifier.frame_start = modifier_json['frame_start']\n        modifier.interpolation = modifier_json['interpolation']\n        modifier.play_mode = modifier_json['play_mode']\n        modifier.time_mode = modifier_json['time_mode']\n        modifier.up_axis = modifier_json['up_axis']\nclass MeshModifierMESH_SEQUENCE_CACHE(MeshModifierCommon):\n    @classmethod\n    def _to_json_spec(cls, modifier_json, modifier):\n        modifier_json['cache_file'] = BLCacheFile.to_json(instance=modifier.cache_file)\n        modifier_json['object_path'] = modifier.object_path\n        modifier_json['read_data'] = BLset.to_json(modifier.read_data)\n    @classmethod\n    def _from_json_spec(cls, modifier, modifier_json):\n        BLCacheFile.from_json(instance=modifier, json=modifier_json['cache_file'], instance_field='cache_file')\n        modifier.object_path = modifier_json['object_path']\n        modifier.read_data = BLset.from_json(json=modifier_json['read_data'])\nclass MeshModifierNORMAL_EDIT(MeshModifierCommon):\n    @classmethod\n    def _to_json_spec(cls, modifier_json, modifier):\n        modifier_json['target'] = BLObject.to_json(instance=modifier.target)\n        modifier_json['invert_vertex_group'] = modifier.invert_vertex_group\n        modifier_json['mix_factor'] = modifier.mix_factor\n        modifier_json['mix_limit'] = modifier.mix_limit\n        modifier_json['mix_mode'] = modifier.mix_mode\n        modifier_json['mode'] = modifier.mode\n        modifier_json['offset'] = BLVector.to_json(instance=modifier.offset)\n        modifier_json['use_direction_parallel'] = modifier.use_direction_parallel\n        modifier_json['vertex_group'] = modifier.vertex_group\n    @classmethod\n    def _from_json_spec(cls, modifier, modifier_json):\n        BLObject.from_json(instance=modifier, json=modifier_json['target'], instance_field='target')\n        modifier.invert_vertex_group = modifier_json['invert_vertex_group']\n        modifier.mix_factor = modifier_json['mix_factor']\n        modifier.mix_limit = modifier_json['mix_limit']\n        modifier.mix_mode = modifier_json['mix_mode']\n        modifier.mode = modifier_json['mode']\n        BLVector.from_json(instance=modifier.offset, json=modifier_json['offset'])\n        modifier.use_direction_parallel = modifier_json['use_direction_parallel']\n        modifier.vertex_group = modifier_json['vertex_group']\nclass MeshModifierUV_PROJECT(MeshModifierCommon):\n    @classmethod\n    def _to_json_spec(cls, modifier_json, modifier):\n        modifier_json['aspect_x'] = modifier.aspect_x\n        modifier_json['aspect_y'] = modifier.aspect_y\n        modifier_json['image'] = BLImage.to_json(instance=modifier.image)\n        modifier_json['projector_count'] = modifier.projector_count\n        modifier_json['projectors'] = BLbpy_prop_collection.to_json(modifier.projectors)\n        modifier_json['scale_x'] = modifier.scale_x\n        modifier_json['scale_y'] = modifier.scale_y\n        modifier_json['use_image_override'] = modifier.use_image_override\n        modifier_json['uv_layer'] = modifier.uv_layer\n    @classmethod\n    def _from_json_spec(cls, modifier, modifier_json):\n        modifier.aspect_x = modifier_json['aspect_x']\n        modifier.aspect_y = modifier_json['aspect_y']\n        BLImage.from_json(instance=modifier, json=modifier_json['image'], instance_field='image')\n        modifier.projector_count = modifier_json['projector_count']\n        BLbpy_prop_collection.from_json(modifier, modifier.projectors, modifier_json['projectors'])\n        modifier.scale_x = modifier_json['scale_x']\n        modifier.scale_y = modifier_json['scale_y']\n        modifier.use_image_override = modifier_json['use_image_override']\n        modifier.uv_layer = modifier_json['uv_layer']\nclass MeshModifierUV_WARP(MeshModifierCommon):\n    @classmethod\n    def _to_json_spec(cls, modifier_json, modifier):\n        modifier_json['axis_u'] = modifier.axis_u\n        modifier_json['axis_v'] = modifier.axis_v\n        modifier_json['bone_from'] = modifier.bone_from\n        modifier_json['bone_to'] = modifier.bone_to\n        modifier_json['center'] = BLbpy_prop_array.to_json(prop_array=modifier.center)\n        modifier_json['object_from'] = BLObject.to_json(instance=modifier.object_from)\n        modifier_json['object_to'] = BLObject.to_json(instance=modifier.object_to)\n        modifier_json['uv_layer'] = modifier.uv_layer\n        modifier_json['vertex_group'] = modifier.vertex_group\n    @classmethod\n    def _from_json_spec(cls, modifier, modifier_json):\n        modifier.axis_u = modifier_json['axis_u']\n        modifier.axis_v = modifier_json['axis_v']\n        modifier.bone_from = modifier_json['bone_from']\n        modifier.bone_to = modifier_json['bone_to']\n        BLbpy_prop_array.from_json(prop_array=modifier.center, json=modifier_json['center'])\n        BLObject.from_json(instance=modifier, json=modifier_json['object_from'], instance_field='object_from')\n        BLObject.from_json(instance=modifier, json=modifier_json['object_to'], instance_field='object_to')\n        modifier.uv_layer = modifier_json['uv_layer']\n        modifier.vertex_group = modifier_json['vertex_group']\nclass MeshModifierVERTEX_WEIGHT_EDIT(MeshModifierCommon):\n    @classmethod\n    def _to_json_spec(cls, modifier_json, modifier):\n        modifier_json['add_threshold'] = modifier.add_threshold\n        modifier_json['default_weight'] = modifier.default_weight\n        modifier_json['falloff_type'] = modifier.falloff_type\n        modifier_json['map_curve'] = BLCurveMapping.to_json(instance=modifier.map_curve)\n        modifier_json['mask_constant'] = modifier.mask_constant\n        modifier_json['mask_tex_map_object'] = BLObject.to_json(instance=modifier.mask_tex_map_object)\n        modifier_json['mask_tex_mapping'] = modifier.mask_tex_mapping\n        modifier_json['mask_tex_use_channel'] = modifier.mask_tex_use_channel\n        modifier_json['mask_tex_uv_layer'] = modifier.mask_tex_uv_layer\n        modifier_json['mask_texture'] = BLTexture.to_json(instance=modifier.mask_texture)\n        modifier_json['mask_vertex_group'] = modifier.mask_vertex_group\n        modifier_json['remove_threshold'] = modifier.remove_threshold\n        modifier_json['use_add'] = modifier.use_add\n        modifier_json['use_remove'] = modifier.use_remove\n        modifier_json['vertex_group'] = modifier.vertex_group\n    @classmethod\n    def _from_json_spec(cls, modifier, modifier_json):\n        modifier.add_threshold = modifier_json['add_threshold']\n        modifier.default_weight = modifier_json['default_weight']\n        modifier.falloff_type = modifier_json['falloff_type']\n        BLCurveMapping.from_json(instance=modifier.map_curve, json=modifier_json['map_curve'])\n        modifier.mask_constant = modifier_json['mask_constant']\n        BLObject.from_json(instance=modifier, json=modifier_json['mask_tex_map_object'], instance_field='mask_tex_map_object')\n        modifier.mask_tex_mapping = modifier_json['mask_tex_mapping']\n        modifier.mask_tex_use_channel = modifier_json['mask_tex_use_channel']\n        modifier.mask_tex_uv_layer = modifier_json['mask_tex_uv_layer']\n        BLTexture.from_json(instance=modifier, json=modifier_json['mask_texture'], instance_field='mask_texture')\n        modifier.mask_vertex_group = modifier_json['mask_vertex_group']\n        modifier.remove_threshold = modifier_json['remove_threshold']\n        modifier.use_add = modifier_json['use_add']\n        modifier.use_remove = modifier_json['use_remove']\n        modifier.vertex_group = modifier_json['vertex_group']\nclass MeshModifierVERTEX_WEIGHT_MIX(MeshModifierCommon):\n    @classmethod\n    def _to_json_spec(cls, modifier_json, modifier):\n        modifier_json['default_weight_a'] = modifier.default_weight_a\n        modifier_json['default_weight_b'] = modifier.default_weight_b\n        modifier_json['mask_constant'] = modifier.mask_constant\n        modifier_json['mask_tex_map_object'] = BLObject.to_json(instance=modifier.mask_tex_map_object)\n        modifier_json['mask_tex_mapping'] = modifier.mask_tex_mapping\n        modifier_json['mask_tex_use_channel'] = modifier.mask_tex_use_channel\n        modifier_json['mask_tex_uv_layer'] = modifier.mask_tex_uv_layer\n        modifier_json['mask_texture'] = BLTexture.to_json(instance=modifier.mask_texture)\n        modifier_json['mask_vertex_group'] = modifier.mask_vertex_group\n        modifier_json['mix_mode'] = modifier.mix_mode\n        modifier_json['mix_set'] = modifier.mix_set\n        modifier_json['vertex_group_a'] = modifier.vertex_group_a\n    @classmethod\n    def _from_json_spec(cls, modifier, modifier_json):\n        modifier.default_weight_a = modifier_json['default_weight_a']\n        modifier.default_weight_b = modifier_json['default_weight_b']\n        modifier.mask_constant = modifier_json['mask_constant']\n        BLObject.from_json(instance=modifier, json=modifier_json['mask_tex_map_object'], instance_field='mask_tex_map_object')\n        modifier.mask_tex_mapping = modifier_json['mask_tex_mapping']\n        modifier.mask_tex_use_channel = modifier_json['mask_tex_use_channel']\n        modifier.mask_tex_uv_layer = modifier_json['mask_tex_uv_layer']\n        BLTexture.from_json(instance=modifier, json=modifier_json['mask_texture'], instance_field='mask_texture')\n        modifier.mask_vertex_group = modifier_json['mask_vertex_group']\n        modifier.mix_mode = modifier_json['mix_mode']\n        modifier.mix_set = modifier_json['mix_set']\n        modifier.vertex_group_a = modifier_json['vertex_group_a']\nclass MeshModifierVERTEX_WEIGHT_PROXIMITY(MeshModifierCommon):\n    @classmethod\n    def _to_json_spec(cls, modifier_json, modifier):\n        modifier_json['falloff_type'] = modifier.falloff_type\n        modifier_json['mask_constant'] = modifier.mask_constant\n        modifier_json['mask_tex_map_object'] = BLObject.to_json(instance=modifier.mask_tex_map_object)\n        modifier_json['mask_tex_mapping'] = modifier.mask_tex_mapping\n        modifier_json['mask_tex_use_channel'] = modifier.mask_tex_use_channel\n        modifier_json['mask_tex_uv_layer'] = modifier.mask_tex_uv_layer\n        modifier_json['mask_texture'] = BLTexture.to_json(instance=modifier.mask_texture)\n        modifier_json['mask_vertex_group'] = modifier.mask_vertex_group\n        modifier_json['max_dist'] = modifier.max_dist\n        modifier_json['min_dist'] = modifier.min_dist\n        modifier_json['proximity_geometry'] = BLset.to_json(modifier.proximity_geometry)\n        modifier_json['proximity_mode'] = modifier.proximity_mode\n        modifier_json['target'] = BLObject.to_json(instance=modifier.target)\n        modifier_json['vertex_group'] = modifier.vertex_group\n    @classmethod\n    def _from_json_spec(cls, modifier, modifier_json):\n        modifier.falloff_type = modifier_json['falloff_type']\n        modifier.mask_constant = modifier_json['mask_constant']\n        BLObject.from_json(instance=modifier, json=modifier_json['mask_tex_map_object'], instance_field='mask_tex_map_object')\n        modifier.mask_tex_mapping = modifier_json['mask_tex_mapping']\n        modifier.mask_tex_use_channel = modifier_json['mask_tex_use_channel']\n        modifier.mask_tex_uv_layer = modifier_json['mask_tex_uv_layer']\n        BLTexture.from_json(instance=modifier, json=modifier_json['mask_texture'], instance_field='mask_texture')\n        modifier.mask_vertex_group = modifier_json['mask_vertex_group']\n        modifier.max_dist = modifier_json['max_dist']\n        modifier.min_dist = modifier_json['min_dist']\n        modifier.proximity_geometry = BLset.from_json(json=modifier_json['proximity_geometry'])\n        modifier.proximity_mode = modifier_json['proximity_mode']\n        BLObject.from_json(instance=modifier, json=modifier_json['target'], instance_field='target')\n", "outputs": ["        modifier.vertex_group = modifier_json['vertex_group']"], "input_length": 2494, "output_length": 7, "length": 2501, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "fb31b1875905f2361345b65d337d936f0d0702582a1188698d18945655258498"}
{"input": "", "context": "import os\nimport pytest\nfrom six import BytesIO\nfrom ..sourcefile import SourceFile, read_script_metadata, js_meta_re, python_meta_re\ndef create(filename, contents=b\"\"):\n    assert isinstance(contents, bytes)\n    return SourceFile(\"/\", filename, \"/\", contents=contents)\ndef items(s):\n    item_type, items = s.manifest_items()\n    if item_type == \"support\":\n        return []\n    else:\n        return [(item_type, item.url) for item in items]\n@pytest.mark.parametrize(\"rel_path\", [\n    \".gitignore\",\n    \".travis.yml\",\n    \"MANIFEST.json\",\n    \"tools/test.html\",\n    \"resources/test.html\",\n    \"common/test.html\",\n    \"support/test.html\",\n    \"css21/archive/test.html\",\n    \"work-in-progress/test.html\",\n    \"conformance-checkers/test.html\",\n    \"conformance-checkers/README.md\",\n    \"conformance-checkers/html/Makefile\",\n    \"conformance-checkers/html/test.html\",\n    \"foo/tools/test.html\",\n    \"foo/resources/test.html\",\n    \"foo/support/test.html\",\n    \"foo/test-support.html\",\n    \"css/common/test.html\",\n    \"css/CSS2/archive/test.html\",\n    \"css/work-in-progress/test.html\",\n])\ndef test_name_is_non_test(rel_path):\n    s = create(rel_path)\n    assert s.name_is_non_test or s.name_is_conformance_support\n    assert not s.content_is_testharness\n    assert items(s) == []\n@pytest.mark.parametrize(\"rel_path\", [\n    \"foo/common/test.html\",\n    \"foo/conformance-checkers/test.html\",\n    \"foo/_certs/test.html\",\n    \"foo/css21/archive/test.html\",\n    \"foo/work-in-progress/test.html\",\n    \"foo/CSS2/archive/test.html\",\n    \"css/css21/archive/test.html\",\n])\ndef test_not_name_is_non_test(rel_path):\n    s = create(rel_path)\n    assert not (s.name_is_non_test or s.name_is_conformance_support)\n    # We aren't actually asserting what type of test these are, just their\n    # name doesn't prohibit them from being tests.\n@pytest.mark.parametrize(\"rel_path\", [\n    \"html/test-manual.html\",\n    \"html/test-manual.xhtml\",\n    \"html/test-manual.https.html\",\n    \"html/test-manual.https.xhtml\"\n])\ndef test_name_is_manual(rel_path):\n    s = create(rel_path)\n    assert not s.name_is_non_test\n    assert s.name_is_manual\n    assert not s.content_is_testharness\n    assert items(s) == [(\"manual\", \"/\" + rel_path)]\n@pytest.mark.parametrize(\"rel_path\", [\n    \"html/test-visual.html\",\n    \"html/test-visual.xhtml\",\n])\ndef test_name_is_visual(rel_path):\n    s = create(rel_path)\n    assert not s.name_is_non_test\n    assert s.name_is_visual\n    assert not s.content_is_testharness\n    assert items(s) == [(\"visual\", \"/\" + rel_path)]\n@pytest.mark.parametrize(\"rel_path\", [\n    \"css-namespaces-3/reftest/ref-lime-1.xml\",\n    \"css21/reference/pass_if_box_ahem.html\",\n    \"css21/csswg-issues/submitted/css2.1/reference/ref-green-box-100x100.xht\",\n    \"selectors-3/selectors-empty-001-ref.xml\",\n    \"css21/text/text-indent-wrap-001-notref-block-margin.xht\",\n    \"css21/text/text-indent-wrap-001-notref-block-margin.xht\",\n    \"css21/css-e-notation-ref-1.html\",\n    \"css21/floats/floats-placement-vertical-004-ref2.xht\",\n    \"css21/box/rtl-linebreak-notref1.xht\",\n    \"css21/box/rtl-linebreak-notref2.xht\",\n    \"2dcontext/drawing-images-to-the-canvas/drawimage_html_image_5_ref.html\",\n    \"2dcontext/line-styles/lineto_ref.html\",\n    \"html/rendering/non-replaced-elements/the-fieldset-element-0/ref.html\"\n])\ndef test_name_is_reference(rel_path):\n    s = create(rel_path)\n    assert not s.name_is_non_test\n    assert s.name_is_reference\n    assert not s.content_is_testharness\n    assert items(s) == []\ndef test_worker():\n    s = create(\"html/test.worker.js\")\n    assert not s.name_is_non_test\n    assert not s.name_is_manual\n    assert not s.name_is_visual\n    assert not s.name_is_multi_global\n    assert s.name_is_worker\n    assert not s.name_is_window\n    assert not s.name_is_reference\n    assert not s.content_is_testharness\n    item_type, items = s.manifest_items()\n    assert item_type == \"testharness\"\n    expected_urls = [\n        \"/html/test.worker.html\",\n    ]\n    assert len(items) == len(expected_urls)\n    for item, url in zip(items, expected_urls):\n        assert item.url == url\n        assert item.timeout is None\ndef test_window():\n    s = create(\"html/test.window.js\")\n    assert not s.name_is_non_test\n    assert not s.name_is_manual\n    assert not s.name_is_visual\n    assert not s.name_is_multi_global\n    assert not s.name_is_worker\n    assert s.name_is_window\n    assert not s.name_is_reference\n    assert not s.content_is_testharness\n    item_type, items = s.manifest_items()\n    assert item_type == \"testharness\"\n    expected_urls = [\n        \"/html/test.window.html\",\n    ]\n    assert len(items) == len(expected_urls)\n    for item, url in zip(items, expected_urls):\n        assert item.url == url\n        assert item.timeout is None\ndef test_worker_long_timeout():\n    contents = b\"\"\"// META: timeout=long\nimportScripts('/resources/testharness.js')\ntest()\"\"\"\n    metadata = list(read_script_metadata(BytesIO(contents), js_meta_re))\n    assert metadata == [(b\"timeout\", b\"long\")]\n    s = create(\"html/test.worker.js\", contents=contents)\n    assert s.name_is_worker\n    item_type, items = s.manifest_items()\n    assert item_type == \"testharness\"\n    for item in items:\n        assert item.timeout == \"long\"\ndef test_window_long_timeout():\n    contents = b\"\"\"// META: timeout=long\ntest()\"\"\"\n    metadata = list(read_script_metadata(BytesIO(contents), js_meta_re))\n    assert metadata == [(b\"timeout\", b\"long\")]\n    s = create(\"html/test.window.js\", contents=contents)\n    assert s.name_is_window\n    item_type, items = s.manifest_items()\n    assert item_type == \"testharness\"\n    for item in items:\n        assert item.timeout == \"long\"\ndef test_python_long_timeout():\n    contents = b\"\"\"# META: timeout=long\n\"\"\"\n    metadata = list(read_script_metadata(BytesIO(contents),\n                                         python_meta_re))\n    assert metadata == [(b\"timeout\", b\"long\")]\n    s = create(\"webdriver/test.py\", contents=contents)\n    assert s.name_is_webdriver\n    item_type, items = s.manifest_items()\n    assert item_type == \"wdspec\"\n    for item in items:\n        assert item.timeout == \"long\"\ndef test_multi_global():\n    s = create(\"html/test.any.js\")\n    assert not s.name_is_non_test\n    assert not s.name_is_manual\n    assert not s.name_is_visual\n    assert s.name_is_multi_global\n    assert not s.name_is_worker\n    assert not s.name_is_reference\n    assert not s.content_is_testharness\n    item_type, items = s.manifest_items()\n    assert item_type == \"testharness\"\n    expected_urls = [\n        \"/html/test.any.html\",\n        \"/html/test.any.worker.html\",\n    ]\n    assert len(items) == len(expected_urls)\n    for item, url in zip(items, expected_urls):\n        assert item.url == url\n        assert item.timeout is None\ndef test_multi_global_long_timeout():\n    contents = b\"\"\"// META: timeout=long\nimportScripts('/resources/testharness.js')\ntest()\"\"\"\n    metadata = list(read_script_metadata(BytesIO(contents), js_meta_re))\n    assert metadata == [(b\"timeout\", b\"long\")]\n    s = create(\"html/test.any.js\", contents=contents)\n    assert s.name_is_multi_global\n    item_type, items = s.manifest_items()\n    assert item_type == \"testharness\"\n    for item in items:\n        assert item.timeout == \"long\"\n@pytest.mark.parametrize(\"input,expected\", [\n    (b\"\"\"//META: foo=bar\\n\"\"\", [(b\"foo\", b\"bar\")]),\n    (b\"\"\"// META: foo=bar\\n\"\"\", [(b\"foo\", b\"bar\")]),\n    (b\"\"\"//  META: foo=bar\\n\"\"\", [(b\"foo\", b\"bar\")]),\n    (b\"\"\"\\n// META: foo=bar\\n\"\"\", []),\n    (b\"\"\" // META: foo=bar\\n\"\"\", []),\n    (b\"\"\"// META: foo=bar\\n// META: baz=quux\\n\"\"\", [(b\"foo\", b\"bar\"), (b\"baz\", b\"quux\")]),\n    (b\"\"\"// META: foo=bar\\n\\n// META: baz=quux\\n\"\"\", [(b\"foo\", b\"bar\")]),\n    (b\"\"\"// META: foo=bar\\n// Start of the test\\n// META: baz=quux\\n\"\"\", [(b\"foo\", b\"bar\")]),\n    (b\"\"\"// META:\\n\"\"\", []),\n    (b\"\"\"// META: foobar\\n\"\"\", []),\n])\ndef test_script_metadata(input, expected):\n    metadata = read_script_metadata(BytesIO(input), js_meta_re)\n    assert list(metadata) == expected\n@pytest.mark.parametrize(\"ext\", [\"htm\", \"html\"])\ndef test_testharness(ext):\n    content = b\"<script src=/resources/testharness.js></script>\"\n    filename = \"html/test.\" + ext\n", "outputs": ["    s = create(filename, content)"], "input_length": 1455, "output_length": 8, "length": 1463, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "748494204a73bc6f3f2e2881e4b151cd19f1d7c0687f3a925d2b0d2de77380e3"}
{"input": "", "context": "/*\n * Copyright (c) 1998-2015 Caucho Technology -- all rights reserved\n *\n * This file is part of Resin(R) Open Source\n *\n * Each copy or derived work must preserve the copyright notice and this\n * notice unmodified.\n *\n * Resin Open Source is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License version 2\n * as published by the Free Software Foundation.\n *\n * Resin Open Source is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE, or any warranty\n * of NON-INFRINGEMENT.  See the GNU General Public License for more\n * details.\n *\n * You should have received a copy of the GNU General Public License\n * along with Resin Open Source; if not, write to the\n *\n *   Free Software Foundation, Inc.\n *   59 Temple Place, Suite 330\n *   Boston, MA 02111-1307  USA\n *\n * @author Alex Rojkov\n */\nusing System;\nusing System.Reflection;\nusing System.Collections;\nusing System.Text;\nusing System.IO;\nusing Microsoft.Win32;\nusing System.Diagnostics;\nusing System.Windows.Forms;\nusing System.ServiceProcess;\nusing System.Threading;\nusing System.Runtime.Serialization.Formatters.Binary;\nusing System.Security.Principal;\nnamespace Caucho\n{\n  public class Resin : ServiceBase\n  {\n    private static String HKEY_JRE = @\"Software\\JavaSoft\\Java Runtime Environment\";\n    private static String HKEY_JDK = @\"Software\\JavaSoft\\Java Development Kit\";\n    private static String CAUCHO_APP_DATA = @\"Caucho Technology\\Resin\";\n    private String _javaExe;\n    private String _javaHome;\n    private String _resinHome;\n    private String _rootDirectory;\n    private Process _process;\n    private ResinArgs ResinArgs;\n    private static Mutex mutex = new Mutex(false, @\"Global\\com.caucho.Resin\");\n    private Resin(ResinArgs args)\n    {\n      ResinArgs = args;\n      _resinHome = ResinArgs.ResinHome;\n      _rootDirectory = ResinArgs.ResinRoot;\n      _javaHome = ResinArgs.JavaHome;\n    }\n    public bool StartResin()\n    {\n      try\n      {\n        if (ResinArgs.IsService)\n          ExecuteJava(\"start\");\n        else\n          ExecuteJava(ResinArgs.Command);\n        return true;\n      } catch (ResinServiceException e)\n      {\n        throw e;\n      } catch (Exception e)\n      {\n        StringBuilder message = new StringBuilder(\"Unable to start application. Make sure java is in your path. Use option -verbose for more detail.\\n\");\n        message.Append(e.ToString());\n        Info(message.ToString());\n        return false;\n      }\n    }\n    public void StopResin()\n    {\n      if (ResinArgs.IsService)\n      {\n        Info(\"Stopping Resin\");\n        ExecuteJava(\"stop\");\n      }\n    }\n    private int Execute()\n    {\n      _resinHome = Util.GetResinHome(_resinHome, System.Reflection.Assembly.GetExecutingAssembly().Location);\n      if (_resinHome == null)\n      {\n        Error(\"Can't find RESIN_HOME\", null);\n        return 1;\n      }\n      if (_rootDirectory == null)\n        _rootDirectory = _resinHome;\n      _javaHome = GetJavaHome(_resinHome, _javaHome);\n      if (_javaExe == null && _javaHome != null)\n        _javaExe = GetJavaExe(_javaHome);\n      if (_javaExe == null)\n        _javaExe = \"java.exe\";\n      System.Environment.SetEnvironmentVariable(\"JAVA_HOME\", _javaHome);\n      Environment.SetEnvironmentVariable(\"PATH\",\n                                         String.Format(\"{0};{1};\\\\openssl\\\\bin;.\",\n                                                       _javaHome + \"\\\\bin\",\n                                                       Environment.GetEnvironmentVariable(\"PATH\")));\n      if (ResinArgs.IsService)\n      {\n        ServiceBase.Run(new ServiceBase[] { this });\n        return 0;\n      }\n      else\n      {\n        if (StartResin())\n        {\n          Join();\n          if (_process != null)\n          {\n            int exitCode = _process.ExitCode;\n            _process.Dispose();\n            return exitCode;\n          }\n        }\n        return 0;\n      }\n    }\n    private static String GetResinAppDataDir()\n    {\n      return Environment.GetFolderPath(Environment.SpecialFolder.ApplicationData) + '\\\\' + CAUCHO_APP_DATA;\n    }\n    private void ExecuteJava(String command)\n    {\n      mutex.WaitOne();\n      try\n      {\n        ExecuteJavaImpl(command);\n      }\n      finally\n      {\n        mutex.ReleaseMutex();\n      }\n    }\n    private void ExecuteJavaImpl(String command)\n    {\n      if (ResinArgs.IsVerbose)\n      {\n        StringBuilder info = new StringBuilder();\n        info.Append(\"java        : \").Append(_javaExe).Append('\\n');\n        info.Append(\"JAVA_HOME   : \").Append(_javaHome).Append('\\n');\n        info.Append(\"RESIN_HOME  : \").Append(_resinHome).Append('\\n');\n        info.Append(\"SERVER_ROOT : \").Append(_rootDirectory).Append('\\n');\n        info.Append(\"PATH        : \").Append(Environment.GetEnvironmentVariable(\"PATH\"));\n        Info(info.ToString());\n      }\n      ProcessStartInfo startInfo = new ProcessStartInfo();\n      startInfo.FileName = _javaExe;\n      StringBuilder arguments = new StringBuilder();\n      arguments.Append(\"-Xrs -jar \");\n      arguments.Append(\"\\\"\" + _resinHome + \"\\\\lib\\\\resin.jar\\\"\");\n      arguments.Append(\" -resin-home \\\"\").Append(_resinHome).Append(\"\\\" \");\n      arguments.Append(\" -root-directory \\\"\").Append(_rootDirectory).Append(\"\\\" \");\n      if (\"\".Equals(ResinArgs.Server))\n        arguments.Append(\" -server \\\"\\\"\");\n      else if (ResinArgs.Server != null)\n        arguments.Append(\" -server \").Append(ResinArgs.Server);\n      if (ResinArgs.ElasticServer)\n        arguments.Append(\" --elastic-server \");\n          /*\n      else if (ResinArgs.DynamicServer != null)\n        arguments.Append(\" -dynamic-server \").Append(ResinArgs.DynamicServer);\n        */\n      if (command != null)\n        arguments.Append(' ').Append(command);\n      else if (ResinArgs.RawArgs.Count == 1)\n        arguments.Append(' ').Append(\"gui\");\n      bool isStart = \"start\".Equals(command)\n                     || \"gui\".Equals(command)\n                     || \"console\".Equals(command);\n      if (isStart && ResinArgs.Cluster != null)\n        arguments.Append(\" -cluster \").Append(ResinArgs.Cluster);\n      if (isStart\n        && ResinArgs.ElasticServer\n        && ! String.IsNullOrEmpty(ResinArgs.ElasticServerAddress)) {\n        arguments.Append(\" --elastic-server-address \").Append(ResinArgs.ElasticServerAddress).Append(' ');\n      }\n      if (isStart\n        && ResinArgs.ElasticServer\n        && ! String.IsNullOrEmpty(ResinArgs.ElasticServerPort)) {\n        arguments.Append(\" --elastic-server-port \").Append(ResinArgs.ElasticServerPort).Append(' ');\n      }\n      arguments.Append(' ').Append(ResinArgs.ResinArguments);\n      startInfo.Arguments = arguments.ToString();\n      if (ResinArgs.IsVerbose)\n        Info(\"Using Command Line: \" + _javaExe + ' ' + startInfo.Arguments);\n      startInfo.UseShellExecute = false;\n      if (ResinArgs.IsService)\n      {\n        startInfo.RedirectStandardError = true;\n        startInfo.RedirectStandardOutput = true;\n        Process process = null;\n        try\n        {\n          process = Process.Start(startInfo);\n        } catch (Exception e)\n        {\n          Error(e.Message, e);\n          return;\n        }\n        StringBuilder error = new StringBuilder();\n        StringBuilder output = new StringBuilder();\n        process.ErrorDataReceived += delegate(Object sendingProcess, DataReceivedEventArgs err)\n        {\n          error.Append(err.Data).Append('\\n');\n        };\n        process.OutputDataReceived += delegate(object sender, DataReceivedEventArgs err)\n        {\n          output.Append(err.Data).Append('\\n');\n        };\n        process.BeginErrorReadLine();\n        process.BeginOutputReadLine();\n        while (!process.HasExited)\n          process.WaitForExit(500);\n        process.CancelErrorRead();\n        process.CancelOutputRead();\n        if (process.HasExited && process.ExitCode != 0)\n        {\n          StringBuilder messageBuilder = new StringBuilder(\"Error Executing Resin Using: \");\n          messageBuilder.Append(startInfo.FileName).Append(' ').Append(startInfo.Arguments);\n          if (output.Length > 0)\n            messageBuilder.Append('\\n').Append(output);\n          if (error.Length > 0)\n            messageBuilder.Append('\\n').Append(error);\n          String message = messageBuilder.ToString();\n          Info(message, true);\n          throw new ResinServiceException(message);\n        }\n      }\n      else\n      {\n        _process = Process.Start(startInfo);\n      }\n    }\n    protected override void OnStart(string[] args)\n    {\n      base.OnStart(args);\n      Info(\"Service: \" + ResinArgs.ServiceName);\n      StartResin();\n    }\n    protected override void OnStop()\n    {\n      base.OnStop();\n      StopResin();\n    }\n    private void Join()\n    {\n      if (_process != null && !_process.HasExited)\n        _process.WaitForExit();\n    }\n    public void Error(String message, Exception e)\n    {\n      Error(message, e, null);\n    }\n    public void Error(String message, Exception e, TextWriter writer)\n    {\n      StringBuilder data = new StringBuilder(message);\n      if (e != null)\n        data.Append('\\n').Append(e.ToString());\n      if (writer != null)\n        writer.WriteLine(data.ToString());\n      else if (ResinArgs.IsService && EventLog != null)\n      {\n        EventLog.WriteEntry(\"Resin: \" + ResinArgs.ServiceName, data.ToString(), EventLogEntryType.Error);\n      }\n      else\n        Console.WriteLine(data.ToString());\n    }\n    private void Info(String message)\n    {\n      Info(message, null, true);\n    }\n    private void Info(String message, bool newLine)\n    {\n      Info(message, null, newLine);\n    }\n    private void Info(String message, TextWriter writer, bool newLine)\n    {\n      if (writer != null && newLine)\n        writer.WriteLine(message);\n      else if (writer != null && !newLine)\n        writer.Write(message);\n      else if (ResinArgs.IsService && EventLog != null)\n      {\n        EventLog.WriteEntry(\"Resin: \" + ResinArgs.ServiceName, message, EventLogEntryType.Information);\n      }\n      else if (newLine)\n        Console.WriteLine(message);\n      else\n        Console.Write(message);\n    }\n    public static int Main(String[] args)\n    {\n      ResinArgs resinArgs = new ResinArgs(Environment.GetCommandLineArgs());\n      Resin resin = new Resin(resinArgs);\n      return resin.Execute();\n    }\n    private static String GetJavaExe(String javaHome)\n    {\n      if (File.Exists(javaHome + @\"\\bin\\java.exe\"))\n        return javaHome + @\"\\bin\\java.exe\";\n      else if (File.Exists(javaHome + @\"\\jrockit.exe\"))\n        return javaHome + @\"\\jrockit.exe\";\n      else\n        return null;\n    }\n    private static String FindJdkInRegistry(String key)\n    {\n      RegistryKey regKey\n        = Registry.LocalMachine.OpenSubKey(key);\n      if (regKey == null)\n        return null;\n      RegistryKey java = regKey.OpenSubKey(\"CurrentVersion\");\n      if (java == null)\n", "outputs": ["        java = regKey.OpenSubKey(\"1.6\");"], "input_length": 1848, "output_length": 9, "length": 1857, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "93c5a52179afec5b92660475de77d18141cc5fb1d782ae7b67850dd12b9a66f6"}
{"input": "", "context": "/*\n *  Freeplane - mind map editor\n *  Copyright (C) 2012 Dimitry\n *\n *  This file author is Dimitry\n *\n *  This program is free software: you can redistribute it and/or modify\n *  it under the terms of the GNU General Public License as published by\n *  the Free Software Foundation, either version 2 of the License, or\n *  (at your option) any later version.\n *\n *  This program is distributed in the hope that it will be useful,\n *  but WITHOUT ANY WARRANTY; without even the implied warranty of\n *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n *  GNU General Public License for more details.\n *\n *  You should have received a copy of the GNU General Public License\n *  along with this program.  If not, see <http://www.gnu.org/licenses/>.\n */\npackage org.freeplane.plugin.script;\nimport java.io.File;\nimport java.io.PrintStream;\nimport java.security.AccessControlException;\nimport java.security.AccessController;\nimport java.security.PrivilegedAction;\nimport java.security.PrivilegedActionException;\nimport java.security.PrivilegedExceptionAction;\nimport java.util.regex.Matcher;\nimport javax.swing.SwingUtilities;\nimport org.codehaus.groovy.ast.ASTNode;\nimport org.codehaus.groovy.ast.ModuleNode;\nimport org.codehaus.groovy.control.CompilerConfiguration;\nimport org.codehaus.groovy.control.customizers.ImportCustomizer;\nimport org.codehaus.groovy.runtime.InvokerHelper;\nimport org.freeplane.features.map.IMapSelection;\nimport org.freeplane.features.map.NodeModel;\nimport org.freeplane.features.mode.Controller;\nimport org.freeplane.plugin.script.proxy.ScriptUtils;\nimport groovy.lang.Binding;\nimport groovy.lang.GroovyRuntimeException;\nimport groovy.lang.Script;\n/**\n * Special scripting implementation for Groovy.\n */\npublic class GroovyScript implements IScript {\n    final private Object script;\n    private final ScriptingPermissions specificPermissions;\n    private FreeplaneScriptBaseClass compiledScript;\n    private Throwable errorsInScript;\n    private CompileTimeStrategy compileTimeStrategy;\n\tprivate ScriptClassLoader scriptClassLoader;\n    public GroovyScript(String script) {\n        this((Object) script);\n    }\n    public GroovyScript(File script) {\n        this((Object) script);\n        compileTimeStrategy = new CompileTimeStrategy(script);\n    }\n    public GroovyScript(String script, ScriptingPermissions permissions) {\n        this((Object) script, permissions);\n    }\n    public GroovyScript(File script, ScriptingPermissions permissions) {\n        this((Object) script, permissions);\n        compileTimeStrategy = new CompileTimeStrategy(script);\n    }\n    private GroovyScript(Object script, ScriptingPermissions permissions) {\n        super();\n        this.script = script;\n        this.specificPermissions = permissions;\n        compiledScript = null;\n        errorsInScript = null;\n        compileTimeStrategy = new CompileTimeStrategy(null);\n    }\n    private GroovyScript(Object script) {\n        this(script, null);\n    }\n    public Script getCompiledScript() {\n        return compiledScript;\n    }\n    @Override\n    public Object execute(final NodeModel node, PrintStream outStream, IFreeplaneScriptErrorHandler errorHandler, ScriptContext scriptContext) {\n        try {\n            if (errorsInScript != null && compileTimeStrategy.canUseOldCompiledScript()) {\n                throw new ExecuteScriptException(errorsInScript.getMessage(), errorsInScript);\n            }\n            final PrintStream oldOut = System.out;\n            ClassLoader contextClassLoader = Thread.currentThread().getContextClassLoader();\n            try {\n                trustedCompileAndCache(outStream);\n                Thread.currentThread().setContextClassLoader(scriptClassLoader);\n                FreeplaneScriptBaseClass scriptWithBinding = AccessController.doPrivileged(new PrivilegedAction<FreeplaneScriptBaseClass>() {\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic FreeplaneScriptBaseClass run() {\n\t\t\t\t\t\treturn compiledScript.withBinding(node, scriptContext);\n\t\t\t\t\t}\n\t\t\t\t}); \n                System.setOut(outStream);\n\t\t\t\tfinal Object result = scriptWithBinding.run();\n\t\t\t\treturn result;\n            } finally {\n                System.setOut(oldOut);\n                Thread.currentThread().setContextClassLoader(contextClassLoader);\n            }\n        } catch (final GroovyRuntimeException e) {\n            handleScriptRuntimeException(e, outStream, errorHandler);\n            // :fixme: This throw is only reached, if\n            // handleScriptRuntimeException\n            // does not raise an exception. Should it be here at all?\n            // And if: Shouldn't it raise an ExecuteScriptException?\n            throw new RuntimeException(e);\n        } catch (final Throwable e) {\n\t\t\tIMapSelection selection = Controller.getCurrentController().getSelection();\n\t\t\tif (selection != null && node != null && ! node.equals(selection.getSelected()) && node.hasVisibleContent()) {\n\t\t\t\tSwingUtilities.invokeLater(new Runnable() {\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic void run() {\n\t\t\t\t\t\tController.getCurrentModeController().getMapController().select(node);\n\t\t\t\t\t}\n\t\t\t\t});\n            }\n            throw new ExecuteScriptException(e.getMessage(), e);\n        }\n    }\n    private ScriptingSecurityManager createScriptingSecurityManager(PrintStream outStream) {\n        return new ScriptSecurity(script, specificPermissions, outStream)\n                .getScriptingSecurityManager();\n    }\n    private void trustedCompileAndCache(PrintStream outStream) throws Throwable {\n\t\tAccessController.doPrivileged(new PrivilegedExceptionAction<Void>() {\n\t\t\t@Override\n\t\t\tpublic Void run() throws PrivilegedActionException {\n\t\t\t\ttry {\n\t\t\t\t\tfinal ScriptingSecurityManager scriptingSecurityManager = createScriptingSecurityManager(outStream);\n\t\t\t\t\tcompileAndCache(scriptingSecurityManager);\n\t\t\t\t} catch (Exception e) {\n\t\t\t\t\tthrow new PrivilegedActionException(e);\n\t\t\t\t} catch (Error e) {\n\t\t\t\t\tthrow e;\n\t\t\t\t} catch (Throwable e) {\n\t\t\t\t\tthrow new RuntimeException(e);\n\t\t\t\t}\n\t\t\t\treturn null;\n\t\t\t}\n\t\t});\n\t}\n    private static boolean accessPermissionCheckerChecked = false;\n    private Script compileAndCache(final ScriptingSecurityManager scriptingSecurityManager) throws Throwable {\n    \tcheckAccessPermissionCheckerExists();\n    \tif (compileTimeStrategy.canUseOldCompiledScript()) {\n\t\t\tscriptClassLoader.setSecurityManager(scriptingSecurityManager);\n            return compiledScript;\n        }\n        removeOldScript();\n        errorsInScript = null;\n        if (script instanceof Script) {\n            return (Script) script;\n        } else {\n            try {\n                final Binding binding = createBindingForCompilation();\n\t\t\t\tscriptClassLoader = ScriptClassLoader.createClassLoader();\n\t\t\t\tscriptClassLoader.setSecurityManager(scriptingSecurityManager);\n\t\t\t\tfinal GroovyShell shell = new GroovyShell(scriptClassLoader, binding,\n                        createCompilerConfiguration());\n                compileTimeStrategy.scriptCompileStart();\n                if (script instanceof String) {\n                    compiledScript = (FreeplaneScriptBaseClass) shell.parse((String) script);\n                } else if (script instanceof File) {\n                    compiledScript = (FreeplaneScriptBaseClass) shell.parse((File) script);\n                } else {\n                    throw new IllegalArgumentException();\n                }\n                compiledScript.setScript(script);\n                compileTimeStrategy.scriptCompiled();\n                return compiledScript;\n            } catch (Throwable e) {\n                errorsInScript = e;\n                throw e;\n            }\n        }\n    }\n\tstatic void checkAccessPermissionCheckerExists() {\n\t\tif(!accessPermissionCheckerChecked){\n    \t\tif(System.getSecurityManager() != null){\n\t\t\t\ttry {\n\t\t\t\t\tGroovyScript.class.getClassLoader().loadClass(\"org.codehaus.groovy.reflection.AccessPermissionChecker\");\n\t\t\t\t} catch (ClassNotFoundException e) {\n\t\t\t\t\tthrow new AccessControlException(\"class org.codehaus.groovy.reflection.AccessPermissionChecker not found\");\n\t\t\t\t}\n\t\t\t}\n    \t\taccessPermissionCheckerChecked = true;\n    \t}\n\t}\n    private void removeOldScript() {\n", "outputs": ["        if (compiledScript != null) {"], "input_length": 1080, "output_length": 8, "length": 1088, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "e1d6fc969346cad53b8e4e4ef1cd05247a92c3cf37ac16a98d3a06fb98c49737"}
{"input": "", "context": "/**\n * The i3DML Project\n * Author:  Keyvan M. Kambakhsh\n * \n * UNDER GPL V3 LICENSE\n **/\nusing System;\nusing i3DML.ObjectModel.Components;\nnamespace i3DML.ObjectModel\n{\n    /// <summary>\n    /// Provides a drawable or a container element.\n    /// </summary>\n    public abstract class Drawable : WorldElement,Ii3DMLInitializable,IDisposable\n    {\n        #region Fields\n        private ScriptManager _ScriptManager;\n        private Point _Position;\n        private Rotation _Rotation;\n        private Ratio _RotationOrigin;\n        private Ratio _Scale;\n        #endregion\n        #region Properties\n        #region Parents\n        /// <summary>\n        /// Root element.\n        /// </summary>\n        [i3DMLReaderIgnore]\n        public World World { get; internal set; }\n        /// <summary>\n        /// Parent element.\n        /// </summary>\n        [i3DMLReaderIgnore]\n        public PlaceBase Parent { get; internal set; }\n        #endregion\n        #region Visiblity\n        /// <summary>\n        /// Is the element visible on the screen?\n        /// </summary>\n        public bool Visible { get; set; }\n        #endregion\n        #region Position\n        /// <summary>\n        /// Position of element in the element's local space.\n        /// </summary>\n        public Point Position { get { return _Position; } set { if (value != null) _Position = value; } }\n        /// <summary>\n        /// Absolute position of element in the root element.\n        /// </summary>\n        [i3DMLReaderIgnore]\n        public Point AbsolutePosition\n        {\n            get\n            {\n                Point absRot = new Point();\n                absRot.X = OriginPosition.X;\n                absRot.Y = OriginPosition.Y;\n                absRot.Z = OriginPosition.Z;\n                Drawable parent = this.Parent;\n                Drawable lastParent = null;\n                while (parent.Parent != null)\n                {\n                    absRot += parent.OriginPosition;\n                    absRot = Matrix.Transform(absRot, Matrix.Rotate(parent.Rotation));\n                    lastParent = parent;\n                    parent = parent.Parent;\n                }\n                if (lastParent != null)\n                {\n                    Point lp = Matrix.Transform(lastParent.OriginPosition, Matrix.Rotate(lastParent.Rotation));\n                    return (absRot - lp + lastParent.OriginPosition);\n                }\n                else\n                    return absRot;\n            }\n        }\n        /// <summary>\n        /// The element's center position in the element's local space (Before scaling).\n        /// </summary>\n        [i3DMLReaderIgnore]\n        public Point CenterPosition\n        {\n            get\n            {\n                Point ret;\n                if (this is Shape)\n                    ret = (this as Shape).Size * RotationOrigin;\n                else if (this is Surface)\n                {\n                    Size2D s = (this as Surface).Size * RotationOrigin;\n                    ret = new Point(s.X, 0, s.Y);\n                }\n                else ret = new Point(0, 0, 0);\n                ret = Matrix.Transform(ret, Matrix.Rotate(Rotation));\n                return ret;\n            }\n        }\n        /// <summary>\n        /// The element's center position in the element's local space (After scaling).\n        /// </summary>\n        [i3DMLReaderIgnore]\n        public Point OriginPosition\n        {\n            get { return (Position * AbsoluteScale / Scale) - CenterPosition * AbsoluteScale; }\n        }\n        #endregion\n        #region Rotation\n        /// <summary>\n        /// The element's rotation in the element's local space.\n        /// </summary>\n        public Rotation Rotation { get { return _Rotation; } set { if (value != null)_Rotation = value; } }\n        /// <summary>\n        /// The element's absolute rotation matrix in the root element.\n        /// </summary>\n        [i3DMLReaderIgnore]\n        public Matrix AbsoluteRotationMatrix\n        {\n            get\n            {\n                Matrix ret = Matrix.Rotate(Rotation);\n                Drawable parent=Parent;\n                while (parent != null)\n                {\n                    ret *= Matrix.Rotate(parent.Rotation);\n                    parent = parent.Parent;\n                }\n                return ret;\n            }\n        }\n        /// <summary>\n        /// The element's rotation origin point ratio.\n        /// </summary>\n        public Ratio RotationOrigin { get { return _RotationOrigin; } set { if (value != null)_RotationOrigin = value; } }\n        #endregion\n        #region Scale\n        /// <summary>\n        /// The element's scale in the element's local space.\n        /// </summary>\n        public Ratio Scale { get { return _Scale; } set { if (value != null) _Scale = value; } }\n        /// <summary>\n        /// The element's absolute scale in the root element.\n        /// </summary>\n        [i3DMLReaderIgnore]\n        public Ratio AbsoluteScale\n        {\n            get\n            {\n                Ratio absScale = new Ratio() { X = Scale.X, Y = Scale.Y, Z = Scale.Z };\n                Drawable parent = Parent;\n                while (parent != null)\n                {\n                    absScale *= parent.Scale;\n                    parent = parent.Parent;\n                }\n                return absScale;\n            }\n        }\n        #endregion\n        #region Scripts\n        \n        /// <summary>\n        /// Corresponding ScriptManager for this drawable.\n        /// </summary>\n        [i3DMLReaderIgnore]\n        protected ScriptManager ScriptManager { get { return _ScriptManager; } private set { _ScriptManager = value; } }\n        /// <summary>\n        /// Contains drawable scripts.\n        /// </summary>\n        public string Script { get; set; }\n        #region Events\n        public string OnUpdate { get; set; }\n        #endregion\n        #endregion\n        #endregion\n        public Drawable()\n        {\n            this.ScriptManager = new ScriptManager(this);\n            this.RotationOrigin = new Ratio() { X = 0.5d, Y = 0.5d, Z = 0.5d };\n            this.Position = new Point() { X = 0d, Y = 0d, Z = 0d };\n            this.Rotation = new Rotation { X = 0d, Y = 0d, Z = 0d };\n            this.Scale = new Ratio() { X = 1, Y = 1, Z = 1 };\n            this.Visible = true;\n        }\n        /// <summary>\n        /// Find an element with a specified name by looking to the descendants of this element.\n        /// </summary>\n        /// <param name=\"Name\">Name of the element we are looking for</param>\n        /// <returns>The found element</returns>\n        public Drawable FindElement(string Name)\n        {\n            if (this.Name == Name)\n                return this;\n            var plcs=new System.Collections.Generic.Stack<PlaceBase>();\n            if (this is PlaceBase)\n                plcs.Push(this as PlaceBase);\n            while (plcs.Count != 0)\n            {\n                PlaceBase pop=plcs.Pop();\n                if (pop.Name == Name)\n                    return pop;\n                for (int i = 0; i < pop.Length; i++)\n                {\n", "outputs": ["                    if (pop[i] is PlaceBase)"], "input_length": 1105, "output_length": 9, "length": 1114, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "2e6050b8cf3fed597666122f1aad7a9ccf699af0309b441c45b803f22ffea7a5"}
{"input": "", "context": "package org.checkerframework.common.aliasing;\n/*>>>\nimport org.checkerframework.checker.compilermsgs.qual.CompilerMessageKey;\n*/\nimport org.checkerframework.common.aliasing.qual.LeakedToResult;\nimport org.checkerframework.common.aliasing.qual.NonLeaked;\nimport org.checkerframework.common.aliasing.qual.Unique;\nimport org.checkerframework.common.basetype.BaseTypeChecker;\nimport org.checkerframework.common.basetype.BaseTypeVisitor;\nimport org.checkerframework.dataflow.cfg.node.MethodInvocationNode;\nimport org.checkerframework.framework.source.Result;\nimport org.checkerframework.framework.type.AnnotatedTypeMirror;\nimport org.checkerframework.framework.type.AnnotatedTypeMirror.AnnotatedArrayType;\nimport org.checkerframework.framework.type.AnnotatedTypeMirror.AnnotatedDeclaredType;\nimport org.checkerframework.framework.type.AnnotatedTypeMirror.AnnotatedExecutableType;\nimport org.checkerframework.javacutil.TreeUtils;\nimport java.util.List;\nimport javax.lang.model.element.ExecutableElement;\nimport javax.lang.model.element.VariableElement;\nimport com.sun.source.tree.ExpressionTree;\nimport com.sun.source.tree.MethodInvocationTree;\nimport com.sun.source.tree.MethodTree;\nimport com.sun.source.tree.NewArrayTree;\nimport com.sun.source.tree.ThrowTree;\nimport com.sun.source.tree.Tree;\nimport com.sun.source.tree.Tree.Kind;\nimport com.sun.source.tree.VariableTree;\n/**\n * This visitor ensures that every constructor whose result is annotated as\n * {@literal @}Unique does not leak aliases.\n * <p>\n *\n * TODO: Implement {@literal @}NonLeaked and {@literal @}LeakedToResult verifications:\n * <p>\n *  {@literal @}NonLeaked: When a method declaration has a parameter annotated as\n *  {@literal @}NonLeaked, the method body must not leak a reference to that parameter.\n * <p>\n *\n *  {@literal @}LeakedToResult: When a method declaration has a parameter annotated as\n *  {@literal @}LeakedToResult, the method body must not leak a reference to that parameter,\n *  except at the method return statements.\n * <p>\n *\n *  Both of the checks above are similar to the @Unique check that is\n *  implemented in this visitor.\n */\npublic class AliasingVisitor extends\n        BaseTypeVisitor<AliasingAnnotatedTypeFactory> {\n    public AliasingVisitor(BaseTypeChecker checker) {\n        super(checker);\n    }\n    /**\n     * Checks that if a method call is being invoked inside a constructor with\n     * result type {@literal @}Unique, it must not leak the \"this\" reference.\n     * There are 3 ways to make sure that this is not happening:\n     * <p>\n     * 1. \"this\" is not an argument of the method call.\n     * <p>\n     * 2. \"this\" is an argument of the method call, but the respective parameter\n     * is annotated as {@literal @}NonLeaked.\n     * <p>\n     * 3. \"this\" is an argument of the method call, but the respective parameter\n     * is annotated as {@literal @}LeakedToResult AND the result of the method\n     * call is not being stored (the method call is a statement).\n     * <p>\n     * The private method <code>isUniqueCheck</code> handles cases 2 and 3.\n     */\n    @Override\n    public Void visitMethodInvocation(MethodInvocationTree node, Void p) {\n        // The check only needs to be done for constructors with result type\n        // @Unique. We also want to avoid visiting the <init> method.\n        if (isInUniqueConstructor(node)) {\n            if (TreeUtils.isSuperCall(node)) {\n                // Check if a call to super() might create an alias: that\n                // happens when the parent's respective constructor is not @Unique.\n                AnnotatedTypeMirror superResult = atypeFactory.\n                        getAnnotatedType(node);\n                if (!superResult.hasAnnotation(Unique.class)) {\n                    checker.report(Result.failure(\"unique.leaked\"), node);\n                }\n            } else {\n                // TODO: Currently the type of \"this\" doesn't always return\n                // the type of the constructor result, therefore we need\n                // this \"else\" block. Once constructors are implemented\n                // correctly we could remove that code below, since the type\n                // of \"this\" in a @Unique constructor will be @Unique.\n                MethodInvocationNode n = (MethodInvocationNode) atypeFactory.\n                        getNodeForTree(node);\n                Tree parent = n.getTreePath().getParentPath().getLeaf();\n                boolean parentIsStatement = parent.getKind() == Kind.\n                        EXPRESSION_STATEMENT;\n                ExecutableElement methodElement = TreeUtils.elementFromUse(node);\n                List<? extends VariableElement> params = methodElement.\n                        getParameters();\n                List<? extends ExpressionTree> args = node.getArguments();\n                assert (args.size() == params.size()) : \"Number of arguments in\"\n                + \" the method call \" + n.toString() + \" is different from the \"\n                + \"number of parameters for the method declaration: \"\n                + methodElement.getSimpleName().toString();\n                for (int i = 0; i < args.size(); i++) {\n                    // Here we are traversing the arguments of the method call.\n                    // For every argument we check if it is a reference to \"this\".\n                    if (TreeUtils.isExplicitThisDereference(args.get(i))) {\n                        // If it is a reference to \"this\", there is still hope that\n                        // it is not being leaked (2. and 3. from the javadoc).\n                        VariableElement param = params.get(i);\n                        boolean hasNonLeaked = atypeFactory.getAnnotatedType(\n                                param).\n                                hasAnnotation(NonLeaked.class);\n                        boolean hasLeakedToResult = atypeFactory.\n                                getAnnotatedType(param).\n                                hasAnnotation(LeakedToResult.class);\n                        isUniqueCheck(node, parentIsStatement, hasNonLeaked,\n                                hasLeakedToResult);\n                    } else {\n                        //Not possible to leak reference here (case 1. from the javadoc).\n                    }\n                }\n                // Now, doing the same as above for the receiver parameter\n                AnnotatedExecutableType annotatedType = atypeFactory.\n                        getAnnotatedType(methodElement);\n                AnnotatedDeclaredType receiverType = annotatedType.\n                        getReceiverType();\n                if (receiverType != null) {\n                    boolean hasNonLeaked = receiverType.hasAnnotation(\n                            NonLeaked.class);\n                    boolean hasLeakedToResult = receiverType.hasAnnotation(\n                            LeakedToResult.class);\n                    isUniqueCheck(node, parentIsStatement, hasNonLeaked,\n                            hasLeakedToResult);\n                }\n            }\n        }\n        return super.visitMethodInvocation(node, p);\n    }\n    private void isUniqueCheck(MethodInvocationTree node, boolean parentIsStatement,\n            boolean hasNonLeaked, boolean hasLeakedToResult) {\n        if (hasNonLeaked || (hasLeakedToResult && parentIsStatement)) {\n            // Not leaked according to cases 2. and 3. from the javadoc of\n            // visitMethodInvocation.\n        } else {\n            // May be leaked, raise warning.\n            checker.report(Result.failure(\"unique.leaked\"), node);\n        }\n    }\n    // TODO: Merge that code in\n    // commonAssignmentCheck(AnnotatedTypeMirror varType, ExpressionTree\n    // valueExp, String errorKey, boolean isLocalVariableAssignement), because\n    // the method below isn't called for pseudo-assignments, but the mentioned\n    // one is. The issue of copy-pasting the code from this method to the other\n    // one is that a declaration such as: List<@Unique Object> will raise a\n    // unique.leaked warning, as there is a pseudo-assignment from @Unique to a\n    // @MaybeAliased object, if the @Unique annotation is not in the stubfile.\n    // TODO: Change the documentation in BaseTypeVisitor to point out that\n    // this isn't called for pseudo-assignments.\n    @Override\n    protected void commonAssignmentCheck(Tree varTree, ExpressionTree valueExp,\n            /*@CompilerMessageKey*/ String errorKey) {\n        super.commonAssignmentCheck(varTree, valueExp, errorKey);\n        if (isInUniqueConstructor(valueExp) && TreeUtils.\n                isExplicitThisDereference(valueExp)) {\n            // If an assignment occurs inside a constructor with\n            // result type @Unique, it will invalidate the @Unique property\n            // by using the \"this\" reference.\n            checker.report(Result.failure(\"unique.leaked\"), valueExp);\n        } else if (canBeLeaked(valueExp)) {\n            checker.report(Result.failure(\"unique.leaked\"), valueExp);\n        }\n    }\n    @Override\n    protected void commonAssignmentCheck(AnnotatedTypeMirror varType,\n            AnnotatedTypeMirror valueType, Tree valueTree, /*@CompilerMessageKey*/ String errorKey) {\n        super.commonAssignmentCheck(varType, valueType, valueTree, errorKey);\n        // If we are visiting a pseudo-assignment, visitorLeafKind is either\n        // Kind.NEW_CLASS or Kind.METHOD_INVOCATION.\n        Kind visitorLeafKind = visitorState.getPath().getLeaf().getKind();\n        Kind parentKind = visitorState.getPath().getParentPath().getLeaf().\n                getKind();\n        if (visitorLeafKind == Kind.NEW_CLASS ||\n                visitorLeafKind == Kind.METHOD_INVOCATION) {\n            // Handling pseudo-assignments\n            if (canBeLeaked(valueTree)) {\n                if (!varType.hasAnnotation(NonLeaked.class) &&\n                        !(varType.hasAnnotation(LeakedToResult.class) &&\n                        parentKind == Kind.EXPRESSION_STATEMENT)) {\n                    checker.report(Result.failure(\"unique.leaked\"), valueTree);\n                }\n            }\n        }\n    }\n    @Override\n    public Void visitThrow(ThrowTree node, Void p) {\n        // throw is also an escape mechanism. If an expression of type\n        // @Unique is thrown, it is not @Unique anymore.\n        ExpressionTree exp = node.getExpression();\n        if (canBeLeaked(exp)) {\n            checker.report(Result.failure(\"unique.leaked\"), exp);\n        }\n        return super.visitThrow(node, p);\n    }\n    @Override\n    public Void visitVariable(VariableTree node, Void p) {\n        // Component types are not allowed to have the @Unique annotation.\n        AnnotatedTypeMirror varType = atypeFactory.getAnnotatedType(node);\n        VariableElement elt = TreeUtils.elementFromDeclaration(node);\n        if (elt.getKind().isField() && varType.hasExplicitAnnotation(Unique.class)) {\n            checker.report(Result.failure(\"unique.location.forbidden\"), node);\n        } else if (node.getType().getKind() == Kind.ARRAY_TYPE) {\n            AnnotatedArrayType arrayType = (AnnotatedArrayType) varType;\n            if (arrayType.getComponentType().hasAnnotation(Unique.class)) {\n                checker.report(Result.failure(\"unique.location.forbidden\"),\n                        node);\n            }\n        } else if (node.getType().getKind() == Kind.PARAMETERIZED_TYPE) {\n            AnnotatedDeclaredType declaredType = (AnnotatedDeclaredType) varType;\n            for (AnnotatedTypeMirror atm : declaredType.getTypeArguments()) {\n                if (atm.hasAnnotation(Unique.class)) {\n                    checker.report(Result.failure(\"unique.location.forbidden\"),\n                            node);\n                }\n            }\n        }\n        return super.visitVariable(node, p);\n    }\n    @Override\n    public Void visitNewArray(NewArrayTree node, Void p) {\n        List<? extends ExpressionTree> initializers = node.getInitializers();\n", "outputs": ["        if (initializers != null && !initializers.isEmpty()) {"], "input_length": 1720, "output_length": 14, "length": 1734, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "cf4df10f387903c72038e4ad6a56ae743ecb803d7c1201f046266f30f07e2459"}
{"input": "", "context": "# -*- coding: utf-8 -*-\n# OpenFisca -- A versatile microsimulation software\n# By: OpenFisca Team <contact@openfisca.fr>\n#\n# Copyright (C) 2011, 2012, 2013, 2014 OpenFisca Team\n# https://github.com/openfisca\n#\n# This file is part of OpenFisca.\n#\n# OpenFisca is free software; you can redistribute it and/or modify\n# it under the terms of the GNU Affero General Public License as\n# published by the Free Software Foundation, either version 3 of the\n# License, or (at your option) any later version.\n#\n# OpenFisca is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU Affero General Public License for more details.\n#\n# You should have received a copy of the GNU Affero General Public License\n# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\"\"\"Handle legislative parameters in XML format (and convert then to JSON).\"\"\"\nimport collections\nimport logging\nimport itertools\nimport datetime\nfrom openfisca_core import conv\nfrom datetime import datetime as dt\n#legislation_json_key_by_xml_tag = dict(\n#    ASSIETTE = 'base',  # \"base\" is singular, because a slice has only one base.\n#    BAREME = 'scales',\n#    CODE = 'parameters',\n#    NODE = 'nodes',\n#    SEUIL= 'threshold',  # \"threshold\" is singular, because a slice has only one base.\n#    TAUX = 'rate',  # \"rate\" is singular, because a slice has only one base.\n#    TRANCHE = 'slices',\n#    VALUE = 'values',\n#    )\nlog = logging.getLogger(__name__)\njson_unit_by_xml_json_type = dict(\n    age = u'year',\n    days = u'day',\n    hours = u'hour',\n    monetary = u'currency',\n    months = u'month',\n    )\nN_ = lambda message: message\nxml_json_formats = (\n    'bool',\n    'float',\n    'integer',\n    'percent',\n    'date',\n    )\ndef make_validate_values_xml_json_dates(require_consecutive_dates = False):\n    def validate_values_xml_json_dates(values_xml_json, state = None):\n        if not values_xml_json:\n            return values_xml_json, None\n        if state is None:\n            state = conv.default_state\n        errors = {}\n        for index, value_xml_json in enumerate(values_xml_json):\n            if value_xml_json['deb'] > value_xml_json['fin']:\n                errors[index] = dict(fin = state._(u\"Last date must be greater than first date\"))\n        sorted_values_xml_json = sorted(values_xml_json, key = lambda value_xml_json: value_xml_json['deb'],\n            reverse = True)\n        next_value_xml_json = sorted_values_xml_json[0]\n        for index, value_xml_json in enumerate(itertools.islice(sorted_values_xml_json, 1, None)):\n            next_date_str = (datetime.date(*(int(fragment) for fragment in value_xml_json['fin'].split('-')))\n                + datetime.timedelta(days = 1)).isoformat()\n            if require_consecutive_dates and next_date_str < next_value_xml_json['deb']:\n                errors.setdefault(index, {})['deb'] = state._(u\"Dates of values are not consecutive\")\n            elif next_date_str > next_value_xml_json['deb']:\n                errors.setdefault(index, {})['deb'] = state._(u\"Dates of values overlap\")\n            next_value_xml_json = value_xml_json\n        return sorted_values_xml_json, errors or None\n    return validate_values_xml_json_dates\ndef translate_xml_element_to_json_item(xml_element):\n    json_element = collections.OrderedDict()\n    text = xml_element.text\n    if text is not None:\n        text = text.strip().strip('#').strip() or None\n        if text is not None:\n            json_element['text'] = text\n    json_element.update(xml_element.attrib)\n    for xml_child in xml_element:\n        json_child_key, json_child = translate_xml_element_to_json_item(xml_child)\n        json_element.setdefault(json_child_key, []).append(json_child)\n    tail = xml_element.tail\n    if tail is not None:\n        tail = tail.strip().strip('#').strip() or None\n        if tail is not None:\n            json_element['tail'] = tail\n    return xml_element.tag, json_element\ndef transform_node_xml_json_to_json(node_xml_json, root = True):\n    comments = []\n    node_json = collections.OrderedDict()\n    if root:\n        node_json['@context'] = u'http://openfisca.fr/contexts/legislation.jsonld'\n    node_json['@type'] = 'Node'\n    child_json_by_code = {}\n    for key, value in node_xml_json.iteritems():\n        if key == 'BAREME':\n            for child_xml_json in value:\n                child_code, child_json = transform_scale_xml_json_to_json(child_xml_json)\n                child_json_by_code[child_code] = child_json\n        elif key == 'VALBYTRANCHES':\n            for child_xml_json in value:\n                child_code, child_json = transform_generation_xml_json_to_json(child_xml_json)\n                child_json_by_code[child_code] = child_json\n        elif key == 'CODE':\n            for child_xml_json in value:\n                child_code, child_json = transform_parameter_xml_json_to_json(child_xml_json)\n                child_json_by_code[child_code] = child_json\n        elif key == 'code':\n            pass\n        elif key == 'deb':\n            node_json['from'] = value\n        elif key == 'fin':\n            node_json['to'] = value\n        elif key == 'NODE':\n            for child_xml_json in value:\n                child_code, child_json = transform_node_xml_json_to_json(child_xml_json, root = False)\n                child_json_by_code[child_code] = child_json\n        elif key in ('tail', 'text'):\n            comments.append(value)\n        else:\n            node_json[key] = value\n    node_json['children'] = collections.OrderedDict(sorted(child_json_by_code.iteritems()))\n    if comments:\n        node_json['comment'] = u'\\n\\n'.join(comments)\n    return node_xml_json['code'], node_json\ndef transform_parameter_xml_json_to_json(parameter_xml_json):\n    comments = []\n    parameter_json = collections.OrderedDict()\n    parameter_json['@type'] = 'Parameter'\n    xml_json_value_to_json_transformer = float\n    for key, value in parameter_xml_json.iteritems():\n        if key in ('code', 'taille'):\n            pass\n        elif key == 'format':\n            parameter_json[key] = dict(\n                bool = u'boolean',\n                percent = u'rate',\n                date = u'date',\n                ).get(value, value)\n            if value == 'bool':\n                xml_json_value_to_json_transformer = lambda xml_json_value: bool(int(xml_json_value))\n            elif value == 'integer':\n                xml_json_value_to_json_transformer = int\n        elif key in ('tail', 'text'):\n            comments.append(value)\n        elif key == 'type':\n            parameter_json['unit'] = json_unit_by_xml_json_type.get(value, value)\n        elif key == 'VALUE':\n            if 'format' in parameter_xml_json:\n                if parameter_xml_json['format'] ==  'date':\n                    format = 'date'\n                elif parameter_xml_json['format'] ==  'integer':\n                    format = int\n                elif parameter_xml_json['format'] ==  'percent':\n                    format = float\n                else:\n                    format = eval(parameter_xml_json['format'])\n            else:\n                format = float\n            parameter_json['values'] = [ transform_value_xml_json_to_json(item, format)\n                for item in value\n                ]\n        else:\n            parameter_json[key] = value\n    if comments:\n        parameter_json['comment'] = u'\\n\\n'.join(comments)\n    return parameter_xml_json['code'], parameter_json\ndef transform_scale_xml_json_to_json(scale_xml_json):\n    comments = []\n    scale_json = collections.OrderedDict()\n    scale_json['@type'] = 'Scale'\n    for key, value in scale_xml_json.iteritems():\n        if key == 'code':\n            pass\n        elif key in ('tail', 'text'):\n            comments.append(value)\n        elif key == 'TRANCHE':\n            scale_json['slices'] = [\n                transform_slice_xml_json_to_json(item)\n                for item in value\n                ]\n        elif key == 'type':\n            scale_json['unit'] = json_unit_by_xml_json_type.get(value, value)\n        else:\n            scale_json[key] = value\n    if comments:\n        scale_json['comment'] = u'\\n\\n'.join(comments)\n    return scale_xml_json['code'], scale_json\ndef transform_generation_xml_json_to_json(generation_xml_json):\n    # Note: update with OF ?\n    comments = []\n    generation_json = collections.OrderedDict()\n    generation_json['@type'] = 'Generation'\n    for key, value in generation_xml_json.iteritems():\n        if key == 'code':\n            pass\n        elif key in ('tail', 'text'):\n            comments.append(value)\n        elif key == 'VARCONTROL':\n            generation_json['control'] = [\n                transform_value_xml_json_to_json(item, str)\n                for item in value[0]['CONTROL']\n                ]\n        elif key == 'TRANCHE':\n            generation_json['slices'] = [\n                transform_slice2_xml_json_to_json(item)\n                for item in value\n                ]\n        elif key == 'type':\n            generation_json['unit'] = json_unit_by_xml_json_type.get(value, value)\n        else:\n            generation_json[key] = value\n    if comments:\n        generation_json['comment'] = u'\\n\\n'.join(comments)\n    return generation_xml_json['code'], generation_json\ndef transform_slice2_xml_json_to_json(slice_xml_json):\n    comments = []\n    slice_json = collections.OrderedDict()\n    for key, value in slice_xml_json.iteritems():\n        if key == 'code':\n            pass\n        elif key == 'SEUIL':\n            slice_json['threshold'] = transform_values_holder_xml_json_to_json(value[0], format ='date')\n        elif key in ('tail', 'text'):\n            comments.append(value)\n        elif key == 'VALEUR':\n            slice_json['valeur'] = transform_values_holder_xml_json_to_json(value[0])\n        else:\n            slice_json[key] = value\n    if comments:\n        slice_json['comment'] = u'\\n\\n'.join(comments)\n    return slice_json\ndef transform_slice_xml_json_to_json(slice_xml_json):\n    comments = []\n    slice_json = collections.OrderedDict()\n    for key, value in slice_xml_json.iteritems():\n        if key == 'ASSIETTE':\n            slice_json['base'] = transform_values_holder_xml_json_to_json(value[0])\n        elif key == 'code':\n            pass\n        elif key == 'SEUIL':\n            slice_json['threshold'] = transform_values_holder_xml_json_to_json(value[0])\n        elif key in ('tail', 'text'):\n            comments.append(value)\n", "outputs": ["        elif key == 'TAUX':"], "input_length": 1735, "output_length": 6, "length": 1741, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "d54a89f96eef1ab6f3c7bcffb4bf6bfe48b5a9558eb6452cc207d0ce4b5c49b6"}
{"input": "", "context": "/*\n * To change this template, choose Tools | Templates\n * and open the template in the editor.\n */\npackage NetSpace;\nimport NetSpace.weapons.WeaponsEnum;\nimport NetSpace.weapons.Weapon;\nimport NetSpace.weapons.WeaponType;\nimport NetSpace.aliens.Enemy;\nimport NetSpace.aliens.EnemyRepresentation;\nimport NetSpace.update.UpdatePatch;\nimport java.io.IOException;\nimport java.io.ObjectInputStream;\nimport java.io.ObjectOutputStream;\nimport java.net.Socket;\nimport java.util.ArrayList;\nimport java.util.Collections;\nimport java.util.HashMap;\nimport java.util.List;\nimport org.newdawn.slick.AppGameContainer;\nimport org.newdawn.slick.BasicGame;\nimport org.newdawn.slick.GameContainer;\nimport org.newdawn.slick.Graphics;\nimport org.newdawn.slick.SlickException;\nimport org.newdawn.slick.Image;\nimport org.newdawn.slick.tiled.*;\nimport org.newdawn.slick.geom.*;\nimport org.newdawn.slick.Animation;\nimport org.newdawn.slick.Input;\n/**\n *\n * @author Aidan Malone\n */\npublic class game extends BasicGame {\n    //Single-player constructor\n    public game()\n    {\n        super(\"game\");\n    }\n    \n    //Multi-player constructor\n    public game(ObjectOutputStream out, ObjectInputStream in, String user)\n    {   \n        super(\"game\");\n        \n        try {\n            Username = user;                \n            Soutput = out;            \n            Sinput = in;\n            \n        } catch (Exception ex) {\n            ex.printStackTrace();\n        }           \n    }\n    //This is the width and height of your game window\n    final static int viewW = 1024, viewH = 690;\n    //Image [] shipSprites;\n    //Animation ship;\n    float theta = 0f;\n    TiledMap StarMap;\n    int mapw, maph;\n    int spritew = 100, spriteh = 100;\n    float Shipx = viewW/2-spritew/2, Shipy = viewH/2-spriteh/2;\n    \n    final int phaseShift = 90;\n    final int speed = 5;\n    float destx = Shipx + spritew/2, desty = Shipy + spriteh/2;\n    float viewx = 0, viewy = 0;   \n    HUD display;\n    //This contains all of the methods for actually controlling the ship's motion\n    Player myPlayer;\n    \n    //This contains the data for all of the players currently registered with\n    //  the server, including yours\n    ArrayList <PlayerInfo> players = new ArrayList<PlayerInfo>();\n    Rectangle camera;\n    WeaponType[] myWeapons;\n    WeaponType auto;\n    \n    //Socket serv;    \n    ObjectInputStream Sinput;\n    ObjectOutputStream Soutput;  \n    \n    final int MAXMSGS = 6;\n    ArrayList <String>Messages = new ArrayList<String>(MAXMSGS);       \n    ArrayList <EnemyRepresentation> ennemies = new ArrayList<EnemyRepresentation>();\n    ArrayList <Weapon> ActiveWeapons = new ArrayList<Weapon>();\n    \n    String Username;\n    float[][] todraw;\n    \n    InputThread inputReader;\n    \n    SpriteBank spriteBank; \n    \n    \n    public static void create()        \n    {\n        try\n        {\n            AppGameContainer app = new AppGameContainer(new game());\n            app.setDisplayMode(viewW, viewH, false);\n            app.setVSync(true);\n            app.start();\n        }\n        catch (SlickException e)\n        {\n            e.printStackTrace();\n        }\n    }\n    \n    public static void createNetGame(ObjectOutputStream out, ObjectInputStream in, String user)\n    { \n        try\n        {            \n            AppGameContainer app = new AppGameContainer(new game(out, in, user));\n            app.setDisplayMode(viewW, viewH, false);\n            app.setVSync(true);             \n            app.start();\n            \n        }\n        catch (SlickException e)\n        {\n            e.printStackTrace();\n        }\n    }    \n    @Override\n    public void init(GameContainer container) throws SlickException\n    {\n        //Load all map variables\n        StarMap = new TiledMap(\"data/StarMap.tmx\");\n        mapw = StarMap.getWidth()*StarMap.getTileWidth();\n        maph = StarMap.getHeight()*StarMap.getTileHeight();\n        //Load the HUD\n        display = new HUD(viewW, viewH);\n        \n        //Initialize the sprites\n        spriteBank = new SpriteBank();\n        myPlayer = new Player(Username,50,50);        \n        \n//        for(int i = 0; i<bots.size(); i++){\n//            ennemies.add(new Enemy((int)(Math.random()*mapw),(int)(Math.random()*maph)));\n//        }\n        camera = new Rectangle(viewx,viewy,viewW,viewH);\n        //Sets which Weapons the player is using\n        myWeapons = new WeaponType[4];\n        myWeapons[0] = new WeaponType(WeaponsEnum.PULSE);\n        myWeapons[1] = new WeaponType(WeaponsEnum.BLAST);\n        myWeapons[2] = new WeaponType(WeaponsEnum.BLAST);\n        myWeapons[3] = new WeaponType(WeaponsEnum.MINE);\n        auto = new WeaponType(WeaponsEnum.LASER);\n        display.loadWeapons(myWeapons);\n        \n        inputReader = new InputThread ();\n        inputReader.start();                \n    }\n    @Override\n    public void update(GameContainer container, int delta) throws SlickException\n    {\n        \n        \n        Input input = container.getInput();\n        float x = input.getMouseX();\n        float y = input.getMouseY();\n        //Checks for the left mouse button.\n        if (input.isMouseButtonDown(0))\n        {            \n             if (display.minimap.contains(x, y)) {\n                myPlayer.newDestination((int)display.getMapX(x, mapw),(int)display.getMapY(y, maph));\n            }\n            else\n            {\n                myPlayer.newDestination((int)(x + viewx),(int)(y + viewy));\n            }\n        }\n        //Checks for key input\n        /*\n        if (inputReader.isKeyDown(Input.KEY_Q))\n        {  \n            //Deals with Player targetting\n            int target = -1;\n            for(int i = 0; i<bots.size(); i++)\n            {\n                if((ennemies.get(i)).isAlive()){\n                    if(ennemies.get(i).hitbox.contains(x + viewx, y + viewy)){\n                        target = i;\n                        break;\n                    }\n                }\n            }\n            player.target = target;\n        }\n        */\n        //Debugging button\n        if (input.isKeyDown(Input.KEY_A))\n        {\n            //System.out.println(ennemies.get(0).ID);            \n            for (int i = 0; i<ennemies.size(); i++){\n                System.out.println(\"Bot #\" + i + \" x: \" + ennemies.get(i).x);\n            }\n        }\n        \n        \n        if (input.isKeyDown(Input.KEY_1))\n        {  \n            if(myWeapons[0].offCD()){\n                Weapon a = myPlayer.fireWeapon((int)(x + viewx),(int)(y+ viewy), myWeapons[0]);\n                a.init(0, Username);\n                ActiveWeapons.add(a); \n                send(a);\n            }            \n        }\n        if (input.isKeyDown(Input.KEY_2))\n        {\n            if(myWeapons[1].offCD()){\n                Weapon a = myPlayer.fireWeapon((int)(x + viewx),(int)(y+ viewy), myWeapons[1]);\n                a.init(1, Username);\n                ActiveWeapons.add(a);\n                send(a);\n            }\n        }\n        if (input.isKeyDown(Input.KEY_3))\n        {\n            if(myWeapons[2].offCD()){\n                Weapon a = myPlayer.fireWeapon((int)(x + viewx),(int)(y+ viewy), myWeapons[2]);\n                a.init(2, Username);\n                ActiveWeapons.add(a); \n                send(a);\n            }\n        }\n        if (input.isKeyDown(Input.KEY_4))\n        {\n            \n            if(myWeapons[3].offCD()){\n                Weapon a = myPlayer.fireWeapon((int)(x + viewx),(int)(y+ viewy), myWeapons[3]);\n                a.init(3, Username);                \n                ActiveWeapons.add(a);\n                send(a);\n            }\n        }\n        //Updates the player\n        myPlayer.update(delta,mapw,maph);\n        \n        //Updates the player's location on the server\n        send(myPlayer.getUpdate());\n        \n        //Updates the other player's animations and ship positions\n        for(int i = 0; i < players.size(); i++){\n            PlayerInfo player2 = players.get(i);            \n            player2.Ship.update(delta);\n            player2.moveShip(delta);\n        }\n        \n        for(int i = 0; i < ennemies.size(); i++){\n            ennemies.get(i).move(delta);\n        }       \n        //updates Weapon cooldowns\n", "outputs": ["        for(int i = 0; i< myWeapons.length; i++) {"], "input_length": 1372, "output_length": 14, "length": 1386, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "309b8b7ab88f6aa7e9dad371bf13c0789e61ca3978afda8c190a9c256ddad557"}
{"input": "", "context": "#region Copyright & License Information\n/*\n * Copyright 2007-2017 The OpenRA Developers (see AUTHORS)\n * This file is part of OpenRA, which is free software. It is made\n * available to you under the terms of the GNU General Public License\n * as published by the Free Software Foundation, either version 3 of\n * the License, or (at your option) any later version. For more\n * information, see COPYING.\n */\n#endregion\nusing System;\nusing System.Collections.Generic;\nusing System.Drawing;\nusing System.Linq;\nusing System.Threading.Tasks;\nusing OpenRA.Chat;\nusing OpenRA.Graphics;\nusing OpenRA.Mods.Common.Traits;\nusing OpenRA.Network;\nusing OpenRA.Traits;\nusing OpenRA.Widgets;\nnamespace OpenRA.Mods.Common.Widgets.Logic\n{\n\tpublic class LobbyLogic : ChromeLogic\n\t{\n\t\tstatic readonly Action DoNothing = () => { };\n\t\tpublic MapPreview Map { get; private set; }\n\t\treadonly ModData modData;\n\t\treadonly Action onStart;\n\t\treadonly Action onExit;\n\t\treadonly OrderManager orderManager;\n\t\treadonly bool skirmishMode;\n\t\treadonly Ruleset modRules;\n\t\treadonly World shellmapWorld;\n\t\treadonly WebServices services;\n\t\tenum PanelType { Players, Options, Music, Kick, ForceStart }\n\t\tPanelType panel = PanelType.Players;\n\t\tenum ChatPanelType { Lobby, Global }\n\t\tChatPanelType chatPanel = ChatPanelType.Lobby;\n\t\treadonly Widget lobby;\n\t\treadonly Widget editablePlayerTemplate;\n\t\treadonly Widget nonEditablePlayerTemplate;\n\t\treadonly Widget emptySlotTemplate;\n\t\treadonly Widget editableSpectatorTemplate;\n\t\treadonly Widget nonEditableSpectatorTemplate;\n\t\treadonly Widget newSpectatorTemplate;\n\t\treadonly ScrollPanelWidget lobbyChatPanel;\n\t\treadonly Widget chatTemplate;\n\t\treadonly ScrollPanelWidget players;\n\t\treadonly Dictionary<string, LobbyFaction> factions = new Dictionary<string, LobbyFaction>();\n\t\treadonly ColorPreviewManagerWidget colorPreview;\n\t\treadonly TabCompletionLogic tabCompletion = new TabCompletionLogic();\n\t\treadonly LabelWidget chatLabel;\n\t\tbool teamChat;\n\t\tbool addBotOnMapLoad;\n\t\tint lobbyChatUnreadMessages;\n\t\tint globalChatLastReadMessages;\n\t\tint globalChatUnreadMessages;\n\t\t// Listen for connection failures\n\t\tvoid ConnectionStateChanged(OrderManager om)\n\t\t{\n\t\t\tif (om.Connection.ConnectionState == ConnectionState.NotConnected)\n\t\t\t{\n\t\t\t\t// Show connection failed dialog\n\t\t\t\tUi.CloseWindow();\n\t\t\t\tAction onConnect = () =>\n\t\t\t\t{\n\t\t\t\t\tGame.OpenWindow(\"SERVER_LOBBY\", new WidgetArgs()\n\t\t\t\t\t{\n\t\t\t\t\t\t{ \"onExit\", onExit },\n\t\t\t\t\t\t{ \"onStart\", onStart },\n\t\t\t\t\t\t{ \"skirmishMode\", false }\n\t\t\t\t\t});\n\t\t\t\t};\n\t\t\t\tAction<string> onRetry = password => ConnectionLogic.Connect(om.Host, om.Port, password, onConnect, onExit);\n\t\t\t\tvar switchPanel = om.ServerExternalMod != null ? \"CONNECTION_SWITCHMOD_PANEL\" : \"CONNECTIONFAILED_PANEL\";\n\t\t\t\tUi.OpenWindow(switchPanel, new WidgetArgs()\n\t\t\t\t{\n\t\t\t\t\t{ \"orderManager\", om },\n\t\t\t\t\t{ \"onAbort\", onExit },\n\t\t\t\t\t{ \"onRetry\", onRetry }\n\t\t\t\t});\n\t\t\t}\n\t\t}\n\t\t[ObjectCreator.UseCtor]\n\t\tinternal LobbyLogic(Widget widget, ModData modData, WorldRenderer worldRenderer, OrderManager orderManager,\n\t\t\tAction onExit, Action onStart, bool skirmishMode)\n\t\t{\n\t\t\tMap = MapCache.UnknownMap;\n\t\t\tlobby = widget;\n\t\t\tthis.modData = modData;\n\t\t\tthis.orderManager = orderManager;\n\t\t\tthis.onStart = onStart;\n\t\t\tthis.onExit = onExit;\n\t\t\tthis.skirmishMode = skirmishMode;\n\t\t\t// TODO: This needs to be reworked to support per-map tech levels, bots, etc.\n\t\t\tthis.modRules = modData.DefaultRules;\n\t\t\tshellmapWorld = worldRenderer.World;\n\t\t\tservices = modData.Manifest.Get<WebServices>();\n\t\t\torderManager.AddChatLine += AddChatLine;\n\t\t\tGame.LobbyInfoChanged += UpdateCurrentMap;\n\t\t\tGame.LobbyInfoChanged += UpdatePlayerList;\n\t\t\tGame.BeforeGameStart += OnGameStart;\n\t\t\tGame.ConnectionStateChanged += ConnectionStateChanged;\n\t\t\tvar name = lobby.GetOrNull<LabelWidget>(\"SERVER_NAME\");\n\t\t\tif (name != null)\n\t\t\t\tname.GetText = () => orderManager.LobbyInfo.GlobalSettings.ServerName;\n\t\t\tUi.LoadWidget(\"LOBBY_MAP_PREVIEW\", lobby.Get(\"MAP_PREVIEW_ROOT\"), new WidgetArgs\n\t\t\t{\n\t\t\t\t{ \"orderManager\", orderManager },\n\t\t\t\t{ \"lobby\", this }\n\t\t\t});\n\t\t\tUpdateCurrentMap();\n\t\t\tvar playerBin = Ui.LoadWidget(\"LOBBY_PLAYER_BIN\", lobby.Get(\"TOP_PANELS_ROOT\"), new WidgetArgs());\n\t\t\tplayerBin.IsVisible = () => panel == PanelType.Players;\n\t\t\tplayers = playerBin.Get<ScrollPanelWidget>(\"LOBBY_PLAYERS\");\n\t\t\teditablePlayerTemplate = players.Get(\"TEMPLATE_EDITABLE_PLAYER\");\n\t\t\tnonEditablePlayerTemplate = players.Get(\"TEMPLATE_NONEDITABLE_PLAYER\");\n\t\t\temptySlotTemplate = players.Get(\"TEMPLATE_EMPTY\");\n\t\t\teditableSpectatorTemplate = players.Get(\"TEMPLATE_EDITABLE_SPECTATOR\");\n\t\t\tnonEditableSpectatorTemplate = players.Get(\"TEMPLATE_NONEDITABLE_SPECTATOR\");\n\t\t\tnewSpectatorTemplate = players.Get(\"TEMPLATE_NEW_SPECTATOR\");\n\t\t\tcolorPreview = lobby.Get<ColorPreviewManagerWidget>(\"COLOR_MANAGER\");\n\t\t\tcolorPreview.Color = Game.Settings.Player.Color;\n\t\t\tforeach (var f in modRules.Actors[\"world\"].TraitInfos<FactionInfo>())\n\t\t\t\tfactions.Add(f.InternalName, new LobbyFaction { Selectable = f.Selectable, Name = f.Name, Side = f.Side, Description = f.Description });\n\t\t\tvar gameStarting = false;\n\t\t\tFunc<bool> configurationDisabled = () => !Game.IsHost || gameStarting ||\n\t\t\t\tpanel == PanelType.Kick || panel == PanelType.ForceStart ||\n\t\t\t\t!Map.RulesLoaded || Map.InvalidCustomRules ||\n\t\t\t\torderManager.LocalClient == null || orderManager.LocalClient.IsReady;\n\t\t\tvar mapButton = lobby.GetOrNull<ButtonWidget>(\"CHANGEMAP_BUTTON\");\n\t\t\tif (mapButton != null)\n\t\t\t{\n\t\t\t\tmapButton.IsDisabled = () => gameStarting || panel == PanelType.Kick || panel == PanelType.ForceStart ||\n\t\t\t\t\torderManager.LocalClient == null || orderManager.LocalClient.IsReady;\n\t\t\t\tmapButton.OnClick = () =>\n\t\t\t\t{\n\t\t\t\t\tvar onSelect = new Action<string>(uid =>\n\t\t\t\t\t{\n\t\t\t\t\t\t// Don't select the same map again\n\t\t\t\t\t\tif (uid == Map.Uid)\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\torderManager.IssueOrder(Order.Command(\"map \" + uid));\n\t\t\t\t\t\tGame.Settings.Server.Map = uid;\n\t\t\t\t\t\tGame.Settings.Save();\n\t\t\t\t\t});\n\t\t\t\t\tUi.OpenWindow(\"MAPCHOOSER_PANEL\", new WidgetArgs()\n\t\t\t\t\t{\n\t\t\t\t\t\t{ \"initialMap\", Map.Uid },\n\t\t\t\t\t\t{ \"initialTab\", MapClassification.System },\n\t\t\t\t\t\t{ \"onExit\", DoNothing },\n\t\t\t\t\t\t{ \"onSelect\", Game.IsHost ? onSelect : null },\n\t\t\t\t\t\t{ \"filter\", MapVisibility.Lobby },\n\t\t\t\t\t});\n\t\t\t\t};\n\t\t\t}\n\t\t\tvar slotsButton = lobby.GetOrNull<DropDownButtonWidget>(\"SLOTS_DROPDOWNBUTTON\");\n\t\t\tif (slotsButton != null)\n\t\t\t{\n\t\t\t\tslotsButton.IsDisabled = () => configurationDisabled() || panel != PanelType.Players ||\n\t\t\t\t\t(orderManager.LobbyInfo.Slots.Values.All(s => !s.AllowBots) &&\n\t\t\t\t\torderManager.LobbyInfo.Slots.Count(s => !s.Value.LockTeam && orderManager.LobbyInfo.ClientInSlot(s.Key) != null) == 0);\n\t\t\t\tslotsButton.OnMouseDown = _ =>\n\t\t\t\t{\n\t\t\t\t\tvar botNames = Map.Rules.Actors[\"player\"].TraitInfos<IBotInfo>().Select(t => t.Name);\n\t\t\t\t\tvar options = new Dictionary<string, IEnumerable<DropDownOption>>();\n\t\t\t\t\tvar botController = orderManager.LobbyInfo.Clients.FirstOrDefault(c => c.IsAdmin);\n\t\t\t\t\tif (orderManager.LobbyInfo.Slots.Values.Any(s => s.AllowBots))\n\t\t\t\t\t{\n\t\t\t\t\t\tvar botOptions = new List<DropDownOption>()\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tnew DropDownOption()\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tTitle = \"Add\",\n\t\t\t\t\t\t\t\tIsSelected = () => false,\n\t\t\t\t\t\t\t\tOnClick = () =>\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\tforeach (var slot in orderManager.LobbyInfo.Slots)\n\t\t\t\t\t\t\t\t\t{\n", "outputs": ["\t\t\t\t\t\t\t\t\t\tvar bot = botNames.Random(Game.CosmeticRandom);"], "input_length": 1169, "output_length": 8, "length": 1177, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "05b1d74b0eb96ff81dca3d318f41ced768150ff86652b338e5c42c1afbfd57c3"}
{"input": "", "context": "/*\n * Copyright (C) 2012 The CyanogenMod Project\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage com.android.internal.telephony;\nimport static com.android.internal.telephony.RILConstants.*;\nimport android.content.Context;\nimport android.os.AsyncResult;\nimport android.os.Message;\nimport android.os.Parcel;\nimport android.os.SystemProperties;\nimport android.util.Log;\nimport com.android.internal.telephony.RILConstants;\nimport java.util.Collections;\nimport android.telephony.PhoneNumberUtils;\nimport java.util.ArrayList;\n/**\n * Custom RIL to handle unique behavior of D2 radio\n *\n * {@hide}\n */\npublic class SamsungBCMRIL extends RIL implements CommandsInterface {\n    public SamsungBCMRIL(Context context, int networkMode, int cdmaSubscription) {\n        super(context, networkMode, cdmaSubscription);\n        mQANElements = 5;\n    }\n    public void\n    dial(String address, int clirMode, UUSInfo uusInfo, Message result) {\n        RILRequest rr = RILRequest.obtain(RIL_REQUEST_DIAL, result);\n        rr.mp.writeString(address);\n        rr.mp.writeInt(clirMode);\n        rr.mp.writeInt(0); // UUS information is absent: Samsung BCM compat\n        if (uusInfo == null) {\n            rr.mp.writeInt(0); // UUS information is absent\n        } else {\n            rr.mp.writeInt(1); // UUS information is present\n            rr.mp.writeInt(uusInfo.getType());\n            rr.mp.writeInt(uusInfo.getDcs());\n            rr.mp.writeByteArray(uusInfo.getUserData());\n        }\n        if (RILJ_LOGD) riljLog(rr.serialString() + \"> \" + requestToString(rr.mRequest));\n        send(rr);\n    }\n    protected void\n    processSolicited (Parcel p) {\n        int serial, error;\n        boolean found = false;\n        serial = p.readInt();\n        error = p.readInt();\n        RILRequest rr;\n        rr = findAndRemoveRequestFromList(serial);\n        if (rr == null) {\n            Log.w(LOG_TAG, \"Unexpected solicited response! sn: \"\n                            + serial + \" error: \" + error);\n            return;\n        }\n        Object ret = null;\n        if (error == 0 || p.dataAvail() > 0) {\n            // either command succeeds or command fails but with data payload\n            try {switch (rr.mRequest) {\n            /*\n cat libs/telephony/ril_commands.h \\\n | egrep \"^ *{RIL_\" \\\n | sed -re 's/\\{([^,]+),[^,]+,([^}]+).+/case \\1: ret = \\2(p); break;/'\n             */\n            case RIL_REQUEST_GET_SIM_STATUS: ret =  responseIccCardStatus(p); break;\n            case RIL_REQUEST_ENTER_SIM_PIN: ret =  responseInts(p); break;\n            case RIL_REQUEST_ENTER_SIM_PUK: ret =  responseInts(p); break;\n            case RIL_REQUEST_ENTER_SIM_PIN2: ret =  responseInts(p); break;\n            case RIL_REQUEST_ENTER_SIM_PUK2: ret =  responseInts(p); break;\n            case RIL_REQUEST_CHANGE_SIM_PIN: ret =  responseInts(p); break;\n            case RIL_REQUEST_CHANGE_SIM_PIN2: ret =  responseInts(p); break;\n            case RIL_REQUEST_ENTER_NETWORK_DEPERSONALIZATION: ret =  responseInts(p); break;\n            case RIL_REQUEST_GET_CURRENT_CALLS: ret =  responseCallList(p); break;\n            case RIL_REQUEST_DIAL: ret =  responseVoid(p); break;\n            case RIL_REQUEST_GET_IMSI: ret =  responseString(p); break;\n            case RIL_REQUEST_HANGUP: ret =  responseVoid(p); break;\n            case RIL_REQUEST_HANGUP_WAITING_OR_BACKGROUND: ret =  responseVoid(p); break;\n            case RIL_REQUEST_HANGUP_FOREGROUND_RESUME_BACKGROUND: {\n                if (mTestingEmergencyCall.getAndSet(false)) {\n                    if (mEmergencyCallbackModeRegistrant != null) {\n                        riljLog(\"testing emergency call, notify ECM Registrants\");\n                        mEmergencyCallbackModeRegistrant.notifyRegistrant();\n                    }\n                }\n                ret =  responseVoid(p);\n                break;\n            }\n            case RIL_REQUEST_SWITCH_WAITING_OR_HOLDING_AND_ACTIVE: ret =  responseVoid(p); break;\n            case RIL_REQUEST_CONFERENCE: ret =  responseVoid(p); break;\n            case RIL_REQUEST_UDUB: ret =  responseVoid(p); break;\n            case RIL_REQUEST_LAST_CALL_FAIL_CAUSE: ret =  responseInts(p); break;\n            case RIL_REQUEST_SIGNAL_STRENGTH: ret =  responseSignalStrength(p); break;\n            case RIL_REQUEST_VOICE_REGISTRATION_STATE: ret =  responseStrings(p); break;\n            case RIL_REQUEST_DATA_REGISTRATION_STATE: ret =  responseStrings(p); break;\n            case RIL_REQUEST_OPERATOR: ret =  responseStrings(p); break;\n            case RIL_REQUEST_RADIO_POWER: ret =  responseVoid(p); break;\n            case RIL_REQUEST_DTMF: ret =  responseVoid(p); break;\n            case RIL_REQUEST_SEND_SMS: ret =  responseSMS(p); break;\n            case RIL_REQUEST_SEND_SMS_EXPECT_MORE: ret =  responseSMS(p); break;\n            case RIL_REQUEST_SETUP_DATA_CALL: ret =  responseSetupDataCall(p); break;\n            case RIL_REQUEST_SIM_IO: ret =  responseICC_IO(p); break;\n            case RIL_REQUEST_SEND_USSD: ret =  responseVoid(p); break;\n            case RIL_REQUEST_CANCEL_USSD: ret =  responseVoid(p); break;\n            case RIL_REQUEST_GET_CLIR: ret =  responseInts(p); break;\n            case RIL_REQUEST_SET_CLIR: ret =  responseVoid(p); break;\n            case RIL_REQUEST_QUERY_CALL_FORWARD_STATUS: ret =  responseCallForward(p); break;\n            case RIL_REQUEST_SET_CALL_FORWARD: ret =  responseVoid(p); break;\n            case RIL_REQUEST_QUERY_CALL_WAITING: ret =  responseInts(p); break;\n            case RIL_REQUEST_SET_CALL_WAITING: ret =  responseVoid(p); break;\n            case RIL_REQUEST_SMS_ACKNOWLEDGE: ret =  responseVoid(p); break;\n            case RIL_REQUEST_GET_IMEI: ret =  responseString(p); break;\n            case RIL_REQUEST_GET_IMEISV: ret =  responseString(p); break;\n            case RIL_REQUEST_ANSWER: ret =  responseVoid(p); break;\n            case RIL_REQUEST_DEACTIVATE_DATA_CALL: ret =  responseVoid(p); break;\n            case RIL_REQUEST_QUERY_FACILITY_LOCK: ret =  responseInts(p); break;\n            case RIL_REQUEST_SET_FACILITY_LOCK: ret =  responseInts(p); break;\n            case RIL_REQUEST_CHANGE_BARRING_PASSWORD: ret =  responseVoid(p); break;\n            case RIL_REQUEST_QUERY_NETWORK_SELECTION_MODE: ret =  responseInts(p); break;\n            case RIL_REQUEST_SET_NETWORK_SELECTION_AUTOMATIC: ret =  responseVoid(p); break;\n            case RIL_REQUEST_SET_NETWORK_SELECTION_MANUAL: ret =  responseVoid(p); break;\n            case RIL_REQUEST_QUERY_AVAILABLE_NETWORKS : ret =  responseOperatorInfos(p); break;\n            case RIL_REQUEST_DTMF_START: ret =  responseVoid(p); break;\n            case RIL_REQUEST_DTMF_STOP: ret =  responseVoid(p); break;\n            case RIL_REQUEST_BASEBAND_VERSION: ret =  responseString(p); break;\n            case RIL_REQUEST_SEPARATE_CONNECTION: ret =  responseVoid(p); break;\n            case RIL_REQUEST_SET_MUTE: ret =  responseVoid(p); break;\n            case RIL_REQUEST_GET_MUTE: ret =  responseInts(p); break;\n            case RIL_REQUEST_QUERY_CLIP: ret =  responseInts(p); break;\n            case RIL_REQUEST_LAST_DATA_CALL_FAIL_CAUSE: ret =  responseInts(p); break;\n            case RIL_REQUEST_DATA_CALL_LIST: ret =  responseDataCallList(p); break;\n            case RIL_REQUEST_RESET_RADIO: ret =  responseVoid(p); break;\n            case RIL_REQUEST_OEM_HOOK_RAW: ret =  responseRaw(p); break;\n            case RIL_REQUEST_OEM_HOOK_STRINGS: ret =  responseStrings(p); break;\n            case RIL_REQUEST_SCREEN_STATE: ret =  responseVoid(p); break;\n            case RIL_REQUEST_SET_SUPP_SVC_NOTIFICATION: ret =  responseVoid(p); break;\n            case RIL_REQUEST_WRITE_SMS_TO_SIM: ret =  responseInts(p); break;\n            case RIL_REQUEST_DELETE_SMS_ON_SIM: ret =  responseVoid(p); break;\n            case RIL_REQUEST_SET_BAND_MODE: ret =  responseVoid(p); break;\n            case RIL_REQUEST_QUERY_AVAILABLE_BAND_MODE: ret =  responseInts(p); break;\n            case RIL_REQUEST_STK_GET_PROFILE: ret =  responseString(p); break;\n            case RIL_REQUEST_STK_SET_PROFILE: ret =  responseVoid(p); break;\n            case RIL_REQUEST_STK_SEND_ENVELOPE_COMMAND: ret =  responseString(p); break;\n            case RIL_REQUEST_STK_SEND_TERMINAL_RESPONSE: ret =  responseVoid(p); break;\n            case RIL_REQUEST_STK_HANDLE_CALL_SETUP_REQUESTED_FROM_SIM: ret =  responseInts(p); break;\n            case RIL_REQUEST_EXPLICIT_CALL_TRANSFER: ret =  responseVoid(p); break;\n            case RIL_REQUEST_SET_PREFERRED_NETWORK_TYPE: ret =  responseVoid(p); break;\n            case RIL_REQUEST_GET_PREFERRED_NETWORK_TYPE: ret =  responseGetPreferredNetworkType(p); break;\n            case RIL_REQUEST_GET_NEIGHBORING_CELL_IDS: ret = responseCellList(p); break;\n            case RIL_REQUEST_SET_LOCATION_UPDATES: ret =  responseVoid(p); break;\n            case RIL_REQUEST_CDMA_SET_SUBSCRIPTION_SOURCE: ret =  responseVoid(p); break;\n            case RIL_REQUEST_CDMA_SET_ROAMING_PREFERENCE: ret =  responseVoid(p); break;\n            case RIL_REQUEST_CDMA_QUERY_ROAMING_PREFERENCE: ret =  responseInts(p); break;\n            case RIL_REQUEST_SET_TTY_MODE: ret =  responseVoid(p); break;\n            case RIL_REQUEST_QUERY_TTY_MODE: ret =  responseInts(p); break;\n            case RIL_REQUEST_CDMA_SET_PREFERRED_VOICE_PRIVACY_MODE: ret =  responseVoid(p); break;\n            case RIL_REQUEST_CDMA_QUERY_PREFERRED_VOICE_PRIVACY_MODE: ret =  responseInts(p); break;\n            case RIL_REQUEST_CDMA_FLASH: ret =  responseVoid(p); break;\n            case RIL_REQUEST_CDMA_BURST_DTMF: ret =  responseVoid(p); break;\n            case RIL_REQUEST_CDMA_SEND_SMS: ret =  responseSMS(p); break;\n            case RIL_REQUEST_CDMA_SMS_ACKNOWLEDGE: ret =  responseVoid(p); break;\n            case RIL_REQUEST_GSM_GET_BROADCAST_CONFIG: ret =  responseGmsBroadcastConfig(p); break;\n            case RIL_REQUEST_GSM_SET_BROADCAST_CONFIG: ret =  responseVoid(p); break;\n            case RIL_REQUEST_GSM_BROADCAST_ACTIVATION: ret =  responseVoid(p); break;\n            case RIL_REQUEST_CDMA_GET_BROADCAST_CONFIG: ret =  responseCdmaBroadcastConfig(p); break;\n            case RIL_REQUEST_CDMA_SET_BROADCAST_CONFIG: ret =  responseVoid(p); break;\n            case RIL_REQUEST_CDMA_BROADCAST_ACTIVATION: ret =  responseVoid(p); break;\n            case RIL_REQUEST_CDMA_VALIDATE_AND_WRITE_AKEY: ret =  responseVoid(p); break;\n            case RIL_REQUEST_CDMA_SUBSCRIPTION: ret =  responseStrings(p); break;\n            case RIL_REQUEST_CDMA_WRITE_SMS_TO_RUIM: ret =  responseInts(p); break;\n            case RIL_REQUEST_CDMA_DELETE_SMS_ON_RUIM: ret =  responseVoid(p); break;\n            case RIL_REQUEST_DEVICE_IDENTITY: ret =  responseStrings(p); break;\n            case RIL_REQUEST_GET_SMSC_ADDRESS: ret = responseString(p); break;\n            case RIL_REQUEST_SET_SMSC_ADDRESS: ret = responseVoid(p); break;\n            case RIL_REQUEST_EXIT_EMERGENCY_CALLBACK_MODE: ret = responseVoid(p); break;\n            case RIL_REQUEST_REPORT_SMS_MEMORY_STATUS: ret = responseVoid(p); break;\n            case RIL_REQUEST_REPORT_STK_SERVICE_IS_RUNNING: ret = responseVoid(p); break;\n            case RIL_REQUEST_CDMA_GET_SUBSCRIPTION_SOURCE: ret =  responseInts(p); break;\n            case RIL_REQUEST_ISIM_AUTHENTICATION: ret =  responseString(p); break;\n            case RIL_REQUEST_ACKNOWLEDGE_INCOMING_GSM_SMS_WITH_PDU: ret = responseVoid(p); break;\n            case RIL_REQUEST_STK_SEND_ENVELOPE_WITH_STATUS: ret = responseICC_IO(p); break;\n            case RIL_REQUEST_VOICE_RADIO_TECH: ret = responseInts(p); break;\n            default:\n                throw new RuntimeException(\"Unrecognized solicited response: \" + rr.mRequest);\n            //break;\n            }} catch (Throwable tr) {\n                // Exceptions here usually mean invalid RIL responses\n                Log.w(LOG_TAG, rr.serialString() + \"< \"\n                        + requestToString(rr.mRequest)\n                        + \" exception, possible invalid RIL response\", tr);\n                if (rr.mResult != null) {\n                    AsyncResult.forMessage(rr.mResult, null, tr);\n                    rr.mResult.sendToTarget();\n                }\n                rr.release();\n                return;\n            }\n        }\n        // Here and below fake RIL_UNSOL_RESPONSE_SIM_STATUS_CHANGED, see b/7255789.\n        // This is needed otherwise we don't automatically transition to the main lock\n        // screen when the pin or puk is entered incorrectly.\n        // Note for the I9082: we're faking more than the standard RIL\n        switch (rr.mRequest) {\n            case RIL_REQUEST_ENTER_SIM_PUK:\n            case RIL_REQUEST_ENTER_SIM_PUK2:\n            case RIL_REQUEST_ENTER_SIM_PIN:\n            case RIL_REQUEST_ENTER_SIM_PIN2:\n            case RIL_REQUEST_CHANGE_SIM_PIN:\n            case RIL_REQUEST_CHANGE_SIM_PIN2:\n            case RIL_REQUEST_SET_FACILITY_LOCK:\n                if (mIccStatusChangedRegistrants != null) {\n                    if (RILJ_LOGD) {\n                        riljLog(\"ON enter sim puk fakeSimStatusChanged: reg count=\"\n                                + mIccStatusChangedRegistrants.size());\n                    }\n                    mIccStatusChangedRegistrants.notifyRegistrants();\n                }\n                break;\n        }\n        if (error != 0) {\n            rr.onError(error, ret);\n            rr.release();\n            return;\n        }\n        if (RILJ_LOGD) riljLog(rr.serialString() + \"< \" + requestToString(rr.mRequest)\n            + \" \" + retToString(rr.mRequest, ret));\n        if (rr.mResult != null) {\n            AsyncResult.forMessage(rr.mResult, ret, null);\n            rr.mResult.sendToTarget();\n        }\n        rr.release();\n    }\n    @Override\n    protected Object\n    responseCallList(Parcel p) {\n        int num;\n        int voiceSettings;\n        ArrayList<DriverCall> response;\n        DriverCall dc;\n        num = p.readInt();\n        response = new ArrayList<DriverCall>(num);\n        for (int i = 0 ; i < num ; i++) {\n            dc = new DriverCall();\n            dc.state = DriverCall.stateFromCLCC(p.readInt());\n", "outputs": ["            dc.index = p.readInt();"], "input_length": 2199, "output_length": 6, "length": 2205, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "2b782fbcd74272b674dccfa2329c31450218b2fed734a8f751daaaf500d2553d"}
{"input": "", "context": "#!/usr/bin/env python\n#\n# Copyright 2009 Facebook\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n# not use this file except in compliance with the License. You may obtain\n# a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.\n\"\"\"``tornado.web`` provides a simple web framework with asynchronous\nfeatures that allow it to scale to large numbers of open connections,\nmaking it ideal for `long polling\n<http://en.wikipedia.org/wiki/Push_technology#Long_polling>`_.\nHere is a simple \"Hello, world\" example app:\n.. testcode::\n    import tornado.ioloop\n    import tornado.web\n    class MainHandler(tornado.web.RequestHandler):\n        def get(self):\n            self.write(\"Hello, world\")\n    if __name__ == \"__main__\":\n        application = tornado.web.Application([\n            (r\"/\", MainHandler),\n        ])\n        application.listen(8888)\n        tornado.ioloop.IOLoop.current().start()\n.. testoutput::\n   :hide:\nSee the :doc:`guide` for additional information.\nThread-safety notes\n-------------------\nIn general, methods on `RequestHandler` and elsewhere in Tornado are\nnot thread-safe.  In particular, methods such as\n`~RequestHandler.write()`, `~RequestHandler.finish()`, and\n`~RequestHandler.flush()` must only be called from the main thread.  If\nyou use multiple threads it is important to use `.IOLoop.add_callback`\nto transfer control back to the main thread before finishing the\nrequest.\n\"\"\"\nfrom __future__ import (absolute_import, division,\n                        print_function, with_statement)\nimport base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport mimetypes\nimport numbers\nimport os.path\nimport re\nimport stat\nimport sys\nimport threading\nimport time\nimport tornado\nimport traceback\nimport types\nfrom io import BytesIO\nfrom tornado.concurrent import Future, is_future\nfrom tornado import escape\nfrom tornado import gen\nfrom tornado import httputil\nfrom tornado import iostream\nfrom tornado import locale\nfrom tornado.log import access_log, app_log, gen_log\nfrom tornado import stack_context\nfrom tornado import template\nfrom tornado.escape import utf8, _unicode\nfrom tornado.util import (import_object, ObjectDict, raise_exc_info,\n                          unicode_type, _websocket_mask)\nfrom tornado.httputil import split_host_and_port\ntry:\n    import Cookie  # py2\nexcept ImportError:\n    import http.cookies as Cookie  # py3\ntry:\n    import urlparse  # py2\nexcept ImportError:\n    import urllib.parse as urlparse  # py3\ntry:\n    from urllib import urlencode  # py2\nexcept ImportError:\n    from urllib.parse import urlencode  # py3\nMIN_SUPPORTED_SIGNED_VALUE_VERSION = 1\n\"\"\"The oldest signed value version supported by this version of Tornado.\nSigned values older than this version cannot be decoded.\n.. versionadded:: 3.2.1\n\"\"\"\nMAX_SUPPORTED_SIGNED_VALUE_VERSION = 2\n\"\"\"The newest signed value version supported by this version of Tornado.\nSigned values newer than this version cannot be decoded.\n.. versionadded:: 3.2.1\n\"\"\"\nDEFAULT_SIGNED_VALUE_VERSION = 2\n\"\"\"The signed value version produced by `.RequestHandler.create_signed_value`.\nMay be overridden by passing a ``version`` keyword argument.\n.. versionadded:: 3.2.1\n\"\"\"\nDEFAULT_SIGNED_VALUE_MIN_VERSION = 1\n\"\"\"The oldest signed value accepted by `.RequestHandler.get_secure_cookie`.\nMay be overridden by passing a ``min_version`` keyword argument.\n.. versionadded:: 3.2.1\n\"\"\"\nclass RequestHandler(object):\n    \"\"\"Base class for HTTP request handlers.\n    Subclasses must define at least one of the methods defined in the\n    \"Entry points\" section below.\n    \"\"\"\n    SUPPORTED_METHODS = (\"GET\", \"HEAD\", \"POST\", \"DELETE\", \"PATCH\", \"PUT\",\n                         \"OPTIONS\")\n    _template_loaders = {}  # {path: template.BaseLoader}\n    _template_loader_lock = threading.Lock()\n    _remove_control_chars_regex = re.compile(r\"[\\x00-\\x08\\x0e-\\x1f]\")\n    def __init__(self, application, request, **kwargs):\n        super(RequestHandler, self).__init__()\n        self.application = application\n        self.request = request\n        self._headers_written = False\n        self._finished = False\n        self._auto_finish = True\n        self._transforms = None  # will be set in _execute\n        self._prepared_future = None\n        self.path_args = None\n        self.path_kwargs = None\n        self.ui = ObjectDict((n, self._ui_method(m)) for n, m in\n                             application.ui_methods.items())\n        # UIModules are available as both `modules` and `_tt_modules` in the\n        # template namespace.  Historically only `modules` was available\n        # but could be clobbered by user additions to the namespace.\n        # The template {% module %} directive looks in `_tt_modules` to avoid\n        # possible conflicts.\n        self.ui[\"_tt_modules\"] = _UIModuleNamespace(self,\n                                                    application.ui_modules)\n        self.ui[\"modules\"] = self.ui[\"_tt_modules\"]\n        self.clear()\n        self.request.connection.set_close_callback(self.on_connection_close)\n        self.initialize(**kwargs)\n    def initialize(self):\n        \"\"\"Hook for subclass initialization.\n        A dictionary passed as the third argument of a url spec will be\n        supplied as keyword arguments to initialize().\n        Example::\n            class ProfileHandler(RequestHandler):\n                def initialize(self, database):\n                    self.database = database\n                def get(self, username):\n                    ...\n            app = Application([\n                (r'/user/(.*)', ProfileHandler, dict(database=database)),\n                ])\n        \"\"\"\n        pass\n    @property\n    def settings(self):\n        \"\"\"An alias for `self.application.settings <Application.settings>`.\"\"\"\n        return self.application.settings\n    def head(self, *args, **kwargs):\n        raise HTTPError(405)\n    def get(self, *args, **kwargs):\n        raise HTTPError(405)\n    def post(self, *args, **kwargs):\n        raise HTTPError(405)\n    def delete(self, *args, **kwargs):\n        raise HTTPError(405)\n    def patch(self, *args, **kwargs):\n        raise HTTPError(405)\n    def put(self, *args, **kwargs):\n        raise HTTPError(405)\n    def options(self, *args, **kwargs):\n        raise HTTPError(405)\n    def prepare(self):\n        \"\"\"Called at the beginning of a request before  `get`/`post`/etc.\n        Override this method to perform common initialization regardless\n        of the request method.\n        Asynchronous support: Decorate this method with `.gen.coroutine`\n        or `.return_future` to make it asynchronous (the\n        `asynchronous` decorator cannot be used on `prepare`).\n        If this method returns a `.Future` execution will not proceed\n        until the `.Future` is done.\n        .. versionadded:: 3.1\n           Asynchronous support.\n        \"\"\"\n        pass\n    def on_finish(self):\n        \"\"\"Called after the end of a request.\n        Override this method to perform cleanup, logging, etc.\n        This method is a counterpart to `prepare`.  ``on_finish`` may\n        not produce any output, as it is called after the response\n        has been sent to the client.\n        \"\"\"\n        pass\n    def on_connection_close(self):\n        \"\"\"Called in async handlers if the client closed the connection.\n        Override this to clean up resources associated with\n        long-lived connections.  Note that this method is called only if\n        the connection was closed during asynchronous processing; if you\n        need to do cleanup after every request override `on_finish`\n        instead.\n        Proxies may keep a connection open for a time (perhaps\n        indefinitely) after the client has gone away, so this method\n        may not be called promptly after the end user closes their\n        connection.\n        \"\"\"\n        if _has_stream_request_body(self.__class__):\n            if not self.request.body.done():\n                self.request.body.set_exception(iostream.StreamClosedError())\n                self.request.body.exception()\n    def clear(self):\n        \"\"\"Resets all headers and content for this response.\"\"\"\n        self._headers = httputil.HTTPHeaders({\n            \"Server\": \"TornadoServer/%s\" % tornado.version,\n            \"Content-Type\": \"text/html; charset=UTF-8\",\n            \"Date\": httputil.format_timestamp(time.time()),\n        })\n        self.set_default_headers()\n        self._write_buffer = []\n        self._status_code = 200\n        self._reason = httputil.responses[200]\n    def set_default_headers(self):\n        \"\"\"Override this to set HTTP headers at the beginning of the request.\n        For example, this is the place to set a custom ``Server`` header.\n        Note that setting such headers in the normal flow of request\n        processing may not do what you want, since headers may be reset\n        during error handling.\n        \"\"\"\n        pass\n    def set_status(self, status_code, reason=None):\n        \"\"\"Sets the status code for our response.\n        :arg int status_code: Response status code. If ``reason`` is ``None``,\n            it must be present in `httplib.responses <http.client.responses>`.\n        :arg string reason: Human-readable reason phrase describing the status\n            code. If ``None``, it will be filled in from\n            `httplib.responses <http.client.responses>`.\n        \"\"\"\n        self._status_code = status_code\n        if reason is not None:\n            self._reason = escape.native_str(reason)\n        else:\n            try:\n                self._reason = httputil.responses[status_code]\n            except KeyError:\n                raise ValueError(\"unknown status code %d\", status_code)\n    def get_status(self):\n        \"\"\"Returns the status code for our response.\"\"\"\n        return self._status_code\n    def set_header(self, name, value):\n        \"\"\"Sets the given response header name and value.\n        If a datetime is given, we automatically format it according to the\n        HTTP specification. If the value is not a string, we convert it to\n        a string. All header values are then encoded as UTF-8.\n        \"\"\"\n        self._headers[name] = self._convert_header_value(value)\n    def add_header(self, name, value):\n        \"\"\"Adds the given response header and value.\n        Unlike `set_header`, `add_header` may be called multiple times\n        to return multiple values for the same header.\n        \"\"\"\n        self._headers.add(name, self._convert_header_value(value))\n    def clear_header(self, name):\n        \"\"\"Clears an outgoing header, undoing a previous `set_header` call.\n        Note that this method does not apply to multi-valued headers\n        set by `add_header`.\n        \"\"\"\n        if name in self._headers:\n            del self._headers[name]\n    _INVALID_HEADER_CHAR_RE = re.compile(br\"[\\x00-\\x1f]\")\n    def _convert_header_value(self, value):\n        if isinstance(value, bytes):\n            pass\n        elif isinstance(value, unicode_type):\n            value = value.encode('utf-8')\n        elif isinstance(value, numbers.Integral):\n            # return immediately since we know the converted value will be safe\n            return str(value)\n        elif isinstance(value, datetime.datetime):\n            return httputil.format_timestamp(value)\n        else:\n            raise TypeError(\"Unsupported header value %r\" % value)\n        # If \\n is allowed into the header, it is possible to inject\n        # additional headers or split the request.\n        if RequestHandler._INVALID_HEADER_CHAR_RE.search(value):\n            raise ValueError(\"Unsafe header value %r\", value)\n        return value\n    _ARG_DEFAULT = []\n    def get_argument(self, name, default=_ARG_DEFAULT, strip=True):\n        \"\"\"Returns the value of the argument with the given name.\n        If default is not provided, the argument is considered to be\n        required, and we raise a `MissingArgumentError` if it is missing.\n        If the argument appears in the url more than once, we return the\n        last value.\n        The returned value is always unicode.\n        \"\"\"\n        return self._get_argument(name, default, self.request.arguments, strip)\n    def get_arguments(self, name, strip=True):\n        \"\"\"Returns a list of the arguments with the given name.\n        If the argument is not present, returns an empty list.\n        The returned values are always unicode.\n        \"\"\"\n        # Make sure `get_arguments` isn't accidentally being called with a\n        # positional argument that's assumed to be a default (like in\n        # `get_argument`.)\n        assert isinstance(strip, bool)\n        return self._get_arguments(name, self.request.arguments, strip)\n    def get_body_argument(self, name, default=_ARG_DEFAULT, strip=True):\n        \"\"\"Returns the value of the argument with the given name\n        from the request body.\n        If default is not provided, the argument is considered to be\n        required, and we raise a `MissingArgumentError` if it is missing.\n        If the argument appears in the url more than once, we return the\n        last value.\n        The returned value is always unicode.\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_argument(name, default, self.request.body_arguments,\n                                  strip)\n    def get_body_arguments(self, name, strip=True):\n        \"\"\"Returns a list of the body arguments with the given name.\n        If the argument is not present, returns an empty list.\n        The returned values are always unicode.\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_arguments(name, self.request.body_arguments, strip)\n    def get_query_argument(self, name, default=_ARG_DEFAULT, strip=True):\n        \"\"\"Returns the value of the argument with the given name\n        from the request query string.\n        If default is not provided, the argument is considered to be\n        required, and we raise a `MissingArgumentError` if it is missing.\n        If the argument appears in the url more than once, we return the\n        last value.\n        The returned value is always unicode.\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_argument(name, default,\n                                  self.request.query_arguments, strip)\n    def get_query_arguments(self, name, strip=True):\n        \"\"\"Returns a list of the query arguments with the given name.\n        If the argument is not present, returns an empty list.\n        The returned values are always unicode.\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_arguments(name, self.request.query_arguments, strip)\n    def _get_argument(self, name, default, source, strip=True):\n        args = self._get_arguments(name, source, strip=strip)\n        if not args:\n            if default is self._ARG_DEFAULT:\n                raise MissingArgumentError(name)\n            return default\n        return args[-1]\n    def _get_arguments(self, name, source, strip=True):\n        values = []\n        for v in source.get(name, []):\n            v = self.decode_argument(v, name=name)\n            if isinstance(v, unicode_type):\n                # Get rid of any weird control chars (unless decoding gave\n                # us bytes, in which case leave it alone)\n                v = RequestHandler._remove_control_chars_regex.sub(\" \", v)\n            if strip:\n                v = v.strip()\n            values.append(v)\n        return values\n    def decode_argument(self, value, name=None):\n        \"\"\"Decodes an argument from the request.\n        The argument has been percent-decoded and is now a byte string.\n        By default, this method decodes the argument as utf-8 and returns\n        a unicode string, but this may be overridden in subclasses.\n        This method is used as a filter for both `get_argument()` and for\n        values extracted from the url and passed to `get()`/`post()`/etc.\n        The name of the argument is provided if known, but may be None\n        (e.g. for unnamed groups in the url regex).\n        \"\"\"\n        try:\n            return _unicode(value)\n        except UnicodeDecodeError:\n            raise HTTPError(400, \"Invalid unicode in %s: %r\" %\n                            (name or \"url\", value[:40]))\n    @property\n    def cookies(self):\n        \"\"\"An alias for\n        `self.request.cookies <.httputil.HTTPServerRequest.cookies>`.\"\"\"\n        return self.request.cookies\n    def get_cookie(self, name, default=None):\n        \"\"\"Gets the value of the cookie with the given name, else default.\"\"\"\n        if self.request.cookies is not None and name in self.request.cookies:\n            return self.request.cookies[name].value\n        return default\n    def set_cookie(self, name, value, domain=None, expires=None, path=\"/\",\n                   expires_days=None, **kwargs):\n        \"\"\"Sets the given cookie name/value with the given options.\n        Additional keyword arguments are set on the Cookie.Morsel\n        directly.\n        See http://docs.python.org/library/cookie.html#morsel-objects\n        for available attributes.\n        \"\"\"\n        # The cookie library only accepts type str, in both python 2 and 3\n        name = escape.native_str(name)\n        value = escape.native_str(value)\n        if re.search(r\"[\\x00-\\x20]\", name + value):\n            # Don't let us accidentally inject bad stuff\n            raise ValueError(\"Invalid cookie %r: %r\" % (name, value))\n        if not hasattr(self, \"_new_cookie\"):\n            self._new_cookie = Cookie.SimpleCookie()\n        if name in self._new_cookie:\n            del self._new_cookie[name]\n        self._new_cookie[name] = value\n        morsel = self._new_cookie[name]\n        if domain:\n            morsel[\"domain\"] = domain\n        if expires_days is not None and not expires:\n            expires = datetime.datetime.utcnow() + datetime.timedelta(\n                days=expires_days)\n        if expires:\n            morsel[\"expires\"] = httputil.format_timestamp(expires)\n        if path:\n            morsel[\"path\"] = path\n        for k, v in kwargs.items():\n            if k == 'max_age':\n                k = 'max-age'\n            # skip falsy values for httponly and secure flags because\n            # SimpleCookie sets them regardless\n            if k in ['httponly', 'secure'] and not v:\n                continue\n            morsel[k] = v\n    def clear_cookie(self, name, path=\"/\", domain=None):\n        \"\"\"Deletes the cookie with the given name.\n        Due to limitations of the cookie protocol, you must pass the same\n        path and domain to clear a cookie as were used when that cookie\n        was set (but there is no way to find out on the server side\n        which values were used for a given cookie).\n        \"\"\"\n        expires = datetime.datetime.utcnow() - datetime.timedelta(days=365)\n        self.set_cookie(name, value=\"\", path=path, expires=expires,\n                        domain=domain)\n    def clear_all_cookies(self, path=\"/\", domain=None):\n        \"\"\"Deletes all the cookies the user sent with this request.\n        See `clear_cookie` for more information on the path and domain\n        parameters.\n        .. versionchanged:: 3.2\n           Added the ``path`` and ``domain`` parameters.\n        \"\"\"\n        for name in self.request.cookies:\n            self.clear_cookie(name, path=path, domain=domain)\n    def set_secure_cookie(self, name, value, expires_days=30, version=None,\n                          **kwargs):\n        \"\"\"Signs and timestamps a cookie so it cannot be forged.\n        You must specify the ``cookie_secret`` setting in your Application\n        to use this method. It should be a long, random sequence of bytes\n        to be used as the HMAC secret for the signature.\n        To read a cookie set with this method, use `get_secure_cookie()`.\n        Note that the ``expires_days`` parameter sets the lifetime of the\n        cookie in the browser, but is independent of the ``max_age_days``\n        parameter to `get_secure_cookie`.\n        Secure cookies may contain arbitrary byte values, not just unicode\n        strings (unlike regular cookies)\n        .. versionchanged:: 3.2.1\n           Added the ``version`` argument.  Introduced cookie version 2\n           and made it the default.\n        \"\"\"\n        self.set_cookie(name, self.create_signed_value(name, value,\n                                                       version=version),\n                        expires_days=expires_days, **kwargs)\n    def create_signed_value(self, name, value, version=None):\n        \"\"\"Signs and timestamps a string so it cannot be forged.\n        Normally used via set_secure_cookie, but provided as a separate\n        method for non-cookie uses.  To decode a value not stored\n        as a cookie use the optional value argument to get_secure_cookie.\n        .. versionchanged:: 3.2.1\n           Added the ``version`` argument.  Introduced cookie version 2\n           and made it the default.\n        \"\"\"\n        self.require_setting(\"cookie_secret\", \"secure cookies\")\n        secret = self.application.settings[\"cookie_secret\"]\n        key_version = None\n        if isinstance(secret, dict):\n            if self.application.settings.get(\"key_version\") is None:\n                raise Exception(\"key_version setting must be used for secret_key dicts\")\n            key_version = self.application.settings[\"key_version\"]\n        return create_signed_value(secret, name, value, version=version,\n                                   key_version=key_version)\n    def get_secure_cookie(self, name, value=None, max_age_days=31,\n                          min_version=None):\n        \"\"\"Returns the given signed cookie if it validates, or None.\n        The decoded cookie value is returned as a byte string (unlike\n        `get_cookie`).\n        .. versionchanged:: 3.2.1\n           Added the ``min_version`` argument.  Introduced cookie version 2;\n           both versions 1 and 2 are accepted by default.\n        \"\"\"\n        self.require_setting(\"cookie_secret\", \"secure cookies\")\n        if value is None:\n            value = self.get_cookie(name)\n        return decode_signed_value(self.application.settings[\"cookie_secret\"],\n                                   name, value, max_age_days=max_age_days,\n                                   min_version=min_version)\n    def get_secure_cookie_key_version(self, name, value=None):\n        \"\"\"Returns the signing key version of the secure cookie.\n        The version is returned as int.\n        \"\"\"\n        self.require_setting(\"cookie_secret\", \"secure cookies\")\n        if value is None:\n            value = self.get_cookie(name)\n        return get_signature_key_version(value)\n    def redirect(self, url, permanent=False, status=None):\n        \"\"\"Sends a redirect to the given (optionally relative) URL.\n        If the ``status`` argument is specified, that value is used as the\n        HTTP status code; otherwise either 301 (permanent) or 302\n        (temporary) is chosen based on the ``permanent`` argument.\n        The default is 302 (temporary).\n        \"\"\"\n        if self._headers_written:\n            raise Exception(\"Cannot redirect after headers have been written\")\n        if status is None:\n            status = 301 if permanent else 302\n        else:\n            assert isinstance(status, int) and 300 <= status <= 399\n        self.set_status(status)\n        self.set_header(\"Location\", utf8(url))\n        self.finish()\n    def write(self, chunk):\n        \"\"\"Writes the given chunk to the output buffer.\n        To write the output to the network, use the flush() method below.\n        If the given chunk is a dictionary, we write it as JSON and set\n        the Content-Type of the response to be ``application/json``.\n        (if you want to send JSON as a different ``Content-Type``, call\n        set_header *after* calling write()).\n        Note that lists are not converted to JSON because of a potential\n        cross-site security vulnerability.  All JSON output should be\n        wrapped in a dictionary.  More details at\n        http://haacked.com/archive/2009/06/25/json-hijacking.aspx/ and\n        https://github.com/facebook/tornado/issues/1009\n        \"\"\"\n        if self._finished:\n            raise RuntimeError(\"Cannot write() after finish()\")\n        if not isinstance(chunk, (bytes, unicode_type, dict)):\n            message = \"write() only accepts bytes, unicode, and dict objects\"\n            if isinstance(chunk, list):\n                message += \". Lists not accepted for security reasons; see http://www.tornadoweb.org/en/stable/web.html#tornado.web.RequestHandler.write\"\n            raise TypeError(message)\n        if isinstance(chunk, dict):\n            if 'unwrap_json' in chunk:\n                chunk = chunk['unwrap_json']\n            else:\n                chunk = escape.json_encode(chunk)\n            self.set_header(\"Content-Type\", \"application/json; charset=UTF-8\")\n        chunk = utf8(chunk)\n        self._write_buffer.append(chunk)\n    def render(self, template_name, **kwargs):\n        \"\"\"Renders the template with the given arguments as the response.\"\"\"\n        html = self.render_string(template_name, **kwargs)\n        # Insert the additional JS and CSS added by the modules on the page\n        js_embed = []\n        js_files = []\n        css_embed = []\n        css_files = []\n        html_heads = []\n        html_bodies = []\n        for module in getattr(self, \"_active_modules\", {}).values():\n            embed_part = module.embedded_javascript()\n            if embed_part:\n                js_embed.append(utf8(embed_part))\n            file_part = module.javascript_files()\n            if file_part:\n                if isinstance(file_part, (unicode_type, bytes)):\n                    js_files.append(file_part)\n                else:\n                    js_files.extend(file_part)\n            embed_part = module.embedded_css()\n            if embed_part:\n                css_embed.append(utf8(embed_part))\n            file_part = module.css_files()\n            if file_part:\n                if isinstance(file_part, (unicode_type, bytes)):\n                    css_files.append(file_part)\n                else:\n                    css_files.extend(file_part)\n            head_part = module.html_head()\n            if head_part:\n                html_heads.append(utf8(head_part))\n            body_part = module.html_body()\n            if body_part:\n                html_bodies.append(utf8(body_part))\n        def is_absolute(path):\n            return any(path.startswith(x) for x in [\"/\", \"http:\", \"https:\"])\n        if js_files:\n            # Maintain order of JavaScript files given by modules\n            paths = []\n            unique_paths = set()\n            for path in js_files:\n                if not is_absolute(path):\n                    path = self.static_url(path)\n                if path not in unique_paths:\n                    paths.append(path)\n                    unique_paths.add(path)\n            js = ''.join('<script src=\"' + escape.xhtml_escape(p) +\n                         '\" type=\"text/javascript\"></script>'\n                         for p in paths)\n            sloc = html.rindex(b'</body>')\n            html = html[:sloc] + utf8(js) + b'\\n' + html[sloc:]\n        if js_embed:\n            js = b'<script type=\"text/javascript\">\\n//<![CDATA[\\n' + \\\n                b'\\n'.join(js_embed) + b'\\n//]]>\\n</script>'\n            sloc = html.rindex(b'</body>')\n            html = html[:sloc] + js + b'\\n' + html[sloc:]\n        if css_files:\n            paths = []\n            unique_paths = set()\n            for path in css_files:\n                if not is_absolute(path):\n                    path = self.static_url(path)\n                if path not in unique_paths:\n                    paths.append(path)\n                    unique_paths.add(path)\n            css = ''.join('<link href=\"' + escape.xhtml_escape(p) + '\" '\n                          'type=\"text/css\" rel=\"stylesheet\"/>'\n                          for p in paths)\n            hloc = html.index(b'</head>')\n            html = html[:hloc] + utf8(css) + b'\\n' + html[hloc:]\n        if css_embed:\n            css = b'<style type=\"text/css\">\\n' + b'\\n'.join(css_embed) + \\\n                b'\\n</style>'\n            hloc = html.index(b'</head>')\n            html = html[:hloc] + css + b'\\n' + html[hloc:]\n        if html_heads:\n            hloc = html.index(b'</head>')\n            html = html[:hloc] + b''.join(html_heads) + b'\\n' + html[hloc:]\n        if html_bodies:\n            hloc = html.index(b'</body>')\n            html = html[:hloc] + b''.join(html_bodies) + b'\\n' + html[hloc:]\n        self.finish(html)\n    def render_string(self, template_name, **kwargs):\n        \"\"\"Generate the given template with the given arguments.\n        We return the generated byte string (in utf8). To generate and\n        write a template as a response, use render() above.\n        \"\"\"\n        # If no template_path is specified, use the path of the calling file\n        template_path = self.get_template_path()\n        if not template_path:\n            frame = sys._getframe(0)\n            web_file = frame.f_code.co_filename\n            while frame.f_code.co_filename == web_file:\n                frame = frame.f_back\n            template_path = os.path.dirname(frame.f_code.co_filename)\n        with RequestHandler._template_loader_lock:\n            if template_path not in RequestHandler._template_loaders:\n                loader = self.create_template_loader(template_path)\n                RequestHandler._template_loaders[template_path] = loader\n            else:\n                loader = RequestHandler._template_loaders[template_path]\n        t = loader.load(template_name)\n        namespace = self.get_template_namespace()\n        namespace.update(kwargs)\n        return t.generate(**namespace)\n    def get_template_namespace(self):\n        \"\"\"Returns a dictionary to be used as the default template namespace.\n        May be overridden by subclasses to add or modify values.\n        The results of this method will be combined with additional\n        defaults in the `tornado.template` module and keyword arguments\n        to `render` or `render_string`.\n        \"\"\"\n        namespace = dict(\n            handler=self,\n            request=self.request,\n            current_user=self.current_user,\n            locale=self.locale,\n            _=self.locale.translate,\n            pgettext=self.locale.pgettext,\n            static_url=self.static_url,\n            xsrf_form_html=self.xsrf_form_html,\n            reverse_url=self.reverse_url\n        )\n        namespace.update(self.ui)\n        return namespace\n    def create_template_loader(self, template_path):\n        \"\"\"Returns a new template loader for the given path.\n        May be overridden by subclasses.  By default returns a\n        directory-based loader on the given path, using the\n        ``autoescape`` and ``template_whitespace`` application\n        settings.  If a ``template_loader`` application setting is\n        supplied, uses that instead.\n        \"\"\"\n        settings = self.application.settings\n        if \"template_loader\" in settings:\n            return settings[\"template_loader\"]\n        kwargs = {}\n        if \"autoescape\" in settings:\n            # autoescape=None means \"no escaping\", so we have to be sure\n            # to only pass this kwarg if the user asked for it.\n            kwargs[\"autoescape\"] = settings[\"autoescape\"]\n        if \"template_whitespace\" in settings:\n            kwargs[\"whitespace\"] = settings[\"template_whitespace\"]\n        return template.Loader(template_path, **kwargs)\n    def flush(self, include_footers=False, callback=None):\n        \"\"\"Flushes the current output buffer to the network.\n        The ``callback`` argument, if given, can be used for flow control:\n        it will be run when all flushed data has been written to the socket.\n        Note that only one flush callback can be outstanding at a time;\n        if another flush occurs before the previous flush's callback\n        has been run, the previous callback will be discarded.\n        .. versionchanged:: 4.0\n           Now returns a `.Future` if no callback is given.\n        \"\"\"\n        chunk = b\"\".join(self._write_buffer)\n        self._write_buffer = []\n        if not self._headers_written:\n            self._headers_written = True\n            for transform in self._transforms:\n                self._status_code, self._headers, chunk = \\\n                    transform.transform_first_chunk(\n                        self._status_code, self._headers,\n                        chunk, include_footers)\n            # Ignore the chunk and only write the headers for HEAD requests\n            if self.request.method == \"HEAD\":\n                chunk = None\n            # Finalize the cookie headers (which have been stored in a side\n            # object so an outgoing cookie could be overwritten before it\n            # is sent).\n            if hasattr(self, \"_new_cookie\"):\n                for cookie in self._new_cookie.values():\n                    self.add_header(\"Set-Cookie\", cookie.OutputString(None))\n            start_line = httputil.ResponseStartLine('',\n                                                    self._status_code,\n                                                    self._reason)\n            return self.request.connection.write_headers(\n                start_line, self._headers, chunk, callback=callback)\n        else:\n            for transform in self._transforms:\n                chunk = transform.transform_chunk(chunk, include_footers)\n            # Ignore the chunk and only write the headers for HEAD requests\n            if self.request.method != \"HEAD\":\n                return self.request.connection.write(chunk, callback=callback)\n            else:\n                future = Future()\n                future.set_result(None)\n                return future\n    def finish(self, chunk=None):\n        \"\"\"Finishes this response, ending the HTTP request.\"\"\"\n        if self._finished:\n            raise RuntimeError(\"finish() called twice\")\n        if chunk is not None:\n            self.write(chunk)\n        # Automatically support ETags and add the Content-Length header if\n        # we have not flushed any content yet.\n        if not self._headers_written:\n            if (self._status_code == 200 and\n                self.request.method in (\"GET\", \"HEAD\") and\n                    \"Etag\" not in self._headers):\n                self.set_etag_header()\n                if self.check_etag_header():\n                    self._write_buffer = []\n                    self.set_status(304)\n            if self._status_code == 304:\n                assert not self._write_buffer, \"Cannot send body with 304\"\n                self._clear_headers_for_304()\n            elif \"Content-Length\" not in self._headers:\n                content_length = sum(len(part) for part in self._write_buffer)\n                self.set_header(\"Content-Length\", content_length)\n        if hasattr(self.request, \"connection\"):\n            # Now that the request is finished, clear the callback we\n            # set on the HTTPConnection (which would otherwise prevent the\n            # garbage collection of the RequestHandler when there\n            # are keepalive connections)\n            self.request.connection.set_close_callback(None)\n        self.flush(include_footers=True)\n        self.request.finish()\n        self._log()\n        self._finished = True\n        self.on_finish()\n        # Break up a reference cycle between this handler and the\n        # _ui_module closures to allow for faster GC on CPython.\n        self.ui = None\n    def send_error(self, status_code=500, **kwargs):\n        \"\"\"Sends the given HTTP error code to the browser.\n        If `flush()` has already been called, it is not possible to send\n        an error, so this method will simply terminate the response.\n        If output has been written but not yet flushed, it will be discarded\n        and replaced with the error page.\n        Override `write_error()` to customize the error page that is returned.\n        Additional keyword arguments are passed through to `write_error`.\n        \"\"\"\n        if self._headers_written:\n            gen_log.error(\"Cannot send error response after headers written\")\n            if not self._finished:\n                # If we get an error between writing headers and finishing,\n                # we are unlikely to be able to finish due to a\n                # Content-Length mismatch. Try anyway to release the\n                # socket.\n                try:\n                    self.finish()\n                except Exception:\n                    gen_log.error(\"Failed to flush partial response\",\n                                  exc_info=True)\n            return\n        self.clear()\n        reason = kwargs.get('reason')\n        if 'exc_info' in kwargs:\n            exception = kwargs['exc_info'][1]\n            if isinstance(exception, HTTPError) and exception.reason:\n                reason = exception.reason\n        self.set_status(status_code, reason=reason)\n        try:\n            self.write_error(status_code, **kwargs)\n        except Exception:\n            app_log.error(\"Uncaught exception in write_error\", exc_info=True)\n        if not self._finished:\n            self.finish()\n    def write_error(self, status_code, **kwargs):\n        \"\"\"Override to implement custom error pages.\n        ``write_error`` may call `write`, `render`, `set_header`, etc\n        to produce output as usual.\n        If this error was caused by an uncaught exception (including\n        HTTPError), an ``exc_info`` triple will be available as\n        ``kwargs[\"exc_info\"]``.  Note that this exception may not be\n        the \"current\" exception for purposes of methods like\n        ``sys.exc_info()`` or ``traceback.format_exc``.\n        \"\"\"\n        if self.settings.get(\"serve_traceback\") and \"exc_info\" in kwargs:\n            # in debug mode, try to send a traceback\n            self.set_header('Content-Type', 'text/plain')\n            for line in traceback.format_exception(*kwargs[\"exc_info\"]):\n                self.write(line)\n            self.finish()\n        else:\n            self.finish(\"<html><title>%(code)d: %(message)s</title>\"\n                        \"<body>%(code)d: %(message)s</body></html>\" % {\n                            \"code\": status_code,\n                            \"message\": self._reason,\n                        })\n    @property\n    def locale(self):\n        \"\"\"The locale for the current session.\n        Determined by either `get_user_locale`, which you can override to\n        set the locale based on, e.g., a user preference stored in a\n        database, or `get_browser_locale`, which uses the ``Accept-Language``\n        header.\n        .. versionchanged: 4.1\n           Added a property setter.\n        \"\"\"\n        if not hasattr(self, \"_locale\"):\n            self._locale = self.get_user_locale()\n            if not self._locale:\n                self._locale = self.get_browser_locale()\n                assert self._locale\n        return self._locale\n    @locale.setter\n    def locale(self, value):\n        self._locale = value\n    def get_user_locale(self):\n        \"\"\"Override to determine the locale from the authenticated user.\n        If None is returned, we fall back to `get_browser_locale()`.\n        This method should return a `tornado.locale.Locale` object,\n        most likely obtained via a call like ``tornado.locale.get(\"en\")``\n        \"\"\"\n        return None\n    def get_browser_locale(self, default=\"en_US\"):\n        \"\"\"Determines the user's locale from ``Accept-Language`` header.\n        See http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.4\n        \"\"\"\n        if \"Accept-Language\" in self.request.headers:\n            languages = self.request.headers[\"Accept-Language\"].split(\",\")\n            locales = []\n            for language in languages:\n                parts = language.strip().split(\";\")\n                if len(parts) > 1 and parts[1].startswith(\"q=\"):\n                    try:\n                        score = float(parts[1][2:])\n                    except (ValueError, TypeError):\n                        score = 0.0\n                else:\n                    score = 1.0\n                locales.append((parts[0], score))\n            if locales:\n                locales.sort(key=lambda pair: pair[1], reverse=True)\n                codes = [l[0] for l in locales]\n                return locale.get(*codes)\n        return locale.get(default)\n    @property\n    def current_user(self):\n        \"\"\"The authenticated user for this request.\n        This is a cached version of `get_current_user`, which you can\n        override to set the user based on, e.g., a cookie. If that\n        method is not overridden, this method always returns None.\n        We lazy-load the current user the first time this method is called\n        and cache the result after that.\n        \"\"\"\n        if not hasattr(self, \"_current_user\"):\n            self._current_user = self.get_current_user()\n        return self._current_user\n    @current_user.setter\n    def current_user(self, value):\n        self._current_user = value\n    def get_current_user(self):\n        \"\"\"Override to determine the current user from, e.g., a cookie.\"\"\"\n        return None\n    def get_login_url(self):\n        \"\"\"Override to customize the login URL based on the request.\n        By default, we use the ``login_url`` application setting.\n        \"\"\"\n        self.require_setting(\"login_url\", \"@tornado.web.authenticated\")\n        return self.application.settings[\"login_url\"]\n    def get_template_path(self):\n        \"\"\"Override to customize template path for each handler.\n        By default, we use the ``template_path`` application setting.\n        Return None to load templates relative to the calling file.\n        \"\"\"\n        return self.application.settings.get(\"template_path\")\n    @property\n    def xsrf_token(self):\n        \"\"\"The XSRF-prevention token for the current user/session.\n        To prevent cross-site request forgery, we set an '_xsrf' cookie\n        and include the same '_xsrf' value as an argument with all POST\n        requests. If the two do not match, we reject the form submission\n        as a potential forgery.\n        See http://en.wikipedia.org/wiki/Cross-site_request_forgery\n        .. versionchanged:: 3.2.2\n           The xsrf token will now be have a random mask applied in every\n           request, which makes it safe to include the token in pages\n           that are compressed.  See http://breachattack.com for more\n           information on the issue fixed by this change.  Old (version 1)\n           cookies will be converted to version 2 when this method is called\n           unless the ``xsrf_cookie_version`` `Application` setting is\n           set to 1.\n        \"\"\"\n        if not hasattr(self, \"_xsrf_token\"):\n            version, token, timestamp = self._get_raw_xsrf_token()\n            output_version = self.settings.get(\"xsrf_cookie_version\", 2)\n            if output_version == 1:\n                self._xsrf_token = binascii.b2a_hex(token)\n            elif output_version == 2:\n                mask = os.urandom(4)\n                self._xsrf_token = b\"|\".join([\n                    b\"2\",\n                    binascii.b2a_hex(mask),\n                    binascii.b2a_hex(_websocket_mask(mask, token)),\n                    utf8(str(int(timestamp)))])\n            else:\n                raise ValueError(\"unknown xsrf cookie version %d\",\n                                 output_version)\n            if version is None:\n                expires_days = 30 if self.current_user else None\n                self.set_cookie(\"_xsrf\", self._xsrf_token,\n                                expires_days=expires_days)\n        return self._xsrf_token\n    def _get_raw_xsrf_token(self):\n        \"\"\"Read or generate the xsrf token in its raw form.\n        The raw_xsrf_token is a tuple containing:\n        * version: the version of the cookie from which this token was read,\n          or None if we generated a new token in this request.\n        * token: the raw token data; random (non-ascii) bytes.\n        * timestamp: the time this token was generated (will not be accurate\n          for version 1 cookies)\n        \"\"\"\n        if not hasattr(self, '_raw_xsrf_token'):\n            cookie = self.get_cookie(\"_xsrf\")\n            if cookie:\n                version, token, timestamp = self._decode_xsrf_token(cookie)\n            else:\n                version, token, timestamp = None, None, None\n            if token is None:\n                version = None\n                token = os.urandom(16)\n                timestamp = time.time()\n            self._raw_xsrf_token = (version, token, timestamp)\n        return self._raw_xsrf_token\n    def _decode_xsrf_token(self, cookie):\n        \"\"\"Convert a cookie string into a the tuple form returned by\n        _get_raw_xsrf_token.\n        \"\"\"\n        try:\n            m = _signed_value_version_re.match(utf8(cookie))\n            if m:\n                version = int(m.group(1))\n                if version == 2:\n                    _, mask, masked_token, timestamp = cookie.split(\"|\")\n                    mask = binascii.a2b_hex(utf8(mask))\n                    token = _websocket_mask(\n                        mask, binascii.a2b_hex(utf8(masked_token)))\n                    timestamp = int(timestamp)\n                    return version, token, timestamp\n                else:\n                    # Treat unknown versions as not present instead of failing.\n                    raise Exception(\"Unknown xsrf cookie version\")\n            else:\n                version = 1\n                try:\n                    token = binascii.a2b_hex(utf8(cookie))\n                except (binascii.Error, TypeError):\n                    token = utf8(cookie)\n                # We don't have a usable timestamp in older versions.\n                timestamp = int(time.time())\n                return (version, token, timestamp)\n        except Exception:\n            # Catch exceptions and return nothing instead of failing.\n            gen_log.debug(\"Uncaught exception in _decode_xsrf_token\",\n                          exc_info=True)\n            return None, None, None\n    def check_xsrf_cookie(self):\n        \"\"\"Verifies that the ``_xsrf`` cookie matches the ``_xsrf`` argument.\n        To prevent cross-site request forgery, we set an ``_xsrf``\n        cookie and include the same value as a non-cookie\n        field with all ``POST`` requests. If the two do not match, we\n        reject the form submission as a potential forgery.\n        The ``_xsrf`` value may be set as either a form field named ``_xsrf``\n        or in a custom HTTP header named ``X-XSRFToken`` or ``X-CSRFToken``\n        (the latter is accepted for compatibility with Django).\n        See http://en.wikipedia.org/wiki/Cross-site_request_forgery\n        Prior to release 1.1.1, this check was ignored if the HTTP header\n        ``X-Requested-With: XMLHTTPRequest`` was present.  This exception\n        has been shown to be insecure and has been removed.  For more\n        information please see\n        http://www.djangoproject.com/weblog/2011/feb/08/security/\n        http://weblog.rubyonrails.org/2011/2/8/csrf-protection-bypass-in-ruby-on-rails\n        .. versionchanged:: 3.2.2\n           Added support for cookie version 2.  Both versions 1 and 2 are\n           supported.\n        \"\"\"\n        token = (self.get_argument(\"_xsrf\", None) or\n                 self.request.headers.get(\"X-Xsrftoken\") or\n                 self.request.headers.get(\"X-Csrftoken\"))\n        if not token:\n            raise HTTPError(403, \"'_xsrf' argument missing from POST\")\n        _, token, _ = self._decode_xsrf_token(token)\n        _, expected_token, _ = self._get_raw_xsrf_token()\n        if not _time_independent_equals(utf8(token), utf8(expected_token)):\n            raise HTTPError(403, \"XSRF cookie does not match POST argument\")\n    def xsrf_form_html(self):\n        \"\"\"An HTML ``<input/>`` element to be included with all POST forms.\n        It defines the ``_xsrf`` input value, which we check on all POST\n        requests to prevent cross-site request forgery. If you have set\n        the ``xsrf_cookies`` application setting, you must include this\n        HTML within all of your HTML forms.\n        In a template, this method should be called with ``{% module\n        xsrf_form_html() %}``\n        See `check_xsrf_cookie()` above for more information.\n        \"\"\"\n        return '<input type=\"hidden\" name=\"_xsrf\" value=\"' + \\\n            escape.xhtml_escape(self.xsrf_token) + '\"/>'\n    def static_url(self, path, include_host=None, **kwargs):\n        \"\"\"Returns a static URL for the given relative static file path.\n        This method requires you set the ``static_path`` setting in your\n        application (which specifies the root directory of your static\n        files).\n        This method returns a versioned url (by default appending\n        ``?v=<signature>``), which allows the static files to be\n        cached indefinitely.  This can be disabled by passing\n        ``include_version=False`` (in the default implementation;\n        other static file implementations are not required to support\n        this, but they may support other options).\n        By default this method returns URLs relative to the current\n        host, but if ``include_host`` is true the URL returned will be\n        absolute.  If this handler has an ``include_host`` attribute,\n        that value will be used as the default for all `static_url`\n        calls that do not pass ``include_host`` as a keyword argument.\n        \"\"\"\n        self.require_setting(\"static_path\", \"static_url\")\n        get_url = self.settings.get(\"static_handler_class\",\n                                    StaticFileHandler).make_static_url\n        if include_host is None:\n            include_host = getattr(self, \"include_host\", False)\n        if include_host:\n            base = self.request.protocol + \"://\" + self.request.host\n        else:\n            base = \"\"\n        return base + get_url(self.settings, path, **kwargs)\n    def require_setting(self, name, feature=\"this feature\"):\n        \"\"\"Raises an exception if the given app setting is not defined.\"\"\"\n        if not self.application.settings.get(name):\n            raise Exception(\"You must define the '%s' setting in your \"\n                            \"application to use %s\" % (name, feature))\n    def reverse_url(self, name, *args):\n        \"\"\"Alias for `Application.reverse_url`.\"\"\"\n        return self.application.reverse_url(name, *args)\n    def compute_etag(self):\n        \"\"\"Computes the etag header to be used for this request.\n        By default uses a hash of the content written so far.\n        May be overridden to provide custom etag implementations,\n        or may return None to disable tornado's default etag support.\n        \"\"\"\n        hasher = hashlib.sha1()\n        for part in self._write_buffer:\n            hasher.update(part)\n        return '\"%s\"' % hasher.hexdigest()\n    def set_etag_header(self):\n        \"\"\"Sets the response's Etag header using ``self.compute_etag()``.\n        Note: no header will be set if ``compute_etag()`` returns ``None``.\n        This method is called automatically when the request is finished.\n        \"\"\"\n        etag = self.compute_etag()\n        if etag is not None:\n            self.set_header(\"Etag\", etag)\n    def check_etag_header(self):\n        \"\"\"Checks the ``Etag`` header against requests's ``If-None-Match``.\n        Returns ``True`` if the request's Etag matches and a 304 should be\n        returned. For example::\n            self.set_etag_header()\n            if self.check_etag_header():\n                self.set_status(304)\n                return\n        This method is called automatically when the request is finished,\n        but may be called earlier for applications that override\n        `compute_etag` and want to do an early check for ``If-None-Match``\n        before completing the request.  The ``Etag`` header should be set\n        (perhaps with `set_etag_header`) before calling this method.\n        \"\"\"\n        computed_etag = utf8(self._headers.get(\"Etag\", \"\"))\n        # Find all weak and strong etag values from If-None-Match header\n        # because RFC 7232 allows multiple etag values in a single header.\n        etags = re.findall(\n            br'\\*|(?:W/)?\"[^\"]*\"',\n            utf8(self.request.headers.get(\"If-None-Match\", \"\"))\n        )\n        if not computed_etag or not etags:\n            return False\n        match = False\n        if etags[0] == b'*':\n            match = True\n        else:\n            # Use a weak comparison when comparing entity-tags.\n            val = lambda x: x[2:] if x.startswith(b'W/') else x\n            for etag in etags:\n                if val(etag) == val(computed_etag):\n                    match = True\n                    break\n        return match\n    def _stack_context_handle_exception(self, type, value, traceback):\n        try:\n            # For historical reasons _handle_request_exception only takes\n            # the exception value instead of the full triple,\n            # so re-raise the exception to ensure that it's in\n            # sys.exc_info()\n            raise_exc_info((type, value, traceback))\n        except Exception:\n            self._handle_request_exception(value)\n        return True\n    @gen.coroutine\n    def _execute(self, transforms, *args, **kwargs):\n        \"\"\"Executes this request with the given output transforms.\"\"\"\n        self._transforms = transforms\n        try:\n            if self.request.method not in self.SUPPORTED_METHODS:\n                raise HTTPError(405)\n            self.path_args = [self.decode_argument(arg) for arg in args]\n            self.path_kwargs = dict((k, self.decode_argument(v, name=k))\n                                    for (k, v) in kwargs.items())\n            # If XSRF cookies are turned on, reject form submissions without\n            # the proper cookie\n            if self.request.method not in (\"GET\", \"HEAD\", \"OPTIONS\") and \\\n                    self.application.settings.get(\"xsrf_cookies\"):\n                self.check_xsrf_cookie()\n            result = self.prepare()\n            if result is not None:\n                result = yield result\n            if self._prepared_future is not None:\n                # Tell the Application we've finished with prepare()\n                # and are ready for the body to arrive.\n                self._prepared_future.set_result(None)\n            if self._finished:\n                return\n            if _has_stream_request_body(self.__class__):\n                # In streaming mode request.body is a Future that signals\n                # the body has been completely received.  The Future has no\n                # result; the data has been passed to self.data_received\n                # instead.\n                try:\n                    yield self.request.body\n                except iostream.StreamClosedError:\n                    return\n            method = getattr(self, self.request.method.lower())\n            result = method(*self.path_args, **self.path_kwargs)\n            if result is not None:\n                result = yield result\n            if self._auto_finish and not self._finished:\n                self.finish()\n        except Exception as e:\n            try:\n                self._handle_request_exception(e)\n            except Exception:\n                app_log.error(\"Exception in exception handler\", exc_info=True)\n            if (self._prepared_future is not None and\n                    not self._prepared_future.done()):\n                # In case we failed before setting _prepared_future, do it\n                # now (to unblock the HTTP server).  Note that this is not\n                # in a finally block to avoid GC issues prior to Python 3.4.\n                self._prepared_future.set_result(None)\n    def data_received(self, chunk):\n        \"\"\"Implement this method to handle streamed request data.\n        Requires the `.stream_request_body` decorator.\n        \"\"\"\n        raise NotImplementedError()\n    def _log(self):\n        \"\"\"Logs the current request.\n        Sort of deprecated since this functionality was moved to the\n        Application, but left in place for the benefit of existing apps\n        that have overridden this method.\n        \"\"\"\n        self.application.log_request(self)\n    def _request_summary(self):\n        return \"%s %s (%s)\" % (self.request.method, self.request.uri,\n                               self.request.remote_ip)\n    def _handle_request_exception(self, e):\n        if isinstance(e, Finish):\n            # Not an error; just finish the request without logging.\n            if not self._finished:\n                self.finish()\n            return\n        try:\n            self.log_exception(*sys.exc_info())\n        except Exception:\n            # An error here should still get a best-effort send_error()\n            # to avoid leaking the connection.\n            app_log.error(\"Error in exception logger\", exc_info=True)\n        if self._finished:\n            # Extra errors after the request has been finished should\n            # be logged, but there is no reason to continue to try and\n            # send a response.\n            return\n        if isinstance(e, HTTPError):\n            if e.status_code not in httputil.responses and not e.reason:\n                gen_log.error(\"Bad HTTP status code: %d\", e.status_code)\n                self.send_error(500, exc_info=sys.exc_info())\n            else:\n                self.send_error(e.status_code, exc_info=sys.exc_info())\n        else:\n            self.send_error(500, exc_info=sys.exc_info())\n    def log_exception(self, typ, value, tb):\n        \"\"\"Override to customize logging of uncaught exceptions.\n        By default logs instances of `HTTPError` as warnings without\n        stack traces (on the ``tornado.general`` logger), and all\n        other exceptions as errors with stack traces (on the\n        ``tornado.application`` logger).\n        .. versionadded:: 3.1\n        \"\"\"\n        if isinstance(value, HTTPError):\n            if value.log_message:\n                format = \"%d %s: \" + value.log_message\n                args = ([value.status_code, self._request_summary()] +\n                        list(value.args))\n                gen_log.warning(format, *args)\n        else:\n            app_log.error(\"Uncaught exception %s\\n%r\", self._request_summary(),\n                          self.request, exc_info=(typ, value, tb))\n    def _ui_module(self, name, module):\n        def render(*args, **kwargs):\n            if not hasattr(self, \"_active_modules\"):\n                self._active_modules = {}\n            if name not in self._active_modules:\n                self._active_modules[name] = module(self)\n            rendered = self._active_modules[name].render(*args, **kwargs)\n            return rendered\n        return render\n    def _ui_method(self, method):\n        return lambda *args, **kwargs: method(self, *args, **kwargs)\n    def _clear_headers_for_304(self):\n        # 304 responses should not contain entity headers (defined in\n        # http://www.w3.org/Protocols/rfc2616/rfc2616-sec7.html#sec7.1)\n        # not explicitly allowed by\n        # http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html#sec10.3.5\n        headers = [\"Allow\", \"Content-Encoding\", \"Content-Language\",\n                   \"Content-Length\", \"Content-MD5\", \"Content-Range\",\n                   \"Content-Type\", \"Last-Modified\"]\n        for h in headers:\n            self.clear_header(h)\ndef asynchronous(method):\n    \"\"\"Wrap request handler methods with this if they are asynchronous.\n    This decorator is for callback-style asynchronous methods; for\n    coroutines, use the ``@gen.coroutine`` decorator without\n    ``@asynchronous``. (It is legal for legacy reasons to use the two\n    decorators together provided ``@asynchronous`` is first, but\n    ``@asynchronous`` will be ignored in this case)\n    This decorator should only be applied to the :ref:`HTTP verb\n    methods <verbs>`; its behavior is undefined for any other method.\n    This decorator does not *make* a method asynchronous; it tells\n    the framework that the method *is* asynchronous.  For this decorator\n    to be useful the method must (at least sometimes) do something\n    asynchronous.\n    If this decorator is given, the response is not finished when the\n    method returns. It is up to the request handler to call\n    `self.finish() <RequestHandler.finish>` to finish the HTTP\n    request. Without this decorator, the request is automatically\n    finished when the ``get()`` or ``post()`` method returns. Example:\n    .. testcode::\n       class MyRequestHandler(RequestHandler):\n           @asynchronous\n           def get(self):\n              http = httpclient.AsyncHTTPClient()\n              http.fetch(\"http://friendfeed.com/\", self._on_download)\n           def _on_download(self, response):\n              self.write(\"Downloaded!\")\n              self.finish()\n    .. testoutput::\n       :hide:\n    .. versionadded:: 3.1\n       The ability to use ``@gen.coroutine`` without ``@asynchronous``.\n    \"\"\"\n    # Delay the IOLoop import because it's not available on app engine.\n    from tornado.ioloop import IOLoop\n    @functools.wraps(method)\n    def wrapper(self, *args, **kwargs):\n        self._auto_finish = False\n        with stack_context.ExceptionStackContext(\n                self._stack_context_handle_exception):\n            result = method(self, *args, **kwargs)\n            if is_future(result):\n                # If @asynchronous is used with @gen.coroutine, (but\n                # not @gen.engine), we can automatically finish the\n                # request when the future resolves.  Additionally,\n                # the Future will swallow any exceptions so we need\n                # to throw them back out to the stack context to finish\n                # the request.\n                def future_complete(f):\n                    f.result()\n                    if not self._finished:\n                        self.finish()\n                IOLoop.current().add_future(result, future_complete)\n                # Once we have done this, hide the Future from our\n                # caller (i.e. RequestHandler._when_complete), which\n                # would otherwise set up its own callback and\n                # exception handler (resulting in exceptions being\n                # logged twice).\n                return None\n            return result\n    return wrapper\ndef stream_request_body(cls):\n    \"\"\"Apply to `RequestHandler` subclasses to enable streaming body support.\n    This decorator implies the following changes:\n    * `.HTTPServerRequest.body` is undefined, and body arguments will not\n      be included in `RequestHandler.get_argument`.\n    * `RequestHandler.prepare` is called when the request headers have been\n      read instead of after the entire body has been read.\n    * The subclass must define a method ``data_received(self, data):``, which\n      will be called zero or more times as data is available.  Note that\n      if the request has an empty body, ``data_received`` may not be called.\n    * ``prepare`` and ``data_received`` may return Futures (such as via\n      ``@gen.coroutine``, in which case the next method will not be called\n      until those futures have completed.\n    * The regular HTTP method (``post``, ``put``, etc) will be called after\n      the entire body has been read.\n    There is a subtle interaction between ``data_received`` and asynchronous\n    ``prepare``: The first call to ``data_received`` may occur at any point\n    after the call to ``prepare`` has returned *or yielded*.\n    \"\"\"\n    if not issubclass(cls, RequestHandler):\n        raise TypeError(\"expected subclass of RequestHandler, got %r\", cls)\n    cls._stream_request_body = True\n    return cls\ndef _has_stream_request_body(cls):\n    if not issubclass(cls, RequestHandler):\n        raise TypeError(\"expected subclass of RequestHandler, got %r\", cls)\n    return getattr(cls, '_stream_request_body', False)\ndef removeslash(method):\n    \"\"\"Use this decorator to remove trailing slashes from the request path.\n    For example, a request to ``/foo/`` would redirect to ``/foo`` with this\n    decorator. Your request handler mapping should use a regular expression\n    like ``r'/foo/*'`` in conjunction with using the decorator.\n    \"\"\"\n    @functools.wraps(method)\n    def wrapper(self, *args, **kwargs):\n        if self.request.path.endswith(\"/\"):\n            if self.request.method in (\"GET\", \"HEAD\"):\n                uri = self.request.path.rstrip(\"/\")\n                if uri:  # don't try to redirect '/' to ''\n                    if self.request.query:\n                        uri += \"?\" + self.request.query\n                    self.redirect(uri, permanent=True)\n                    return\n            else:\n                raise HTTPError(404)\n        return method(self, *args, **kwargs)\n    return wrapper\ndef addslash(method):\n    \"\"\"Use this decorator to add a missing trailing slash to the request path.\n    For example, a request to ``/foo`` would redirect to ``/foo/`` with this\n    decorator. Your request handler mapping should use a regular expression\n", "outputs": ["    like ``r'/foo/?'`` in conjunction with using the decorator."], "input_length": 10857, "output_length": 13, "length": 10870, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "c0d5b4e90b76d5ffb9ecae690dfca08c781d7451a800637794aa09e682402eaa"}
{"input": "", "context": "#!/usr/bin/python\n#\n# This file is part of Ansible\n#\n# Ansible is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# Ansible is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.\n#\nANSIBLE_METADATA = {'status': ['preview'],\n                    'supported_by': 'community',\n                    'metadata_version': '1.0'}\nDOCUMENTATION = '''\n---\nmodule: ce_ntp_auth\nversion_added: \"2.4\"\nshort_description: Manages NTP authentication configuration on HUAWEI CloudEngine switches.\ndescription:\n    - Manages NTP authentication configuration on HUAWEI CloudEngine switches.\nauthor:\n    - Zhijin Zhou (@CloudEngine-Ansible)\nnotes:\n    - If C(state=absent), the module will attempt to remove the given key configuration.\n      If a matching key configuration isn't found on the device, the module will fail.\n    - If C(state=absent) and C(authentication=on), authentication will be turned on.\n    - If C(state=absent) and C(authentication=off), authentication will be turned off.\noptions:\n    key_id:\n        description:\n            - Authentication key identifier (numeric).\n        required: true\n    auth_pwd:\n        description:\n            - Plain text with length of 1 to 255, encrypted text with length of 20 to 392.\n        required: false\n        default: null\n    auth_mode:\n        description:\n            - Specify authentication algorithm.\n        required: false\n        default: null\n        choices: ['hmac-sha256', 'md5']\n    auth_type:\n        description:\n            - Whether the given password is in cleartext or\n              has been encrypted. If in cleartext, the device\n              will encrypt it before storing it.\n        required: false\n        default: encrypt\n        choices: ['text', 'encrypt']\n    trusted_key:\n        description:\n            - Whether the given key is required to be supplied by a time source\n              for the device to synchronize to the time source.\n        required: false\n        default: 'disable'\n        choices: ['enable', 'disable']\n    authentication:\n        description:\n            - Configure ntp authentication enable or unconfigure ntp authentication enable.\n        required: false\n        default: null\n        choices: ['enable', 'disable']\n    state:\n        description:\n            - Manage the state of the resource.\n        required: false\n        default: present\n        choices: ['present','absent']\n'''\nEXAMPLES = '''\n- name: NTP AUTH test\n  hosts: cloudengine\n  connection: local\n  gather_facts: no\n  vars:\n    cli:\n      host: \"{{ inventory_hostname }}\"\n      port: \"{{ ansible_ssh_port }}\"\n      username: \"{{ username }}\"\n      password: \"{{ password }}\"\n      transport: cli\n  tasks:\n  - name: \"Configure ntp authentication key-id\"\n    ce_ntp_auth:\n      key_id: 32\n      auth_mode: md5\n      auth_pwd: 11111111111111111111111\n      provider: \"{{ cli }}\"\n  - name: \"Configure ntp authentication key-id and trusted authentication keyid\"\n    ce_ntp_auth:\n      key_id: 32\n      auth_mode: md5\n      auth_pwd: 11111111111111111111111\n      trusted_key: enable\n      provider: \"{{ cli }}\"\n  - name: \"Configure ntp authentication key-id and authentication enable\"\n    ce_ntp_auth:\n      key_id: 32\n      auth_mode: md5\n      auth_pwd: 11111111111111111111111\n      authentication: enable\n      provider: \"{{ cli }}\"\n  - name: \"Unconfigure ntp authentication key-id and trusted authentication keyid\"\n    ce_ntp_auth:\n      key_id: 32\n      state: absent\n      provider: \"{{ cli }}\"\n  - name: \"Unconfigure ntp authentication key-id and authentication enable\"\n    ce_ntp_auth:\n      key_id: 32\n      authentication: enable\n      state: absent\n      provider: \"{{ cli }}\"\n'''\nRETURN = '''\nproposed:\n    description: k/v pairs of parameters passed into module\n    returned: always\n    type: dict\n    sample: {\n                \"auth_type\": \"text\",\n                \"authentication\": \"enable\",\n                \"key_id\": \"32\",\n                \"auth_pwd\": \"1111\",\n                \"auth_mode\": \"md5\",\n                \"trusted_key\": \"enable\",\n                \"state\": \"present\"\n            }\nexisting:\n    description: k/v pairs of existing ntp authentication\n    returned: always\n    type: dict\n    sample: {\n                \"authentication\": \"off\",\n                \"authentication-keyid\": [\n                    {\n                        \"auth_mode\": \"md5\",\n                        \"key_id\": \"1\",\n                        \"trusted_key\": \"disable\"\n                    }\n                ]\n            }\nend_state:\n    description: k/v pairs of ntp authentication after module execution\n    returned: always\n    type: dict\n    sample: {\n                \"authentication\": \"off\",\n                \"authentication-keyid\": [\n                    {\n                        \"auth_mode\": \"md5\",\n                        \"key_id\": \"1\",\n                        \"trusted_key\": \"disable\"\n                    },\n                    {\n                        \"auth_mode\": \"md5\",\n                        \"key_id\": \"32\",\n                        \"trusted_key\": \"enable\"\n                    }\n                ]\n            }\nstate:\n    description: state as sent in from the playbook\n    returned: always\n    type: string\n    sample: \"present\"\nupdates:\n    description: command sent to the device\n    returned: always\n    type: list\n    sample: [\n                \"ntp authentication-key 32 md5 1111\",\n                \"ntp trusted-key 32\",\n                \"ntp authentication enable\"\n            ]\nchanged:\n    description: check to see if a change was made on the device\n    returned: always\n    type: boolean\n    sample: true\n'''\nimport copy\nimport re\nfrom ansible.module_utils.basic import AnsibleModule\nfrom ansible.module_utils.ce import ce_argument_spec, load_config, get_nc_config, set_nc_config\nCE_NC_GET_NTP_AUTH_CONFIG = \"\"\"\n<filter type=\"subtree\">\n  <ntp xmlns=\"http://www.huawei.com/netconf/vrp\" content-version=\"1.0\" format-version=\"1.0\">\n    <ntpAuthKeyCfgs>\n      <ntpAuthKeyCfg>\n        <keyId>%s</keyId>\n        <mode></mode>\n        <keyVal></keyVal>\n        <isReliable></isReliable>\n      </ntpAuthKeyCfg>\n    </ntpAuthKeyCfgs>\n  </ntp>\n</filter>\n\"\"\"\nCE_NC_GET_ALL_NTP_AUTH_CONFIG = \"\"\"\n<filter type=\"subtree\">\n  <ntp xmlns=\"http://www.huawei.com/netconf/vrp\" content-version=\"1.0\" format-version=\"1.0\">\n    <ntpAuthKeyCfgs>\n      <ntpAuthKeyCfg>\n        <keyId></keyId>\n        <mode></mode>\n        <keyVal></keyVal>\n        <isReliable></isReliable>\n      </ntpAuthKeyCfg>\n    </ntpAuthKeyCfgs>\n  </ntp>\n</filter>\n\"\"\"\nCE_NC_GET_NTP_AUTH_ENABLE = \"\"\"\n<filter type=\"subtree\">\n  <ntp xmlns=\"http://www.huawei.com/netconf/vrp\" content-version=\"1.0\" format-version=\"1.0\">\n    <ntpSystemCfg>\n      <isAuthEnable></isAuthEnable>\n    </ntpSystemCfg>\n  </ntp>\n</filter>\n\"\"\"\nCE_NC_MERGE_NTP_AUTH_CONFIG = \"\"\"\n<config>\n  <ntp xmlns=\"http://www.huawei.com/netconf/vrp\" content-version=\"1.0\" format-version=\"1.0\">\n    <ntpAuthKeyCfgs>\n      <ntpAuthKeyCfg operation=\"merge\">\n        <keyId>%s</keyId>\n        <mode>%s</mode>\n        <keyVal>%s</keyVal>\n        <isReliable>%s</isReliable>\n      </ntpAuthKeyCfg>\n    </ntpAuthKeyCfgs>\n  </ntp>\n</config>\n\"\"\"\nCE_NC_MERGE_NTP_AUTH_ENABLE = \"\"\"\n<config>\n  <ntp xmlns=\"http://www.huawei.com/netconf/vrp\" content-version=\"1.0\" format-version=\"1.0\">\n    <ntpSystemCfg operation=\"merge\">\n      <isAuthEnable>%s</isAuthEnable>\n    </ntpSystemCfg>\n  </ntp>\n</config>\n\"\"\"\nCE_NC_DELETE_NTP_AUTH_CONFIG = \"\"\"\n<config>\n  <ntp xmlns=\"http://www.huawei.com/netconf/vrp\" content-version=\"1.0\" format-version=\"1.0\">\n    <ntpAuthKeyCfgs>\n      <ntpAuthKeyCfg operation=\"delete\">\n        <keyId>%s</keyId>\n      </ntpAuthKeyCfg>\n    </ntpAuthKeyCfgs>\n  </ntp>\n</config>\n\"\"\"\nclass NtpAuth(object):\n    \"\"\"Manage ntp authentication\"\"\"\n    def __init__(self, argument_spec):\n        self.spec = argument_spec\n        self.module = None\n        self.init_module()\n        # ntp_auth configration info\n        self.key_id = self.module.params['key_id']\n        self.password = self.module.params['auth_pwd'] or None\n        self.auth_mode = self.module.params['auth_mode'] or None\n        self.auth_type = self.module.params['auth_type']\n        self.trusted_key = self.module.params['trusted_key']\n        self.authentication = self.module.params['authentication'] or None\n        self.state = self.module.params['state']\n        self.check_params()\n        self.ntp_auth_conf = dict()\n        self.key_id_exist = False\n        self.cur_trusted_key = 'disable'\n        # state\n        self.changed = False\n        self.updates_cmd = list()\n        self.results = dict()\n        self.proposed = dict()\n        self.existing = list()\n        self.end_state = list()\n        self.get_ntp_auth_exist_config()\n    def check_params(self):\n        \"\"\"Check all input params\"\"\"\n        if not self.key_id.isdigit():\n            self.module.fail_json(\n                msg='Error: key_id is not digit.')\n        if (int(self.key_id) < 1) or (int(self.key_id) > 4294967295):\n            self.module.fail_json(\n                msg='Error: The length of key_id is between 1 and 4294967295.')\n        if self.state == \"present\":\n            if (self.auth_type == 'encrypt') and\\\n                    ((len(self.password) < 20) or (len(self.password) > 392)):\n                self.module.fail_json(\n                    msg='Error: The length of encrypted password is between 20 and 392.')\n            elif (self.auth_type == 'text') and\\\n                    ((len(self.password) < 1) or (len(self.password) > 255)):\n                self.module.fail_json(\n                    msg='Error: The length of text password is between 1 and 255.')\n    def init_module(self):\n        \"\"\"Init module object\"\"\"\n        required_if = [(\"state\", \"present\", (\"password\", \"auth_mode\"))]\n        self.module = AnsibleModule(\n            argument_spec=self.spec,\n            required_if=required_if,\n            supports_check_mode=True\n        )\n    def check_response(self, xml_str, xml_name):\n        \"\"\"Check if response message is already succeed.\"\"\"\n        if \"<ok/>\" not in xml_str:\n            self.module.fail_json(msg='Error: %s failed.' % xml_name)\n    def get_ntp_auth_enable(self):\n        \"\"\"Get ntp authentication enable state\"\"\"\n        xml_str = CE_NC_GET_NTP_AUTH_ENABLE\n        con_obj = get_nc_config(self.module, xml_str)\n        if \"<data/>\" in con_obj:\n            return\n        # get ntp authentication enable\n        auth_en = re.findall(\n            r'.*<isAuthEnable>(.*)</isAuthEnable>.*', con_obj)\n        if auth_en:\n            if auth_en[0] == 'true':\n                self.ntp_auth_conf['authentication'] = 'enable'\n            else:\n                self.ntp_auth_conf['authentication'] = 'disable'\n    def get_ntp_all_auth_keyid(self):\n        \"\"\"Get all authentication keyid info\"\"\"\n        ntp_auth_conf = list()\n        xml_str = CE_NC_GET_ALL_NTP_AUTH_CONFIG\n        con_obj = get_nc_config(self.module, xml_str)\n        if \"<data/>\" in con_obj:\n            self.ntp_auth_conf[\"authentication-keyid\"] = \"None\"\n            return ntp_auth_conf\n        # get ntp authentication config\n        ntp_auth = re.findall(\n            r'.*<keyId>(.*)</keyId>.*\\s*<mode>(.*)</mode>.*\\s*'\n            r'<keyVal>(.*)</keyVal>.*\\s*<isReliable>(.*)</isReliable>.*', con_obj)\n        for ntp_auth_num in ntp_auth:\n            if ntp_auth_num[0] == self.key_id:\n                self.key_id_exist = True\n                if ntp_auth_num[3] == 'true':\n                    self.cur_trusted_key = 'enable'\n                else:\n                    self.cur_trusted_key = 'disable'\n            if ntp_auth_num[3] == 'true':\n                trusted_key = 'enable'\n            else:\n                trusted_key = 'disable'\n            ntp_auth_conf.append(dict(key_id=ntp_auth_num[0],\n                                      auth_mode=ntp_auth_num[1].lower(),\n                                      trusted_key=trusted_key))\n        self.ntp_auth_conf[\"authentication-keyid\"] = ntp_auth_conf\n        return ntp_auth_conf\n    def get_ntp_auth_exist_config(self):\n        \"\"\"Get ntp authentication existed configure\"\"\"\n        self.get_ntp_auth_enable()\n        self.get_ntp_all_auth_keyid()\n    def config_ntp_auth_keyid(self):\n        \"\"\"Config ntp authentication keyid\"\"\"\n        if self.trusted_key == 'enable':\n            trusted_key = 'true'\n        else:\n            trusted_key = 'false'\n        xml_str = CE_NC_MERGE_NTP_AUTH_CONFIG % (\n            self.key_id, self.auth_mode.upper(), self.password, trusted_key)\n        ret_xml = set_nc_config(self.module, xml_str)\n        self.check_response(ret_xml, \"NTP_AUTH_KEYID_CONFIG\")\n    def config_ntp_auth_enable(self):\n        \"\"\"Config ntp authentication enable\"\"\"\n        if self.ntp_auth_conf['authentication'] != self.authentication:\n            if self.authentication == 'enable':\n                state = 'true'\n            else:\n                state = 'false'\n            xml_str = CE_NC_MERGE_NTP_AUTH_ENABLE % state\n            ret_xml = set_nc_config(self.module, xml_str)\n            self.check_response(ret_xml, \"NTP_AUTH_ENABLE\")\n    def undo_config_ntp_auth_keyid(self):\n        \"\"\"Undo ntp authentication key-id\"\"\"\n        xml_str = CE_NC_DELETE_NTP_AUTH_CONFIG % self.key_id\n        ret_xml = set_nc_config(self.module, xml_str)\n        self.check_response(ret_xml, \"UNDO_NTP_AUTH_KEYID_CONFIG\")\n    def cli_load_config(self, commands):\n        \"\"\"Load config by cli\"\"\"\n        if not self.module.check_mode:\n            load_config(self.module, commands)\n    def config_ntp_auth_keyid_by_cli(self):\n        \"\"\"Config ntp authentication keyid bye the way of CLI\"\"\"\n", "outputs": ["        commands = list()"], "input_length": 2374, "output_length": 5, "length": 2379, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "1ba449c545f32e4561baabc0420494dcf39868c4d67b798c9b7e7b243a46c99e"}
{"input": "", "context": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nfrom HttpUtils import App, buildOpener\nclass Device(object):\n    def __init__(self, token):\n        self.token = token\n        self.app = App()\n    def check_inspection(self):\n        data = self.app.check__inspection()\n        return data\n    def notification_postDevicetoken(self, loginId, password,\n                                     token=None, S=\"nosessionid\"):\n        if token == None:\n            token = self.token\n        params = {\n            \"S\": S,  # magic,don't touch\n            \"login_id\": loginId,\n            \"password\": password,\n            \"token\": token.encode(\"base64\")\n        }\n        data = self.app.notification_post__devicetoken(params)\n        return data\n    def newUser(self, loginId, password):\n        # self.notification_postDevicetoken(loginId, password)\n        return User(self.app, loginId, password)\nclass User(object):\n    def __init__(self, app, loginId, password):\n        self.login_id = loginId\n        self.password = password\n        self.app = app\n        self.session = None\n        self.userId = None\n        self.menu = Menu(self.app)\n        self.roundtable = RoundTable(self.app)\n        self.exploration = Exploration(self.app)\n    def login(self):\n        params = {\n            \"login_id\": self.login_id,\n            \"password\": self.password,\n        }\n        data = self.app.login(params)\n        self.session = data.response.header.session_id\n        self.userId = data.response.body.login.user_id\n        self.cardList = data.response.header.your_data.owner_card_list.user_card\n        return data\n    def mainmenu(self):\n        data = self.app.mainmenu()\n        return data\n    def endTutorial(self):\n        params = {\n            \"S\": self.session,\n            \"step\": '8000',\n        }\n        data = self.app.tutorial_next(params)\n        return data\n    def cardUpdate(self):\n        params = {\n            \"S\": self.session,\n            \"revision\": '0',\n        }\n        data = self.app.masterdata_card_update(params)\n        return data\n    def cardCategoryUpdate(self):\n        params = {\n            \"S\": self.session,\n            \"revision\": '0',\n        }\n        data = self.app.masterdata_card__category_update(params)\n        return data\n    def cardComboUpdate(self):\n        params = {\n            \"S\": self.session,\n            \"revision\": '0',\n        }\n        data = self.app.masterdata_combo_update(params)\n        return data\nclass RoundTable(object):\n    def __init__(self, app):\n        self.app = app\n    def edit(self):\n        params = {\n            \"move\": \"1\",\n        }\n        data = self.app.roundtable_edit(params)\n        return data\n    def save(self, cards, leader):\n        '7803549,15208758,17258743,empty,empty,empty,empty,empty,empty,empty,empty,empty'\n        '17258743'\n        cards = cards + [\"empty\"]*(12-len(cards))\n        params = {\n            \"C\": \",\".join(cards),\n            \"lr\": leader,\n        }\n        data = self.app.cardselect_savedeckcard(params)\n        return data\nclass Menu(object):\n    def __init__(self, app):\n        self.app = app\n    def menulist(self):\n        data = self.app.menu_menulist()\n        return data\n    def fairyselect(self):\n        data  = self.app.menu_fairyselect()\n        return data\n    def friendlist(self, move = \"0\"):\n        params = {\n            \"move\": \"0\",\n        }\n        data = self.app.menu_friendlist(params)\n        return data\n    def likeUser(self, users, dialog = \"1\"):\n        users = \",\".join(map(lambda x:str(x),users))\n        params = {\n            \"dialog\": dialog,\n            \"user_id\": users,\n        }\n        data = self.app.friend_like__user(params)\n        return data\nclass Exploration(object):\n    def __init__(self, app):\n        self.app = app\n    def getAreaList(self):\n        data = self.app.exploration_area()\n        return data\n    def getFloorList(self, areaId):\n        params = {\n            \"area_id\": areaId,\n        }\n        data = self.app.exploration_floor(params)\n        return data\n    def getFloorStatus(self, areaID, floorId, check=\"1\"):\n        params = {\n            \"area_id\": areaID,\n            \"floor_id\": floorId,\n            \"check\": check,  # magic,don't touch\n        }\n        data = self.app.exploration_get__floor(params)\n        return data\n    def explore(self, areaId, floorId, autoBuild=\"1\"):\n        params = {\n            \"area_id\": areaId,\n            \"floor_id\": floorId,\n            \"auto_build\": autoBuild,\n        }\n        data = self.app.exploration_explore(params)\n        return data\n    def fairyFloor(self, serialId, userId, check=\"1\"):\n        params = {\n            \"serial_id\": serialId,\n            \"user_id\": userId,\n            \"check\": check,  # magic,don't touch\n        }\n        data = self.app.exploration_fairy__floor(params)\n        return data\n    def fairybattle(self, serialId, userId):\n        params = {\n            \"serial_id\": serialId,\n            \"user_id\": userId,\n        }\n        data = self.app.exploration_fairybattle(params)\n        return data\n    def fairyhistory(self, serialId, userId):\n        params = {\n            \"serial_id\": serialId,\n            \"user_id\": userId,\n        }\n        data = self.app.exploration_fairyhistory(params)\n        return data\n    def fairyLose(self, serialId, userId):\n        params = {\n            \"serial_id\": serialId,\n            \"user_id\": userId,\n        }\n        data = self.app.exploration_fairy__lose(params)\n        return data\n    def faityWin(self, serialId, userId):\n        params = {\n            \"serial_id\": serialId,\n            \"user_id\": userId,\n        }\n        data = self.app.exploration_fairy__win(params)\n        return data\nif __name__ == \"__main__\":\n    from config import deviceToken, loginId, password\n", "outputs": ["    device = Device(token=deviceToken)"], "input_length": 988, "output_length": 6, "length": 994, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "171fb0f5e759a9cdd1d19b5dba0cda9da5f683fad3bd0ae9e8560ac39440f573"}
{"input": "", "context": "\"\"\"\nHigh-level QEMU test utility functions.\nThis module is meant to reduce code size by performing common test procedures.\nGenerally, code here should look like test code.\nMore specifically:\n    - Functions in this module should raise exceptions if things go wrong\n    - Functions in this module typically use functions and classes from\n      lower-level modules (e.g. utils_misc, qemu_vm, aexpect).\n    - Functions in this module should not be used by lower-level modules.\n    - Functions in this module should be used in the right context.\n      For example, a function should not be used where it may display\n      misleading or inaccurate info or debug messages.\n:copyright: 2008-2013 Red Hat Inc.\n\"\"\"\nimport os\nimport re\nimport six\nimport time\nimport logging\nfrom functools import reduce\nfrom avocado.core import exceptions\nfrom avocado.utils import path as utils_path\nfrom avocado.utils import process\nfrom avocado.utils import cpu as cpuutil\nfrom virttest import error_context\nfrom virttest import utils_misc\nfrom virttest import qemu_monitor\nfrom virttest.qemu_devices import qdevices\nfrom virttest.staging import utils_memory\nfrom virttest.compat_52lts import decode_to_text\ndef guest_active(vm):\n    o = vm.monitor.info(\"status\")\n    if isinstance(o, six.string_types):\n        return \"status: running\" in o\n    else:\n        if \"status\" in o:\n            return o.get(\"status\") == \"running\"\n        else:\n            return o.get(\"running\")\ndef get_numa_status(numa_node_info, qemu_pid, debug=True):\n    \"\"\"\n    Get the qemu process memory use status and the cpu list in each node.\n    :param numa_node_info: Host numa node information\n    :type numa_node_info: NumaInfo object\n    :param qemu_pid: process id of qemu\n    :type numa_node_info: string\n    :param debug: Print the debug info or not\n    :type debug: bool\n    :return: memory and cpu list in each node\n    :rtype: tuple\n    \"\"\"\n    node_list = numa_node_info.online_nodes\n    qemu_memory = []\n    qemu_cpu = []\n    cpus = cpuutil.get_pid_cpus(qemu_pid)\n    for node_id in node_list:\n        qemu_memory_status = utils_memory.read_from_numa_maps(qemu_pid,\n                                                              \"N%d\" % node_id)\n        memory = sum([int(_) for _ in list(qemu_memory_status.values())])\n        qemu_memory.append(memory)\n        cpu = [_ for _ in cpus if _ in numa_node_info.nodes[node_id].cpus]\n        qemu_cpu.append(cpu)\n        if debug:\n            logging.debug(\"qemu-kvm process using %s pages and cpu %s in \"\n                          \"node %s\" % (memory, \" \".join(cpu), node_id))\n    return (qemu_memory, qemu_cpu)\ndef pin_vm_threads(vm, node):\n    \"\"\"\n    Pin VM threads to single cpu of a numa node\n    :param vm: VM object\n    :param node: NumaNode object\n    \"\"\"\n    if len(vm.vcpu_threads) + len(vm.vhost_threads) < len(node.cpus):\n        for i in vm.vcpu_threads:\n            logging.info(\"pin vcpu thread(%s) to cpu(%s)\" %\n                         (i, node.pin_cpu(i)))\n        for i in vm.vhost_threads:\n            logging.info(\"pin vhost thread(%s) to cpu(%s)\" %\n                         (i, node.pin_cpu(i)))\n    elif (len(vm.vcpu_threads) <= len(node.cpus) and\n          len(vm.vhost_threads) <= len(node.cpus)):\n        for i in vm.vcpu_threads:\n            logging.info(\"pin vcpu thread(%s) to cpu(%s)\" %\n                         (i, node.pin_cpu(i)))\n        for i in vm.vhost_threads:\n            logging.info(\"pin vhost thread(%s) to extra cpu(%s)\" %\n                         (i, node.pin_cpu(i, extra=True)))\n    else:\n        logging.info(\"Skip pinning, no enough nodes\")\ndef _check_driver_verifier(session, driver, timeout=300):\n    \"\"\"\n    Check driver verifier status\n    :param session: VM session.\n    :param driver: The driver need to query\n    :param timeout: Timeout in seconds\n    \"\"\"\n    logging.info(\"Check %s driver verifier status\" % driver)\n    query_cmd = \"verifier /querysettings\"\n    output = session.cmd_output(query_cmd, timeout=timeout)\n    return (driver in output, output)\n@error_context.context_aware\ndef setup_win_driver_verifier(session, driver, vm, timeout=300):\n    \"\"\"\n    Enable driver verifier for windows guest.\n    :param driver: The driver which needs enable the verifier.\n    :param vm: VM object.\n    :param timeout: Timeout in seconds.\n    \"\"\"\n    verifier_status = _check_driver_verifier(session, driver)[0]\n    if not verifier_status:\n        error_context.context(\"Enable %s driver verifier\" % driver,\n                              logging.info)\n        verifier_setup_cmd = \"verifier /standard /driver %s.sys\" % driver\n        session.cmd(verifier_setup_cmd,\n                    timeout=timeout,\n                    ignore_all_errors=True)\n        session = vm.reboot(session)\n        verifier_status, output = _check_driver_verifier(session, driver)\n        if not verifier_status:\n            msg = \"%s verifier is not enabled, details: %s\" % (driver,\n                                                               output)\n            raise exceptions.TestFail(msg)\n    logging.info(\"%s verifier is enabled already\" % driver)\n    return session\ndef clear_win_driver_verifier(driver, vm, timeout=300):\n    \"\"\"\n    Clear the driver verifier in windows guest.\n    :param driver: The driver need to clear\n    :param vm: VM object.\n    :param timeout: Timeout in seconds.\n    \"\"\"\n    session = vm.wait_for_login(timeout=timeout)\n    try:\n        verifier_status = _check_driver_verifier(session, driver)[1]\n        if verifier_status:\n            logging.info(\"Clear driver verifier\")\n            verifier_clear_cmd = \"verifier /reset\"\n            session.cmd(verifier_clear_cmd,\n                        timeout=timeout,\n                        ignore_all_errors=True)\n            session = vm.reboot(session)\n    finally:\n        session.close()\n@error_context.context_aware\ndef windrv_verify_running(session, test, driver, timeout=300):\n    \"\"\"\n    Check if driver is running for windows guest within a period time.\n    :param session: VM session\n    :param test: Kvm test object\n    :param driver: The driver which needs to check.\n    :param timeout: Timeout in seconds.\n    \"\"\"\n    def _check_driver_stat():\n        \"\"\"\n        Check if driver is in Running status.\n        \"\"\"\n        output = session.cmd_output(driver_check_cmd, timeout=timeout)\n        if \"Running\" in output:\n            return True\n        return False\n    error_context.context(\"Check %s driver state.\" % driver, logging.info)\n    driver_check_cmd = (r'wmic sysdriver where PathName=\"C:\\\\Windows\\\\System32'\n                        r'\\\\drivers\\\\%s.sys\" get State /value') % driver\n    if not utils_misc.wait_for(_check_driver_stat, timeout, 0, 5):\n        test.error(\"%s driver is not running\" % driver)\n@error_context.context_aware\ndef windrv_check_running_verifier(session, vm, test, driver, timeout=300):\n    \"\"\"\n    Check whether the windows driver is running, then enable driver verifier.\n    :param vm: the VM that use the driver.\n    :param test: the KVM test object.\n    :param driver: the driver concerned.\n    :timeout: the timeout to use in this process, in seconds.\n    \"\"\"\n    windrv_verify_running(session, test, driver, timeout)\n    return setup_win_driver_verifier(session, driver, vm, timeout)\ndef setup_runlevel(params, session):\n    \"\"\"\n    Setup the runlevel in guest.\n    :param params: Dictionary with the test parameters.\n    :param session: VM session.\n    \"\"\"\n    cmd = \"runlevel\"\n    ori_runlevel = \"0\"\n    expect_runlevel = params.get(\"expect_runlevel\", \"3\")\n    # Note: All guest services may have not been started when\n    #       the guest gets IP addr; the guest runlevel maybe\n    #       is \"unknown\" whose exit status is 1 at that time,\n    #       which will cause the cmd execution failed. Need some\n    #       time here to wait for the guest services start.\n    if utils_misc.wait_for(lambda: session.cmd_status(cmd) == 0, 15):\n        ori_runlevel = session.cmd(cmd)\n    ori_runlevel = ori_runlevel.split()[-1]\n    if ori_runlevel == expect_runlevel:\n        logging.info(\"Guest runlevel is already %s as expected\" % ori_runlevel)\n    else:\n        session.cmd(\"init %s\" % expect_runlevel)\n        tmp_runlevel = session.cmd(cmd)\n        tmp_runlevel = tmp_runlevel.split()[-1]\n        if tmp_runlevel != expect_runlevel:\n            logging.warn(\"Changing runlevel from %s to %s failed (%s)!\",\n                         ori_runlevel, expect_runlevel, tmp_runlevel)\nclass GuestSuspend(object):\n    \"\"\"\n    Suspend guest, supports both Linux and Windows.\n    \"\"\"\n    SUSPEND_TYPE_MEM = \"mem\"\n    SUSPEND_TYPE_DISK = \"disk\"\n    def __init__(self, test, params, vm):\n        if not params or not vm:\n            raise exceptions.TestError(\"Missing 'params' or 'vm' parameters\")\n        self._open_session_list = []\n        self.test = test\n        self.vm = vm\n        self.params = params\n        self.login_timeout = float(self.params.get(\"login_timeout\", 360))\n        self.services_up_timeout = float(self.params.get(\"services_up_timeout\",\n                                                         30))\n        self.os_type = self.params.get(\"os_type\")\n    def _get_session(self):\n        self.vm.verify_alive()\n        session = self.vm.wait_for_login(timeout=self.login_timeout)\n        return session\n    def _session_cmd_close(self, session, cmd):\n        try:\n            return session.cmd_status_output(cmd)\n        finally:\n            try:\n                session.close()\n            except Exception:\n                pass\n    def _cleanup_open_session(self):\n        try:\n            for s in self._open_session_list:\n                if s:\n                    s.close()\n        except Exception:\n            pass\n    @error_context.context_aware\n    def setup_bg_program(self, **args):\n        \"\"\"\n        Start up a program as a flag in guest.\n        \"\"\"\n        suspend_bg_program_setup_cmd = args.get(\"suspend_bg_program_setup_cmd\")\n        error_context.context(\n            \"Run a background program as a flag\", logging.info)\n        session = self._get_session()\n        self._open_session_list.append(session)\n        logging.debug(\"Waiting all services in guest are fully started.\")\n        time.sleep(self.services_up_timeout)\n        session.sendline(suspend_bg_program_setup_cmd)\n    @error_context.context_aware\n    def check_bg_program(self, **args):\n        \"\"\"\n        Make sure the background program is running as expected\n        \"\"\"\n        suspend_bg_program_chk_cmd = args.get(\"suspend_bg_program_chk_cmd\")\n        error_context.context(\n            \"Verify background program is running\", logging.info)\n        session = self._get_session()\n        s, _ = self._session_cmd_close(session, suspend_bg_program_chk_cmd)\n        if s:\n            raise exceptions.TestFail(\n                \"Background program is dead. Suspend failed.\")\n    @error_context.context_aware\n    def kill_bg_program(self, **args):\n        error_context.context(\"Kill background program after resume\")\n        suspend_bg_program_kill_cmd = args.get(\"suspend_bg_program_kill_cmd\")\n        try:\n            session = self._get_session()\n            self._session_cmd_close(session, suspend_bg_program_kill_cmd)\n        except Exception as e:\n            logging.warn(\"Could not stop background program: '%s'\", e)\n            pass\n    @error_context.context_aware\n    def _check_guest_suspend_log(self, **args):\n        error_context.context(\"Check whether guest supports suspend\",\n                              logging.info)\n        suspend_support_chk_cmd = args.get(\"suspend_support_chk_cmd\")\n        session = self._get_session()\n        s, o = self._session_cmd_close(session, suspend_support_chk_cmd)\n        return s, o\n    def verify_guest_support_suspend(self, **args):\n        s, _ = self._check_guest_suspend_log(**args)\n        if s:\n            raise exceptions.TestError(\"Guest doesn't support suspend.\")\n    @error_context.context_aware\n    def start_suspend(self, **args):\n        suspend_start_cmd = args.get(\"suspend_start_cmd\")\n        error_context.context(\n            \"Start suspend [%s]\" % (suspend_start_cmd), logging.info)\n        session = self._get_session()\n        self._open_session_list.append(session)\n        # Suspend to disk\n        session.sendline(suspend_start_cmd)\n    @error_context.context_aware\n    def verify_guest_down(self, **args):\n        # Make sure the VM goes down\n        error_context.context(\"Wait for guest goes down after suspend\")\n        suspend_timeout = 240 + int(self.params.get(\"smp\")) * 60\n        if not utils_misc.wait_for(self.vm.is_dead, suspend_timeout, 2, 2):\n            raise exceptions.TestFail(\"VM refuses to go down. Suspend failed.\")\n    @error_context.context_aware\n    def resume_guest_mem(self, **args):\n        error_context.context(\"Resume suspended VM from memory\")\n        self.vm.monitor.system_wakeup()\n    @error_context.context_aware\n    def resume_guest_disk(self, **args):\n        error_context.context(\"Resume suspended VM from disk\")\n        self.vm.create()\n    @error_context.context_aware\n    def verify_guest_up(self, **args):\n        error_context.context(\"Verify guest system log\", logging.info)\n        suspend_log_chk_cmd = args.get(\"suspend_log_chk_cmd\")\n        session = self._get_session()\n", "outputs": ["        s, o = self._session_cmd_close(session, suspend_log_chk_cmd)"], "input_length": 2205, "output_length": 10, "length": 2215, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "02fba3875755b8b9891946196ee8bd23dbd880df9376a2a7157f6f39c101786d"}
{"input": "", "context": "package org.tanaguru.service;\nimport junit.framework.TestCase;\nimport org.tanaguru.crawler.CrawlerFactory;\nimport org.tanaguru.entity.audit.Audit;\nimport org.tanaguru.entity.audit.AuditImpl;\nimport org.tanaguru.entity.parameterization.*;\nimport org.tanaguru.entity.service.parameterization.ParameterDataService;\nimport org.tanaguru.factory.TanaguruCrawlerControllerFactory;\nimport org.tanaguru.service.mock.MockParameterDataService;\nimport java.util.HashSet;\nimport java.util.List;\nimport java.util.ResourceBundle;\nimport java.util.Set;\npublic class TanaguruCrawlerServiceImplTest extends TestCase {\n    private static final String FULL_SITE_CRAWL_URL_KEY = \"full-site-crawl-url\";\n    private static final String ROBOTS_RESTRICTED_CRAWL_URL_KEY =\n            \"robots-restricted-crawl-url\";\n    private static final String SITES_URL_BUNDLE_NAME = \"sites-url\";\n    private static final String PAGE_NAME_LEVEL1 = \"page-1.html\";\n    private static final String PAGE_NAME_LEVEL2 = \"page-2.html\";\n    private static final String FORBIDDEN_PAGE_NAME = \"page-access-forbidden-for-robots.html\";\n    private final ResourceBundle bundle =\n            ResourceBundle.getBundle(SITES_URL_BUNDLE_NAME);\n    private CrawlerService crawlerService;\n    private CrawlerFactory crawlerFactory;\n    private ParameterDataService mockParameterDataService;\n    public TanaguruCrawlerServiceImplTest(String testName) {\n        super(testName);\n    }\n    @Override\n    protected void setUp() throws Exception {\n        super.setUp();\n        mockParameterDataService = new MockParameterDataService();\n        crawlerFactory = new TanaguruCrawlerControllerFactory();\n        crawlerService = new TanaguruCrawlerServiceImpl();\n        crawlerService.setCrawlerFactory(crawlerFactory);\n        crawlerService.setParameterDataService(mockParameterDataService);\n        crawlerFactory.setOutputDir(\"/tmp/\");\n    }\n    @Override\n    protected void tearDown() throws Exception {\n        super.tearDown();\n    }\n    /**\n     *\n     * @param siteUrl\n     * @param depth\n     * @param exclusionRegex\n     * @param inlusionRegex\n     * @param maxDuration\n     * @param maxDocuments\n     * @param proxyHost\n     * @param proxyPort\n     * @return\n     */\n    private List<String> initialiseAndLaunchCrawl(\n            String siteUrl,\n            int depth,\n            String exclusionRegex,\n            String inclusionRegex,\n            long maxDuration,\n            int maxDocuments) {\n        Audit audit = new AuditImpl();\n        audit.setParameterSet(setCrawlParameters(String.valueOf(depth),exclusionRegex, inclusionRegex, String.valueOf(maxDuration), String.valueOf(maxDocuments)));\n        return  crawlerService.getUrlListByCrawlingFromUrl(audit, siteUrl);\n    }\n    public void testCrawl_SiteWithDepthLevel0Option() {\n        System.out.println(\"crawl_full_site_With_Depth_Level0_Option\");\n        String siteUrl = bundle.getString(FULL_SITE_CRAWL_URL_KEY);\n        List<String> contentList = initialiseAndLaunchCrawl(siteUrl, 0, \"\", \"\", 86400L, 10000);\n        assertEquals(1, contentList.size());\n        assertTrue(contentList.contains(siteUrl));\n    }\n    public void testCrawl_SiteWithDepthLevel1Option() {\n        System.out.println(\"crawl_full_site_With_Depth_Level1_Option\");\n        String siteUrl = bundle.getString(FULL_SITE_CRAWL_URL_KEY);\n        List<String> contentList = initialiseAndLaunchCrawl(siteUrl, 1, \"\", \"\", 86400L, 10000);\n        assertEquals(3, contentList.size());\n        assertTrue(contentList.contains(siteUrl));\n        assertTrue(contentList.contains(siteUrl + PAGE_NAME_LEVEL1));\n        assertTrue(contentList.contains(siteUrl + FORBIDDEN_PAGE_NAME));\n    }\n    public void testCrawl_SiteWithRegexpExclusionOption() {\n        System.out.println(\"crawl_full_site_With_Regexp_Exclusion_Option\");\n        String siteUrl = bundle.getString(FULL_SITE_CRAWL_URL_KEY);\n        List<String> contentList = initialiseAndLaunchCrawl(siteUrl, 4, \".html\", \"\", 86400L, 10000);\n        assertEquals(1, contentList.size());\n        assertTrue(contentList.contains(siteUrl));\n    }\n    public void testCrawl_SiteWithRegexpInclusionOption() {\n        System.out.println(\"crawl_full_site_With_Regexp_Inclusion_Option\");\n        String siteUrl = bundle.getString(FULL_SITE_CRAWL_URL_KEY)+\"page-1.html\";\n        List<String> contentList = initialiseAndLaunchCrawl(siteUrl, 2, \"\", \"page-\", 86400L, 10000);\n        assertEquals(3, contentList.size());\n        assertTrue(contentList.contains(siteUrl));\n        assertTrue(contentList.contains(bundle.getString(FULL_SITE_CRAWL_URL_KEY) + PAGE_NAME_LEVEL2));\n        assertTrue(contentList.contains(bundle.getString(FULL_SITE_CRAWL_URL_KEY) + FORBIDDEN_PAGE_NAME));\n    }\n    public void testCrawl_SiteWithRegexpInclusionOption2() {\n        System.out.println(\"crawl_full_site_With_Regexp_Inclusion_Option 2\");\n        String siteUrl = bundle.getString(FULL_SITE_CRAWL_URL_KEY)+\"page-1.html\";\n        List<String> contentList = initialiseAndLaunchCrawl(siteUrl, 2, \"\", \"page-\\\\d\", 86400L, 10);\n        assertEquals(2, contentList.size());\n        assertTrue(contentList.contains(siteUrl));\n        assertTrue(contentList.contains(bundle.getString(FULL_SITE_CRAWL_URL_KEY) + PAGE_NAME_LEVEL2));\n    }\n    public void testCrawl_SiteWithRegexpInclusionOption3() {\n        System.out.println(\"crawl_full_site_With_Regexp_Inclusion_Option 3\");\n        String siteUrl = bundle.getString(FULL_SITE_CRAWL_URL_KEY);\n        List<String> contentList = initialiseAndLaunchCrawl(siteUrl, 2, \"\", \"page-\\\\d\", 86400L, 10);\n        assertEquals(3, contentList.size());\n        assertTrue(contentList.contains(siteUrl));\n        assertTrue(contentList.contains(siteUrl + PAGE_NAME_LEVEL1));\n        assertTrue(contentList.contains(siteUrl + PAGE_NAME_LEVEL2));\n    }\n    public void testCrawl_SiteWithRegexpExclusionOption2() {\n        System.out.println(\"crawl_full_site_With_Regexp_Exclusion_Option2\");\n        String siteUrl = bundle.getString(FULL_SITE_CRAWL_URL_KEY);\n        List<String> contentList = initialiseAndLaunchCrawl(siteUrl, 4, \"robot\", \"\", 86400L, 10000);\n        assertEquals(3, contentList.size());\n        assertTrue(contentList.contains(siteUrl));\n        assertTrue(contentList.contains(siteUrl + PAGE_NAME_LEVEL1));\n        assertTrue(contentList.contains(siteUrl + PAGE_NAME_LEVEL2));\n    }\n    public void testCrawl_SiteWithRegexpExclusionOption3() {\n        System.out.println(\"crawl_full_site_With_Regexp_Exclusion_Option3\");\n        String siteUrl = bundle.getString(FULL_SITE_CRAWL_URL_KEY);\n        List<String> contentList = initialiseAndLaunchCrawl(siteUrl, 4, \"robot;page-2\", \"\", 86400L, 10000);\n        assertEquals(2, contentList.size());\n        assertTrue(contentList.contains(siteUrl));\n        assertTrue(contentList.contains(siteUrl + PAGE_NAME_LEVEL1));\n    }\n    /**\n     * * Test the crawl of a site without robots.txt file\n     */\n    public void testCrawl_Site() {\n        System.out.println(\"crawl_full_site\");\n        String siteUrl = bundle.getString(FULL_SITE_CRAWL_URL_KEY);\n        List<String> contentList = initialiseAndLaunchCrawl(siteUrl, 3, \"\", \"\", 86400L, 10000);\n        assertEquals(4, contentList.size());\n        assertTrue(contentList.contains(siteUrl));\n        assertTrue(contentList.contains(siteUrl + PAGE_NAME_LEVEL1));\n        assertTrue(contentList.contains(siteUrl + PAGE_NAME_LEVEL2));\n        assertTrue(contentList.contains(siteUrl + FORBIDDEN_PAGE_NAME));\n    }\n    /**\n     * Test the crawl of a page\n     */\n    public void testCrawl_Page() {\n        System.out.println(\"crawl_page\");\n        String siteUrl = bundle.getString(FULL_SITE_CRAWL_URL_KEY);\n        Audit audit = new AuditImpl();\n        audit.setParameterSet(setCrawlParameters(\"3\", \"\", \"\", \"\", \"\"));\n        List<String> contentList = crawlerService.getUrlListByCrawlingFromUrl(audit, siteUrl);\n        assertEquals(1, contentList.size());\n        assertTrue(contentList.contains(siteUrl));\n        assertFalse(contentList.contains(siteUrl + PAGE_NAME_LEVEL1));\n        assertFalse(contentList.contains(siteUrl + PAGE_NAME_LEVEL2));\n        assertFalse(contentList.contains(siteUrl + FORBIDDEN_PAGE_NAME));\n    }\n    /**\n     * Test the crawl of a site with robots.txt file\n     */\n    public void testCrawl_Site_With_Robots() {\n        System.out.println(\"crawl_site_with_robots\");\n        String siteUrl = bundle.getString(ROBOTS_RESTRICTED_CRAWL_URL_KEY);\n        List<String> contentList = initialiseAndLaunchCrawl(siteUrl, 3, \"\", \"\", 86400L, 10000);\n        assertEquals(3, contentList.size());\n        assertTrue(contentList.contains(siteUrl));\n        assertTrue(contentList.contains(siteUrl + PAGE_NAME_LEVEL1));\n        assertTrue(contentList.contains(siteUrl + PAGE_NAME_LEVEL2));\n        assertFalse(contentList.contains(siteUrl + FORBIDDEN_PAGE_NAME));\n    }\n    /**\n     *\n     * @param depth\n     * @param exclusionRegexp\n     * @param inclusionRegexp\n     * @param maxDuration\n     * @param maxDocuments\n     * @param proxyHost\n     * @param proxyPort\n     * @return The set of Parameters regarding options set as argument\n     */\n    private Set<Parameter> setCrawlParameters(\n            String depth,\n            String exclusionRegexp,\n            String inclusionRegexp,\n            String maxDuration,\n            String maxDocuments) {\n        Set<Parameter> crawlParameters = new HashSet<>();\n        ParameterFamily pf = new ParameterFamilyImpl();\n        pf.setParameterFamilyCode(\"CRAWLER\");\n        //DEPTH\n", "outputs": ["        ParameterElement ped = new ParameterElementImpl();"], "input_length": 1379, "output_length": 8, "length": 1387, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "f47edb71cc4716220bb2108024a86397c2bbca38f6fd53707513410ca4a1b034"}
{"input": "", "context": "import sys\nimport pdb\nfrom socket import IPPROTO_TCP, IPPROTO_UDP, IPPROTO_ICMP\nimport logging\nfrom ipaddr import IPv4Address\nfrom struct import pack as spack\nfrom pytricia import PyTricia\nimport socket\nfrom fslib.node import Node, PortInfo\nfrom fslib.link import NullLink\nfrom fslib.common import fscore, get_logger\nfrom fslib.flowlet import Flowlet, FlowIdent\nfrom fslib.util import default_ip_to_macaddr\nfrom fslib.configurator import FsConfigurator\nfrom fslib.openflow import load_pox_component, load_odl_component\nfrom pox.openflow import libopenflow_01 as oflib\nimport pox.core\nfrom pox.lib.addresses import *\nimport pox.lib.packet as pktlib\nfrom pox.lib.util import dpid_to_str\nimport pox.openflow.of_01 as ofcore\nfrom pox.datapaths.switch import SoftwareSwitch\nclass UnhandledPoxPacketFlowletTranslation(Exception):\n    pass\nclass PoxFlowlet(Flowlet):\n    __slots__ = ['origpkt']\n    def __init__(self, ident):\n        Flowlet.__init__(self, ident)\n        self.origpkt = None\nclass OpenflowMessage(Flowlet):\n    __slots__ = ['ofmsg']\n    def __init__(self, ident, ofmsg):\n        Flowlet.__init__(self, ident)\n        self.ofmsg = ofmsg\n        self.bytes = len(ofmsg)\ndef flowlet_to_packet(flowlet):\n    if hasattr(flowlet, \"origpkt\"):\n        return getattr(flowlet, \"origpkt\")\n    ident = flowlet.ident.key\n    etherhdr = pktlib.ethernet()\n    etherhdr.src = EthAddr(flowlet.srcmac)\n    etherhdr.dst = EthAddr(flowlet.dstmac)\n    etherhdr.type = pktlib.ethernet.IP_TYPE\n    ipv4 = pktlib.ipv4() \n    ipv4.srcip = IPAddr(ident.srcip)\n    ipv4.dstip = IPAddr(ident.dstip)\n    ipv4.protocol = ident.ipproto\n    ipv4.tos = flowlet.iptos\n    iplen = flowlet.bytes / flowlet.pkts\n    ipv4.iplen = iplen\n    payloadlen = 0\n    etherhdr.payload = ipv4\n    if ident.ipproto == IPPROTO_ICMP:\n        layer4 = pktlib.icmp()\n        layer4.type = ident.dport >> 8\n        layer4.code = ident.dport & 0x00FF\n        payloadlen = max(iplen-28,0)\n    elif ident.ipproto == IPPROTO_UDP:\n        layer4 = pktlib.udp()\n        layer4.srcport = ident.sport \n        layer4.dstport = ident.dport \n    elif ident.ipproto == IPPROTO_TCP:\n        layer4 = pktlib.tcp()\n        layer4.srcport = ident.sport \n        layer4.dstport = ident.dport \n        layer4.flags = flowlet.tcpflags\n        layer4.off = 5\n        payloadlen = max(iplen-40,0)\n        layer4.tcplen = payloadlen\n        layer4.payload = spack('{}x'.format(payloadlen))\n    else:\n        raise UnhandledPoxPacketFlowletTranslation(\"Can't translate IP protocol {} from flowlet to POX packet\".format(fident.ipproto))\n    ipv4.payload = layer4\n    etherhdr.origflet = flowlet\n    return etherhdr\ndef packet_to_flowlet(pkt):\n    try:\n        return getattr(pkt, \"origflet\")\n    except AttributeError,e:\n        log = get_logger()\n        flet = None\n        ip = pkt.find('ipv4')\n        if ip is None:\n            flet = PoxFlowlet(FlowIdent())\n            log.debug(\"Received non-IP packet {} from POX: there's no direct translation to fs\".format(str(pkt.payload)))\n        else:\n            dport = sport = tcpflags = 0\n            if ip.protocol == IPPROTO_TCP:\n                tcp = ip.payload\n                sport = tcp.srcport\n                dport = tcp.dstport\n                tcpflags = tcp.flags\n                log.debug(\"Translating POX TCP packet to fs {}\".format(tcp))\n            elif ip.protocol == IPPROTO_UDP:\n                udp = ip.payload\n                sport = udp.srcport\n                dport = udp.dstport\n                log.debug(\"Translating POX UDP packet to fs {}\".format(udp))\n            elif ip.protocol == IPPROTO_ICMP:\n                icmp = ip.payload\n                dport = (icmp.type << 8) | icmp.code\n                log.debug(\"Translating POX ICMP packet to fs {}\".format(icmp))\n            else:\n                log.warn(\"Received unhandled IPv4 packet {} from POX: can't translate to fs\".format(str(ip.payload)))\n            flet = PoxFlowlet(FlowIdent(srcip=ip.srcip, dstip=ip.dstip, ipproto=ip.protocol, sport=sport, dport=dport))\n            flet.tcpflags = tcpflags\n            flet.iptos = ip.tos\n        flet.srcmac = pkt.src\n        flet.dstmac = pkt.dst\n        flet.pkts = 1\n        flet.bytes = len(pkt)\n        flet.origpkt = pkt\n        return flet\nclass PoxBridgeSoftwareSwitch(SoftwareSwitch):\n    def __init__(self, *args, **kwargs):\n        SoftwareSwitch.__init__(self, *args, **kwargs)\n    def _output_packet_physical(self, packet, port_num):\n        self.forward(packet, port_num)\n        SoftwareSwitch._output_packet_physical(self, packet, port_num)\n    def set_output_packet_callback(self, fn):\n        self.forward = fn\n    # start here\n    '''\n    def _get_table_entry(self, dpid):\n        print self.pox_switch\n    '''\nclass OpenflowSwitch(Node):\n    __slots__ = ['dpid', 'pox_switch', 'controller_name', 'controller_links', 'ipdests', \n                 'interface_to_port_map', 'trafgen_ip', 'autoack', 'trafgen_mac', 'dstmac_cache',\n                 'trace','tracePkt']\n    def __init__(self, name, measurement_config, **kwargs):\n        Node.__init__(self, name, measurement_config, **kwargs)\n        self.dpid = abs(hash(name))\n        self.dstmac_cache = {}\n        self.pox_switch = PoxBridgeSoftwareSwitch(self.dpid, name=name, \n            ports=0, miss_send_len=2**16, max_buffers=2**8, features=None)\n        self.pox_switch.set_connection(self)\n        self.pox_switch.set_output_packet_callback(self. send_packet)\n        self.controller_name = kwargs.get('controller', 'controller')\n        self.autoack = bool(eval(kwargs.get('autoack', 'False')))\n        self.controller_links = {}\n        self.interface_to_port_map = {}\n        self.trace = bool(eval(kwargs.get('trace', 'False')))\n        self.tracePkt = bool(eval(kwargs.get('tracePkt','False')))\n        self.ipdests = PyTricia()\n        for prefix in kwargs.get('ipdests','').split():\n            self.ipdests[prefix] = True\n        # explicitly add a localhost link/interface\n        ipa,ipb = [ ip for ip in next(FsConfigurator.link_subnetter).iterhosts() ]\n        remotemac = default_ip_to_macaddr(ipb)\n        self.add_link(NullLink, ipa, ipb, 'remote', remotemac=remotemac)\n        self.trafgen_ip = str(ipa)\n        self.trafgen_mac = remotemac\n        self.dstmac_cache[self.name] = remotemac\n    @property\n    def remote_macaddr(self):\n        return self.trafgen_mac\n    def send_packet(self, packet, port_num):\n        '''Forward a data plane packet out a given port'''\n        flet = packet_to_flowlet(packet)\n        # has packet reached destination?\n        if flet is None or self.ipdests.get(flet.dstaddr, None):\n            return\n        pinfo = self.ports[port_num]\n        # self.logger.debug(\"Switch sending translated packet {}->{} from {}->{} on port {} to {}\".format(packet, flet, flet.srcmac, flet.dstmac, port_num, pinfo.link.egress_name))\n        pinfo.link.flowlet_arrival(flet, self.name, pinfo.remoteip)\n    def send(self, ofmessage):\n        '''Callback function for POX SoftwareSwitch to send an outgoing OF message\n        to controller.'''\n        if not self.started:\n            # self.logger.debug(\"OF switch-to-controller deferred message {}\".format(ofmessage))\n            evid = 'deferred switch->controller send'\n            fscore().after(0.0, evid, self.send, ofmessage)\n        else:\n            # self.logger.debug(\"OF switch-to-controller {} - {}\".format(str(self.controller_links[self.controller_name]), ofmessage))\n            clink = self.controller_links[self.controller_name]\n            self.controller_links[self.controller_name].flowlet_arrival(OpenflowMessage(FlowIdent(), ofmessage), self.name, self.controller_name)\n    def set_message_handler(self, *args):\n        '''Dummy callback function for POX SoftwareSwitchBase'''\n        pass\n    def process_packet(self, poxpkt, inputport):\n        '''Process an incoming POX packet.  Mainly want to check whether\n        it's an ARP and update our ARP \"table\" state'''\n        # self.logger.debug(\"Switch {} processing packet: {}\".format(self.name, str(poxpkt)))\n        if poxpkt.type == poxpkt.ARP_TYPE:\n            if poxpkt.payload.opcode == pktlib.arp.REQUEST:\n                self.logger.debug(\"Got ARP request: {}\".format(str(poxpkt.payload)))\n                arp = poxpkt.payload\n                dstip = str(IPv4Address(arp.protodst))\n                srcip = str(IPv4Address(arp.protosrc))\n                if dstip in self.interface_to_port_map:\n                    portnum = self.interface_to_port_map[dstip]\n", "outputs": ["                    pinfo = self.ports[portnum]"], "input_length": 1343, "output_length": 6, "length": 1349, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "b67e980bff6abc547392e6da63ba6430cccceeb8d76d9ce5153227749f8b759b"}
{"input": "", "context": " /* KIARA - Middleware for efficient and QoS/Security-aware invocation of services and exchange of messages\n *\n * Copyright (C) 2014 Proyectos y Sistemas de Mantenimiento S.L. (eProsima)\n *\n * This library is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 3 of the License, or (at your option) any later version.\n *\n * This library is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with this library. If not, see <http://www.gnu.org/licenses/>.\n *\n *\n * @file EnumSwitchUnion.java\n * This file contains the class representing a user defined union.\n *\n * This file was generated by using the tool Kiaragen.\n *\n */\n \n \npackage org.fiware.kiara.serialization.types;\nimport java.io.IOException;\nimport org.fiware.kiara.serialization.impl.Serializable;\nimport org.fiware.kiara.serialization.impl.SerializerImpl;\nimport org.fiware.kiara.serialization.impl.CDRSerializer;\nimport org.fiware.kiara.transport.impl.TransportMessage;\nimport java.util.List;\nimport java.util.ArrayList;\nimport java.util.Objects;\nimport org.fiware.kiara.serialization.impl.BasicSerializers;\nimport org.fiware.kiara.serialization.impl.BinaryInputStream;\nimport org.fiware.kiara.serialization.impl.BinaryOutputStream;\nimport org.fiware.kiara.serialization.impl.Serializable;\nimport org.fiware.kiara.serialization.impl.SerializerImpl;\nimport org.fiware.kiara.serialization.impl.CDRSerializer;\nimport org.fiware.kiara.serialization.impl.ListAsArraySerializer;\nimport org.fiware.kiara.serialization.impl.ListAsSequenceSerializer;\nimport org.fiware.kiara.serialization.impl.Serializer;\nimport org.fiware.kiara.serialization.impl.MapAsMapSerializer;\nimport org.fiware.kiara.serialization.impl.SetAsSetSerializer;\nimport org.fiware.kiara.serialization.impl.ObjectSerializer;\nimport org.fiware.kiara.serialization.impl.EnumSerializer;\npublic class EnumSwitchUnion implements Serializable {\n\tprivate EnumSwitcher m_d;\n\tprivate int intVal;\n\tprivate java.lang.String stringVal;\n\tprivate float floatVal;\n\t\n\tpublic EnumSwitchUnion() {\n\t\tthis.intVal = 0;\n\t\tthis.stringVal = \"\";\n\t\tthis.floatVal = (float) 0.0;\n\t}\n\t\n\tpublic void _d(EnumSwitcher discriminator) {\n\t\tthis.m_d = discriminator;\n\t}\n\t\n\t/*\n\t * @param other An object instance of Object\n\t */\n\t @Override\n\tpublic boolean equals(Object other) {\n\t\tboolean comparison = true;\n\t\t\n\t\tif (other instanceof EnumSwitchUnion) {\n\t\t\n\t\t\tswitch(this.m_d) {\n\t\t\n\t\t\t\tcase option_1:\n\t\t\t\tcase option_2:\n\t\t\t\t\tcomparison = comparison && (this.intVal == ((EnumSwitchUnion) other).intVal);\n\t\t\t\t\tbreak;\n\t\t\t\tcase option_3:\n\t\t\t\t\tcomparison = comparison && (this.stringVal.compareTo(((EnumSwitchUnion) other).stringVal) == 0);\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\tcomparison = comparison && (this.floatVal == ((EnumSwitchUnion) other).floatVal);\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\t\n\t\treturn comparison;\n\t}\n\t\n\t/*\n\t * This method serializes a EnumSwitchUnion.\n\t *\n\t * @see org.fiware.kiara.serialization.impl.Serializable#serialize(org.fiware.kiara.serialization.impl.SerializerImpl, org.fiware.kiara.serialization.impl.BinaryOutputStream, java.lang.String)\n\t */\n\t@Override\n\tpublic void serialize(SerializerImpl impl, BinaryOutputStream message, String name) throws IOException {\n\t\timpl.serializeEnum(message, name, this.m_d);\n\t\tswitch(this.m_d) {\n\t\t\tcase option_1:\n\t\t\tcase option_2:\n\t\t\t\timpl.serializeI32(message, name, this.intVal);\n\t\t\t\tbreak;\n\t\t\tcase option_3:\n\t\t\t\timpl.serializeString(message, name, this.stringVal);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\timpl.serializeFloat32(message, name, this.floatVal);\n\t\t\t\tbreak;\n\t\t}\n\t}\n\t/*\n\t * This method deserializes a EnumSwitchUnion.\n\t *\n\t * @see org.fiware.kiara.serialization.impl.Serializable#deserialize(org.fiware.kiara.serialization.impl.SerializerImpl, org.fiware.kiara.serialization.impl.BinaryInputStream, java.lang.String)\n\t */\n\t@Override\n\tpublic void deserialize(SerializerImpl impl, BinaryInputStream message, String name) throws IOException {\n\t\tthis.m_d = impl.deserializeEnum(message, name, EnumSwitcher.class);\n\t\tswitch(this.m_d) {\n\t\t\tcase option_1:\n\t\t\tcase option_2:\n\t\t\t\tthis.intVal = impl.deserializeI32(message, name);\n\t\t\t\tbreak;\n\t\t\tcase option_3:\n\t\t\t\tthis.stringVal = impl.deserializeString(message, name);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tthis.floatVal = impl.deserializeFloat32(message, name);\n\t\t\t\tbreak;\n\t\t}\n\t}\n\t\n\t/*\n\t * Method to get the attribute intVal.\n\t */\n\tpublic int getIntVal() {\n\t\tboolean canDoIt = false;\n\t\tswitch(this.m_d) {\n\t\t\tcase option_1:\n\t\t\tcase option_2:\n\t\t\t\tcanDoIt=true;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t}\n\t\tif (!canDoIt) {\n\t\t\tthrow new UnsupportedOperationException(\"Invalid union value\");\n\t\t}\n\t\treturn this.intVal;\n\t}\n\t/*\n\t * Method to set the attribute intVal.\n\t */\n\tpublic void setIntVal(int intVal) {\n\t\tboolean canDoIt = false;\n\t\tswitch(this.m_d) {\n\t\t\tcase option_1:\n\t\t\tcase option_2:\n\t\t\t\tcanDoIt=true;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t}\n\t\tif (!canDoIt) {\n\t\t\tthrow new UnsupportedOperationException(\"Invalid union value\");\n\t\t}\n\t\tthis.intVal = intVal;\n\t}\n\t/*\n\t * Method to get the attribute stringVal.\n\t */\n\tpublic java.lang.String getStringVal() {\n\t\tboolean canDoIt = false;\n\t\tswitch(this.m_d) {\n\t\t\tcase option_3:\n\t\t\t\tcanDoIt=true;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t}\n\t\tif (!canDoIt) {\n\t\t\tthrow new UnsupportedOperationException(\"Invalid union value\");\n\t\t}\n\t\treturn this.stringVal;\n\t}\n\t/*\n\t * Method to set the attribute stringVal.\n\t */\n\tpublic void setStringVal(java.lang.String stringVal) {\n\t\tboolean canDoIt = false;\n\t\tswitch(this.m_d) {\n\t\t\tcase option_3:\n\t\t\t\tcanDoIt=true;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t}\n\t\tif (!canDoIt) {\n\t\t\tthrow new UnsupportedOperationException(\"Invalid union value\");\n\t\t}\n\t\tthis.stringVal = stringVal;\n\t}\n\t/*\n\t * Method to get the attribute floatVal.\n\t */\n\tpublic float getFloatVal() {\n\t\tboolean canDoIt = false;\n\t\tswitch(this.m_d) {\n\t\t\tcase option_1:\n\t\t\tcase option_2:\n\t\t\t\tbreak;\n\t\t\tcase option_3:\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tcanDoIt=true;\n\t\t\t\tbreak;\n\t\t}\n\t\tif (!canDoIt) {\n\t\t\tthrow new UnsupportedOperationException(\"Invalid union value\");\n\t\t}\n\t\treturn this.floatVal;\n\t}\n\t/*\n\t * Method to set the attribute floatVal.\n\t */\n\tpublic void setFloatVal(float floatVal) {\n\t\tboolean canDoIt = false;\n\t\tswitch(this.m_d) {\n\t\t\tcase option_1:\n\t\t\tcase option_2:\n\t\t\t\tbreak;\n\t\t\tcase option_3:\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tcanDoIt=true;\n\t\t\t\tbreak;\n\t\t}\n\t\tif (!canDoIt) {\n\t\t\tthrow new UnsupportedOperationException(\"Invalid union value\");\n\t\t}\n\t\tthis.floatVal = floatVal;\n\t}\n\t\n\t/*\n\t *This method calculates the maximum size in CDR for this class.\n\t * \n\t * @param current_alignment Integer containing the current position in the buffer.\n\t */\n\tpublic static int getMaxCdrSerializedSize(int current_alignment)\n\t{\n\t    int current_align = current_alignment;\n\t    int sum = 0;\n\t    int current_sum = 0;\n\t    \n\t    current_align += 4 + CDRSerializer.alignment(current_align, 4); // Enum type\n\t            \n", "outputs": ["\t    current_sum += 4 + CDRSerializer.alignment(current_sum, 4);"], "input_length": 1118, "output_length": 11, "length": 1129, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "88dd178b36d1ffeb53e118949514a0345c98ee2bb3368f2dca6577ec7330da0f"}
{"input": "", "context": "using System;\nusing iTextSharp.text;\n/*\n * $Id: Barcode39.cs,v 1.5 2006/09/17 15:58:51 psoares33 Exp $\n *\n * Copyright 2002-2006 by Paulo Soares.\n *\n * The contents of this file are subject to the Mozilla Public License Version 1.1\n * (the \"License\"); you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at http://www.mozilla.org/MPL/\n *\n * Software distributed under the License is distributed on an \"AS IS\" basis,\n * WITHOUT WARRANTY OF ANY KIND, either express or implied. See the License\n * for the specific language governing rights and limitations under the License.\n *\n * The Original Code is 'iText, a free JAVA-PDF library'.\n *\n * The Initial Developer of the Original Code is Bruno Lowagie. Portions created by\n * the Initial Developer are Copyright (C) 1999, 2000, 2001, 2002 by Bruno Lowagie.\n * All Rights Reserved.\n * Co-Developer of the code is Paulo Soares. Portions created by the Co-Developer\n * are Copyright (C) 2000, 2001, 2002 by Paulo Soares. All Rights Reserved.\n *\n * Contributor(s): all the names of the contributors are added in the source code\n * where applicable.\n *\n * Alternatively, the contents of this file may be used under the terms of the\n * LGPL license (the \"GNU LIBRARY GENERAL PUBLIC LICENSE\"), in which case the\n * provisions of LGPL are applicable instead of those above.  If you wish to\n * allow use of your version of this file only under the terms of the LGPL\n * License and not to allow others to use your version of this file under\n * the MPL, indicate your decision by deleting the provisions above and\n * replace them with the notice and other provisions required by the LGPL.\n * If you do not delete the provisions above, a recipient may use your version\n * of this file under either the MPL or the GNU LIBRARY GENERAL PUBLIC LICENSE.\n *\n * This library is free software; you can redistribute it and/or modify it\n * under the terms of the MPL as stated above or under the terms of the GNU\n * Library General Public License as published by the Free Software Foundation;\n * either version 2 of the License, or any later version.\n *\n * This library is distributed in the hope that it will be useful, but WITHOUT\n * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n * FOR A PARTICULAR PURPOSE. See the GNU Library general Public License for more\n * details.\n *\n * If you didn't download this code from the following link, you should check if\n * you aren't using an obsolete version:\n * http://www.lowagie.com/iText/\n */\nnamespace iTextSharp.text.pdf {\n    /** Implements the code 39 and code 39 extended. The default parameters are:\n     * <pre>\n     *x = 0.8f;\n     *n = 2;\n     *font = BaseFont.CreateFont(\"Helvetica\", \"winansi\", false);\n     *size = 8;\n     *baseline = size;\n     *barHeight = size * 3;\n     *textint= Element.ALIGN_CENTER;\n     *generateChecksum = false;\n     *checksumText = false;\n     *startStopText = true;\n     *extended = false;\n     * </pre>\n     *\n     * @author Paulo Soares (psoares@consiste.pt)\n     */\n    public class Barcode39 : Barcode {\n        /** The bars to generate the code.\n        */    \n        private static readonly byte[][] BARS = \n        {\n            new byte[] {0,0,0,1,1,0,1,0,0},\n            new byte[] {1,0,0,1,0,0,0,0,1},\n            new byte[] {0,0,1,1,0,0,0,0,1},\n            new byte[] {1,0,1,1,0,0,0,0,0},\n            new byte[] {0,0,0,1,1,0,0,0,1},\n            new byte[] {1,0,0,1,1,0,0,0,0},\n            new byte[] {0,0,1,1,1,0,0,0,0},\n            new byte[] {0,0,0,1,0,0,1,0,1},\n            new byte[] {1,0,0,1,0,0,1,0,0},\n            new byte[] {0,0,1,1,0,0,1,0,0},\n            new byte[] {1,0,0,0,0,1,0,0,1},\n            new byte[] {0,0,1,0,0,1,0,0,1},\n            new byte[] {1,0,1,0,0,1,0,0,0},\n            new byte[] {0,0,0,0,1,1,0,0,1},\n            new byte[] {1,0,0,0,1,1,0,0,0},\n            new byte[] {0,0,1,0,1,1,0,0,0},\n            new byte[] {0,0,0,0,0,1,1,0,1},\n            new byte[] {1,0,0,0,0,1,1,0,0},\n            new byte[] {0,0,1,0,0,1,1,0,0},\n            new byte[] {0,0,0,0,1,1,1,0,0},\n            new byte[] {1,0,0,0,0,0,0,1,1},\n            new byte[] {0,0,1,0,0,0,0,1,1},\n            new byte[] {1,0,1,0,0,0,0,1,0},\n            new byte[] {0,0,0,0,1,0,0,1,1},\n            new byte[] {1,0,0,0,1,0,0,1,0},\n            new byte[] {0,0,1,0,1,0,0,1,0},\n            new byte[] {0,0,0,0,0,0,1,1,1},\n            new byte[] {1,0,0,0,0,0,1,1,0},\n            new byte[] {0,0,1,0,0,0,1,1,0},\n            new byte[] {0,0,0,0,1,0,1,1,0},\n            new byte[] {1,1,0,0,0,0,0,0,1},\n            new byte[] {0,1,1,0,0,0,0,0,1},\n            new byte[] {1,1,1,0,0,0,0,0,0},\n            new byte[] {0,1,0,0,1,0,0,0,1},\n            new byte[] {1,1,0,0,1,0,0,0,0},\n            new byte[] {0,1,1,0,1,0,0,0,0},\n            new byte[] {0,1,0,0,0,0,1,0,1},\n            new byte[] {1,1,0,0,0,0,1,0,0},\n            new byte[] {0,1,1,0,0,0,1,0,0},\n            new byte[] {0,1,0,1,0,1,0,0,0},\n            new byte[] {0,1,0,1,0,0,0,1,0},\n            new byte[] {0,1,0,0,0,1,0,1,0},\n            new byte[] {0,0,0,1,0,1,0,1,0},\n            new byte[] {0,1,0,0,1,0,1,0,0}\n        };\n     \n        /** The index chars to <CODE>BARS</CODE>.\n        */    \n        private const string CHARS = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ-. $/+%*\";\n        \n        /** The character combinations to make the code 39 extended.\n        */    \n        private const string EXTENDED = \"%U\" +\n            \"$A$B$C$D$E$F$G$H$I$J$K$L$M$N$O$P$Q$R$S$T$U$V$W$X$Y$Z\" +\n            \"%A%B%C%D%E  /A/B/C/D/E/F/G/H/I/J/K/L - ./O\" +\n            \" 0 1 2 3 4 5 6 7 8 9/Z%F%G%H%I%J%V\" +\n            \" A B C D E F G H I J K L M N O P Q R S T U V W X Y Z\" +\n            \"%K%L%M%N%O%W\" +\n            \"+A+B+C+D+E+F+G+H+I+J+K+L+M+N+O+P+Q+R+S+T+U+V+W+X+Y+Z\" +\n            \"%P%Q%R%S%T\";\n            \n        /** Creates a new Barcode39.\n        */    \n        public Barcode39() {\n            x = 0.8f;\n            n = 2;\n            font = BaseFont.CreateFont(\"Helvetica\", \"winansi\", false);\n            size = 8;\n            baseline = size;\n            barHeight = size * 3;\n            textAlignment = Element.ALIGN_CENTER;\n            generateChecksum = false;\n            checksumText = false;\n            startStopText = true;\n            extended = false;\n        }\n        \n        /** Creates the bars.\n        * @param text the text to create the bars. This text does not include the start and\n        * stop characters\n        * @return the bars\n        */    \n        public static byte[] GetBarsCode39(string text) {\n            text = \"*\" + text + \"*\";\n            byte[] bars = new byte[text.Length * 10 - 1];\n            for (int k = 0; k < text.Length; ++k) {\n                int idx = CHARS.IndexOf(text[k]);\n                if (idx < 0)\n                    throw new ArgumentException(\"The character '\" + text[k] + \"' is illegal in code 39.\");\n                Array.Copy(BARS[idx], 0, bars, k * 10, 9);\n            }\n            return bars;\n        }\n        \n        /** Converts the extended text into a normal, escaped text,\n        * ready to generate bars.\n        * @param text the extended text\n        * @return the escaped text\n        */    \n        public static string GetCode39Ex(string text) {\n            string ret = \"\";\n            for (int k = 0; k < text.Length; ++k) {\n                char c = text[k];\n                if (c > 127)\n                    throw new ArgumentException(\"The character '\" + c + \"' is illegal in code 39 extended.\");\n                char c1 = EXTENDED[c * 2];\n                char c2 = EXTENDED[c * 2 + 1];\n                if (c1 != ' ')\n                    ret += c1;\n                ret += c2;\n            }\n            return ret;\n        }\n        \n        /** Calculates the checksum.\n        * @param text the text\n        * @return the checksum\n        */    \n        internal static char GetChecksum(string text) {\n            int chk = 0;\n            for (int k = 0; k < text.Length; ++k) {\n                int idx = CHARS.IndexOf(text[k]);\n                if (idx < 0)\n                    throw new ArgumentException(\"The character '\" + text[k] + \"' is illegal in code 39.\");\n                chk += idx;\n            }\n            return CHARS[chk % 43];\n        }\n        \n        /** Gets the maximum area that the barcode and the text, if\n        * any, will occupy. The lower left corner is always (0, 0).\n        * @return the size the barcode occupies.\n        */    \n        public override Rectangle BarcodeSize {\n            get {\n                float fontX = 0;\n                float fontY = 0;\n                if (font != null) {\n                    if (baseline > 0)\n                        fontY = baseline - font.GetFontDescriptor(BaseFont.DESCENT, size);\n                    else\n                        fontY = -baseline + size;\n                    string fullCode = code;\n                    if (generateChecksum && checksumText)\n                        fullCode += GetChecksum(fullCode);\n                    if (startStopText)\n                        fullCode = \"*\" + fullCode + \"*\";\n                    fontX = font.GetWidthPoint(altText != null ? altText : fullCode, size);\n                }            \n                string fCode = code;\n                if (extended)\n                    fCode = GetCode39Ex(code);\n", "outputs": ["                int len = fCode.Length + 2;"], "input_length": 1855, "output_length": 7, "length": 1862, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "79c3414726b7c46533d6a39f2eddfcfc2a8d8b94a4d3d0402d34d3d54536db6c"}
{"input": "", "context": "// Taken from https://stackoverflow.com/questions/6596327/how-to-check-if-a-file-is-signed-in-c\nusing System;\nusing System.Runtime.InteropServices;\nnamespace VisualStudioHelpDownloaderPlus\n{\n    internal static class AuthenticodeTools\n    {\n        [DllImport(\"Wintrust.dll\", PreserveSig = true, SetLastError = false)]\n        private static extern uint WinVerifyTrust(IntPtr hWnd, IntPtr pgActionID, IntPtr pWinTrustData);\n        private static uint WinVerifyTrust(string fileName)\n        {\n            Guid wintrust_action_generic_verify_v2 = new Guid(\"{00AAC56B-CD44-11d0-8CC2-00C04FC295EE}\");\n            uint result = 0;\n            using (WINTRUST_FILE_INFO fileInfo = new WINTRUST_FILE_INFO(fileName, Guid.Empty))\n            using (UnmanagedPointer guidPtr = new UnmanagedPointer(Marshal.AllocHGlobal(Marshal.SizeOf(typeof(Guid))), AllocMethod.HGlobal))\n            using (UnmanagedPointer wvtDataPtr = new UnmanagedPointer(Marshal.AllocHGlobal(Marshal.SizeOf(typeof(WINTRUST_DATA))), AllocMethod.HGlobal))\n            {\n                WINTRUST_DATA data = new WINTRUST_DATA(fileInfo);\n                IntPtr pGuid = guidPtr;\n                IntPtr pData = wvtDataPtr;\n                Marshal.StructureToPtr(wintrust_action_generic_verify_v2, pGuid, true);\n                Marshal.StructureToPtr(data, pData, true);\n                result = WinVerifyTrust(IntPtr.Zero, pGuid, pData);\n            }\n            return result;\n        }\n        public static bool IsTrusted(string fileName)\n        {\n            return WinVerifyTrust(fileName) == 0;\n        }\n    }\n    internal struct WINTRUST_FILE_INFO : IDisposable\n    {\n        public WINTRUST_FILE_INFO(string fileName, Guid subject)\n        {\n            cbStruct = (uint)Marshal.SizeOf(typeof(WINTRUST_FILE_INFO));\n            pcwszFilePath = fileName;\n            if (subject != Guid.Empty)\n            {\n                pgKnownSubject = Marshal.AllocHGlobal(Marshal.SizeOf(typeof(Guid)));\n                Marshal.StructureToPtr(subject, pgKnownSubject, true);\n            }\n            else\n            {\n                pgKnownSubject = IntPtr.Zero;\n            }\n            hFile = IntPtr.Zero;\n        }\n        public uint cbStruct;\n        [MarshalAs(UnmanagedType.LPTStr)]\n        public string pcwszFilePath;\n        public IntPtr hFile;\n        public IntPtr pgKnownSubject;\n        #region IDisposable Members\n        public void Dispose()\n        {\n            Dispose(true);\n        }\n        private void Dispose(bool disposing)\n        {\n            if (pgKnownSubject != IntPtr.Zero)\n            {\n                Marshal.DestroyStructure(pgKnownSubject, typeof(Guid));\n                Marshal.FreeHGlobal(pgKnownSubject);\n            }\n        }\n        #endregion\n    }\n    enum AllocMethod\n    {\n        HGlobal,\n        CoTaskMem\n    };\n    enum UnionChoice\n    {\n        File = 1,\n        Catalog,\n        Blob,\n        Signer,\n        Cert\n    };\n    enum UiChoice\n    {\n        All = 1,\n        NoUI,\n        NoBad,\n        NoGood\n    };\n    enum RevocationCheckFlags\n    {\n        None = 0,\n        WholeChain\n    };\n    enum StateAction\n    {\n        Ignore = 0,\n        Verify,\n        Close,\n        AutoCache,\n        AutoCacheFlush\n    };\n    enum TrustProviderFlags\n    {\n        UseIE4Trust = 1,\n        NoIE4Chain = 2,\n        NoPolicyUsage = 4,\n        RevocationCheckNone = 16,\n        RevocationCheckEndCert = 32,\n        RevocationCheckChain = 64,\n        RecovationCheckChainExcludeRoot = 128,\n        Safer = 256,\n        HashOnly = 512,\n        UseDefaultOSVerCheck = 1024,\n        LifetimeSigning = 2048\n    };\n    enum UIContext\n    {\n        Execute = 0,\n        Install\n    };\n    [StructLayout(LayoutKind.Sequential)]\n    internal struct WINTRUST_DATA : IDisposable\n    {\n        public WINTRUST_DATA(WINTRUST_FILE_INFO fileInfo)\n        {\n            cbStruct = (uint)Marshal.SizeOf(typeof(WINTRUST_DATA));\n            pInfoStruct = Marshal.AllocHGlobal(Marshal.SizeOf(typeof(WINTRUST_FILE_INFO)));\n            Marshal.StructureToPtr(fileInfo, pInfoStruct, false);\n            dwUnionChoice = UnionChoice.File;\n            pPolicyCallbackData = IntPtr.Zero;\n            pSIPCallbackData = IntPtr.Zero;\n            dwUIChoice = UiChoice.NoUI;\n            fdwRevocationChecks = RevocationCheckFlags.None;\n            dwStateAction = StateAction.Ignore;\n            hWVTStateData = IntPtr.Zero;\n            pwszURLReference = IntPtr.Zero;\n            dwProvFlags = TrustProviderFlags.Safer;\n            dwUIContext = UIContext.Execute;\n        }\n        public uint cbStruct;\n        public IntPtr pPolicyCallbackData;\n        public IntPtr pSIPCallbackData;\n        public UiChoice dwUIChoice;\n        public RevocationCheckFlags fdwRevocationChecks;\n        public UnionChoice dwUnionChoice;\n        public IntPtr pInfoStruct;\n        public StateAction dwStateAction;\n        public IntPtr hWVTStateData;\n        private IntPtr pwszURLReference;\n        public TrustProviderFlags dwProvFlags;\n        public UIContext dwUIContext;\n        #region IDisposable Members\n        public void Dispose()\n        {\n            Dispose(true);\n        }\n        private void Dispose(bool disposing)\n        {\n            if (dwUnionChoice == UnionChoice.File)\n            {\n                using (WINTRUST_FILE_INFO info = new WINTRUST_FILE_INFO())\n                {\n                    Marshal.PtrToStructure(pInfoStruct, info);\n                    info.Dispose();\n                }\n                Marshal.DestroyStructure(pInfoStruct, typeof(WINTRUST_FILE_INFO));\n            }\n            Marshal.FreeHGlobal(pInfoStruct);\n        }\n        #endregion\n    }\n    internal sealed class UnmanagedPointer : IDisposable\n    {\n        private IntPtr m_ptr;\n        private AllocMethod m_meth;\n        internal UnmanagedPointer(IntPtr ptr, AllocMethod method)\n        {\n            m_meth = method;\n            m_ptr = ptr;\n        }\n        ~UnmanagedPointer()\n        {\n            Dispose(false);\n        }\n        #region IDisposable Members\n        private void Dispose(bool disposing)\n        {\n            if (m_ptr != IntPtr.Zero)\n            {\n                if (m_meth == AllocMethod.HGlobal)\n                {\n                    Marshal.FreeHGlobal(m_ptr);\n                }\n", "outputs": ["                else if (m_meth == AllocMethod.CoTaskMem)"], "input_length": 775, "output_length": 7, "length": 782, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "aaa2ea7cebe547ab08da2e4ed76f684d7dcab8a274c0e2e9c37c1ebff9c5cf69"}
{"input": "", "context": "#region Copyright & License Information\n/*\n * Copyright 2007-2017 The OpenRA Developers (see AUTHORS)\n * This file is part of OpenRA, which is free software. It is made\n * available to you under the terms of the GNU General Public License\n * as published by the Free Software Foundation, either version 3 of\n * the License, or (at your option) any later version. For more\n * information, see COPYING.\n */\n#endregion\nusing System;\nusing System.Collections.Generic;\nusing System.Globalization;\nusing System.IO;\nusing System.Linq;\nusing System.Net;\nusing System.Net.Sockets;\nusing System.Threading;\nusing OpenRA.Graphics;\nusing OpenRA.Network;\nusing OpenRA.Primitives;\nusing OpenRA.Support;\nnamespace OpenRA.Server\n{\n\tpublic enum ServerState\n\t{\n\t\tWaitingPlayers = 1,\n\t\tGameStarted = 2,\n\t\tShuttingDown = 3\n\t}\n\tpublic class Server\n\t{\n\t\tpublic readonly string TwoHumansRequiredText = \"This server requires at least two human players to start a match.\";\n\t\tpublic readonly IPAddress Ip;\n\t\tpublic readonly int Port;\n\t\tpublic readonly MersenneTwister Random = new MersenneTwister();\n\t\tpublic readonly bool Dedicated;\n\t\t// Valid player connections\n\t\tpublic List<Connection> Conns = new List<Connection>();\n\t\t// Pre-verified player connections\n\t\tpublic List<Connection> PreConns = new List<Connection>();\n\t\tpublic Session LobbyInfo;\n\t\tpublic ServerSettings Settings;\n\t\tpublic ModData ModData;\n\t\tpublic List<string> TempBans = new List<string>();\n\t\t// Managed by LobbyCommands\n\t\tpublic MapPreview Map;\n\t\treadonly int randomSeed;\n\t\treadonly TcpListener listener;\n\t\treadonly TypeDictionary serverTraits = new TypeDictionary();\n\t\tprotected volatile ServerState internalState = ServerState.WaitingPlayers;\n\t\tpublic ServerState State\n\t\t{\n\t\t\tget { return internalState; }\n\t\t\tprotected set { internalState = value; }\n\t\t}\n\t\tpublic static void SyncClientToPlayerReference(Session.Client c, PlayerReference pr)\n\t\t{\n\t\t\tif (pr == null)\n\t\t\t\treturn;\n\t\t\tif (pr.LockFaction)\n\t\t\t\tc.Faction = pr.Faction;\n\t\t\tif (pr.LockSpawn)\n\t\t\t\tc.SpawnPoint = pr.Spawn;\n\t\t\tif (pr.LockTeam)\n\t\t\t\tc.Team = pr.Team;\n\t\t\tc.Color = pr.LockColor ? pr.Color : c.PreferredColor;\n\t\t}\n\t\tstatic void SendData(Socket s, byte[] data)\n\t\t{\n\t\t\tvar start = 0;\n\t\t\tvar length = data.Length;\n\t\t\t// Non-blocking sends are free to send only part of the data\n\t\t\twhile (start < length)\n\t\t\t{\n\t\t\t\tSocketError error;\n\t\t\t\tvar sent = s.Send(data, start, length - start, SocketFlags.None, out error);\n\t\t\t\tif (error == SocketError.WouldBlock)\n\t\t\t\t{\n\t\t\t\t\tLog.Write(\"server\", \"Non-blocking send of {0} bytes failed. Falling back to blocking send.\", length - start);\n\t\t\t\t\ts.Blocking = true;\n\t\t\t\t\tsent = s.Send(data, start, length - start, SocketFlags.None);\n\t\t\t\t\ts.Blocking = false;\n\t\t\t\t}\n\t\t\t\telse if (error != SocketError.Success)\n\t\t\t\t\tthrow new SocketException((int)error);\n\t\t\t\tstart += sent;\n\t\t\t}\n\t\t}\n\t\tpublic void Shutdown()\n\t\t{\n\t\t\tState = ServerState.ShuttingDown;\n\t\t}\n\t\tpublic void EndGame()\n\t\t{\n\t\t\tforeach (var t in serverTraits.WithInterface<IEndGame>())\n\t\t\t\tt.GameEnded(this);\n\t\t}\n\t\tpublic Server(IPEndPoint endpoint, ServerSettings settings, ModData modData, bool dedicated)\n\t\t{\n\t\t\tLog.AddChannel(\"server\", \"server.log\");\n\t\t\tlistener = new TcpListener(endpoint);\n\t\t\tlistener.Start();\n\t\t\tvar localEndpoint = (IPEndPoint)listener.LocalEndpoint;\n\t\t\tIp = localEndpoint.Address;\n\t\t\tPort = localEndpoint.Port;\n\t\t\tDedicated = dedicated;\n\t\t\tSettings = settings;\n\t\t\tSettings.Name = OpenRA.Settings.SanitizedServerName(Settings.Name);\n\t\t\tModData = modData;\n\t\t\trandomSeed = (int)DateTime.Now.ToBinary();\n\t\t\tif (UPnP.Status == UPnPStatus.Enabled)\n\t\t\t\tUPnP.ForwardPort(Settings.ListenPort, Settings.ExternalPort).Wait();\n\t\t\tforeach (var trait in modData.Manifest.ServerTraits)\n\t\t\t\tserverTraits.Add(modData.ObjectCreator.CreateObject<ServerTrait>(trait));\n\t\t\tLobbyInfo = new Session\n\t\t\t{\n\t\t\t\tGlobalSettings =\n\t\t\t\t{\n\t\t\t\t\tRandomSeed = randomSeed,\n\t\t\t\t\tMap = settings.Map,\n\t\t\t\t\tServerName = settings.Name,\n\t\t\t\t\tEnableSingleplayer = settings.EnableSingleplayer || !dedicated,\n\t\t\t\t\tGameUid = Guid.NewGuid().ToString()\n\t\t\t\t}\n\t\t\t};\n\t\t\tnew Thread(_ =>\n\t\t\t{\n\t\t\t\tforeach (var t in serverTraits.WithInterface<INotifyServerStart>())\n\t\t\t\t\tt.ServerStarted(this);\n\t\t\t\tLog.Write(\"server\", \"Initial mod: {0}\", ModData.Manifest.Id);\n\t\t\t\tLog.Write(\"server\", \"Initial map: {0}\", LobbyInfo.GlobalSettings.Map);\n\t\t\t\tvar timeout = serverTraits.WithInterface<ITick>().Min(t => t.TickTimeout);\n\t\t\t\tfor (;;)\n\t\t\t\t{\n\t\t\t\t\tvar checkRead = new List<Socket>();\n\t\t\t\t\tif (State == ServerState.WaitingPlayers)\n\t\t\t\t\t\tcheckRead.Add(listener.Server);\n\t\t\t\t\tcheckRead.AddRange(Conns.Select(c => c.Socket));\n\t\t\t\t\tcheckRead.AddRange(PreConns.Select(c => c.Socket));\n\t\t\t\t\tif (checkRead.Count > 0)\n\t\t\t\t\t\tSocket.Select(checkRead, null, null, timeout);\n\t\t\t\t\tif (State == ServerState.ShuttingDown)\n\t\t\t\t\t{\n\t\t\t\t\t\tEndGame();\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tforeach (var s in checkRead)\n\t\t\t\t\t{\n\t\t\t\t\t\tif (s == listener.Server)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tAcceptConnection();\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tvar preConn = PreConns.SingleOrDefault(c => c.Socket == s);\n\t\t\t\t\t\tif (preConn != null)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tpreConn.ReadData(this);\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tvar conn = Conns.SingleOrDefault(c => c.Socket == s);\n\t\t\t\t\t\tif (conn != null)\n\t\t\t\t\t\t\tconn.ReadData(this);\n\t\t\t\t\t}\n\t\t\t\t\tforeach (var t in serverTraits.WithInterface<ITick>())\n\t\t\t\t\t\tt.Tick(this);\n\t\t\t\t\tif (State == ServerState.ShuttingDown)\n\t\t\t\t\t{\n\t\t\t\t\t\tEndGame();\n\t\t\t\t\t\tif (UPnP.Status == UPnPStatus.Enabled)\n\t\t\t\t\t\t\tUPnP.RemovePortForward().Wait();\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tforeach (var t in serverTraits.WithInterface<INotifyServerShutdown>())\n\t\t\t\t\tt.ServerShutdown(this);\n\t\t\t\tPreConns.Clear();\n\t\t\t\tConns.Clear();\n\t\t\t\ttry { listener.Stop(); }\n\t\t\t\tcatch { }\n\t\t\t}) { IsBackground = true }.Start();\n\t\t}\n\t\tint nextPlayerIndex;\n\t\tpublic int ChooseFreePlayerIndex()\n\t\t{\n\t\t\treturn nextPlayerIndex++;\n\t\t}\n\t\tvoid AcceptConnection()\n\t\t{\n\t\t\tSocket newSocket;\n\t\t\ttry\n\t\t\t{\n\t\t\t\tif (!listener.Server.IsBound)\n\t\t\t\t\treturn;\n\t\t\t\tnewSocket = listener.AcceptSocket();\n\t\t\t}\n\t\t\tcatch (Exception e)\n\t\t\t{\n\t\t\t\t/* TODO: Could have an exception here when listener 'goes away' when calling AcceptConnection! */\n\t\t\t\t/* Alternative would be to use locking but the listener doesn't go away without a reason. */\n\t\t\t\tLog.Write(\"server\", \"Accepting the connection failed.\", e);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tvar newConn = new Connection { Socket = newSocket };\n\t\t\ttry\n\t\t\t{\n\t\t\t\tnewConn.Socket.Blocking = false;\n\t\t\t\tnewConn.Socket.NoDelay = true;\n\t\t\t\t// assign the player number.\n\t\t\t\tnewConn.PlayerIndex = ChooseFreePlayerIndex();\n\t\t\t\tSendData(newConn.Socket, BitConverter.GetBytes(ProtocolVersion.Version));\n\t\t\t\tSendData(newConn.Socket, BitConverter.GetBytes(newConn.PlayerIndex));\n\t\t\t\tPreConns.Add(newConn);\n\t\t\t\t// Dispatch a handshake order\n\t\t\t\tvar request = new HandshakeRequest\n\t\t\t\t{\n\t\t\t\t\tMod = ModData.Manifest.Id,\n\t\t\t\t\tVersion = ModData.Manifest.Metadata.Version,\n\t\t\t\t\tMap = LobbyInfo.GlobalSettings.Map\n\t\t\t\t};\n\t\t\t\tDispatchOrdersToClient(newConn, 0, 0, new ServerOrder(\"HandshakeRequest\", request.Serialize()).Serialize());\n\t\t\t}\n\t\t\tcatch (Exception e)\n\t\t\t{\n\t\t\t\tDropClient(newConn);\n\t\t\t\tLog.Write(\"server\", \"Dropping client {0} because handshake failed: {1}\", newConn.PlayerIndex.ToString(CultureInfo.InvariantCulture), e);\n\t\t\t}\n\t\t}\n\t\tvoid ValidateClient(Connection newConn, string data)\n\t\t{\n\t\t\ttry\n\t\t\t{\n\t\t\t\tif (State == ServerState.GameStarted)\n\t\t\t\t{\n\t\t\t\t\tLog.Write(\"server\", \"Rejected connection from {0}; game is already started.\",\n\t\t\t\t\t\tnewConn.Socket.RemoteEndPoint);\n\t\t\t\t\tSendOrderTo(newConn, \"ServerError\", \"The game has already started\");\n\t\t\t\t\tDropClient(newConn);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tvar handshake = HandshakeResponse.Deserialize(data);\n\t\t\t\tif (!string.IsNullOrEmpty(Settings.Password) && handshake.Password != Settings.Password)\n\t\t\t\t{\n\t\t\t\t\tvar message = string.IsNullOrEmpty(handshake.Password) ? \"Server requires a password\" : \"Incorrect password\";\n", "outputs": ["\t\t\t\t\tSendOrderTo(newConn, \"AuthenticationError\", message);"], "input_length": 1389, "output_length": 11, "length": 1400, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "b045b9298e92c1b2a915f57d96a7121c3b8e9d1b9043942b9c254b9d0622be9a"}
{"input": "", "context": "# -*- coding: utf-8 -*-\nimport threading\nimport logging\nimport time\nimport select\nimport socket\nimport ssl\nimport struct\nfrom errors import *\nfrom constants import *\nimport users\nimport channels\nimport blobs\nimport commands\nimport messages\nimport callbacks\nimport tools\nimport soundoutput\nimport mumble_pb2\nfrom pycelt import SUPPORTED_BITSTREAMS\nclass Mumble(threading.Thread):\n    \"\"\"\n    Mumble client library main object.\n    basically a thread\n    \"\"\"\n    def __init__(self, host=None, port=None, user=None, password=None, client_certif=None, reconnect=False, debug=False):\n        \"\"\"\n        host=mumble server hostname or address\n        port=mumble server port\n        user=user to use for the connection\n        password=password for the connection\n        client_certif=client certificate to authenticate the connection (NOT IMPLEMENTED)\n        reconnect=if True, try to reconnect if disconnected\n        debug=if True, send debugging messages (lot of...) to the stdout\n        \"\"\"\n#TODO: client certificate authentication\n#TODO: exit both threads properly\n#TODO: use UDP audio\n        threading.Thread.__init__(self)\n        \n        self.Log = logging.getLogger(\"PyMumble\")  # logging object for errors and debugging\n        if debug:\n            self.Log.setLevel(logging.DEBUG)\n        else:\n            self.Log.setLevel(logging.ERROR)\n            \n        ch = logging.StreamHandler()\n        ch.setLevel(logging.DEBUG)\n        formatter = logging.Formatter('%(asctime)s-%(name)s-%(levelname)s-%(message)s')\n        ch.setFormatter(formatter)\n        self.Log.addHandler(ch)\n        \n        self.parent_thread = threading.current_thread()  # main thread of the calling application\n        self.mumble_thread = None  # thread of the mumble client library\n        \n        self.host = host\n        self.port = port\n        self.user = user\n        self.password = password\n        self.client_certif = client_certif\n        self.reconnect = reconnect\n        \n        self.receive_sound = False  # set to True to treat incoming audio, otherwise it is simply ignored\n        \n        self.loop_rate = PYMUMBLE_LOOP_RATE\n        \n        self.application = PYMUMBLE_VERSION_STRING\n        self.callbacks = callbacks.CallBacks()  #callbacks management\n        self.ready_lock = threading.Lock()  # released when the connection is fully established with the server\n        self.ready_lock.acquire()\n        \n    def init_connection(self):\n        \"\"\"Initialize variables that are local to a connection, (needed if the client automatically reconnect)\"\"\"\n        self.ready_lock.acquire(False)  # reacquire the ready-lock in case of reconnection\n        \n        self.connected = PYMUMBLE_CONN_STATE_NOT_CONNECTED\n        self.control_socket = None\n        self.media_socket = None  # Not implemented - for UDP media\n        \n        self.bandwidth = PYMUMBLE_BANDWIDTH  # reset the outgoing bandwidth to it's default before connectiong\n        self.server_max_bandwidth = None\n        self.udp_active = False\n        \n        self.users = users.Users(self, self.callbacks)  # contain the server's connected users informations\n        self.channels = channels.Channels(self, self.callbacks)  # contain the server's channels informations\n        self.blobs = blobs.Blobs(self)  # manage the blob objects\n        self.sound_output = soundoutput.SoundOutput(self, PYMUMBLE_AUDIO_PER_PACKET, self.bandwidth)  # manage the outgoing sounds\n        self.commands = commands.Commands()  # manage commands sent between the main and the mumble threads\n        \n        self.receive_buffer = \"\"  # initialize the control connection input buffer\n        \n    def run(self):\n        \"\"\"Connect to the server and start the loop in its thread.  Retry if requested\"\"\"\n        self.mumble_thread = threading.current_thread()\n        \n        # loop if auto-reconnect is requested\n        while True:\n            self.init_connection()  # reset the connection-specific object members\n            \n            self.connect()\n            \n            self.loop()\n        \n            if not self.reconnect or not self.parent_thread.is_alive():\n                break\n            \n            time.sleep(PYMUMBLE_CONNECTION_RETRY_INTERVAL)\n        \n    def connect(self):\n        \"\"\"Connect to the server\"\"\"\n        \n        # Connect the SSL tunnel\n        self.Log.debug(\"connecting to %s on port %i.\", self.host, self.port)\n        std_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.control_socket = ssl.wrap_socket(std_sock, certfile=self.client_certif, ssl_version=ssl.PROTOCOL_TLSv1)\n        self.control_socket.connect((self.host, self.port))\n        \n        self.control_socket.setblocking(0)\n        \n        # Perform the Mumble authentication\n        version = mumble_pb2.Version()\n        version.version = (PYMUMBLE_PROTOCOL_VERSION[0] << 16) + (PYMUMBLE_PROTOCOL_VERSION[1] << 8) + PYMUMBLE_PROTOCOL_VERSION[2]\n        version.release = self.application\n        version.os = PYMUMBLE_OS_STRING\n        version.os_version = PYMUMBLE_OS_VERSION_STRING\n        self.Log.debug(\"sending: version: %s\", version)\n        self.send_message(PYMUMBLE_MSG_TYPES_VERSION, version)\n        \n        authenticate = mumble_pb2.Authenticate()\n        authenticate.username = self.user\n        authenticate.password = self.password\n        authenticate.celt_versions.extend(SUPPORTED_BITSTREAMS.keys())\n#        authenticate.celt_versions.extend([-2147483637])  # for debugging - only celt 0.7\n        authenticate.opus = True\n        self.Log.debug(\"sending: authenticate: %s\", authenticate)\n        self.send_message(PYMUMBLE_MSG_TYPES_AUTHENTICATE, authenticate)\n        \n        self.connected = PYMUMBLE_CONN_STATE_AUTHENTICATING\n        \n    def loop(self):\n        \"\"\"\n        Main loop\n        waiting for a message from the server for maximum self.loop_rate time\n        take care of sending the ping\n        take care of sending the queued commands to the server\n        check on every iteration for outgoing sound \n        check for disconnection\n        \"\"\"\n        self.Log.debug(\"entering loop\")\n        \n        last_ping = time.time()  # keep track of the last ping time\n        \n        # loop as long as the connection and the parent thread are alive\n        while self.connected != PYMUMBLE_CONN_STATE_NOT_CONNECTED and self.parent_thread.is_alive():\n            if last_ping + PYMUMBLE_PING_DELAY <= time.time():  # when it is time, send the ping\n                self.ping()\n                last_ping = time.time()\n            if self.connected == PYMUMBLE_CONN_STATE_CONNECTED:\n                while self.commands.is_cmd():\n                    self.treat_command(self.commands.pop_cmd())  # send the commands coming from the application to the server\n                    \n                self.sound_output.send_audio()  # send outgoing audio if available\n            \n            (rlist, wlist, xlist) = select.select([self.control_socket], [], [self.control_socket], self.loop_rate)  # wait for a socket activity\n            \n            if self.control_socket in rlist:  # something to be read on the control socket\n                self.read_control_messages()\n            elif self.control_socket in xlist:  # socket was closed\n                self.control_socket.close()\n                self.connected = PYMUMBLE_CONN_STATE_NOT_CONNECTED\n                \n    def ping(self):\n        \"\"\"Send the keepalive through available channels\"\"\"\n#TODO: Ping counters        \n        ping = mumble_pb2.Ping()\n        ping.timestamp=int(time.time())\n        self.Log.debug(\"sending: ping: %s\", ping)\n        self.send_message(PYMUMBLE_MSG_TYPES_PING, ping)\n    \n    def send_message(self, type, message):\n        \"\"\"Send a control message to the server\"\"\"\n        packet=struct.pack(\"!HL\", type, message.ByteSize()) + message.SerializeToString()\n        while len(packet)>0:\n            self.Log.debug(\"sending message\")\n            sent=self.control_socket.send(packet)\n            if sent < 0:\n                raise socket.error(\"Server socket error\")\n            packet=packet[sent:]\n            \n    def read_control_messages(self):\n        \"\"\"Read control messages coming from the server\"\"\"\n#        from tools import toHex  # for debugging\n        \n        buffer = self.control_socket.recv(PYMUMBLE_READ_BUFFER_SIZE)\n        self.receive_buffer += buffer\n        while len(self.receive_buffer) >= 6:  # header is present (type + length)\n            self.Log.debug(\"read control connection\")\n            header = self.receive_buffer[0:6]\n            (type, size) = struct.unpack(\"!HL\", header)  # decode header\n            if len(self.receive_buffer) < size+6:  # if not length data, read further\n                break\n            \n#            self.Log.debug(\"message received : \" + toHex(self.receive_buffer[0:size+6]))  # for debugging\n            \n            message = self.receive_buffer[6:size+6]  # get the control message\n            self.receive_buffer = self.receive_buffer[size+6:]  # remove from the buffer the read part\n        \n            self.dispatch_control_message(type, message)\n            \n    def dispatch_control_message(self, type, message):\n        \"\"\"Dispatch control messages based on their type\"\"\"\n        self.Log.debug(\"dispatch control message\")\n        if type == PYMUMBLE_MSG_TYPES_UDPTUNNEL:  # audio encapsulated in control message\n            self.sound_received(message)\n            \n        elif type == PYMUMBLE_MSG_TYPES_VERSION:\n            mess = mumble_pb2.Version()\n            mess.ParseFromString(message)\n            self.Log.debug(\"message: Version : %s\", mess)\n            \n        elif type == PYMUMBLE_MSG_TYPES_AUTHENTICATE:\n            mess = mumble_pb2.Authenticate()\n            mess.ParseFromString(message)\n            self.Log.debug(\"message: Authenticate : %s\", mess)\n            \n        elif type == PYMUMBLE_MSG_TYPES_PING:\n            mess = mumble_pb2.Ping()\n            mess.ParseFromString(message)\n            self.Log.debug(\"message: Ping : %s\", mess)\n            \n        elif type == PYMUMBLE_MSG_TYPES_REJECT:\n            mess = mumble_pb2.Reject()\n            mess.ParseFromString(message)\n            self.Log.debug(\"message: reject : %s\", mess)\n            self.ready_lock.release()\n            raise ConnectionRejectedError(mess.reason)\n        \n        elif type == PYMUMBLE_MSG_TYPES_SERVERSYNC:  # this message finish the connection process\n            mess = mumble_pb2.ServerSync()\n            mess.ParseFromString(message)\n            self.Log.debug(\"message: serversync : %s\", mess)\n            self.users.set_myself(mess.session)\n            self.server_max_bandwidth = mess.max_bandwidth \n            self.set_bandwidth(mess.max_bandwidth)\n            \n            if self.connected == PYMUMBLE_CONN_STATE_AUTHENTICATING:\n                self.connected = PYMUMBLE_CONN_STATE_CONNECTED\n                self.callbacks(PYMUMBLE_CLBK_CONNECTED)\n                self.ready_lock.release()  # release the ready-lock\n        elif type == PYMUMBLE_MSG_TYPES_CHANNELREMOVE:\n            mess = mumble_pb2.ChannelRemove()\n            mess.ParseFromString(message)\n            self.Log.debug(\"message: ChannelRemove : %s\", mess)\n            \n            self.channels.remove(mess.channel_id)\n            \n        elif type == PYMUMBLE_MSG_TYPES_CHANNELSTATE:\n            mess = mumble_pb2.ChannelState()\n            mess.ParseFromString(message)\n            self.Log.debug(\"message: channelstate : %s\", mess)\n            \n            self.channels.update(mess)\n            \n        elif type == PYMUMBLE_MSG_TYPES_USERREMOVE:\n            mess = mumble_pb2.UserRemove()\n            mess.ParseFromString(message)\n            self.Log.debug(\"message: UserRemove : %s\", mess)\n            \n            self.users.remove(mess)\n            \n        elif type == PYMUMBLE_MSG_TYPES_USERSTATE:\n            mess = mumble_pb2.UserState()\n            mess.ParseFromString(message)\n            self.Log.debug(\"message: userstate : %s\", mess)\n            \n            self.users.update(mess)\n            \n        elif type == PYMUMBLE_MSG_TYPES_BANLIST:\n            mess = mumble_pb2.BanList()\n            mess.ParseFromString(message)\n            self.Log.debug(\"message: BanList : %s\", mess)\n            \n        elif type == PYMUMBLE_MSG_TYPES_TEXTMESSAGE:\n            mess = mumble_pb2.TextMessage()\n            mess.ParseFromString(message)\n            self.Log.debug(\"message: TextMessage : %s\", mess)\n            self.callbacks(PYMUMBLE_CLBK_TEXTMESSAGERECEIVED, mess.message)\n            \n        elif type == PYMUMBLE_MSG_TYPES_PERMISSIONDENIED:\n            mess = mumble_pb2.PermissionDenied()\n            mess.ParseFromString(message)\n            self.Log.debug(\"message: PermissionDenied : %s\", mess)\n            \n        elif type == PYMUMBLE_MSG_TYPES_ACL:\n            mess = mumble_pb2.ACL()\n            mess.ParseFromString(message)\n            self.Log.debug(\"message: ACL : %s\", mess)\n            \n        elif type == PYMUMBLE_MSG_TYPES_QUERYUSERS:\n            mess = mumble_pb2.QueryUsers()\n            mess.ParseFromString(message)\n            self.Log.debug(\"message: QueryUsers : %s\", mess)\n            \n        elif type == PYMUMBLE_MSG_TYPES_CRYPTSETUP:\n            mess = mumble_pb2.CryptSetup()\n            mess.ParseFromString(message)\n            self.Log.debug(\"message: CryptSetup : %s\", mess)\n            \n        elif type == PYMUMBLE_MSG_TYPES_CONTEXTACTIONADD:\n            mess = mumble_pb2.ContextActionAdd()\n            mess.ParseFromString(message)\n            self.Log.debug(\"message: ContextActionAdd : %s\", mess)\n            \n        elif type == PYMUMBLE_MSG_TYPES_CONTEXTACTION:\n            mess = mumble_pb2.ContextActionAdd()\n            mess.ParseFromString(message)\n            self.Log.debug(\"message: ContextActionAdd : %s\", mess)\n            \n        elif type == PYMUMBLE_MSG_TYPES_USERLIST:\n            mess = mumble_pb2.UserList()\n            mess.ParseFromString(message)\n            self.Log.debug(\"message: UserList : %s\", mess)\n            \n        elif type == PYMUMBLE_MSG_TYPES_VOICETARGET:\n            mess = mumble_pb2.VoiceTarget()\n            mess.ParseFromString(message)\n            self.Log.debug(\"message: VoiceTarget : %s\", mess)\n            \n        elif type == PYMUMBLE_MSG_TYPES_PERMISSIONQUERY:\n            mess = mumble_pb2.PermissionQuery()\n            mess.ParseFromString(message)\n            self.Log.debug(\"message: PermissionQuery : %s\", mess)\n            \n        elif type == PYMUMBLE_MSG_TYPES_CODECVERSION:\n            mess = mumble_pb2.CodecVersion()\n            mess.ParseFromString(message)\n            self.Log.debug(\"message: CodecVersion : %s\", mess)\n            \n            self.sound_output.set_default_codec(mess)\n            \n        elif type == PYMUMBLE_MSG_TYPES_USERSTATS:\n            mess = mumble_pb2.UserStats()\n            mess.ParseFromString(message)\n            self.Log.debug(\"message: UserStats : %s\", mess)\n            \n        elif type == PYMUMBLE_MSG_TYPES_REQUESTBLOB:\n            mess = mumble_pb2.RequestBlob()\n            mess.ParseFromString(message)\n            self.Log.debug(\"message: RequestBlob : %s\", mess)\n            \n        elif type == PYMUMBLE_MSG_TYPES_SERVERCONFIG:\n            mess = mumble_pb2.ServerConfig()\n            mess.ParseFromString(message)\n            self.Log.debug(\"message: ServerConfig : %s\", mess)        \n    def set_bandwidth(self, bandwidth):\n        \"\"\"set the total allowed outgoing bandwidth\"\"\"\n        if self.server_max_bandwidth is not None and bandwidth > self.server_max_bandwidth:\n            self.bandwidth = self.server_max_bandwidth\n        else: \n            self.bandwidth = bandwidth\n            \n        self.sound_output.set_bandwidth(self.bandwidth)  # communicate the update to the outgoing audio manager\n    \n    def sound_received(self, message):\n        \"\"\"Manage a received sound message\"\"\"\n#        from tools import toHex  # for debugging\n        pos = 0\n        \n#        self.Log.debug(\"sound packet : \" + toHex(message))  # for debugging\n                \n        (header, ) = struct.unpack(\"!B\", message[pos])  # extract the header\n        type = ( header & 0b11100000 ) >> 5\n        target = header & 0b00011111\n        pos += 1\n        \n        if type == PYMUMBLE_AUDIO_TYPE_PING:\n            return\n            \n        session = tools.VarInt()  # decode session id\n        pos += session.decode(message[pos:pos+10])\n        \n        sequence = tools.VarInt()  # decode sequence number\n        pos += sequence.decode(message[pos:pos+10])\n        \n        self.Log.debug(\"audio packet received from %i, sequence %i, type:%i, target:%i, lenght:%i\", session.value, sequence.value, type, target, len(message))\n        \n        terminator = False  # set to true if it's the last 10 ms audio frame for the packet (used with CELT codec)\n        while ( pos < len(message)) and not terminator:  # get the audio frames one by one\n            if type == PYMUMBLE_AUDIO_TYPE_OPUS:\n                size = tools.VarInt()  # OPUS use varint for the frame length\n                \n                pos += size.decode(message[pos:pos+10])\n                size = size.value\n                \n                if not (size & 0x2000):  # terminator is 0x2000 in the resulting int.\n                    terminator = True    # should actually always be 0 as OPUS can use variable length audio frames\n                \n                size = size & 0x1fff  # isolate the size from the terminator\n            else:\n                (header, ) = struct.unpack(\"!B\", message[pos])  # CELT length and terminator is encoded in a 1 byte int\n                if not (header & 0b10000000):\n                    terminator = True\n                size = header & 0b01111111\n                pos += 1\n    \n            self.Log.debug(\"Audio frame : time:%f, last:%s, size:%i, type:%i, target:%i, pos:%i\",time.time(), str(terminator), size, type, target, pos-1)\n            if size > 0 and self.receive_sound:  # if audio must be treated\n                try:\n                    newsound = self.users[session.value].sound.add(message[pos:pos+size],\n                                                                   sequence.value,\n                                                                   type,\n                                                                   target)  # add the sound to the user's sound queue\n                    self.callbacks(PYMUMBLE_CLBK_SOUNDRECEIVED, self.users[session.value], newsound)\n            \n                    self.Log.debug(\"Audio frame : time:%f last:%s, size:%i, uncompressed:%i, type:%i, target:%i\",time.time(), str(terminator), size, newsound.size, type, target)\n                except CodecNotSupportedError as msg:\n                    print msg\n                except KeyError:  # sound received after user removed\n                    pass\n                sequence.value += int(round(newsound.duration / 1000 * 10))  # add 1 sequence per 10ms of audio \n#            if len(message) - pos < size:\n#                raise InvalidFormatError(\"Invalid audio frame size\")\n            \n            pos += size  # go further in the packet, after the audio frame\n            \n#TODO: get position info\n            \n    def set_application_string(self, string):\n        \"\"\"Set the application name, that can be viewed by other clients on the server\"\"\"\n        self.application = string\n    def set_loop_rate(self, rate):\n        \"\"\"set the current main loop rate (pause per iteration)\"\"\"\n        self.loop_rate = rate\n        \n    def get_loop_rate(self):\n        \"\"\"get the current main loop rate (pause per iteration)\"\"\"\n        return(self.loop_rate)\n    def set_receive_sound(self, value):\n        \"\"\"Enable or disable the management of incoming sounds\"\"\"\n        if value:\n            self.receive_sound = True\n        else:\n            self.receive_sound = False\n    def is_ready(self):\n        \"\"\"Wait for the connection to be fully completed.  To be used in the main thread\"\"\"\n        self.ready_lock.acquire()\n        self.ready_lock.release()\n        \n    def execute_command(self, cmd, blocking=True):\n        \"\"\"Create a command to be sent to the server.  To be userd in the main thread\"\"\"\n        self.is_ready()\n        \n        lock = self.commands.new_cmd(cmd)\n        if blocking and self.mumble_thread is not threading.current_thread():\n            lock.acquire()\n            lock.release()\n        return lock\n#TODO: manage a timeout for blocking commands.  Currently, no command actually waits for the server to execute\n#      The result of these commands should actually be checked against incoming server updates\n        \n    def treat_command(self, cmd):\n        \"\"\"Send the awaiting commands to the server.  Used in the pymumble thread.\"\"\"\n        if cmd.cmd == PYMUMBLE_CMD_MOVE:\n            userstate = mumble_pb2.UserState()\n            userstate.session = cmd.parameters[\"session\"]\n            userstate.channel_id = cmd.parameters[\"channel_id\"]\n            self.Log.debug(\"Moving to channel\")\n            self.send_message(PYMUMBLE_MSG_TYPES_USERSTATE, userstate)\n            cmd.response = True\n            self.commands.answer(cmd)\n        elif cmd.cmd == PYMUMBLE_CMD_MODUSERSTATE:\n            userstate = mumble_pb2.UserState()\n            userstate.session = cmd.parameters[\"session\"]\n            \n            if \"mute\" in cmd.parameters:\n                userstate.mute = cmd.parameters[\"mute\"]\n            if \"self_mute\" in cmd.parameters:\n                userstate.self_mute = cmd.parameters[\"self_mute\"]\n            if \"deaf\" in cmd.parameters:\n                userstate.deaf = cmd.parameters[\"deaf\"]\n            if \"self_deaf\" in cmd.parameters:\n                userstate.self_deaf = cmd.parameters[\"self_deaf\"]\n            if \"suppress\" in cmd.parameters:\n                userstate.suppress = cmd.parameters[\"suppress\"]\n            if \"recording\" in cmd.parameters:\n                userstate.recording = cmd.parameters[\"recording\"]\n            if \"comment\" in cmd.parameters:\n                userstate.comment = cmd.parameters[\"comment\"]\n            if \"texture\" in cmd.parameters:\n", "outputs": ["                userstate.texture = cmd.parameters[\"texture\"]"], "input_length": 3127, "output_length": 8, "length": 3135, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "80a4582c6d67b80b1f816f00754451efe535e12cc0a9baba33254019f024da8e"}
{"input": "", "context": "package com.censoredsoftware.capitalism.data;\nimport com.censoredsoftware.capitalism.Capitalism;\nimport com.censoredsoftware.capitalism.data.util.ServerDatas;\nimport com.censoredsoftware.capitalism.data.util.TimedDatas;\nimport com.censoredsoftware.capitalism.entity.Firm;\nimport com.censoredsoftware.capitalism.entity.Person;\nimport com.censoredsoftware.censoredlib.data.ServerData;\nimport com.censoredsoftware.censoredlib.data.TimedData;\nimport com.censoredsoftware.censoredlib.helper.ConfigFile;\nimport com.google.common.collect.Maps;\nimport org.bukkit.Bukkit;\nimport org.bukkit.ChatColor;\nimport org.bukkit.configuration.ConfigurationSection;\nimport org.bukkit.entity.Player;\nimport java.util.HashMap;\nimport java.util.Map;\nimport java.util.UUID;\nimport java.util.concurrent.ConcurrentMap;\npublic class DataManager\n{\n\t// Data\n\tpublic static ConcurrentMap<String, Person> persons;\n\tpublic static ConcurrentMap<UUID, Firm> firms;\n\tpublic static ConcurrentMap<UUID, TimedData> timedData;\n\tpublic static ConcurrentMap<UUID, ServerData> serverData;\n\tprivate static ConcurrentMap<String, HashMap<String, Object>> tempData;\n\tstatic\n\t{\n\t\tfor(File file : File.values())\n\t\t\tfile.getConfigFile().loadToData();\n\t\ttempData = Maps.newConcurrentMap();\n\t}\n\tpublic static void save()\n\t{\n\t\tfor(File file : File.values())\n\t\t\tfile.getConfigFile().saveToFile();\n\t}\n\tpublic static void flushData()\n\t{\n\t\t// Kick everyone\n\t\tfor(Player player : Bukkit.getOnlinePlayers())\n\t\t\tplayer.kickPlayer(ChatColor.GREEN + \"Data has been reset, you can rejoin now.\");\n\t\t// Clear the data\n\t\tpersons.clear();\n\t\tfirms.clear();\n\t\ttimedData.clear();\n\t\ttempData.clear();\n\t\tserverData.clear();\n\t\tsave();\n\t\t// Reload the PLUGIN\n\t\tBukkit.getServer().getPluginManager().disablePlugin(Capitalism.PLUGIN);\n\t\tBukkit.getServer().getPluginManager().enablePlugin(Capitalism.PLUGIN);\n\t}\n\t/*\n\t * Temporary data\n\t */\n\tpublic static boolean hasKeyTemp(String key, String subKey)\n\t{\n\t\treturn tempData.containsKey(key) && tempData.get(key).containsKey(subKey);\n\t}\n\tpublic static Object getValueTemp(String key, String subKey)\n\t{\n\t\tif(tempData.containsKey(key)) return tempData.get(key).get(subKey);\n\t\telse return null;\n\t}\n\tpublic static void saveTemp(String key, String subKey, Object value)\n\t{\n\t\tif(!tempData.containsKey(key)) tempData.put(key, new HashMap<String, Object>());\n\t\ttempData.get(key).put(subKey, value);\n\t}\n\tpublic static void removeTemp(String key, String subKey)\n\t{\n\t\tif(tempData.containsKey(key) && tempData.get(key).containsKey(subKey)) tempData.get(key).remove(subKey);\n\t}\n\t/*\n\t * Timed data\n\t */\n\tpublic static void saveTimed(String key, String subKey, Object data, Integer seconds)\n\t{\n\t\t// Remove the data if it exists already\n\t\tTimedDatas.remove(key, subKey);\n\t\t// Create and save the timed data\n\t\tTimedData timedData = new TimedData();\n\t\ttimedData.generateId();\n\t\ttimedData.setKey(key);\n\t\ttimedData.setSubKey(subKey);\n\t\ttimedData.setData(data.toString());\n\t\ttimedData.setSeconds(seconds);\n\t\tDataManager.timedData.put(timedData.getId(), timedData);\n\t}\n\tpublic static void removeTimed(String key, String subKey)\n\t{\n\t\tTimedDatas.remove(key, subKey);\n\t}\n\tpublic static boolean hasTimed(String key, String subKey)\n\t{\n\t\treturn TimedDatas.find(key, subKey) != null;\n\t}\n\tpublic static Object getTimedValue(String key, String subKey)\n\t{\n\t\treturn TimedDatas.find(key, subKey).getData();\n\t}\n\tpublic static long getTimedExpiration(String key, String subKey)\n\t{\n\t\treturn TimedDatas.find(key, subKey).getExpiration();\n\t}\n\t/*\n\t * Server data\n\t */\n\tpublic static void saveServerData(String key, String subKey, Object data)\n\t{\n\t\t// Remove the data if it exists already\n\t\tServerDatas.remove(key, subKey);\n\t\t// Create and save the timed data\n\t\tServerData serverData = new ServerData();\n\t\tserverData.generateId();\n\t\tserverData.setKey(key);\n\t\tserverData.setSubKey(subKey);\n\t\tserverData.setData(data.toString());\n\t\tDataManager.serverData.put(serverData.getId(), serverData);\n\t}\n\tpublic static void removeServerData(String key, String subKey)\n\t{\n\t\tServerDatas.remove(key, subKey);\n\t}\n\tpublic static boolean hasServerData(String key, String subKey)\n\t{\n\t\treturn ServerDatas.find(key, subKey) != null;\n\t}\n\tpublic static Object getServerDataValue(String key, String subKey)\n\t{\n\t\treturn ServerDatas.find(key, subKey).getData();\n\t}\n\tpublic static enum File\n\t{\n\t\tPLAYER(new ConfigFile<String, Person>()\n\t\t{\n\t\t\t@Override\n\t\t\tpublic Person create(String string, ConfigurationSection conf)\n\t\t\t{\n\t\t\t\treturn new Person(string, conf);\n\t\t\t}\n\t\t\t@Override\n\t\t\tpublic ConcurrentMap<String, Person> getLoadedData()\n\t\t\t{\n\t\t\t\treturn DataManager.persons;\n\t\t\t}\n\t\t\t@Override\n\t\t\tpublic String getSavePath()\n\t\t\t{\n\t\t\t\treturn Capitalism.SAVE_PATH;\n\t\t\t}\n\t\t\t@Override\n\t\t\tpublic String getSaveFile()\n\t\t\t{\n\t\t\t\treturn \"persons.yml\";\n\t\t\t}\n\t\t\t@Override\n\t\t\tpublic Map<String, Object> serialize(String string)\n\t\t\t{\n\t\t\t\treturn getLoadedData().get(string).serialize();\n\t\t\t}\n\t\t\t@Override\n\t\t\tpublic String convertFromString(String stringId)\n\t\t\t{\n\t\t\t\treturn stringId;\n\t\t\t}\n\t\t\t@Override\n\t\t\tpublic void loadToData()\n\t\t\t{\n\t\t\t\tpersons = loadFromFile();\n\t\t\t}\n\t\t}), FIRM(new ConfigFile<UUID, Firm>()\n\t\t{\n\t\t\t@Override\n\t\t\tpublic Firm create(UUID id, ConfigurationSection conf)\n\t\t\t{\n\t\t\t\treturn new Firm(id, conf);\n\t\t\t}\n\t\t\t@Override\n\t\t\tpublic ConcurrentMap<UUID, Firm> getLoadedData()\n\t\t\t{\n\t\t\t\treturn DataManager.firms;\n\t\t\t}\n\t\t\t@Override\n\t\t\tpublic String getSavePath()\n\t\t\t{\n\t\t\t\treturn Capitalism.SAVE_PATH;\n\t\t\t}\n\t\t\t@Override\n\t\t\tpublic String getSaveFile()\n\t\t\t{\n\t\t\t\treturn \"firms.yml\";\n\t\t\t}\n\t\t\t@Override\n\t\t\tpublic Map<String, Object> serialize(UUID id)\n\t\t\t{\n\t\t\t\treturn getLoadedData().get(id).serialize();\n\t\t\t}\n\t\t\t@Override\n\t\t\tpublic UUID convertFromString(String stringId)\n\t\t\t{\n\t\t\t\treturn UUID.fromString(stringId);\n\t\t\t}\n\t\t\t@Override\n\t\t\tpublic void loadToData()\n\t\t\t{\n", "outputs": ["\t\t\t\tfirms = loadFromFile();"], "input_length": 1023, "output_length": 6, "length": 1029, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "6b7fbdc56c308bd42218fac82fddb5fc0cf03727fceb16ea9b63e50f4cdd7515"}
{"input": "", "context": "package org.checkerframework.checker.igj;\nimport org.checkerframework.checker.igj.qual.AssignsFields;\nimport org.checkerframework.checker.igj.qual.I;\nimport org.checkerframework.checker.igj.qual.Immutable;\nimport org.checkerframework.checker.igj.qual.Mutable;\nimport org.checkerframework.checker.igj.qual.ReadOnly;\nimport org.checkerframework.common.basetype.BaseAnnotatedTypeFactory;\nimport org.checkerframework.common.basetype.BaseTypeChecker;\nimport org.checkerframework.framework.type.AnnotatedTypeFactory;\nimport org.checkerframework.framework.type.AnnotatedTypeMirror;\nimport org.checkerframework.framework.type.AnnotatedTypeMirror.AnnotatedArrayType;\nimport org.checkerframework.framework.type.AnnotatedTypeMirror.AnnotatedDeclaredType;\nimport org.checkerframework.framework.type.AnnotatedTypeMirror.AnnotatedExecutableType;\nimport org.checkerframework.framework.type.AnnotatedTypeMirror.AnnotatedTypeVariable;\nimport org.checkerframework.framework.type.AnnotatedTypeMirror.AnnotatedWildcardType;\nimport org.checkerframework.framework.type.DefaultTypeHierarchy;\nimport org.checkerframework.framework.type.QualifierHierarchy;\nimport org.checkerframework.framework.type.TypeHierarchy;\nimport org.checkerframework.framework.type.treeannotator.ListTreeAnnotator;\nimport org.checkerframework.framework.type.treeannotator.TreeAnnotator;\nimport org.checkerframework.framework.type.typeannotator.ListTypeAnnotator;\nimport org.checkerframework.framework.type.typeannotator.TypeAnnotator;\nimport org.checkerframework.framework.type.visitor.AnnotatedTypeScanner;\nimport org.checkerframework.framework.type.visitor.SimpleAnnotatedTypeVisitor;\nimport org.checkerframework.framework.type.visitor.VisitHistory;\nimport org.checkerframework.framework.util.AnnotatedTypes;\nimport org.checkerframework.framework.util.GraphQualifierHierarchy;\nimport org.checkerframework.framework.util.MultiGraphQualifierHierarchy.MultiGraphFactory;\nimport org.checkerframework.javacutil.AnnotationUtils;\nimport org.checkerframework.javacutil.ElementUtils;\nimport org.checkerframework.javacutil.ErrorReporter;\nimport org.checkerframework.javacutil.Pair;\nimport org.checkerframework.javacutil.TreeUtils;\nimport org.checkerframework.javacutil.TypesUtils;\nimport java.util.Collection;\nimport java.util.Collections;\nimport java.util.HashMap;\nimport java.util.HashSet;\nimport java.util.Iterator;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Set;\nimport javax.lang.model.element.AnnotationMirror;\nimport javax.lang.model.element.Element;\nimport javax.lang.model.element.ElementKind;\nimport javax.lang.model.element.TypeElement;\nimport javax.lang.model.type.TypeKind;\nimport javax.lang.model.type.TypeVariable;\nimport com.sun.source.tree.ClassTree;\nimport com.sun.source.tree.ExpressionTree;\nimport com.sun.source.tree.MethodInvocationTree;\nimport com.sun.source.tree.NewClassTree;\nimport com.sun.source.tree.Tree;\nimport com.sun.source.tree.TypeCastTree;\n/**\n * Adds implicit and default IGJ annotations, only if the user does not\n * annotate the type explicitly.  The default annotations are designed\n * to minimize the number of {@code Immutable} or {@code ReadOnly}\n * appearing in the source code.\n * <p>\n *\n * Implicit Annotations for literals:<br>\n * Immutable  -  any primitive literal (e.g. integer, long, boolean, etc.)<br>\n * IGJBottom  -  a null literal\n * <p>\n *\n * However, due to the default setting being similar to the implicit\n * annotations, there is no significant distinction between the two in\n * implementation.\n * <p>\n *\n * Default Annotations:\n * <p>\n *\n * This factory will add the {@link Immutable} annotation to a type if the\n * input is\n * <ol>\n * <li value=\"1\">(*)a primitive type,\n * <li value=\"2\">a known immutable type, if the class type is annotated as\n *    {@code Immutable}\n * </ol>\n *\n * It will add the {@link ReadOnly} annotation to a type if the input is\n * <ol>\n * <li value=\"3\">a method receiver for an immutable class\n * <li value=\"4\">a result of unification of different immutabilities (e.g.\n *    within Conditional Expressions)\n * <li value=\"5\">supertype of a wildcard/type parameter in a class/method declaration\n * </ol>\n *\n * It will add {@link IGJBottom}, a special bottom annotation to a type if\n * the input can be assigned to anything, like the following cases:\n * <ol>\n * <li value=\"6\">(*)the input is a {@code null} literal\n * <li value=\"7\">(*)the input is an unannotated new array tree\n * <li value=\"8\">the input is an unannotated new class tree invoking a constructor\n *    of {@code ReadOnly} or {@code AssignsFields} receiver type\n * <li value=\"9\">the input is the class or interface declaration\n * </ol>\n *\n * It will add the {@link Mutable} annotation to a type if\n * <ol>\n * <li value=\"10\">any remaining unqualified types (i.e. Mutable is the default)\n * </ol>\n *\n * Implementation detail:  (*) cases are handled with a meta-annotation\n * rather than in this class.\n * <p>\n *\n * Furthermore, it resolves {@link I} annotation to the proper annotation,\n * according to its specification (described in {@link I} javadoc).\n */\n//\n// To ease dealing with libraries, this inserts the bottom qualifier\n// rather than immutable in many cases, like all literals.\n// Should change that\npublic class IGJAnnotatedTypeFactory extends BaseAnnotatedTypeFactory {\n    //\n    // IGJ tries to adhere to the various rules specified by the\n    // type system and the conventions of the framework, except for two\n    // things:\n    // 1. overloading the meaning of BOTTOM_QUAL\n    //    Review the javadoc of #createQualiferHierarchy\n    //\n    // 2. Having two qualifiers for a given type in one particular case\n    //    which is that the self type (i.e. type of 'this' identifier) within\n    //    a method with an AssignsFields receiver within I classes, then the self type is\n    //    '@AssignsFields @I EnclosingClass' and they are treated as\n    //    Incomparable.  This is useful in the following cases:\n    //\n    //    a. for method invocability tests, a method with an AssignsFields receiver from within\n    //       a readonly context can be called only via AssignsFields reference\n    //       of 'this'.  I cannot be a receiver type, so it doesn't interfere.\n    //\n    //    b. for assignment, 'this' can be assigned to '@I EnclosingClass'\n    //       reference within such methods (assignment encompasses the escape\n    //       of this when passed to method parameters).  Fields and variables\n    //       cannot be AssignsFields, so it's safe.\n    //\n    //    The design of QualifierHierarchy.isSubtype(Collection, Collection)\n    //    reflect this choice.\n    //\n    /** Supported annotations for IGJ.  Used for subtyping rules. **/\n    protected final AnnotationMirror READONLY, MUTABLE, IMMUTABLE, I, ASSIGNS_FIELDS, BOTTOM_QUAL;\n    /** the {@link I} annotation value key */\n    protected static final String IMMUTABILITY_KEY = \"value\";\n    /**\n     * Constructor for IGJAnnotatedTypeFactory object.\n     *\n     * @param checker the checker to which this factory belongs\n     */\n    public IGJAnnotatedTypeFactory(BaseTypeChecker checker) {\n        super(checker);\n        READONLY = AnnotationUtils.fromClass(elements, ReadOnly.class);\n        MUTABLE = AnnotationUtils.fromClass(elements, Mutable.class);\n        IMMUTABLE = AnnotationUtils.fromClass(elements, Immutable.class);\n        I = AnnotationUtils.fromClass(elements, I.class);\n        ASSIGNS_FIELDS = AnnotationUtils.fromClass(elements, AssignsFields.class);\n        BOTTOM_QUAL = AnnotationUtils.fromClass(elements, IGJBottom.class);\n        addAliasedAnnotation(org.jmlspecs.annotation.Immutable.class, IMMUTABLE);\n        addAliasedAnnotation(org.jmlspecs.annotation.Readonly.class, READONLY);\n        addAliasedAnnotation(net.jcip.annotations.Immutable.class, IMMUTABLE);\n        // TODO: Add an alias for the Pure JML annotation. It's not a type qualifier, I think adding\n        // it above does not work. Also see NullnessAnnotatedTypeFactory.\n        // this.addAliasedDeclAnnotation(org.jmlspecs.annotation.Pure.class, Pure.class, annotationToUse);\n        this.postInit();\n    }\n    @Override\n    protected TreeAnnotator createTreeAnnotator() {\n        return new ListTreeAnnotator(\n                super.createTreeAnnotator(),\n                new IGJTreePreAnnotator(this)\n        );\n    }\n    @Override\n    protected TypeAnnotator createTypeAnnotator() {\n        return new ListTypeAnnotator(\n                new IGJTypePostAnnotator(this),\n                super.createTypeAnnotator()\n        );\n    }\n    // TODO: do store annotations into the Element -> remove this override\n    // Currently, many test cases fail without this.\n    @Override\n    public void postProcessClassTree(ClassTree tree) {\n    }\n    // **********************************************************************\n    // add implicit annotations\n    // **********************************************************************\n    /**\n     * Helper class for annotating unannotated types.\n     */\n    private class IGJTypePostAnnotator extends TypeAnnotator {\n        public IGJTypePostAnnotator(IGJAnnotatedTypeFactory atypeFactory) {\n            super(atypeFactory);\n        }\n        /**\n         * For Declared types:\n         *  Classes are mutable\n         *  Interface declaration are placeholders\n         *  Enum and annotations  are immutable\n         */\n        @Override\n        public Void visitDeclared(AnnotatedDeclaredType type, Void p) {\n            if (!hasImmutabilityAnnotation(type)) {\n                // Actual element\n                TypeElement element = (TypeElement)type.getUnderlyingType().asElement();\n                AnnotatedDeclaredType elementType = fromElement(element);\n                // ElementKind elemKind = elem != null ? elem.getKind() : ElementKind.OTHER;\n                if (TypesUtils.isBoxedPrimitive(type.getUnderlyingType())\n                        || element.getQualifiedName().contentEquals(\"java.lang.String\")\n                        || ElementUtils.isObject(element)) {\n                    // variation of case 1\n                    // TODO: These cases are more of hacks and they should\n                    // really be immutable or readonly\n                    type.addAnnotation(BOTTOM_QUAL);\n                } else if (elementType.hasEffectiveAnnotation(IMMUTABLE)) {\n                    // case 2: known immutable types\n                    type.addAnnotation(IMMUTABLE);\n                }\n            }\n            return null; //super.visitDeclared(type, p);\n            /*\n            if (!hasImmutabilityAnnotation(type)) {\n                // Actual element\n                TypeElement element = (TypeElement)type.getUnderlyingType().asElement();\n                AnnotatedDeclaredType elementType = fromElement(element);\n                // ElementKind elemKind = elem != null ? elem.getKind() : ElementKind.OTHER;\n                if (TypesUtils.isBoxedPrimitive(type.getUnderlyingType())\n                        || element.getQualifiedName().contentEquals(\"java.lang.String\")\n                        || ElementUtils.isObject(element)) {\n                    // variation of case 1\n                    // TODO: These cases are more of hacks and they should\n                    // really be immutable or readonly\n                    type.replaceAnnotation(BOTTOM_QUAL);\n                } else if (elementType.hasEffectiveAnnotation(IMMUTABLE)) {\n                    // case 2: known immutable types\n                    type.replaceAnnotation(IMMUTABLE);\n                //} else if (elemKind == ElementKind.LOCAL_VARIABLE) {\n                //    type.replaceAnnotation(READONLY);\n                } else if (elementType.hasEffectiveAnnotation(MUTABLE)) { // not immutable\n                    // case 7: mutable by default\n                    type.replaceAnnotation(MUTABLE);\n                //} else if (elemKind.isClass() || elemKind.isInterface()) {\n                    // case 9: class or interface declaration\n                //    type.replaceAnnotation(BOTTOM_QUAL);\n                //} else if (elemKind.isField()) {\n                    /*\n                        && type.getElement() != null // We don't know the field context here\n                        && getAnnotatedType(ElementUtils.enclosingClass(type.getElement())).hasEffectiveAnnotation(IMMUTABLE)) {\n                    type.replaceAnnotation(IMMUTABLE);\n                    TODO: This case is not exercised by any of the test cases. Is it needed?\n                } else if (element.getKind().isClass() || element.getKind().isInterface()) {\n                    // case 10\n                    type.replaceAnnotation(MUTABLE);\n                } else {\n                    assert false : \"shouldn't be here!\";\n                }\n            }\n            return super.visitDeclared(type, p);\n            */\n        }\n        @Override\n        public Void visitExecutable(AnnotatedExecutableType type, Void p) {\n            AnnotatedDeclaredType receiver;\n            if (type.getElement().getKind() == ElementKind.CONSTRUCTOR) {\n                receiver = (AnnotatedDeclaredType) type.getReturnType();\n            } else {\n                receiver = type.getReceiverType();\n            }\n            if (receiver != null &&\n                    hasImmutabilityAnnotation(receiver)) {\n                return super.visitExecutable(type, p);\n            }\n            TypeElement ownerElement = ElementUtils.enclosingClass(type.getElement());\n            AnnotatedDeclaredType ownerType = getAnnotatedType(ownerElement);\n            if (type.getElement().getKind() == ElementKind.CONSTRUCTOR) {\n                // TODO: hack\n                if (ownerType.hasEffectiveAnnotation(MUTABLE) || ownerType.hasEffectiveAnnotation(BOTTOM_QUAL))\n                    receiver.replaceAnnotation(MUTABLE);\n                else\n                    receiver.replaceAnnotation(ASSIGNS_FIELDS);\n            } else if (receiver == null) {\n                // Nothing to do for static methods.\n            } else if (ElementUtils.isObject(ownerElement) || ownerType.hasEffectiveAnnotation(IMMUTABLE)) {\n                // case 3\n                receiver.replaceAnnotation(BOTTOM_QUAL);\n            } else {\n                // case 10: rest\n                receiver.replaceAnnotation(MUTABLE);\n            }\n            return super.visitExecutable(type, p);\n        }\n/*\n        @Override\n        public Void visitTypeVariable(AnnotatedTypeVariable type, Void p) {\n            // In a declaration the upperbound is ReadOnly, while\n            // the upper bound in a use is Mutable\n            if (type.getUpperBoundField() != null\n                    && !hasImmutabilityAnnotation(type.getUpperBoundField())) {\n                // ElementKind elemKind = elem != null ? elem.getKind() : ElementKind.OTHER;\n                /*if (elemKind.isClass() || elemKind.isInterface()\n                        || elemKind == ElementKind.CONSTRUCTOR\n                        || elemKind == ElementKind.METHOD)\n                    // case 5: upper bound within a class/method declaration\n                    type.getUpperBoundField().replaceAnnotation(READONLY);\n                else* / if (TypesUtils.isObject(type.getUnderlyingType()))\n                    // case 10: remaining cases\n                    type.getUpperBoundField().replaceAnnotation(MUTABLE);\n            }\n            return super.visitTypeVariable(type, p);\n        }\n*/\n        @Override\n        public Void visitWildcard(AnnotatedWildcardType type, Void p) {\n            // In a declaration the upper bound is ReadOnly, while\n            // the upper bound in a use is Mutable\n            if (type.getExtendsBound() != null\n                    && !hasImmutabilityAnnotation(type.getExtendsBound())) {\n                // ElementKind elemKind = elem != null ? elem.getKind() : ElementKind.OTHER;\n                /*if (elemKind.isClass() || elemKind.isInterface()\n                        || elemKind == ElementKind.CONSTRUCTOR\n                        || elemKind == ElementKind.METHOD)\n                    // case 5: upper bound within a class/method declaration\n                    type.getExtendsBound().replaceAnnotation(READONLY);\n                else*/ if (TypesUtils.isObject(type.getUnderlyingType()))\n                    // case 10: remaining cases\n                    type.getExtendsBound().replaceAnnotation(MUTABLE);\n            }\n            return super.visitWildcard(type, p);\n        }\n    }\n    /**\n     * Helper class to annotate trees.\n     *\n     * It only adds a BOTTOM_QUAL for new classes and new arrays,\n     * when an annotation is not specified\n     */\n    private class IGJTreePreAnnotator extends TreeAnnotator {\n        public IGJTreePreAnnotator(IGJAnnotatedTypeFactory atypeFactory) {\n            super(atypeFactory);\n        }\n        @Override\n        public Void visitNewClass(NewClassTree node, AnnotatedTypeMirror p) {\n            /*\n            if (node.getClassBody() != null) {\n                System.out.println(\"Visit anonymous: \" + node + \" + input: \" + p);\n                AnnotatedTypeMirror tt = IGJAnnotatedTypeFactory.this.getAnnotatedType(node.getIdentifier());\n                p.replaceAnnotations(tt.getAnnotations());\n                System.out.println(\"  final type: \" + p);\n                // Is this the right way to handle anonymous classes?\n            } else */\n            if (!hasImmutabilityAnnotation(p)) {\n                AnnotatedTypeMirror ct = fromElement(\n                        ((AnnotatedDeclaredType)p).getUnderlyingType().asElement());\n                if (!hasImmutabilityAnnotation(ct) || ct.hasAnnotationRelaxed(I)) {\n                    AnnotatedExecutableType con = getAnnotatedType(TreeUtils.elementFromUse(node));\n                    if (con.getReceiverType() != null &&\n                            con.getReceiverType().hasEffectiveAnnotation(IMMUTABLE))\n                        p.replaceAnnotation(IMMUTABLE);\n                    else\n                        p.replaceAnnotation(MUTABLE);\n                } else {\n                    // case 2: known immutability type\n                    p.addAnnotations(ct.getAnnotations());\n                }\n            }\n            return null;\n        }\n        @Override\n        public Void visitTypeCast(TypeCastTree node, AnnotatedTypeMirror p) {\n            if (!hasImmutabilityAnnotation(p)) {\n                AnnotatedTypeMirror castedType = getAnnotatedType(node.getExpression());\n                p.addAnnotations(castedType.getAnnotations());\n            }\n            return null;\n        }\n    }\n    @Override\n    protected AnnotatedDeclaredType getImplicitReceiverType(ExpressionTree tree) {\n        AnnotatedDeclaredType receiver = super.getImplicitReceiverType(tree);\n        if (receiver != null && !isMostEnclosingThisDeref(tree)) {\n            receiver.replaceAnnotation(READONLY);\n        }\n        return receiver;\n    }\n    /**\n     * Returns the type of field {@code this},  for the scope of this tree.\n     * In IGJ, the self type is the method receiver in this scope.\n     */\n    @Override\n    public AnnotatedDeclaredType getSelfType(Tree tree) {\n        AnnotatedDeclaredType act = getCurrentClassType(tree);\n        AnnotatedDeclaredType methodReceiver;\n        if (isWithinConstructor(tree)) {\n            methodReceiver = (AnnotatedDeclaredType) getAnnotatedType(visitorState.getMethodTree()).getReturnType();\n        } else {\n            methodReceiver = getCurrentMethodReceiver(tree);\n        }\n        if (methodReceiver == null)\n            return act;\n        // Are we in a mutable or Immutable scope\n        if (isWithinConstructor(tree) && !methodReceiver.hasEffectiveAnnotation(MUTABLE)) {\n            methodReceiver.replaceAnnotation(ASSIGNS_FIELDS);\n        }\n        if (methodReceiver.hasEffectiveAnnotation(MUTABLE) ||\n                methodReceiver.hasEffectiveAnnotation(IMMUTABLE)) {\n            return methodReceiver;\n        } else if (act.hasAnnotationRelaxed(I) || act.hasEffectiveAnnotation(IMMUTABLE)) {\n            if (methodReceiver.hasEffectiveAnnotation(ASSIGNS_FIELDS))\n                act.replaceAnnotation(ASSIGNS_FIELDS);\n            return act;\n        } else\n            return methodReceiver;\n    }\n    // **********************************************************************\n    // resolving @I Immutability\n    // **********************************************************************\n    /**\n     * Replace all instances of {@code @I} in the super types with the\n     * immutability of the current type\n     *\n     * @param type  the type whose supertypes are requested\n     * @param supertypes    the supertypes of type\n     */\n    @Override\n    protected void postDirectSuperTypes(AnnotatedTypeMirror type,\n            List<? extends AnnotatedTypeMirror> supertypes) {\n        super.postDirectSuperTypes(type, supertypes);\n        Map<String, AnnotationMirror> templateMapping =\n            new ImmutabilityTemplateCollector().visit(type);\n        new ImmutabilityResolver().visit(supertypes, templateMapping);\n        for (AnnotatedTypeMirror supertype: supertypes) {\n            typeAnnotator.visit(supertype, null);\n        }\n    }\n    /**\n     * Resolve the instances of {@code @I} in the {@code elementType} based\n     * on {@code owner}, according to is specification.\n     */\n    @Override\n    public void postAsMemberOf(AnnotatedTypeMirror elementType,\n            AnnotatedTypeMirror owner, Element element) {\n        resolveImmutabilityTypeVar(elementType, owner);\n    }\n    @Override\n    protected void annotateInheritedFromClass(/*@Mutable*/ AnnotatedTypeMirror type,\n            Set<AnnotationMirror> fromClass) {\n        // Ignore annotations inherited from a class.\n        // TODO: this mechanism is implemented in special IGJ logic and\n        // should be cleaned up.\n    }\n    /**\n     * Resolves {@code @I} in the type of the method type base on the method\n     * invocation tree parameters.  Any unresolved {@code @I}s is resolved to a\n     * place holder type.\n     *\n     * It resolves {@code @I} annotation in the following way:\n     * <ul>\n     *  <li>based on the tree receiver, done automatically through implicit\n     *      invocation of\n     *      {@link AnnotatedTypes#asMemberOf(Types, AnnotatedTypeFactory, AnnotatedTypeMirror, Element)}</li>\n     *  <li>based on the invocation passed parameters</li>\n     *  <li>if any yet unresolved immutability variables get resolved to a\n     *      wildcard type</li>\n     * </ul>\n     */\n    @Override\n    public Pair<AnnotatedExecutableType, List<AnnotatedTypeMirror>> methodFromUse(MethodInvocationTree tree) {\n        Pair<AnnotatedExecutableType, List<AnnotatedTypeMirror>> mfuPair = super.methodFromUse(tree);\n        AnnotatedExecutableType type = mfuPair.first;\n        // javac produces enum super calls with zero arguments even though the\n        // method element requires two.\n        // See also BaseTypeVisitor.visitMethodInvocation and\n        // CFGBuilder.CFGTranslationPhaseOne.visitMethodInvocation\n        if (TreeUtils.isEnumSuper(tree)) return mfuPair;\n        List<AnnotatedTypeMirror> requiredArgs = AnnotatedTypes.expandVarArgs(this, type, tree.getArguments());\n        List<AnnotatedTypeMirror> arguments = AnnotatedTypes.getAnnotatedTypes(this, requiredArgs, tree.getArguments());\n        ImmutabilityTemplateCollector collector = new ImmutabilityTemplateCollector();\n        Map<String, AnnotationMirror> matchingMapping = collector.visit(arguments, requiredArgs);\n        if (!matchingMapping.isEmpty())\n            new ImmutabilityResolver().visit(type, matchingMapping);\n        // For finding resolved types, rather than to actually resolve immutability\n        Map<String, AnnotationMirror> fromReceiver = collector.visit(getReceiverType(tree));\n        final Map<String, AnnotationMirror> mapping =\n            collector.reduce(matchingMapping, fromReceiver);\n        new AnnotatedTypeScanner<Void, Void>() {\n            @Override\n            public Void visitDeclared(AnnotatedDeclaredType type, Void p) {\n                if (type.hasAnnotationRelaxed(I)) {\n                    AnnotationMirror anno =\n                        type.getAnnotation(I.class);\n                    if (!mapping.containsValue(anno)) {\n                        type.replaceAnnotation(BOTTOM_QUAL);\n                    }\n                }\n                return super.visitDeclared(type, p);\n            }\n        }.visit(type);\n        return mfuPair;\n    }\n    /**\n     * Infers the immutability of {@code @I}s based on the provided types, and\n     * replace all instances of {@code @I} with their corresponding qualifiers.\n     * The {@code @I} annotations that are not resolved are left intact.\n     *\n     * @param type      the type with {@code @I} annotation\n     * @param provided  the types with qualifiers that may be bound to\n     *                  {@code @I}\n     * @return true iff a qualifier has been resolved.\n     */\n    private boolean resolveImmutabilityTypeVar(AnnotatedTypeMirror type,\n            AnnotatedTypeMirror ...provided) {\n        ImmutabilityTemplateCollector collector = new ImmutabilityTemplateCollector();\n        // maps the @I values to I resolved annotations\n        Map<String, AnnotationMirror> templateMapping = Collections.emptyMap();\n        for (AnnotatedTypeMirror pt : provided)\n            templateMapping = collector.reduce(templateMapping, collector.visit(pt));\n        // There is nothing to resolve\n        if (templateMapping.isEmpty())\n            return false;\n        new ImmutabilityResolver().visit(type, templateMapping);\n        return true;\n    }\n    /**\n     * A helper class that resolves the immutability on a types based on a\n     * provided mapping.\n     *\n     * It returns a set of the annotations that were inserted. This is important\n     * to recognize which immutability type variables were resolved and which\n     * are to be made into place holder.\n     */\n    private class ImmutabilityResolver extends\n    AnnotatedTypeScanner<Void, Map<String, AnnotationMirror>> {\n        public void visit(Iterable<? extends AnnotatedTypeMirror> types,\n                Map<String, AnnotationMirror> templateMapping) {\n            if (templateMapping != null && !templateMapping.isEmpty()) {\n                for (AnnotatedTypeMirror type : types)\n                    visit(type, templateMapping);\n            }\n        }\n        @Override\n        public Void visitDeclared(AnnotatedDeclaredType type,\n                Map<String, AnnotationMirror> p) {\n            if (type.hasAnnotationRelaxed(I)) {\n                String immutableString =\n                    AnnotationUtils.getElementValue(getImmutabilityAnnotation(type),\n                            IMMUTABILITY_KEY, String.class, true);\n                if (p.containsKey(immutableString)) {\n                    type.replaceAnnotation(p.get(immutableString));\n                }\n            }\n            return super.visitDeclared(type, p);\n        }\n    }\n    /**\n     * A Helper class that tries to resolve the immutability type variable,\n     * as the type variable is assigned to the most restricted immutability\n     */\n    private class ImmutabilityTemplateCollector\n    extends SimpleAnnotatedTypeVisitor<Map<String, AnnotationMirror>, AnnotatedTypeMirror> {\n        public Map<String, AnnotationMirror> reduce(Map<String, AnnotationMirror> r1,\n", "outputs": ["                Map<String, AnnotationMirror> r2) {"], "input_length": 4142, "output_length": 9, "length": 4151, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "d316273796e73ac60b536c017c48a5222d3d750623fc70c1b156340ec1bab480"}
{"input": "", "context": "// <file>\n//     <copyright see=\"prj:///doc/copyright.txt\"/>\n//     <license see=\"prj:///doc/license.txt\"/>\n//     <owner name=\"Daniel Grunwald\" email=\"daniel@danielgrunwald.de\"/>\n//     <version>$Revision$</version>\n// </file>\nusing System;\nusing System.Collections.Generic;\nusing System.IO;\nnamespace ICSharpCode.Core\n{\n\t/// <summary>\n\t/// Class that helps starting up ICSharpCode.Core.\n\t/// </summary>\n\t/// <remarks>\n\t/// Initializing ICSharpCode.Core requires initializing several static classes\n\t/// and the <see cref=\"AddInTree\"/>. <see cref=\"CoreStartup\"/> does this work\n\t/// for you, provided you use it like this:\n\t/// 1. Create a new CoreStartup instance\n\t/// 2. (Optional) Set the values of the properties.\n\t/// 3. Call <see cref=\"StartCoreServices()\"/>.\n\t/// 4. Add \"preinstalled\" AddIns using <see cref=\"AddAddInsFromDirectory\"/>\n\t///    and <see cref=\"AddAddInFile\"/>.\n\t/// 5. (Optional) Call <see cref=\"ConfigureExternalAddIns\"/> to support\n\t///    disabling AddIns and installing external AddIns\n\t/// 6. (Optional) Call <see cref=\"ConfigureUserAddIns\"/> to support installing\n\t///    user AddIns.\n\t/// 7. Call <see cref=\"RunInitialization\"/>.\n\t/// </remarks>\n\tpublic sealed class CoreStartup\n\t{\n\t\tList<string> addInFiles = new List<string>();\n\t\tList<string> disabledAddIns = new List<string>();\n\t\tbool externalAddInsConfigured;\n\t\tstring propertiesName;\n\t\tstring configDirectory;\n\t\tstring dataDirectory;\n\t\tstring applicationName;\n\t\t\n\t\t/// <summary>\n\t\t/// Sets the name used for the properties (only name, without path or extension).\n\t\t/// Must be set before StartCoreServices() is called.\n\t\t/// </summary>\n\t\tpublic string PropertiesName {\n\t\t\tget {\n\t\t\t\treturn propertiesName;\n\t\t\t}\n\t\t\tset {\n\t\t\t\tif (value == null || value.Length == 0)\n\t\t\t\t\tthrow new ArgumentNullException(\"value\");\n\t\t\t\tpropertiesName = value;\n\t\t\t}\n\t\t}\n\t\t\n\t\t/// <summary>\n\t\t/// Sets the directory name used for the property service.\n\t\t/// Must be set before StartCoreServices() is called.\n\t\t/// Use null to use the default path \"%ApplicationData%\\%ApplicationName%\",\n\t\t/// where %ApplicationData% is the system setting for\n\t\t/// \"c:\\documents and settings\\username\\application data\"\n\t\t/// and %ApplicationName% is the application name you used in the\n\t\t/// CoreStartup constructor call.\n\t\t/// </summary>\n\t\tpublic string ConfigDirectory {\n\t\t\tget {\n\t\t\t\treturn configDirectory;\n\t\t\t}\n\t\t\tset {\n\t\t\t\tconfigDirectory = value;\n\t\t\t}\n\t\t}\n\t\t\n\t\t/// <summary>\n\t\t/// Sets the data directory used to load resources.\n\t\t/// Must be set before StartCoreServices() is called.\n\t\t/// Use null to use the default path \"ApplicationRootPath\\data\".\n\t\t/// </summary>\n\t\tpublic string DataDirectory {\n\t\t\tget {\n\t\t\t\treturn dataDirectory;\n\t\t\t}\n\t\t\tset {\n\t\t\t\tdataDirectory = value;\n\t\t\t}\n\t\t}\n\t\t\n\t\t/// <summary>\n\t\t/// Creates a new CoreStartup instance.\n\t\t/// </summary>\n\t\t/// <param name=\"applicationName\">\n\t\t/// The name of your application.\n\t\t/// This is used as default title for message boxes,\n\t\t/// default name for the configuration directory etc.\n\t\t/// </param>\n\t\tpublic CoreStartup(string applicationName)\n\t\t{\n\t\t\tif (applicationName == null)\n\t\t\t\tthrow new ArgumentNullException(\"applicationName\");\n\t\t\tthis.applicationName = applicationName;\n\t\t\tpropertiesName = applicationName + \"Properties\";\n\t\t\tMessageService.DefaultMessageBoxTitle = applicationName;\n\t\t\tMessageService.ProductName = applicationName;\n\t\t}\n\t\t\n\t\t/// <summary>\n\t\t/// Find AddIns by searching all .addin files recursively in <paramref name=\"addInDir\"/>.\n\t\t/// The found AddIns are added to the list of AddIn files to load.\n\t\t/// </summary>\n\t\tpublic void AddAddInsFromDirectory(string addInDir)\n\t\t{\n\t\t\tif (addInDir == null)\n\t\t\t\tthrow new ArgumentNullException(\"addInDir\");\n\t\t\taddInFiles.AddRange(FileUtility.SearchDirectory(addInDir, \"*.addin\"));\n\t\t}\n\t\t\n\t\t/// <summary>\n\t\t/// Add the specified .addin file to the list of AddIn files to load.\n\t\t/// </summary>\n\t\tpublic void AddAddInFile(string addInFile)\n\t\t{\n\t\t\tif (addInFile == null)\n\t\t\t\tthrow new ArgumentNullException(\"addInFile\");\n\t\t\taddInFiles.Add(addInFile);\n\t\t}\n\t\t\n\t\t/// <summary>\n\t\t/// Use the specified configuration file to store information about\n\t\t/// disabled AddIns and external AddIns.\n\t\t/// You have to call this method to support the <see cref=\"AddInManager\"/>.\n\t\t/// </summary>\n\t\t/// <param name=\"addInConfigurationFile\">\n\t\t/// The name of the file used to store the list of disabled AddIns\n\t\t/// and the list of installed external AddIns.\n\t\t/// A good value for this parameter would be\n\t\t/// <c>Path.Combine(<see cref=\"PropertyService.ConfigDirectory\"/>, \"AddIns.xml\")</c>.\n\t\t/// </param>\n\t\tpublic void ConfigureExternalAddIns(string addInConfigurationFile)\n\t\t{\n\t\t\texternalAddInsConfigured = true;\n\t\t\tAddInManager.ConfigurationFileName = addInConfigurationFile;\n\t\t\tAddInManager.LoadAddInConfiguration(addInFiles, disabledAddIns);\n\t\t}\n\t\t\n\t\t/// <summary>\n\t\t/// Configures user AddIn support.\n\t\t/// </summary>\n\t\t/// <param name=\"addInInstallTemp\">\n\t\t/// The AddIn installation temporary directory.\n\t\t/// ConfigureUserAddIns will install the AddIns from this directory and\n\t\t/// store the parameter value in <see cref=\"AddInManager.AddInInstallTemp\"/>.\n\t\t/// </param>\n\t\t/// <param name=\"userAddInPath\">\n\t\t/// The path where user AddIns are installed to.\n\t\t/// AddIns from this directory will be loaded.\n\t\t/// </param>\n\t\tpublic void ConfigureUserAddIns(string addInInstallTemp, string userAddInPath)\n\t\t{\n\t\t\tif (!externalAddInsConfigured) {\n\t\t\t\tthrow new InvalidOperationException(\"ConfigureExternalAddIns must be called before ConfigureUserAddIns\");\n\t\t\t}\n\t\t\tAddInManager.AddInInstallTemp = addInInstallTemp;\n\t\t\tAddInManager.UserAddInPath = userAddInPath;\n\t\t\tif (Directory.Exists(addInInstallTemp)) {\n\t\t\t\tAddInManager.InstallAddIns(disabledAddIns);\n\t\t\t}\n\t\t\tif (Directory.Exists(userAddInPath)) {\n\t\t\t\tAddAddInsFromDirectory(userAddInPath);\n\t\t\t}\n\t\t}\n\t\t\n\t\t/// <summary>\n\t\t/// Initializes the AddIn system.\n\t\t/// This loads the AddIns that were added to the list,\n\t\t/// then it executes the <see cref=\"ICommand\">commands</see>\n\t\t/// in <c>/Workspace/Autostart</c>.\n\t\t/// </summary>\n\t\tpublic void RunInitialization()\n\t\t{\n\t\t\tAddInTree.Load(addInFiles, disabledAddIns);\n\t\t\t\n\t\t\t// run workspace autostart commands\n\t\t\tLoggingService.Info(\"Running autostart commands...\");\n\t\t\tforeach (ICommand command in AddInTree.BuildItems<ICommand>(\"/Workspace/Autostart\", null, false)) {\n\t\t\t\ttry {\n\t\t\t\t\tcommand.Run();\n\t\t\t\t} catch (Exception ex) {\n\t\t\t\t\t// allow startup to continue if some commands fail\n\t\t\t\t\tMessageService.ShowError(ex);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\n\t\t/// <summary>\n\t\t/// Starts the core services.\n\t\t/// This initializes the PropertyService and ResourceService.\n\t\t/// </summary>\n\t\tpublic void StartCoreServices()\n\t\t{\n", "outputs": ["\t\t\tif (configDirectory == null)"], "input_length": 1220, "output_length": 6, "length": 1226, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "aada0711be99d44ccac86a308ecb8f9b5af2c54097df882ccc440e58edfe9a00"}
{"input": "", "context": "//\n// System.Data.Constraint.cs\n//\n// Author:\n//\tFranklin Wise <gracenote@earthlink.net>\n//\tDaniel Morgan\n//      Tim Coleman (tim@timcoleman.com)\n//\n//\n// (C) Ximian, Inc. 2002\n// Copyright (C) Tim Coleman, 2002\n//\n//\n// Copyright (C) 2004 Novell, Inc (http://www.novell.com)\n//\n// Permission is hereby granted, free of charge, to any person obtaining\n// a copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to\n// permit persons to whom the Software is furnished to do so, subject to\n// the following conditions:\n//\n// The above copyright notice and this permission notice shall be\n// included in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n// EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n// NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\n// LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\n// OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\n// WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n//\nusing System;\nusing System.Collections;\nusing System.ComponentModel;\nusing System.Runtime.InteropServices;\nusing System.Runtime.Serialization;\nusing System.Data.Common;\nnamespace System.Data {\n\t[Serializable]\n\tinternal delegate void DelegateConstraintNameChange (object sender, string newName);\n\t[DefaultProperty (\"ConstraintName\")]\n#if !NET_2_0\n\t[Serializable]\n#endif\n\t[TypeConverterAttribute (typeof (ConstraintConverter))]\n\tpublic abstract class Constraint {\n\t\tstatic readonly object beforeConstraintNameChange = new object ();\n\t\tEventHandlerList events = new EventHandlerList ();\n\t\tinternal event DelegateConstraintNameChange BeforeConstraintNameChange {\n\t\t\tadd { events.AddHandler (beforeConstraintNameChange, value); }\n\t\t\tremove { events.RemoveHandler (beforeConstraintNameChange, value); }\n\t\t}\n\t\t//if constraintName is not set then a name is\n\t\t//created when it is added to\n\t\t//the ConstraintCollection\n\t\t//it can not be set to null, empty or duplicate\n\t\t//once it has been added to the collection\n\t\tprivate string _constraintName;\n\t\tprivate PropertyCollection _properties;\n\t\tprivate Index _index;\n\t\t//Used for membership checking\n\t\tprivate ConstraintCollection _constraintCollection;\n\t\tDataSet dataSet;\n\t\tprotected Constraint ()\n\t\t{\n\t\t\tdataSet = null;\n\t\t\t_properties = new PropertyCollection ();\n\t\t}\n\t\t[CLSCompliant (false)]\n\t\tprotected internal virtual DataSet _DataSet {\n\t\t\tget { return dataSet; }\n\t\t}\n\t\t[DataCategory (\"Data\")]\n#if !NET_2_0\n\t\t[DataSysDescription (\"Indicates the name of this constraint.\")]\n#endif\n\t\t[DefaultValue (\"\")]\n\t\tpublic virtual string ConstraintName {\n\t\t\tget { return _constraintName == null ? \"\" : _constraintName; }\n\t\t\tset {\n\t\t\t\t//This should only throw an exception when it\n\t\t\t\t//is a member of a ConstraintCollection which\n\t\t\t\t//means we should let the ConstraintCollection\n\t\t\t\t//handle exceptions when this value changes\n\t\t\t\t_onConstraintNameChange (value);\n\t\t\t\t_constraintName = value;\n\t\t\t}\n\t\t}\n\t\t[Browsable (false)]\n\t\t[DataCategory (\"Data\")]\n#if !NET_2_0\n\t\t[DataSysDescription (\"The collection that holds custom user information.\")]\n#endif\n\t\tpublic PropertyCollection ExtendedProperties {\n\t\t\tget { return _properties; }\n\t\t}\n#if !NET_2_0\n\t\t[DataSysDescription (\"Indicates the table of this constraint.\")]\n#endif\n\t\tpublic abstract DataTable Table {\n\t\t\tget;\n\t\t}\n\t\tinternal ConstraintCollection ConstraintCollection {\n\t\t\tget { return _constraintCollection; }\n\t\t\tset { _constraintCollection = value; }\n\t\t}\n\t\tprivate void _onConstraintNameChange (string newName)\n\t\t{\n\t\t\tDelegateConstraintNameChange eh = events [beforeConstraintNameChange] as DelegateConstraintNameChange;\n\t\t\tif (eh != null)\n\t\t\t\teh (this, newName);\n\t\t}\n\t\t//call once before adding a constraint to a collection\n\t\t//will throw an exception to prevent the add if a rule is broken\n\t\tinternal abstract void AddToConstraintCollectionSetup (ConstraintCollection collection);\n\t\tinternal abstract bool IsConstraintViolated ();\n\t\tinternal static void ThrowConstraintException ()\n\t\t{\n\t\t\tthrow new ConstraintException(\"Failed to enable constraints. One or more rows contain values violating non-null, unique, or foreign-key constraints.\");\n\t\t}\n\t\tbool initInProgress = false;\n\t\tinternal virtual bool InitInProgress {\n\t\t\tget { return initInProgress; }\n\t\t\tset { initInProgress = value; }\n\t\t}\n\t\tinternal virtual void FinishInit (DataTable table)\n\t\t{\n\t\t}\n\t\tinternal void AssertConstraint ()\n\t\t{\n\t\t\t// The order is important.. IsConstraintViolated fills the RowErrors if it detects\n\t\t\t// a violation\n\t\t\tif (!IsConstraintViolated ())\n\t\t\t\treturn;\n\t\t\tif (Table._duringDataLoad || (Table.DataSet != null && !Table.DataSet.EnforceConstraints))\n\t\t\t\treturn;\n\t\t\tThrowConstraintException ();\n\t\t}\n\t\tinternal abstract void AssertConstraint (DataRow row);\n\t\tinternal virtual void RollbackAssert (DataRow row)\n\t\t{\n\t\t}\n\t\t//call once before removing a constraint to a collection\n\t\t//can throw an exception to prevent the removal\n\t\tinternal abstract void RemoveFromConstraintCollectionCleanup (ConstraintCollection collection);\n\t\t[MonoTODO]\n\t\tprotected void CheckStateForProperty ()\n\t\t{\n\t\t\tthrow new NotImplementedException ();\n\t\t}\n\t\tprotected internal void SetDataSet (DataSet dataSet)\n\t\t{\n\t\t\tthis.dataSet = dataSet;\n\t\t}\n\t\tinternal void SetExtendedProperties (PropertyCollection properties)\n\t\t{\n\t\t\t_properties = properties;\n\t\t}\n\t\tinternal Index Index {\n\t\t\tget { return _index; }\n\t\t\tset {\n\t\t\t\tif (_index != null) {\n\t\t\t\t\t_index.RemoveRef();\n\t\t\t\t\tTable.DropIndex(_index);\n\t\t\t\t}\n\t\t\t\t_index = value;\n\t\t\t\tif (_index != null)\n\t\t\t\t\t_index.AddRef();\n\t\t\t}\n\t\t}\n", "outputs": ["\t\tinternal abstract bool IsColumnContained (DataColumn column);"], "input_length": 995, "output_length": 9, "length": 1004, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "46b93022e06b71dc9982647db65ebaa38a672b5f8252f4e3648ffacf1fa6771a"}
{"input": "", "context": "import unittest\nimport os\nimport mock\nimport errno\nimport testlib\nclass TestTestContext(unittest.TestCase):\n    def test_generate_inventory_file(self):\n        context = testlib.TestContext()\n        context.inventory = dict(key='value')\n        self.assertEquals(\"key='value'\", context.generate_inventory_contents())\n    @testlib.with_context\n    def test_adapter_adds_scsi_host_entry(self, context):\n        context.add_adapter(testlib.SCSIAdapter())\n        self.assertEquals(['host0'], os.listdir('/sys/class/scsi_host'))\n    @testlib.with_context\n    def test_add_disk_adds_scsi_disk_entry(self, context):\n        import glob\n        adapter = context.add_adapter(testlib.SCSIAdapter())\n        adapter.add_disk()\n        self.assertEquals(\n            ['/sys/class/scsi_disk/0:0:0:0'],\n            glob.glob('/sys/class/scsi_disk/0*'))\n    @testlib.with_context\n    def test_add_disk_adds_scsibus_entry(self, context):\n        import glob\n        adapter = context.add_adapter(testlib.SCSIAdapter())\n        adapter.long_id = 'HELLO'\n        adapter.add_disk()\n        self.assertEquals(\n            ['/dev/disk/by-scsibus/HELLO-0:0:0:0'],\n            glob.glob('/dev/disk/by-scsibus/*'))\n    @testlib.with_context\n    def test_add_disk_adds_device(self, context):\n        adapter = context.add_adapter(testlib.SCSIAdapter())\n        adapter.add_disk()\n        self.assertEquals(\n            ['sda'],\n            os.listdir('/sys/class/scsi_disk/0:0:0:0/device/block'))\n    @testlib.with_context\n    def test_add_disk_adds_disk_by_id_entry(self, context):\n        adapter = context.add_adapter(testlib.SCSIAdapter())\n        disk = adapter.add_disk()\n        disk.long_id = 'SOMEID'\n        self.assertEquals(['SOMEID'], os.listdir('/dev/disk/by-id'))\n    @testlib.with_context\n    def test_add_disk_adds_glob(self, context):\n        import glob\n        adapter = context.add_adapter(testlib.SCSIAdapter())\n        disk = adapter.add_disk()\n        self.assertEquals(['/dev/disk/by-id'], glob.glob('/dev/disk/by-id'))\n    @testlib.with_context\n    def test_add_disk_path_exists(self, context):\n        adapter = context.add_adapter(testlib.SCSIAdapter())\n        disk = adapter.add_disk()\n        self.assertTrue(os.path.exists('/dev/disk/by-id'))\n    @testlib.with_context\n    def test_add_parameter_parameter_file_exists(self, context):\n        adapter = context.add_adapter(testlib.SCSIAdapter())\n        disk = adapter.add_disk()\n        adapter.add_parameter('fc_host', {'node_name': 'ignored'})\n        self.assertTrue(os.path.exists('/sys/class/fc_host/host0/node_name'))\n    @testlib.with_context\n    def test_add_parameter_parameter_file_contents(self, context):\n        adapter = context.add_adapter(testlib.SCSIAdapter())\n        disk = adapter.add_disk()\n        adapter.add_parameter('fc_host', {'node_name': 'value'})\n        param_file = open('/sys/class/fc_host/host0/node_name')\n        param_value = param_file.read()\n        param_file.close()\n        self.assertEquals('value', param_value)\n    @testlib.with_context\n    def test_uname_explicitly_defined(self, context):\n        context.kernel_version = 'HELLO'\n        import os\n        result = os.uname()\n        self.assertEquals('HELLO', result[2])\n    @testlib.with_context\n    def test_uname_default_kernel_version(self, context):\n        import os\n        result = os.uname()\n        self.assertEquals('3.1', result[2])\n    @testlib.with_context\n    def test_inventory(self, context):\n        context.inventory = {}\n        inventory_file = open('/etc/xensource-inventory', 'rb')\n        inventory = inventory_file.read()\n        inventory_file.close()\n        self.assertEquals('', inventory)\n    @testlib.with_context\n    def test_default_inventory(self, context):\n        inventory_file = open('/etc/xensource-inventory', 'rb')\n        inventory = inventory_file.read()\n        inventory_file.close()\n        self.assertEquals(\"PRIMARY_DISK='/dev/disk/by-id/primary'\", inventory)\n    @testlib.with_context\n    def test_exists_returns_false_for_non_existing(self, context):\n        self.assertFalse(os.path.exists('somefile'))\n    @testlib.with_context\n    def test_exists_returns_true_for_root(self, context):\n        self.assertTrue(os.path.exists('/'))\n    @testlib.with_context\n    def test_stat_nonexistent_file_throws_oserror(self, context):\n        self.assertRaises(\n            OSError,\n            lambda: os.stat('/nonexistingstuff'))\n    @testlib.with_context\n    def test_stat_does_not_fail_with_existing_file(self, context):\n        os.makedirs('/existingstuff')\n        os.stat('/existingstuff')\n    @testlib.with_context\n    def test_error_codes_read(self, context):\n        context.setup_error_codes()\n        errorcodes_file = open('/opt/xensource/sm/XE_SR_ERRORCODES.xml', 'rb')\n        errorcodes = errorcodes_file.read()\n        errorcodes_file.close()\n        self.assertTrue(\"<SM-errorcodes>\" in errorcodes)\n    @testlib.with_context\n    def test_executable_shows_up_on_filesystem(self, context):\n        context.add_executable('/something', None)\n        self.assertTrue(os.path.exists('/something'))\n    @testlib.with_context\n    def test_subprocess_execution(self, context):\n        context.add_executable(\n            'something',\n            lambda args, inp: (1, inp + ' out', ','.join(args)))\n        import subprocess\n        proc = subprocess.Popen(\n            ['something', 'a', 'b'],\n            stdin=subprocess.PIPE,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            close_fds=True)\n        out, err = proc.communicate('in')\n        rc = proc.returncode\n        self.assertEquals(1, rc)\n        self.assertEquals('in out', out)\n        self.assertEquals('something,a,b', err)\n    @testlib.with_context\n    def test_modinfo(self, context):\n        import subprocess\n        proc = subprocess.Popen(\n            ['/sbin/modinfo', '-d', 'somemodule'],\n            stdin=subprocess.PIPE,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            close_fds=True)\n        out, err = proc.communicate('in')\n        rc = proc.returncode\n        self.assertEquals(0, rc)\n        self.assertEquals('somemodule-description', out)\n        self.assertEquals('', err)\n    @testlib.with_context\n    def test_makedirs_mocked_out(self, context):\n        import os\n        os.makedirs('/blah/subdir')\n        self.assertTrue(os.path.exists('/blah/subdir'))\n    @testlib.with_context\n    def test_makedirs_raises_if_exists(self, context):\n        import os\n        os.makedirs('/blah/subdir')\n        self.assertRaises(OSError, os.makedirs, '/blah/subdir')\n    @testlib.with_context\n    def test_setup_error_codes(self, context):\n        context.setup_error_codes()\n        self.assertTrue(\n            os.path.exists('/opt/xensource/sm/XE_SR_ERRORCODES.xml'))\n    @testlib.with_context\n    def test_write_a_file(self, context):\n        import os\n        os.makedirs('/blah/subdir')\n        f = open('/blah/subdir/somefile', 'w+')\n        f.write('hello')\n        f.close()\n        self.assertTrue(\n            ('/blah/subdir/somefile', 'hello')\n            in list(context.generate_path_content()))\n    @testlib.with_context\n    def test_write_a_file_in_non_existing_dir(self, context):\n        with self.assertRaises(IOError) as cm:\n            open('/blah/subdir/somefile', 'w')\n        self.assertEquals(errno.ENOENT, cm.exception.errno)\n    @testlib.with_context\n    def test_file_returns_an_object_with_fileno_callable(self, context):\n        f = file('/file', 'w+')\n        self.assertTrue(hasattr(f, 'fileno'))\n        self.assertTrue(callable(f.fileno))\n    @testlib.with_context\n    def test_filenos_are_unique(self, context):\n        import os\n        os.makedirs('/blah/subdir')\n        file_1 = file('/blah/subdir/somefile', 'w+')\n        fileno_1 = file_1.fileno()\n        file_2 = file('/blah/subdir/somefile2', 'w+')\n        fileno_2 = file_2.fileno()\n        self.assertTrue(fileno_1 != fileno_2)\n    def test_get_created_directories(self):\n        context = testlib.TestContext()\n        context.fake_makedirs('/some/path')\n        self.assertEquals([\n            '/',\n            '/some',\n            '/some/path'],\n            context.get_created_directories())\n    def test_popen_raises_error(self):\n        import subprocess\n", "outputs": ["        context = testlib.TestContext()"], "input_length": 1132, "output_length": 5, "length": 1137, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "42c0afa1720fe1a15745f44eb34903a6ef7fb9f60c16555d780884ec6e3047bc"}
{"input": "", "context": "using System.Collections.Generic;\nusing System.Linq;\nusing AutoJIT.Contrib;\nusing AutoJIT.CSharpConverter.ConversionModule.Helper;\nusing AutoJIT.CSharpConverter.ConversionModule.StatementConverter.Interface;\nusing AutoJIT.Parser;\nusing AutoJIT.Parser.AST;\nusing AutoJIT.Parser.AST.Statements;\nusing AutoJIT.Parser.AST.Statements.Interface;\nusing AutoJIT.Parser.AST.Visitor;\nusing AutoJIT.Parser.Extensions;\nusing AutoJITRuntime;\nusing Microsoft.CodeAnalysis;\nusing Microsoft.CodeAnalysis.CSharp;\nusing Microsoft.CodeAnalysis.CSharp.Syntax;\nnamespace AutoJIT.CSharpConverter.ConversionModule.Visitor\n{\n    public class ConversionVisitor : SyntaxVisitorBase<IEnumerable<CSharpSyntaxNode>>\n    {\n        private readonly ICSharpSkeletonFactory _cSharpSkeletonFactory;\n        private readonly IInjectionService _injectionService;\n        protected IContextService ContextService;\n        public ConversionVisitor( IInjectionService injectionService, IContextService contextService, ICSharpSkeletonFactory cSharpSkeletonFactory ) {\n            _injectionService = injectionService;\n            ContextService = contextService;\n            _cSharpSkeletonFactory = cSharpSkeletonFactory;\n        }\n        public void InitializeContext( IContext context ) {\n            ContextService.Initialize( context );\n        }\n        public override IEnumerable<CSharpSyntaxNode> VisitAssignStatement( AssignStatement node ) {\n            return GetConverter<AssignStatement>().Convert( node, ContextService );\n        }\n        public override IEnumerable<CSharpSyntaxNode> VisitContinueCaseStatement( ContinueCaseStatement node ) {\n            return GetConverter<ContinueCaseStatement>().Convert( node, ContextService );\n        }\n        public override IEnumerable<CSharpSyntaxNode> VisitContinueLoopStatement( ContinueLoopStatement node ) {\n            return GetConverter<ContinueLoopStatement>().Convert( node, ContextService );\n        }\n        public override IEnumerable<CSharpSyntaxNode> VisitDimStatement( DimStatement node ) {\n            return GetConverter<DimStatement>().Convert( node, ContextService );\n        }\n        public override IEnumerable<CSharpSyntaxNode> VisitDoUntilStatement( DoUntilStatement node ) {\n            return GetConverter<DoUntilStatement>().Convert( node, ContextService );\n        }\n        public override IEnumerable<CSharpSyntaxNode> VisitExitloopStatement( ExitloopStatement node ) {\n            return GetConverter<ExitloopStatement>().Convert( node, ContextService );\n        }\n        public override IEnumerable<CSharpSyntaxNode> VisitExitStatement( ExitStatement node ) {\n            return GetConverter<ExitStatement>().Convert( node, ContextService );\n        }\n        public override IEnumerable<CSharpSyntaxNode> VisitForInStatement( ForInStatement node ) {\n            return GetConverter<ForInStatement>().Convert( node, ContextService );\n        }\n        public override IEnumerable<CSharpSyntaxNode> VisitForToNextStatement( ForToNextStatement node ) {\n            return GetConverter<ForToNextStatement>().Convert( node, ContextService );\n        }\n        public override IEnumerable<CSharpSyntaxNode> VisitFunctionCallStatement( FunctionCallStatement node ) {\n            return GetConverter<FunctionCallStatement>().Convert( node, ContextService );\n        }\n        public override IEnumerable<CSharpSyntaxNode> VisitGlobalDeclarationStatement( GlobalDeclarationStatement node ) {\n            return GetConverter<GlobalDeclarationStatement>().Convert( node, ContextService );\n        }\n        public override IEnumerable<CSharpSyntaxNode> VisitIfElseStatement( IfElseStatement node ) {\n            return GetConverter<IfElseStatement>().Convert( node, ContextService );\n        }\n        public override IEnumerable<CSharpSyntaxNode> VisitInitDefaultParameterStatement( InitDefaultParameterStatement node ) {\n            return GetConverter<InitDefaultParameterStatement>().Convert( node, ContextService );\n        }\n        public override IEnumerable<CSharpSyntaxNode> VisitLocalDeclarationStatement( LocalDeclarationStatement node ) {\n            return GetConverter<LocalDeclarationStatement>().Convert( node, ContextService );\n        }\n        public override IEnumerable<CSharpSyntaxNode> VisitStaticDeclarationStatement( StaticDeclarationStatement node ) {\n            return GetConverter<StaticDeclarationStatement>().Convert( node, ContextService );\n        }\n        public override IEnumerable<CSharpSyntaxNode> VisitGlobalEnumDeclarationStatement( GlobalEnumDeclarationStatement node ) {\n            return GetConverter<GlobalEnumDeclarationStatement>().Convert( node, ContextService );\n        }\n        public override IEnumerable<CSharpSyntaxNode> VisitLocalEnumDeclarationStatement( LocalEnumDeclarationStatement node ) {\n            return GetConverter<LocalEnumDeclarationStatement>().Convert( node, ContextService );\n        }\n        public override IEnumerable<CSharpSyntaxNode> VisitReDimStatement( ReDimStatement node ) {\n            return GetConverter<ReDimStatement>().Convert( node, ContextService );\n        }\n        public override IEnumerable<CSharpSyntaxNode> VisitReturnStatement( ReturnStatement node ) {\n            return GetConverter<ReturnStatement>().Convert( node, ContextService );\n        }\n        public override IEnumerable<CSharpSyntaxNode> VisitSelectCaseStatement( SelectCaseStatement node ) {\n            return GetConverter<SelectCaseStatement>().Convert( node, ContextService );\n        }\n        public override IEnumerable<CSharpSyntaxNode> VisitSwitchCaseStatement( SwitchCaseStatement node ) {\n            return GetConverter<SwitchCaseStatement>().Convert( node, ContextService );\n        }\n        public override IEnumerable<CSharpSyntaxNode> VisitWhileStatement( WhileStatement node ) {\n            return GetConverter<WhileStatement>().Convert( node, ContextService );\n        }\n        public override IEnumerable<CSharpSyntaxNode> VisitVariableFunctionCallStatement( VariableFunctionCallStatement node ) {\n            return GetConverter<VariableFunctionCallStatement>().Convert( node, ContextService );\n        }\n        public override IEnumerable<CSharpSyntaxNode> VisitFunction( Function node ) {\n            return Convert( node, ContextService ).ToEnumerable();\n        }\n        public override IEnumerable<CSharpSyntaxNode> VisitBlockStatement( BlockStatement node ) {\n            return GetConverter<BlockStatement>().Convert( node, ContextService );\n        }\n        public override IEnumerable<CSharpSyntaxNode> VisitAutoitScriptRoot( AutoitScriptRoot node ) {\n            var memberList = new SyntaxList<MemberDeclarationSyntax>();\n            ContextService.SetGlobalContext( true );\n            var blockSyntax = (BlockSyntax) node.MainFunction.Accept( this ).Single();\n            blockSyntax = blockSyntax.AddStatements(\n                SyntaxFactory.ReturnStatement( SyntaxFactory.LiteralExpression( SyntaxKind.NumericLiteralExpression, SyntaxFactory.Literal( \"0\", 0 ) ) ) );\n            var main = SyntaxFactory.MethodDeclaration(SyntaxFactory.IdentifierName(typeof(Variant).Name), \"Main\").AddModifiers(SyntaxFactory.Token(SyntaxKind.PublicKeyword)).WithBody(blockSyntax);\n            memberList = memberList.Add(main);\n            ContextService.SetGlobalContext( false );\n            memberList = memberList.AddRange( ContextService.PopGlobalVariables() );\n            ContextService.ResetFunctionContext();\n            foreach (Function function in node.Functions) {\n                memberList = memberList.Add( (MemberDeclarationSyntax) function.Accept( this ).Single() );\n                memberList = memberList.AddRange( ContextService.PopGlobalVariables() );\n                ContextService.ResetFunctionContext();\n            }\n            NamespaceDeclarationSyntax finalScript = _cSharpSkeletonFactory.EmbedInClassTemplate( new List<MemberDeclarationSyntax>( memberList ), ContextService.GetRuntimeInstanceName(), \"AutoJITScriptClass\", ContextService.GetContextInstanceName() );\n            finalScript = RemoveEmptyStatements( finalScript );\n            finalScript = FixByReferenceCalls( finalScript, memberList );\n            return finalScript.ToEnumerable();\n        }\n        protected MemberDeclarationSyntax Convert( Function function, IContextService context ) {\n            IList<IStatementNode> statementNodes = function.Statements.Block;\n            statementNodes = DeclareParameter( statementNodes, function.Parameter, context );\n            List<StatementSyntax> dotNetStatements = ConvertStatements( statementNodes );\n            dotNetStatements = OrderDeclarations( dotNetStatements );\n            if ( !( dotNetStatements.Last() is ReturnStatementSyntax ) ) {\n                dotNetStatements.Add( SyntaxFactory.ReturnStatement( SyntaxFactory.LiteralExpression( SyntaxKind.NumericLiteralExpression, SyntaxFactory.Literal( \"0\", 0 ) ) ) );    \n            }\n            BlockSyntax body = dotNetStatements.ToBlock();\n            return SyntaxFactory.MethodDeclaration( SyntaxFactory.IdentifierName( typeof (Variant).Name ), function.Name.Token.Value.StringValue ).AddModifiers( SyntaxFactory.Token( SyntaxKind.PublicKeyword ) ).WithParameterList( SyntaxFactory.ParameterList( CreaterParameter( function.Parameter, context ).ToSeparatedSyntaxList() ) ).WithBody( body );\n        }\n        private IList<IStatementNode> DeclareParameter( IList<IStatementNode> statementNodes, IEnumerable<AutoitParameter> parameter, IContextService context ) {\n            foreach (AutoitParameter parameterInfo in parameter) {\n                context.RegisterLocal( parameterInfo.ParameterName.Token.Value.StringValue );\n                if ( parameterInfo.DefaultValue != null ) {\n                    var statement = new InitDefaultParameterStatement( context.GetVariableName( parameterInfo.ParameterName.Token.Value.StringValue ), parameterInfo.DefaultValue );\n                    statement.Initialize();\n                    statementNodes.Insert( 0, statement );\n                }\n            }\n            return statementNodes;\n        }\n        private static List<StatementSyntax> OrderDeclarations( List<StatementSyntax> cSharpStatements ) {\n            List<LocalDeclarationStatementSyntax> allDeclarations = cSharpStatements.SelectMany( s => s.DescendantNodesAndSelf().OfType<LocalDeclarationStatementSyntax>() ).ToList();\n            for ( int index = 0; index < cSharpStatements.Count; index++ ) {\n                cSharpStatements[index] = cSharpStatements[index].ReplaceNodes( allDeclarations, ( node, syntaxNode ) => SyntaxFactory.EmptyStatement() );\n            }\n            cSharpStatements.InsertRange( 0, allDeclarations );\n            return cSharpStatements;\n        }\n        private List<StatementSyntax> ConvertStatements( IEnumerable<IStatementNode> statements ) {\n            List<CSharpSyntaxNode> nodes = statements.SelectMany( x => x.Accept( this ) ).ToList();\n            return nodes.OfType<StatementSyntax>().ToList();\n        }\n        private IEnumerable<ParameterSyntax> CreaterParameter( IEnumerable<AutoitParameter> parameters, IContextService context ) {\n            return parameters.Select(\n                p => {\n                    ParameterSyntax parameter = SyntaxFactory.Parameter( SyntaxFactory.Identifier( context.GetVariableName( p.ParameterName.Token.Value.StringValue ) ) ).WithType( SyntaxFactory.IdentifierName( typeof (Variant).Name ) );\n                    if ( p.DefaultValue != null ) {\n                        parameter = parameter.WithDefault( SyntaxFactory.EqualsValueClause( SyntaxFactory.LiteralExpression( SyntaxKind.NullLiteralExpression ) ) );\n                    }\n                    if ( p.IsByRef ) {\n                        parameter = parameter.WithModifiers( new SyntaxTokenList().Add( SyntaxFactory.Token( SyntaxKind.RefKeyword ) ) );\n                    }\n                    return parameter;\n                } );\n        }\n        private IAutoitStatementConverter<T, StatementSyntax> GetConverter<T>() where T : IStatementNode {\n            var converter = _injectionService.Inject<IAutoitStatementConverter<T, StatementSyntax>>();\n            return converter;\n        }\n        private static NamespaceDeclarationSyntax RemoveEmptyStatements( NamespaceDeclarationSyntax finalScript ) {\n            List<EmptyStatementSyntax> emptyStatements = finalScript.DescendantNodes().OfType<EmptyStatementSyntax>().Where( x => x.Parent.GetType() != typeof (LabeledStatementSyntax) ).ToList();\n            finalScript = finalScript.RemoveNodes( emptyStatements, SyntaxRemoveOptions.KeepEndOfLine );\n            return finalScript;\n        }\n        private static NamespaceDeclarationSyntax FixByReferenceCalls( NamespaceDeclarationSyntax finalScript, SyntaxList<MemberDeclarationSyntax> memberList ) {\n            var toReplace = new Dictionary<ArgumentSyntax, ArgumentSyntax>();\n            IEnumerable<ArgumentSyntax> argumentSyntaxs = finalScript.DescendantNodes().OfType<ArgumentSyntax>();\n", "outputs": ["            foreach (ArgumentSyntax argumentSyntax in argumentSyntaxs) {"], "input_length": 1572, "output_length": 8, "length": 1580, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "30cd4f52d9d8d4f998b3a50a21bbdb44609e66807791686c3cdf5791ff699ea9"}
{"input": "", "context": "import logging\nimport datetime\nimport simplejson\nimport tempfile\ntry:\n  from hashlib import md5\nexcept:\n  from md5 import md5\nfrom dirac.lib.base import *\nfrom dirac.lib.diset import getRPCClient, getTransferClient\nfrom dirac.lib.credentials import getUsername, getSelectedGroup, getSelectedSetup\nfrom DIRAC import S_OK, S_ERROR, gLogger, gConfig\nfrom DIRAC.Core.Utilities import Time, List\nfrom DIRAC.Core.Utilities.DictCache import DictCache\nfrom DIRAC.Core.Security import CS\nfrom DIRAC.AccountingSystem.Client.ReportsClient import ReportsClient\nfrom dirac.lib.webBase import defaultRedirect\nlog = logging.getLogger( __name__ )\nclass AccountingplotsController( BaseController ):\n  __keysCache = DictCache()\n  def __getUniqueKeyValues( self, typeName ):\n    userGroup = getSelectedGroup()\n    if 'NormalUser' in CS.getPropertiesForGroup( userGroup ):\n      cacheKey = ( getUsername(), userGroup, getSelectedSetup(), typeName )\n    else:\n      cacheKey = ( userGroup, getSelectedSetup(), typeName )\n    data = AccountingplotsController.__keysCache.get( cacheKey )\n    if not data:\n      rpcClient = getRPCClient( \"Accounting/ReportGenerator\" )\n      retVal = rpcClient.listUniqueKeyValues( typeName )\n      if 'rpcStub' in retVal:\n        del( retVal[ 'rpcStub' ] )\n      if not retVal[ 'OK' ]:\n        return retVal\n      #Site ordering based on TierLevel / alpha\n      if 'Site' in retVal[ 'Value' ]:\n        siteLevel = {}\n        for siteName in retVal[ 'Value' ][ 'Site' ]:\n          sitePrefix = siteName.split( \".\" )[0].strip()\n          level = gConfig.getValue( \"/Resources/Sites/%s/%s/MoUTierLevel\" % ( sitePrefix, siteName ), 10 )\n          if level not in siteLevel:\n            siteLevel[ level ] = []\n          siteLevel[ level ].append( siteName )\n        orderedSites = []\n        for level in sorted( siteLevel ):\n          orderedSites.extend( sorted( siteLevel[ level ] ) )\n        retVal[ 'Value' ][ 'Site' ] = orderedSites\n      data = retVal\n      AccountingplotsController.__keysCache.add( cacheKey, 300, data )\n    return data\n  def index( self ):\n    # Return a rendered template\n    #   return render('/some/template.mako')\n    # or, Return a response\n    return defaultRedirect()\n  def dataOperation( self ):\n    return self.__showPlotPage( \"DataOperation\", \"/systems/accounting/dataOperation.mako\" )\n  def job( self ):\n    return self.__showPlotPage( \"Job\", \"/systems/accounting/job.mako\" )\n  def WMSHistory( self ):\n    return self.__showPlotPage( \"WMSHistory\", \"/systems/accounting/WMSHistory.mako\" )\n  def pilot( self ):\n    return self.__showPlotPage( \"Pilot\", \"/systems/accounting/Pilot.mako\" )\n  def SRMSpaceTokenDeployment( self ):\n    return self.__showPlotPage( \"SRMSpaceTokenDeployment\", \"/systems/accounting/SRMSpaceTokenDeployment.mako\" )\n  def plotPage( self ):\n    try:\n      typeName = str( request.params[ 'typeName' ] )\n    except:\n      c.errorMessage = \"Oops. missing type\"\n      return render( \"/error.mako\" )\n    return self.__showPlotPage( typeName , \"/systems/accounting/%s.mako\" % typeName )\n  def __showPlotPage( self, typeName, templateFile ):\n    #Get unique key values\n    retVal = self.__getUniqueKeyValues( typeName )\n    if not retVal[ 'OK' ]:\n      c.error = retVal[ 'Message' ]\n      return render ( \"/error.mako\" )\n    c.selectionValues = simplejson.dumps( retVal[ 'Value' ] )\n    #Cache for plotsList?\n    data = AccountingplotsController.__keysCache.get( \"reportsList:%s\" % typeName )\n    if not data:\n      repClient = ReportsClient( rpcClient = getRPCClient( \"Accounting/ReportGenerator\" ) )\n      retVal = repClient.listReports( typeName )\n      if not retVal[ 'OK' ]:\n        c.error = retVal[ 'Message' ]\n        return render ( \"/error.mako\" )\n      data = simplejson.dumps( retVal[ 'Value' ] )\n      AccountingplotsController.__keysCache.add( \"reportsList:%s\" % typeName, 300, data )\n    c.plotsList = data\n    return render ( templateFile )\n  @jsonify\n  def getKeyValuesForType( self ):\n    try:\n      typeName = str( request.params[ 'typeName' ] )\n    except:\n      return S_ERROR( \"Missing or invalid type name!\" )\n    retVal = self.__getUniqueKeyValues( typeName )\n    if not retVal[ 'OK' ] and 'rpcStub' in retVal:\n      del( retVal[ 'rpcStub' ] )\n    return retVal\n  def __parseFormParams(self):\n    params = request.params\n    return parseFormParams(params)\n  def __translateToExpectedExtResult( self, retVal ):\n    if retVal[ 'OK' ]:\n      return { 'success' : True, 'data' : retVal[ 'Value' ][ 'plot' ] }\n    else:\n      return { 'success' : False, 'errors' : retVal[ 'Message' ] }\n  def __queryForPlot( self ):\n    retVal = self.__parseFormParams()\n    if not retVal[ 'OK' ]:\n      return retVal\n    params = retVal[ 'Value' ]\n    repClient = ReportsClient( rpcClient = getRPCClient( \"Accounting/ReportGenerator\" ) )\n    retVal = repClient.generateDelayedPlot( *params )\n    return retVal\n  def getPlotData( self ):\n    retVal = self.__parseFormParams()\n    if not retVal[ 'OK' ]:\n      c.error = retVal[ 'Message' ]\n      return render( \"/error.mako\" )\n    params = retVal[ 'Value' ]\n    repClient = ReportsClient( rpcClient = getRPCClient( \"Accounting/ReportGenerator\" ) )\n    retVal = repClient.getReport( *params )\n    if not retVal[ 'OK' ]:\n      c.error = retVal[ 'Message' ]\n      return render( \"/error.mako\" )\n    rawData = retVal[ 'Value' ]\n    groupKeys = rawData[ 'data' ].keys()\n    groupKeys.sort()\n    if 'granularity' in rawData:\n      granularity = rawData[ 'granularity' ]\n      data = rawData['data']\n      tS = int( Time.toEpoch( params[2] ) )\n      timeStart = tS - tS % granularity\n      strData = \"epoch,%s\\n\" % \",\".join( groupKeys )\n      for timeSlot in range( timeStart, int( Time.toEpoch( params[3] ) ), granularity ):\n        lineData = [ str( timeSlot ) ]\n        for key in groupKeys:\n          if timeSlot in data[ key ]:\n            lineData.append( str( data[ key ][ timeSlot ] ) )\n          else:\n            lineData.append( \"\" )\n        strData += \"%s\\n\" % \",\".join( lineData )\n    else:\n      strData = \"%s\\n\" % \",\".join( groupKeys )\n      strData += \",\".join( [ str( rawData[ 'data' ][ k ] ) for k in groupKeys ] )\n    response.headers['Content-type'] = 'text/csv'\n    response.headers['Content-Disposition'] = 'attachment; filename=\"%s.csv\"' % md5( str( params ) ).hexdigest()\n    response.headers['Content-Length'] = len( strData )\n    return strData\n  @jsonify\n  def generatePlot( self ):\n    return self.__translateToExpectedExtResult( self.__queryForPlot() )\n  def generatePlotAndGetHTML( self ):\n    retVal = self.__queryForPlot()\n    if not retVal[ 'OK' ]:\n      return \"<h2>Can't regenerate plot: %s</h2>\" % retVal[ 'Message' ]\n    return \"<img src='getPlotImg?file=%s'/>\" % retVal[ 'Value' ][ 'plot' ]\n  def getPlotImg( self ):\n    \"\"\"\n    Get plot image\n    \"\"\"\n    if 'file' not in request.params:\n      c.error = \"Maybe you forgot the file?\"\n      return render( \"/error.mako\" )\n    plotImageFile = str( request.params[ 'file' ] )\n    if plotImageFile.find( \".png\" ) < -1:\n      c.error = \"Not a valid image!\"\n      return render( \"/error.mako\" )\n    transferClient = getTransferClient( \"Accounting/ReportGenerator\" )\n    tempFile = tempfile.TemporaryFile()\n    retVal = transferClient.receiveFile( tempFile, plotImageFile )\n    if not retVal[ 'OK' ]:\n      c.error = retVal[ 'Message' ]\n      return render( \"/error.mako\" )\n    tempFile.seek( 0 )\n    data = tempFile.read()\n    response.headers['Content-type'] = 'image/png'\n    response.headers['Content-Disposition'] = 'attachment; filename=\"%s.png\"' % md5( plotImageFile ).hexdigest()\n    response.headers['Content-Length'] = len( data )\n    response.headers['Content-Transfer-Encoding'] = 'Binary'\n    response.headers['Cache-Control'] = \"no-cache, no-store, must-revalidate, max-age=0\"\n    response.headers['Pragma'] = \"no-cache\"\n    response.headers['Expires'] = ( datetime.datetime.utcnow() - datetime.timedelta( minutes = -10 ) ).strftime( \"%d %b %Y %H:%M:%S GMT\" )\n    return data\n  @jsonify\n  def getPlotListAndSelectionValues(self):\n    result = {}\n    try:\n      typeName = str( request.params[ 'typeName' ] )\n    except:\n      return S_ERROR( \"Missing or invalid type name!\" )\n    retVal = self.__getUniqueKeyValues( typeName )\n    if not retVal[ 'OK' ] and 'rpcStub' in retVal:\n      del( retVal[ 'rpcStub' ] )\n      return retVal\n    selectionValues = retVal['Value']\n    data = AccountingplotsController.__keysCache.get( \"reportsList:%s\" % typeName )\n    if not data:\n      repClient = ReportsClient( rpcClient = getRPCClient( \"Accounting/ReportGenerator\" ) )\n      retVal = repClient.listReports( typeName )\n      if not retVal[ 'OK' ]:\n        return retVal\n      data = simplejson.dumps( retVal[ 'Value' ] )\n      AccountingplotsController.__keysCache.add( \"reportsList:%s\" % typeName, 300, data )\n    try:\n      plotsList = eval(data)\n    except:\n      return S_ERROR('Failed to convert a string to a list!')\n    return S_OK({'SelectionData':selectionValues, 'PlotList':plotsList})\ndef parseFormParams(params):\n  pD = {}\n  extraParams = {}\n  pinDates = False\n  for name in params:\n    if name.find( \"_\" ) != 0:\n      continue\n    value = params[ name ]\n    name = name[1:]\n    pD[ name ] = str( value )\n  #Personalized title?\n  if 'plotTitle' in pD:\n    extraParams[ 'plotTitle' ] = pD[ 'plotTitle' ]\n    del( pD[ 'plotTitle' ] )\n  #Pin dates?\n  if 'pinDates' in pD:\n    pinDates = pD[ 'pinDates' ]\n    del( pD[ 'pinDates' ] )\n    pinDates = pinDates.lower() in ( \"yes\", \"y\", \"true\", \"1\" )\n  #Get plotname\n  if not 'grouping' in pD:\n    return S_ERROR( \"Missing grouping!\" )\n  grouping = pD[ 'grouping' ]\n  #Get plotname\n  if not 'typeName' in pD:\n    return S_ERROR( \"Missing type name!\" )\n  typeName = pD[ 'typeName' ]\n  del( pD[ 'typeName' ] )\n  #Get plotname\n  if not 'plotName' in pD:\n    return S_ERROR( \"Missing plot name!\" )\n", "outputs": ["  reportName = pD[ 'plotName' ]"], "input_length": 1841, "output_length": 7, "length": 1848, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "4b5e2dc34d2946e73cfbabf8b97ff6e33915f947a1c70a25e11ebab01151446c"}
{"input": "", "context": "/*\n    Copyright (C) 2014-2019 de4dot@gmail.com\n    This file is part of dnSpy\n    dnSpy is free software: you can redistribute it and/or modify\n    it under the terms of the GNU General Public License as published by\n    the Free Software Foundation, either version 3 of the License, or\n    (at your option) any later version.\n    dnSpy is distributed in the hope that it will be useful,\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n    GNU General Public License for more details.\n    You should have received a copy of the GNU General Public License\n    along with dnSpy.  If not, see <http://www.gnu.org/licenses/>.\n*/\nusing System;\nusing System.Collections.Generic;\nusing System.Diagnostics;\nusing System.IO;\nusing System.Text;\nusing dnlib.DotNet.MD;\nusing dnlib.PE;\nusing Microsoft.Build.Framework;\nusing Microsoft.Build.Utilities;\nnamespace MakeEverythingPublic {\n\tpublic sealed class MakeEverythingPublic : Task {\n\t\t// Increment it if something changes so the files are re-created\n\t\tconst string VERSION = \"v1\";\n#pragma warning disable CS8618 // Non-nullable field is uninitialized.\n\t\t[Required]\n\t\tpublic string IVTString { get; set; }\n\t\t[Required]\n\t\tpublic string DestinationDirectory { get; set; }\n\t\t[Required]\n\t\tpublic string AssembliesToMakePublic { get; set; }\n\t\t[Required]\n\t\tpublic ITaskItem[] ReferencePath { get; set; }\n\t\t[Output]\n\t\tpublic ITaskItem[] OutputReferencePath { get; private set; }\n#pragma warning restore CS8618 // Non-nullable field is uninitialized.\n\t\tpublic override bool Execute() {\n\t\t\tif (string.IsNullOrWhiteSpace(IVTString)) {\n\t\t\t\tLog.LogMessageFromText(nameof(IVTString) + \" is an empty string\", MessageImportance.High);\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\tif (string.IsNullOrWhiteSpace(DestinationDirectory)) {\n\t\t\t\tLog.LogMessageFromText(nameof(DestinationDirectory) + \" is an empty string\", MessageImportance.High);\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\tvar assembliesToFix = new HashSet<string>(StringComparer.OrdinalIgnoreCase);\n\t\t\tforeach (var tmp in AssembliesToMakePublic.Split(';')) {\n\t\t\t\tvar asmName = tmp.Trim();\n\t\t\t\tvar asmSimpleName = asmName;\n\t\t\t\tint index = asmSimpleName.IndexOf(',');\n\t\t\t\tif (index >= 0)\n\t\t\t\t\tasmSimpleName = asmSimpleName.Substring(0, index).Trim();\n\t\t\t\tif (asmSimpleName.Length == 0)\n\t\t\t\t\tcontinue;\n\t\t\t\tassembliesToFix.Add(asmSimpleName);\n\t\t\t}\n\t\t\tOutputReferencePath = new ITaskItem[ReferencePath.Length];\n\t\t\tbyte[]? ivtBlob = null;\n\t\t\tfor (int i = 0; i < ReferencePath.Length; i++) {\n\t\t\t\tvar file = ReferencePath[i];\n\t\t\t\tOutputReferencePath[i] = file;\n\t\t\t\tvar filename = file.ItemSpec;\n\t\t\t\tvar fileExt = Path.GetExtension(filename);\n\t\t\t\tvar asmSimpleName = Path.GetFileNameWithoutExtension(filename);\n\t\t\t\tif (!assembliesToFix.Contains(asmSimpleName))\n\t\t\t\t\tcontinue;\n\t\t\t\tif (!File.Exists(filename)) {\n\t\t\t\t\tLog.LogMessageFromText($\"File does not exist: {filename}\", MessageImportance.High);\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t\tvar patchDir = DestinationDirectory;\n\t\t\t\tDirectory.CreateDirectory(patchDir);\n\t\t\t\tvar fileInfo = new FileInfo(filename);\n\t\t\t\tlong filesize = fileInfo.Length;\n\t\t\t\tlong writeTime = fileInfo.LastWriteTimeUtc.ToBinary();\n\t\t\t\tvar extraInfo = $\"_{VERSION} {filesize} {writeTime}_\";\n\t\t\t\tvar patchedFilename = Path.Combine(patchDir, asmSimpleName + extraInfo + fileExt);\n\t\t\t\tif (StringComparer.OrdinalIgnoreCase.Equals(patchedFilename, filename))\n\t\t\t\t\tcontinue;\n\t\t\t\tif (!File.Exists(patchedFilename)) {\n\t\t\t\t\tif (ivtBlob is null)\n\t\t\t\t\t\tivtBlob = CreateIVTBlob(IVTString);\n\t\t\t\t\tvar data = File.ReadAllBytes(filename);\n\t\t\t\t\ttry {\n\t\t\t\t\t\tusing (var peImage = new PEImage(data, filename, ImageLayout.File, verify: true)) {\n\t\t\t\t\t\t\tusing (var md = MetadataFactory.CreateMetadata(peImage, verify: true)) {\n\t\t\t\t\t\t\t\tvar result = new IVTPatcher(data, md, ivtBlob).Patch();\n\t\t\t\t\t\t\t\tif (result != IVTPatcherResult.OK) {\n\t\t\t\t\t\t\t\t\tstring errMsg;\n\t\t\t\t\t\t\t\t\tswitch (result) {\n\t\t\t\t\t\t\t\t\tcase IVTPatcherResult.NoCustomAttributes:\n\t\t\t\t\t\t\t\t\t\terrMsg = $\"Assembly '{asmSimpleName}' has no custom attributes\";\n\t\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t\tcase IVTPatcherResult.NoIVTs:\n\t\t\t\t\t\t\t\t\t\terrMsg = $\"Assembly '{asmSimpleName}' has no InternalsVisibleToAttributes\";\n\t\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t\tcase IVTPatcherResult.IVTBlobTooSmall:\n\t\t\t\t\t\t\t\t\t\terrMsg = $\"Assembly '{asmSimpleName}' has no InternalsVisibleToAttribute blob that is big enough to store '{IVTString}'. Use a shorter assembly name and/or a shorter public key, or skip PublicKey=xxxx... altogether (if it's a C# assembly)\";\n\t\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t\t\t\t\tDebug.Fail($\"Unknown error result: {result}\");\n\t\t\t\t\t\t\t\t\t\terrMsg = \"Unknown error\";\n\t\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\tLog.LogMessageFromText(errMsg, MessageImportance.High);\n\t\t\t\t\t\t\t\t\treturn false;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\t\tFile.WriteAllBytes(patchedFilename, data);\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tcatch {\n\t\t\t\t\t\t\t\t\ttry { File.Delete(patchedFilename); } catch { }\n\t\t\t\t\t\t\t\t\tthrow;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tcatch (Exception ex) when (ex is IOException || ex is BadImageFormatException) {\n\t\t\t\t\t\tLog.LogMessageFromText($\"File '{filename}' is not a .NET file\", MessageImportance.High);\n\t\t\t\t\t\treturn false;\n\t\t\t\t\t}\n\t\t\t\t\tvar xmlDocFile = Path.ChangeExtension(filename, \"xml\");\n\t\t\t\t\tif (File.Exists(xmlDocFile)) {\n\t\t\t\t\t\tvar newXmlDocFile = Path.ChangeExtension(patchedFilename, \"xml\");\n\t\t\t\t\t\tif (File.Exists(newXmlDocFile))\n\t\t\t\t\t\t\tFile.Delete(newXmlDocFile);\n\t\t\t\t\t\tFile.Copy(xmlDocFile, newXmlDocFile);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tOutputReferencePath[i] = new TaskItem(patchedFilename);\n\t\t\t}\n\t\t\treturn true;\n\t\t}\n\t\tstatic byte[] CreateIVTBlob(string newIVTString) {\n\t\t\tvar caStream = new MemoryStream();\n\t\t\tvar caWriter = new BinaryWriter(caStream);\n\t\t\tcaWriter.Write((ushort)1);\n\t\t\tWriteString(caWriter, newIVTString);\n\t\t\tcaWriter.Write((ushort)0);\n\t\t\tvar newIVTBlob = caStream.ToArray();\n\t\t\tvar compressedSize = GetCompressedUInt32Bytes((uint)newIVTBlob.Length);\n\t\t\tvar blob = new byte[compressedSize + newIVTBlob.Length];\n\t\t\tvar blobStream = new MemoryStream(blob);\n\t\t\tvar blobWriter = new BinaryWriter(blobStream);\n\t\t\tWriteCompressedUInt32(blobWriter, (uint)newIVTBlob.Length);\n\t\t\tblobWriter.Write(newIVTBlob);\n\t\t\tif (blobWriter.BaseStream.Position != blob.Length)\n\t\t\t\tthrow new InvalidOperationException();\n\t\t\treturn blob;\n\t\t}\n\t\tstatic void WriteString(BinaryWriter writer, string s) {\n\t\t\tvar bytes = Encoding.UTF8.GetBytes(s);\n\t\t\tWriteCompressedUInt32(writer, (uint)bytes.Length);\n\t\t\twriter.Write(bytes);\n\t\t}\n\t\tstatic void WriteCompressedUInt32(BinaryWriter writer, uint value) {\n\t\t\tif (value <= 0x7F)\n\t\t\t\twriter.Write((byte)value);\n\t\t\telse if (value <= 0x3FFF) {\n\t\t\t\twriter.Write((byte)((value >> 8) | 0x80));\n\t\t\t\twriter.Write((byte)value);\n\t\t\t}\n\t\t\telse if (value <= 0x1FFFFFFF) {\n\t\t\t\twriter.Write((byte)((value >> 24) | 0xC0));\n\t\t\t\twriter.Write((byte)(value >> 16));\n\t\t\t\twriter.Write((byte)(value >> 8));\n\t\t\t\twriter.Write((byte)value);\n\t\t\t}\n\t\t\telse\n\t\t\t\tthrow new ArgumentOutOfRangeException(\"UInt32 value can't be compressed\");\n\t\t}\n\t\tstatic uint GetCompressedUInt32Bytes(uint value) {\n", "outputs": ["\t\t\tif (value <= 0x7F)"], "input_length": 1282, "output_length": 7, "length": 1289, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "46392ffe964f2e4e4983ea215ba762e2f47ef649bfaf14c1e4fb634c70adcdee"}
{"input": "", "context": "///////////////////////////////////////////////////////////////////////////////////////\n// Copyright (C) 2006-2019 Esper Team. All rights reserved.                           /\n// http://esper.codehaus.org                                                          /\n// ---------------------------------------------------------------------------------- /\n// The software in this package is published under the terms of the GPL license       /\n// a copy of which has been included with this distribution in the license.txt file.  /\n///////////////////////////////////////////////////////////////////////////////////////\nusing System;\nusing System.Collections.Generic;\nnamespace com.espertech.esper.common.@internal.collection\n{\n    /// <summary> reference-counting set based on a HashMap implementation that stores keys and a reference counter for\n    /// each unique key value. Each time the same key is added, the reference counter increases.\n    /// Each time a key is removed, the reference counter decreases.\n    /// </summary>\n    public class RefCountedSet<TK>\n    {\n        private bool _hasNullEntry;\n        private int _nullEntry;\n        private readonly IDictionary<TK, int> _refSet;\n        private int _numValues;\n        /// <summary>\n        /// Constructor.\n        /// </summary>\n        public RefCountedSet()\n        {\n            _refSet = new Dictionary<TK, int>();\n        }\n        public RefCountedSet(\n            IDictionary<TK, int> refSet,\n            int numValues)\n        {\n            _refSet = refSet;\n            _numValues = numValues;\n        }\n        /// <summary>\n        /// Adds a key to the set, but the key is null.  It behaves the same, but has its own\n        /// variables that need to be incremented.\n        /// </summary>\n        private bool AddNull()\n        {\n            if (!_hasNullEntry) {\n                _hasNullEntry = true;\n                _numValues++;\n                _nullEntry = 0;\n                return true;\n            }\n            _numValues++;\n            _nullEntry++;\n            return false;\n        }\n        /// <summary> Add a key to the set. Add with a reference count of one if the key didn't exist in the set.\n        /// Increase the reference count by one if the key already exists.\n        /// Return true if this is the first time the key was encountered, or false if key is already in set.\n        /// </summary>\n        /// <param name=\"key\">to add\n        /// </param>\n        /// <returns> true if the key is not in the set already, false if the key is already in the set\n        /// </returns>\n        public virtual bool Add(TK key)\n        {\n            if (ReferenceEquals(key, null)) {\n                return AddNull();\n            }\n            int value;\n            if (!_refSet.TryGetValue(key, out value)) {\n                _refSet[key] = 1;\n                _numValues++;\n                return true;\n            }\n            value++;\n            _numValues++;\n            _refSet[key] = value;\n            return false;\n        }\n        /// <summary>\n        /// Removes the null key\n        /// </summary>\n        private bool RemoveNull()\n        {\n            if (_nullEntry == 1) {\n                _hasNullEntry = false;\n                _nullEntry--;\n                return true;\n            }\n            _nullEntry--;\n            _numValues--;\n            return false;\n        }\n        /// <summary>\n        /// Adds the specified key.\n        /// </summary>\n        /// <param name=\"key\">The key.</param>\n        /// <param name=\"numReferences\">The num references.</param>\n        public void Add(\n            TK key,\n            int numReferences)\n        {\n            int value;\n            if (!_refSet.TryGetValue(key, out value)) {\n                _refSet[key] = numReferences;\n                _numValues += numReferences;\n                return;\n            }\n            throw new ArgumentException(\"Value '\" + key + \"' already in collection\");\n        }\n        /// <summary> Removed a key to the set. Removes the key if the reference count is one.\n        /// Decreases the reference count by one if the reference count is more then one.\n        /// Return true if the reference count was one and the key thus removed, or false if key is stays in set.\n        /// </summary>\n        /// <param name=\"key\">to add\n        /// </param>\n        /// <returns> true if the key is removed, false if it stays in the set\n        /// </returns>\n        /// <throws>  IllegalStateException is a key is removed that wasn't added to the map </throws>\n        public virtual bool Remove(TK key)\n        {\n            if (ReferenceEquals(key, null)) {\n                return RemoveNull();\n            }\n            int value;\n            if (!_refSet.TryGetValue(key, out value)) {\n                return true; // ignore duplcate removals\n            }\n            if (value == 1) {\n                _refSet.Remove(key);\n                _numValues--;\n                return true;\n            }\n            value--;\n            _refSet[key] = value;\n            _numValues--;\n            return false;\n        }\n        /// <summary>\n        /// Remove a key from the set regardless of the number of references.\n        /// </summary>\n        /// <param name=\"key\">to add</param>\n        /// <returns>\n        /// true if the key is removed, false if the key was not found\n        /// </returns>\n        /// <throws>IllegalStateException if a key is removed that wasn't added to the map</throws>\n        public bool RemoveAll(TK key)\n        {\n            return _refSet.Remove(key);\n        }\n        /// <summary> Returns an iterator over the entry set.</summary>\n        /// <returns> entry set iterator\n        /// </returns>\n        public IEnumerator<KeyValuePair<TK, int>> GetEnumerator()\n        {\n            if (_hasNullEntry) {\n                yield return new KeyValuePair<TK, int>(default(TK), _nullEntry);\n            }\n            foreach (KeyValuePair<TK, int> value in _refSet) {\n                yield return value;\n            }\n        }\n        /// <summary>\n        /// Gets the keys.\n        /// </summary>\n        /// <value>The keys.</value>\n        public ICollection<TK> Keys {\n            get { return _refSet.Keys; }\n        }\n        /// <summary> Returns the number of values in the collection.</summary>\n        /// <returns> size\n        /// </returns>\n        public virtual int Count {\n            get { return _numValues; }\n        }\n        /// <summary>\n        /// Clear out the collection.\n        /// </summary>\n        public virtual void Clear()\n        {\n            _refSet.Clear();\n            _numValues = 0;\n        }\n        public IDictionary<TK, int> RefSet {\n            get { return _refSet; }\n        }\n        public int NumValues {\n            get { return _numValues; }\n", "outputs": ["            set { _numValues = value; }"], "input_length": 1153, "output_length": 7, "length": 1160, "all_classes": "null", "language": "en", "dataset": "lcc", "_id": "c1478dbb40512d330c867d76b3b64c3dbe1dc23bbd763dea9ce8d63bbae32445"}
